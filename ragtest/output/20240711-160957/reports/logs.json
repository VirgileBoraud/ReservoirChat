{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"/home/l-t7-unknown/.local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"/home/l-t7-unknown/.local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py\", line 36, in _execute_llm\n    embedding = await self.client.embeddings.create(\n  File \"/home/l-t7-unknown/.local/lib/python3.10/site-packages/openai/resources/embeddings.py\", line 215, in create\n    return await self._post(\n  File \"/home/l-t7-unknown/.local/lib/python3.10/site-packages/openai/_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"/home/l-t7-unknown/.local/lib/python3.10/site-packages/openai/_base_client.py\", line 1519, in request\n    return await self._request(\n  File \"/home/l-t7-unknown/.local/lib/python3.10/site-packages/openai/_base_client.py\", line 1620, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.NotFoundError: <!doctype html>\n<html lang=en>\n<title>404 Not Found</title>\n<h1>Not Found</h1>\n<p>The requested URL was not found on the server. If you entered the URL manually please check your spelling and try again.</p>\n", "source": "<!doctype html>\n<html lang=en>\n<title>404 Not Found</title>\n<h1>Not Found</h1>\n<p>The requested URL was not found on the server. If you entered the URL manually please check your spelling and try again.</p>", "details": {"input": ["\"MA\u00ceTRE RENARD\":\"Ma\u00eetre Renard is a character who is attracted by the smell of the cheese and engages in a conversation with Ma\u00eetre Corbeau.\"", "\"PH\u00c9NIX DES H\u00d4TES DE CES BOIS\":\"Ph\u00e9nix des h\u00f4tes de ces bois is a metaphorical description of Ma\u00eetre Corbeau as the most beautiful bird in the woods.\"", "\"FROMAGE\":\"fromage is a piece of cheese that is being held by Ma\u00eetre Corbeau and is the subject of the conversation.\"", "\"MA\u00ceTRE CORBEAU\":", "\"JURA\":\"Jura is a geographic location, possibly a region or a country.\""]}}
{"type": "error", "data": "Error executing verb \"text_embed\" in create_final_entities: <!doctype html>\n<html lang=en>\n<title>404 Not Found</title>\n<h1>Not Found</h1>\n<p>The requested URL was not found on the server. If you entered the URL manually please check your spelling and try again.</p>", "stack": "Traceback (most recent call last):\n  File \"/home/l-t7-unknown/.local/lib/python3.10/site-packages/datashaper/workflow/workflow.py\", line 415, in _execute_verb\n    result = await result\n  File \"/home/l-t7-unknown/.local/lib/python3.10/site-packages/graphrag/index/verbs/text/embed/text_embed.py\", line 105, in text_embed\n    return await _text_embed_in_memory(\n  File \"/home/l-t7-unknown/.local/lib/python3.10/site-packages/graphrag/index/verbs/text/embed/text_embed.py\", line 130, in _text_embed_in_memory\n    result = await strategy_exec(texts, callbacks, cache, strategy_args)\n  File \"/home/l-t7-unknown/.local/lib/python3.10/site-packages/graphrag/index/verbs/text/embed/strategies/openai.py\", line 61, in run\n    embeddings = await _execute(llm, text_batches, ticker, semaphore)\n  File \"/home/l-t7-unknown/.local/lib/python3.10/site-packages/graphrag/index/verbs/text/embed/strategies/openai.py\", line 105, in _execute\n    results = await asyncio.gather(*futures)\n  File \"/home/l-t7-unknown/.local/lib/python3.10/site-packages/graphrag/index/verbs/text/embed/strategies/openai.py\", line 99, in embed\n    chunk_embeddings = await llm(chunk)\n  File \"/home/l-t7-unknown/.local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py\", line 104, in __call__\n    result = await self._delegate(input, **kwargs)\n  File \"/home/l-t7-unknown/.local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 177, in __call__\n    result, start = await execute_with_retry()\n  File \"/home/l-t7-unknown/.local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 159, in execute_with_retry\n    async for attempt in retryer:\n  File \"/home/l-t7-unknown/.local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n    do = await self.iter(retry_state=self._retry_state)\n  File \"/home/l-t7-unknown/.local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n    result = await action(retry_state)\n  File \"/home/l-t7-unknown/.local/lib/python3.10/site-packages/tenacity/_utils.py\", line 99, in inner\n    return call(*args, **kwargs)\n  File \"/home/l-t7-unknown/.local/lib/python3.10/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n  File \"/usr/lib/python3.10/concurrent/futures/_base.py\", line 451, in result\n    return self.__get_result()\n  File \"/usr/lib/python3.10/concurrent/futures/_base.py\", line 403, in __get_result\n    raise self._exception\n  File \"/home/l-t7-unknown/.local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 165, in execute_with_retry\n    return await do_attempt(), start\n  File \"/home/l-t7-unknown/.local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 147, in do_attempt\n    return await self._delegate(input, **kwargs)\n  File \"/home/l-t7-unknown/.local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 49, in __call__\n    return await self._invoke(input, **kwargs)\n  File \"/home/l-t7-unknown/.local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"/home/l-t7-unknown/.local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py\", line 36, in _execute_llm\n    embedding = await self.client.embeddings.create(\n  File \"/home/l-t7-unknown/.local/lib/python3.10/site-packages/openai/resources/embeddings.py\", line 215, in create\n    return await self._post(\n  File \"/home/l-t7-unknown/.local/lib/python3.10/site-packages/openai/_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"/home/l-t7-unknown/.local/lib/python3.10/site-packages/openai/_base_client.py\", line 1519, in request\n    return await self._request(\n  File \"/home/l-t7-unknown/.local/lib/python3.10/site-packages/openai/_base_client.py\", line 1620, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.NotFoundError: <!doctype html>\n<html lang=en>\n<title>404 Not Found</title>\n<h1>Not Found</h1>\n<p>The requested URL was not found on the server. If you entered the URL manually please check your spelling and try again.</p>\n", "source": "<!doctype html>\n<html lang=en>\n<title>404 Not Found</title>\n<h1>Not Found</h1>\n<p>The requested URL was not found on the server. If you entered the URL manually please check your spelling and try again.</p>", "details": null}
{"type": "error", "data": "Error running pipeline!", "stack": "Traceback (most recent call last):\n  File \"/home/l-t7-unknown/.local/lib/python3.10/site-packages/graphrag/index/run.py\", line 323, in run_pipeline\n    result = await workflow.run(context, callbacks)\n  File \"/home/l-t7-unknown/.local/lib/python3.10/site-packages/datashaper/workflow/workflow.py\", line 369, in run\n    timing = await self._execute_verb(node, context, callbacks)\n  File \"/home/l-t7-unknown/.local/lib/python3.10/site-packages/datashaper/workflow/workflow.py\", line 415, in _execute_verb\n    result = await result\n  File \"/home/l-t7-unknown/.local/lib/python3.10/site-packages/graphrag/index/verbs/text/embed/text_embed.py\", line 105, in text_embed\n    return await _text_embed_in_memory(\n  File \"/home/l-t7-unknown/.local/lib/python3.10/site-packages/graphrag/index/verbs/text/embed/text_embed.py\", line 130, in _text_embed_in_memory\n    result = await strategy_exec(texts, callbacks, cache, strategy_args)\n  File \"/home/l-t7-unknown/.local/lib/python3.10/site-packages/graphrag/index/verbs/text/embed/strategies/openai.py\", line 61, in run\n    embeddings = await _execute(llm, text_batches, ticker, semaphore)\n  File \"/home/l-t7-unknown/.local/lib/python3.10/site-packages/graphrag/index/verbs/text/embed/strategies/openai.py\", line 105, in _execute\n    results = await asyncio.gather(*futures)\n  File \"/home/l-t7-unknown/.local/lib/python3.10/site-packages/graphrag/index/verbs/text/embed/strategies/openai.py\", line 99, in embed\n    chunk_embeddings = await llm(chunk)\n  File \"/home/l-t7-unknown/.local/lib/python3.10/site-packages/graphrag/llm/base/caching_llm.py\", line 104, in __call__\n    result = await self._delegate(input, **kwargs)\n  File \"/home/l-t7-unknown/.local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 177, in __call__\n    result, start = await execute_with_retry()\n  File \"/home/l-t7-unknown/.local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 159, in execute_with_retry\n    async for attempt in retryer:\n  File \"/home/l-t7-unknown/.local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n    do = await self.iter(retry_state=self._retry_state)\n  File \"/home/l-t7-unknown/.local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n    result = await action(retry_state)\n  File \"/home/l-t7-unknown/.local/lib/python3.10/site-packages/tenacity/_utils.py\", line 99, in inner\n    return call(*args, **kwargs)\n  File \"/home/l-t7-unknown/.local/lib/python3.10/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n  File \"/usr/lib/python3.10/concurrent/futures/_base.py\", line 451, in result\n    return self.__get_result()\n  File \"/usr/lib/python3.10/concurrent/futures/_base.py\", line 403, in __get_result\n    raise self._exception\n  File \"/home/l-t7-unknown/.local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 165, in execute_with_retry\n    return await do_attempt(), start\n  File \"/home/l-t7-unknown/.local/lib/python3.10/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 147, in do_attempt\n    return await self._delegate(input, **kwargs)\n  File \"/home/l-t7-unknown/.local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 49, in __call__\n    return await self._invoke(input, **kwargs)\n  File \"/home/l-t7-unknown/.local/lib/python3.10/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"/home/l-t7-unknown/.local/lib/python3.10/site-packages/graphrag/llm/openai/openai_embeddings_llm.py\", line 36, in _execute_llm\n    embedding = await self.client.embeddings.create(\n  File \"/home/l-t7-unknown/.local/lib/python3.10/site-packages/openai/resources/embeddings.py\", line 215, in create\n    return await self._post(\n  File \"/home/l-t7-unknown/.local/lib/python3.10/site-packages/openai/_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"/home/l-t7-unknown/.local/lib/python3.10/site-packages/openai/_base_client.py\", line 1519, in request\n    return await self._request(\n  File \"/home/l-t7-unknown/.local/lib/python3.10/site-packages/openai/_base_client.py\", line 1620, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.NotFoundError: <!doctype html>\n<html lang=en>\n<title>404 Not Found</title>\n<h1>Not Found</h1>\n<p>The requested URL was not found on the server. If you entered the URL manually please check your spelling and try again.</p>\n", "source": "<!doctype html>\n<html lang=en>\n<title>404 Not Found</title>\n<h1>Not Found</h1>\n<p>The requested URL was not found on the server. If you entered the URL manually please check your spelling and try again.</p>", "details": null}
