<graphml xmlns="http://graphml.graphdrawing.org/xmlns" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://graphml.graphdrawing.org/xmlns http://graphml.graphdrawing.org/xmlns/1.0/graphml.xsd">
  <key id="d6" for="edge" attr.name="source_id" attr.type="string" />
  <key id="d5" for="edge" attr.name="description" attr.type="string" />
  <key id="d4" for="edge" attr.name="weight" attr.type="double" />
  <key id="d3" for="node" attr.name="entity_type" attr.type="string" />
  <key id="d2" for="node" attr.name="source_id" attr.type="string" />
  <key id="d1" for="node" attr.name="description" attr.type="string" />
  <key id="d0" for="node" attr.name="type" attr.type="string" />
  <graph edgedefault="undirected">
    <node id="&quot;RESERVOIR COMPUTING&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Reservoir Computing is a method used for both regression and classification tasks."
"Reservoir Computing is a type of recurrent neural network architecture that includes techniques such as Echo State Networks and Liquid State Machines."
"Reservoir Computing is a neural network architecture that uses a reservoir of neurons to process input signals, with feedback connections helping to stabilize and control neuron activities."
"Reservoir Computing is a mechanism used in neural networks to ensure reliable and consistent outputs by balancing sensitivity to input signals and robustness against noise."
"Reservoir Computing is a type of recurrent neural network used for time series prediction and data analysis."
"Reservoir Computing is a method used for processing and analyzing data, involving a reservoir of neurons that update their state based on input data."
"Reservoir Computing is a field that focuses on the design and analysis of recurrent neural networks with a large number of interconnected neurons, known as reservoirs."
"Reservoir Computing is a type of machine learning model that uses a reservoir of randomly connected nodes to process input data. The output is then computed using a simple linear regression model, making reservoir computing efficient and effective for various tasks."
"Reservoir Computing is a method used for processing data, involving nodes that can handle multiple inputs or outputs."
"Reservoir Computing is a field that focuses on the design and analysis of recurrent neural networks with a large number of interconnected processing nodes, known as reservoirs."
"Reservoir Computing is a type of recurrent neural network that efficiently handles temporal and sequential data, making it suitable for both regression and classification tasks."
"Reservoir Computing is a type of technology used for both regression and classification tasks, efficiently handling temporal and sequential data."
"Reservoir Computing is a type of machine learning algorithm used for processing data."
"Reservoir Computing is a type of technology used for hyperparameter exploration and optimization."
"Reservoir Computing is a field of study that focuses on the use of reservoirs, such as Echo State Networks, for various applications."
"Reservoir Computing is a technique used for training connections, in this case using linear regression with a regularization coefficient of 10^-5."
"Reservoir Computing is a type of machine learning algorithm used for timeseries prediction and analysis."
"Reservoir Computing is a method used for processing and analyzing time-series data, involving a reservoir of neurons that evolve over time."
"Reservoir Computing is a method used for processing time-series data, involving a reservoir of units that evolve over time."
"Reservoir Computing is a term that encompasses various recurrent neural network architectures, including Echo State Networks and Liquid State Machines."
"Reservoir Computing is a concept in the field of neural networks, involving the use of a reservoir of nodes with fixed connections and adaptive output weights."
"Reservoir Computing is a method used in modeling systems, which demands reservoirs of inordinate size for complex systems but offers alternatives for simpler systems."
"Reservoir Computing is a Machine Learning paradigm for training Recurrent Neural Networks, mentioned in the text."
"Reservoir Computing is a Machine Learning paradigm that focuses on training Recurrent Neural Networks while keeping the recurrent layer untrained."
"Reservoir Computing is a concept that involves chaining models together, using delayed connections, and incorporating external signals. It is a method used in the construction of RC models."
"Reservoir Computing is a method used for chaotic timeseries forecasting, as mentioned in the text."
"Reservoir Computing is a method used for time series prediction, which involves training a reservoir of neurons to learn the dynamics of the data."
"Reservoir Computing is a method used for generating timeseries data, involving a reservoir, input connectivity, regularization, and other parameters."
"Reservoir Computing is a method that takes arrays of shape (timesteps, features) as input and returns an array of shape (timesteps, states). It allows for resetting or modifying reservoir state and feeding states to a node anytime."
"Reservoir Computing is a method used for training a readout node to predict the next value in a sequence."
"Reservoir Computing is a type of recurrent neural network that uses a sparse, randomly generated matrix to store information."
"Reservoir Computing is a type of machine learning model used in the code."
"Reservoir Computing is a method used for processing and analyzing time-series data, involving a reservoir of neurons."
"Reservoir Computing is a concept that summarizes various approaches, including Echo State Networks, Liquid State Machines, and the Backpropagation Decorrelation learning rule for RNNs, which are all related to each other."

"Reservoir Computing is an idea that uses a randomly configured ensemble of spiking neural oscillators to obtain a desired target output from a recurrent neural network."</data>
      <data key="d2">069ae9388dfd52fec9c184c7168f64dd,0b6c69085074b2cf23267eb149068b9f,136559fd2a1fbef4cc8a6b11abcb3eef,158f53cd85edbb4f2e4c77b78c5e7acc,1c462a6eef00aac37dc1ab33a689b930,22499cd4a0b7216dad5b05eb109fcb73,2386633041e820b604fc4457264b5a33,257d4cf08ffc32b99856b6e31fa4221e,26d78bc91458f47d4053954505c45f92,2f4c992d69812866e6fce6dbb52d8612,4a9f33fa18891b67267b7615d61caaac,4d87a0d12ce76c7a493a24e1c4b06a83,56cde5dc9d350498c1544cd57733ca8f,6de297d888d10db4c987b5eafc6398b2,716940af834825642e01a3cb59a7e006,804bd76fa6f4950ef9a5cf8f0025fc1c,82a734e7c7ada95b1c99783140dd7168,8553a88d9aaf4f71d359c721a1f6fa70,86a136730a696f1a817bd530dbff778d,87757855658e1d198ec49a3290760dd5,88ff8a7687e01f40b2c9d151b6e83d64,8e16fc97c32c39d7961b52e21b99dc53,8ecf03267c90a64376f5040307d98195,9e84667b4aeb0789808517f0912043ce,a16039f06e545c915f8e7668c39c3e5c,a3368f9cab1f65643dba089af5a1f95e,b32958d42199d47252887dc7be40ab5a,b3361508c3e49b5bb3089f10e31d2c81,b5b73413fbe4ab8b61c4a939fe6c6a2b,baeb61b8c35e75d37a338fafd6a417fa,d622f95153798af8bb6f485db54aaea3,e9f7bc2274e59b0767e1172a848ddca9,ef85a7b1ca82dc1446ea71964d607a73,f2d5625f36aa4cb036089ce89ec607eb,f730c6800099724052a2d061f3cd8c2e,fac681bdc38ae5829173c747ee6240fa</data>
    </node>
    <node id="&quot;JAPANESE VOWEL DATASET&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"The Japanese Vowel Dataset is composed of utterances of the Japanese vowel &#230;, from 9 different male speakers, used for classification tasks."</data>
      <data key="d2">86a136730a696f1a817bd530dbff778d</data>
    </node>
    <node id="&quot;MALE SPEAKERS&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Male Speakers are the individuals who contributed utterances to the Japanese Vowel Dataset."</data>
      <data key="d2">86a136730a696f1a817bd530dbff778d</data>
    </node>
    <node id="&quot;M. KUDO&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"M. Kudo is a reference mentioned in the text, likely an author or contributor."
"M. Kudo is a co-author of a reference mentioned in the text, contributing to the research on multidimensional curve classification."</data>
      <data key="d2">7cd25eb11825d9b9c2978d248997c3fe,86a136730a696f1a817bd530dbff778d</data>
    </node>
    <node id="&quot;J. TOYAMA&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"J. Toyama is a reference mentioned in the text, likely an author or contributor."
"J. Toyama is a co-author of a reference mentioned in the text, contributing to the research on multidimensional curve classification."</data>
      <data key="d2">7cd25eb11825d9b9c2978d248997c3fe,86a136730a696f1a817bd530dbff778d</data>
    </node>
    <node id="&quot;M. SHIMBO&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"M. Shimbo is a reference mentioned in the text, likely an author or contributor."
"M. Shimbo is a co-author of a reference mentioned in the text, contributing to the research on multidimensional curve classification."</data>
      <data key="d2">7cd25eb11825d9b9c2978d248997c3fe,86a136730a696f1a817bd530dbff778d</data>
    </node>
    <node id="&quot;CLASSIFICATION TASK&quot;">
      <data key="d0">"EVENT"</data>
      <data key="d1">"Classification Task is the goal of assigning to each utterance the label of its speaker in the Japanese Vowel Dataset."
"A Classification Task is a type of machine learning problem where the goal is to categorize input data into discrete classes."
"Classification Task is the machine learning task being performed, which involves categorizing data into different classes."</data>
      <data key="d2">716940af834825642e01a3cb59a7e006,86a136730a696f1a817bd530dbff778d,f5358a50d00a1cac02dd4ad8fcb167ee</data>
    </node>
    <node id="&quot;UCI MACHINE LEARNING REPOSITORY&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"UCI Machine Learning Repository is the source of the Japanese Vowels dataset, which provides the audio signals for analysis."</data>
      <data key="d2">7cd25eb11825d9b9c2978d248997c3fe</data>
    </node>
    <node id="&quot;JAPANESE VOWELS DATASET&quot;">
      <data key="d0">"DATASET"</data>
      <data key="d1">"Japanese Vowels Dataset is a collection of audio signals used for analysis, with each signal represented as a 12-dimensional vector of Linear Prediction Coefficients (LPC)."
"The Japanese Vowels dataset is a collection of spoken utterances used for classification tasks, where the goal is to assign each utterance to one of nine speakers."
"The Japanese Vowels dataset is a collection of spoken utterances used for classification tasks, with the goal of assigning each utterance to one of nine speakers."
"Japanese Vowels Dataset is a dataset used for demonstrating machine learning models."
"The Japanese Vowels Dataset is a dataset used for machine learning tasks, including classification and prediction."
"The Japanese Vowels Dataset is used for classification with reservoir computing, mentioned in the text."</data>
      <data key="d2">35631fbf2ad11c53d75cb9b42e2c39b4,7cd25eb11825d9b9c2978d248997c3fe,870f29520f7a1c42eecb0c4ff855f09e,9f7337ee2d87543ced3b99dcae344b13,c1ba6d7a4f4bd16c4fd25baf07c9747c,d58662ee42c14a0787d839ebfd0a6e9b</data>
    </node>
    <node id="&quot;MULTIDIMENSIONAL CURVE CLASSIFICATION&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Multidimensional Curve Classification is a technique mentioned in a reference, used to categorize data points based on their passing-through regions."</data>
      <data key="d2">7cd25eb11825d9b9c2978d248997c3fe</data>
    </node>
    <node id="&quot;PATTERN RECOGNITION LETTERS&quot;">
      <data key="d0">"PUBLICATION"</data>
      <data key="d1">"Pattern Recognition Letters is a publication where a reference is mentioned, contributing to the research on multidimensional curve classification."</data>
      <data key="d2">7cd25eb11825d9b9c2978d248997c3fe</data>
    </node>
    <node id="&quot;CEPSTRA&quot;">
      <data key="d0">"TECHNOLOGY"</data>
      <data key="d1">"cepstra is a feature extraction technique used in audio processing, such as speech recognition and synthesis."</data>
      <data key="d2">79d5959f3f6471cad55498ab4a8a3176</data>
    </node>
    <node id="&quot;RESERVOIRPY&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"ReservoirPy is a library or framework used for building and working with reservoir computing nodes, which are used for processing sequences, such as audio data."
"ReservoirPy is a library used to build and train neural network models, such as the Echo State Network used in the text."
"ReservoirPy is a library used for creating reservoir computing models, which are used for data analysis and prediction."
"ReservoirPy is a library used for creating and training reservoir computing models, which are used for classification of sequential patterns."
"ReservoirPy is a library for reservoir computing, which includes the development of Echo State Networks."
"ReservoirPy is a tool used for creating Echo State Networks, mentioned in the text."
"ReservoirPy is a platform that requires timeseries data to be formatted as NumPy arrays of shape (timesteps, features) to avoid unexpected results or errors."
"ReservoirPy is a system that uses Numpy and Scipy for all computations, storing data in Numpy arrays."
"ReservoirPy is a library mentioned in the text, which uses only Numpy and Scipy for all computations."
"ReservoirPy is a Python library for reservoir computing, providing tools for designing and training Echo State Networks."
"ReservoirPy is a Python library used for creating and analyzing reservoir computing networks, such as Echo State Networks (ESNs)."
"ReservoirPy is a library or framework that includes concepts such as 'from_state' and 'with_state' parameters, which are used to specify the initial state of the reservoir in different contexts."
"ReservoirPy is a library used for creating and working with reservoir computing networks."
"ReservoirPy is a software library or tool that supports the training and running of multiple reservoirs or nodes simultaneously, enhancing the overall computational efficiency of the model."
"ReservoirPy is a library used for creating and working with Echo State Networks, which includes the implementation of input-to-readout connections."
"ReservoirPy is a software library used for creating and working with Echo State Networks (ESNs)."
"ReservoirPy is a software library or module that provides tools for creating and working with reservoir computing networks."
"ReservoirPy is a library for creating and working with reservoir computing networks, including Echo State Networks."
"ReservoirPy is a Python library that provides tools for working with Echo State Networks (ESNs), including utilities for optimizing hyperparameters."
"ReservoirPy is a software library used for analyzing and processing data, mentioned in the text."
"ReservoirPy is a tool used for optimizing objective functions, such as the Root Mean Squared Error (RMSE) and R-squared (R^2)."
"ReservoirPy is a tool used for hyperparameter optimization, which accepts objective functions with certain conventions."
"ReservoirPy is a library used for hyperparameter optimization in machine learning models."
"ReservoirPy is a library used for hyper-parameter exploration and visualization in the context of Reservoir Computing."
"ReservoirPy is a library that provides tools and utilities for various tasks, including the Japanese Vowels dataset and functions for sequence-to-sequence encoding."
"ReservoirPy is a framework used for creating and working with reservoir models, which includes the integration of Scikit-Learn models."
"ReservoirPy is a Python library for creating, training, and simulating reservoir computing networks, used for tasks such as time series prediction and classification."
"ReservoirPy is an organization that provides a library for creating and working with reservoir computing models, which are used in the code."
"ReservoirPy is a library used for creating and training reservoir models."
"ReservoirPy is a library used for creating and working with reservoirs, which are used in the context of machine learning and data processing."
"ReservoirPy is a library used for creating reservoir computing models, which includes the Reservoir node and ScikitLearnNode."
"ReservoirPy is a library for implementing Reservoir Computing architectures, with a focus on Echo State Networks, and offers features such as offline and online training, parallel implementation, and sparse matrix computation."
"ReservoirPy is a Python library for creating and training reservoir computing networks, with features such as offline and online training, parallel implementation, and graphical tools for hyperparameter exploration."
"ReservoirPy is a library for creating and working with reservoir computing models, such as Echo State Networks."
"ReservoirPy is a Python library for reservoir computing, used for timeseries prediction and analysis."
"ReservoirPy is a Python library for reservoir computing, used for installing packages and running Python Notebooks."
"ReservoirPy is a tool used for exploring hyperparameters, mentioned in the text."
"ReservoirPy is a library mentioned in the text, which is cited in a paper by Trouvain et al."
"ReservoirPy is a library developed and supported by Inria at Bordeaux, France, in the Mnemosyne group, for designing echo state networks."
"ReservoirPy is a library developed and supported by Inria at Bordeaux, France in the Mnemosyne group, for designing Echo State Networks."
"ReservoirPy is a Python library used for creating and analyzing reservoir computing systems, such as Echo State Networks."
"Reservoirpy is a library used for creating and working with reservoir computing models."
"ReservoirPy is a library used for reservoir computing, which includes tools for optimizing hyperparameters."
"ReservoirPy is a tool that provides users with wrappers around other tools for data analysis and forecasting."
"ReservoirPy is a library used for time series forecasting and hyperparameter optimization."
"reservoirpy is a Python library for Reservoir Computing (RC) models design and training, with a focus on Echo State Networks (ESNs)."
"reservoirpy is a Python library for Reservoir Computing models design and training, with a focus on Echo State Networks, mentioned in the text."
"ReservoirPy is a Python library for Reservoir Computing, providing tools and algorithms for training and analyzing Echo State Networks."
"Reservoirpy is a library written in Python 3, tailored for RC networks design, with a focus on Echo State Networks (ESNs)."
"reservoirpy is a Python library for designing recurrent neural networks, with a focus on Echo State Networks, and offers features such as online/offline learning, feedback connections, and parallelism."
"reservoirpy is a library that contains various implementations of Reservoir Computing tools, defined as Node sub-classes."
"reservoirpy is a library that contains various implementations of RC tools, such as Reservoir, Ridge, LMS, and RLS."
"ReservoirPy is an open-source library for reservoir computing, providing nodes for reservoirs and various utilities."
"Reservoirpy is an open-source library for reservoir computing, providing features such as initialization functions, activation functions, and observables."
"reservoirpy is a software used for chaotic timeseries forecasting, mentioned in the example section."
"reservoirpy is a library mentioned in the text, likely used for reservoir computing tasks."
"reservoirpy is a toolbox for applying Reservoir Computing techniques to time-based data, offering high-level and low-level APIs, reservoir architectures, readouts, and learning rules."
"reservoirpy is an open-source toolbox for applying Reservoir Computing techniques to time-series data, under development for future features."
"reservoirpy is a library that supports the implementation of Liquid State Machines (LSMs) and other tools for machine learning."
"Reservoirpy is a library used for reservoir computing, as mentioned in the text."
"ReservoirPy is a library used in the provided code to work with the Mackey-Glass Equations."
"ReservoirPy is a Python library used for building and training Echo State Networks."
"ReservoirPy is a library used for training and running Echo State Networks (ESNs), which is mentioned in the text."
"ReservoirPy is a library mentioned in the text, which provides various chaotic timeseries for analysis."
"ReservoirPy is a library used for training the Echo State Network (ESN) model, which is used for data analysis and prediction."
"ReservoirPy is a library for creating and working with Reservoir Computing architectures."
"ReservoirPy is a library for creating and training Echo State Networks (ESNs), which is used in the provided code."
"ReservoirPy is a library used for creating and training reservoir models, which are used for time series prediction and analysis."
"ReservoirPy is a library used for creating and working with reservoir computing nodes and models."
"ReservoirPy is a library used for performing generative tasks, such as creating reservoirs and readouts with customizable weight matrices."
"reservoirpy is a module that contains functions for creating weights from any scipy.stats distribution."
"ReservoirPy is a library used for reservoir computing, which includes functions to generate matrices."
"ReservoirPy is a library that provides tools for working with reservoirs, which are used in various applications such as echo state networks."
"ReservoirPy is a library or framework that includes nodes such as ESN and Ridge, and is used for creating models."
"ReservoirPy is a library used for creating and training reservoir computing nodes, including the ESN node."
"ReservoirPy is a library used for creating and working with reservoir computing models, such as Deep ESN."
"ReservoirPy is a Python tool for defining, training, and using Reservoir Computing architectures, such as Echo State Networks (ESNs)."
"ReservoirPy is a library that uses Numpy and Scipy for all computations, and it is used to create Echo State Networks (ESNs)."
"ReservoirPy is a library mentioned for creating and working with ESNs, including the Reservoir and Ridge nodes."
"ReservoirPy is a library used for creating and working with reservoirs, such as the Reservoir class mentioned in the text."
"ReservoirPy is a library used for creating and working with reservoirs, which are used for data processing and analysis."
"ReservoirPy is a library that provides various nodes such as Reservoir, which can be triggered on single timesteps or complete timeseries."
"ReservoirPy is a library used for creating and training ESNs, containing nodes such as Reservoir and Ridge."
"ReservoirPy is a library used for creating and working with reservoirs, which are used for processing time-series data."
"ReservoirPy is a library used for creating and training Echo State Networks (ESNs), which are used for time series prediction and analysis."
"ReservoirPy is a library used for creating and training Echo State Networks (ESNs)."
"ReservoirPy is a library used for creating and working with reservoir computing models."
"ReservoirPy is a library used for creating and working with reservoir computing models, which are used for data processing and prediction."
"ReservoirPy is a library used for creating and working with reservoirs, which are used in the context of echo state networks."
"Reservoirpy is a library or toolkit used for generating matrices, such as the Reservoir matrix in the provided code."
"ReservoirPy is a library for generating matrices used in reservoir computing, which is a type of recurrent neural network."
"ReservoirPy is a library used for creating and working with reservoir computers, which are used for tasks such as time series prediction and data analysis."
"ReservoirPy is a library used for creating and training echo state networks (ESNs)."
"ReservoirPy is a library or framework mentioned in the text, used for creating and training reservoir computing models."
"ReservoirPy is a library used for creating and working with reservoir models, which are used for data processing and analysis."
"ReservoirPy is a library used for reservoir computing, mentioned in the text."
"ReservoirPy is a library used for data preprocessing and analysis, as demonstrated in the provided code."
"ReservoirPy is a library used for building and training Echo State Networks, which is being used in the provided text."
"ReservoirPy is a library used for creating and training reservoir computing networks."
"ReservoirPy is an open-source library for creating and training reservoir computing models, including the ESN used in the provided code."
"ReservoirPy is a library used for creating and working with reservoir computing models."
"ReservoirPy is a library used for creating and working with reservoirs, which are used in the provided code."
"ReservoirPy is a library used for defining and training reservoir computing models, which are used for time series prediction and analysis."
"ReservoirPy is a library used for reservoir computing, which is mentioned in the text."
"ReservoirPy is a library used for reservoir computing and time series analysis, mentioned in the text."
"ReservoirPy is a library used for training and running reservoir computing models, such as the Echo State Network."
"ReservoirPy is a library used for creating and working with reservoir computing models."
"ReservoirPy is a library used for creating reservoir computing models, which are used for data processing and analysis."</data>
      <data key="d2">0036fb6f489e13c0db0f1c02bf3323be,00d22666fe697ffb66c2392939f45b39,0113164912437e96423379cb9c039f56,01f8dd8235ba0d4cf0837b5ea958ec95,069ae9388dfd52fec9c184c7168f64dd,0982b8d1eb1e636b19fa2e9d9361e566,09ea760dd2f000c961d1cfd4ea795da5,0b6c69085074b2cf23267eb149068b9f,0e0afab060f214d46062c9886e762002,136559fd2a1fbef4cc8a6b11abcb3eef,15e969cdc81fd313d389558850d0c8ec,18910a60b2547ec3133340f42c45bb47,1ea13fb2c1fff4954b699a8e2377f99f,20b16c2e1cb8813ade96fea5f9591631,2336a57d055095c6ffa9d156ddee0096,238049de5f28dca3e857a46a8b1bed03,280cbdf53022bbaed48ccb34ebe142bc,295606b4bc5d12929a913a3c79f93734,296bb6eb4ef7d170f7224efcccbbbaf7,29f9b2e5fa311519b18e7aef31c68d0a,2a197220a94bac0b44fc0b07712e45ba,2d8ea1123f365fb047b024022ba4fdc4,2f4c992d69812866e6fce6dbb52d8612,31ee481e47ac3a0b970199e72a0e0d31,324a8f3fb4d19b91457a99999e6d3d17,34b9ce80a22112b32e063179511af6e0,37549a8af907ce182bd36eec43002a7d,3a3b7a67b23341dcd1b04ec5b61683f6,3ae4ccee74392bfe317d8132e99a3aa9,3b4d50c051c177770830f7c0a6b3dd69,3bee7b78d0ab9582cc9bffe9e305df2e,3ff318aebcb07ca141d0a40730d96c7c,4073cafddb73621f26061385c5570659,41fa16855df7da666dc6fc38d2f8ee53,4d87a0d12ce76c7a493a24e1c4b06a83,4da651284dbab3f68dc3cae41e6e0311,4f7b43545046f0e6f9b6fb3816da1d79,50d4e4aab1823b8df6573ccf227f24d0,5732296d26c7a572dc90d4af1172626a,58330f62da357197950f63388e4ceaff,593080a95ef7640b3925b07cad1bedd4,64b0ff9558a0f4794c16619aa76354c4,688ebc7151bc148ac24dc7e2727d7afe,6be085e79e86abc5b1a7eaff6bda1ec5,6daefaa8fbd5c1492f2d832d79841463,6de297d888d10db4c987b5eafc6398b2,716940af834825642e01a3cb59a7e006,71f966d00b6d0eceb580d00b9cb86b1e,73e81fd6509a2ba400a8435793ade3c5,74c073137c970e32982756d008532cb8,75c1234e634cf2c009a116e4ee6c053e,77c3759b4ed32509aaf1403c6fa8030f,79d5959f3f6471cad55498ab4a8a3176,7b9936d57ece8ba985947a7aca12e2c7,7f2d69f9a9baca70ffd25a6865189206,7f70879016c133fe58e4838172a69613,8294eed5fc10df1c118f9afa266910e4,82de30f43839f4985de20a981b524af1,83fafb2423a01afae7e522917d79ace9,8648b5740b93d805f139d9745e1171e8,870f29520f7a1c42eecb0c4ff855f09e,8965403859beb43a6ab7e5c8c916b857,8c66981c9d2009113219bbf2681f664c,8f2f2cfd667a304a288723de779c9bee,91704ce63f9ba41247fdc452a7a62ba6,94fd1ebf256db17e4ac2255b89caa473,96c47d9b671ce319abe9c6ba2b8ae122,9abdbd696e340cb5dd8c66ac5cd30c67,9b360c6a33aafa6827417de5bd4faa82,9f7337ee2d87543ced3b99dcae344b13,a16039f06e545c915f8e7668c39c3e5c,a1adb5de4156f0a4a448caf79056e886,a2b183778107462d474c53e4ec0a9221,a3a74dc4754a8c8b0730f808285893e2,a58317c7e13f27d513fc7671fd187ecb,a8df60a94e25d863b436f47f4f8e6a6d,af2db1cc5ab6b16acae2c93d3facb668,b03e2cc6fe2648e792c1d5f1ec5773a3,b11a9f7777c0232bfa7323ae82ad139b,b2beacacc8c190393e4583a69518378c,b3c8de6f33c2ebb84f0d2797933d0cad,b483c6bbce54156c724905b340aa2e85,bc2d4d6bb706c3d06ffd2c9c2f362104,c05906c1f12c4edfc32a04aa9935067e,c5413fef3b2d7e4d688c66e6046b56c7,c82c9d05b211ff65131f70eb8cb13513,cb71a9bc3b00e7abcd1a53004abdea69,cdc64af0dde941250d89b191d0666c9b,d0b9bbbd7257712eafd2eda5db1d0a8d,d1047d9e322054de394b880adaf6b536,d4684af3c445d312afe4d838abc45502,d58662ee42c14a0787d839ebfd0a6e9b,d5e39e29b61f6ea0ffe0c868ba7a4252,d622f95153798af8bb6f485db54aaea3,d7ac2f6fb13af389417785f2f3152c52,e39809b687cd044a7918eca37727a188,e94f386a2ed7de2156b4864797cc199e,ead6383a44acd8ebd17907b85a910455,eb7a223eeb120e3fcc45a96a6018707d,ed28ba3543e07641536ff1eb5e0749dd,eebc9d7d2b66e3898b7d068c38fd200f,ef85a7b1ca82dc1446ea71964d607a73,f5358a50d00a1cac02dd4ad8fcb167ee,f70c7d3d89baaabbeaad57b58e379e08,f838f4cbb7060f4409ba2d174a396fb1,fcac967511cf2b019fd856e23d2e91d9,fe90abb0dde126fafbf44782aeb6738c,ff860bc63e3d697a6183c0b850689048</data>
    </node>
    <node id="&quot;SEQUENCE-TO-SEQUENCE MODEL&quot;">
      <data key="d0">"TECHNOLOGY"</data>
      <data key="d1">"Sequence-to-sequence model is a type of machine learning model used for encoding sequences, such as audio data, into new sequences in the output space."
"sequence-to-sequence model is a type of machine learning model that maps input sequences to output sequences."
"Sequence-to-Sequence Model is a type of machine learning model used for tasks such as translation and speech recognition."</data>
      <data key="d2">688ebc7151bc148ac24dc7e2727d7afe,79d5959f3f6471cad55498ab4a8a3176,9414efd266e7135a2cdd7461a888b045</data>
    </node>
    <node id="&quot;TRANSDUCTION&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Transduction is the process of encoding each vector of an input sequence into a new vector in the output space, used in sequence-to-sequence models."
"Transduction is a method used in sequence-to-sequence models to generate a sequence of output labels from input data."
"Transduction refers to a sequence-to-sequence model used in machine learning."
"Transduction refers to the process of transforming input data into output data, which is a key aspect of the sequence-to-sequence modeling task."</data>
      <data key="d2">688ebc7151bc148ac24dc7e2727d7afe,79d5959f3f6471cad55498ab4a8a3176,9414efd266e7135a2cdd7461a888b045,c05906c1f12c4edfc32a04aa9935067e</data>
    </node>
    <node id="&quot;SIMPLE ECHO STATE NETWORK&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"The Simple Echo State Network is a model used to solve a task, which is trained on encoding input sequences into output sequences."</data>
      <data key="d2">75c1234e634cf2c009a116e4ee6c053e</data>
    </node>
    <node id="&quot;SEQUENCE-TO-SEQUENCE ENCODING&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Sequence-to-Sequence Encoding is a method used to solve the task, which involves transforming input sequences into output sequences."
"Sequence-to-sequence encoding, also known as transduction, is a method used to solve tasks where a model is trained to encode each vector of input sequence into a new vector in the output space."
"Sequence-to-Sequence Encoding, also known as transduction, is a method used by ReservoirPy Nodes to convert a sequence of input data into a sequence of output labels."</data>
      <data key="d2">75c1234e634cf2c009a116e4ee6c053e,9f7337ee2d87543ced3b99dcae344b13,a6f2502b5336ffc8606e1167b2813004</data>
    </node>
    <node id="&quot;TRAINING&quot;">
      <data key="d0">"EVENT"</data>
      <data key="d1">"Training is the process of fitting the model to the input data, allowing it to learn and make predictions."
"Training is the process of training the ESN network on a dataset, which happens offline and only once."
"Training is the process of fitting the ESN model to the input data and optimizing its parameters."
"Training is the process of training a neural network model, such as ESN, to learn patterns and make predictions."
"Training is the process of training the Echo State Network (ESN) model using a dataset, with the goal of learning patterns and making predictions."
"Training is mentioned in the text as a process that involves delivering targets to each readout using a dictionary."
"Training is the process of teaching the Ridge Readout to predict the next value in the Sine Wave sequence."
"Training is the process of fitting the ESN Model to input and output data, initializing nodes and training the Ridge readout."
"Training is the process of adjusting the reservoir's parameters to improve its performance in processing input data."</data>
      <data key="d2">324a8f3fb4d19b91457a99999e6d3d17,36e4df75a46fb977f9516f2d2f1f9bc2,59b469bdd618b3f36b3547f4f2b8a862,75c1234e634cf2c009a116e4ee6c053e,894d59d781535ca85389c4226715c007,8ade7819a5f8d1ec26e9bdbd059142e6,cc1fb6ca5695434ad0279c2606e928af,d0b9bbbd7257712eafd2eda5db1d0a8d,f2d5625f36aa4cb036089ce89ec607eb</data>
    </node>
    <node id="&quot;PREDICTION&quot;">
      <data key="d0">"EVENT"</data>
      <data key="d1">"Prediction is the process of using the trained model to make output sequences based on input sequences."
"Prediction is the process of forecasting future outcomes based on past data, using reservoir computing models."
"Prediction is a concept mentioned in the text, referring to forecasting or estimating future events or outcomes based on current data."
"Prediction is the process of generating future values of the timeseries based on the learned patterns and dynamics of the input data."
"Prediction is a part of statistical inference, which involves transferring knowledge about a sample to make predictions about the population or future data points."
"Prediction is the process of using a trained model to make predictions about future data, which is a common application of the Echo State Network (ESN) model."

"Prediction is the process of using the trained ESN model to predict future values of the sine wave."
"Prediction is the process of using a trained reservoir computing model to make predictions about future data."</data>
      <data key="d2">09ea760dd2f000c961d1cfd4ea795da5,14bccd672d2f8dd2cd7300581c8844fb,64b0ff9558a0f4794c16619aa76354c4,693e4d1e43289f46866236c10207a17e,75c1234e634cf2c009a116e4ee6c053e,8c520b4037fe01ffce62d46b67175e67,9261efcc24379d9c0b2d35a2fde8275d,c82c9d05b211ff65131f70eb8cb13513,d0b9bbbd7257712eafd2eda5db1d0a8d</data>
    </node>
    <node id="&quot;SPEAKER LABELING&quot;">
      <data key="d0">"EVENT"</data>
      <data key="d1">"Speaker Labeling is the process of assigning a label to each input sequence in a sequence-to-vector model, which is used for classification of sequential patterns."</data>
      <data key="d2">64b0ff9558a0f4794c16619aa76354c4</data>
    </node>
    <node id="&quot;SEQUENCE-TO-VECTOR MODEL&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Sequence-to-Vector Model is a type of model where inference is performed only once on the whole input sequence, and it is used for assigning one label to each input sequence."
"Sequence-to-Vector Model is a more advanced method used for classifying sequential patterns, where inference is performed only once on the whole input sequence."</data>
      <data key="d2">64b0ff9558a0f4794c16619aa76354c4,a6f2502b5336ffc8606e1167b2813004</data>
    </node>
    <node id="&quot;DATA ANALYSIS&quot;">
      <data key="d0">"EVENT"</data>
      <data key="d1">"Data Analysis is the process of inspecting, cleaning, transforming, and modeling data to discover useful information, draw conclusions, and support decision-making."
"Data Analysis is the process of inspecting, cleaning, transforming, and modeling data to discover useful information, draw conclusions, and support decision-making."
"Data Analysis is the process of inspecting, cleaning, transforming, and modeling data to discover useful information, draw conclusions, and support decision-making."
"Data Analysis is the process of examining and interpreting data to gain insights and make decisions, which is facilitated by the trained ESN model."
"Data Analysis refers to the process of inspecting, cleaning, transforming, and modeling data to discover useful information, draw conclusions, and support decision-making."
"Data Analysis is the process of inspecting, cleaning, transforming, and modeling data to discover useful information, as performed by the Data Scientist."</data>
      <data key="d2">29f9b2e5fa311519b18e7aef31c68d0a,64b0ff9558a0f4794c16619aa76354c4,7b9936d57ece8ba985947a7aca12e2c7,9fdaabd6c7e893a275a3848c10007477,d0b9bbbd7257712eafd2eda5db1d0a8d,d15f6d075c072f0335b5332f11c00299</data>
    </node>
    <node id="&quot;RIDGE&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Ridge is a type of model used in reservoir computing for training the readout, which is a part of the reservoir computing model."
"ridge is a parameter explored by hp_space that represents the ridge, but its configuration is not provided in the given text."
"ridge is a parameter explored by hp_space, log-uniformly distributed between 1e-8 and 1e1."
"Ridge is a type of readout layer in the ESN that uses linear regression to train connections from the reservoir to the output layer."
"Ridge is a component of the reservoir computing model used in the code."
"Ridge is a component used in the provided code, likely a type of regularization technique."
"ridge is a parameter that specifies a regularization parameter, which is log-uniformly distributed between 1e-8 and 1e1."
"Ridge is a hyperparameter representing the regularization term in the machine learning model."
"Ridge is a regularization technique used to prevent overfitting in a model by adding a penalty term to the loss function."
"Ridge is a tool in reservoirpy that learns connections through Tikhonov linear regression for a readout layer of neurons."
"Ridge is a concept used in machine learning, referring to a type of linear regression that includes a penalty term to reduce overfitting."
"Ridge is a component of the ESN neural network, used for readout and training."
"Ridge is a regularization technique used in the ESN model to prevent overfitting and improve generalization."
"Ridge is a machine learning algorithm used for regression tasks."
"Ridge is a type of readout used in the ESN system for making predictions."
"Ridge is a type of readout layer used in ESNs, which estimates the output based on the reservoir's state."
"Ridge is a type of linear regression model that applies a regularization term to the loss function to prevent overfitting."
"Ridge is a type of regression model used for training the readout component of a reservoir model."
"Ridge is a regularization technique used in machine learning models to prevent overfitting."
"Ridge is a type of regularization used in the context of predicting timeseries, with a ridge parameter of 1e-7."
"Ridge is a type of node in ReservoirPy, which is used in conjunction with ESN for processing sequences of inputs and targets."
"Ridge is a component of the ESN node in ReservoirPy, used for training the readout weights."
"Ridge is a type of readout used in the ESN model for time series prediction."
"Ridge is a component mentioned in the text, which is used in the construction of Deep Echo State Networks."
"Ridge is a type of regression model used for making predictions based on the processed data from reservoirs."
"Ridge is a machine learning model that can be trained using its fit() method to create a mapping from inputs to targets."
"Ridge is a type of regularization used in machine learning to prevent overfitting, often used in the context of linear regression."
"Ridge is a node in the ESN Model used as a readout, which is trained to make predictions based on reservoir activations."
"Ridge is a regularization technique used in machine learning to prevent overfitting."
"Ridge is a type of regularization used in machine learning models to prevent overfitting."
"Ridge is a regularization technique used in the ESN Model to prevent overfitting."
"Ridge is a type of regression model used for data prediction and analysis."
"Ridge is a type of organization or system used in the provided code, likely a part of a larger machine learning framework."
"Ridge refers to a type of linear regression that uses a penalty term to prevent overfitting, which is a common issue in machine learning."
"Ridge refers to a type of linear regression used in the readout stage of an echo state network (ESN)."
"Ridge is a term used in the context of reservoir computing, referring to a type of readout or output layer."
"Ridge is a component in a reservoir model, used for data processing and analysis."
"Ridge is a type of linear regression used as the readout in the ESN."
"Ridge is a type of regression model used in the code."
"Ridge is a regularization technique used in the ESN model to prevent overfitting and improve generalization."
"Ridge is a regularization technique used in the model, with a parameter ridge."
"Ridge is a machine learning algorithm used for regression tasks, which is used in the provided code."
"Ridge is a parameter in the Hyperopt configuration, which is mentioned in the text."
"Ridge is a component of the model used for output prediction."</data>
      <data key="d2">00d22666fe697ffb66c2392939f45b39,069ae9388dfd52fec9c184c7168f64dd,0753d4e507badadd900c522ee03ad28d,09198e939639c229c2c97555f65b12a7,0982b8d1eb1e636b19fa2e9d9361e566,09ea760dd2f000c961d1cfd4ea795da5,136d135c710f6cf78a4c536d43276fe1,1ea13fb2c1fff4954b699a8e2377f99f,2336a57d055095c6ffa9d156ddee0096,2bcc39da2ecef3011cc3da428fca5dd5,31ee481e47ac3a0b970199e72a0e0d31,36e4df75a46fb977f9516f2d2f1f9bc2,3ae4ccee74392bfe317d8132e99a3aa9,3bee7b78d0ab9582cc9bffe9e305df2e,3ff318aebcb07ca141d0a40730d96c7c,46dcc47b4358d3895c1eeb1182c6f997,5366a81a025c098744b5d6f1432c2fbc,59b469bdd618b3f36b3547f4f2b8a862,5cea9edfd65fcfa25a081554300b28cc,6daefaa8fbd5c1492f2d832d79841463,72e6eee633bcb5b1458c4cee3975cee1,751b176a8d6149a853e597c65a6fe0cf,7b9936d57ece8ba985947a7aca12e2c7,7f2d69f9a9baca70ffd25a6865189206,7f70879016c133fe58e4838172a69613,80033e741d8e10abdcfe20dd17192152,80c9f51870e239404ed671ef0374f191,8294eed5fc10df1c118f9afa266910e4,82ff270b1bbdfe0ee11e603de1e326c7,8648b5740b93d805f139d9745e1171e8,8ade7819a5f8d1ec26e9bdbd059142e6,8c520b4037fe01ffce62d46b67175e67,94fd1ebf256db17e4ac2255b89caa473,993a69efae014a8f8d6ec0c235104d46,a0feae89e52a4291db0a512a3a102d8e,adfc38e9dc5e6fd0fe67ce83dfa1f154,b03e2cc6fe2648e792c1d5f1ec5773a3,bf4eaad93f89884d02cdad6a50f145a6,c82c9d05b211ff65131f70eb8cb13513,e39809b687cd044a7918eca37727a188,f0c8d4d322d73f46464e3e9f6914f2ee,f1fc6fbc8158d3da070d55544041a2ca,f70c7d3d89baaabbeaad57b58e379e08,f7f7dbc1e69b3b0e801bc5ba9c0cabca</data>
    </node>
    <node id="&quot;RESERVOIR&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Reservoir is a component of reservoir computing models used for generating internal states based on input sequences."
"reservoir is a component used in the model, potentially responsible for generating states based on input data."
"Reservoir is a pool of randomly connected neurons in an Echo State Network, forming a genuine recurrent neural network."
"The Reservoir is a component of Echo State Networks that receives input signals and transforms them into high-dimensional representations."
"Reservoir is a type of artificial neural network used in ReservoirPy, characterized by bi-directional flow of information."
"The Reservoir is a component in a machine learning model that processes input data and generates internal states."
"Reservoir is a component of an Echo State Network (ESN) that processes the input data and generates dynamic representations."
"Reservoir is a component in reservoir computing that processes input data in a specific way to enhance the model's ability to capture various aspects of the data."
"Reservoir is a component that receives feedback from the readout and uses the most recent output information for current processing."
"Reservoir is a component of Echo State Networks (ESNs) that stores and processes input data."
"The Reservoir in an ESN is a recurrently connected network of nodes that help preserve information and capture temporal dynamics."
"Reservoir is a concept used in reservoir computing, representing a recurrent network with a sparse, random connectivity structure."
"Reservoir is a component of the ESN that encodes inputs in a high-dimensional space using a random recurrent network."
"Reservoir is a component of the reservoir computing model used in the code."
"Reservoir is a component in a system that processes input data, with its dynamics influenced by the Spectral Radius and Echo State Property."
"The Reservoir is a system described in the text, with properties such as Spectral Radius and Echo State Property, and parameters such as Input Scaling, Units, and Leak Rate."
"Reservoir is a component used in the provided code, likely a part of a machine learning model."
"Reservoir is a component of the ESN system that must have the echo state property for the system to function correctly."
"Reservoir is a tool in reservoirpy that performs high dimensional embedding of timeseries using a recurrent pool of leaky neurons."
"Reservoir is a concept used in Reservoir Computing, which is a type of machine learning algorithm."
"Reservoir is a component of the ESN neural network, responsible for processing input data."
"Reservoir refers to a component of the ESN network that stores and processes information."
"Reservoir is a component of the ESN model that processes input data and generates a high-dimensional state space."
"Reservoir is a component of Echo State Networks, responsible for processing and storing input data."
"Reservoir is a component of the ESN system used for processing input data."
"Reservoir is a component of ESNs that processes input data and generates a rich representation for the readout layer."
"Reservoir is a component of the model that processes the input data."
"Reservoir is a concept used in the model, which processes the input data."
"Reservoir is a component of ESNs that processes input data and generates internal states."
"Reservoir is a component of a reservoir model, which stores and processes information from input data."
"Reservoir is a component of a reservoir computing model, responsible for processing input data."
"Reservoir is a type of model used in the context of predicting timeseries, with a learning rate of 0.5 and a spectral radius of 0.9."
"Reservoir is a component of the ESN node in ReservoirPy, used for creating the reservoir computing network."
"Reservoir is a component of the ESN model that stores and processes data."
"Reservoir is a component mentioned in the text, which is used in the construction of Deep Echo State Networks."
"Reservoir is a key component in reservoir computing models, used for processing and storing input data."
"The reservoir is a pool of artificial rate neurons randomly connected to their inputs and to themselves, forming a recurrent neural network."
"Reservoir is a component of an ESN that processes input data and generates internal activations."
"Reservoir is a component mentioned in the text, which is part of the ReservoirPy library. It is used to create a reservoir for an ESN."
"Reservoir is a node provided by ReservoirPy, which can be triggered on single timesteps or complete timeseries."
"Reservoir is a recurrent neural network used to process a timeseries, with the ability to reset or modify its state."
"Reservoir is a type of network mentioned in the text, capable of performing operations and keeping track of internal activations."
"The Reservoir is a component mentioned in the text, likely a part of a larger system."
"The reservoir is a component of the ESN model that processes input data."
"Reservoir is a component of an ESN that processes input data and generates a high-dimensional representation of the input."
"Reservoir is a node in the ESN Model that processes input data."
"Reservoir is a system or network used in the context of processing time series data, such as a sine wave."
"Reservoir is a component of the ESN Model, which stores and processes information."
"Reservoir is a component of a reservoir computing model, which stores and processes data."
"Reservoir is a component of an echo state network that stores and processes information."
"Reservoir is a type of organization or system used in the provided code, likely a part of a larger machine learning framework."
"Reservoir is a concept used in the provided code, likely referring to a reservoir computation or a reservoir matrix."
"Reservoir refers to the core component of an echo state network (ESN), which stores and processes information."
"Reservoir is a term used in the context of reservoir computing, referring to a component of the model."
"Reservoir is a component of the ESN that processes input data."
"Reservoir is a component in the Generative Mode method, which has properties such as units, leak_rate, spectral_radius, input_scaling, connectivity, input_connectivity, and regularization."
"Reservoir is a component of the model used for training and generating data."
"Reservoir refers to a core component of reservoir computing networks, which processes input data."
"Reservoir is a component of the Echo State Network (ESN) model that stores and processes information from the input data."
"Reservoir is a component of the ESN model that processes input data and generates a high-dimensional state space."
"Reservoir is a system or network used in the text, likely in a computational context."
"Reservoir is a term used in the context of a neural network, likely referring to a component that stores and processes information."
"Reservoir is an organization or system that runs simulations with different leaking rates."
"Reservoir is a component in a model used for time series prediction, with parameters such as units, sr, and lr."
"Reservoir is a component of an Echo State Network (ESN), a type of recurrent neural network, used in the provided code."
"Reservoir is a component of the model used for processing input data."
"Reservoir is a component used in the code to process input data."
"Reservoir is a concept used in reservoir computing, referring to a recurrent neural network structure that stores input data and processes it through a non-linear transformation."
"Reservoir is a component mentioned in the text, but its specific role or function is not clearly defined."</data>
      <data key="d2">00d22666fe697ffb66c2392939f45b39,0753d4e507badadd900c522ee03ad28d,09198e939639c229c2c97555f65b12a7,0c5a253fb2bcebe8674581a5dc12fd96,0d922ae20673124fc4588949e3863ed0,0e0afab060f214d46062c9886e762002,0e6f0f7cd882a638ecb571ef36068868,1365a36c76afc697ac626fd0f784804a,1ea13fb2c1fff4954b699a8e2377f99f,1f30b86a46d4819603edc730df816c49,2336a57d055095c6ffa9d156ddee0096,2bcc39da2ecef3011cc3da428fca5dd5,2cba60e2f36479613bb0243a19f3a3b4,31ee481e47ac3a0b970199e72a0e0d31,324a8f3fb4d19b91457a99999e6d3d17,333ecf478bfbd4291de9f193bbf0443a,36e4df75a46fb977f9516f2d2f1f9bc2,3a3b7a67b23341dcd1b04ec5b61683f6,3ae4ccee74392bfe317d8132e99a3aa9,3ff318aebcb07ca141d0a40730d96c7c,46dcc47b4358d3895c1eeb1182c6f997,4b78fdc153f982e64291112395c316c7,4da651284dbab3f68dc3cae41e6e0311,548c454b31f852543b600df173bd44ab,58115d5a63315a84d9c8d4e6ddc98ffd,59b469bdd618b3f36b3547f4f2b8a862,5d3baa9818a4e01fe1196c43378a2cea,6a4432cd530b28770e2b903fe242a0d1,6daefaa8fbd5c1492f2d832d79841463,70db98fabc82fc96ecf8cc2c023b586b,711ec1b4879d910d0df0a477c9e240ba,72e6eee633bcb5b1458c4cee3975cee1,751b176a8d6149a853e597c65a6fe0cf,7b294b788fe5ee385d08c4aabe2ca71d,7f2d69f9a9baca70ffd25a6865189206,7f70879016c133fe58e4838172a69613,80c9f51870e239404ed671ef0374f191,8294eed5fc10df1c118f9afa266910e4,82f7e4647b9da5d5063fe92613f4fbcb,82ff270b1bbdfe0ee11e603de1e326c7,83fafb2423a01afae7e522917d79ace9,8ade7819a5f8d1ec26e9bdbd059142e6,8c520b4037fe01ffce62d46b67175e67,94fd1ebf256db17e4ac2255b89caa473,993a69efae014a8f8d6ec0c235104d46,9b360c6a33aafa6827417de5bd4faa82,a0feae89e52a4291db0a512a3a102d8e,a35f6cae32a3d24b18ee17ec0471a9d4,b03e2cc6fe2648e792c1d5f1ec5773a3,b101b38a87b2fcac0ff450a4e3f22143,b957e1bf5bf175c7630222ca742c7933,bba680a0a7dd439bd5b0fe1547ffe040,bf4eaad93f89884d02cdad6a50f145a6,c4f5a27caf9dd9c1d972492c1147efa0,c82c9d05b211ff65131f70eb8cb13513,cb71a9bc3b00e7abcd1a53004abdea69,cc1fb6ca5695434ad0279c2606e928af,cdc64af0dde941250d89b191d0666c9b,cf15a09e77b695a117e1cca05461aea2,d25cd385546ec6a033287e75d65a551a,dc3bd3697a140b64d70e0e3ac6db6c7e,e39809b687cd044a7918eca37727a188,ed28ba3543e07641536ff1eb5e0749dd,eebc9d7d2b66e3898b7d068c38fd200f,f0c8d4d322d73f46464e3e9f6914f2ee,f1fc6fbc8158d3da070d55544041a2ca,f5358a50d00a1cac02dd4ad8fcb167ee,f7f7dbc1e69b3b0e801bc5ba9c0cabca,fa082948fa919150e9c06c6f5c1b53b0</data>
    </node>
    <node id="&quot;INPUT&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Input is a component of reservoir computing models used for feeding input sequences into the model."
"Input refers to the data or information that is processed and stored in STM."
"An input is a data point or example used to pass information to a model."
"Input refers to the data or information fed into a neural network for processing."
"Input is a node in ESNs that represents the input data to be processed."
"Input refers to the data that is fed into the model."
"Input is a component of the ESN model that provides data to the reservoir."
"Input is a component mentioned in the text, which is used in the construction of Deep Echo State Networks."
"Input refers to the data or signals fed into the reservoir computing model for processing."
"Input is a component of a reservoir computing model that provides data to be processed and analyzed."
"Input refers to the data or signals fed into an echo state network (ESN) for processing and prediction."
"Input is a term used in the context of reservoir computing, referring to the data or signals fed into the model."
"Input is a component in a reservoir model, used for data processing and analysis."</data>
      <data key="d2">00d22666fe697ffb66c2392939f45b39,1ea13fb2c1fff4954b699a8e2377f99f,2336a57d055095c6ffa9d156ddee0096,58115d5a63315a84d9c8d4e6ddc98ffd,59b469bdd618b3f36b3547f4f2b8a862,65a025a8610d85bf0d2b6c4979eb7439,8648b5740b93d805f139d9745e1171e8,bf4dccb5096a917a6a71f0cc224e4d7c,c82c9d05b211ff65131f70eb8cb13513,dd41fca2f283c4f8c8d1cba5b836da45,e39809b687cd044a7918eca37727a188,f0c8d4d322d73f46464e3e9f6914f2ee,f1fc6fbc8158d3da070d55544041a2ca</data>
    </node>
    <node id="&quot;JAPANESE VOWELS&quot;">
      <data key="d0">"EVENT"</data>
      <data key="d1">"Japanese Vowels is a dataset used for training and testing the reservoir computing model."
"Japanese Vowels refers to the vowel sounds used in the Japanese language, which are used in a task involving sequence-to-sequence modeling."
"Japanese Vowels is a dataset used for training and testing the model."</data>
      <data key="d2">1ea13fb2c1fff4954b699a8e2377f99f,688ebc7151bc148ac24dc7e2727d7afe,a0feae89e52a4291db0a512a3a102d8e</data>
    </node>
    <node id="&quot;Y_TRAIN&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Y_train is an array storing a single label for each utterance, potentially representing a training dataset."
"Y_train is a component of a machine learning model used for storing labels or targets for training data."
"y_train is a dataset used for training the machine learning model, containing the target values."
"Y_train is a subset of the Y variable used for training the machine learning model."
"y_train is a variable representing the training target data used to train the ESN system."
"Y_train is a variable that likely contains the training target data for the ESN model."
"Y_train is a target dataset used to train the readout component of the reservoir model."
"Y_train is a dataset used for training a model, such as an Echo State Network (ESN), on target data, which can be used as feedback during the prediction phase."
"Y_train is a concept or variable used in the provided code, likely representing the training data output."
"y_train is a subset of the output data used for training the ESN."
"y_train is a subset of the target data used for training the ESN model."
"Y_train is a variable used to store the training target data, which is mentioned in the text."
"Y_train is a set of target data used for training the model."
"Y_train is a variable in the code that represents the training output data."
"Y_train is a dataset used for training the machine learning models, containing target labels."
"Y_train is a dataset used for training the Reservoir Model, containing the target values."</data>
      <data key="d2">0036fb6f489e13c0db0f1c02bf3323be,0970cd32ce54f6ee1180ab237fdcefe1,0982b8d1eb1e636b19fa2e9d9361e566,3ff318aebcb07ca141d0a40730d96c7c,71366a4c7e791080872ba783d3787bd7,72e6eee633bcb5b1458c4cee3975cee1,751b176a8d6149a853e597c65a6fe0cf,75e530c1a04e30b373dc7cc68e3ad819,7f2d69f9a9baca70ffd25a6865189206,80c9f51870e239404ed671ef0374f191,a0feae89e52a4291db0a512a3a102d8e,b101b38a87b2fcac0ff450a4e3f22143,b3361508c3e49b5bb3089f10e31d2c81,b338d2dcc1fe6ccf42407444c02cad7c,dc3bd3697a140b64d70e0e3ac6db6c7e,f70c7d3d89baaabbeaad57b58e379e08</data>
    </node>
    <node id="&quot;STATES_TRAIN&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"states_train is a variable used in the training process, potentially representing a set of training states."</data>
      <data key="d2">b101b38a87b2fcac0ff450a4e3f22143</data>
    </node>
    <node id="&quot;READOUT&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"readout is a component used in the model, potentially responsible for generating predictions based on states."
"Readout is a single layer of neurons in an Echo State Network that decodes the reservoir's activations to perform a task."
"Readout is a component that sends its state to the reservoir for feedback, allowing the reservoir to remember and incorporate past decisions or predictions."
"Readout is a component of Echo State Networks (ESNs) that generates predictions based on the reservoir's output."
"Readout refers to the final stage of the ESN network that produces the output prediction."
"Readout is a component of Echo State Networks, responsible for transforming the internal state of the network into output predictions."
"Readout is a component of the model that produces the output data."
"Readout is a concept used in the model, which outputs the final result based on the processed data."
"The readout is a single layer of neurons that decodes the reservoir activations to perform a task."
"Readout is a component of an ESN that takes the activations of the reservoir and produces output predictions."
"Readout is a type of network mentioned in the text, which works similarly to a reservoir but requires fitting to learn connections from the reservoir to the readout neurons."
"The readout is a component of the ESN model that makes predictions based on the output of the reservoir."
"Readout refers to the algorithm used to extract meaningful information from the reservoir's output."
"Readout is a component of the Echo State Network (ESN) model that maps the reservoir's output to the desired output."</data>
      <data key="d2">0d922ae20673124fc4588949e3863ed0,1365a36c76afc697ac626fd0f784804a,324a8f3fb4d19b91457a99999e6d3d17,333ecf478bfbd4291de9f193bbf0443a,58115d5a63315a84d9c8d4e6ddc98ffd,711ec1b4879d910d0df0a477c9e240ba,7b294b788fe5ee385d08c4aabe2ca71d,83fafb2423a01afae7e522917d79ace9,b101b38a87b2fcac0ff450a4e3f22143,bf4eaad93f89884d02cdad6a50f145a6,cc1fb6ca5695434ad0279c2606e928af,cdc64af0dde941250d89b191d0666c9b,cf15a09e77b695a117e1cca05461aea2,d25cd385546ec6a033287e75d65a551a</data>
    </node>
    <node id="&quot;X_TEST&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"X_test is a variable used in the testing process, potentially representing a set of test input data."
"X_test is a component of a machine learning model used for processing test data."
"x_test is a dataset used for testing the machine learning model."
"X_test is a subset of the X variable used for testing the performance of the trained machine learning model."
"X_test is a variable representing the testing input data used to evaluate the performance of the trained ESN system."
"X_test is a subset of the input data used for testing the ESN."
"X_test is a subset of the input data used for testing the trained ESN model."
"X_test is a variable used to store the testing input data, which is mentioned in the text."
"X_test is a set of input data used for testing the model's performance."
"X_test is a variable in the code that represents the testing input data."
"X_test is a dataset used for testing the trained machine learning models, containing input features."
"X_test is a dataset used for testing the performance of the Reservoir Model."</data>
      <data key="d2">0036fb6f489e13c0db0f1c02bf3323be,0970cd32ce54f6ee1180ab237fdcefe1,0982b8d1eb1e636b19fa2e9d9361e566,71366a4c7e791080872ba783d3787bd7,72e6eee633bcb5b1458c4cee3975cee1,75e530c1a04e30b373dc7cc68e3ad819,80c9f51870e239404ed671ef0374f191,a0feae89e52a4291db0a512a3a102d8e,b101b38a87b2fcac0ff450a4e3f22143,b3361508c3e49b5bb3089f10e31d2c81,dc3bd3697a140b64d70e0e3ac6db6c7e,f70c7d3d89baaabbeaad57b58e379e08</data>
    </node>
    <node id="&quot;Y_PRED&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Y_pred is a variable used to store predicted labels, potentially representing a set of model predictions."
"y_pred is a variable representing the predicted values of the output in a machine learning model."
"Y_pred is a variable containing the predicted values generated by a model."
"Y_pred is a variable in the code that represents the predicted output data."</data>
      <data key="d2">00648b24263129fdae8652f1a3339041,9078b0f36522f21a9e8e1aadac48ed9c,b101b38a87b2fcac0ff450a4e3f22143,dc3bd3697a140b64d70e0e3ac6db6c7e</data>
    </node>
    <node id="&quot;Y_TEST&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Y_test is a variable used to store true labels, potentially representing a set of actual test data labels."
"y_test is a variable representing the true values of the output in a machine learning model."
"Y_test is a component of a machine learning model used for storing labels or targets for test data."
"Y_test is a variable containing the actual values used for testing the performance of a model."
"y_test is a dataset used for testing the machine learning model, containing the actual target values."
"Y_test is a subset of the Y variable used for testing the performance of the trained machine learning model."
"y_test is a variable representing the testing target data used to evaluate the performance of the trained ESN system."
"y_test is a subset of the output data used for testing the ESN."
"y_test is a subset of the target data used for testing the trained ESN model."
"y_test is the actual target data used for testing the performance of a model."
"Y_test is a variable used to store the testing target data, which is mentioned in the text."
"Y_test is a set of target data used for testing the model's performance."
"Y_test is a variable in the code that represents the testing output data."
"Y_test is a dataset used for testing the trained machine learning models, containing target labels."
"Y_test is a dataset used for testing the performance of the Reservoir Model, containing the actual target values."</data>
      <data key="d2">0036fb6f489e13c0db0f1c02bf3323be,00648b24263129fdae8652f1a3339041,0970cd32ce54f6ee1180ab237fdcefe1,0982b8d1eb1e636b19fa2e9d9361e566,1db5e6cd356c6066227de5e273de1abe,71366a4c7e791080872ba783d3787bd7,72e6eee633bcb5b1458c4cee3975cee1,75e530c1a04e30b373dc7cc68e3ad819,80c9f51870e239404ed671ef0374f191,9078b0f36522f21a9e8e1aadac48ed9c,a0feae89e52a4291db0a512a3a102d8e,b101b38a87b2fcac0ff450a4e3f22143,b3361508c3e49b5bb3089f10e31d2c81,dc3bd3697a140b64d70e0e3ac6db6c7e,f70c7d3d89baaabbeaad57b58e379e08</data>
    </node>
    <node id="&quot;ACCURACY_SCORE&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"accuracy_score is a function used to evaluate the performance of the model, potentially comparing predicted labels with true labels."
"accuracy_score is a function used to evaluate the performance of a model by comparing its predictions to the actual values."
"accuracy_score is a function used to evaluate the performance of the trained ESN model."
"accuracy_score is a metric used to evaluate the performance of a model, comparing predicted outputs to actual targets."
"accuracy_score is a metric used to evaluate the performance of machine learning models."
"accuracy_score is a function used to evaluate the performance of the trained machine learning models, comparing their predictions with the actual labels."</data>
      <data key="d2">0036fb6f489e13c0db0f1c02bf3323be,00648b24263129fdae8652f1a3339041,1db5e6cd356c6066227de5e273de1abe,72e6eee633bcb5b1458c4cee3975cee1,9414efd266e7135a2cdd7461a888b045,b101b38a87b2fcac0ff450a4e3f22143</data>
    </node>
    <node id="&quot;DR. STEPHEN GROSSBERG&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Dr. Stephen Grossberg is a researcher at Boston University, MA, who focuses on recurrent neural networks."</data>
      <data key="d2">5e20e3cd48e20db98711d9948014c2d8</data>
    </node>
    <node id="&quot;BOSTON UNIVERSITY&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Boston University is an educational institution where Dr. Stephen Grossberg works on recurrent neural networks."</data>
      <data key="d2">5e20e3cd48e20db98711d9948014c2d8</data>
    </node>
    <node id="&quot;MA&quot;">
      <data key="d0">"GEO"</data>
      <data key="d1">"MA is a geographical location, likely referring to Massachusetts, where Boston University is located."</data>
      <data key="d2">5e20e3cd48e20db98711d9948014c2d8</data>
    </node>
    <node id="&quot;ARTIFICIAL NEURAL NETWORKS (ARNN)&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Artificial Neural Networks (aRNN) are a type of neural network used in technological applications, mentioned in the text."</data>
      <data key="d2">5e20e3cd48e20db98711d9948014c2d8</data>
    </node>
    <node id="&quot;BIOLOGICAL RECURRENT NEURAL NETWORKS (BRNN)&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Biological Recurrent Neural Networks (bRNN) are a type of neural network found in the brain, with feedback signals occurring in neurons within a single processing layer or between multiple processing layers."</data>
      <data key="d2">5e20e3cd48e20db98711d9948014c2d8</data>
    </node>
    <node id="&quot;MCCULLOCH-PITTS MODEL&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"The McCulloch-Pitts Model is a classical model of threshold logic systems that describes the interaction of nodes in a network."
"The McCulloch-Pitts Model is a neural network model developed by McCulloch and Pitts, which had a significant influence on the field of neural networks and the development of digital computers."</data>
      <data key="d2">25eb64dbb12dee61a753085741ee91d4,5838adba6968ede203f6820ddc368bc4</data>
    </node>
    <node id="&quot;BINARY SYSTEMS&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Binary Systems are a type of recurrent neural network that were inspired by neurophysiological observations showing that signals between many neurons are carried by all-or-none spikes."</data>
      <data key="d2">5838adba6968ede203f6820ddc368bc4</data>
    </node>
    <node id="&quot;LINEAR SYSTEMS&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Linear Systems are a type of recurrent neural network that use linear operations to combine inputs and produce outputs."</data>
      <data key="d2">5838adba6968ede203f6820ddc368bc4</data>
    </node>
    <node id="&quot;CONTINUOUS-NONLINEAR SYSTEMS&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Continuous-Nonlinear Systems are a type of recurrent neural network that use continuous and nonlinear operations to combine inputs and produce outputs."</data>
      <data key="d2">5838adba6968ede203f6820ddc368bc4</data>
    </node>
    <node id="&quot;SHORT-TERM MEMORY (STM)&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Short-Term Memory (STM) refers to the activities or traces of nodes in a network, which are used to store and process information."</data>
      <data key="d2">5838adba6968ede203f6820ddc368bc4</data>
    </node>
    <node id="&quot;NODES&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Nodes refer to the individual units in a network that perform computations and interact with each other."
"Nodes are processing units in a network, capable of receiving and transmitting data."</data>
      <data key="d2">5838adba6968ede203f6820ddc368bc4,e9f7bc2274e59b0767e1172a848ddca9</data>
    </node>
    <node id="&quot;GROSSBERG&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Grossberg is a researcher who has made contributions to the field of recurrent neural networks, including the development of continuous-nonlinear systems."
"Grossberg is a researcher who discovered laws of adaptive behavior in real time and derived neural networks based on these laws."
"Grossberg is a researcher and developer of the Additive Model, known for his contributions to neural network research."
"Grossberg is a researcher mentioned in the text, contributing to the development of neural network models and equations."
"Grossberg is a person mentioned in the text, who introduced the generalized STM equation and other neural models."
"Grossberg is a researcher mentioned in the text who has contributed to the development of neural models."
"Grossberg is a researcher mentioned in the text who has contributed to the understanding of neural networks and their functions."
"Grossberg is a person mentioned in the text as the author of various works related to MTM and its applications."
"Grossberg is a researcher mentioned in the text who has contributed to the development of adaptive weights and long-term memory traces."
"Grossberg is a reference to Stephen Grossberg, a cognitive scientist and neural network researcher."
"Grossberg is a person mentioned in the text who has contributed to the development of neural network learning algorithms such as Outstar Learning and Instar Learning."
"Grossberg is a researcher who introduced ART, combining Instars and Outstars in his work, and also used them in his earlier research."
"Grossberg is a person mentioned in the text who has contributed to the development of ART and related concepts."
"A person who proposed the on-center off-surround network as a solution to the noise-saturation dilemma."
"Grossberg is a researcher who has generalized the feedforward on-center off-surround shunting network equations, generating many useful properties."
"Grossberg is a researcher mentioned in the text, known for his contributions to the shunting network equations and their physiological interpretation."
"Grossberg is a person mentioned in the text, possibly a researcher or author."
"Grossberg is a researcher mentioned in the text, contributing to the development of various concepts and theories."
"Grossberg is a researcher who proved theorems showing how the choice of feedback signal function transforms an input pattern before it is stored persistently in STM."
"Grossberg is an author who has developed the Competitive Learning (CL) and Adaptive Resonance Theory (ART) models, and has been mentioned in the context of shunting dynamics."
"Grossberg is a researcher mentioned in the text, known for his work on competitive dynamical systems and theorems for rate-based neurons."
"Grossberg is a researcher who developed a mathematical method to classify the dynamics of competitive systems and studied a general problem of competition, decision, and consensus."
"Grossberg is a scientist who introduced a class of bRNNs to study the problem of how complicated a system can be and still generate order."
"Grossberg is a researcher who posed questions about the trade-off between global consensus and local signals, and introduced a class of bRNNs that generate global consensus."
"Grossberg is a researcher who proved that all trajectories in a specific type of system are stored in STM, indicating a significant contribution to the field."
"Grossberg is a reference to a specific author who is mentioned in the context of the Theorem."
"Grossberg is a contributor to the Cohen-Grossberg Model and the Liapunov Function, with a focus on proving global approach to equilibria."
"Grossberg is mentioned in the text as a co-author in multiple references related to the neural network and its components."
"Grossberg is a researcher mentioned in the context of multiple models, including the LAMINART Family, LIST PARSE, and TELOS models."
"Grossberg is a co-author of a study that introduces the TELOS Model and its components."
"Grossberg is a researcher mentioned in the text who has published on spatial pattern learning and signal transmission between cells."
"Grossberg is a researcher mentioned in the context of the Unbiased Spatial Pattern Learning Theorem."
"Grossberg is a researcher who has made significant contributions to the field of associative learning and pattern recognition."
"Grossberg is a person mentioned in the text, who has developed the Competitive Learning or Self-Organizing Map Network and Adaptive Resonance Theory."
"Grossberg is a researcher who introduced Adaptive Resonance Theory and proposed the use of top-down learned expectations and attentional focusing in learning models."
"Grossberg is a person who introduced the passive decay associative law in the 1960s."
"Grossberg is a person mentioned in the text who coined the term 'stability-plasticity dilemma' in relation to Adaptive Resonance Theory."
"Grossberg is a researcher and author known for his contributions to Adaptive Resonance Theory and other areas of cognitive science."
"Grossberg is a cognitive scientist known for his contributions to the understanding of Working Memory and its representation."
"Grossberg is a researcher who noted the importance of learning list chunks for the usefulness of working memory and predicted that all WMs are designed to solve the temporal chunking problem."
"Grossberg is a researcher who predicted two constraints for stable learning and memory of list chunks: the LTM Invariance Principle and the Normalization Rule."
"Grossberg is a researcher who predicted the LTM Invariance Principle and the Normalization Rule to support stable learning and memory of list chunks."
"Grossberg is a researcher mentioned in the text who has contributed to the analysis of working memories and long-term memory of list chunks."
"Grossberg is a researcher whose work has been cited in the context of Item-and-Order working memory."
"Grossberg is a researcher whose prediction that all working memories have a similar design to enable stable list chunks to be learned is supported by the accumulating evidence."
"Grossberg is a researcher whose work on working memory networks and list chunking networks is referenced in the text."
"Grossberg is a psychologist who developed a model of working memory and contributed to the understanding of serial verbal learning."
"Grossberg is a researcher mentioned in the text who has made contributions to the understanding of Working Memory and Short-Term Memory."
"Grossberg is a researcher who proved that the TMS is smaller than the IMS in 1978a."
"Grossberg is a researcher who has contributed to the development of models for learning of temporal order, such as the Additive Model and the Shunting Model."
"Grossberg is a researcher who developed the concept of Avalanche."
"Grossberg is a researcher who proposed the inclusion of command cells in circuits to allow for sensitivity to environmental feedback."
"Grossberg is a person mentioned in the text who describes a series of mechanisms that modulate Avalanche performance."
"Grossberg is a researcher mentioned in the text for describing mechanisms that modulate Avalanche performance and for proposing the Cognitive-Emotional-Motor theory of reinforcement learning."
"Grossberg is a researcher who has made significant contributions to the development of the Cognitive-Emotional-Motor (CogEM) Theory and related models."
"Grossberg is a person mentioned in the text, likely a researcher or a scientist."
"Grossberg is an organization or researcher known for their work on Self-Organizing Avalanches and mathematical analyses of learning processes."
"Grossberg is a researcher mentioned in the text, known for contributions in the field of data and neural networks."</data>
      <data key="d2">01e2a32da700813f593038a23a618e55,03fedd128d2ad4ec7e1e1a60d26ba4f5,0af3b52f2586c4e957aee493160223ba,0c9db6cd87deaca2e432c260d775349c,0dd75f3ca11854714bdbfc8a96ccf256,1976b19f768a8fdf37207b680c3b2b40,1c0f47f0b77faab56cbeba0e1e3e7e70,2061ae5039f379b5837d33a062f72ad1,24771832864aa38abd6aebec04b13a10,254fd1fbc0a719a86b8021fa759d22ea,2cbd29d6f0019f0c85bee43779ae8f4d,2e76149ff772441e6627913bc1df5000,2ea6b3379a87077d75e5c45024f4f3e2,3235445917507f02710bd66cc8368194,3281409fdcd18b09ca3109260ddb96d9,32b8b59687b8d1556ec90c99a090653c,3334f6dcd53b71cf3ceb7648ead24d5a,392028b79561bd7471cb68e7c9258b1e,3a64c8c26895f111f00a349dd69bb505,3d5b88f7f81ed9e14f07335bbef17020,4364aa6091e1966365fa889b34f5cf90,43cf5e32e2df964318d03574e6cd6cdc,47d1d12642cdab6e9a5d21c184f83c9c,4959d1559344e462a6a7463fd3273659,4c7e78f7237cb3420e70c7749bb259f9,554e8565591507441cecaa652cb926db,5838adba6968ede203f6820ddc368bc4,597668e07c7554bd2d0cb29399285a39,5c4e24fc9bd10d0bd59a84d56f960cf9,5d6b6e0d1a9ace28e21dce2cb0ac78c0,644602009dec8474bb5cd4702b391d3e,653b7986c4757bd5d0a251369187efa6,6648b18760b8b182e1097ad15c4df685,75495c1fc835d41adf5afcb01e8e520a,7aeda101aa8aba76f319932f0bd568f7,7ba0dfde8cc54bb1dcf66b46fcdd88f8,7beb44dd43aea0791fcb35806356ddb3,88a3f14024e29666891496bb6cd7d0e4,91f030f6c14c673e6d029c9bf1a66515,97a9ce754fa34aaf01d6cce57560b247,97ad8d6e6e3bf27ae6a7b457af9b312e,9b30fc06ca06f49c2faa238da7eddc6f,a9285aaa34de96a8fa62903437d2f3c4,b1636ec22c34ef50b57dec32239c6535,b286a9022774f24a400744b2a1b08bab,b69b23b14e0feccb488ba5412db0824c,bb19119aa74e1f624e402fcef651aac2,be0954a6263de67c84da3141d95de445,c3257facbf1b0a5da49d6a115f66df87,c486b91dc15a126174fe546094568aaa,c580fa74e3c36285cfae7df56340a990,dcd38cdc6195b2bbf41d936af0bf1f5f,df77d35da87a38cae0984a42b9a1d41c,eb6c9a7d24cc59ff93d554093a4360a4,f2468cda326d1ca11c98f2fbde186400,f290960776c5ec561653e90d2ac6751b,f373521b781482587f80fffc5623a1f9,fba20e559e6ecb61ebbf3a805e6d072c</data>
    </node>
    <node id="&quot;JOHN VON NEUMANN&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"John von Neumann is a mathematician and computer scientist who contributed to the development of the digital computer, influenced by the McCulloch-Pitts Model."</data>
      <data key="d2">25eb64dbb12dee61a753085741ee91d4</data>
    </node>
    <node id="&quot;FRANK ROSENBLATT&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Frank Rosenblatt is a psychologist and neuroscientist who developed the continuous-time STM equation used in the classical Perceptron model."</data>
      <data key="d2">25eb64dbb12dee61a753085741ee91d4</data>
    </node>
    <node id="&quot;WARREN MCCULLOCH&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Warren McCulloch is a neurophysiologist who, along with Walter Pitts, developed the McCulloch-Pitts Model, a foundational model in neural networks."</data>
      <data key="d2">25eb64dbb12dee61a753085741ee91d4</data>
    </node>
    <node id="&quot;WALTER PITTS&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Walter Pitts is a neurophysiologist who, along with Warren McCulloch, developed the McCulloch-Pitts Model, a foundational model in neural networks."</data>
      <data key="d2">25eb64dbb12dee61a753085741ee91d4</data>
    </node>
    <node id="&quot;FRANK CAIANIELLO&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Frank Caianiello is a neuroscientist who developed a binary STM equation influenced by activities at multiple times in the past."</data>
      <data key="d2">25eb64dbb12dee61a753085741ee91d4</data>
    </node>
    <node id="&quot;CLASSICAL PERCEPTRON MODEL&quot;">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">25eb64dbb12dee61a753085741ee91d4</data>
    </node>
    <node id="&quot;BINARY STM EQUATION&quot;">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">25eb64dbb12dee61a753085741ee91d4</data>
    </node>
    <node id="&quot;CAIANIELLO&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Caianiello is an organization that introduced equations to change the weights in a learning model."</data>
      <data key="d2">9e901f71d0d2339294da133518f2162f</data>
    </node>
    <node id="&quot;ROSENBLATT&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Rosenblatt is an organization that introduced equations to change the weights in a learning model."
"Rosenblatt is an organization or individual associated with the development of the LTM equations used for pattern classification."</data>
      <data key="d2">7c556574ea1f1f26ee3ad2a63d56b8e7,9e901f71d0d2339294da133518f2162f</data>
    </node>
    <node id="&quot;WIDROW&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Widrow is an organization that introduced the gradient descent Adeline adaptive pattern recognition machine."
"Widrow is an organization or individual associated with the development of the gradient descent Adeline adaptive pattern recognition machine."</data>
      <data key="d2">7c556574ea1f1f26ee3ad2a63d56b8e7,9e901f71d0d2339294da133518f2162f</data>
    </node>
    <node id="&quot;ANDERSON&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Anderson is an organization that described neural pattern recognition using a spatial cross-correlation function."
"Anderson is an organization or individual associated with the initial description of neural pattern recognition using a spatial cross-correlation function."</data>
      <data key="d2">7c556574ea1f1f26ee3ad2a63d56b8e7,9e901f71d0d2339294da133518f2162f</data>
    </node>
    <node id="&quot;STM&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"STM is an organization or concept mentioned in the text, but its full name or description is not provided."
"STM is a type of memory system mentioned in the text, which includes terms such as LTM and MTM."
"STM is mentioned in the text, referring to short-term memory traces in the research."
"STM refers to Short-Term Memory, a component in neural networks that stores temporary patterns and activities."
"STM refers to Short-Term Memory, a component that temporarily stores and processes information."
"STM stands for Short-Term Memory, which is a component of the brain that enables it to process and learn from spatial and temporal patterns of information."
"STM is a concept mentioned in the text, possibly a reference to Short-Term Memory or a specific organization."
"STM is an abbreviation used to refer to Short-Term Memory, a component mentioned in the text that stores input patterns persistently."
"STM refers to a persistent storage mechanism used to store input patterns."
"STM is a storage mechanism mentioned in the text, used to store patterns in signals."
"STM is a concept mentioned in the text, likely referring to a Short-Term Memory system or a similar entity."
"STM is a concept referring to Short-Term Memory, which is mentioned in the text as a component that needs to store more than one feature or category."
"STM refers to a short-term memory system used for storing and processing information."
"STM is a component of a model or theory that stores partially contrast-enhanced patterns."
"STM is an abbreviation used in the text, but without further context, it's unclear what it stands for."
"STM refers to Short-Term Memory, a type of memory that holds information temporarily for immediate use."
"STM stands for Short-Term Memory, which is one of the components mentioned in the text."
"STM is a component mentioned in the text that interacts with LTM during neuronal learning."
"STM is a component of the Generalized Additive RNNs architecture, which sends axons to other cells and learns spatial patterns."
"STM refers to Short-Term Memory, a component of Working Memory that stores information temporarily for immediate use."
"STM is a type of memory mentioned in the text, which stores and updates patterns based on input."
"STM is a type of memory that can trigger learning and enable fluently recalled information at a future time."</data>
      <data key="d2">0d925896ce2bf9b73be90d8fa5ddb402,24771832864aa38abd6aebec04b13a10,2e76149ff772441e6627913bc1df5000,35551dc55b5522082b778171ff6d1bf9,3a64c8c26895f111f00a349dd69bb505,53f5bc3f4c71310c593a23aef01d1633,5812b5d4bcdfbf80de28dca56a6559b3,653b7986c4757bd5d0a251369187efa6,65a025a8610d85bf0d2b6c4979eb7439,6a47ed5881928d48cdcb74e40867a711,7ba0dfde8cc54bb1dcf66b46fcdd88f8,8da881a4f375e8a524fd0bf46ae2279e,8ee5dee5c6f3e89d8d8c20e3fe957583,91f030f6c14c673e6d029c9bf1a66515,97ad8d6e6e3bf27ae6a7b457af9b312e,9b30fc06ca06f49c2faa238da7eddc6f,9e901f71d0d2339294da133518f2162f,b40ff9b93414391d5e4b3c06dfe02bc9,b4f6256f3430f1aa72ca8092809ebba1,b881b9051ad24c6a16b468803fba51d3,c580fa74e3c36285cfae7df56340a990,fba20e559e6ecb61ebbf3a805e6d072c</data>
    </node>
    <node id="&quot;LTM&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"LTM is an organization or concept mentioned in the text, but its full name or description is not provided."
"LTM is a type of long-term memory system mentioned in the text, which changes at a slower rate than STM."
"LTM refers to Long-Term Memory, a component in neural networks that stores learned patterns and activities."
"LTM refers to Long-Term Memory, a component that stores and retrieves information over an extended period."
"LTM stands for Long-Term Memory, which is a component of the brain that enables it to store and retrieve learned information."
"LTM refers to Long-Term Memory, a type of memory that holds information for long-term storage and retrieval."
"LTM stands for Long-Term Memory, which is one of the components mentioned in the text."
"LTM is a component mentioned in the text that interacts with STM during neuronal learning."
"LTM is a component of the Generalized Additive RNNs architecture, which receives axons from other cells and learns spatial patterns."
"LTM refers to Long-Term Memory, a cognitive system that stores information for long-term retention and retrieval."
"LTM refers to a theoretical concept that biases working memory toward more primacy dominance."
"LTM is a type of memory that enables information to be fluently recalled at a future time."</data>
      <data key="d2">0d925896ce2bf9b73be90d8fa5ddb402,2e76149ff772441e6627913bc1df5000,392028b79561bd7471cb68e7c9258b1e,53f5bc3f4c71310c593a23aef01d1633,5812b5d4bcdfbf80de28dca56a6559b3,653b7986c4757bd5d0a251369187efa6,97ad8d6e6e3bf27ae6a7b457af9b312e,9b30fc06ca06f49c2faa238da7eddc6f,9e901f71d0d2339294da133518f2162f,b40ff9b93414391d5e4b3c06dfe02bc9,b881b9051ad24c6a16b468803fba51d3,c580fa74e3c36285cfae7df56340a990</data>
    </node>
    <node id="&quot;ADELINE&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Adeline is a pattern recognition machine introduced by Widrow."
</data>
      <data key="d2">7c556574ea1f1f26ee3ad2a63d56b8e7,9e901f71d0d2339294da133518f2162f</data>
    </node>
    <node id="&quot;PERCEPTRON&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Perceptron is a model mentioned in the text, but its full name or description is not provided."
"Perceptron is a simple machine learning algorithm used for binary classification tasks, which iteratively adjusts the weights of input features to separate data points into two classes."
"Perceptron is a model from scikit-learn used for classification tasks."
"Perceptron is a classifier implemented in the scikit-learn library, used for binary classification tasks."
"Perceptron is a model from Scikit-learn used for classification tasks."
"Perceptron is a machine learning algorithm used for classification tasks, provided by the Scikit-learn library."</data>
      <data key="d2">0036fb6f489e13c0db0f1c02bf3323be,35631fbf2ad11c53d75cb9b42e2c39b4,9e901f71d0d2339294da133518f2162f,d58662ee42c14a0787d839ebfd0a6e9b,dadca3c89b34dc48a60c53367ab55768,f5358a50d00a1cac02dd4ad8fcb167ee</data>
    </node>
    <node id="&quot;NEURAL PATTERN RECOGNITION&quot;">
      <data key="d0" />
      <data key="d1">
</data>
      <data key="d2">7c556574ea1f1f26ee3ad2a63d56b8e7,9e901f71d0d2339294da133518f2162f</data>
    </node>
    <node id="&quot;KOHONEN&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Kohonen is an organization or individual associated with the transition from linear algebra concepts to more biologically motivated studies in neural network research."
"Kohonen is a person mentioned in the text who has used Instar Learning in his applications of the Self-Organizing Map (SOM) model."
"Kohonen is a researcher who used Instar Learning in his applications of the SOM model."
"Kohonen is an author who has developed the SOM model, which utilizes shunting dynamics in some versions."</data>
      <data key="d2">2cbd29d6f0019f0c85bee43779ae8f4d,43cf5e32e2df964318d03574e6cd6cdc,7c556574ea1f1f26ee3ad2a63d56b8e7,b286a9022774f24a400744b2a1b08bab</data>
    </node>
    <node id="&quot;HARTLINE&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Hartline is an organization or individual associated with neurophysiological experiments on the lateral eye of the Limulus, or horseshoe crab, leading to the development of the steady state Hartline-Ratliff model."</data>
      <data key="d2">7c556574ea1f1f26ee3ad2a63d56b8e7</data>
    </node>
    <node id="&quot;LTM EQUATIONS&quot;">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">7c556574ea1f1f26ee3ad2a63d56b8e7</data>
    </node>
    <node id="&quot;NEURAL NETWORK RESEARCH&quot;">
      <data key="d0" />
      <data key="d1">
"Neural Network Research is an ongoing field of study, with the Additive Model and Hopfield Model being significant contributions."</data>
      <data key="d2">7c556574ea1f1f26ee3ad2a63d56b8e7,df77d35da87a38cae0984a42b9a1d41c</data>
    </node>
    <node id="&quot;STEADY STATE HARTLINE-RATLIFF MODEL&quot;">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">7c556574ea1f1f26ee3ad2a63d56b8e7</data>
    </node>
    <node id="&quot;HARTLINE-RATLIFF MODEL&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"The Hartline-Ratliff Model is a steady state model developed by H.K. Hartline and J.A. Ratliff in 1957, inspired by neurophysiological experiments on the lateral eye of the Limulus."</data>
      <data key="d2">48763056731d01884b6cf37bf0e0d0db</data>
    </node>
    <node id="&quot;H.K. HARTLINE&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"H.K. Hartline is a neurophysiologist who led the experiments on the lateral eye of the Limulus, for which he received the Nobel Prize in Physiology or Medicine in 1967."</data>
      <data key="d2">48763056731d01884b6cf37bf0e0d0db</data>
    </node>
    <node id="&quot;J.A. RATLIFF&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"J.A. Ratliff is a neurophysiologist who extended the steady-state Hartline-Ratliff model to a dynamical model in 1963."</data>
      <data key="d2">48763056731d01884b6cf37bf0e0d0db</data>
    </node>
    <node id="&quot;LIMULUS&quot;">
      <data key="d0">"GEO"</data>
      <data key="d1">"Limulus is a species of horseshoe crab used in neurophysiological experiments."</data>
      <data key="d2">48763056731d01884b6cf37bf0e0d0db</data>
    </node>
    <node id="&quot;ADDITIVE MODEL&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"The Additive Model is a model described in the text, which is a precursor of the dynamical model developed by J.A. Ratliff."
"The Additive Model is a concept used in computational analyses, consisting of a main term and additional terms for positive and negative feedback, as well as input."
"The Additive Model is a neural network model developed by Grossberg, used in various computational analyses and research areas."
"The Additive Model is a neural network concept mentioned in the text, with applications in decision-making and other areas."
"The Additive Model is a mathematical model that is used as an approximation of the Shunting Model when inputs are small and do not approach saturation values."
"Additive Model is another variant of the STM Equation, with parameters C and F set to 0."

"Additive Model is a model mentioned in the text for which Hopfield stated a Liapunov function."
"The Additive Model is a probabilistic decision-making model that does not exhibit self-normalization properties."
"The Additive Model is a type of network mentioned in the text, which is included in the Cohen-Grossberg Model systems."
"Additive Model is a component of the Liapunov function proposed by Cohen and Grossberg, which has been erroneously called the Hopfield network."
"The Additive Model is a model used to explain associative learning of temporal order information in serial learning paradigms."</data>
      <data key="d2">0dd75f3ca11854714bdbfc8a96ccf256,2cbd29d6f0019f0c85bee43779ae8f4d,2e76149ff772441e6627913bc1df5000,3281409fdcd18b09ca3109260ddb96d9,431b0938a2956f5d7d752462f3b71101,47d1d12642cdab6e9a5d21c184f83c9c,48763056731d01884b6cf37bf0e0d0db,98173c1c0fcd64ceb914e0dd6b366b30,9ed5e24bce2907e0ffa4acbe066dbfff,be0954a6263de67c84da3141d95de445,d4afac3b7aed3d6e11ff5eaf34589c2d,df77d35da87a38cae0984a42b9a1d41c</data>
    </node>
    <node id="&quot;HUGH EVERETT&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Hugh Everett is a physicist who extended a steady-state model to a dynamical model in 1963."</data>
      <data key="d2">caf44d8df044312829ae3fe56df0c440</data>
    </node>
    <node id="&quot;ANDREW HODGKIN&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Andrew Hodgkin is a physicist who, along with Alan Huxley, studied the squid giant axon in 1952."</data>
      <data key="d2">caf44d8df044312829ae3fe56df0c440</data>
    </node>
    <node id="&quot;ALAN HUXLEY&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Alan Huxley is a physicist who, along with Andrew Hodgkin, studied the squid giant axon in 1952."</data>
      <data key="d2">caf44d8df044312829ae3fe56df0c440</data>
    </node>
    <node id="&quot;JOHN HOPFIELD&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"John Hopfield is a physicist who derived neural networks that form the foundation of most current biological neural network research in 1982."
"John Hopfield is not explicitly mentioned in the text, but the term 'infinite impulse response' is associated with his work on Hopfield networks, which are a type of recurrent neural network."</data>
      <data key="d2">caf44d8df044312829ae3fe56df0c440,f5b970cf7201f4a918d8bd6a1267657c</data>
    </node>
    <node id="&quot;NEURAL NETWORKS&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Neural Networks are a focus of study, with examples from the work of Hugh Everett, Andrew Hodgkin, Alan Huxley, and John Hopfield."
"Neural Networks are a focus of the text, with researchers and physicists contributing to their development and study."
"Neural Networks are a field of study that focuses on the structure and function of biological neurons and artificial neural networks, which are mathematical models inspired by biological neurons."
"Neural Networks is a field of study mentioned in the text, focusing on the simulation of biological neural systems for information processing."

"Neural Networks are a type of artificial intelligence modeled after the human brain, used for tasks such as sequence prediction."</data>
      <data key="d2">47d1d12642cdab6e9a5d21c184f83c9c,4c7e78f7237cb3420e70c7749bb259f9,b31ca51b419f7270ee5f4910c90ea331,be49e9beb2d7cc985fe9f6517fa0f4fe,bf4dccb5096a917a6a71f0cc224e4d7c,caf44d8df044312829ae3fe56df0c440</data>
    </node>
    <node id="&quot;SQUID GIANT AXON&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"The Squid Giant Axon is a subject of study by Andrew Hodgkin and Alan Huxley in 1952."</data>
      <data key="d2">caf44d8df044312829ae3fe56df0c440</data>
    </node>
    <node id="&quot;ROCKEFELLER INSTITUTE&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Rockefeller Institute is an institution where Grossberg was a student and published a monograph about his research."</data>
      <data key="d2">3235445917507f02710bd66cc8368194</data>
    </node>
    <node id="&quot;COLLEGE FRESHMAN&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Grossberg was a College Freshman when he introduced the paradigm of using nonlinear systems of differential equations to model brain mechanisms."</data>
      <data key="d2">3235445917507f02710bd66cc8368194</data>
    </node>
    <node id="&quot;ADAPTIVE BEHAVIOR&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Adaptive Behavior refers to the ability of an individual learner to adjust autonomously in real time, as discovered by Grossberg."</data>
      <data key="d2">3235445917507f02710bd66cc8368194</data>
    </node>
    <node id="&quot;COMPUTATIONAL ANALYSIS&quot;">
      <data key="d0">"EVENT"</data>
      <data key="d1">"Computational Analysis is an event where the Additive Model is applied, likely involving mathematical and computational processes."</data>
      <data key="d2">9ed5e24bce2907e0ffa4acbe066dbfff</data>
    </node>
    <node id="&quot;MAIN TERM&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"The Main Term is a component of the Additive Model, representing the primary term in the equation."</data>
      <data key="d2">9ed5e24bce2907e0ffa4acbe066dbfff</data>
    </node>
    <node id="&quot;POSITIVE FEEDBACK TERM&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"The Positive Feedback Term is a component of the Additive Model, representing the influence of positive feedback on the system."</data>
      <data key="d2">9ed5e24bce2907e0ffa4acbe066dbfff</data>
    </node>
    <node id="&quot;NEGATIVE FEEDBACK TERM&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"The Negative Feedback Term is a component of the Additive Model, representing the influence of negative feedback on the system."</data>
      <data key="d2">9ed5e24bce2907e0ffa4acbe066dbfff</data>
    </node>
    <node id="&quot;INPUT TERM&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"The Input Term is a component of the Additive Model, representing external inputs to the system."</data>
      <data key="d2">9ed5e24bce2907e0ffa4acbe066dbfff</data>
    </node>
    <node id="&quot;MATHEMATICAL PROCESSES&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Mathematical Processes are a type of event that may be involved in the Computational Analysis, involving the application of mathematical concepts and techniques."</data>
      <data key="d2">9ed5e24bce2907e0ffa4acbe066dbfff</data>
    </node>
    <node id="&quot;COMPUTATIONAL PROCESSES&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Computational Processes are a type of event that may be involved in the Computational Analysis, involving the use of computers and algorithms to perform calculations and simulations."</data>
      <data key="d2">9ed5e24bce2907e0ffa4acbe066dbfff</data>
    </node>
    <node id="&quot;HOPFIELD MODEL&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"The Hopfield Model is a type of recurrent neural network developed by Hopfield, which is a simplified version of the Additive Model."</data>
      <data key="d2">df77d35da87a38cae0984a42b9a1d41c</data>
    </node>
    <node id="&quot;HOPFIELD&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Hopfield is a researcher who developed the Hopfield Model, which is a simplified version of the Additive Model."
"Hopfield is a researcher mentioned in the text, contributing to the development of the Hopfield model in neural networks."
"Hopfield is a researcher who stated a Liapunov function for the Additive Model."
"Hopfield is a researcher mentioned in the text who stated a Liapunov function for the Additive Model."
"Hopfield is a researcher who published a special case of the Additive Model and Liapunov function, asserting that trajectories approach equilibria."</data>
      <data key="d2">47d1d12642cdab6e9a5d21c184f83c9c,98173c1c0fcd64ceb914e0dd6b366b30,be0954a6263de67c84da3141d95de445,d4afac3b7aed3d6e11ff5eaf34589c2d,df77d35da87a38cae0984a42b9a1d41c</data>
    </node>
    <node id="&quot;COMPUTATIONAL VISION&quot;">
      <data key="d0">"EVENT"</data>
      <data key="d1">"Computational Vision is an application area where the Additive Model has been used for analysis and recognition."</data>
      <data key="d2">df77d35da87a38cae0984a42b9a1d41c</data>
    </node>
    <node id="&quot;LEARNING&quot;">
      <data key="d0">"EVENT"</data>
      <data key="d1">"Learning is an application area where the Additive Model has been used for analysis and decision-making."</data>
      <data key="d2">df77d35da87a38cae0984a42b9a1d41c</data>
    </node>
    <node id="&quot;SPEECH AND LANGUAGE ANALYSIS&quot;">
      <data key="d0">"EVENT"</data>
      <data key="d1">"Speech and Language Analysis is an application area where the Additive Model has been used for analysis of temporal order."</data>
      <data key="d2">df77d35da87a38cae0984a42b9a1d41c</data>
    </node>
    <node id="&quot;SENSORY-MOTOR CONTROL&quot;">
      <data key="d0">"EVENT"</data>
      <data key="d1">"Sensory-Motor Control is an application area where the Additive Model has been used for analysis and control."
"Sensory-Motor Control is mentioned as an event or phenomenon that MTM dynamics help to explain."</data>
      <data key="d2">254fd1fbc0a719a86b8021fa759d22ea,df77d35da87a38cae0984a42b9a1d41c</data>
    </node>
    <node id="&quot;USHER&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Usher is a researcher mentioned in the text, contributing to decision-making in neural networks."</data>
      <data key="d2">47d1d12642cdab6e9a5d21c184f83c9c</data>
    </node>
    <node id="&quot;MCCLELLAND&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"McClelland is a researcher mentioned in the text, contributing to decision-making in neural networks."</data>
      <data key="d2">47d1d12642cdab6e9a5d21c184f83c9c</data>
    </node>
    <node id="&quot;STM EQUATION&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"The STM Equation is a neural network concept mentioned in the text, with applications in modeling individual neurons and maintaining sensitivity."
"STM Equation is a mathematical model used to describe neural models of different brain systems, including parameters such as A, B, C, D, E, and F."</data>
      <data key="d2">3281409fdcd18b09ca3109260ddb96d9,47d1d12642cdab6e9a5d21c184f83c9c</data>
    </node>
    <node id="&quot;HODGKIN&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Hodgkin is a scientist who developed a mathematical model for the shunting dynamics of individual neurons."</data>
      <data key="d2">431b0938a2956f5d7d752462f3b71101</data>
    </node>
    <node id="&quot;STM TRACES&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"STM traces are signals or activities that are bounded within an interval and interact with balanced positive and negative signals."
"STM Traces are short-term memory traces, representing activities in a neural system."
"STM Traces are a component of the Generalized Additive System, representing the activities of the system."</data>
      <data key="d2">18be9bfe53d3b9c1e15c1c8238674459,431b0938a2956f5d7d752462f3b71101,8bb0e63353e66a2c60a878028beff5f9</data>
    </node>
    <node id="&quot;SHUNTING MODEL&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"The Shunting Model is a mathematical model that approximates the Additive Model in certain conditions and uses a combination of shunting and additive terms."
"Shunting Model is a variant of the STM Equation, with parameters C and F, and E set to 0 or a specific value, respectively."
"The Shunting Model is a mathematical model used to describe the behavior of cells in the network."
"The Shunting Model is a type of network mentioned in the text, which is included in the Cohen-Grossberg Model systems."
"Shunting Model is a component of the Liapunov function proposed by Cohen and Grossberg."
"The Shunting Model is a model used to explain associative learning of temporal order information in serial learning paradigms."</data>
      <data key="d2">0dd75f3ca11854714bdbfc8a96ccf256,2e76149ff772441e6627913bc1df5000,3281409fdcd18b09ca3109260ddb96d9,431b0938a2956f5d7d752462f3b71101,68b4b33f0da5edc9dcb301a08821b352,98173c1c0fcd64ceb914e0dd6b366b30</data>
    </node>
    <node id="&quot;WILSON-COWAN MODEL&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"The Wilson-Cowan model is a mathematical model developed by Wilson and Cowan that also uses a combination of shunting and additive terms, but in a different formulation."
"The Wilson-Cowan Model is mentioned in the text, which uses a sigmoid of sums that is multiplied by a shunting term."</data>
      <data key="d2">431b0938a2956f5d7d752462f3b71101,653b7986c4757bd5d0a251369187efa6</data>
    </node>
    <node id="&quot;WILSON&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Wilson is a scientist who developed the Wilson-Cowan model with Cowan."</data>
      <data key="d2">431b0938a2956f5d7d752462f3b71101</data>
    </node>
    <node id="&quot;COWAN&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Cowan is a scientist who developed the Wilson-Cowan model with Wilson."
"Cowan is a researcher who reviewed experimental data supporting the existence of a four plus or minus one WM capacity limit when LTM and grouping influences are minimized."</data>
      <data key="d2">392028b79561bd7471cb68e7c9258b1e,431b0938a2956f5d7d752462f3b71101</data>
    </node>
    <node id="&quot;MTM&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"MTM is a type of medium-term memory system mentioned in the text, which changes at a rate intermediate between STM and LTM."
"MTM refers to a system or model that includes MTM traces or habituative transmitter gates, which are described in the text."
"MTM refers to Medium-Term Memory, a component that stores and retrieves information for a moderate duration."
"MTM stands for Medium-Term Memory, which is not explicitly mentioned in the text but could be inferred based on the context."</data>
      <data key="d2">0d925896ce2bf9b73be90d8fa5ddb402,254fd1fbc0a719a86b8021fa759d22ea,653b7986c4757bd5d0a251369187efa6,b40ff9b93414391d5e4b3c06dfe02bc9</data>
    </node>
    <node id="&quot;FAST INHIBITION&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Fast Inhibition is a feature of the STM Equation that assumes inhibitory interneurons respond instantaneously to their inputs."</data>
      <data key="d2">3281409fdcd18b09ca3109260ddb96d9</data>
    </node>
    <node id="&quot;SLOWER INHIBITION&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Slower Inhibition is a feature of the STM Equation that considers the temporal evolution of inhibitory interneuronal activities."</data>
      <data key="d2">3281409fdcd18b09ca3109260ddb96d9</data>
    </node>
    <node id="&quot;COHEN AND GROSSBERG&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Cohen and Grossberg are researchers who derived a Liapunov function for a generalization of the Additive and Shunting Models."
"Cohen and Grossberg are researchers who have contributed to the study of competitive systems and developed the Masking Field model."
"Cohen and Grossberg are researchers who developed the Cohen-Grossberg Liapunov function to prove the existence of global equilibria."
"Cohen and Grossberg are researchers who proposed a Liapunov function that includes the Additive Model and Shunting Model."</data>
      <data key="d2">4a78ff105fdd9a4b0d01ccf1e5816c74,4b48be5db14c2e681ef8f4ee7de4b847,98173c1c0fcd64ceb914e0dd6b366b30,d4afac3b7aed3d6e11ff5eaf34589c2d</data>
    </node>
    <node id="&quot;MEDIUM-TERM MEMORY (MTM)&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Medium-term memory (MTM) is described as activity-dependent habituation, often called habituative transmitter gates, which plays multiple roles in the described system."</data>
      <data key="d2">d4afac3b7aed3d6e11ff5eaf34589c2d</data>
    </node>
    <node id="&quot;ADDITIVE AND SHUNTING MODELS&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Additive and Shunting Models are mentioned in the context of a generalization by Cohen and Grossberg."
"The Additive and Shunting Models are mentioned in the text, referring to a network structure used in the research."
"Additive and Shunting Models are neural network architectures mentioned in the text."</data>
      <data key="d2">24771832864aa38abd6aebec04b13a10,97ad8d6e6e3bf27ae6a7b457af9b312e,d4afac3b7aed3d6e11ff5eaf34589c2d</data>
    </node>
    <node id="&quot;LIAPUNOV FUNCTION&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Liapunov Function is a mathematical concept used to analyze the stability of dynamic systems, including the one mentioned in the text."
"The Liapunov Function is a mathematical concept used to analyze the stability of systems, such as the Cohen-Grossberg Model."
"Liapunov Function is a mathematical concept used to analyze the stability of dynamic systems."
"A Liapunov function is a mathematical concept used to prove the global convergence of a system."</data>
      <data key="d2">01e2a32da700813f593038a23a618e55,0dd75f3ca11854714bdbfc8a96ccf256,98173c1c0fcd64ceb914e0dd6b366b30,be0954a6263de67c84da3141d95de445</data>
    </node>
    <node id="&quot;COHEN-GROSSBERG MODEL&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Cohen-Grossberg Model is a model mentioned in the text that includes the Liapunov function."
"The Cohen-Grossberg Model is a system of equations used to study the behavior of networks, with a focus on symmetry in interaction coefficients."
"The Cohen-Grossberg Model is a model developed by Cohen and Grossberg, which is adapted by Kosko."
"The Cohen-Grossberg model is a neural network model developed by Cohen and Grossberg in 1983."</data>
      <data key="d2">01e2a32da700813f593038a23a618e55,0dd75f3ca11854714bdbfc8a96ccf256,644602009dec8474bb5cd4702b391d3e,be0954a6263de67c84da3141d95de445</data>
    </node>
    <node id="&quot;MEDIUM-TERM MEMORY&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Medium-term Memory, or activity-dependent habituation, is a concept mentioned in the text that plays multiple roles in neural networks."</data>
      <data key="d2">be0954a6263de67c84da3141d95de445</data>
    </node>
    <node id="&quot;GATED DIPOLE OPPONENT PROCESSING NETWORK&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Gated Dipole Opponent Processing Network is a type of neural network mentioned in the text that enables reset events and arousal bursts."</data>
      <data key="d2">be0954a6263de67c84da3141d95de445</data>
    </node>
    <node id="&quot;ADAPTIVE RESONANCE THEORY&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Adaptive Resonance Theory is mentioned in the text as a related concept to MTM."
"Adaptive Resonance Theory is a concept mentioned in the text, likely a theoretical framework developed by Grossberg."
"Adaptive Resonance Theory is a concept mentioned in the text, which was introduced by Grossberg to propose how top-down learned expectations and attentional focusing could dynamically stabilize learning in a Competitive Learning or Self-Organizing Map model."
"Adaptive Resonance Theory is a learning model introduced by Grossberg in 1976 to stabilize learning in response to input patterns."
"Adaptive Resonance Theory, or ART, is a cognitive and bRNN theory that explains how the brain autonomously learns to categorize, recognize, and predict objects and events."
"Adaptive Resonance Theory is a cognitive and bRNN theory that explains how the brain autonomously learns to categorize, recognize, and predict objects and events in a changing world."
"Adaptive Resonance Theory is a neural network model developed by Grossberg, which focuses on the role of attention in learning and recognition."</data>
      <data key="d2">01e2a32da700813f593038a23a618e55,2061ae5039f379b5837d33a062f72ad1,254fd1fbc0a719a86b8021fa759d22ea,32b8b59687b8d1556ec90c99a090653c,3d5b88f7f81ed9e14f07335bbef17020,554e8565591507441cecaa652cb926db,644602009dec8474bb5cd4702b391d3e</data>
    </node>
    <node id="&quot;VISUAL PERCEPTION&quot;">
      <data key="d0">"EVENT"</data>
      <data key="d1">"Visual Perception is mentioned as an event or phenomenon that MTM dynamics help to explain."
"Visual Perception is mentioned in the context of brightness constancy and brightness contrast, which are explained by the Normalization Rule."
"Visual Perception refers to the process by which the brain interprets and understands visual information from the environment."</data>
      <data key="d2">254fd1fbc0a719a86b8021fa759d22ea,8202e13f45a323970b361921f923c605,c8c573c11d0f29d207b3b639a9466518</data>
    </node>
    <node id="&quot;COGNITIVE-EMOTIONAL INTERACTIONS&quot;">
      <data key="d0">"EVENT"</data>
      <data key="d1">"Cognitive-Emotional Interactions is mentioned as an event or phenomenon that MTM dynamics help to explain."</data>
      <data key="d2">254fd1fbc0a719a86b8021fa759d22ea</data>
    </node>
    <node id="&quot;DECISION-MAKING UNDER RISK&quot;">
      <data key="d0">"EVENT"</data>
      <data key="d1">"Decision-Making under Risk is mentioned as an event or phenomenon that MTM dynamics help to explain."</data>
      <data key="d2">254fd1fbc0a719a86b8021fa759d22ea</data>
    </node>
    <node id="&quot;GUTOWSKI&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Gutowski is an author mentioned in the text, likely a researcher."</data>
      <data key="d2">c73b76e10166042ccaba5603ed67f380</data>
    </node>
    <node id="&quot;OGMEN AND GAGN&#201;&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Ogmen and Gagn&#233; are likely a research team or authors mentioned in the text."</data>
      <data key="d2">c73b76e10166042ccaba5603ed67f380</data>
    </node>
    <node id="&quot;ABBOTT ET AL.&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Abbott et al. is a group of authors mentioned in the text, likely a research team."</data>
      <data key="d2">c73b76e10166042ccaba5603ed67f380</data>
    </node>
    <node id="&quot;TSODYKS AND MARKRAM&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Tsodyks and Markram are likely a research team or authors mentioned in the text."</data>
      <data key="d2">c73b76e10166042ccaba5603ed67f380</data>
    </node>
    <node id="&quot;GAUDIANO AND GROSSBERG&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Gaudiano and Grossberg are likely a research team or authors mentioned in the text."
"Gaudiano and Grossberg is a research collaboration mentioned in the text, contributing to the complexity of the mass action term."</data>
      <data key="d2">24771832864aa38abd6aebec04b13a10,c73b76e10166042ccaba5603ed67f380</data>
    </node>
    <node id="&quot;GROSSBERG AND SEITZ&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Grossberg and Seitz are likely a research team or authors mentioned in the text."</data>
      <data key="d2">c73b76e10166042ccaba5603ed67f380</data>
    </node>
    <node id="&quot;MTM TRACE&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"MTM Trace is a term used in the text, likely referring to a specific concept or technique in neurophysiology."</data>
      <data key="d2">c73b76e10166042ccaba5603ed67f380</data>
    </node>
    <node id="&quot;HABITUATIVE TRANSMITTER GATE&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Habituative Transmitter Gate is a term used in the text, likely referring to a specific concept or technique in neurophysiology."</data>
      <data key="d2">c73b76e10166042ccaba5603ed67f380</data>
    </node>
    <node id="&quot;MASS ACTION INTERACTION&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Mass Action Interaction is a term used in the text, likely referring to a specific concept or technique in neurophysiology."</data>
      <data key="d2">c73b76e10166042ccaba5603ed67f380</data>
    </node>
    <node id="&quot;ADAPTIVE WEIGHTS&quot;">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">24771832864aa38abd6aebec04b13a10</data>
    </node>
    <node id="&quot;MASS ACTION TERM&quot;">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">24771832864aa38abd6aebec04b13a10</data>
    </node>
    <node id="&quot;LTM TRACES&quot;">
      <data key="d0" />
      <data key="d1">
"LTM Traces are long-term memory traces, representing adaptive weights in a neural system."
"LTM Traces are a component of the Generalized Additive System, representing the adaptive weights of the system."</data>
      <data key="d2">18be9bfe53d3b9c1e15c1c8238674459,24771832864aa38abd6aebec04b13a10,8bb0e63353e66a2c60a878028beff5f9</data>
    </node>
    <node id="&quot;HEBB&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Hebb is a reference to Donald O. Hebb, a neuroscientist known for his work on neural networks and learning."
"Hebb is a person who ascribed the property of monotonely increasing learned weights to his law in the 1940s."</data>
      <data key="d2">32b8b59687b8d1556ec90c99a090653c,97ad8d6e6e3bf27ae6a7b457af9b312e</data>
    </node>
    <node id="&quot;OUTSTAR LEARNING&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Outstar Learning is a variant of gated steepest descent learning introduced by Grossberg for spatial pattern learning."
"Outstar Learning is a variant of gated steepest descent learning introduced by Grossberg in 1968b for spatial pattern learning."</data>
      <data key="d2">97ad8d6e6e3bf27ae6a7b457af9b312e,b286a9022774f24a400744b2a1b08bab</data>
    </node>
    <node id="&quot;INSTAR LEARNING&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Instar Learning is another variant of learning used in Grossberg's research."
"Instar Learning is another variant of gated steepest descent learning used in Grossberg's work for learning bottom-up adaptive filters in Self-Organizing Map (SOM) models."</data>
      <data key="d2">97ad8d6e6e3bf27ae6a7b457af9b312e,b286a9022774f24a400744b2a1b08bab</data>
    </node>
    <node id="&quot;HEBBIAN TRACES&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Hebbian Traces are a type of connection strength in neural networks that saturate at maximum values, according to the Hebb postulate."</data>
      <data key="d2">b286a9022774f24a400744b2a1b08bab</data>
    </node>
    <node id="&quot;SELF-ORGANIZING MAP (SOM)&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Self-Organizing Map (SOM) is a type of artificial neural network that uses a recurrent on-center off-surround network for storage and learning of spatial patterns."
"Self-Organizing Map (SOM) is a model developed by Kohonen, which also utilizes shunting dynamics in some versions."</data>
      <data key="d2">2cbd29d6f0019f0c85bee43779ae8f4d,b286a9022774f24a400744b2a1b08bab</data>
    </node>
    <node id="&quot;LONG-TERM MEMORY (LTM)&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Long-Term Memory (LTM) is a type of memory in neural networks that stores learned patterns and connections."</data>
      <data key="d2">b286a9022774f24a400744b2a1b08bab</data>
    </node>
    <node id="&quot;HECHT-NIELSEN&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Hecht-Nielsen is a researcher who referred to a network with Instars and Outstars as a counterpropagation network."</data>
      <data key="d2">43cf5e32e2df964318d03574e6cd6cdc</data>
    </node>
    <node id="&quot;SOM MODEL&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"SOM model is a neural network model used for data analysis and visualization."</data>
      <data key="d2">43cf5e32e2df964318d03574e6cd6cdc</data>
    </node>
    <node id="&quot;ART&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"ART is a neural network model introduced by Grossberg, which uses Instars and Outstars for learning."
"ART is a concept introduced in the text, likely an organization or system, but no specific details are provided."</data>
      <data key="d2">2061ae5039f379b5837d33a062f72ad1,43cf5e32e2df964318d03574e6cd6cdc</data>
    </node>
    <node id="&quot;SOM MODELS&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"SOM Models are mentioned in the text, likely referring to Self-Organizing Maps, which are a type of artificial neural network."</data>
      <data key="d2">2061ae5039f379b5837d33a062f72ad1</data>
    </node>
    <node id="&quot;INSTAR-OUTSTAR NETWORK&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Instar-Outstar Network is a type of network mentioned in the text, likely a combination of Instar and Outstar learning systems."</data>
      <data key="d2">2061ae5039f379b5837d33a062f72ad1</data>
    </node>
    <node id="&quot;O&#8217;REILLY&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"O&#8217;Reilly is a person mentioned in the text, likely a researcher or author."</data>
      <data key="d2">b40ff9b93414391d5e4b3c06dfe02bc9</data>
    </node>
    <node id="&quot;MUNAKATA&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Munakata is a person mentioned in the text, likely a researcher or author."</data>
      <data key="d2">b40ff9b93414391d5e4b3c06dfe02bc9</data>
    </node>
    <node id="&quot;LEABRA MODEL&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"The Leabra model is a neural network model developed by O&#8217;Reilly and Munakata, which utilizes STM, MTM, and LTM equations."</data>
      <data key="d2">b40ff9b93414391d5e4b3c06dfe02bc9</data>
    </node>
    <node id="&quot;O&#8217;REILLY AND MUNAKATA&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"O&#8217;Reilly and Munakata are mentioned as the authors of the Leabra model, which is used in the context of processing spatial patterns."</data>
      <data key="d2">0d925896ce2bf9b73be90d8fa5ddb402</data>
    </node>
    <node id="&quot;THE BRAIN&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"The brain is referred to as an organization that processes patterned information, learns from spatial and temporal patterns, and compensates for variable input intensities."</data>
      <data key="d2">0d925896ce2bf9b73be90d8fa5ddb402</data>
    </node>
    <node id="&quot;SPATIAL PATTERNS&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Spatial patterns refer to the distribution of information across networks of neurons, such as in a picture or a scene."</data>
      <data key="d2">0d925896ce2bf9b73be90d8fa5ddb402</data>
    </node>
    <node id="&quot;TEMPORAL PATTERNS&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Temporal patterns refer to the sequence of signals over time, such as in speech."</data>
      <data key="d2">0d925896ce2bf9b73be90d8fa5ddb402</data>
    </node>
    <node id="&quot;NEURONS&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Neurons are biological cells that process information, evolving network designs to compensate for variable input intensities."
"Neurons are the individual units in a reservoir, which can be triggered and activated."
"Neurons are the individual units within the Reservoir, which evolve in time following the evolution of the input timeseries."
"Neurons are a biological concept mentioned in the text, likely in the context of a neural network or similar technology."</data>
      <data key="d2">0e0afab060f214d46062c9886e762002,31080b985ce23ef751d488d0f7b9eff6,b957e1bf5bf175c7630222ca742c7933,c4f5a27caf9dd9c1d972492c1147efa0</data>
    </node>
    <node id="&quot;BRAINS&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Brains are mentioned as having evolved network designs in neurons to process variable input intensities."</data>
      <data key="d2">31080b985ce23ef751d488d0f7b9eff6</data>
    </node>
    <node id="&quot;NOISE-SATURATION DILEMMA&quot;">
      <data key="d0">"EVENT"</data>
      <data key="d1">"The Noise-Saturation Dilemma refers to the challenge of maintaining neuronal sensitivity to input patterns while dealing with variable input intensities."
"The challenge of maintaining sensitivity to relative inputs while avoiding saturation when the total input size varies significantly."</data>
      <data key="d2">31080b985ce23ef751d488d0f7b9eff6,7beb44dd43aea0791fcb35806356ddb3</data>
    </node>
    <node id="&quot;ON-CENTER OFF-SURROUND NETWORK&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"The On-center Off-Surround Network is a network design that enables neurons to retain sensitivity to the relative sizes of their inputs across the network."
"A type of network that obeys the membrane or shunting equations of neurophysiology, which helps to explain its ubiquity in the brain."</data>
      <data key="d2">31080b985ce23ef751d488d0f7b9eff6,7beb44dd43aea0791fcb35806356ddb3</data>
    </node>
    <node id="&quot;MEMBRANE&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Membrane, or shunting, is a concept mentioned in the context of neuronal network design."</data>
      <data key="d2">31080b985ce23ef751d488d0f7b9eff6</data>
    </node>
    <node id="&quot;SPATIAL PATTERN&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"A spatial pattern of inputs that is processed by a network of cells."</data>
      <data key="d2">7beb44dd43aea0791fcb35806356ddb3</data>
    </node>
    <node id="&quot;NETWORK OF CELLS&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"A network of cells that processes a spatial pattern of inputs, with each cell maintaining sensitivity to the relative size of its inputs."</data>
      <data key="d2">7beb44dd43aea0791fcb35806356ddb3</data>
    </node>
    <node id="&quot;RELATIVE SIZE&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"The constant relative size, or reflectance, of each input in the spatial pattern."</data>
      <data key="d2">7beb44dd43aea0791fcb35806356ddb3</data>
    </node>
    <node id="&quot;TOTAL INPUT SIZE&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"The variable total input size that is the sum of the relative sizes of all inputs in the spatial pattern."</data>
      <data key="d2">7beb44dd43aea0791fcb35806356ddb3</data>
    </node>
    <node id="&quot;CELL (V_I)&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Each cell in the network of cells that maintains sensitivity to the relative size of its inputs."
"Cell (v_i) is a biological unit that maintains sensitivity to its input size (I_i) and competes with other inputs (I_k) to activate itself."</data>
      <data key="d2">7beb44dd43aea0791fcb35806356ddb3,fe551b6e0c32ef0fb9ac0a07ff64d6ba</data>
    </node>
    <node id="&quot;INPUT (I_I)&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Each input in the spatial pattern that is processed by the network of cells."
"Input (I_i) is the total input size that each cell (v_i) receives, and increasing it increases the sensitivity of the cell."</data>
      <data key="d2">7beb44dd43aea0791fcb35806356ddb3,fe551b6e0c32ef0fb9ac0a07ff64d6ba</data>
    </node>
    <node id="&quot;INPUT (I_K)&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Input (I_k) are the additional inputs that compete with Input (I_i) to inhibit the activation of cell (v_i)."</data>
      <data key="d2">fe551b6e0c32ef0fb9ac0a07ff64d6ba</data>
    </node>
    <node id="&quot;KUFFLER&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Kuffler is a researcher who reported on-center off-surround anatomies in the cat retina."
"Kuffler is a researcher who reported on-center off-surround anatomies in the cat retina in 1953."</data>
      <data key="d2">9d40ff29a29b7422b2b0c76b957c54f3,fe551b6e0c32ef0fb9ac0a07ff64d6ba</data>
    </node>
    <node id="&quot;ON-CENTER OFF-SURROUND ANATOMY&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"On-Center Off-Surround Anatomy is a neural structure that activates and inhibits cells through time, with each cell having excitable sites that can spontaneously decay."</data>
      <data key="d2">9d40ff29a29b7422b2b0c76b957c54f3</data>
    </node>
    <node id="&quot;CELLS&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Cells are the units of which each possesses excitable sites that can be excited or inhibited."</data>
      <data key="d2">9d40ff29a29b7422b2b0c76b957c54f3</data>
    </node>
    <node id="&quot;INPUTS&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Inputs are the stimuli that can excite or inhibit cells."
"Inputs are examples from a dataset that are passed to a model for processing, such as data points in supervised learning."</data>
      <data key="d2">54b1174770e13d4a2bc0916db477cc56,9d40ff29a29b7422b2b0c76b957c54f3</data>
    </node>
    <node id="&quot;FEEDFORWARD ON-CENTER NETWORK&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"A network defined by equation (13) that consists of cells obeying a simple version of the Shunting Model."</data>
      <data key="d2">68b4b33f0da5edc9dcb301a08821b352</data>
    </node>
    <node id="&quot;EQUATION (13)&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Equation (13) defines the behavior of the Feedforward On-Center Network."
"Equation (13) is a mathematical expression used in the text to describe a process involving automatic gain control."</data>
      <data key="d2">04e132fa3a85e95e1e6164428852446e,68b4b33f0da5edc9dcb301a08821b352</data>
    </node>
    <node id="&quot;EQUATION (8)&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Equation (8) is a reference to a previous mathematical model used for comparison."</data>
      <data key="d2">68b4b33f0da5edc9dcb301a08821b352</data>
    </node>
    <node id="&quot;FIXED SPATIAL PATTERN&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"A fixed spatial pattern is presented to the network, with the total input (I) held constant for a while."</data>
      <data key="d2">68b4b33f0da5edc9dcb301a08821b352</data>
    </node>
    <node id="&quot;OFF-SURROUND&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Off-surround is a term used in the text to describe an inhibitory input that multiplies a variable in Equation (13)."</data>
      <data key="d2">04e132fa3a85e95e1e6164428852446e</data>
    </node>
    <node id="&quot;VARIABLE X_I&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Variable x_i is a term used in the text to represent a value that changes based on input strength."</data>
      <data key="d2">04e132fa3a85e95e1e6164428852446e</data>
    </node>
    <node id="&quot;INPUT I&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Input I is a term used in the text to represent an external factor that affects the behavior of Variable x_i."</data>
      <data key="d2">04e132fa3a85e95e1e6164428852446e</data>
    </node>
    <node id="&quot;MASS ACTION NETWORKS&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Mass Action Networks is a term used in the text to describe a type of system where both the steady state and the rate of change of a variable depend upon input strength."</data>
      <data key="d2">04e132fa3a85e95e1e6164428852446e</data>
    </node>
    <node id="&quot;ACTIVITIES (X_I)&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Activities (x_i) are described as variables in a mathematical model, with their behavior influenced by input strength (I) and a conservation law."</data>
      <data key="d2">c8c573c11d0f29d207b3b639a9466518</data>
    </node>
    <node id="&quot;INPUT STRENGTH (I)&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Input Strength (I) is a variable in a mathematical model that influences the behavior of Activities (x_i) and the total activity (x)."</data>
      <data key="d2">c8c573c11d0f29d207b3b639a9466518</data>
    </node>
    <node id="&quot;TOTAL ACTIVITY (X)&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Total Activity (x) is the sum of all Activities (x_i) and is independent of the number of active cells, approaching a constant (B) as Input Strength (I) increases."</data>
      <data key="d2">c8c573c11d0f29d207b3b639a9466518</data>
    </node>
    <node id="&quot;NORMALIZATION RULE&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"The Normalization Rule is a conservation law that ensures the total activity remains constant by forcing a decrease in other activities when one activity increases."
"The Normalization Rule is a constraint that ensures stable learning and memory of list chunks, likely through a specialized process."
"Normalization Rule is a rule that assumes working memory has a limited capacity and activity is redistributed, not just added, when new items are stored."
"The Normalization Rule is a principle that ensures the total activity of the working memory network has a maximum capacity, redistributing activity when new items are stored."
"Normalization Rule is a principle mentioned in the text, which follows from the tendency of RCFs to normalize total network activity."</data>
      <data key="d2">1976b19f768a8fdf37207b680c3b2b40,4364aa6091e1966365fa889b34f5cf90,c38beddeac1d3cac8282ad59bc835788,c8c573c11d0f29d207b3b639a9466518,dcd38cdc6195b2bbf41d936af0bf1f5f</data>
    </node>
    <node id="&quot;WEBER LAW&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Weber Law is a principle in psychophysics that describes the relationship between the perceived intensity of a stimulus and its physical intensity."</data>
      <data key="d2">8202e13f45a323970b361921f923c605</data>
    </node>
    <node id="&quot;SHIFT PROPERTY&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Shift Property is a property of a system that causes the entire response curve to shift without a loss of sensitivity."</data>
      <data key="d2">8202e13f45a323970b361921f923c605</data>
    </node>
    <node id="&quot;BRIGHTNESS CONSTANCY&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Brightness Constancy is a property of visual perception that ensures that objects appear the same brightness regardless of their surrounding luminance."</data>
      <data key="d2">8202e13f45a323970b361921f923c605</data>
    </node>
    <node id="&quot;BRIGHTNESS CONTRAST&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Brightness Contrast is a visual phenomenon that occurs when increasing the luminance of inputs to the off-surround makes the on-center look darker."</data>
      <data key="d2">8202e13f45a323970b361921f923c605</data>
    </node>
    <node id="&quot;NORMALIZATION PROPERTY&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Normalization Property is a property that underlies many properties of limited capacity processing in the brain, such as visual perception and cognition."</data>
      <data key="d2">8202e13f45a323970b361921f923c605</data>
    </node>
    <node id="&quot;WORKING MEMORY&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Working Memory is a limited capacity system in the brain that holds and manipulates information for immediate use in cognitive tasks."
"Working Memory refers to the cognitive system that temporarily stores and manipulates information needed for immediate use."
"Working Memory is a cognitive system that temporarily stores and manipulates information."
"Working Memory is a cognitive system that temporarily stores and manipulates information, such as items in a sequence, for processing and recall."
"Working Memory is a cognitive system that temporarily stores and manipulates information, with a limited capacity and activity redistribution when new items are stored."
"Working Memory is a model developed by Grossberg (1978a, 1978b) that explains the storage and retrieval of items in short-term memory, considering factors such as activity levels and noise."</data>
      <data key="d2">1976b19f768a8fdf37207b680c3b2b40,3d5b88f7f81ed9e14f07335bbef17020,5c4e24fc9bd10d0bd59a84d56f960cf9,8202e13f45a323970b361921f923c605,a9285aaa34de96a8fa62903437d2f3c4,b69b23b14e0feccb488ba5412db0824c</data>
    </node>
    <node id="&quot;SYSTEM&quot;">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">8202e13f45a323970b361921f923c605</data>
    </node>
    <node id="&quot;LIMITED CAPACITY PROCESSING&quot;">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">8202e13f45a323970b361921f923c605</data>
    </node>
    <node id="&quot;SHUNTING NETWORK&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"The Shunting Network is a model used to describe the activity of neurons, with properties such as Weber law processing, adaptation level processing, and edge and spatial frequency processing."</data>
      <data key="d2">f290960776c5ec561653e90d2ac6751b</data>
    </node>
    <node id="&quot;NEUROPHYSIOLOGY&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Neurophysiology is the scientific discipline that studies the electrical and chemical properties of neurons and their role in information processing."</data>
      <data key="d2">f290960776c5ec561653e90d2ac6751b</data>
    </node>
    <node id="&quot;WERBLIN&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Werblin is a researcher who has studied the retina of the mudpuppy Necturus, finding a shift property similar to that described in the shunting network equations."</data>
      <data key="d2">f290960776c5ec561653e90d2ac6751b</data>
    </node>
    <node id="&quot;RETINA&quot;">
      <data key="d0">"GEO"</data>
      <data key="d1">"The Retina is a part of the eye that contains photoreceptor cells, which are sensitive to light and transmit visual information to the brain."</data>
      <data key="d2">f290960776c5ec561653e90d2ac6751b</data>
    </node>
    <node id="&quot;MUDPUPPY NECTURUS&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"The Mudpuppy Necturus is an aquatic animal whose retina has been studied for its shift property in response to off-surround input."</data>
      <data key="d2">f290960776c5ec561653e90d2ac6751b</data>
    </node>
    <node id="&quot;HODGKIN AND HUXLEY&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Hodgkin and Huxley are a research team mentioned in the text, known for their work on the membrane equation in neurophysiology."
"Hodgkin and Huxley are researchers who proposed a model of signal propagation in axons."</data>
      <data key="d2">a94f07c842345c77af089558b0786bfe,f2468cda326d1ca11c98f2fbde186400</data>
    </node>
    <node id="&quot;SHUNTING NETWORK EQUATIONS&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Shunting Network Equations are a mathematical model mentioned in the text, used to generate various properties such as Weber law processing and edge and spatial frequency processing."</data>
      <data key="d2">f2468cda326d1ca11c98f2fbde186400</data>
    </node>
    <node id="&quot;MEMBRANE EQUATION&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"The Membrane Equation is a mathematical model mentioned in the text, which describes the voltage of a cell and is based on the work of Hodgkin and Huxley."
"The Membrane Equation is a mathematical model that describes the voltage of a cell based on various conductances and saturation voltages."</data>
      <data key="d2">768cec2f00889d1e375cb4955c58ad60,f2468cda326d1ca11c98f2fbde186400</data>
    </node>
    <node id="&quot;SODIUM CHANNEL&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Sodium Channel is a type of ion channel that contributes to the membrane equation, representing the excitatory saturation voltage."</data>
      <data key="d2">768cec2f00889d1e375cb4955c58ad60</data>
    </node>
    <node id="&quot;POTASSIUM CHANNEL&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Potassium Channel is a type of ion channel that contributes to the membrane equation, representing the inhibitory saturation voltage."</data>
      <data key="d2">768cec2f00889d1e375cb4955c58ad60</data>
    </node>
    <node id="&quot;ION CHANNEL&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Ion Channel is a general term for a type of protein that allows specific ions to pass through a membrane, such as Sodium Channel and Potassium Channel."</data>
      <data key="d2">768cec2f00889d1e375cb4955c58ad60</data>
    </node>
    <node id="&quot;(20)&quot;">
      <data key="d0">"EVENT"</data>
      <data key="d1">"(20) is an event mentioned in the text, possibly a reference to a specific process or condition."</data>
      <data key="d2">91f030f6c14c673e6d029c9bf1a66515</data>
    </node>
    <node id="&quot;(V^+)&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"(V^+) is a concept mentioned in the text, possibly a reference to a specific voltage or value."</data>
      <data key="d2">91f030f6c14c673e6d029c9bf1a66515</data>
    </node>
    <node id="&quot;(V^-)&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"(V^-) is a concept mentioned in the text, possibly a reference to a specific voltage or value."</data>
      <data key="d2">91f030f6c14c673e6d029c9bf1a66515</data>
    </node>
    <node id="&quot;(V^P)&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"(V^p) is a concept mentioned in the text, possibly a reference to a specific voltage or value."</data>
      <data key="d2">91f030f6c14c673e6d029c9bf1a66515</data>
    </node>
    <node id="&quot;BRNN&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"bRNN is a concept mentioned in the text, possibly a reference to a Bidirectional Recurrent Neural Network or a specific organization."
"bRNN is an abbreviation used to refer to a bidirectional Recurrent Neural Network, a concept mentioned in the text."</data>
      <data key="d2">3a64c8c26895f111f00a349dd69bb505,91f030f6c14c673e6d029c9bf1a66515</data>
    </node>
    <node id="&quot;RCF&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"RCF is an abbreviation used to refer to a Recurrent Competitive Field, a type of recurrent neural network mentioned in the text."
"RCF stands for Recurrent Cascade of Firing, a type of network that exhibits shunting dynamics."
"RCF is a type of network mentioned in the text, often used in the context of competitive dynamical systems."
"RCF stands for Recurrent Competitive Filter, which is a mechanism used in the Sparse Stable Category Learning Theorem to allow multiple Instars to compete with each other."</data>
      <data key="d2">2cbd29d6f0019f0c85bee43779ae8f4d,3a64c8c26895f111f00a349dd69bb505,b1636ec22c34ef50b57dec32239c6535,be49e9beb2d7cc985fe9f6517fa0f4fe</data>
    </node>
    <node id="&quot;BUBBLE&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Bubble refers to a self-normalizing process that generates a partial contrast-enhancement, or enhancement above a quenching threshold."</data>
      <data key="d2">7ba0dfde8cc54bb1dcf66b46fcdd88f8</data>
    </node>
    <node id="&quot;RECURRENT NONLINEAR DYNAMICAL SYSTEMS&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Recurrent Nonlinear Dynamical Systems are systems that exhibit cooperative-competitive behavior and are applicable to various fields."</data>
      <data key="d2">7ba0dfde8cc54bb1dcf66b46fcdd88f8</data>
    </node>
    <node id="&quot;INPUTS I_I AND J_I&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Inputs I_i and J_i are mentioned in the text as variables that are set to zero during the STM storage process."</data>
      <data key="d2">b4f6256f3430f1aa72ca8092809ebba1</data>
    </node>
    <node id="&quot;FUNCTION F(W)&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Function f(w) is mentioned in the text as a function used in the equations, with a specific property when it is linear."</data>
      <data key="d2">b4f6256f3430f1aa72ca8092809ebba1</data>
    </node>
    <node id="&quot;FUNCTION H(W)&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Function h(w) is mentioned in the text as a function that exhibits a 'hill' of activity under certain conditions."</data>
      <data key="d2">b4f6256f3430f1aa72ca8092809ebba1</data>
    </node>
    <node id="&quot;EQUATIONS (21) AND (22)&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Equations (21) and (22) are mentioned in the text as mathematical representations used in the analysis."</data>
      <data key="d2">b4f6256f3430f1aa72ca8092809ebba1</data>
    </node>
    <node id="&quot;A&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"A is a variable or parameter mentioned in the text, but no specific information about its identity is provided."</data>
      <data key="d2">8da881a4f375e8a524fd0bf46ae2279e</data>
    </node>
    <node id="&quot;B&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"B is a variable or parameter mentioned in the text, but no specific information about its identity is provided."</data>
      <data key="d2">8da881a4f375e8a524fd0bf46ae2279e</data>
    </node>
    <node id="&quot;C&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"C is a variable or parameter mentioned in the text, but no specific information about its identity is provided."</data>
      <data key="d2">8da881a4f375e8a524fd0bf46ae2279e</data>
    </node>
    <node id="&quot;D&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"D is a variable or parameter mentioned in the text, but no specific information about its identity is provided."</data>
      <data key="d2">8da881a4f375e8a524fd0bf46ae2279e</data>
    </node>
    <node id="&quot;W&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"w is a variable or parameter mentioned in the text, but no specific information about its identity is provided."</data>
      <data key="d2">8da881a4f375e8a524fd0bf46ae2279e</data>
    </node>
    <node id="&quot;X(T)&quot;">
      <data key="d0">"EVENT"</data>
      <data key="d1">"x(t) is a function or signal mentioned in the text, representing a signal over time."</data>
      <data key="d2">8da881a4f375e8a524fd0bf46ae2279e</data>
    </node>
    <node id="&quot;F(X)&quot;">
      <data key="d0">"EVENT"</data>
      <data key="d1">"f(x) is a function mentioned in the text, which takes the variable x as input."</data>
      <data key="d2">8da881a4f375e8a524fd0bf46ae2279e</data>
    </node>
    <node id="&quot;F(W)&quot;">
      <data key="d0">"EVENT"</data>
      <data key="d1">"f(w) is a function mentioned in the text, which takes the variable w as input."</data>
      <data key="d2">8da881a4f375e8a524fd0bf46ae2279e</data>
    </node>
    <node id="&quot;H(W)&quot;">
      <data key="d0">"EVENT"</data>
      <data key="d1">"h(w) is a function mentioned in the text, which is described as the hill function of f(w)."</data>
      <data key="d2">8da881a4f375e8a524fd0bf46ae2279e</data>
    </node>
    <node id="&quot;NETWORK&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"The Network is a system that processes information and makes choices based on input patterns."
"The Network is a system that chooses the population with the initial maximum of activity and inhibits activity in all other populations, behaving like a winner-take-all binary choice machine."</data>
      <data key="d2">0ae1c3b9a183835b90295e9712b9656d,d69baa85c856a1c0b5446a9c9fcd31b8</data>
    </node>
    <node id="&quot;SIGNAL FUNCTION&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"A Signal Function is a mathematical function used to process information in the Network."
"Signal Function is a concept mentioned in the text that must suppress noise and be faster-than-linear at small activities."</data>
      <data key="d2">0ae1c3b9a183835b90295e9712b9656d,35551dc55b5522082b778171ff6d1bf9</data>
    </node>
    <node id="&quot;LINEAR SIGNAL FUNCTION&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"A Linear Signal Function is a type of Signal Function that amplifies noise and eliminates differences in inputs."</data>
      <data key="d2">0ae1c3b9a183835b90295e9712b9656d</data>
    </node>
    <node id="&quot;SLOWER-THAN-LINEAR SIGNAL FUNCTION&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"A Slower-than-Linear Signal Function is a type of Signal Function that also amplifies noise and eliminates differences in inputs."</data>
      <data key="d2">0ae1c3b9a183835b90295e9712b9656d</data>
    </node>
    <node id="&quot;FASTER-THAN-LINEAR SIGNAL FUNCTION&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"A Faster-than-Linear Signal Function is a type of Signal Function that suppresses noise and enhances differences in inputs."</data>
      <data key="d2">0ae1c3b9a183835b90295e9712b9656d</data>
    </node>
    <node id="&quot;HILL FUNCTION&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"A Hill Function is a mathematical function used to analyze the behavior of the Network."</data>
      <data key="d2">0ae1c3b9a183835b90295e9712b9656d</data>
    </node>
    <node id="&quot;NOISE&quot;">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">0ae1c3b9a183835b90295e9712b9656d</data>
    </node>
    <node id="&quot;EQUILIBRIUM POINTS&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Equilibrium Points are the stable states of a system, which in this context are the solutions of an equation that describes the behavior of the Network."</data>
      <data key="d2">d69baa85c856a1c0b5446a9c9fcd31b8</data>
    </node>
    <node id="&quot;SIGNAL&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"The Signal is a concept that is mentioned in the text, but its specific nature is not explicitly described."</data>
      <data key="d2">d69baa85c856a1c0b5446a9c9fcd31b8</data>
    </node>
    <node id="&quot;BIOLOGY&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Biology is mentioned in the text as a field where signal functions are studied and must be bounded."</data>
      <data key="d2">35551dc55b5522082b778171ff6d1bf9</data>
    </node>
    <node id="&quot;NOISE SUPPRESSION&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Noise Suppression is a technique used to reduce unwanted signals, allowing for the storage of specific features or categories."</data>
      <data key="d2">6a47ed5881928d48cdcb74e40867a711</data>
    </node>
    <node id="&quot;SIGMOID SIGNAL FUNCTION&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Sigmoid Signal Function is a mathematical function that combines faster-than-linear and slower-than-linear properties, used for noise suppression and contrast enhancement."</data>
      <data key="d2">6a47ed5881928d48cdcb74e40867a711</data>
    </node>
    <node id="&quot;QUENCHING THRESHOLD&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Quenching Threshold is a value that determines when initial activity is quenched or contrast-enhanced, converting the network into a tunable filter."</data>
      <data key="d2">6a47ed5881928d48cdcb74e40867a711</data>
    </node>
    <node id="&quot;CORTICAL MODELS&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Cortical Models are theoretical representations of the brain's cortex, used for studying shunting dynamics."</data>
      <data key="d2">6a47ed5881928d48cdcb74e40867a711</data>
    </node>
    <node id="&quot;RCFS&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"RCFs refer to recurrent cortical feedbacks, which are studied in the context of cortical models."
"RCFs are a type of model or theory that has been studied to explain various data, such as visual perception and decision-making."

"RCFs are likely a type of specialized process mentioned in the text, potentially related to the Normalization Rule."
"RCFs are specialized units mentioned in the text, but their nature is not explicitly defined."
"RCFs, or Recurrent Connections with Feedback, are a type of network mentioned in the text that help to store inputs in short-term memory and obey the LTM Invariance Principle."
"RCFs are a type of network model mentioned in the text, which behaves like an Item-and-Order working memory model under certain conditions."</data>
      <data key="d2">1976b19f768a8fdf37207b680c3b2b40,4364aa6091e1966365fa889b34f5cf90,53f5bc3f4c71310c593a23aef01d1633,6a47ed5881928d48cdcb74e40867a711,8ee5dee5c6f3e89d8d8c20e3fe957583,c38beddeac1d3cac8282ad59bc835788,dcd38cdc6195b2bbf41d936af0bf1f5f</data>
    </node>
    <node id="&quot;QT&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"QT is a component of a model or theory that converts a network into a tunable filter."</data>
      <data key="d2">8ee5dee5c6f3e89d8d8c20e3fe957583</data>
    </node>
    <node id="&quot;USHER AND MCCLELLAND&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Usher and McClelland are authors who have modeled probabilistic decision-making using an Additive Model."</data>
      <data key="d2">8ee5dee5c6f3e89d8d8c20e3fe957583</data>
    </node>
    <node id="&quot;DOUGLAS ET AL.&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Douglas et al. are authors who have applied shunting properties to simulate data about the properties of cortical circuits that subserve visual perception."
"Douglas et al. are authors who have applied shunting properties to simulate data about the properties of the cortical circuits that subserve visual perception."</data>
      <data key="d2">2cbd29d6f0019f0c85bee43779ae8f4d,8ee5dee5c6f3e89d8d8c20e3fe957583</data>
    </node>
    <node id="&quot;GROSSBERG AND MINGOLLA&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Grossberg and Mingolla are authors who have used shunting properties to simulate data about cortical circuits that subserve visual perception."
"Grossberg and Mingolla are authors who have applied shunting properties in their research."</data>
      <data key="d2">2cbd29d6f0019f0c85bee43779ae8f4d,8ee5dee5c6f3e89d8d8c20e3fe957583</data>
    </node>
    <node id="&quot;GROSSBERG AND TODOROVIC&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Grossberg and Todorovic are authors who have used shunting properties to simulate data about cortical circuits that subserve visual perception."
"Grossberg and Todorovic are authors who have applied shunting properties in their research."</data>
      <data key="d2">2cbd29d6f0019f0c85bee43779ae8f4d,8ee5dee5c6f3e89d8d8c20e3fe957583</data>
    </node>
    <node id="&quot;HEEGER&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Heeger is an author who has applied shunting properties to simulate data about cortical circuits that subserve visual perception."
"Heeger is an author who has applied shunting properties in their research."</data>
      <data key="d2">2cbd29d6f0019f0c85bee43779ae8f4d,8ee5dee5c6f3e89d8d8c20e3fe957583</data>
    </node>
    <node id="&quot;CISEK&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Cisek is an author who has applied shunting properties to simulate data about the selection of commands for arm movement control."</data>
      <data key="d2">8ee5dee5c6f3e89d8d8c20e3fe957583</data>
    </node>
    <node id="&quot;GROSSBERG AND PILLY&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Grossberg and Pilly are authors who have applied shunting properties to simulate data about the control of eye movements in response to probabilistically defined visual motion signals."</data>
      <data key="d2">8ee5dee5c6f3e89d8d8c20e3fe957583</data>
    </node>
    <node id="&quot;COMPETITIVE LEARNING (CL)&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Competitive Learning (CL) is a model developed by Grossberg and others, which utilizes shunting dynamics."</data>
      <data key="d2">2cbd29d6f0019f0c85bee43779ae8f4d</data>
    </node>
    <node id="&quot;ADAPTIVE RESONANCE THEORY (ART)&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Adaptive Resonance Theory (ART) is a model developed by Grossberg, which does not utilize shunting dynamics."</data>
      <data key="d2">2cbd29d6f0019f0c85bee43779ae8f4d</data>
    </node>
    <node id="&quot;MCLAUGHLIN ET AL.&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"McLaughlin et al. are authors who have applied shunting properties in their research."</data>
      <data key="d2">2cbd29d6f0019f0c85bee43779ae8f4d</data>
    </node>
    <node id="&quot;VON DER MALSBURG&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"von der Malsburg is an author who has developed a version of the CL model that does not utilize shunting dynamics."
"von der Malsburg is a person mentioned in the text, likely a researcher or a scientist."</data>
      <data key="d2">2cbd29d6f0019f0c85bee43779ae8f4d,eb6c9a7d24cc59ff93d554093a4360a4</data>
    </node>
    <node id="&quot;PALMA ET AL.&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Palma et al. are authors who have shown that an RCF with spiking neurons can replicate key properties of the Grossberg (1973) theorems for rate-based neurons."</data>
      <data key="d2">2cbd29d6f0019f0c85bee43779ae8f4d</data>
    </node>
    <node id="&quot;COMPETITIVE DYNAMICAL SYSTEMS&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Competitive Dynamical Systems is a concept mentioned in the text, defined by a system of differential equations with competitive interactions between populations."</data>
      <data key="d2">b1636ec22c34ef50b57dec32239c6535</data>
    </node>
    <node id="&quot;MAY AND LEONARD MODEL&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"The May and Leonard Model is a mathematical model developed by May and Leonard to study the voting paradox, which is an example of a competitive system."</data>
      <data key="d2">3334f6dcd53b71cf3ceb7648ead24d5a</data>
    </node>
    <node id="&quot;COMPETITIVE SYSTEM&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Competitive System refers to a system in which entities compete for resources or advantages, leading to dynamic changes in the system."</data>
      <data key="d2">3334f6dcd53b71cf3ceb7648ead24d5a</data>
    </node>
    <node id="&quot;VOTING PARADOX&quot;">
      <data key="d0">"EVENT"</data>
      <data key="d1">"The Voting Paradox is a phenomenon in which the outcome of a vote can be influenced by the voting strategy of a minority group, leading to counterintuitive results."
"The Voting Paradox is a concept introduced by Grossberg in 1975, which is studied using a method of bRNNs."</data>
      <data key="d2">0af3b52f2586c4e957aee493160223ba,3334f6dcd53b71cf3ceb7648ead24d5a</data>
    </node>
    <node id="&quot;LIAPUNOV FUNCTIONAL&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"The Liapunov Functional is a mathematical tool used to analyze the behavior of systems, as introduced by Grossberg."</data>
      <data key="d2">0af3b52f2586c4e957aee493160223ba</data>
    </node>
    <node id="&quot;SOCIAL CHAOS&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Social Chaos is a problem that arises when arbitrarily many individuals, each obeying unique and personal laws, interact with each other, leading to the question of how to achieve global order or consensus."</data>
      <data key="d2">0af3b52f2586c4e957aee493160223ba</data>
    </node>
    <node id="&quot;ALLIGOOD ET AL.&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Alligood et al. is a group of researchers mentioned in the text, focusing on the question of how simple a system can be to generate chaotic behavior."</data>
      <data key="d2">597668e07c7554bd2d0cb29399285a39</data>
    </node>
    <node id="&quot;SYSTEM (21)&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"System (21) is a specific type of system mentioned in the text that generates globally-consistent decision-making."
"System (21) is a special case of a competitive network with a broad inhibitory surround, which is a part of the Adaptation Level Systems."</data>
      <data key="d2">597668e07c7554bd2d0cb29399285a39,edd10f4a8bda41294ef582dc7f048ad5</data>
    </node>
    <node id="&quot;ADAPTATION LEVEL SYSTEMS&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Adaptation Level Systems is a class of systems that includes a special case called System (21), characterized by globally-consistent decision-making and a broad inhibitory surround."</data>
      <data key="d2">edd10f4a8bda41294ef582dc7f048ad5</data>
    </node>
    <node id="&quot;STATE-DEPENDENT AMPLIFICATION FUNCTION&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"State-dependent Amplification Function is a mathematical function used in the equations defining the behavior of Adaptation Level Systems."</data>
      <data key="d2">edd10f4a8bda41294ef582dc7f048ad5</data>
    </node>
    <node id="&quot;SELF-SIGNAL FUNCTION&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Self-signal Function is a mathematical function used in the equations defining the behavior of Adaptation Level Systems."</data>
      <data key="d2">edd10f4a8bda41294ef582dc7f048ad5</data>
    </node>
    <node id="&quot;STATE-DEPENDENT ADAPTATION LEVEL&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"State-dependent Adaptation Level is a mathematical function used in the equations defining the behavior of Adaptation Level Systems."</data>
      <data key="d2">edd10f4a8bda41294ef582dc7f048ad5</data>
    </node>
    <node id="&quot;THEOREM&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"The Theorem is a mathematical result that proves the stability of a price in a competitive market with an arbitrary number of competing firms."
"The Theorem is a mathematical result that applies to the Cohen-Grossberg Model, proving its stability and the balancing of each firm's books."</data>
      <data key="d2">0c9db6cd87deaca2e432c260d775349c,0dd75f3ca11854714bdbfc8a96ccf256</data>
    </node>
    <node id="&quot;COMPETITIVE MARKET&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Competitive Market is a system where multiple firms operate, each choosing a production and savings strategy to maximize net profit based on a market price."</data>
      <data key="d2">0c9db6cd87deaca2e432c260d775349c</data>
    </node>
    <node id="&quot;FIRMS&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Firms are the individual entities within the Competitive Market that make decisions based on market price and their own production and savings strategies."</data>
      <data key="d2">0c9db6cd87deaca2e432c260d775349c</data>
    </node>
    <node id="&quot;COHEN&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Cohen is a contributor to the Cohen-Grossberg Model and the Liapunov Function, with a focus on proving global approach to equilibria."</data>
      <data key="d2">0dd75f3ca11854714bdbfc8a96ccf256</data>
    </node>
    <node id="&quot;BRAIN-STATE-IN-A-BOX MODEL&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"The Brain-State-in-a-Box Model is a system mentioned in the text, which is included in the Cohen-Grossberg Model systems."</data>
      <data key="d2">0dd75f3ca11854714bdbfc8a96ccf256</data>
    </node>
    <node id="&quot;ANDERSON ET AL.&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Anderson et al. are mentioned in the text as contributors to the Brain-State-in-a-Box Model, which is included in the Cohen-Grossberg Model systems."</data>
      <data key="d2">0dd75f3ca11854714bdbfc8a96ccf256</data>
    </node>
    <node id="&quot;COHEN-GROSSBERG SYSTEMS&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Cohen-Grossberg Systems are a class of competitive systems developed by Cohen and Grossberg, which generate jump trees and are the subject of ongoing research."
"Cohen-Grossberg Systems are mathematical models developed by Cohen and Grossberg."</data>
      <data key="d2">4a78ff105fdd9a4b0d01ccf1e5816c74,4b48be5db14c2e681ef8f4ee7de4b847</data>
    </node>
    <node id="&quot;GLOBAL EQUILIBRIUM&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Global Equilibrium is a theoretical concept that Cohen and Grossberg attempted to prove for their systems, which would have significant implications for the study of competitive systems."
"Global Equilibrium is a concept that Cohen and Grossberg attempted to prove by showing that all Cohen-Grossberg systems generate jump trees, and thus no jump cycles."</data>
      <data key="d2">4a78ff105fdd9a4b0d01ccf1e5816c74,4b48be5db14c2e681ef8f4ee7de4b847</data>
    </node>
    <node id="&quot;JUMP TREES&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Jump Trees are a feature of Cohen-Grossberg Systems, which are hypothesized to not contain jump cycles, aiding in the proof of Global Equilibrium."</data>
      <data key="d2">4b48be5db14c2e681ef8f4ee7de4b847</data>
    </node>
    <node id="&quot;LIAPUNOV METHODS&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Liapunov Methods are a mathematical technique used to analyze the stability of dynamic systems, which Cohen and Grossberg used as inspiration in their research."</data>
      <data key="d2">4b48be5db14c2e681ef8f4ee7de4b847</data>
    </node>
    <node id="&quot;COMPETITIVE SYSTEMS&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Competitive Systems are a broader class of systems that Cohen and Grossberg's research contributes to, focusing on understanding their behavior and properties."</data>
      <data key="d2">4b48be5db14c2e681ef8f4ee7de4b847</data>
    </node>
    <node id="&quot;MASKING FIELD MODEL&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"The Masking Field Model is a specific model developed by Cohen and Grossberg, which has been studied in the context of Global Equilibrium and jump trees."</data>
      <data key="d2">4b48be5db14c2e681ef8f4ee7de4b847</data>
    </node>
    <node id="&quot;COHEN-GROSSBERG LIAPUNOV FUNCTION&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"The Cohen-Grossberg Liapunov Function is a mathematical tool developed by Cohen and Grossberg to prove the existence of global equilibria."</data>
      <data key="d2">4a78ff105fdd9a4b0d01ccf1e5816c74</data>
    </node>
    <node id="&quot;BURTON&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Burton is a researcher who has referred to the Cohen-Grossberg-Hopfield model in their work."</data>
      <data key="d2">98173c1c0fcd64ceb914e0dd6b366b30</data>
    </node>
    <node id="&quot;BURWICK&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Burwick is a researcher who has referred to the Cohen-Grossberg-Hopfield model in their work."</data>
      <data key="d2">98173c1c0fcd64ceb914e0dd6b366b30</data>
    </node>
    <node id="&quot;GUO ET AL.&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Guo et al. is a group of researchers who have referred to the Cohen-Grossberg-Hopfield model in their work."</data>
      <data key="d2">98173c1c0fcd64ceb914e0dd6b366b30</data>
    </node>
    <node id="&quot;HOPFIELD NETWORK&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"The Hopfield Network is a neural network model published in multiple articles since the 1960s, often misattributed to other investigators."
"Hopfield Network is a type of recurrent neural network developed by John Hopfield in 1982, which was also based on the work of Shun&#8217;ichi Amari."
"The Hopfield network is a type of neural network invented by John Hopfield in 1982."
"Hopfield Network is a type of recurrent neural network (RNN) that requires stationary inputs and guarantees convergence, but it is not a general RNN."
"Hopfield Network is a type of RNN with equally sized connections across layers, used for content-addressable memory and pattern recognition."</data>
      <data key="d2">643e65a5f4132289cfd1d5b954043642,8b12ccb4afc119b3357ceff10e04ce9f,a8c0edd2cdddb7d6d899284063b541f5,b31ca51b419f7270ee5f4910c90ea331,f59839daadfb1f3832bb9f8d201a7126</data>
    </node>
    <node id="&quot;COHEN-GROSSBERG-HOPFIELD MODEL&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"The Cohen-Grossberg-Hopfield Model is a more historically accurate name for the Hopfield Network, used in various articles."</data>
      <data key="d2">643e65a5f4132289cfd1d5b954043642</data>
    </node>
    <node id="&quot;JOHN J. HOPFIELD&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"John J. Hopfield is a researcher who published the Hopfield Network model in multiple articles since the 1960s."</data>
      <data key="d2">643e65a5f4132289cfd1d5b954043642</data>
    </node>
    <node id="&quot;DAVID COHEN&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"David Cohen is a researcher who contributed to the development of the Hopfield Network model, often referred to in the Cohen-Grossberg-Hopfield Model."</data>
      <data key="d2">643e65a5f4132289cfd1d5b954043642</data>
    </node>
    <node id="&quot;MICHAEL I. GROSSBERG&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Michael I. Grossberg is a researcher who contributed to the development of the Hopfield Network model, often referred to in the Cohen-Grossberg-Hopfield Model."</data>
      <data key="d2">643e65a5f4132289cfd1d5b954043642</data>
    </node>
    <node id="&quot;SYNCHRONIZED OSCILLATIONS&quot;">
      <data key="d0">"EVENT"</data>
      <data key="d1">"Synchronized Oscillations is a phenomenon described in the text, where neural networks can persistently oscillate."</data>
      <data key="d2">643e65a5f4132289cfd1d5b954043642</data>
    </node>
    <node id="&quot;EXCITATORY FEEDBACK SIGNALS&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Excitatory Feedback Signals are signals that stimulate other populations in a neural network."</data>
      <data key="d2">53f5bc3f4c71310c593a23aef01d1633</data>
    </node>
    <node id="&quot;INHIBITORY INTERNEURONS&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Inhibitory Interneurons are neurons that produce inhibitory signals, which can slow down the activity of other neurons."</data>
      <data key="d2">53f5bc3f4c71310c593a23aef01d1633</data>
    </node>
    <node id="&quot;SHUNTING NETWORKS&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Shunting Networks are neural networks that use fast-acting inhibitory interneurons to regulate their activity."</data>
      <data key="d2">53f5bc3f4c71310c593a23aef01d1633</data>
    </node>
    <node id="&quot;HABITUATIVE GATES&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Habituative Gates are mechanisms that multiply recurrent signals in a neural network, enhancing their impact."
"Habituative Gates are mentioned in the text as a mechanism that multiplies recurrent signals."</data>
      <data key="d2">53f5bc3f4c71310c593a23aef01d1633,9b30fc06ca06f49c2faa238da7eddc6f</data>
    </node>
    <node id="&quot;BRNNS&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"bRNNs refer to Biologically Realistic Neural Networks, which are neural networks that are modeled after the structure and function of the brain."
"bRNNs stand for Biologically-Inspired Recurrent Neural Networks, which are embodied in architectures with highly differentiated anatomical circuits, as mentioned in the text."</data>
      <data key="d2">53f5bc3f4c71310c593a23aef01d1633,9b30fc06ca06f49c2faa238da7eddc6f</data>
    </node>
    <node id="&quot;SLOW INHIBITORY INTERNEURONS&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Slow Inhibitory Interneurons are a type of neuron that multiply recurrent signals, as mentioned in the text."</data>
      <data key="d2">9b30fc06ca06f49c2faa238da7eddc6f</data>
    </node>
    <node id="&quot;RNNS&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"RNNs stand for Recurrent Neural Networks, which are characterized by their interaction terms, as mentioned in the text."
"RNNs are a type of artificial neural network designed to process sequential or time-series data, with key features including sequential data handling and shared parameters."
"RNNs are Recurrent Neural Networks, a type of artificial neural network used for sequential data processing."
"RNNs are a type of technology used for training and processing time series data."
"RNNs are a type of neural network mentioned in the text, used for information computation."
"RNNs are a type of neural network that operate on the linear progression of time, combining the previous time step and a hidden representation into the representation for the current time step."

"RNNs are a type of neural network that have proven successful in areas such as language processing, but were once known for their slow computation and error-prone nature."</data>
      <data key="d2">001240f9b2caf047ee61a89e03f7b309,418f92b0dd08e03a20637ffec8193bfc,4b89d9404fd683ecd03d5846ee2d86ce,797480b3d8c00dbb7f02fccb2ab8256a,7ede01f521333d9e39fc34a245103242,9b30fc06ca06f49c2faa238da7eddc6f,b32958d42199d47252887dc7be40ab5a,eafe89ad19a57846f953a1dfcf8571f8</data>
    </node>
    <node id="&quot;CEREBRAL CORTEX&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"The Cerebral Cortex is mentioned in the text as a component of the brain that works with bRNNs to perform various functions."</data>
      <data key="d2">9b30fc06ca06f49c2faa238da7eddc6f</data>
    </node>
    <node id="&quot;LAMINAR COMPUTING&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Laminar Computing is a computational paradigm mentioned in the text, which classifies how different behavioral functions may be realized by architectures that are all variations on a shared laminar design."</data>
      <data key="d2">9b30fc06ca06f49c2faa238da7eddc6f</data>
    </node>
    <node id="&quot;LAMINART FAMILY&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"The LAMINART Family is a group of models mentioned in the text that illustrate the computational paradigm of Laminar Computing and are used to see, among other things."
"LAMINART Family is a model that explains how the visual cortex interacts to see, focusing on areas V1, V2, and V4."</data>
      <data key="d2">6648b18760b8b182e1097ad15c4df685,9b30fc06ca06f49c2faa238da7eddc6f</data>
    </node>
    <node id="&quot;LIST&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"The LIST is mentioned in the text as an organization or group that is not further described in the provided text."</data>
      <data key="d2">9b30fc06ca06f49c2faa238da7eddc6f</data>
    </node>
    <node id="&quot;CARPENTER&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Carpenter is mentioned in the text as a co-author in a reference related to the recurrent signals in the neural network."
"Carpenter is a person mentioned in the text who has discussed the problem of catastrophic forgetting in relation to learning new facts."</data>
      <data key="d2">554e8565591507441cecaa652cb926db,9b30fc06ca06f49c2faa238da7eddc6f</data>
    </node>
    <node id="&quot;CAO&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Cao is mentioned in the text as a co-author in a reference related to the visual cortex and its interaction."
"Cao is a researcher mentioned in the context of the LAMINART Family model."</data>
      <data key="d2">6648b18760b8b182e1097ad15c4df685,9b30fc06ca06f49c2faa238da7eddc6f</data>
    </node>
    <node id="&quot;RAIZADA&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Raizada is mentioned in the text as a co-author in a reference related to the visual cortex and its interaction."
"Raizada is a researcher mentioned in the context of the LAMINART Family model."</data>
      <data key="d2">6648b18760b8b182e1097ad15c4df685,9b30fc06ca06f49c2faa238da7eddc6f</data>
    </node>
    <node id="&quot;VERSACE&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Versace is mentioned in the text as a co-author in a reference related to the visual cortex and its interaction."</data>
      <data key="d2">9b30fc06ca06f49c2faa238da7eddc6f</data>
    </node>
    <node id="&quot;RECURRENT SIGNALS&quot;">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">9b30fc06ca06f49c2faa238da7eddc6f</data>
    </node>
    <node id="&quot;NEURAL NETWORK COMPONENTS&quot;">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">9b30fc06ca06f49c2faa238da7eddc6f</data>
    </node>
    <node id="&quot;VISUAL CORTEX INTERACTION&quot;">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">9b30fc06ca06f49c2faa238da7eddc6f</data>
    </node>
    <node id="&quot;LIST PARSE MODEL&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"LIST PARSE Model is a model that explains how prefrontal cortical working memory and list chunk learning interact with volitional processes to generate motor trajectory commands."</data>
      <data key="d2">6648b18760b8b182e1097ad15c4df685</data>
    </node>
    <node id="&quot;PEARSON&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Pearson is a researcher mentioned in the context of the LIST PARSE Model."</data>
      <data key="d2">6648b18760b8b182e1097ad15c4df685</data>
    </node>
    <node id="&quot;CARTWORD MODEL&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"cARTWORD Model is a model that explains contextual interactions during speech perception by the auditory cortex, including backwards effects in time."</data>
      <data key="d2">6648b18760b8b182e1097ad15c4df685</data>
    </node>
    <node id="&quot;KAZEROUNIAN&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Kazerounian is a researcher mentioned in the context of the cARTWORD Model."
"Kazerounian is a co-author of a study that introduces the TELOS Model and its components."</data>
      <data key="d2">6648b18760b8b182e1097ad15c4df685,75495c1fc835d41adf5afcb01e8e520a</data>
    </node>
    <node id="&quot;TELOS MODEL&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"TELOS Model is a model that explains learning and choice of saccadic eye movement commands by interactions between prefrontal cortex, frontal eye fields, posterior parietal cortex, and anterior and posterior inferotemporal cortex, as well as basal ganglia circuits."
"The TELOS Model is a model of learning and choice of saccadic eye movement commands, involving interactions between various brain regions."</data>
      <data key="d2">6648b18760b8b182e1097ad15c4df685,75495c1fc835d41adf5afcb01e8e520a</data>
    </node>
    <node id="&quot;PFC&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"PFC is a part of the brain mentioned in the context of the TELOS Model."</data>
      <data key="d2">6648b18760b8b182e1097ad15c4df685</data>
    </node>
    <node id="&quot;FEF&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"FEF is a part of the brain mentioned in the context of the TELOS Model."</data>
      <data key="d2">6648b18760b8b182e1097ad15c4df685</data>
    </node>
    <node id="&quot;PPC&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"PPC is a part of the brain mentioned in the context of the TELOS Model."</data>
      <data key="d2">6648b18760b8b182e1097ad15c4df685</data>
    </node>
    <node id="&quot;ITA&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"ITa is a part of the brain mentioned in the context of the TELOS Model."</data>
      <data key="d2">6648b18760b8b182e1097ad15c4df685</data>
    </node>
    <node id="&quot;ITP&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"ITp is a part of the brain mentioned in the context of the TELOS Model."</data>
      <data key="d2">6648b18760b8b182e1097ad15c4df685</data>
    </node>
    <node id="&quot;BG&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"BG is a part of the brain mentioned in the context of the TELOS Model."</data>
      <data key="d2">6648b18760b8b182e1097ad15c4df685</data>
    </node>
    <node id="&quot;LISTELOS MODEL&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"The lisTELOS Model is a model of learning and choice of sequences of saccadic eye movements, involving an Item-Order-Rank spatial working memory in the prefrontal cortex and interactions with other brain regions."</data>
      <data key="d2">75495c1fc835d41adf5afcb01e8e520a</data>
    </node>
    <node id="&quot;PREFRONTAL CORTEX&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"The Prefrontal Cortex is a brain region involved in both the TELOS and lisTELOS Models, playing a role in learning and choice of eye movement commands."</data>
      <data key="d2">75495c1fc835d41adf5afcb01e8e520a</data>
    </node>
    <node id="&quot;FRONTAL EYE FIELDS&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"The Frontal Eye Fields are a brain region involved in both the TELOS and lisTELOS Models, playing a role in the generation of eye movement commands."</data>
      <data key="d2">75495c1fc835d41adf5afcb01e8e520a</data>
    </node>
    <node id="&quot;POSTERIOR PARIETAL CORTEX (PPC)&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"PPC is a region of the brain that interacts with other regions to carry out specific operations."
"Posterior Parietal Cortex (PPC) is a region of the brain involved in spatial orientation, attention, and visual perception."</data>
      <data key="d2">89a24f37cf198d043ccd6b6b795dc232,db27e91f327c97c16df11a500cdeab4d</data>
    </node>
    <node id="&quot;FRONTAL EYE FIELDS (FEF)&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"FEF is a region of the brain that interacts with other regions to carry out specific operations."</data>
      <data key="d2">89a24f37cf198d043ccd6b6b795dc232</data>
    </node>
    <node id="&quot;BASAL GANGLIA (BG)&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"BG is a region of the brain that interacts with other regions to carry out specific operations."</data>
      <data key="d2">89a24f37cf198d043ccd6b6b795dc232</data>
    </node>
    <node id="&quot;SUPERIOR COLLICULUS (SC)&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"SC is a region of the brain that interacts with other regions to carry out specific operations."
"Superior Colliculus (SC) is a region of the brainstem involved in visual processing and motor control."</data>
      <data key="d2">89a24f37cf198d043ccd6b6b795dc232,db27e91f327c97c16df11a500cdeab4d</data>
    </node>
    <node id="&quot;MOTIVATOR MODEL&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"MOTIVATOR Model is a model that focuses on valued goals and blocks learning of irrelevant events during reinforcement learning and motivated attention."
"MOTIVATOR Model is a brain mechanism model that emerged from the ideas and generalizations of the Cognitive-Emotional-Motor (CogEM) Theory."</data>
      <data key="d2">89a24f37cf198d043ccd6b6b795dc232,f373521b781482587f80fffc5623a1f9</data>
    </node>
    <node id="&quot;INFEROTEMPORAL (IT) CORTEX&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"IT Cortex is a region of the brain that interacts with other regions in cognitive-emotional interactions."</data>
      <data key="d2">89a24f37cf198d043ccd6b6b795dc232</data>
    </node>
    <node id="&quot;RHINAL (RHIN) CORTEX&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"RHIN Cortex is a region of the brain that interacts with other regions in cognitive-emotional interactions."</data>
      <data key="d2">89a24f37cf198d043ccd6b6b795dc232</data>
    </node>
    <node id="&quot;LATERAL ORBITOFRONTAL CORTEX (ORBL)&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"ORBl is a region of the brain that interacts with other regions in cognitive-emotional interactions."</data>
      <data key="d2">89a24f37cf198d043ccd6b6b795dc232</data>
    </node>
    <node id="&quot;MEDIAL ORBITOFRONTAL CORTEX (ORBM)&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"ORBm is a region of the brain that interacts with other regions in cognitive-emotional interactions."</data>
      <data key="d2">89a24f37cf198d043ccd6b6b795dc232</data>
    </node>
    <node id="&quot;AMYGDALA (AMYGD)&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"AMYGD is a region of the brain that interacts with other regions in cognitive-emotional interactions."</data>
      <data key="d2">89a24f37cf198d043ccd6b6b795dc232</data>
    </node>
    <node id="&quot;LATERAL HYPOTHALAMUS (LH)&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"LH is a region of the brain that interacts with other regions in cognitive-emotional interactions."</data>
      <data key="d2">89a24f37cf198d043ccd6b6b795dc232</data>
    </node>
    <node id="&quot;BASAL GANGLIA&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Basal Ganglia is a region of the brain that interacts with other regions in cognitive-emotional interactions."
"Basal Ganglia is a group of nuclei in the brain involved in movement, emotion, and motivation."
"Basal ganglia are a group of subcortical structures that modulate song performance in songbirds."
"Basal Ganglia is a brain region that modulates song performance in songbirds, indicating its role in flexible performance."</data>
      <data key="d2">44ddf121af4b66da2bfd6b2ac0637a23,7aeda101aa8aba76f319932f0bd568f7,89a24f37cf198d043ccd6b6b795dc232,db27e91f327c97c16df11a500cdeab4d</data>
    </node>
    <node id="&quot;ARTSCAN MODEL&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"ARTSCAN Model is a model that focuses on view-invariant object learning and visual search during unconstrained saccadic eye movements."</data>
      <data key="d2">89a24f37cf198d043ccd6b6b795dc232</data>
    </node>
    <node id="&quot;VISUAL CORTEX V1&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Visual Cortex V1 is a region of the brain that interacts with other regions in the ARTSCAN Model."</data>
      <data key="d2">89a24f37cf198d043ccd6b6b795dc232</data>
    </node>
    <node id="&quot;VISUAL CORTEX V2&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Visual Cortex V2 is a region of the brain that interacts with other regions in the ARTSCAN Model."</data>
      <data key="d2">89a24f37cf198d043ccd6b6b795dc232</data>
    </node>
    <node id="&quot;VISUAL CORTEX V3A&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Visual Cortex V3A is a region of the brain that interacts with other regions in the ARTSCAN Model."</data>
      <data key="d2">89a24f37cf198d043ccd6b6b795dc232</data>
    </node>
    <node id="&quot;VISUAL CORTEX V4&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Visual Cortex V4 is a region of the brain that interacts with other regions in the ARTSCAN Model."</data>
      <data key="d2">89a24f37cf198d043ccd6b6b795dc232</data>
    </node>
    <node id="&quot;PREFRONTAL CORTEX (PFC)&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Prefrontal Cortex (PFC) is a region of the brain that interacts with other regions in the ARTSCAN Model."
"Prefrontal Cortex (PFC) is a region of the brain involved in decision-making, planning, and cognitive control."</data>
      <data key="d2">89a24f37cf198d043ccd6b6b795dc232,db27e91f327c97c16df11a500cdeab4d</data>
    </node>
    <node id="&quot;POSTERIOR PARIETAL CORTEX&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Posterior Parietal Cortex is a region of the brain that interacts with other regions to carry out specific operations."</data>
      <data key="d2">89a24f37cf198d043ccd6b6b795dc232</data>
    </node>
    <node id="&quot;AMYGDALA&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Amygdala is a part of the brain involved in processing emotions and fear responses."</data>
      <data key="d2">db27e91f327c97c16df11a500cdeab4d</data>
    </node>
    <node id="&quot;LATERAL HYPOTHALAMUS&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Lateral Hypothalamus is a part of the brain involved in regulating various bodily functions, including reward and motivation."</data>
      <data key="d2">db27e91f327c97c16df11a500cdeab4d</data>
    </node>
    <node id="&quot;REWARD EXPECTATION FILTER&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Reward Expectation Filter is a mechanism that modulates the reward value of stimuli based on previous experiences."</data>
      <data key="d2">db27e91f327c97c16df11a500cdeab4d</data>
    </node>
    <node id="&quot;ARTSCAN&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"ARTSCAN is a model that simulates view-invariant object learning and visual search during unconstrained saccadic eye movements."</data>
      <data key="d2">db27e91f327c97c16df11a500cdeab4d</data>
    </node>
    <node id="&quot;VISUAL CORTICES V1, V2, V3A, AND V4&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Visual Cortices V1, V2, V3A, and V4 are areas of the brain involved in processing visual information."</data>
      <data key="d2">db27e91f327c97c16df11a500cdeab4d</data>
    </node>
    <node id="&quot;LATERAL INTRAPARIETAL AREA (LIP)&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Lateral Intraparietal Area (LIP) is a region of the brain involved in visual processing and spatial attention."</data>
      <data key="d2">db27e91f327c97c16df11a500cdeab4d</data>
    </node>
    <node id="&quot;POSTERIOR AND ANTERIOR INFEROTEMPORAL CORTEX (PIT, AIT)&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Posterior and Anterior Inferotemporal Cortex (pIT, aIT) are regions of the brain involved in object recognition and visual perception."</data>
      <data key="d2">db27e91f327c97c16df11a500cdeab4d</data>
    </node>
    <node id="&quot;ARTSCENE SEARCH&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"ARTSCENE Search is a model that simulates object and spatial contextual cueing of visual search for desired objects in a scene."</data>
      <data key="d2">db27e91f327c97c16df11a500cdeab4d</data>
    </node>
    <node id="&quot;VENTRAL AND DORSOLATERAL PREFRONTAL CORTEX (VPFC, DLPFC)&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Ventral and Dorsolateral Prefrontal Cortex (VPFC, DLPFC) are regions of the brain involved in decision-making, planning, and cognitive control."</data>
      <data key="d2">db27e91f327c97c16df11a500cdeab4d</data>
    </node>
    <node id="&quot;PERIRHINAL CORTEX (PRC)&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Perirhinal Cortex (PRC) is a region of the brain involved in spatial navigation and memory."</data>
      <data key="d2">db27e91f327c97c16df11a500cdeab4d</data>
    </node>
    <node id="&quot;PARAHIPPOCAMPAL CORTEX (PHC)&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Parahippocampal Cortex (PHC) is a region of the brain involved in spatial navigation and memory."</data>
      <data key="d2">db27e91f327c97c16df11a500cdeab4d</data>
    </node>
    <node id="&quot;GRIDPLACEMAP&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"GridPlaceMap is a model that simulates the formation of a grid cell representation of space."</data>
      <data key="d2">db27e91f327c97c16df11a500cdeab4d</data>
    </node>
    <node id="&quot;VISUAL CORTICES V1, V2, AND V4&quot;">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">db27e91f327c97c16df11a500cdeab4d</data>
    </node>
    <node id="&quot;POSTERIOR AND ANTERIOR INFEROTEMPORAL CORTEX (ITA, ITP)&quot;">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">db27e91f327c97c16df11a500cdeab4d</data>
    </node>
    <node id="&quot;BRAIN REGIONS&quot;">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">db27e91f327c97c16df11a500cdeab4d</data>
    </node>
    <node id="&quot;NEURONAL LEARNING&quot;">
      <data key="d0">"EVENT"</data>
      <data key="d1">"Neuronal Learning is a process described in the text that involves the interaction of STM and LTM."</data>
      <data key="d2">b881b9051ad24c6a16b468803fba51d3</data>
    </node>
    <node id="&quot;MATHEMATICAL THEOREMS&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Mathematical Theorems are mentioned in the text as a foundation for the learning capabilities of the architectures."
"Mathematical Theorems are mentioned as a foundation for the learning capabilities of the Generalized Additive RNNs architecture."</data>
      <data key="d2">5812b5d4bcdfbf80de28dca56a6559b3,b881b9051ad24c6a16b468803fba51d3</data>
    </node>
    <node id="&quot;GENERALIZED ADDITIVE RNNS&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Generalized Additive RNNs is a type of architecture that includes interactions between STM and LTM, allowing it to learn from its environments."</data>
      <data key="d2">5812b5d4bcdfbf80de28dca56a6559b3</data>
    </node>
    <node id="&quot;SPATIAL PATTERN LEARNING&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Spatial Pattern Learning is a concept mentioned in the text, referring to the ability of certain anatomies to learn patterns."
"Spatial Pattern Learning is the process of identifying and learning patterns in spatial data, such as images or signals."</data>
      <data key="d2">5d6b6e0d1a9ace28e21dce2cb0ac78c0,be49e9beb2d7cc985fe9f6517fa0f4fe</data>
    </node>
    <node id="&quot;SIGNAL TRANSMISSION&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Signal Transmission is a concept mentioned in the text, referring to the process of transmitting signals between cells."</data>
      <data key="d2">5d6b6e0d1a9ace28e21dce2cb0ac78c0</data>
    </node>
    <node id="&quot;KATZ&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Katz is a researcher who contributed to the understanding of signal density and its effect on postsynaptic cells."</data>
      <data key="d2">a94f07c842345c77af089558b0786bfe</data>
    </node>
    <node id="&quot;SIGNAL PROPAGATION&quot;">
      <data key="d0">"EVENT"</data>
      <data key="d1">"Signal Propagation refers to the transmission of signals along axons and their effect on postsynaptic cells."</data>
      <data key="d2">a94f07c842345c77af089558b0786bfe</data>
    </node>
    <node id="&quot;AXON&quot;">
      <data key="d0">"BIO"</data>
      <data key="d1">"Axon is a type of nerve cell that transmits signals from the cell body to other cells."</data>
      <data key="d2">a94f07c842345c77af089558b0786bfe</data>
    </node>
    <node id="&quot;SYNAPTIC KNOB&quot;">
      <data key="d0">"BIO"</data>
      <data key="d1">"Synaptic Knob is a structure on the axon where signals interact with postsynaptic cells."</data>
      <data key="d2">a94f07c842345c77af089558b0786bfe</data>
    </node>
    <node id="&quot;IONIC FLUXES&quot;">
      <data key="d0">"BIO"</data>
      <data key="d1">"Ionic Fluxes refer to the movement of ions in response to signals, contributing to signal transmission."</data>
      <data key="d2">a94f07c842345c77af089558b0786bfe</data>
    </node>
    <node id="&quot;CHEMICAL TRANSMITTER&quot;">
      <data key="d0">"BIO"</data>
      <data key="d1">"Chemical Transmitter is a substance released at synaptic knobs to communicate signals to postsynaptic cells."</data>
      <data key="d2">a94f07c842345c77af089558b0786bfe</data>
    </node>
    <node id="&quot;SIGNAL DENSITY&quot;">
      <data key="d0">"BIO"</data>
      <data key="d1">"Signal Density refers to the concentration of signals at synaptic knobs, influencing chemical transmitter release and postsynaptic cell effect."</data>
      <data key="d2">a94f07c842345c77af089558b0786bfe</data>
    </node>
    <node id="&quot;SIGNAL VELOCITY&quot;">
      <data key="d0">"BIO"</data>
      <data key="d1">"Signal Velocity refers to the speed at which signals propagate along axons, which should be proportional to axon length for unbiased learning."
"Signal Velocity refers to the speed at which signals are transmitted through axons."</data>
      <data key="d2">18be9bfe53d3b9c1e15c1c8238674459,a94f07c842345c77af089558b0786bfe</data>
    </node>
    <node id="&quot;AXON LENGTH&quot;">
      <data key="d0">"BIO"</data>
      <data key="d1">"Axon Length refers to the length of a nerve axon, which should be proportional to axon diameter for consistent signal velocity."
"Axon Length refers to the physical length of axons, which can influence signal transmission."</data>
      <data key="d2">18be9bfe53d3b9c1e15c1c8238674459,a94f07c842345c77af089558b0786bfe</data>
    </node>
    <node id="&quot;AXONS&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Axons are part of a neural system, transmitting signals from source cells to target cells."</data>
      <data key="d2">18be9bfe53d3b9c1e15c1c8238674459</data>
    </node>
    <node id="&quot;SOURCE CELLS&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Source Cells are the origin points of signals transmitted through axons."</data>
      <data key="d2">18be9bfe53d3b9c1e15c1c8238674459</data>
    </node>
    <node id="&quot;TARGET CELLS&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Target Cells are the end points of signals transmitted through axons."</data>
      <data key="d2">18be9bfe53d3b9c1e15c1c8238674459</data>
    </node>
    <node id="&quot;AXON DIAMETER&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Axon Diameter refers to the width of axons, which can also impact signal transmission."</data>
      <data key="d2">18be9bfe53d3b9c1e15c1c8238674459</data>
    </node>
    <node id="&quot;GENERALIZED ADDITIVE SYSTEM&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"The Generalized Additive System is a model described in the text, with activities represented by STM traces and adaptive weights represented by LTM traces."</data>
      <data key="d2">8bb0e63353e66a2c60a878028beff5f9</data>
    </node>
    <node id="&quot;SAMPLED CELLS&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Sampled Cells are a component of the Generalized Additive System, representing the cells that are being observed or sampled."</data>
      <data key="d2">8bb0e63353e66a2c60a878028beff5f9</data>
    </node>
    <node id="&quot;SAMPLING CELLS&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Sampling Cells are a component of the Generalized Additive System, representing the cells that are actively sampling the system."</data>
      <data key="d2">8bb0e63353e66a2c60a878028beff5f9</data>
    </node>
    <node id="&quot;SIGNAL FUNCTIONAL&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"The Signal Functional is a component of the Generalized Additive System, representing a spike-based signaling term that is non-negative."</data>
      <data key="d2">8bb0e63353e66a2c60a878028beff5f9</data>
    </node>
    <node id="&quot;SAMPLING FUNCTIONAL&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"The Sampling Functional is a component of the Generalized Additive System, representing a spike-based signaling term that is non-negative and is involved in the learning process."</data>
      <data key="d2">8bb0e63353e66a2c60a878028beff5f9</data>
    </node>
    <node id="&quot;DECAY FUNCTIONAL&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"The Decay Functional is a component of the Generalized Additive System, representing the decay of associative learning and possibly including gated steepest descent learning."</data>
      <data key="d2">8bb0e63353e66a2c60a878028beff5f9</data>
    </node>
    <node id="&quot;UNBIASED SPATIAL PATTERN LEARNING THEOREM&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"The Unbiased Spatial Pattern Learning Theorem proves how unbiased learning may occur in response to correlated stimuli and spatial patterns."
"The Unbiased Spatial Pattern Learning Theorem is a mathematical concept mentioned in the text, which guarantees that the network can learn a spatial pattern."</data>
      <data key="d2">4959d1559344e462a6a7463fd3273659,6e8f1f4e6c7865b14f3b5665aa62e12e</data>
    </node>
    <node id="&quot;CONDITIONED STIMULI (CS)&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Conditioned Stimuli (CS) are signals that are correlated with particular spatial patterns in the context of the Unbiased Spatial Pattern Learning Theorem."</data>
      <data key="d2">4959d1559344e462a6a7463fd3273659</data>
    </node>
    <node id="&quot;UNCONDITIONED STIMULI (US)&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Unconditioned Stimuli (US) are particular spatial patterns that are correlated with Conditioned Stimuli in the context of the Unbiased Spatial Pattern Learning Theorem."</data>
      <data key="d2">4959d1559344e462a6a7463fd3273659</data>
    </node>
    <node id="&quot;PAVLOVIAN CONDITIONING&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Pavlovian Conditioning is a form of associative learning that involves pairing a stimulus with a response to create a conditioned response."</data>
      <data key="d2">c486b91dc15a126174fe546094568aaa</data>
    </node>
    <node id="&quot;CS AND US&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"CS and US are likely abbreviations for Conditioned Stimulus and Unconditioned Stimulus, which are components of Pavlovian Conditioning."</data>
      <data key="d2">c486b91dc15a126174fe546094568aaa</data>
    </node>
    <node id="&quot;GENERALIZED ADDITIVE MODEL&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"The Generalized Additive Model is a statistical framework that allows for the modeling of complex relationships between variables."</data>
      <data key="d2">c486b91dc15a126174fe546094568aaa</data>
    </node>
    <node id="&quot;OUTSTAR LEARNING THEOREM&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"The Outstar Learning Theorem is a specific case of the Generalized Additive Model, which has been mentioned in the text."
"The Outstar Learning Theorem is a learning theory proposed by Stanley Grossberg, which suggests how a series of Outstars can learn an arbitrary spatiotemporal pattern."</data>
      <data key="d2">be49e9beb2d7cc985fe9f6517fa0f4fe,c486b91dc15a126174fe546094568aaa</data>
    </node>
    <node id="&quot;GROSSBERG AND SOMERS&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Grossberg and Somers is a collaboration between researchers Grossberg and Somers, who have published on the topic of resynchronizing activities in networks."</data>
      <data key="d2">c486b91dc15a126174fe546094568aaa</data>
    </node>
    <node id="&quot;GROSSBERG AND GRUNEWALD&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Grossberg and Grunewald is a collaboration between researchers Grossberg and Grunewald, who have published on the topic of resynchronizing activities in networks."</data>
      <data key="d2">c486b91dc15a126174fe546094568aaa</data>
    </node>
    <node id="&quot;YAZDANBAKHSH AND GROSSBERG&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Yazdanbakhsh and Grossberg is a collaboration between researchers Yazdanbakhsh and Grossberg, who have published on the topic of resynchronizing activities in laminar cortical circuits."</data>
      <data key="d2">c486b91dc15a126174fe546094568aaa</data>
    </node>
    <node id="&quot;STANLEY GROSSBERG&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Stanley Grossberg is a researcher known for his contributions to neural networks and learning theories, including the Outstar Learning Theorem and the Sparse Stable Category Learning Theorem."</data>
      <data key="d2">be49e9beb2d7cc985fe9f6517fa0f4fe</data>
    </node>
    <node id="&quot;SPARSE STABLE CATEGORY LEARNING THEOREM&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"The Sparse Stable Category Learning Theorem is another learning theory proposed by Stanley Grossberg, which occurs using the dual network to the Outstar, namely the Instar. This theorem involves multiple Instars competing with each other via a RCF to form a Competitive Learning or Self-Organizing Map network."</data>
      <data key="d2">be49e9beb2d7cc985fe9f6517fa0f4fe</data>
    </node>
    <node id="&quot;INSTAR&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Instar is the dual network to the Outstar, which competes with other Instars to form a Competitive Learning or Self-Organizing Map network."</data>
      <data key="d2">be49e9beb2d7cc985fe9f6517fa0f4fe</data>
    </node>
    <node id="&quot;LEARNING THEORIES&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Learning Theories are theoretical frameworks that explain how systems can learn and adapt to new information or patterns."</data>
      <data key="d2">be49e9beb2d7cc985fe9f6517fa0f4fe</data>
    </node>
    <node id="&quot;COMPETITIVE LEARNING&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Competitive Learning is a type of unsupervised learning in which a network of neurons competes for the right to respond to input patterns."
"Competitive Learning is a type of learning model that involves competition among neurons to respond to input patterns."
"Competitive Learning is a method mentioned in the text, likely a concept or a technique used in research."</data>
      <data key="d2">01e2a32da700813f593038a23a618e55,be49e9beb2d7cc985fe9f6517fa0f4fe,eb6c9a7d24cc59ff93d554093a4360a4</data>
    </node>
    <node id="&quot;SELF-ORGANIZING MAP&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Self-Organizing Map is a type of artificial neural network that learns to represent the structure of input data, typically in a lower-dimensional space."
"Self-Organizing Map is a type of learning model that dynamically organizes input data."</data>
      <data key="d2">01e2a32da700813f593038a23a618e55,be49e9beb2d7cc985fe9f6517fa0f4fe</data>
    </node>
    <node id="&quot;COMPETITIVE LEARNING OR SELF-ORGANIZING MAP NETWORK&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"The Competitive Learning or Self-Organizing Map Network is a type of network mentioned in the text, which is formed by multiple Instars competing via a RCF."</data>
      <data key="d2">644602009dec8474bb5cd4702b391d3e</data>
    </node>
    <node id="&quot;KOSKO&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Kosko is a person mentioned in the text, who has adapted the Cohen-Grossberg Model."
"Kosko is a researcher who adapted the Cohen-Grossberg model and Liapunov function to define a system that combines STM and LTM."
"Kosko is a person who referred to the equation in (39) as the signal Hebb law, although it does not fully obey Hebb's property."</data>
      <data key="d2">01e2a32da700813f593038a23a618e55,32b8b59687b8d1556ec90c99a090653c,644602009dec8474bb5cd4702b391d3e</data>
    </node>
    <node id="&quot;SHORT-TERM MEMORY&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Short-Term Memory, or STM, is a type of memory that retains information for a short period of time."
"Short-Term Memory is a component of Working Memory that holds information for brief periods, typically lasting around 30 seconds."
"Short-Term Memory (STM) is a cognitive system that temporarily stores information for immediate use."</data>
      <data key="d2">01e2a32da700813f593038a23a618e55,3d5b88f7f81ed9e14f07335bbef17020,5c4e24fc9bd10d0bd59a84d56f960cf9</data>
    </node>
    <node id="&quot;LONG-TERM MEMORY&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Long-Term Memory, or LTM, is a type of memory that retains information for a longer period of time."
"Long-Term Memory is a cognitive system that stores information over extended periods, supporting stable learning and the retention of list chunks."</data>
      <data key="d2">01e2a32da700813f593038a23a618e55,1976b19f768a8fdf37207b680c3b2b40</data>
    </node>
    <node id="&quot;PASSIVE DECAY ASSOCIATIVE LAW&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"The Passive Decay Associative Law is a learning law that was introduced in Grossberg's work in the 1960s."</data>
      <data key="d2">01e2a32da700813f593038a23a618e55</data>
    </node>
    <node id="&quot;BAM&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"BAM is a type of model that applies to learning laws, such as the passive decay associative law and the signal Hebb law."
"BAM is an organization mentioned in the text, which was inspired by Adaptive Resonance Theory."</data>
      <data key="d2">32b8b59687b8d1556ec90c99a090653c,554e8565591507441cecaa652cb926db</data>
    </node>
    <node id="&quot;FRENCH&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"French is a person mentioned in the text who has also discussed the problem of catastrophic forgetting in relation to learning new facts."</data>
      <data key="d2">554e8565591507441cecaa652cb926db</data>
    </node>
    <node id="&quot;PAGE&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Page is a person mentioned in the text who has discussed the problem of catastrophic forgetting in relation to learning new facts."</data>
      <data key="d2">554e8565591507441cecaa652cb926db</data>
    </node>
    <node id="&quot;DESIMONE&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Desimone is a person mentioned in the text who has discussed the operation of attention via a form of self-normalizing 'biased competition' in relation to Adaptive Resonance Theory."
"Desimone is a researcher mentioned in the text as having contributed to the concept of self-normalizing biased competition in the context of attention."</data>
      <data key="d2">3d5b88f7f81ed9e14f07335bbef17020,554e8565591507441cecaa652cb926db</data>
    </node>
    <node id="&quot;SCHOLARPEDIA&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Scholarpedia is a peer-reviewed online encyclopedia that provides open access to scholarly articles."</data>
      <data key="d2">3d5b88f7f81ed9e14f07335bbef17020</data>
    </node>
    <node id="&quot;BADDELEY&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Baddeley is a psychologist mentioned in the text as a contributor to the understanding of Working Memory and Short-Term Memory."
"Baddeley is a cognitive psychologist known for his contributions to the understanding of Working Memory."</data>
      <data key="d2">3d5b88f7f81ed9e14f07335bbef17020,5c4e24fc9bd10d0bd59a84d56f960cf9</data>
    </node>
    <node id="&quot;COGNITIVE SCIENTISTS&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Cognitive Scientists are researchers studying the processes of the mind and cognition."</data>
      <data key="d2">5c4e24fc9bd10d0bd59a84d56f960cf9</data>
    </node>
    <node id="&quot;NEUROSCIENTISTS&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Neuroscientists are researchers studying the brain and its functions."</data>
      <data key="d2">5c4e24fc9bd10d0bd59a84d56f960cf9</data>
    </node>
    <node id="&quot;EVENT SEQUENCES&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Event Sequences are sequences of events that are temporarily stored in Working Memory."</data>
      <data key="d2">5c4e24fc9bd10d0bd59a84d56f960cf9</data>
    </node>
    <node id="&quot;LIST CHUNKS&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"List Chunks are unitized plans that group events in Working Memory, allowing for later performance."
"List Chunks are sequences of items that can be learned and recognized as a single unit, enabling efficient storage and recall in working memory."
"List Chunks are learned sequences of events that are sensitive to their context, acting as sampling cells and planning nodes in a Context-Sensitive Self-Organizing Avalanche."
"List Chunks are units of learned sequences that can create context and control subsequent responses in verbal, spatial, and motor learning."</data>
      <data key="d2">2ea6b3379a87077d75e5c45024f4f3e2,5c4e24fc9bd10d0bd59a84d56f960cf9,a9285aaa34de96a8fa62903437d2f3c4,cdd2935776d71ef9fd3a33979af0b9b5</data>
    </node>
    <node id="&quot;ATKINSON AND SHIFFRIN&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Atkinson and Shiffrin are researchers who proposed a binary activation model of working memory, which is contrasted with the Item-and-Order WM model."</data>
      <data key="d2">a9285aaa34de96a8fa62903437d2f3c4</data>
    </node>
    <node id="&quot;ITEM-AND-ORDER MODELS&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Item-and-Order models are a type of model that Grossberg predicted to embody two constraints for stable learning and memory of list chunks."</data>
      <data key="d2">4364aa6091e1966365fa889b34f5cf90</data>
    </node>
    <node id="&quot;LTM INVARIANCE PRINCIPLE&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"The LTM Invariance Principle is a postulate that ensures stable learning and memory of list chunks, allowing new superset list chunks to be learned without distorting existing representations."
"LTM Invariance Principle is a postulate that ensures stable learning and memory of list chunks without catastrophic forgetting of familiar subset list chunks."
"LTM Invariance Principle is a principle mentioned in the text, which suggests that all working memories are specialized versions of the same underlying network design."</data>
      <data key="d2">4364aa6091e1966365fa889b34f5cf90,c38beddeac1d3cac8282ad59bc835788,dcd38cdc6195b2bbf41d936af0bf1f5f</data>
    </node>
    <node id="&quot;RECURRENT CONNECTIONS&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Recurrent Connections are connections in a network that allow for the storage of inputs in short-term memory after the inputs shut off."</data>
      <data key="d2">1976b19f768a8fdf37207b680c3b2b40</data>
    </node>
    <node id="&quot;GROSSBERG AND PEARSON&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Grossberg and Pearson are mentioned as the authors of a model that generalizes Item-and-Order working memories to include rank information, permitting the temporary storage of repeated items in a list."</data>
      <data key="d2">c38beddeac1d3cac8282ad59bc835788</data>
    </node>
    <node id="&quot;ITEM-ORDER-RANK WORKING MEMORIES&quot;">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">c38beddeac1d3cac8282ad59bc835788</data>
    </node>
    <node id="&quot;FRONTAL CORTEX&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Frontal Cortex is a region of the brain involved in various cognitive functions, including working memory."
"Frontal cortex is a brain region that modulates song performance in higher species, such as songbirds."
"Frontal Cortex is a brain region that modulates song performance in songbirds, indicating its role in flexible performance."</data>
      <data key="d2">296fa3812e2c81f685d8cdc403cb03dd,44ddf121af4b66da2bfd6b2ac0637a23,7aeda101aa8aba76f319932f0bd568f7</data>
    </node>
    <node id="&quot;ITEM-AND-ORDER WORKING MEMORY&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Item-and-Order Working Memory is a cognitive model that stores and recalls lists in a specific order, influenced by primacy, recency, and bowed activation gradients."</data>
      <data key="d2">296fa3812e2c81f685d8cdc403cb03dd</data>
    </node>
    <node id="&quot;ITEM-ORDER-RANK WORKING MEMORY&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Item-Order-Rank Working Memory is a variant of Item-and-Order Working Memory that includes positional information, allowing the temporary storage of repeated items in a list."</data>
      <data key="d2">296fa3812e2c81f685d8cdc403cb03dd</data>
    </node>
    <node id="&quot;FREE RECALL&quot;">
      <data key="d0">"EVENT"</data>
      <data key="d1">"Free Recall is a cognitive process where individuals try to recall a once-heard list in any order, typically showing patterns of primacy and recency."</data>
      <data key="d2">296fa3812e2c81f685d8cdc403cb03dd</data>
    </node>
    <node id="&quot;BRADSKI ET AL.&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Bradski et al. is a group of researchers who mathematically proved the patterns of activation in an Item-and-Order working memory."
"Bradski et al. is a group of researchers who defined the STORE model, a family of Item-and-Order RNNs with mathematically provable primacy, recency, and bowed gradient properties."</data>
      <data key="d2">392028b79561bd7471cb68e7c9258b1e,c3257facbf1b0a5da49d6a115f66df87</data>
    </node>
    <node id="&quot;BOARDMAN AND BULLOCK&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Boardman and Bullock are researchers who have developed variants of the Item-and-Order working memory design."</data>
      <data key="d2">c3257facbf1b0a5da49d6a115f66df87</data>
    </node>
    <node id="&quot;HOUGHTON AND HARTLEY&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Houghton and Hartley are researchers who have contributed to the Item-and-Order working memory design."</data>
      <data key="d2">c3257facbf1b0a5da49d6a115f66df87</data>
    </node>
    <node id="&quot;PAGE AND NORRIS&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Page and Norris are researchers who have developed variants of the Item-and-Order working memory design."</data>
      <data key="d2">c3257facbf1b0a5da49d6a115f66df87</data>
    </node>
    <node id="&quot;RHODES ET AL.&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Rhodes et al. are researchers who have developed variants of the Item-and-Order working memory design."</data>
      <data key="d2">c3257facbf1b0a5da49d6a115f66df87</data>
    </node>
    <node id="&quot;HOUGHTON&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Houghton is a researcher who has referred to Item-and-Order models as Competitive Queuing models."</data>
      <data key="d2">c3257facbf1b0a5da49d6a115f66df87</data>
    </node>
    <node id="&quot;FARRELL AND LEWANDOWSKY&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Farrell and Lewandowsky are researchers who have provided experimental support for Item-and-Order working memory properties."</data>
      <data key="d2">c3257facbf1b0a5da49d6a115f66df87</data>
    </node>
    <node id="&quot;AVERBECK ET AL.&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Averbeck et al. are researchers who have reported neurophysiological evidence supporting the primacy gradient in Item-and-Order working memory."
"Averbeck et al. is a research group that has reported neurophysiological evidence of primacy gradients and inhibition of the most active cell in sequential copying movements."</data>
      <data key="d2">1c0f47f0b77faab56cbeba0e1e3e7e70,c3257facbf1b0a5da49d6a115f66df87</data>
    </node>
    <node id="&quot;ITEM-AND-ORDER WM&quot;">
      <data key="d0" />
      <data key="d1">
</data>
      <data key="d2">1c0f47f0b77faab56cbeba0e1e3e7e70,c3257facbf1b0a5da49d6a115f66df87</data>
    </node>
    <node id="&quot;JONES ET AL.&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Jones et al. is a research group that has reported similar performance characteristics to those of verbal WM for a spatial serial recall task."</data>
      <data key="d2">1c0f47f0b77faab56cbeba0e1e3e7e70</data>
    </node>
    <node id="&quot;AGAM ET AL.&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Agam et al. is a research group that has reported psychophysical evidence of Item-and-Order WM properties in humans as they perform sequential copying movements."
"Agam et al. is a research group that reported data consistent with the formation of list chunks, supporting Grossberg's predictions."</data>
      <data key="d2">1c0f47f0b77faab56cbeba0e1e3e7e70,97a9ce754fa34aaf01d6cce57560b247</data>
    </node>
    <node id="&quot;SILVER ET AL.&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Silver et al. is a research group that has used Item-and-Order WMs to simulate neurophysiological data about spatial WMs."</data>
      <data key="d2">1c0f47f0b77faab56cbeba0e1e3e7e70</data>
    </node>
    <node id="&quot;VERBAL WM&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Verbal WM refers to the working memory system that processes verbal information."</data>
      <data key="d2">1c0f47f0b77faab56cbeba0e1e3e7e70</data>
    </node>
    <node id="&quot;SPATIAL WM&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Spatial WM refers to the working memory system that processes spatial information."</data>
      <data key="d2">1c0f47f0b77faab56cbeba0e1e3e7e70</data>
    </node>
    <node id="&quot;MOTOR WM&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Motor WM refers to the working memory system that processes motor information."</data>
      <data key="d2">1c0f47f0b77faab56cbeba0e1e3e7e70</data>
    </node>
    <node id="&quot;PRIMACY GRADIENT&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Primacy Gradient refers to the preference for remembering the first items in a sequence better than the last items."</data>
      <data key="d2">1c0f47f0b77faab56cbeba0e1e3e7e70</data>
    </node>
    <node id="&quot;INHIBITION OF THE MOST ACTIVE CELL&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Inhibition of the Most Active Cell refers to the suppression of the most recently activated cell after its command is read out."</data>
      <data key="d2">1c0f47f0b77faab56cbeba0e1e3e7e70</data>
    </node>
    <node id="&quot;SEQUENTIAL COPYING MOVEMENTS&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Sequential Copying Movements refer to the performance of repeating a sequence of movements in the same order."</data>
      <data key="d2">1c0f47f0b77faab56cbeba0e1e3e7e70</data>
    </node>
    <node id="&quot;WORKING MEMORY DESIGN&quot;">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">1c0f47f0b77faab56cbeba0e1e3e7e70</data>
    </node>
    <node id="&quot;MILLER&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Miller is a psychologist whose work on immediate memory span is referenced in the text."
"Miller is a psychologist who proposed the concept of the immediate memory span."
"Miller is a researcher mentioned in the text who has made contributions to the understanding of immediate memory span."</data>
      <data key="d2">97a9ce754fa34aaf01d6cce57560b247,b69b23b14e0feccb488ba5412db0824c,c580fa74e3c36285cfae7df56340a990</data>
    </node>
    <node id="&quot;MURDOCK&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Murdock is a psychologist whose work on recall patterns is referenced in the text."</data>
      <data key="d2">97a9ce754fa34aaf01d6cce57560b247</data>
    </node>
    <node id="&quot;VON RESTORFF&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Von Restorff is a psychologist who studied the effects of similarity and distinctiveness in visual perception, leading to the concept of isolation effects."</data>
      <data key="d2">b69b23b14e0feccb488ba5412db0824c</data>
    </node>
    <node id="&quot;IMMEDIATE MEMORY SPAN&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Immediate Memory Span is the limited number of items that can be held in short-term memory, as proposed by Miller (1956)."
"Immediate Memory Span refers to the maximum number of items that can be held in Working Memory for immediate use."</data>
      <data key="d2">b69b23b14e0feccb488ba5412db0824c,c580fa74e3c36285cfae7df56340a990</data>
    </node>
    <node id="&quot;TRANSIENT MEMORY SPAN&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Transient Memory Span is a concept that differs from the Immediate Memory Span, suggesting a more dynamic and temporary holding capacity for items in memory."
"Transient Memory Span refers to the longest list length for which a Working Memory can store a primacy gradient without significant top-down Long-Term Memory component."</data>
      <data key="d2">b69b23b14e0feccb488ba5412db0824c,c580fa74e3c36285cfae7df56340a990</data>
    </node>
    <node id="&quot;SERIAL VERBAL LEARNING&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Serial Verbal Learning is a process of learning and remembering a sequence of verbal items, which can be influenced by associative and competitive mechanisms, as mentioned by Grossberg (1969, 1974)."</data>
      <data key="d2">b69b23b14e0feccb488ba5412db0824c</data>
    </node>
    <node id="&quot;ISOLATION EFFECTS&quot;">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">b69b23b14e0feccb488ba5412db0824c</data>
    </node>
    <node id="&quot;WM&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"WM refers to Working Memory, a cognitive system that holds information temporarily for immediate use."</data>
      <data key="d2">c580fa74e3c36285cfae7df56340a990</data>
    </node>
    <node id="&quot;IMS&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"IMS refers to a theoretical concept, possibly the Magical Number Seven, which is estimated to have a capacity limit of four plus or minus one."</data>
      <data key="d2">392028b79561bd7471cb68e7c9258b1e</data>
    </node>
    <node id="&quot;TMS&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"TMS refers to a theoretical concept that is predicted to be smaller than the IMS."</data>
      <data key="d2">392028b79561bd7471cb68e7c9258b1e</data>
    </node>
    <node id="&quot;STORE 1 MODEL&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"STORE 1 model is a specific model defined by Bradski et al. in 1992 and 1994, which is a member of the STORE model family."
"The STORE 1 Model is a defined system consisting of neuronal populations and layers, used for processing input data."</data>
      <data key="d2">392028b79561bd7471cb68e7c9258b1e,9c685cea284029fa1f27ebaa280615a5</data>
    </node>
    <node id="&quot;VISUAL SHORT TERM MEMORY&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Visual short term memory is a theoretical concept that may be related to the discussion of working memory and long-term memory."</data>
      <data key="d2">392028b79561bd7471cb68e7c9258b1e</data>
    </node>
    <node id="&quot;SKI ET AL.&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Ski et al. are the authors of a study that introduced the STORE 1 Model."</data>
      <data key="d2">9c685cea284029fa1f27ebaa280615a5</data>
    </node>
    <node id="&quot;1992&quot;">
      <data key="d0">"EVENT"</data>
      <data key="d1">"1992 is the year when the first study by Ski et al. was published, introducing the STORE 1 Model."</data>
      <data key="d2">9c685cea284029fa1f27ebaa280615a5</data>
    </node>
    <node id="&quot;1994&quot;">
      <data key="d0">"EVENT"</data>
      <data key="d1">"1994 is the year when another study by Ski et al. was published, further developing the STORE 1 Model."</data>
      <data key="d2">9c685cea284029fa1f27ebaa280615a5</data>
    </node>
    <node id="&quot;EQUATION (41)&quot;">
      <data key="d0">"EVENT"</data>
      <data key="d1">"Equation (41) is a recurrent feedback loop that updates the STM pattern based on input when it is on."</data>
      <data key="d2">65a025a8610d85bf0d2b6c4979eb7439</data>
    </node>
    <node id="&quot;EQUATION (42)&quot;">
      <data key="d0">"EVENT"</data>
      <data key="d1">"Equation (42) is mentioned in the context of Equation (41) and is likely a related recurrent feedback loop."</data>
      <data key="d2">65a025a8610d85bf0d2b6c4979eb7439</data>
    </node>
    <node id="&quot;SERIAL LEARNING&quot;">
      <data key="d0">"EVENT"</data>
      <data key="d1">"Serial Learning is mentioned as a process that enables fluently recalling stored sequences of items from a list."
"Serial Learning is a method of learning where new units are continually synthesized as a result of practice, and the context of previous events can determine subsequent responses."</data>
      <data key="d2">65a025a8610d85bf0d2b6c4979eb7439,cdd2935776d71ef9fd3a33979af0b9b5</data>
    </node>
    <node id="&quot;AVALANCHE&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"An Avalanche is a ritualistic encoding method that describes a simple example of learning an arbitrary act, such as a piano recital or a dance, in a minimal way."
"Avalanche is a learning mechanism that encodes an arbitrary space-time pattern using a minimal number of cells, insensitive to environmental feedback."
"Avalanche is a type of circuit that sequentially activates a series of Outstars to sample a spatiotemporal pattern."
"Avalanche is a circuit that activates once and cannot be stopped, requiring command cells for sensitivity to environmental feedback."
"Avalanche is a system mentioned in the text that can activate ritualistic behavior and is described as having mechanisms that modulate its performance."</data>
      <data key="d2">2e76149ff772441e6627913bc1df5000,44ddf121af4b66da2bfd6b2ac0637a23,7aeda101aa8aba76f319932f0bd568f7,88a3f14024e29666891496bb6cd7d0e4,bb19119aa74e1f624e402fcef651aac2</data>
    </node>
    <node id="&quot;SPATIOTEMPORAL PATTERN&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Spatiotemporal Pattern is a sequence of spatial patterns that is sampled and learned by the Avalanche mechanism."</data>
      <data key="d2">bb19119aa74e1f624e402fcef651aac2</data>
    </node>
    <node id="&quot;OUTSTARS&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Outstars are components of the Avalanche mechanism that sequentially sample a spatiotemporal pattern."
"Outstars are neurons within the Avalanche circuit that can fire only if activated by a command cell."
"Outstars are a type of neural structure mentioned in the text that sends signals to Avalanche Cells."</data>
      <data key="d2">03fedd128d2ad4ec7e1e1a60d26ba4f5,7aeda101aa8aba76f319932f0bd568f7,bb19119aa74e1f624e402fcef651aac2</data>
    </node>
    <node id="&quot;HVC-RA NETWORK&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"HVC-RA Network is a neural network that controls songbird singing, and an Avalanche-type circuit occurs within it."</data>
      <data key="d2">44ddf121af4b66da2bfd6b2ac0637a23</data>
    </node>
    <node id="&quot;SONGBIRD SINGING&quot;">
      <data key="d0">"EVENT"</data>
      <data key="d1">"Songbird singing is a behavior controlled by the HVC-RA Network, which includes an Avalanche-type circuit."</data>
      <data key="d2">44ddf121af4b66da2bfd6b2ac0637a23</data>
    </node>
    <node id="&quot;ANDALMAN AND FEE&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Andalman and Fee are researchers who have studied the modulation of song performance by frontal and basal ganglia circuits in songbirds."</data>
      <data key="d2">44ddf121af4b66da2bfd6b2ac0637a23</data>
    </node>
    <node id="&quot;COMMAND CELLS&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Command Cells are neurons that control stereotyped behaviors and are necessary for the Avalanche circuit to respond to environmental feedback."
"Command Cells are a type of neural structure found in invertebrates that control stereotyped behaviors, such as the rhythmic beating of crayfish swimmerets."
"Command Cells are mentioned in the text as a component of the Avalanche system that can determine which ritualistic behavior the system will activate."</data>
      <data key="d2">03fedd128d2ad4ec7e1e1a60d26ba4f5,7aeda101aa8aba76f319932f0bd568f7,88a3f14024e29666891496bb6cd7d0e4</data>
    </node>
    <node id="&quot;STEIN&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Stein is a researcher who has studied the role of command cells in controlling the rhythmic beating of crayfish swimmerets."
"Stein is a person mentioned in the text who published a study on command cells in crayfish."</data>
      <data key="d2">03fedd128d2ad4ec7e1e1a60d26ba4f5,7aeda101aa8aba76f319932f0bd568f7</data>
    </node>
    <node id="&quot;FLEXIBLE PERFORMANCE&quot;">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">7aeda101aa8aba76f319932f0bd568f7</data>
    </node>
    <node id="&quot;AVALANCHE CELLS&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Avalanche Cells are a type of neural structure mentioned in the text that can fire only if they receive signals from the previous Outstar source cell and from the command cell."</data>
      <data key="d2">03fedd128d2ad4ec7e1e1a60d26ba4f5</data>
    </node>
    <node id="&quot;CARLSON&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Carlson is a person mentioned in the text who published a study on command cells in invertebrates."
"Carlson is a researcher mentioned in the text for studying behavioral acts in invertebrates."</data>
      <data key="d2">03fedd128d2ad4ec7e1e1a60d26ba4f5,88a3f14024e29666891496bb6cd7d0e4</data>
    </node>
    <node id="&quot;DETHIER&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Dethier is a person mentioned in the text who published a study on command cells in invertebrates."
"Dethier is a researcher mentioned in the text for studying behavioral acts in invertebrates."</data>
      <data key="d2">03fedd128d2ad4ec7e1e1a60d26ba4f5,88a3f14024e29666891496bb6cd7d0e4</data>
    </node>
    <node id="&quot;COGEM THEORY&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"CogEM Theory is a theory mentioned in the text that proposes a role for incentive motivation in reinforcement learning and the competition between different drive representations that control the incentive motivation."</data>
      <data key="d2">88a3f14024e29666891496bb6cd7d0e4</data>
    </node>
    <node id="&quot;REWARD&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Reward is mentioned in the text as a type of event that can be evaluated by the Avalanche network to determine what actions are important."</data>
      <data key="d2">88a3f14024e29666891496bb6cd7d0e4</data>
    </node>
    <node id="&quot;PUNISHMENT&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Punishment is mentioned in the text as a type of event that can be evaluated by the Avalanche network to determine what actions are important."</data>
      <data key="d2">88a3f14024e29666891496bb6cd7d0e4</data>
    </node>
    <node id="&quot;COGNITIVE-EMOTIONAL-MOTOR (COGEM) THEORY&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Cognitive-Emotional-Motor (CogEM) Theory is a model of reinforcement learning that emphasizes the role of incentive motivation and competition between drive representations."</data>
      <data key="d2">f373521b781482587f80fffc5623a1f9</data>
    </node>
    <node id="&quot;TELOS AND LISTELOS&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"TELOS and lisTELOS are brain circuit models that focus on volitional control of behavioral choice."</data>
      <data key="d2">f373521b781482587f80fffc5623a1f9</data>
    </node>
    <node id="&quot;ADVANCED BRAINS&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Advanced Brains are described as having mechanisms such as high-dimensional bRNNs, which are familiar in the context of the discussed models."</data>
      <data key="d2">f373521b781482587f80fffc5623a1f9</data>
    </node>
    <node id="&quot;CLAUS&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Claus is a source mentioned in the text, likely an organization or a research group."</data>
      <data key="d2">eb6c9a7d24cc59ff93d554093a4360a4</data>
    </node>
    <node id="&quot;SCHULTZ ET AL.&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Schultz et al. is a source mentioned in the text, likely a research group or a team of authors."</data>
      <data key="d2">eb6c9a7d24cc59ff93d554093a4360a4</data>
    </node>
    <node id="&quot;SELF-ORGANIZING MAPS&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Self-Organizing Maps is a method mentioned in the text, likely a concept or a technique used in research."</data>
      <data key="d2">eb6c9a7d24cc59ff93d554093a4360a4</data>
    </node>
    <node id="&quot;INSTAR-OUTSTAR MAPS&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Instar-Outstar maps is a concept mentioned in the text, likely a type of map or a model used in research."</data>
      <data key="d2">eb6c9a7d24cc59ff93d554093a4360a4</data>
    </node>
    <node id="&quot;SELF-ORGANIZING AVALANCHE&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Self-Organizing Avalanche is a system that learns its sampling cells, temporal order links, and output spatial patterns."
"Self-Organizing Avalanche is a learning mechanism that can learn its sampling cells, temporal order links, and output spatial patterns."</data>
      <data key="d2">2ea6b3379a87077d75e5c45024f4f3e2,6e8f1f4e6c7865b14f3b5665aa62e12e</data>
    </node>
    <node id="&quot;DR. PAUL GROSSBERG&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Dr. Paul Grossberg is a researcher mentioned in the text, known for his contributions to the Self-Organizing Avalanche system."</data>
      <data key="d2">6e8f1f4e6c7865b14f3b5665aa62e12e</data>
    </node>
    <node id="&quot;CONTEXT-SENSITIVE SELF-ORGANIZING AVALANCHE&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Context-Sensitive Self-Organizing Avalanche is a learning network that is sensitive to whole sequences of previous events, allowing it to learn list chunks and plan actions."</data>
      <data key="d2">2ea6b3379a87077d75e5c45024f4f3e2</data>
    </node>
    <node id="&quot;YOUNG&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Young is a researcher who expresses skepticism about the usefulness of serial learning methods for studying verbal learning processes."
"Young is a researcher mentioned in the text, contributing to the algebraic conditions for additive-sigmoid neuron reservoirs."</data>
      <data key="d2">3b592e5ac113a5c031925f91a182baa6,cdd2935776d71ef9fd3a33979af0b9b5</data>
    </node>
    <node id="&quot;UNDERWOOD&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Underwood is a researcher who criticizes the applicability of serial learning methods in verbal learning research."</data>
      <data key="d2">cdd2935776d71ef9fd3a33979af0b9b5</data>
    </node>
    <node id="&quot;VERBAL LEARNING&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Verbal Learning refers to the acquisition and retention of new verbal units and sequences, which can be influenced by the context of previous events."</data>
      <data key="d2">cdd2935776d71ef9fd3a33979af0b9b5</data>
    </node>
    <node id="&quot;YOUNG (1968)&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Young (1968) is a serial learning expert who expressed concerns about the limitations of serial learning methods for studying verbal learning processes."</data>
      <data key="d2">54e2e54daeae6bcf60e5f0b98040259d</data>
    </node>
    <node id="&quot;UNDERWOOD (1966)&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Underwood (1966) is an author who highlighted the success of a theory and compared its originator to a Nobel Prize winner in psychology."</data>
      <data key="d2">54e2e54daeae6bcf60e5f0b98040259d</data>
    </node>
    <node id="&quot;CLASSICAL SERIAL LEARNING DATA&quot;">
      <data key="d0">"EVENT"</data>
      <data key="d1">"Classical Serial Learning Data refers to a set of data that inspired concerns about serial learning methods and have been explained and simulated using the mechanisms summarized in the review."</data>
      <data key="d2">54e2e54daeae6bcf60e5f0b98040259d</data>
    </node>
    <node id="&quot;GROSSBERG (1969C)&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Grossberg (1969c) is an author who provided explanations and simulations of classical serial learning data."</data>
      <data key="d2">54e2e54daeae6bcf60e5f0b98040259d</data>
    </node>
    <node id="&quot;GROSSBERG AND PEPE (1970, 1971)&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Grossberg and Pepe (1970, 1971) are authors who contributed to the explanations and simulations of classical serial learning data."</data>
      <data key="d2">54e2e54daeae6bcf60e5f0b98040259d</data>
    </node>
    <node id="&quot;GROSSBERG (1978A, 1993)&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Grossberg (1978a, 1993) is an author who reviewed the explanations and simulations of classical serial learning data."</data>
      <data key="d2">54e2e54daeae6bcf60e5f0b98040259d</data>
    </node>
    <node id="&quot;ECHO STATE NETWORKS&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Echo State Networks are a type of recurrent neural network architecture in reservoir computing that consist of a pool of randomly connected neurons, forming a genuine recurrent neural network."
"Echo State Networks are a type of recurrent neural network architecture in reservoir computing, consisting of a reservoir and a readout component."
"Echo State Networks is a type of recurrent neural network that uses a reservoir to capture intricate patterns and dynamics of the input data."
"Echo State Networks (ESNs) is a type of neural network used for time series prediction and other tasks, involving the use of a reservoir and a readout layer."
"Echo State Networks (ESNs) are a type of recurrent neural network that utilize a reservoir to capture and process data patterns."
"Echo State Networks (ESN) is a type of recurrent neural network used for time series prediction and other tasks, which is being optimized using Hyperopt in the context of the paper."
"Echo State Networks are a type of reservoir computing architecture that ReservoirPy specializes in implementing."
"Echo State Networks are a type of recurrent neural network used for time series prediction and data assimilation."
"Echo State Networks are a type of recurrent neural network used for solving complex tasks, such as the one described in the text."
"Echo State Networks are a type of recurrent neural network known for their ability to learn and approximate complex functions."
"Echo State Networks are a type of computational model that have become relevant and popular, particularly for applications in signal processing."
"Echo State Networks are a type of Recurrent Neural Network mentioned in the text, which are a focus of the reservoirpy library."
"Echo State Networks are a type of Recurrent Neural Network that uses a random recurrent layer of neurons, known as a reservoir, to perform computations."
"Echo State Networks (ESNs) are a type of recurrent neural network developed by Jaeger, known for their ability to project input data into a high-dimensional non-linear space."
"Echo State Networks are a type of neural network with a sparsely connected random hidden layer, where the weights of output neurons are the only part of the network that can change."
"Echo State Networks are a type of recurrent neural network architecture consisting of a reservoir and a readout."
"Echo State Networks are a type of recurrent neural network that use a reservoir to store and process information."
"Echo State Networks are a type of recurrent neural network that uses a sparsely connected reservoir to process input data, which is being discussed in the provided text."
"Echo State Networks are a type of neural network that operates a random, large, fixed, recurring network with the input signal, inducing a nonlinear response signal in each neuron, and connects a desired output signal by a trainable linear combination of all these response signals."
"Echo State Networks are a variant of reservoir computing that can be built in different ways, including with or without directly trainable input-to-output connections, and with different neurotypes and reservoir internal connectivity patterns."
"Echo State Networks are a type of recurrent neural network that uses a sparsely connected, randomly generated reservoir to process input signals."</data>
      <data key="d2">0e6f0f7cd882a638ecb571ef36068868,10112a11d47463e2aad7352c52922d61,136559fd2a1fbef4cc8a6b11abcb3eef,158f53cd85edbb4f2e4c77b78c5e7acc,257d4cf08ffc32b99856b6e31fa4221e,41fa16855df7da666dc6fc38d2f8ee53,423cdb622c47fa8cec25f22eb9f9f01f,46913f0d73ba0b8cecfdf42bde9862f4,4d87a0d12ce76c7a493a24e1c4b06a83,5a9eaff8c67e594f49fae0318a502c6a,6de297d888d10db4c987b5eafc6398b2,711ec1b4879d910d0df0a477c9e240ba,73e81fd6509a2ba400a8435793ade3c5,82a734e7c7ada95b1c99783140dd7168,83fafb2423a01afae7e522917d79ace9,8965403859beb43a6ab7e5c8c916b857,8e16fc97c32c39d7961b52e21b99dc53,a3368f9cab1f65643dba089af5a1f95e,bc2d4d6bb706c3d06ffd2c9c2f362104,ed28ba3543e07641536ff1eb5e0749dd,f0b3b2a88425b0563005400ea246528b</data>
    </node>
    <node id="&quot;RECURRENT NEURAL NETWORK&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Recurrent Neural Network is a type of artificial neural network that processes sequences of inputs or produces sequences of outputs, allowing past information to be used in processing future inputs."
"A Recurrent Neural Network (RNN) is a type of artificial neural network that processes sequences of inputs using internal state, allowing outputs from some nodes to affect future inputs to the same nodes. It is characterized by bi-directional flow of information and is suitable for tasks like handwriting and speech recognition."
"A Recurrent Neural Network (RNN) is a type of artificial neural network that allows information to flow bidirectionally between its layers, making it suitable for tasks such as handwriting recognition and speech recognition."
"The Recurrent Neural Network is described as a type of neural network that processes a time series and returns a collection of predictions, while updating a hidden state at each time step."
"Recurrent Neural Network is a type of neural network that has connections that form a directed cycle."</data>
      <data key="d2">5445391448d4ac43471e2bce5eb41a70,8e16fc97c32c39d7961b52e21b99dc53,dcd6355fc1ed8a61a1b70c50ce60fd36,e1bf3df1ff001613df1451d6d8bf3ee4,f5b970cf7201f4a918d8bd6a1267657c</data>
    </node>
    <node id="&quot;SUPPORT VECTOR MACHINES&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Support Vector Machines are a set of supervised learning methods used for classification, regression, and outlier detection."</data>
      <data key="d2">8e16fc97c32c39d7961b52e21b99dc53</data>
    </node>
    <node id="&quot;TIME SERIES FORECASTING&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Time Series Forecasting is the use of a model to predict future values based on previously observed values."
"Time Series Forecasting is the use of a model to predict future values based on previously observed values."
"Time Series Forecasting is the use of a model to predict future values based on previously observed values in time series analysis."
"Time series forecasting is an application that uses previous predictions to improve future forecasts, benefiting from the incorporation of past information through feedback connections."
"Time series forecasting is an application that uses previous predictions to improve future forecasts."
"Time Series Forecasting is the process of predicting the next value in a sequence of data points based on the current and previous values."
"Time Series Forecasting is the process of predicting future values based on past observations."
"Time Series Forecasting is the use of a model to predict future values based on previously observed values in a time series."
"Time Series Forecasting is the process of predicting future values based on past observations, which is the primary task performed by the ESN Model."</data>
      <data key="d2">05ba4f2e1a9472bd286417154cb0c0d4,52d001cd1786e3d9f36e0c57538bc21e,57a27a1504a5ef7d330172c0ac1085c9,70c3a879c0f6e6b76a13d02d67bce1a8,8e16fc97c32c39d7961b52e21b99dc53,c4b54c2da2dda7e660de7bd6de6f13b4,dc76db79c20c315f30e0297619904b6f,e94f386a2ed7de2156b4864797cc199e,f70c7d3d89baaabbeaad57b58e379e08</data>
    </node>
    <node id="&quot;SEQUENCE GENERATION&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Sequence Generation is the process of creating a sequence of items, such as words in a sentence, using a model."</data>
      <data key="d2">8e16fc97c32c39d7961b52e21b99dc53</data>
    </node>
    <node id="&quot;INRIA&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Inria is an organization that has published a document on Reservoir Computing and maintains a reservoirPy page and a github repository."
"INRIA is mentioned as the email domain of Xavier Hinaut, the contact person for the library."
"Inria is a French Research Institute that supports the development of ReservoirPy and is located at Bordeaux, France."
"Inria is a French Research Institute in Digital Sciences, supporting the development of ReservoirPy."</data>
      <data key="d2">20b16c2e1cb8813ade96fea5f9591631,296bb6eb4ef7d170f7224efcccbbbaf7,2a197220a94bac0b44fc0b07712e45ba,8e16fc97c32c39d7961b52e21b99dc53</data>
    </node>
    <node id="&quot;RESERVOIRPY DOCUMENTATION&quot;">
      <data key="d0">"LOCATION"</data>
      <data key="d1">"ReservoirPy documentation is a resource where more information about the library and its components can be found."
"ReservoirPy documentation is a resource mentioned in the text for learning more about creating Echo State Networks."
"ReservoirPy documentation is a resource that provides detailed information about the library and its usage."</data>
      <data key="d2">475ca77684df5045266ddf079f2e37f1,6be085e79e86abc5b1a7eaff6bda1ec5,83fafb2423a01afae7e522917d79ace9</data>
    </node>
    <node id="&quot;WIKIPEDIA PAGE&quot;">
      <data key="d0">"LOCATION"</data>
      <data key="d1">"Wikipedia page is a resource where more information about Echo State Networks can be found."
"The Wikipedia page is a resource mentioned in the text for learning more about Echo State Networks."</data>
      <data key="d2">6be085e79e86abc5b1a7eaff6bda1ec5,83fafb2423a01afae7e522917d79ace9</data>
    </node>
    <node id="&quot;ESNS&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"ESNs are a type of neural network mentioned in the text, which are created using ReservoirPy."
"ESNs are a type of recurrent neural network known for their universal computation and approximation properties."
"ESNs are a type of RNN training algorithm that is fast, does not suffer from bifurcations, and is easy to implement, introduced to outperform other algorithms."
"ESNs are Echo State Networks, a type of recurrent neural network introduced as an alternative to RNNs due to their fast and simple training algorithms."
"ESNs are a type of recurrent neural network that includes direct connections from input to readout, enabling advanced data processing."
"ESNs are a type of recurrent neural network known for their simplicity and efficiency in time series prediction and reservoir computation."
"ESNs are a type of machine learning model developed independently by Wolfgang Maass, used for reservoir computing."
"ESNs are a type of recurrent neural network known for their performance in time series prediction tasks."</data>
      <data key="d2">2a2a93486d6198ce228e77e120dc3c0c,4b89d9404fd683ecd03d5846ee2d86ce,6be085e79e86abc5b1a7eaff6bda1ec5,7f2d69f9a9baca70ffd25a6865189206,b32958d42199d47252887dc7be40ab5a,e805d3f438bd9c485639f1c69f917ae5,eafe89ad19a57846f953a1dfcf8571f8,f1fc6fbc8158d3da070d55544041a2ca</data>
    </node>
    <node id="&quot;FEATURE&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"A feature is an attribute associated with an input or sample, mentioned in the text."
"A feature is an attribute associated with an input or sample, such as a pixel in an image or a state's Euclidean distance to the goal state."</data>
      <data key="d2">6be085e79e86abc5b1a7eaff6bda1ec5,dd41fca2f283c4f8c8d1cba5b836da45</data>
    </node>
    <node id="&quot;LABEL&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Labels are the values that you're trying to figure out, mentioned in the text."</data>
      <data key="d2">6be085e79e86abc5b1a7eaff6bda1ec5</data>
    </node>
    <node id="&quot;HOUSE PRICE MODEL&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"House Price Model is a concept used to predict the price of a house based on various features such as the number of bedrooms, location, and size."</data>
      <data key="d2">8c15845717f6b8610fe30ac08cc78b4e</data>
    </node>
    <node id="&quot;LABELS&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Labels are the actual values that the House Price Model is trying to predict, in this case, the actual price of the house."</data>
      <data key="d2">8c15845717f6b8610fe30ac08cc78b4e</data>
    </node>
    <node id="&quot;RECURRENT NEURAL NETWORK (RNN)&quot;">
      <data key="d0">"TECHNOLOGY"</data>
      <data key="d1">"RNN is a type of artificial neural network that allows the output from some nodes to affect subsequent input to the same nodes, creating a bi-directional flow of information. It is suitable for tasks like speech recognition and can use its internal state to process arbitrary sequences of inputs."
"Recurrent Neural Network (RNN) is a type of neural network that is dynamic and used for various applications, including time series prediction and pattern recognition."</data>
      <data key="d2">8c15845717f6b8610fe30ac08cc78b4e,a4b801e70cf2ba3a3101d34899450087</data>
    </node>
    <node id="&quot;RECURRENT NEURAL NETWORKS (RNNS)&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"RNNs are a type of neural network that can process arbitrary sequences of inputs, making them suitable for tasks like handwriting recognition and speech recognition."
"RNNs are a type of artificial neural network designed to process sequential data, such as time series or natural language."
"RNNs are a type of artificial neural network designed to process sequential or time-series data, utilizing their 'memory' to take information from previous inputs, influencing the current output."
"Recurrent Neural Networks (RNNs) are a type of neural network architecture designed to process sequential data by maintaining an internal state."
"Recurrent Neural Networks (RNNs) are a type of neural network that acts as a random, nonlinear medium whose dynamic response is used as a signal base in echo state networks."</data>
      <data key="d2">04b89ad6396cb78ca75689473c47a247,24a607f45ad989d81411fed4f2941884,4246748fef7001ea0bd03ac702565b0d,a3368f9cab1f65643dba089af5a1f95e,d0a69d653d08e58959dd8d0f2033e697</data>
    </node>
    <node id="&quot;CONVOLUTIONAL NEURAL NETWORKS (CNNS)&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"CNNs are a type of neural network that belong to the class of finite impulse response networks, characterized by directed acyclic graphs that can be unrolled."</data>
      <data key="d2">04b89ad6396cb78ca75689473c47a247</data>
    </node>
    <node id="&quot;LONG SHORT-TERM MEMORY NETWORKS (LSTMS)&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"LSTMs are a type of RNN that incorporates controlled storage mechanisms, known as gated states or gated memory."
"LSTMs are a type of RNN that uses gated states or gated memory to address the vanishing gradient problem and better capture long-term dependencies in sequential data."</data>
      <data key="d2">04b89ad6396cb78ca75689473c47a247,24a607f45ad989d81411fed4f2941884</data>
    </node>
    <node id="&quot;GATED RECURRENT UNITS (GRUS)&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"GRUs are a type of RNN that uses gated states, similar to LSTMs, to manage and update information over time."
"GRUs are a type of RNN that use gating mechanisms to selectively update and reset hidden states, making them more efficient in processing long sequences of data."</data>
      <data key="d2">04b89ad6396cb78ca75689473c47a247,24a607f45ad989d81411fed4f2941884</data>
    </node>
    <node id="&quot;FEEDBACK NEURAL NETWORKS (FNNS)&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"FNNs are neural networks that incorporate time delays or feedback loops, replacing standard storage mechanisms."
"FNNs are a type of neural network that incorporates time delays or feedback loops, replacing standard storage, and are used to process sequential data."</data>
      <data key="d2">04b89ad6396cb78ca75689473c47a247,24a607f45ad989d81411fed4f2941884</data>
    </node>
    <node id="&quot;TURING CAPABILITIES&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Turing Capabilities refer to the theoretical ability of RNNs to mimic the computational power of a Turing machine."</data>
      <data key="d2">04b89ad6396cb78ca75689473c47a247</data>
    </node>
    <node id="&quot;HANDWRITING RECOGNITION&quot;">
      <data key="d0">"EVENT"</data>
      <data key="d1">"Handwriting Recognition is an application of RNNs that involves processing unsegmented, connected handwriting."
"Handwriting Recognition is a task that can be performed by a Recurrent Neural Network, as it allows the processing of arbitrary sequences of inputs."</data>
      <data key="d2">24a607f45ad989d81411fed4f2941884,f5b970cf7201f4a918d8bd6a1267657c</data>
    </node>
    <node id="&quot;SPEECH RECOGNITION&quot;">
      <data key="d0">"EVENT"</data>
      <data key="d1">"Speech Recognition is an application of RNNs that involves recognizing and processing spoken language."
"Speech recognition is an application that uses previous phoneme activations to better predict subsequent phonemes, leveraging the memory capabilities of feedback connections."
"Speech recognition is an application that incorporates previous phoneme activations to better predict subsequent phonemes."
"Speech Recognition is another task that can be performed by a Recurrent Neural Network, as it allows the processing of arbitrary sequences of inputs."</data>
      <data key="d2">24a607f45ad989d81411fed4f2941884,57a27a1504a5ef7d330172c0ac1085c9,c4b54c2da2dda7e660de7bd6de6f13b4,f5b970cf7201f4a918d8bd6a1267657c</data>
    </node>
    <node id="&quot;SEQUENTIAL DATA&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Sequential data is data arranged in sequences where the order matters, and each data point is dependent on other data points in this sequence."</data>
      <data key="d2">24a607f45ad989d81411fed4f2941884</data>
    </node>
    <node id="&quot;TIME SERIES&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Time Series is a sequence of data points collected at successive equally spaced points in time, used for analysis and prediction."
"Time Series is a concept mentioned in the text, referring to a sequence of data points collected at regular time intervals."
"Time Series is a sequence of data points collected at successive equally spaced points in time, often used for analysis and forecasting."
"Time Series is a type of panel data, which is a multidimensional data set, characterized by a one-dimensional panel structure."
"A time series is mentioned as input to the recurrent neural network, which processes all entries of the time series through the layers of the neural network."
"Time Series refers to a sequence of data points collected at regular time intervals."
"Time Series refers to a sequence of data points collected at regular time intervals, which is being analyzed and predicted in the provided text."
"Time Series refers to a sequence of data points collected at regular time intervals."</data>
      <data key="d2">14bccd672d2f8dd2cd7300581c8844fb,29aad23ce67e778ac31d4fb287fd20c7,5445391448d4ac43471e2bce5eb41a70,70c3a879c0f6e6b76a13d02d67bce1a8,76963fa19a9caab847e50167f71c86a2,8a015d76b241ce06eb72867bbb712edd,973d44d321c7ceee7add295c60b085d2,c087c124713c7ade4223617d95928cbf</data>
    </node>
    <node id="&quot;TIME SERIES ANALYSIS&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Time Series Analysis is the process of analyzing Time Series data to extract meaningful statistics and characteristics."
"Time Series Analysis is a method for analyzing time series data, focusing on extracting meaningful statistics and characteristics."
"Time Series Analysis is the process of analyzing time series data to extract meaningful statistics and characteristics."
"Time Series Analysis is a type of analysis that focuses on relationships between different points in time within a single series, distinct from cross-sectional studies and spatial data analysis."
"Time Series Analysis is a statistical method used to analyze data points collected at regular time intervals."
"Time Series Analysis is the primary focus of the text, used for various purposes such as forecasting, signal detection, data mining, and pattern recognition."
"Time Series Analysis is a statistical method used for analyzing data points collected at regular intervals, such as time."</data>
      <data key="d2">4b75a8a7637b05307e62f309c682d43b,70c3a879c0f6e6b76a13d02d67bce1a8,8a015d76b241ce06eb72867bbb712edd,8e69dad9d25c6b8f037f22592687e195,a2b394d556da06b8c14dd2f5e106343b,c7d17582a93a296eaaf9b9fca737ba51,dc76db79c20c315f30e0297619904b6f</data>
    </node>
    <node id="&quot;MATHEMATICS&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Mathematics is the field of study that deals with numbers, shapes, and structures, and it provides the foundation for Time Series analysis."
"Mathematics is the field of study that deals with the logic of shape, quantity, and arrangement."</data>
      <data key="d2">70c3a879c0f6e6b76a13d02d67bce1a8,8a015d76b241ce06eb72867bbb712edd</data>
    </node>
    <node id="&quot;DATA POINTS&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Data Points are individual observations or measurements in a Time Series, which are collected at successive equally spaced points in time."</data>
      <data key="d2">8a015d76b241ce06eb72867bbb712edd</data>
    </node>
    <node id="&quot;SUCCESSIVE EQUALLY SPACED POINTS&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Successive Equally Spaced Points refer to the regular interval between data points in a Time Series."</data>
      <data key="d2">8a015d76b241ce06eb72867bbb712edd</data>
    </node>
    <node id="&quot;EXAMPLES OF TIME SERIES&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Examples of Time Series include Heights of ocean tides, Counts of sunspots, and Daily closing value of the Dow Jones Industrial Average."</data>
      <data key="d2">8a015d76b241ce06eb72867bbb712edd</data>
    </node>
    <node id="&quot;REGRESSION ANALYSIS&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Regression Analysis is a statistical method often used to test relationships between one or more different time series."
"Regression Analysis is a statistical method used to test relationships between one or more dependent variables and one or more independent variables."
"Regression Analysis is a statistical method used to test relationships between one or more different time series."
"Regression Analysis is a statistical technique used to infer relationships among two or more variables, focusing on uncertainty in the data."
"Regression Analysis is a technique used to approximate a function when only a set of points is provided, and the function is an operation on the real numbers."</data>
      <data key="d2">630c86e110e2dabbe068f446b619cef3,70c3a879c0f6e6b76a13d02d67bce1a8,8e69dad9d25c6b8f037f22592687e195,9ec0dac4c72bcc2c78c7df43b9969fe7,dc76db79c20c315f30e0297619904b6f</data>
    </node>
    <node id="&quot;CROSS-SECTIONAL STUDIES&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Cross-Sectional Studies involve data without a natural ordering of observations, such as explaining people's wages by their education levels."</data>
      <data key="d2">dc76db79c20c315f30e0297619904b6f</data>
    </node>
    <node id="&quot;SPATIAL DATA ANALYSIS&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Spatial Data Analysis involves observations typically relating to geographical locations, such as house prices by location."</data>
      <data key="d2">dc76db79c20c315f30e0297619904b6f</data>
    </node>
    <node id="&quot;TEMPORAL ORDERING&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Temporal Ordering refers to the natural ordering of time series data, distinguishing it from cross-sectional studies."</data>
      <data key="d2">dc76db79c20c315f30e0297619904b6f</data>
    </node>
    <node id="&quot;STOCHASTIC MODELS&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Stochastic Models reflect the fact that observations close together in time will be more closely related than observations further apart."
"Stochastic Models are used in time series analysis to account for the relationship between observations close together in time."</data>
      <data key="d2">dc76db79c20c315f30e0297619904b6f,e94f386a2ed7de2156b4864797cc199e</data>
    </node>
    <node id="&quot;TIME REVERSIBILITY&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Time Reversibility is a characteristic of time series models that express values for a given period as deriving from past values, rather than future values."</data>
      <data key="d2">dc76db79c20c315f30e0297619904b6f</data>
    </node>
    <node id="&quot;REAL-VALUED CONTINUOUS DATA&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Real-Valued Continuous Data refers to data types such as temperature readings over time, used in time series analysis."</data>
      <data key="d2">e94f386a2ed7de2156b4864797cc199e</data>
    </node>
    <node id="&quot;DISCRETE NUMERIC DATA&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Discrete Numeric Data refers to data types such as counts of events occurring in fixed intervals, used in time series analysis."</data>
      <data key="d2">e94f386a2ed7de2156b4864797cc199e</data>
    </node>
    <node id="&quot;DISCRETE SYMBOLIC DATA&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Discrete Symbolic Data refers to sequences of characters such as letters and words in a language, used in time series analysis."</data>
      <data key="d2">e94f386a2ed7de2156b4864797cc199e</data>
    </node>
    <node id="&quot;NUMPY&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"NumPy is an open-source organization that provides a library for working with arrays in Python, which is mentioned in the text."
"NumPy is a fundamental package for scientific computing in Python, providing a powerful N-dimensional array object and various derived objects."
"NumPy is an open-source Python library that provides a powerful N-dimensional array object and various routines for operations on arrays. It is used for scientific computing and is fundamental in ReservoirPy."
"NumPy is an open-source Python library used for numerical computing and array manipulation."
"Numpy is a library in Python used for numerical computations, providing functions to work with arrays and matrices."
"Numpy is a library for numerical computing in Python, used to create arrays and perform mathematical operations."
"NumPy is a library used for numerical computing in Python, and the ptp function mentioned in the text is a function provided by NumPy."
"numpy is a standard scientific library in Python used for numerical computations and array manipulation."
"Numpy is a library used for numerical computing in Python, as mentioned in the text."
"Numpy is a library used for numerical computing in Python, providing support for arrays and matrices."
"Numpy is a library used for numerical computing in Python, which is mentioned in the context of reservoir parameters."
"Numpy is a library used for numerical computing in Python, providing functions to generate matrices."
"Numpy is a library for the Python programming language, adding support for large, multi-dimensional arrays and matrices, along with a large collection of high-level mathematical functions to operate on these arrays."
"Numpy is a library used by ReservoirPy for all computations, including data storage and manipulation."
"Numpy is a library used for numerical computing in Python, which is used to store and manipulate data in ReservoirPy."
"Numpy is a library used to perform numerical computations in Python, which is mentioned in the context of ESNs."
"Numpy is a library used for numerical computing in Python, used for handling the sine wave data."
"Numpy is a library used for numerical computations in Python, which is used in the provided code for handling arrays and mathematical operations."
"Numpy is a library used for numerical computations in the code."
"Numpy is a library used for numerical computations in Python."
"Numpy is a library for numerical computing in Python, used to generate and manipulate matrices."
"Numpy is a library used for numerical computing in Python, providing support for large, multi-dimensional arrays and matrices, along with a collection of mathematical functions."
"Numpy is a library used for numerical computations in Python."
"Numpy is a library used for numerical computing in Python."
"NumPy is a library used for numerical computing in Python."
"Numpy is a library used for numerical computations in the provided code."</data>
      <data key="d2">00d22666fe697ffb66c2392939f45b39,14bccd672d2f8dd2cd7300581c8844fb,1cbfde86d1258f2b267135412e50a590,2f4c992d69812866e6fce6dbb52d8612,34b9ce80a22112b32e063179511af6e0,37549a8af907ce182bd36eec43002a7d,38b3e8ea0ec280360770513327b0d9d3,4073cafddb73621f26061385c5570659,4246748fef7001ea0bd03ac702565b0d,50d4e4aab1823b8df6573ccf227f24d0,5732296d26c7a572dc90d4af1172626a,593080a95ef7640b3925b07cad1bedd4,71f966d00b6d0eceb580d00b9cb86b1e,74c073137c970e32982756d008532cb8,7b9936d57ece8ba985947a7aca12e2c7,8294eed5fc10df1c118f9afa266910e4,8648b5740b93d805f139d9745e1171e8,a58317c7e13f27d513fc7671fd187ecb,bc2d4d6bb706c3d06ffd2c9c2f362104,cdc64af0dde941250d89b191d0666c9b,d5e39e29b61f6ea0ffe0c868ba7a4252,dddc79e4cd04d2d07e35930dd8458168,ef85a7b1ca82dc1446ea71964d607a73,f838f4cbb7060f4409ba2d174a396fb1,fe90abb0dde126fafbf44782aeb6738c,ff860bc63e3d697a6183c0b850689048</data>
    </node>
    <node id="&quot;API&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"API is a concept mentioned in the text, referring to an Application Programming Interface that allows software applications to communicate with each other."</data>
      <data key="d2">14bccd672d2f8dd2cd7300581c8844fb</data>
    </node>
    <node id="&quot;VERBOSITY&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Verbosity is a concept mentioned in the text, referring to the level of detail provided in the output of a program."
"Verbosity refers to the level of detail provided in the output of a program, with higher levels producing more detailed information."</data>
      <data key="d2">14bccd672d2f8dd2cd7300581c8844fb,f838f4cbb7060f4409ba2d174a396fb1</data>
    </node>
    <node id="&quot;SEED&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Seed is a concept mentioned in the text, referring to an initial value used to initialize a random number generator, making the results reproducible."
"A seed is an initial value used to initialize a pseudorandom number generator, ensuring deterministic and repeatable results."
"SEED is a hyperparameter used for reproducibility in experiments."
"SEED is a hyperparameter used for reproducibility in a system or process."
"seed is a parameter explored by hp_space, fixed to 1234, used for the ESN initialization."
"seed is a parameter that specifies the random state seed, ensuring reproducibility."
"Seed is a parameter in Reservoir Computing used for reproducibility, ensuring that the same random numbers are generated in each run."
"seed is a parameter used to initialize the random number generator in the ESN."
"Seed is a parameter used to initialize the random number generator in the ESN model, ensuring reproducibility of results."
"SEED is a term used in the text, likely referring to an initial value or starting point used in the Reservoir system."
"Seed is a parameter in the Hyperopt configuration, which is mentioned in the text."</data>
      <data key="d2">09198e939639c229c2c97555f65b12a7,0982b8d1eb1e636b19fa2e9d9361e566,14bccd672d2f8dd2cd7300581c8844fb,2386633041e820b604fc4457264b5a33,3c4d88c41f6efbfccea6f8814bf8430e,72e6eee633bcb5b1458c4cee3975cee1,76f47f241e255f9f36646409d2ec30f1,80033e741d8e10abdcfe20dd17192152,adfc38e9dc5e6fd0fe67ce83dfa1f154,bba680a0a7dd439bd5b0fe1547ffe040,f838f4cbb7060f4409ba2d174a396fb1</data>
    </node>
    <node id="&quot;SOFTWARE APPLICATIONS&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Software Applications are systems that use APIs to communicate with each other, enabling integration and interaction."</data>
      <data key="d2">f838f4cbb7060f4409ba2d174a396fb1</data>
    </node>
    <node id="&quot;APIS&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"APIs define methods and data formats for applications to request and exchange information."</data>
      <data key="d2">f838f4cbb7060f4409ba2d174a396fb1</data>
    </node>
    <node id="&quot;NUMPY ARRAY&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"A Numpy array is a powerful n-dimensional array object in Python, used for efficient storage and manipulation of large datasets."</data>
      <data key="d2">f838f4cbb7060f4409ba2d174a396fb1</data>
    </node>
    <node id="&quot;SCIPY&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"SciPy is an open-source Python library used for scientific and technical computing. It builds on NumPy and provides a large collection of algorithms and functions for optimization and integration."
"SciPy is an open-source Python library used for scientific and technical computing, building on NumPy and providing a large collection of algorithms and functions."
"Scipy is a library in Python used for scientific computing, providing functions for optimization, integration, and sparse matrices."
"scipy is a standard scientific library in Python used for mathematical and scientific computations, including signal processing, optimization, and statistics."
"Scipy is a library used for scientific computing in Python, providing support for sparse matrices."
"Scipy is a library used for scientific computing in Python, which is mentioned in the context of reservoir parameters and initializer functions."
"Scipy is a library used for scientific computing in Python, providing functions to handle sparse matrices."
"Scipy is a library for the Python programming language that provides mathematical functions and convenience functions for optimization, statistics, and other tasks."
"Scipy is a library used by ReservoirPy for computations, in addition to Numpy."
"Scipy is a library used for scientific computing in Python, which is used in computations within ReservoirPy."
"Scipy is a library used for scientific computing in Python, which is mentioned in the context of ESNs for sparse matrices."
"Scipy is a library for scientific computing in Python, used to generate sparse matrices."
"Scipy is a library used for scientific computing in Python, providing support for mathematical functions, optimization, integration, and more."</data>
      <data key="d2">1cbfde86d1258f2b267135412e50a590,37549a8af907ce182bd36eec43002a7d,38b3e8ea0ec280360770513327b0d9d3,4246748fef7001ea0bd03ac702565b0d,5732296d26c7a572dc90d4af1172626a,74c073137c970e32982756d008532cb8,7b9936d57ece8ba985947a7aca12e2c7,bc2d4d6bb706c3d06ffd2c9c2f362104,cdc64af0dde941250d89b191d0666c9b,d5e39e29b61f6ea0ffe0c868ba7a4252,ef85a7b1ca82dc1446ea71964d607a73,fe90abb0dde126fafbf44782aeb6738c,ff860bc63e3d697a6183c0b850689048</data>
    </node>
    <node id="&quot;BACKPROPAGATION OF ERROR&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Backpropagation of Error is a method used to train neural network models by estimating gradients."
"Backpropagation of Error is a method used to train neural network models by estimating gradients, which helps the model learn by adjusting its parameters."</data>
      <data key="d2">001240f9b2caf047ee61a89e03f7b309,8fdd0220497c9b9d8c2ece14be6a8f25</data>
    </node>
    <node id="&quot;GRADIENT DESCENT&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Gradient Descent is a method of finding the minimum value of a function, often used in conjunction with backpropagation to update the network parameters."
"Gradient Descent is a method of finding the minimum value of a function, often used in conjunction with backpropagation to update the network parameters."
"Gradient Descent is an optimization algorithm used to minimize the error in machine learning models."
"Gradient Descent is an optimization algorithm used to minimize the error term in neural networks."
"Gradient Descent is a method used for optimizing parameters in machine learning models, facing challenges in standard RNN architectures due to vanishing gradients."</data>
      <data key="d2">0bb54b1de8d2297293defe94addb8076,1aec5b03f663d1614b2ecbf97981a5c2,8fdd0220497c9b9d8c2ece14be6a8f25,eafe89ad19a57846f953a1dfcf8571f8,f60e4bd6b9e356b88d3a008130e8ac4b</data>
    </node>
    <node id="&quot;STOCHASTIC GRADIENT DESCENT&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Stochastic Gradient Descent is a variant of gradient descent that updates the parameters using random subsets of data."
"Stochastic Gradient Descent is a variant of gradient descent that updates the parameters using random subsets of data."</data>
      <data key="d2">8fdd0220497c9b9d8c2ece14be6a8f25,f60e4bd6b9e356b88d3a008130e8ac4b</data>
    </node>
    <node id="&quot;NEURAL NETWORK MODELS&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Neural Network Models are computational models inspired by the structure and function of the human brain, used for tasks such as pattern recognition and decision-making."</data>
      <data key="d2">8fdd0220497c9b9d8c2ece14be6a8f25</data>
    </node>
    <node id="&quot;LINEAR REGRESSION&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Linear Regression is a method used to predict the value of one variable based on the value of another variable, estimating the coefficients of the linear equation that best fits the data points."
"Linear Regression is a statistical method used to predict the relationship between two variables, finding the best-fit line that minimizes the differences between predicted and actual values."
"Linear Regression is a statistical technique used to transform data into actionable information, uncovering patterns and relationships."
"Linear Regression is a statistical method used for modeling relationships between variables, with shortcomings such as instability of the estimate and unreliability of the forecast in a high-dimensional context."
"Linear Regression is a statistical method used for training connections in the Echo State Network."
"Linear Regression is a statistical method used to find the relationship between two variables by fitting a linear equation to the observed data."
"Linear Regression is a statistical method mentioned in the text, used to train a readout."
"Linear Regression is a statistical method mentioned in the text, used by offline readouts and the Ridge Readout."</data>
      <data key="d2">4b0fe17444b892af954d2561fec36eb6,573ef2ebe6a637a429cdc073a8508ca4,5d3baa9818a4e01fe1196c43378a2cea,6a4432cd530b28770e2b903fe242a0d1,861c28cb739722ddeb0babb7e1427409,d25cd385546ec6a033287e75d65a551a,f60e4bd6b9e356b88d3a008130e8ac4b,f730c6800099724052a2d061f3cd8c2e</data>
    </node>
    <node id="&quot;BACKPROPAGATION&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Backpropagation is a mathematical algorithm used in the learning of artificial neural networks, commonly used with optimization algorithms like gradient descent or stochastic gradient descent."</data>
      <data key="d2">f60e4bd6b9e356b88d3a008130e8ac4b</data>
    </node>
    <node id="&quot;LEAST SQUARES METHOD&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"The Least Squares Method is a statistical method used to find the best-fit line for a set of paired data, minimizing the differences between the predicted values and the actual values."
"Least Squares Method is a method used in Linear Regression to find the best-fit line that minimizes the sum of the squares of the differences between the observed values and the values predicted by the line."</data>
      <data key="d2">573ef2ebe6a637a429cdc073a8508ca4,f60e4bd6b9e356b88d3a008130e8ac4b</data>
    </node>
    <node id="&quot;ORGANIZATIONS&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Organizations are mentioned as benefiting from Linear Regression, using it to transform raw data into actionable information and make better decisions."</data>
      <data key="d2">573ef2ebe6a637a429cdc073a8508ca4</data>
    </node>
    <node id="&quot;IBM&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"IBM is referenced as a source of detailed information about Linear Regression."
"IBM is a source of information about Linear Regression."
"IBM is a source of information about Ridge Regression, providing detailed explanations and resources."
"IBM is a technology company that provides information about overfitting on their website."</data>
      <data key="d2">173a2da2c7ea80f95b04db8422ced004,4b0fe17444b892af954d2561fec36eb6,573ef2ebe6a637a429cdc073a8508ca4,b5b73413fbe4ab8b61c4a939fe6c6a2b</data>
    </node>
    <node id="&quot;INDEPENDENT VARIABLE&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Independent Variable is a variable that is used to predict or explain the changes in the dependent variable."</data>
      <data key="d2">573ef2ebe6a637a429cdc073a8508ca4</data>
    </node>
    <node id="&quot;DEPENDENT VARIABLE&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Dependent Variable is a variable that is being predicted or explained by the independent variable."</data>
      <data key="d2">573ef2ebe6a637a429cdc073a8508ca4</data>
    </node>
    <node id="&quot;LINEAR REGRESSION ANALYSIS&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Linear Regression Analysis is a statistical method used to understand the relationship between two continuous variables."</data>
      <data key="d2">573ef2ebe6a637a429cdc073a8508ca4</data>
    </node>
    <node id="&quot;SIMPLE LINEAR REGRESSION CALCULATORS&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Simple Linear Regression Calculators are tools that use the Least Squares Method to find the best-fit line for a set of paired data."</data>
      <data key="d2">573ef2ebe6a637a429cdc073a8508ca4</data>
    </node>
    <node id="&quot;DATA ASSUMPTIONS&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Data Assumptions are conditions that the data must meet before using Linear Regression, such as linearity, independence, and normal distribution of errors."</data>
      <data key="d2">573ef2ebe6a637a429cdc073a8508ca4</data>
    </node>
    <node id="&quot;RIDGE REGRESSION&quot;">
      <data key="d0">"TECHNIQUE"</data>
      <data key="d1">"Ridge Regression is a statistical regularization technique used to prevent overfitting in machine learning models, particularly useful when dealing with multicollinearity."
"Ridge Regression is a statistical method used to address multicollinearity in data, adjusting coefficients to improve model generalization."
"Ridge Regression is a regularization technique used to prevent overfitting in machine learning models."
"Ridge Regression is a form of linear regression with L2 regularization, which helps avoid overfitting by penalizing large weights, improving the model's generalization and robustness to noise."
"Ridge Regression is a regularization technique used to prevent overfitting in statistical models by adding a penalty term to the loss function."
"Ridge Regression is a regularization technique used to prevent overfitting in statistical modeling."
"ridge regression is a method used for offline training of an Echo State Network (ESN)."
"Ridge Regression is a technique used to estimate the coefficients of a linear regression model, which helps to prevent overfitting by adding a penalty term to the loss function."
"Ridge Regression is a method used for estimating the coefficients of multiple-regression models when the input variables are highly correlated."
"Ridge Regression is a method used for regression analysis that adds a penalty term to the loss function to prevent overfitting."
"Ridge Regression is a type of linear regression that uses a regularization term to prevent overfitting, which is mentioned in the provided text."
"Ridge Regression is a regularization technique used to prevent overfitting in the readout layer of the Echo State Network."</data>
      <data key="d2">18e4624a6da9e8e6d9b9b2ed260bf9b2,1db191f05801d40d5a346febd10d3352,41fa16855df7da666dc6fc38d2f8ee53,4b0fe17444b892af954d2561fec36eb6,593080a95ef7640b3925b07cad1bedd4,688ebc7151bc148ac24dc7e2727d7afe,71f966d00b6d0eceb580d00b9cb86b1e,77c3759b4ed32509aaf1403c6fa8030f,87757855658e1d198ec49a3290760dd5,b5b73413fbe4ab8b61c4a939fe6c6a2b,ed28ba3543e07641536ff1eb5e0749dd,fe90abb0dde126fafbf44782aeb6738c</data>
    </node>
    <node id="&quot;OVERFITTING&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Overfitting occurs when a model performs well on training data but poorly on new, unseen data."

"Overfitting occurs when a model learns the training data too well, including its noise and irrelevant details, resulting in poor generalization on new, unseen data."
"Overfitting is a problem in machine learning where a model learns the training data too well, including noise and irrelevant details, leading to poor generalization on new data."
</data>
      <data key="d2">173a2da2c7ea80f95b04db8422ced004,4b0fe17444b892af954d2561fec36eb6,77c3759b4ed32509aaf1403c6fa8030f,87757855658e1d198ec49a3290760dd5,b09c66bc81fd63720bef0cfa941ee65b</data>
    </node>
    <node id="&quot;MULTICOLLINEARITY&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Multicollinearity is a situation where two or more independent variables are highly correlated."
</data>
      <data key="d2">4b0fe17444b892af954d2561fec36eb6,b5b73413fbe4ab8b61c4a939fe6c6a2b</data>
    </node>
    <node id="&quot;FEEDBACK CONNECTIONS&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Feedback Connections in Reservoir Computing architectures help stabilize and control the activity of neurons in the reservoir, maintaining a balance between sensitivity to input signals and robustness against noise."
"Feedback Connections are structural links between nodes in a network that allow for recurrent information flow, enabling the network to utilize its past activations to influence current processing."
"Feedback connections are connections from the readout to the input, which can be used for generating signals or long term forecasting."

"Feedback connections are a feature of ESNs that allow nodes to access the state of other nodes with a time delay of one timestep."
"Feedback Connections are a technique used in reservoir computing models to improve data processing and prediction."</data>
      <data key="d2">3ecffab3c205dece73b47f9a7004fc89,7f2d69f9a9baca70ffd25a6865189206,b5b73413fbe4ab8b61c4a939fe6c6a2b,c82c9d05b211ff65131f70eb8cb13513,cf15a09e77b695a117e1cca05461aea2,ead6383a44acd8ebd17907b85a910455</data>
    </node>
    <node id="&quot;RESERVOIR NEURONS&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Reservoir Neurons in Reservoir Computing architectures process input signals, and their connections do not need to be trained as they are predefined."
"Reservoir neurons are the individual units within a reservoir that process and store information from the input data, which are activated and visualized in the provided code."</data>
      <data key="d2">a58317c7e13f27d513fc7671fd187ecb,b5b73413fbe4ab8b61c4a939fe6c6a2b</data>
    </node>
    <node id="&quot;RANDOM HIGH-DIMENSIONAL VECTOR&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"A Random High-Dimensional Vector refers to the activations of the reservoir in Echo State Networks, which capture intricate patterns and dynamics of the input data."
"A Random High-Dimensional Vector refers to the activations of the reservoir in Echo State Networks, which capture intricate patterns and dynamics of the input data."</data>
      <data key="d2">0e6f0f7cd882a638ecb571ef36068868,82a734e7c7ada95b1c99783140dd7168</data>
    </node>
    <node id="&quot;READOUT LAYER&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"The Readout Layer is a component of Echo State Networks that is trained to decode the high-dimensional activation vectors from the reservoir and produce accurate predictions."
"Readout Layer is a component of an Echo State Network (ESN) that processes the output data."
"Readout Layer is a part of a neural network model that processes the combined input vector to produce an output."</data>
      <data key="d2">0e6f0f7cd882a638ecb571ef36068868,4da651284dbab3f68dc3cae41e6e0311,a35f6cae32a3d24b18ee17ec0471a9d4</data>
    </node>
    <node id="&quot;RIDGE NODE&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"A Ridge Node is a form of regularized linear regression used to create the readout in Echo State Networks, which helps prevent overfitting and ensures the model generalizes well to new data."
"Ridge node is a type of node mentioned in the text, which is able to perform regularized linear regression on the reservoir&#8217;s activations."</data>
      <data key="d2">0e6f0f7cd882a638ecb571ef36068868,9b360c6a33aafa6827417de5bd4faa82</data>
    </node>
    <node id="&quot;GITHUB&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"GitHub is a platform used to host and share the code and resources mentioned in the text, such as the first tutorial on Echo State Networks."
"GitHub is a web-based hosting service for version control using Git, where the first tutorial on ReservoirPy is located."
"GitHub is mentioned as the repository where new implementations are regularly added to ReservoirPy."</data>
      <data key="d2">0e6f0f7cd882a638ecb571ef36068868,77c3759b4ed32509aaf1403c6fa8030f,fcac967511cf2b019fd856e23d2e91d9</data>
    </node>
    <node id="&quot;ECHO STATE NETWORK (ESN)&quot;">
      <data key="d0">"TECHNOLOGY"</data>
      <data key="d1">"Echo State Network (ESN) is a type of recurrent neural network used for time series prediction and reservoir computing."
"Echo State Network (ESN) is a type of recurrent neural network that utilizes a reservoir to process input data and a readout layer to process output data."
"Echo State Network (ESN) is a type of recurrent neural network that uses a reservoir of nodes to process input data."
"Echo State Network (ESN) is a type of neural network used for time series prediction and analysis."
"Echo State Network (ESN) is a type of recurrent neural network used for time series prediction and other tasks, which utilizes feedback connections to incorporate past activations into current processing."
"Echo State Network (ESN) is a type of recurrent neural network that uses a sparsely connected reservoir to store past information and a readout layer to produce outputs."
"ESN is a type of network with a sparsely connected random hidden layer, used for reproducing certain time series."
"Echo State Network (ESN) is a type of recurrent neural network used for time series prediction and data analysis."
"Echo State Network (ESN) is a type of Recurrent Neural Network (RNN) that operates a random, large, fixed neural network with the input signal."</data>
      <data key="d2">1365a36c76afc697ac626fd0f784804a,32f8cfb6373e6cb4d6daa32e52aa74fc,3ecffab3c205dece73b47f9a7004fc89,4da651284dbab3f68dc3cae41e6e0311,57a27a1504a5ef7d330172c0ac1085c9,77c3759b4ed32509aaf1403c6fa8030f,a4b801e70cf2ba3a3101d34899450087,a8c0edd2cdddb7d6d899284063b541f5,b641b2be224e677674f7d3523e87ccde</data>
    </node>
    <node id="&quot;TIME CONSTANT&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Time Constant is a parameter in an Echo State Network (ESN) that affects how quickly the neurons in the reservoir update their states in response to inputs."</data>
      <data key="d2">77c3759b4ed32509aaf1403c6fa8030f</data>
    </node>
    <node id="&quot;LEAKING RATE&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Leaking Rate is a parameter in an Echo State Network (ESN) that controls the rate at which neurons forget previous states."
"Leaking Rate is a parameter used in Reservoir Computing to control the rate at which the reservoir state decays over time."
"Leaking Rate is a parameter in Reservoir Computing that controls the rate at which the state of the reservoir decays over time."
"Leaking Rate is a parameter that controls the time constant of the ESN, influencing the inertia and recall of previous states."
"Leaking Rate is a parameter mentioned in the text, which is log-uniformly distributed between 1e-3 and 1."
"Leaking Rate is a parameter in Reservoir Computing that controls the rate at which information is lost from the reservoir."
"The Leaking Rate is a parameter being explored, which is log-uniformly distributed between 1e-3 and 1."</data>
      <data key="d2">0a9b132ecb1c4b63fdbb0e144295362e,26d78bc91458f47d4053954505c45f92,2d8ea1123f365fb047b024022ba4fdc4,65ba78d1f678e080bd930319c54234ef,77c3759b4ed32509aaf1403c6fa8030f,8553a88d9aaf4f71d359c721a1f6fa70,8ecf03267c90a64376f5040307d98195</data>
    </node>
    <node id="&quot;SPECTRAL RADIUS&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Spectral Radius is a property of the reservoir matrix in an Echo State Network (ESN) that determines the stability and memory capacity of the reservoir."
"Spectral Radius is a mathematical concept that determines the stability and memory capacity of the reservoir in an Echo State Network (ESN)."
"Spectral Radius is a hyper-parameter in Reservoir Computing that affects the stability and dynamics of the reservoir layer."
"Spectral radius is a term used in the context of reservoir computing models, referring to the maximum absolute eigenvalue of the reservoir matrix W."
"Spectral Radius is a mathematical concept used in the context of reservoirs, with values close to 1 associated with stable dynamics and values further from 1 associated with chaotic dynamics."
"Spectral Radius is a mathematical concept used in the context of a reservoir, with a value close to 1 having theoretical implications for the reservoir states."
"Spectral Radius is a parameter in Reservoir Computing that determines the stability and speed of the reservoir's dynamics."
"Spectral Radius is a parameter mentioned in the text, which is log-uniformly distributed between 1e-2 and 10."
"The Spectral Radius is a concept mentioned in the context of the Echo State Property and its relationship with the reservoir weight matrix."
"The Spectral Radius is a mathematical concept used to analyze the behavior of a Reservoir Weight Matrix."
"Spectral Radius is a property of a matrix in mathematics, which is mentioned in the context of initializing weight matrices."
"Spectral Radius is a parameter used to control the dynamics of the reservoir in the Echo State Network (ESN) model."
"Spectral Radius is a parameter in the Reservoir component of the ESN model that determines the stability of the system."
"Spectral Radius is a concept used in the provided code to describe the maximum eigenvalue of a matrix."
"Spectral Radius is a mathematical concept used in the analysis of matrices, which is mentioned in the context of a neural network component."
"Spectral Radius is a parameter in Reservoir Computing that determines the stability and dynamics of the reservoir."
"The Spectral Radius is a parameter being explored, which is log-uniformly distributed between 1e-2 and 10."</data>
      <data key="d2">01f8dd8235ba0d4cf0837b5ea958ec95,0a9b132ecb1c4b63fdbb0e144295362e,1365a36c76afc697ac626fd0f784804a,1f30b86a46d4819603edc730df816c49,26d78bc91458f47d4053954505c45f92,3b592e5ac113a5c031925f91a182baa6,4073cafddb73621f26061385c5570659,65ba78d1f678e080bd930319c54234ef,716940af834825642e01a3cb59a7e006,72e6eee633bcb5b1458c4cee3975cee1,77c3759b4ed32509aaf1403c6fa8030f,82f7e4647b9da5d5063fe92613f4fbcb,8ecf03267c90a64376f5040307d98195,94fd1ebf256db17e4ac2255b89caa473,a9f53979e9dbe6b936ff3374c73006dd,b957e1bf5bf175c7630222ca742c7933,ff860bc63e3d697a6183c0b850689048</data>
    </node>
    <node id="&quot;ECHO STATE NETWORKS (ESNS)&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Echo State Networks (ESNs) are a type of recurrent neural network that use a reservoir of interconnected neurons to process input data."
"ESNs are a type of recurrent neural network used for time series prediction and analysis."
"Echo State Networks (ESNs) are a type of recurrent neural network used for training and prediction tasks."
"Echo State Networks (ESNs) are a type of recurrent neural network that uses a sparsely connected reservoir to process sequential data."
"Echo State Networks (ESNs) are a type of recurrent neural network used for time series prediction and generation."
"ESNs are a type of recurrent neural network used for time series prediction and generation."
"Echo State Networks (ESNs) are a type of reservoir computing model used to encode inputs in a high-dimensional space and predict outputs."
"Echo State Networks (ESNs) are a type of model that reservoirpy focuses on, particularly in its design and training."
"Echo State Networks (ESNs) are a type of recurrent neural network used for time series prediction, mentioned in the text."
"Echo State Networks (ESNs) are a type of Reservoir Computing architecture supported by ReservoirPy."
"Echo State Networks (ESNs) are a type of recurrent neural network architecture built using a reservoir and a readout, and they are created using ReservoirPy."</data>
      <data key="d2">01f8dd8235ba0d4cf0837b5ea958ec95,0c3779349544e78c4d650ccf76623127,0d922ae20673124fc4588949e3863ed0,18910a60b2547ec3133340f42c45bb47,37549a8af907ce182bd36eec43002a7d,4b78fdc153f982e64291112395c316c7,74c073137c970e32982756d008532cb8,a2b183778107462d474c53e4ec0a9221,af2db1cc5ab6b16acae2c93d3facb668,d0a69d653d08e58959dd8d0f2033e697,fa7c410cf411eb68eb517e23427ec1c8</data>
    </node>
    <node id="&quot;RESERVOIR MATRIX&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Reservoir Matrix is a component of an Echo State Network (ESN) that represents the connections between the reservoir neurons."</data>
      <data key="d2">01f8dd8235ba0d4cf0837b5ea958ec95</data>
    </node>
    <node id="&quot;RESERVOIR DYNAMICS&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Reservoir Dynamics refers to the behavior of the reservoir neurons in an Echo State Network (ESN), which can be influenced by the spectral radius."</data>
      <data key="d2">01f8dd8235ba0d4cf0837b5ea958ec95</data>
    </node>
    <node id="&quot;CHAOTICITY&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Chaoticity is a measure of the complexity and unpredictability in the behavior of the reservoir neurons, which can be altered by changing the spectral radius."</data>
      <data key="d2">01f8dd8235ba0d4cf0837b5ea958ec95</data>
    </node>
    <node id="&quot;NP.PI&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"np.pi is a mathematical constant representing the ratio of a circle's circumference to its diameter, approximately equal to 3.14159."
"np.pi represents the mathematical constant &#960; (pi), approximated in python by 3.141592653589793."</data>
      <data key="d2">01f8dd8235ba0d4cf0837b5ea958ec95,475ca77684df5045266ddf079f2e37f1</data>
    </node>
    <node id="&quot;NP.SIN&quot;">
      <data key="d0">"FUNCTION"</data>
      <data key="d1">"np.sin is a function in numpy that computes the sine of all elements in the input array."</data>
      <data key="d2">475ca77684df5045266ddf079f2e37f1</data>
    </node>
    <node id="&quot;NP.LINSPACE&quot;">
      <data key="d0">"FUNCTION"</data>
      <data key="d1">"np.linspace is a function in numpy that returns evenly spaced numbers over a specified interval."</data>
      <data key="d2">475ca77684df5045266ddf079f2e37f1</data>
    </node>
    <node id="&quot;NP.RESHAPE&quot;">
      <data key="d0">"FUNCTION"</data>
      <data key="d1">"np.reshape is a function in numpy that gives a new shape to an array without changing its data."</data>
      <data key="d2">475ca77684df5045266ddf079f2e37f1</data>
    </node>
    <node id="&quot;SINGLE TIMESTEP OF DATA&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"A single timestep of data refers to one discrete time point in a sequence of data, representing the value of the variable being measured at that particular moment in time."</data>
      <data key="d2">475ca77684df5045266ddf079f2e37f1</data>
    </node>
    <node id="&quot;TIMESTEP&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Timestep is a discrete time point in a sequence of data used for training or evaluating a model in time series analysis."
"A Timestep is a single point in time within a Timeseries, representing the data value at that specific moment."
"A Timestep is a single data point collected or recorded at a specific time interval, representing a moment in time."
"Timestep is a term used to refer to a single point in time, mentioned in the text."
"Timestep is a single point in a timeseries, used for triggering nodes such as Reservoir in ReservoirPy."</data>
      <data key="d2">0e0afab060f214d46062c9886e762002,56cde5dc9d350498c1544cd57733ca8f,af2db1cc5ab6b16acae2c93d3facb668,c41b9b19460dc63e06639ea4bbbd1515,fa082948fa919150e9c06c6f5c1b53b0</data>
    </node>
    <node id="&quot;INPUT DATA&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Input Data is the sequence of data used for training or evaluating a model, such as hourly temperature data."
"Input Data refers to the data fed into the model, which is bypassed by the reservoir and directly fed to the readout layer."
"Input Data refers to the timeseries data used to train and test the ESN model."
"Input Data refers to the data used to train the ESN model, in this case, a sine wave."
</data>
      <data key="d2">1365a36c76afc697ac626fd0f784804a,4da651284dbab3f68dc3cae41e6e0311,56cde5dc9d350498c1544cd57733ca8f,693e4d1e43289f46866236c10207a17e,7b294b788fe5ee385d08c4aabe2ca71d</data>
    </node>
    <node id="&quot;STATE VECTOR&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"State Vector is the output of the reservoir neurons, representing the internal state of the reservoir at a given time."</data>
      <data key="d2">56cde5dc9d350498c1544cd57733ca8f</data>
    </node>
    <node id="&quot;NULL&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Null is a special value used to represent the absence of a value or an empty value in programming."</data>
      <data key="d2">56cde5dc9d350498c1544cd57733ca8f</data>
    </node>
    <node id="&quot;PROGRAMMING&quot;">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">56cde5dc9d350498c1544cd57733ca8f</data>
    </node>
    <node id="&quot;NULL VECTOR&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Null Vector is a vector with all elements equal to zero, often used as an initial state for reservoir computing."</data>
      <data key="d2">baeb61b8c35e75d37a338fafd6a417fa</data>
    </node>
    <node id="&quot;SHAPE ATTRIBUTE&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Shape Attribute is used to determine the size and structure of arrays, such as the state vector in reservoir computing."</data>
      <data key="d2">baeb61b8c35e75d37a338fafd6a417fa</data>
    </node>
    <node id="&quot;EMPTY FUNCTION&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Empty Function is used to create a new array without initializing the entries, allowing for later data filling."</data>
      <data key="d2">baeb61b8c35e75d37a338fafd6a417fa</data>
    </node>
    <node id="&quot;OUTPUT DIMENSION&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Output Dimension refers to the size of the output from a reservoir, which is used to specify the size of the state vector."</data>
      <data key="d2">baeb61b8c35e75d37a338fafd6a417fa</data>
    </node>
    <node id="&quot;NP.EMPTY&quot;">
      <data key="d0">"FUNCTION"</data>
      <data key="d1">"np.empty is a function that creates a new array of the specified shape and size, but without initializing the entries, resulting in an array with random values."</data>
      <data key="d2">53e61c078c8f43b7a9b0efb347f394a6</data>
    </node>
    <node id="&quot;RESERVOIR.OUTPUT_DIM&quot;">
      <data key="d0">"ATTRIBUTE"</data>
      <data key="d1">"reservoir.output_dim is an attribute that specifies the number of output dimensions of the reservoir, defining the second dimension of the 'states' array."</data>
      <data key="d2">53e61c078c8f43b7a9b0efb347f394a6</data>
    </node>
    <node id="&quot;STATES&quot;">
      <data key="d0">"VARIABLE"</data>
      <data key="d1">"states is a variable that represents an array used to store the activations of neurons in a reservoir computing system.""States are variables that store the internal state of a system or model, representing the current condition or configuration of the system, and are used to calculate the next state based on the current state and input."
"States are specific conditions or configurations within a system or environment, often used in contexts like reinforcement learning."
"States refer to the internal representations or memory of a reservoir node, which can be reset, modified, or fed to a node at any time."</data>
      <data key="d2">53e61c078c8f43b7a9b0efb347f394a6,54b1174770e13d4a2bc0916db477cc56,9e84667b4aeb0789808517f0912043ce</data>
      <data key="d3">"VARIABLES"</data>
    </node>
    <node id="&quot;STATES[:, :20]&quot;">
      <data key="d0">"SLICE"</data>
      <data key="d1">"states[:, :20] is a slice notation that selects all rows in the 'states' array and the first 20 columns, used to access and visualize the activations of the first 20 neurons across all timesteps in the timeseries."</data>
      <data key="d2">53e61c078c8f43b7a9b0efb347f394a6</data>
    </node>
    <node id="&quot;FOR-LOOP&quot;">
      <data key="d0">"CONTROL FLOW STATEMENT"</data>
      <data key="d1">"A for-loop is a control flow statement used to repeatedly execute a block of code a certain number of times or over a sequence of elements, useful for tasks like processing each element in a dataset or performing a series of computations multiple times."
"A for-loop is a control flow statement in programming used to repeatedly execute a block of code a certain number of times or over a sequence of elements."</data>
      <data key="d2">53e61c078c8f43b7a9b0efb347f394a6,54b1174770e13d4a2bc0916db477cc56</data>
    </node>
    <node id="&quot;FEATURES&quot;">
      <data key="d0">"ATTRIBUTES"</data>
      <data key="d1">"Features are attributes or properties that describe and represent data points, used as input for machine learning models to learn patterns and make predictions."
"Features are attributes or properties associated with an input or sample, such as pixels in an image or variables in a dataset."
"Features are attributes associated with inputs or samples, such as pixels in images or Euclidean distance in states, used to train machine learning models."
"Features refer to the individual variables or measurements in the input data."</data>
      <data key="d2">53e61c078c8f43b7a9b0efb347f394a6,54b1174770e13d4a2bc0916db477cc56,9e84667b4aeb0789808517f0912043ce,e72d27e122bf954a854a23a367c9c609</data>
    </node>
    <node id="&quot;MODEL&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"A model is a function that takes inputs and produces outputs based on learned patterns or relationships."
"The Model is a machine learning system that learns by adjusting its parameters to minimize errors and make accurate predictions."
"Model refers to a higher-level structure that integrates nodes, such as ESN, to perform specific tasks."
"Model refers to a mathematical representation of a system or process, used to make predictions or decisions."
"Model is a machine learning model used for training and testing."
"A Model is a graph of nodes that can be trained as a whole, allowing for complex operations to be represented."
"Model refers to the overall structure of a reservoir model, which includes the reservoir and readout components."
"Model is a component in a reservoir model, used for data processing and analysis."
"The Model is a combination of the Reservoir and Ridge components, used for time series prediction."
"Model is a sequence-to-vector model used for classification tasks."
"Model is a concept used to refer to the machine learning model being created and evaluated."</data>
      <data key="d2">00648b24263129fdae8652f1a3339041,3ff318aebcb07ca141d0a40730d96c7c,46dcc47b4358d3895c1eeb1182c6f997,75e530c1a04e30b373dc7cc68e3ad819,8648b5740b93d805f139d9745e1171e8,a0feae89e52a4291db0a512a3a102d8e,c41b9b19460dc63e06639ea4bbbd1515,dc46bcef51e88747b544f7efb111203a,dd41fca2f283c4f8c8d1cba5b836da45,df811c27ddc46d5b90c5863a52666a4b,eebc9d7d2b66e3898b7d068c38fd200f</data>
    </node>
    <node id="&quot;SUPERVISED LEARNING&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Supervised Learning is a type of machine learning where models learn from data that has already been labeled, using techniques such as regression and classification."
"Supervised Learning is a type of machine learning where models learn from data that has already been labeled, using techniques such as regression and classification."
"Supervised Learning is a concept mentioned in the text."</data>
      <data key="d2">58330f62da357197950f63388e4ceaff,dbca0570761b1698d32f0c0bfb593b1a,e72d27e122bf954a854a23a367c9c609</data>
    </node>
    <node id="&quot;UNSUPERVISED LEARNING&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Unsupervised Learning is a type of machine learning where models try to find patterns in data that doesn't have labels, using techniques such as grouping and clustering."
"Unsupervised Learning is a type of machine learning where models try to find patterns in data that doesn't have labels, using techniques such as clustering."
"Unsupervised Learning is a type of machine learning where the model learns patterns from unlabeled data."</data>
      <data key="d2">58330f62da357197950f63388e4ceaff,7b6ff30ef255db2d2c68326d78cf0115,e72d27e122bf954a854a23a367c9c609</data>
    </node>
    <node id="&quot;IMAGE CLASSIFICATION&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Image Classification is a machine learning task where models are trained to categorize images into different classes based on visual features."</data>
      <data key="d2">e72d27e122bf954a854a23a367c9c609</data>
    </node>
    <node id="&quot;MACHINE TRANSLATION&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Machine Translation is a natural language processing task where models are trained to translate text from one language to another."</data>
      <data key="d2">e72d27e122bf954a854a23a367c9c609</data>
    </node>
    <node id="&quot;REINFORCEMENT LEARNING&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Reinforcement Learning is a type of machine learning where models learn to make decisions by taking actions in an environment and receiving rewards or penalties."</data>
      <data key="d2">e72d27e122bf954a854a23a367c9c609</data>
    </node>
    <node id="&quot;CONTEXT MANAGER&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"A Context Manager in Python is a construct that allows for setup and cleanup actions around a block of code, using the `with` statement. In the case of the reservoir, it temporarily changes the state of the reservoir for operations inside its block."</data>
      <data key="d2">58330f62da357197950f63388e4ceaff</data>
    </node>
    <node id="&quot;FROM_STATE&quot;">
      <data key="d0" />
      <data key="d1">
"from_state is a parameter used to initialize the reservoir with a specific state at the start of a simulation or training process."</data>
      <data key="d2">58330f62da357197950f63388e4ceaff,cb71a9bc3b00e7abcd1a53004abdea69</data>
    </node>
    <node id="&quot;WITH_STATE&quot;">
      <data key="d0" />
      <data key="d1">
"with_state is a parameter used to continue the simulation or training process from a specific state, updating the reservoir's state during its operation."</data>
      <data key="d2">58330f62da357197950f63388e4ceaff,cb71a9bc3b00e7abcd1a53004abdea69</data>
    </node>
    <node id="&quot;RUN(X)&quot;">
      <data key="d0">"EVENT"</data>
      <data key="d1">"run(X) is a method that processes the entire timeseries X through the reservoir node, updating the reservoir's state at each timestep based on the input data."</data>
      <data key="d2">cb71a9bc3b00e7abcd1a53004abdea69</data>
    </node>
    <node id="&quot;RECURRENT NETWORK&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Recurrent network is a type of artificial neural network characterized by bi-directional flow of information, allowing outputs from some nodes to affect future inputs."</data>
      <data key="d2">cb71a9bc3b00e7abcd1a53004abdea69</data>
    </node>
    <node id="&quot;ARTIFICIAL NEURAL NETWORK&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"An Artificial Neural Network (ANN) is a machine learning model inspired by biological neural networks in animal brains. It consists of connected units called neurons, which process and transmit signals through connections with adjustable weights. ANNs are used for tasks like predictive modeling and adaptive control, learning from data through training methods."
"An artificial neural network (ANN) is a machine learning model inspired by biological neural networks in animal brains, used for tasks like predictive modeling and adaptive control."
"Artificial Neural Network is a broader term that refers to a network of interconnected nodes or neurons, which can be either feedforward or recurrent."</data>
      <data key="d2">7e6b5dcab1703bfec57161a4d5543848,e1bf3df1ff001613df1451d6d8bf3ee4,f5b970cf7201f4a918d8bd6a1267657c</data>
    </node>
    <node id="&quot;RESERVOIR NODE&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"A reservoir node is a component of a Recurrent Neural Network that updates the reservoir's state at each timestep based on the input data. It returns the activations of the reservoir neurons for the whole timeseries, transforming the input data into high-dimensional representations."
"The Reservoir Node is a component of the ESN Model that processes the data input, storing and manipulating the information for further processing."
"Reservoir Node is a component of the Echo State Network (ESN) model that processes the input data."</data>
      <data key="d2">32f8cfb6373e6cb4d6daa32e52aa74fc,55ea2a468a24d087a0563cf9fb654dc0,e1bf3df1ff001613df1451d6d8bf3ee4</data>
    </node>
    <node id="&quot;RIDGE READOUT&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Ridge Readout is an offline readout that uses linear regression to learn the connections from the reservoir to the readout neurons."
"A Ridge Readout is a type of readout node used in Reservoir Computing, which utilizes ridge regression to learn the connections from the reservoir to the readout neurons."
"Ridge Readout is a machine learning technique that uses a regularization term to prevent overfitting and improve the model's generalization."
"The Ridge Readout is a type of readout mentioned in the text, which uses linear regression and ridge regularization to solve a task."
"Ridge Readout is a specific type of readout node used in the Reservoir Computing method."</data>
      <data key="d2">5d3baa9818a4e01fe1196c43378a2cea,7e6b5dcab1703bfec57161a4d5543848,87757855658e1d198ec49a3290760dd5,b09c66bc81fd63720bef0cfa941ee65b,f2d5625f36aa4cb036089ce89ec607eb</data>
    </node>
    <node id="&quot;ONLINE READOUTS&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Online Readouts are readouts that can update their weights continuously as new data arrives, making them suitable for real-time applications."</data>
      <data key="d2">7e6b5dcab1703bfec57161a4d5543848</data>
    </node>
    <node id="&quot;WIKIPEDIA PAGE ON NEURAL NETWORKS&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"The Wikipedia page on Neural Networks provides detailed information about artificial neural networks and their applications."</data>
      <data key="d2">7e6b5dcab1703bfec57161a4d5543848</data>
    </node>
    <node id="&quot;FITTING PROCESS&quot;">
      <data key="d0">"EVENT"</data>
      <data key="d1">"The Fitting Process is the training phase where a model learns the connections from the reservoir to the readout neurons based on the provided data."</data>
      <data key="d2">87757855658e1d198ec49a3290760dd5</data>
    </node>
    <node id="&quot;RIDGE PARAMETER&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Ridge Parameter is a hyperparameter in Ridge Readout that controls the strength of the regularization term, with a value of 1e-7 used to prevent overfitting."
"The Ridge Parameter is a regularization term used in machine learning models to prevent overfitting."</data>
      <data key="d2">173a2da2c7ea80f95b04db8422ced004,b09c66bc81fd63720bef0cfa941ee65b</data>
    </node>
    <node id="&quot;TEACHER VECTORS&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Teacher Vectors are the target outputs used during the training of a machine learning model."
"Teacher Vectors are the actual target values used as feedback in Forced Feedback technique."
"Teacher Vectors are the actual target values used as feedback during the training phase of an Echo State Network."</data>
      <data key="d2">0d922ae20673124fc4588949e3863ed0,173a2da2c7ea80f95b04db8422ced004,3ecffab3c205dece73b47f9a7004fc89</data>
    </node>
    <node id="&quot;TRAINING TASK&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"A Training Task is a specific objective that a machine learning model needs to achieve during training, such as prediction or classification."
"The Training Task is the process of specifying the objective for the Model, such as predicting future values or classifying data."
"The Training Task is mentioned in the text, where the Ridge Readout is trained to create a mapping from input to target timeseries to solve a specific task."
"Training Task is the process of training the ESN model using a subset of the input and target data."</data>
      <data key="d2">09ea760dd2f000c961d1cfd4ea795da5,173a2da2c7ea80f95b04db8422ced004,5d3baa9818a4e01fe1196c43378a2cea,c41b9b19460dc63e06639ea4bbbd1515</data>
    </node>
    <node id="&quot;TIMESERIES&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"A Timeseries is a sequence of data points collected or recorded at successive time intervals, capturing the evolution of data over time."
"A Timeseries is a sequence of Timesteps, capturing the evolution of data over time."
"Timeseries is a data set being used in the context of training the ESN to make one-step-ahead forecasts."
"Timeseries is a sequence of data points indexed in time order, used in the context of the Echo State Network."
"Timeseries refers to a sequence of data points indexed in time order, used to visualize and analyze the behavior of the Mackey-Glass Equation."
"Timeseries is a sequence of data points collected at regular time intervals, used for prediction and generation tasks."
"Timeseries are sequential data used in the tutorial to train and perform predictions with an Echo State Network (ESN) created using ReservoirPy."
"Timeseries is a sequence of data points, which can be used as input for nodes such as Reservoir in ReservoirPy."
"Timeseries is a sequence of data points collected at regular time intervals, used as input for the Reservoir."
"Timeseries is a sequence of data points indexed in time order, which is being generated and compared to real timeseries data in the text."</data>
      <data key="d2">0e0afab060f214d46062c9886e762002,518f1e492b92054cf2f5c5289444da02,70db98fabc82fc96ecf8cc2c023b586b,74c073137c970e32982756d008532cb8,7f70879016c133fe58e4838172a69613,c41b9b19460dc63e06639ea4bbbd1515,c4f5a27caf9dd9c1d972492c1147efa0,f730c6800099724052a2d061f3cd8c2e,f7f7dbc1e69b3b0e801bc5ba9c0cabca,fa082948fa919150e9c06c6f5c1b53b0</data>
    </node>
    <node id="&quot;READOUT NODE&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"The Readout Node is a component of the Model that is trained as a standalone node to perform a specific task, such as predicting future values or classifying data."
"The Readout Node is a component in a machine learning model that takes the internal states of the Reservoir and makes predictions based on them."
"The Readout Node is a component of the ESN Model that outputs the final processed data."
"Readout Node is a component of the Echo State Network (ESN) model that produces the output based on the processed input data."</data>
      <data key="d2">32f8cfb6373e6cb4d6daa32e52aa74fc,55ea2a468a24d087a0563cf9fb654dc0,c41b9b19460dc63e06639ea4bbbd1515,fa082948fa919150e9c06c6f5c1b53b0</data>
    </node>
    <node id="&quot;WARMUP PARAMETER&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"The Warmup Parameter is a setting used to discard a specified number of initial Timesteps when training the Readout Node."
"The Warmup Parameter is used to discard a specified number of initial timesteps when training the readout in Echo State Networks, ensuring the model trains on stable and relevant activations."</data>
      <data key="d2">fa082948fa919150e9c06c6f5c1b53b0,fa7c410cf411eb68eb517e23427ec1c8</data>
    </node>
    <node id="&quot;CANONICAL METHOD&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"The Canonical Method is a common approach for creating and training Echo State Networks, involving training the reservoir and readout as a connected model."</data>
      <data key="d2">fa7c410cf411eb68eb517e23427ec1c8</data>
    </node>
    <node id="&quot;NON-CANONICAL METHOD&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"The Non-Canonical Method is an alternative approach for creating and training Echo State Networks, involving training the reservoir and readout separately."</data>
      <data key="d2">fa7c410cf411eb68eb517e23427ec1c8</data>
    </node>
    <node id="&quot;FORECASTING&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Forecasting is the process of making predictions about future data points based on past data, analyzing patterns and trends in existing data to estimate future values."
"Forecasting is the process of making predictions about future data points based on past data, involving the analysis of patterns and trends in existing data."
"Forecasting is the process of predicting future values based on past data."
"Forecasting is the process of predicting future values based on past data, in this case, 10 steps ahead for the Double-Scroll Attractor."
"Forecasting is a specific type of prediction that involves making predictions about specific points in time."

"Forecasting is the process of predicting future values based on historical data, which is demonstrated in the provided code using the ReservoirPy library."</data>
      <data key="d2">2d8ea1123f365fb047b024022ba4fdc4,423d3b5ec1acc9a4cb448a15d3b6b595,4ac00cf37a752d89d55a749c01c6f6fd,9261efcc24379d9c0b2d35a2fde8275d,b2beacacc8c190393e4583a69518378c,cc12e22afbf2ef530100516df59d24f2,fa7c410cf411eb68eb517e23427ec1c8</data>
    </node>
    <node id="&quot;MATRIX&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Matrix refers to a mathematical structure that represents a collection of numbers arranged in rows and columns, often used in various mathematical and computational operations."</data>
      <data key="d2">cc12e22afbf2ef530100516df59d24f2</data>
    </node>
    <node id="&quot;WEIGHT&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Weight in a matrix refers to the individual numerical values that define the strength of connections between nodes in a neural network."</data>
      <data key="d2">cc12e22afbf2ef530100516df59d24f2</data>
    </node>
    <node id="&quot;PARALLELIZATION&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Parallelization is the process of dividing a computational task into smaller sub-tasks that can be executed simultaneously on multiple processors or cores to improve performance and efficiency."
"Parallelization is the process of dividing a computational task into smaller sub-tasks that can be executed simultaneously on multiple processors or cores."
"Parallelization is the process of distributing a task across multiple processors or cores to speed up computation and reduce overall processing time."
"Parallelization refers to the distribution of computational tasks across multiple processors or cores to speed up computation and reduce overall processing time."
"Parallelization refers to the process of running multiple tasks simultaneously to speed up computation."</data>
      <data key="d2">1cbfde86d1258f2b267135412e50a590,593080a95ef7640b3925b07cad1bedd4,a16039f06e545c915f8e7668c39c3e5c,cc12e22afbf2ef530100516df59d24f2,ead6383a44acd8ebd17907b85a910455</data>
    </node>
    <node id="&quot;NEURAL NETWORK&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Neural Network is a computational model inspired by the structure and function of the human brain, used for various tasks such as pattern recognition, decision-making, and prediction."
"Neural Network is a type of machine learning model inspired by the structure and function of the human brain. It consists of interconnected nodes or neurons that process information and learn patterns from data."
"Neural Network is a type of machine learning model used for training, which includes the ESN network."</data>
      <data key="d2">894d59d781535ca85389c4226715c007,a16039f06e545c915f8e7668c39c3e5c,cc12e22afbf2ef530100516df59d24f2</data>
    </node>
    <node id="&quot;TIME SERIES DATA&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Time Series Data refers to a sequence of data points collected at regular time intervals, such as predicting the next values of a sine wave."
"Time Series Data are observations that have a natural temporal ordering, making Time Series Analysis distinct from cross-sectional studies and spatial data analysis."
"Time Series Data refers to a sequence of data points collected at regular time intervals."
"Time Series Data refers to a sequence of data points collected at regular time intervals."</data>
      <data key="d2">2bcc39da2ecef3011cc3da428fca5dd5,8e69dad9d25c6b8f037f22592687e195,a000a3fbf1f8fad62e4c25b495858c79,cc12e22afbf2ef530100516df59d24f2</data>
    </node>
    <node id="&quot;MANUAL MANAGEMENT&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Manual Management refers to the process of manually managing state transitions and fitting processes outside the integrated model workflow, potentially using different configurations or additional preprocessing steps."</data>
      <data key="d2">cc12e22afbf2ef530100516df59d24f2</data>
    </node>
    <node id="&quot;DEEP ARCHITECTURE&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Deep Architecture refers to a neural network with multiple hidden layers between the input and output layers, allowing it to learn and represent more complex patterns and features in the data."</data>
      <data key="d2">a16039f06e545c915f8e7668c39c3e5c</data>
    </node>
    <node id="&quot;MACHINE LEARNING&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Machine Learning is a field of artificial intelligence that focuses on developing algorithms and statistical models that enable computers to learn patterns and make predictions or decisions based on data."
"Machine Learning is mentioned in the text as a field related to Reservoir Computing."
"Machine Learning is a field of artificial intelligence that enables systems to learn patterns and make predictions from data."</data>
      <data key="d2">136559fd2a1fbef4cc8a6b11abcb3eef,6de297d888d10db4c987b5eafc6398b2,a16039f06e545c915f8e7668c39c3e5c</data>
    </node>
    <node id="&quot;DEEP ARCHITECTURES&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Deep Architectures refer to models containing multiple layers of reservoirs, enabling the capture of complex patterns in data."
"Deep Architectures refer to the practice of combining nodes in various ways to create more complex structures than a simple reservoir and readout."</data>
      <data key="d2">8965403859beb43a6ab7e5c8c916b857,f0c8d4d322d73f46464e3e9f6914f2ee</data>
    </node>
    <node id="&quot;INPUT-TO-READOUT CONNECTIONS&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Input-to-readout connections in Echo State Networks allow the input data to be directly fed to the readout layer, bypassing the reservoir."
"Input-to-readout connections are direct connections from input to readout in more advanced ESNs, allowing for more complex modeling."
"Input-to-readout connections refer to the direct connections from input to readout in advanced ESNs, allowing for more complex data processing."
"Input-to-readout Connections refer to the connections between the input data and the readout layer in a reservoir computing model."</data>
      <data key="d2">71f966d00b6d0eceb580d00b9cb86b1e,8965403859beb43a6ab7e5c8c916b857,ead6383a44acd8ebd17907b85a910455,f1fc6fbc8158d3da070d55544041a2ca</data>
    </node>
    <node id="&quot;INPUT NODES&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Input Nodes are nodes in an Echo State Network (ESN) that receive and process the input data."</data>
      <data key="d2">b641b2be224e677674f7d3523e87ccde</data>
    </node>
    <node id="&quot;RESERVOIR NODES&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Reservoir Nodes are nodes in an Echo State Network (ESN) that store and process the input data, allowing the network to learn and capture patterns."</data>
      <data key="d2">b641b2be224e677674f7d3523e87ccde</data>
    </node>
    <node id="&quot;READOUT NODES&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Readout Nodes are nodes in an Echo State Network (ESN) that produce the final output based on the processed input data."</data>
      <data key="d2">b641b2be224e677674f7d3523e87ccde</data>
    </node>
    <node id="&quot;CHAINING&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Chaining refers to the sequential connection of nodes, such as input, reservoir, and readout nodes, to form a complete model in an Echo State Network (ESN)."</data>
      <data key="d2">b641b2be224e677674f7d3523e87ccde</data>
    </node>
    <node id="&quot;MANY-TO-ONE CONNECTIONS&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Many-to-one connections refer to a setup where multiple nodes or data sources are connected to a single node, allowing the aggregation of multiple inputs before feeding them into a single readout node."</data>
      <data key="d2">b641b2be224e677674f7d3523e87ccde</data>
    </node>
    <node id="&quot;ONE-TO-MANY CONNECTIONS&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"One-to-many connections refer to a setup where the output from a single node is distributed to multiple subsequent nodes, allowing the same data to be processed in different ways by different nodes."
"One-to-Many Connections refer to a setup where the output from a single node is distributed to multiple subsequent nodes, allowing the same data to be processed in different ways by different nodes."</data>
      <data key="d2">a35f6cae32a3d24b18ee17ec0471a9d4,b641b2be224e677674f7d3523e87ccde</data>
    </node>
    <node id="&quot;SPECIAL CONCAT NODE&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Special Concat Node is a component that combines inputs from different sources into a single vector."</data>
      <data key="d2">a35f6cae32a3d24b18ee17ec0471a9d4</data>
    </node>
    <node id="&quot;ITERABLES OF NODES&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Iterables of Nodes refer to using a collection of nodes in a neural network, allowing for flexible and complex connections, such as many-to-one or one-to-many connections."</data>
      <data key="d2">a35f6cae32a3d24b18ee17ec0471a9d4</data>
    </node>
    <node id="&quot;CONCAT NODE&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Concat Node is a special type of node that aggregates multiple input vectors into a single concatenated vector, allowing subsequent nodes to process the combined input."
"The Concat Node is a component that aggregates multiple input vectors into a single concatenated vector, allowing subsequent nodes to process this combined input."</data>
      <data key="d2">55ea2a468a24d087a0563cf9fb654dc0,e9f7bc2274e59b0767e1172a848ddca9</data>
    </node>
    <node id="&quot;ESN MODEL&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"The ESN Model is a data processing model that includes nodes such as input node, reservoir node, concat node, and readout node."
"ESN Model is a type of model that combines the input, reservoir, and readout components."
"ESN model is a combination of a Reservoir and Ridge, used for predicting timeseries."
"ESN Model is a type of model containing a reservoir and a readout, used for training and running on timeseries data."
"ESN Model is a machine learning model used for time series prediction, as demonstrated in the provided text."
"ESN Model is a type of neural network model created using the ReservoirPy library."
"ESN Model is a machine learning model used for time series forecasting, developed by Jaeger and Haas."</data>
      <data key="d2">52d001cd1786e3d9f36e0c57538bc21e,55ea2a468a24d087a0563cf9fb654dc0,58115d5a63315a84d9c8d4e6ddc98ffd,8294eed5fc10df1c118f9afa266910e4,8ade7819a5f8d1ec26e9bdbd059142e6,8c520b4037fe01ffce62d46b67175e67,973d44d321c7ceee7add295c60b085d2</data>
    </node>
    <node id="&quot;INPUT NODE&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"The Input Node is a component of the ESN Model that receives and processes the initial data input."</data>
      <data key="d2">55ea2a468a24d087a0563cf9fb654dc0</data>
    </node>
    <node id="&quot;DATA&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Data refers to the input data used in the Echo State Network (ESN) model."
"Data is a concept used in the context of a model, serving as input for the reservoir and readout nodes."
"Data is a component in a reservoir model, used for data processing and analysis."
"Data refers to the input and output data used in the reservoir computing model."</data>
      <data key="d2">069ae9388dfd52fec9c184c7168f64dd,32f8cfb6373e6cb4d6daa32e52aa74fc,8648b5740b93d805f139d9745e1171e8,cf15a09e77b695a117e1cca05461aea2</data>
    </node>
    <node id="&quot;CONCATENATE NODE&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Concatenate Node is a component of the Echo State Network (ESN) model that combines multiple inputs into a single input stream."</data>
      <data key="d2">32f8cfb6373e6cb4d6daa32e52aa74fc</data>
    </node>
    <node id="&quot;FEEDBACK CONNECTION&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Feedback Connection is a mechanism in the Echo State Network (ESN) model that allows the state of one node to influence another node with a one-timestep delay."
"Feedback Connection is a mechanism in an Echo State Network (ESN) that allows the state of one node to influence another node with a one-timestep delay, enabling the network to remember and utilize past information for current processing."
"Feedback Connection is a mechanism that allows the receiver node to access the state of the sender node with a one-timestep delay, creating a copy of the receiver holding a reference to the sender."
"A Feedback Connection is a type of connection between nodes that delays the signal, allowing for more complex operations to be represented."
"A feedback connection is an optional feature that feeds the activations of the readout back to the reservoir, helping to tame the reservoir neurons' activities."</data>
      <data key="d2">32f8cfb6373e6cb4d6daa32e52aa74fc,333ecf478bfbd4291de9f193bbf0443a,57a27a1504a5ef7d330172c0ac1085c9,711ec1b4879d910d0df0a477c9e240ba,dc46bcef51e88747b544f7efb111203a</data>
    </node>
    <node id="&quot;CONTROL SYSTEMS&quot;">
      <data key="d0">"EVENT"</data>
      <data key="d1">"Control systems is an application that uses past control signals to adjust future control actions, taking advantage of the dynamic capabilities of feedback connections."
"Control systems is an application that uses past control signals to adjust future control actions for better system stability."</data>
      <data key="d2">57a27a1504a5ef7d330172c0ac1085c9,c4b54c2da2dda7e660de7bd6de6f13b4</data>
    </node>
    <node id="&quot;'&gt;&gt;' OPERATOR&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"The '&gt;&gt;' operator is used to chain connections between nodes in sequence."</data>
      <data key="d2">c4b54c2da2dda7e660de7bd6de6f13b4</data>
    </node>
    <node id="&quot;'&lt;&lt;' OPERATOR&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"The '&lt;&lt;' operator creates a feedback connection, where the receiver node can access the state of the sender node with a one-timestep delay."</data>
      <data key="d2">c4b54c2da2dda7e660de7bd6de6f13b4</data>
    </node>
    <node id="&quot;'&lt;&lt;=' OPERATOR&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"The '&lt;&lt;=' operator also establishes a feedback connection but without creating a copy of the receiver node."</data>
      <data key="d2">c4b54c2da2dda7e660de7bd6de6f13b4</data>
    </node>
    <node id="&quot;IN-PLACE FEEDBACK CONNECTION&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"In-place Feedback Connection is a variant of the Feedback Connection that does not create a copy of the receiver node, allowing it to directly hold the reference to the sender node's state."</data>
      <data key="d2">333ecf478bfbd4291de9f193bbf0443a</data>
    </node>
    <node id="&quot;FORCED FEEDBACK&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Forced Feedback is a technique used in training Echo State Networks (ESNs) to provide teacher vectors as feedback to the reservoir during training."
"Forced Feedback is a training technique that uses teacher vectors (actual target values) as feedback to stabilize the training process and help the network learn more effectively."
"Forced feedback is an external feedback timeseries provided to a receiver node during runtime to replace missing feedback signals and maintain network functionality."</data>
      <data key="d2">0d922ae20673124fc4588949e3863ed0,3ecffab3c205dece73b47f9a7004fc89,9f1e5883a5f969a6d913beed5a5abd4f</data>
    </node>
    <node id="&quot;MODEL.FIT()&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Model.fit() is a method used to train an Echo State Network, allowing for the specification of parameters such as forced feedback."
"Model.fit() is a method used to train a model, such as an Echo State Network (ESN), on input data."</data>
      <data key="d2">3ecffab3c205dece73b47f9a7004fc89,b338d2dcc1fe6ccf42407444c02cad7c</data>
    </node>
    <node id="&quot;TEACHER FORCING&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Teacher Forcing is a training technique used in sequence modeling where the model is provided with the correct input at each time step during training, allowing it to learn the sequence more accurately."
"Teacher Forcing is a training technique used in sequence modeling where true output values are fed as inputs to the network during training."
"Teacher Forcing is a technique used during the generation of system states, where correct outputs are written into the output units."</data>
      <data key="d2">3ecffab3c205dece73b47f9a7004fc89,6a4432cd530b28770e2b903fe242a0d1,d0a69d653d08e58959dd8d0f2033e697</data>
    </node>
    <node id="&quot;SEQUENCE MODELING&quot;">
      <data key="d0" />
      <data key="d1">
"Sequence Modeling is a field of machine learning that deals with processing sequential data, such as time series or text."</data>
      <data key="d2">3ecffab3c205dece73b47f9a7004fc89,d0a69d653d08e58959dd8d0f2033e697</data>
    </node>
    <node id="&quot;CONVERGENCE&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Convergence in machine learning refers to the process where the training algorithm iteratively adjusts the model's parameters until the model reaches a stable state with minimal error."
"Convergence is the process where a machine learning model reaches a stable state with minimal error, indicating it has learned patterns in the training data."</data>
      <data key="d2">9f1e5883a5f969a6d913beed5a5abd4f,d0a69d653d08e58959dd8d0f2033e697</data>
    </node>
    <node id="&quot;MACHINE LEARNING MODEL&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"A machine learning model that relies on its own predictions and may face challenges in generating reasonable outputs."
"Machine Learning Model is a concept that refers to a mathematical model that is trained on data to make predictions or decisions without being explicitly programmed to perform the task."</data>
      <data key="d2">9f1e5883a5f969a6d913beed5a5abd4f,bd4cf5e35045463b7f0d8da82debc122</data>
    </node>
    <node id="&quot;SHIFT FEEDBACK&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Shift feedback ensures that the forced feedback timeseries is shifted by one timestep relative to the input timeseries, aligning past outputs with future inputs."</data>
      <data key="d2">9f1e5883a5f969a6d913beed5a5abd4f</data>
    </node>
    <node id="&quot;GENERATION&quot;">
      <data key="d0">"EVENT"</data>
      <data key="d1">"Generation refers to the process of predicting the next data point in a timeseries and using this prediction as input to generate subsequent data points."
"Generation refers to the process of predicting future values of a timeseries based on past data, using a trained ESN model."
"Generation refers to the process of creating new data using feedback connections."</data>
      <data key="d2">0c3779349544e78c4d650ccf76623127,4b78fdc153f982e64291112395c316c7,ead6383a44acd8ebd17907b85a910455</data>
    </node>
    <node id="&quot;LONG-TERM FORECASTING&quot;">
      <data key="d0">"EVENT"</data>
      <data key="d1">"Long-term forecasting involves using a trained model to predict future values of a timeseries over an extended period, beyond the immediate next data point."
"Long-term Forecasting involves predicting many steps ahead in a timeseries, providing a sequence of future values."</data>
      <data key="d2">0c3779349544e78c4d650ccf76623127,4b78fdc153f982e64291112395c316c7</data>
    </node>
    <node id="&quot;SHIFT_FB=TRUE&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"shift_fb=True is a parameter used to ensure the correct temporal alignment between input and feedback timeseries in Echo State Networks (ESNs)."</data>
      <data key="d2">0c3779349544e78c4d650ccf76623127</data>
    </node>
    <node id="&quot;WITH_FEEDBACK() CONTEXT MANAGER&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"The with_feedback() context manager is used to temporarily change the feedback received by the reservoir in Echo State Networks (ESNs) for experimentation or manipulation."</data>
      <data key="d2">0c3779349544e78c4d650ccf76623127</data>
    </node>
    <node id="&quot;TRAINING DATA&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Training Data is the historical data used to train an ESN model, allowing it to learn the underlying patterns and dynamics."
"Training Data is a set of data used to train a machine learning model, mentioned in the text."
"Training Data refers to the data used to train the Echo State Network (ESN) model."</data>
      <data key="d2">1365a36c76afc697ac626fd0f784804a,4b78fdc153f982e64291112395c316c7,af2db1cc5ab6b16acae2c93d3facb668</data>
    </node>
    <node id="&quot;ESN&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"ESN is a type of recurrent neural network that uses a sparse, randomly generated reservoir to capture and maintain the temporal dynamics of the input data."
"ESN is a type of neural network used for processing time series data, which uses the last state of the network as the starting point for prediction."
"ESN stands for Echo State Network, a type of recurrent neural network used for time series prediction and data analysis."
"ESN stands for Echo State Network, a type of recurrent neural network used for time series prediction and data analysis."
"ESN is an abbreviation for Echo State Networks, a type of recurrent neural network used for time series prediction and modeling."
"ESN is a type of recurrent neural network used for standalone training and running, optimized for parallel computation."
"ESN is a type of reservoir computing model used for training and running."

"ESN is a type of computing machine that encodes inputs in a high-dimensional space using a reservoir and reads out the desired output from the activations of the reservoir."
"ESN is an Echo State Network, which is a type of reservoir used in the context of Reservoir Computing."
"ESN stands for Echo State Network, a type of reservoir computing used for timeseries prediction."
"ESN stands for Echo State Network, which is a type of recurrent neural network used for time series prediction and data analysis."
"ESN refers to Echo State Networks, a type of recurrent neural network mentioned in the text."
"ESN is an abbreviation for Echo State Network, a variant of RNN used in the reservoir computing idea."
"ESN is a system described in the text, which includes a reservoir, input states, and output weights."
"ESN is a system or model that uses a reservoir to process information, with the echo state property being a key feature."
"ESN stands for Echo State Network, a type of neural network mentioned in the text."
"ESN is a network mentioned in the context of ELM, which is similar to ESN where recurrence has been removed."
"ESN is an abbreviation mentioned in the text, likely referring to an Echo State Network, a type of reservoir computing model."
"ESN is a type of neural network used for training, with parameters such as spectral radius, input scaling, and regularization."
"ESN is a type of reservoir-based recurrent neural network used for time series prediction and training."
"ESN is a machine learning model used for time series prediction and forecasting."
"ESN is a machine learning model used for time series forecasting and generative tasks."
"ESN is a machine learning model used for time series prediction and generation."
"ESN is a type of reservoir computing model used for time series prediction and generation."
"ESN is a machine learning model used for time series prediction, consisting of a reservoir and a readout component."
"ESN stands for Echo State Network, a type of recurrent neural network used for time series prediction and data analysis."
"ESN is a type of neural network used for training, which includes a special node E."
"ESN is a type of recurrent neural network that uses a special node for training, allowing parallelization of states computations and speeding up the training process."
"ESN is an acronym for Echo State Network, a type of recurrent neural network used for processing and predicting data."
"ESN stands for Echo State Network, a type of Reservoir Computing architecture."
"ESN stands for Echo State Network, a type of recurrent neural network used for time series prediction and analysis."
"ESN stands for Echo State Network, a type of reservoir computing model used for prediction and generation tasks."
"ESN is a model used for long-term forecasting and generative tasks, with customizable weight matrices and initializer functions."
"ESN stands for Echo State Network, which is a type of recurrent neural network that uses a sparsely connected reservoir to process input data."
"ESN is a type of node in ReservoirPy, which can be created from standard Reservoir and Ridge nodes. It is used for processing sequences of inputs and targets."
"ESN is a type of reservoir computing node created from the Reservoir and Ridge nodes in ReservoirPy, which supports parallelization and can be used for training and running."
"ESN is a type of model used for time series prediction, which includes a reservoir and a readout."
"ESN is a type of neural network that uses a sparsely connected reservoir to process input data."
"ESN stands for Echo State Network, which is a type of recurrent neural network that uses a reservoir to process input data."
"ESN is a model that combines a reservoir and a readout to solve complex tasks, such as speech recognition or chaotic timeseries forecasting."
"ESN stands for Echo State Network, a type of recurrent neural network used for time series prediction and other tasks."
"ESN stands for Echo State Network, which is a type of recurrent neural network used for time series prediction and analysis."
"ESN stands for Echo State Network, which is a type of recurrent neural network used for tasks such as time series prediction and data analysis."
"ESN stands for echo state network, a type of recurrent neural network used for time series prediction and other tasks."
"ESN is a type of reservoir-based neural network used for training and prediction."
"ESN is a model used for time series prediction, as indicated by the code and the context."
"ESN is an abbreviation for Echo State Network, a type of recurrent neural network used for time series prediction and data analysis."
"ESN is a machine learning model used for time series prediction and generative tasks."
"esn is a model used for training and generating data."
"ESN is a type of machine learning model used for time series prediction, developed by the ReservoirPy library."
"ESN is a type of reservoir computing model used in the code."
"ESN is a type of neural network used for training, with parameters such as units, leak rate, spectral radius, and inputs scaling."
"ESN is a machine learning model used for time series prediction, consisting of a reservoir and a readout component."
"ESN is a type of neural network used for time series prediction and analysis, with hyperparameters such as UNITS, LEAK_RATE, and SPECTRAL_RADIUS."
"ESN is an Echo State Network, a type of recurrent neural network, which is used in the provided code."</data>
      <data key="d2">00d22666fe697ffb66c2392939f45b39,069ae9388dfd52fec9c184c7168f64dd,088d2280349d652200861994c09d7dd5,09198e939639c229c2c97555f65b12a7,09ea760dd2f000c961d1cfd4ea795da5,0ae9f3cf96547c05eff54812cb72ac31,0b6c69085074b2cf23267eb149068b9f,0c5a253fb2bcebe8674581a5dc12fd96,18e4624a6da9e8e6d9b9b2ed260bf9b2,1cbfde86d1258f2b267135412e50a590,1db191f05801d40d5a346febd10d3352,1db5e6cd356c6066227de5e273de1abe,251a50c2ae8ceea4fd7da1127cc5f461,29aad23ce67e778ac31d4fb287fd20c7,31ee481e47ac3a0b970199e72a0e0d31,3695f5d218cdda0a91ae6a2f9b296837,36e4df75a46fb977f9516f2d2f1f9bc2,38b3e8ea0ec280360770513327b0d9d3,3ae4ccee74392bfe317d8132e99a3aa9,3bee7b78d0ab9582cc9bffe9e305df2e,424bf7c7b82dc966139c25f7c9ccffb7,593080a95ef7640b3925b07cad1bedd4,593306edfb8d4c7ef4b99d24fa009970,693e4d1e43289f46866236c10207a17e,6a4432cd530b28770e2b903fe242a0d1,71366a4c7e791080872ba783d3787bd7,72e6eee633bcb5b1458c4cee3975cee1,76963fa19a9caab847e50167f71c86a2,7b294b788fe5ee385d08c4aabe2ca71d,7b9936d57ece8ba985947a7aca12e2c7,7f70879016c133fe58e4838172a69613,80c9f51870e239404ed671ef0374f191,82ff270b1bbdfe0ee11e603de1e326c7,894d59d781535ca85389c4226715c007,993a69efae014a8f8d6ec0c235104d46,9b360c6a33aafa6827417de5bd4faa82,a1adb5de4156f0a4a448caf79056e886,a621b44739e0cb4379645a4a58f16697,b338d2dcc1fe6ccf42407444c02cad7c,bf4eaad93f89884d02cdad6a50f145a6,cc1fb6ca5695434ad0279c2606e928af,cdc64af0dde941250d89b191d0666c9b,d0b9bbbd7257712eafd2eda5db1d0a8d,d4563a00dc04ebf7bcf01e5062fde46f,d7ac2f6fb13af389417785f2f3152c52,d8e227aa2ab10a1fa9952614e3dea820,df811c27ddc46d5b90c5863a52666a4b,e396354e3a9be76616392af11f56e671,ead6383a44acd8ebd17907b85a910455,eb7a223eeb120e3fcc45a96a6018707d,f0c8d4d322d73f46464e3e9f6914f2ee,f18a060e6d2bb1da70432cbc71378770,f730c6800099724052a2d061f3cd8c2e,f7f7dbc1e69b3b0e801bc5ba9c0cabca,fd81bdceb3e2b91ac2605a3d201d1eb4,fe90abb0dde126fafbf44782aeb6738c</data>
    </node>
    <node id="&quot;CUSTOM WEIGHT MATRIX&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"A Custom Weight Matrix is a matrix used to connect the input layer to the reservoir in an ESN, allowing for the adjustment of the input-reservoir connections to improve the model's performance."
"A custom weight matrix is a manually specified array of weights used in neural networks to control their behavior and performance."</data>
      <data key="d2">693e4d1e43289f46866236c10207a17e,d8e227aa2ab10a1fa9952614e3dea820</data>
    </node>
    <node id="&quot;CUSTOM INITIALIZER FUNCTION&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"A custom initializer function is a user-defined function used to generate initial weights for the parameters of a neural network node, allowing for tailored initialization."</data>
      <data key="d2">d8e227aa2ab10a1fa9952614e3dea820</data>
    </node>
    <node id="&quot;**KWARGS&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"**kwargs allows a function to accept additional keyword arguments, providing flexibility in function usage."</data>
      <data key="d2">d8e227aa2ab10a1fa9952614e3dea820</data>
    </node>
    <node id="&quot;NP.RANDOM.NORMAL&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"np.random.normal is a function from the NumPy library used to generate random numbers from a normal distribution."
"np.random.normal generates random numbers from a normal (Gaussian) distribution."
"np.random.normal is a function used to generate random numbers from a normal distribution."</data>
      <data key="d2">3a3b7a67b23341dcd1b04ec5b61683f6,4a8a4a7eeebd68a535cf84cfaecebaba,d8e227aa2ab10a1fa9952614e3dea820</data>
    </node>
    <node id="&quot;RESERVOIRPY.MAT_GEN&quot;">
      <data key="d0">"MODULE"</data>
      <data key="d1">"reservoirpy.mat_gen provides initializers for creating custom weight matrices from various statistical distributions."
"reservoirpy.mat_gen is a submodule of ReservoirPy that provides initializers for creating custom weight matrices."</data>
      <data key="d2">4a8a4a7eeebd68a535cf84cfaecebaba,8f2f2cfd667a304a288723de779c9bee</data>
    </node>
    <node id="&quot;RESERVOIRPY.MAT_GEN.RANDOM_SPARSE&quot;">
      <data key="d0">"FUNCTION"</data>
      <data key="d1">"reservoirpy.mat_gen.random_sparse is a function that initializes a weight matrix with a sparse distribution of values."</data>
      <data key="d2">4a8a4a7eeebd68a535cf84cfaecebaba</data>
    </node>
    <node id="&quot;PLT.HIST&quot;">
      <data key="d0">"FUNCTION"</data>
      <data key="d1">"plt.hist is a function that creates a histogram of data."
"plt.hist is a function used for plotting a histogram of the weights distribution in the Reservoir matrix."</data>
      <data key="d2">3a3b7a67b23341dcd1b04ec5b61683f6,4a8a4a7eeebd68a535cf84cfaecebaba</data>
    </node>
    <node id="&quot;NP.RANDOM.UNIFORM&quot;">
      <data key="d0">"FUNCTION"</data>
      <data key="d1">"np.random.uniform generates random numbers from a uniform distribution."</data>
      <data key="d2">4a8a4a7eeebd68a535cf84cfaecebaba</data>
    </node>
    <node id="&quot;KWARGS&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"kwargs is a Python feature that allows a function to accept an arbitrary number of keyword arguments."</data>
      <data key="d2">4a8a4a7eeebd68a535cf84cfaecebaba</data>
    </node>
    <node id="&quot;RESERVOIR.W.RAVEL()&quot;">
      <data key="d0">"FUNCTION"</data>
      <data key="d1">"reservoir.W.ravel() flattens a matrix W into a one-dimensional array."</data>
      <data key="d2">4a8a4a7eeebd68a535cf84cfaecebaba</data>
    </node>
    <node id="&quot;RANDOM_SPARSE&quot;">
      <data key="d0">"FUNCTION"</data>
      <data key="d1">"random_sparse is a function that creates a sparse matrix with randomly distributed non-zero elements based on a specified statistical distribution."
"random_sparse is a function from the reservoirpy.mat_gen module that creates a random sparse matrix initializer."
"random_sparse is a function used to generate random sparse matrices with specified properties."</data>
      <data key="d2">3a3b7a67b23341dcd1b04ec5b61683f6,8f2f2cfd667a304a288723de779c9bee,96c47d9b671ce319abe9c6ba2b8ae122</data>
    </node>
    <node id="&quot;UNIFORM DISTRIBUTION&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"A uniform distribution generates values that are evenly spread within a specified range."
"A uniform distribution generates non-zero elements of a matrix from a uniform distribution, ensuring values are evenly spread within a specified range."
"Uniform Distribution is a type of probability distribution used to generate matrices."</data>
      <data key="d2">8559ec6650745de27a3f41815fbfde09,8f2f2cfd667a304a288723de779c9bee,d5e39e29b61f6ea0ffe0c868ba7a4252</data>
    </node>
    <node id="&quot;DELAYED MATRIX CREATION&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Delayed matrix creation initializes the parameters only when needed, such as at the first run."</data>
      <data key="d2">8559ec6650745de27a3f41815fbfde09</data>
    </node>
    <node id="&quot;MATRIX CREATION&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Matrix creation generates the parameters immediately upon calling the initializer function."</data>
      <data key="d2">8559ec6650745de27a3f41815fbfde09</data>
    </node>
    <node id="&quot;GAUSSIAN DISTRIBUTION&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"A Gaussian distribution, also known as a normal distribution, is a probability distribution characterized by its bell-shaped curve, symmetric around the mean, defined by its mean and standard deviation."</data>
      <data key="d2">8559ec6650745de27a3f41815fbfde09</data>
    </node>
    <node id="&quot;BERNOULLI RANDOM VARIABLE&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"A Bernoulli random variable is a binary variable that takes the value 1 with probability \( p \) and 0 with probability \( 1-p \), representing the outcome of a Bernoulli trial."
"Bernoulli Random Variable is a binary variable that takes the value 1 with probability p and 0 with probability 1-p, representing the outcome of a Bernoulli trial."</data>
      <data key="d2">1cbfde86d1258f2b267135412e50a590,8559ec6650745de27a3f41815fbfde09</data>
    </node>
    <node id="&quot;NORMAL DISTRIBUTION&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Normal Distribution is a probability distribution characterized by its bell-shaped curve, defined by its mean and standard deviation."
"Normal Distribution is a type of probability distribution used to generate matrices."</data>
      <data key="d2">1cbfde86d1258f2b267135412e50a590,d5e39e29b61f6ea0ffe0c868ba7a4252</data>
    </node>
    <node id="&quot;MULTIPROCESSING&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Multiprocessing is a method of parallel computation that involves using multiple processors or cores to execute tasks simultaneously, improving performance and efficiency."
"Multiprocessing is a method of parallelizing tasks by using multiple processors or cores to execute tasks simultaneously."</data>
      <data key="d2">18e4624a6da9e8e6d9b9b2ed260bf9b2,593080a95ef7640b3925b07cad1bedd4</data>
    </node>
    <node id="&quot;ESN OFFLINE TRAINING WITH RIDGE REGRESSION&quot;">
      <data key="d0">"EVENT"</data>
      <data key="d1">"ESN offline training with ridge regression refers to the process of training an Echo State Network using ridge regression for offline tasks."</data>
      <data key="d2">18e4624a6da9e8e6d9b9b2ed260bf9b2</data>
    </node>
    <node id="&quot;JOBLIB&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Joblib is a Python library for lightweight pipelining, providing tools for transparent disk-caching of functions and parallel computing."
"Joblib is a Python library that provides utilities for caching, parallelization, and persistence of Python objects, which is mentioned in the text."
"Joblib is a Python library used for parallelizing CPU-bound tasks, such as data loading and processing."
"Joblib is a library in Python for providing lightweight pipelining in Python jobs, which can be used to parallelize the computation of node states over independent sequences of inputs in ESN training/running."
"joblib is a library that provides utilities for parallel and efficient computing, used in the provided code."</data>
      <data key="d2">085c9d7a2af51b93826fc393600682d8,18e4624a6da9e8e6d9b9b2ed260bf9b2,9fdaabd6c7e893a275a3848c10007477,f3b5b178557c4991ab5b81d869a4752e,fe90abb0dde126fafbf44782aeb6738c</data>
    </node>
    <node id="&quot;COMPUTING NODE STATES OVER INDEPENDENT SEQUENCES OF INPUTS&quot;">
      <data key="d0">"EVENT"</data>
      <data key="d1">"Computing node states over independent sequences of inputs involves processing each sequence separately and in parallel, calculating the activations or outputs of nodes for each input sequence."</data>
      <data key="d2">18e4624a6da9e8e6d9b9b2ed260bf9b2</data>
    </node>
    <node id="&quot;COMPUTING NODE STATES&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Computing Node States refers to the process of calculating the activations or states of the nodes for each input sequence, which is mentioned in the text."</data>
      <data key="d2">085c9d7a2af51b93826fc393600682d8</data>
    </node>
    <node id="&quot;SEQUENCES&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Sequences are mentioned in the text as data that can have varying lengths, such as timeseries or spoken sentences."
</data>
      <data key="d2">085c9d7a2af51b93826fc393600682d8,6f3d0ba82cf3b10b19b64f73ace8c695</data>
    </node>
    <node id="&quot;DIFFERENT LENGTHS&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Different Lengths between sequences is mentioned as a challenge, with techniques like padding, truncation, dynamic batching, and sequence masking suggested as solutions."</data>
      <data key="d2">085c9d7a2af51b93826fc393600682d8</data>
    </node>
    <node id="&quot;PADDING&quot;">
      <data key="d0">"TECHNIQUE"</data>
      <data key="d1">"Padding is a method used to extend shorter sequences with a specific value to match the length of the longest sequence."</data>
      <data key="d2">33a235bffff79a56e3ff5e5a9e86a3de</data>
    </node>
    <node id="&quot;TRUNCATION&quot;">
      <data key="d0">"TECHNIQUE"</data>
      <data key="d1">"Truncation is a method used to cut longer sequences to match the length of the shortest or a predefined length."</data>
      <data key="d2">33a235bffff79a56e3ff5e5a9e86a3de</data>
    </node>
    <node id="&quot;DYNAMIC BATCHING&quot;">
      <data key="d0">"TECHNIQUE"</data>
      <data key="d1">"Dynamic Batching is a method that groups sequences of similar lengths in batches to minimize padding."</data>
      <data key="d2">33a235bffff79a56e3ff5e5a9e86a3de</data>
    </node>
    <node id="&quot;SEQUENCE MASKING&quot;">
      <data key="d0">"TECHNIQUE"</data>
      <data key="d1">"Sequence Masking is a method used to ignore padded values during processing and computation."</data>
      <data key="d2">33a235bffff79a56e3ff5e5a9e86a3de</data>
    </node>
    <node id="&quot;DIMENSIONALITY REDUCTION&quot;">
      <data key="d0">"TECHNIQUE"</data>
      <data key="d1">"Dimensionality Reduction is a method used to apply techniques such as PCA (Principal Component Analysis) to reduce the number of dimensions in sequences to a common size."</data>
      <data key="d2">33a235bffff79a56e3ff5e5a9e86a3de</data>
    </node>
    <node id="&quot;FEATURE ENGINEERING&quot;">
      <data key="d0">"TECHNIQUE"</data>
      <data key="d1">"Feature Engineering is a method used to add or remove features to match the required dimensionality."
"Feature Engineering is the process of adding or removing features to match the required dimensionality."</data>
      <data key="d2">33a235bffff79a56e3ff5e5a9e86a3de,6f3d0ba82cf3b10b19b64f73ace8c695</data>
    </node>
    <node id="&quot;INTERPOLATION&quot;">
      <data key="d0">"TECHNIQUE"</data>
      <data key="d1">"Interpolation is a method used to adjust the length of sequences by interpolating additional points."
"Interpolation is a method used in curve fitting where an exact fit to the data is required."
"Interpolation is a method used to estimate unknown quantities between known quantities, often used in the construction of economic time series."
"Interpolation is a method used to estimate values between known data points."
"Interpolation is a technique used to approximate a function when only a set of points is provided, and the function is an operation on the real numbers."</data>
      <data key="d2">33a235bffff79a56e3ff5e5a9e86a3de,472b44b36407c9a89cf5c51459188263,630c86e110e2dabbe068f446b619cef3,9ec0dac4c72bcc2c78c7df43b9969fe7,bde7c826c746ece93a512a0cf167fa3e</data>
    </node>
    <node id="&quot;EXTRAPOLATION&quot;">
      <data key="d0">"TECHNIQUE"</data>
      <data key="d1">"Extrapolation is a method used to adjust the length of sequences by reducing points to match a common length."
"Extrapolation is the use of a fitted curve beyond the range of the observed data, subject to a degree of uncertainty."
"Extrapolation is a method used to predict values of a function beyond the range of the observed data, subject to a degree of uncertainty."
"Extrapolation is a method used to estimate values beyond the range of known data points, subject to greater uncertainty."
"Extrapolation is a technique used to approximate a function when only a set of points is provided, and the function is an operation on the real numbers."</data>
      <data key="d2">33a235bffff79a56e3ff5e5a9e86a3de,472b44b36407c9a89cf5c51459188263,630c86e110e2dabbe068f446b619cef3,9ec0dac4c72bcc2c78c7df43b9969fe7,bde7c826c746ece93a512a0cf167fa3e</data>
    </node>
    <node id="&quot;DIMENSIONALITY REDUCTION TECHNIQUES&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Dimensionality Reduction Techniques are methods used to reduce the number of dimensions in sequences to a common size, such as PCA (Principal Component Analysis)."</data>
      <data key="d2">6f3d0ba82cf3b10b19b64f73ace8c695</data>
    </node>
    <node id="&quot;INTERPOLATION OR EXTRAPOLATION&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Interpolation or Extrapolation is a technique used to adjust the length of sequences by adding or reducing points to match the desired length."</data>
      <data key="d2">6f3d0ba82cf3b10b19b64f73ace8c695</data>
    </node>
    <node id="&quot;TRANSFORMATION TECHNIQUES&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Transformation Techniques are methods used to transform input sequences to a uniform dimensionality before feeding them into the model, such as embedding layers."</data>
      <data key="d2">6f3d0ba82cf3b10b19b64f73ace8c695</data>
    </node>
    <node id="&quot;NP.LINSPACE()&quot;">
      <data key="d0">"FUNCTION"</data>
      <data key="d1">"np.linspace() is a function that generates an array of evenly spaced values between two specified endpoints."</data>
      <data key="d2">6f3d0ba82cf3b10b19b64f73ace8c695</data>
    </node>
    <node id="&quot;NP.SIN()&quot;">
      <data key="d0">"FUNCTION"</data>
      <data key="d1">"np.sin() is a function that computes the sine of all elements in the input array."</data>
      <data key="d2">6f3d0ba82cf3b10b19b64f73ace8c695</data>
    </node>
    <node id="&quot;NP.ARRAY()&quot;">
      <data key="d0">"FUNCTION"</data>
      <data key="d1">"np.array() is a function that creates a NumPy array from an input sequence."</data>
      <data key="d2">6f3d0ba82cf3b10b19b64f73ace8c695</data>
    </node>
    <node id="&quot;LINSPACE()&quot;">
      <data key="d0">"TECHNOLOGY"</data>
      <data key="d1">"linspace() is a function used to generate an array of evenly spaced values, which is used to create a sine wave for input and target sequences."</data>
      <data key="d2">df811c27ddc46d5b90c5863a52666a4b</data>
    </node>
    <node id="&quot;CPU CORES&quot;">
      <data key="d0">"TECHNOLOGY"</data>
      <data key="d1">"CPU cores are processing units in a computer's processor, used for parallel computation to manage system resources."</data>
      <data key="d2">df811c27ddc46d5b90c5863a52666a4b</data>
    </node>
    <node id="&quot;PARALLEL COMPUTATION&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Parallel computation is the use of multiple processes or threads to perform tasks simultaneously, improving efficiency."</data>
      <data key="d2">df811c27ddc46d5b90c5863a52666a4b</data>
    </node>
    <node id="&quot;WORKERS&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"workers is a parameter that specifies the number of parallel processes to use for training and running the ESN."</data>
      <data key="d2">3695f5d218cdda0a91ae6a2f9b296837</data>
    </node>
    <node id="&quot;BACKEND&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"backend is a parameter that specifies the method of execution for the ESN."</data>
      <data key="d2">3695f5d218cdda0a91ae6a2f9b296837</data>
    </node>
    <node id="&quot;COMPLEX MODELS&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Complex Models are advanced reservoir computing models that can handle more complex tasks, such as Hierarchical ESNs, Deep ESNs, and Multi-inputs ESNs."
"Complex Models in reservoir computing refer to models that are more sophisticated and capable of handling intricate tasks, such as Hierarchical ESNs, Deep ESNs, and Multi-inputs ESNs."</data>
      <data key="d2">22499cd4a0b7216dad5b05eb109fcb73,3695f5d218cdda0a91ae6a2f9b296837</data>
    </node>
    <node id="&quot;HIERARCHICAL ESNS&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Hierarchical ESNs are a type of complex model that utilize a hierarchical structure to process sequences at different levels of abstraction."
"Hierarchical ESNs are complex models where nodes are connected in a sequential manner, forming a hierarchy. They allow data to flow through multiple layers of reservoirs and readouts."</data>
      <data key="d2">22499cd4a0b7216dad5b05eb109fcb73,3695f5d218cdda0a91ae6a2f9b296837</data>
    </node>
    <node id="&quot;DEEP ESNS&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Deep ESNs are a type of complex model that utilize multiple layers of ESNs to learn hierarchical representations of the input data."
"Deep ESNs involve multiple layers of reservoirs connected in series and parallel pathways. They create a more intricate structure that can handle complex tasks."</data>
      <data key="d2">22499cd4a0b7216dad5b05eb109fcb73,3695f5d218cdda0a91ae6a2f9b296837</data>
    </node>
    <node id="&quot;MULTI-INPUTS ESNS&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Multi-inputs ESNs are a type of complex model that can handle multiple input streams simultaneously, allowing for more flexible and expressive modeling."
"Multi-inputs ESNs are complex models that can handle multiple input sources, allowing for the integration of diverse data streams."</data>
      <data key="d2">22499cd4a0b7216dad5b05eb109fcb73,3695f5d218cdda0a91ae6a2f9b296837</data>
    </node>
    <node id="&quot;DICTIONARY&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"A dictionary in Python is a data structure that stores key-value pairs. In the context of training models, a dictionary can be used to specify the target outputs for each readout node during training."
"A dictionary in Python is a collection data type that stores data in pairs, where each key is associated with a value, and each key must be unique."
"A dictionary in Python is a collection data type that stores data in pairs, where each key is associated with a value. It is used to specify the parameters of a model when using a ScikitLearnNode."</data>
      <data key="d2">22499cd4a0b7216dad5b05eb109fcb73,84cacfea14ea9ff46a34150e77a0767a,861c28cb739722ddeb0babb7e1427409</data>
    </node>
    <node id="&quot;DEEP ESN&quot;">
      <data key="d0">"TECHNOLOGY"</data>
      <data key="d1">"Deep ESNs are a type of model that involve multiple layers of reservoirs connected in series and parallel pathways, enhancing depth and complexity."
"Deep ESN is a type of model used for time series prediction, involving multiple reservoirs and readouts."
"Deep ESN is a type of reservoir computing model mentioned in the text, consisting of multiple interconnected reservoirs."</data>
      <data key="d2">2336a57d055095c6ffa9d156ddee0096,c7c2383410ac00bad82831596a2d27a6,e39809b687cd044a7918eca37727a188</data>
    </node>
    <node id="&quot;MULTI-INPUTS ESN&quot;">
      <data key="d0">"TECHNOLOGY"</data>
      <data key="d1">"Multi-inputs ESNs are a type of model that handle multiple inputs and process them through different pathways before merging the results, allowing integration and processing of diverse input data streams."</data>
      <data key="d2">c7c2383410ac00bad82831596a2d27a6</data>
    </node>
    <node id="&quot;MACKEY-GLASS EQUATION&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Mackey-Glass equation is a set of delayed differential equations describing the temporal behavior of different physiological signals, often used to study chaotic systems."
"Mackey-Glass Equation is a set of delayed differential equations used to study chaotic systems and describe the behavior of physiological signals."
"The Mackey-Glass Equation is a nonlinear differential equation used to model the dynamics of a chemical reaction, known for its chaotic behavior."
"The Mackey-Glass Equation is a chaotic system used for timeseries forecasting in the text."
"The Mackey-Glass Equation is a mathematical model used to describe the dynamics of a chemical reaction."
"The Mackey-Glass Equation is a time series data generation equation used in the context of the ESN analysis."</data>
      <data key="d2">1db5e6cd356c6066227de5e273de1abe,50d4e4aab1823b8df6573ccf227f24d0,518f1e492b92054cf2f5c5289444da02,9f13e40ee24c7913a62781d708e3b47e,c5c29ba06a5cc70a086c2c2c8858e5aa,c7c2383410ac00bad82831596a2d27a6</data>
    </node>
    <node id="&quot;CHAOTIC SYSTEMS&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Chaotic Systems are complex and unpredictable systems that exhibit sensitive dependence on initial conditions."
</data>
      <data key="d2">9f13e40ee24c7913a62781d708e3b47e,af2db1cc5ab6b16acae2c93d3facb668</data>
    </node>
    <node id="&quot;TIME DELAY&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Time Delay is a parameter in the Mackey-Glass Equation that controls the chaotic behavior of the system."</data>
      <data key="d2">9f13e40ee24c7913a62781d708e3b47e</data>
    </node>
    <node id="&quot;DATA RESCALING&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Data Rescaling is a preprocessing step that standardizes data, improving performance and stability."</data>
      <data key="d2">9f13e40ee24c7913a62781d708e3b47e</data>
    </node>
    <node id="&quot;FUNCTION .CM.MAGMA&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Function .cm.magma is not mentioned in the provided text, so it's unclear what this entity represents without additional context."</data>
      <data key="d2">9f13e40ee24c7913a62781d708e3b47e</data>
    </node>
    <node id="&quot;MACKEY-GLASS TIMESERIES&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Mackey-Glass timeseries is a mathematical model used for time series analysis, requiring rescaling between -1 and 1 for preprocessing."
"Mackey-Glass Timeseries is a synthetic dataset used for chaotic timeseries prediction tasks."
"Mackey-Glass timeseries is a chaotic univariate timeseries used as inputs for the reservoir computing model."
"Mackey-Glass timeseries is a dataset used for forecasting in the example section."
"Mackey-Glass timeseries is a dataset mentioned in the text, used for training and forecasting."
"Mackey-Glass timeseries is a mathematical function used as a benchmark for time series prediction and data analysis."
"Mackey-Glass Timeseries is a type of data series generated by the Mackey-Glass Equations."
"Mackey-Glass Timeseries is a type of data series generated from the Mackey-Glass Equations, used for chaotic timeseries forecasting."
"Mackey-Glass Timeseries is a dataset used in the provided code for demonstrating reservoir computing."</data>
      <data key="d2">238049de5f28dca3e857a46a8b1bed03,2f4c992d69812866e6fce6dbb52d8612,4073cafddb73621f26061385c5570659,4ac00cf37a752d89d55a749c01c6f6fd,6daefaa8fbd5c1492f2d832d79841463,94fd1ebf256db17e4ac2255b89caa473,a1adb5de4156f0a4a448caf79056e886,a2b183778107462d474c53e4ec0a9221,d7ac2f6fb13af389417785f2f3152c52</data>
    </node>
    <node id="&quot;STANDARDIZATION&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Standardization is a preprocessing step that scales data to have a mean of 0 and a standard deviation of 1, improving performance and stability."</data>
      <data key="d2">4ac00cf37a752d89d55a749c01c6f6fd</data>
    </node>
    <node id="&quot;MAGMA COLORMAP&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Magma colormap is a color scheme used to visualize data, with dark purple representing the first step and bright yellow representing the last step."</data>
      <data key="d2">4ac00cf37a752d89d55a749c01c6f6fd</data>
    </node>
    <node id="&quot;NP.ARANGE() FUNCTION&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"np.arange() function generates an array of values within a specified range."</data>
      <data key="d2">4ac00cf37a752d89d55a749c01c6f6fd</data>
    </node>
    <node id="&quot;NP.ARANGE(0, 500)&quot;">
      <data key="d0">"TECHNOLOGY"</data>
      <data key="d1">"np.arange(0, 500) is a function call that generates an array of numbers from 0 to 499."</data>
      <data key="d2">7d747b0c740e8b5b60726dcf7dcadef5</data>
    </node>
    <node id="&quot;X_TRAIN&quot;">
      <data key="d0">"TECHNOLOGY"</data>
      <data key="d1">"X_train is a variable that likely contains training data."
"X_train is a component of a machine learning model used for processing data."
"x_train is a dataset used for training the machine learning model."
"X_train is a subset of the X variable used for training the machine learning model."
"X_train is a variable representing the training input data used to train the ESN system."
"X_train is a variable that likely contains the training input data for the ESN model."
"X_train is a training dataset used to train the reservoir model."
"X_train is a dataset used for training a model, such as an Echo State Network (ESN), on input data."
"X_train is a concept or variable used in the provided code, likely representing the training data input."
"X_train is a subset of the input data used for training the ESN."
"X_train is a subset of the input data used for training the ESN model."
"X_train is a variable used to store the training input data, which is mentioned in the text."
"X_train is a set of input data used for training the model."
"X_train is a variable in the code that represents the training input data."
"X_train is a dataset used for training the machine learning models, containing input features."
"X_train is a dataset used for training the Reservoir Model."</data>
      <data key="d2">0036fb6f489e13c0db0f1c02bf3323be,0970cd32ce54f6ee1180ab237fdcefe1,0982b8d1eb1e636b19fa2e9d9361e566,3ff318aebcb07ca141d0a40730d96c7c,71366a4c7e791080872ba783d3787bd7,72e6eee633bcb5b1458c4cee3975cee1,751b176a8d6149a853e597c65a6fe0cf,75e530c1a04e30b373dc7cc68e3ad819,7d747b0c740e8b5b60726dcf7dcadef5,7f2d69f9a9baca70ffd25a6865189206,80c9f51870e239404ed671ef0374f191,a0feae89e52a4291db0a512a3a102d8e,b3361508c3e49b5bb3089f10e31d2c81,b338d2dcc1fe6ccf42407444c02cad7c,dc3bd3697a140b64d70e0e3ac6db6c7e,f70c7d3d89baaabbeaad57b58e379e08</data>
    </node>
    <node id="&quot;PLT.PLOT&quot;">
      <data key="d0">"TECHNOLOGY"</data>
      <data key="d1">"plt.plot is a function call from the matplotlib library used to create a plot."</data>
      <data key="d2">7d747b0c740e8b5b60726dcf7dcadef5</data>
    </node>
    <node id="&quot;TO_FORECASTING&quot;">
      <data key="d0">"TECHNOLOGY"</data>
      <data key="d1">"to_forecasting is a function that likely prepares data for forecasting tasks."</data>
      <data key="d2">7d747b0c740e8b5b60726dcf7dcadef5</data>
    </node>
    <node id="&quot;X&quot;">
      <data key="d0">"TECHNOLOGY"</data>
      <data key="d1">"X is a variable that likely contains data to be forecasted."
"X is a variable or feature used in the time series forecasting process."
"X is a variable representing the input data in the time series."
"X is a variable that likely contains the input data for the ESN model."
"X is a dataset used for making predictions using the trained reservoir model."
"X is a variable representing the input data used for training the ESN node."
"X is a variable representing a sine wave, which is used as input data for the ESN model."
"X is the input data used for training and prediction in the ESN."
"X is a variable used to represent input data in the context of data analysis and machine learning."</data>
      <data key="d2">09198e939639c229c2c97555f65b12a7,09ea760dd2f000c961d1cfd4ea795da5,31ee481e47ac3a0b970199e72a0e0d31,3ff318aebcb07ca141d0a40730d96c7c,593306edfb8d4c7ef4b99d24fa009970,7d747b0c740e8b5b60726dcf7dcadef5,7f2d69f9a9baca70ffd25a6865189206,e396354e3a9be76616392af11f56e671,f70c7d3d89baaabbeaad57b58e379e08</data>
    </node>
    <node id="&quot;READOUT.WOUT&quot;">
      <data key="d0">"TECHNOLOGY"</data>
      <data key="d1">"readout.Wout is a variable that likely contains weights in a neural network model."</data>
      <data key="d2">7d747b0c740e8b5b60726dcf7dcadef5</data>
    </node>
    <node id="&quot;OFFLINE TRAINING&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Offline Training is a method where a model is trained on a complete dataset in one go."
"Offline Training is a method where the model is trained on a complete dataset in one go, often requiring significant memory and processing power."</data>
      <data key="d2">7d747b0c740e8b5b60726dcf7dcadef5,c9e71660f79df626c288b3a58eab0f2f</data>
    </node>
    <node id="&quot;ONLINE TRAINING&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Online Training is a method where a model is updated incrementally as new data arrives."
"Online Training is a method that updates the model incrementally as new data arrives, allowing the model to learn and adapt in real-time."</data>
      <data key="d2">7d747b0c740e8b5b60726dcf7dcadef5,c9e71660f79df626c288b3a58eab0f2f</data>
    </node>
    <node id="&quot;MODEL TRAINING&quot;">
      <data key="d0" />
      <data key="d1">
"Model Training is the process of training a machine learning model to make predictions or classifications, as performed by the Data Scientist."</data>
      <data key="d2">7d747b0c740e8b5b60726dcf7dcadef5,9fdaabd6c7e893a275a3848c10007477</data>
    </node>
    <node id="&quot;NP.R_&quot;">
      <data key="d0">"FUNCTION"</data>
      <data key="d1">"np.r_ is a shorthand for 'np.concatenate', used to concatenate arrays along the first axis."
"np.r_ is a function in NumPy used for concatenating arrays along a specified axis."</data>
      <data key="d2">9078b0f36522f21a9e8e1aadac48ed9c,c9e71660f79df626c288b3a58eab0f2f</data>
    </node>
    <node id="&quot;NP.ARANGE&quot;">
      <data key="d0">"FUNCTION"</data>
      <data key="d1">"np.arange is a function used to return evenly spaced values within a given interval."</data>
      <data key="d2">c9e71660f79df626c288b3a58eab0f2f</data>
    </node>
    <node id="&quot;NP.RAVEL&quot;">
      <data key="d0">"FUNCTION"</data>
      <data key="d1">"np.ravel is a function used to flatten a multi-dimensional array into a one-dimensional array."</data>
      <data key="d2">c9e71660f79df626c288b3a58eab0f2f</data>
    </node>
    <node id="&quot;BIAS&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Bias is a constant value added to the input of a neuron before the activation function to help the model make more accurate predictions."
"Bias is a constant value added to the input of a neuron to help the model make more accurate predictions."
"Bias refers to the inherent assumptions or preferences that can influence the results of a model, and it is a term used in machine learning to describe this effect."</data>
      <data key="d2">9078b0f36522f21a9e8e1aadac48ed9c,c9e71660f79df626c288b3a58eab0f2f,e805d3f438bd9c485639f1c69f917ae5</data>
    </node>
    <node id="&quot;NP.CONCATENATE&quot;">
      <data key="d0" />
      <data key="d1">
"np.concatenate is a function used to combine arrays along a specified axis."</data>
      <data key="d2">00648b24263129fdae8652f1a3339041,c9e71660f79df626c288b3a58eab0f2f</data>
    </node>
    <node id="&quot;WOUT&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Wout is a weight matrix used in the output layer of a neural network model."</data>
      <data key="d2">9078b0f36522f21a9e8e1aadac48ed9c</data>
    </node>
    <node id="&quot;NP.ABS&quot;">
      <data key="d0">"TECHNOLOGY"</data>
      <data key="d1">"np.abs is a function in NumPy used to compute the absolute values of elements in an array."</data>
      <data key="d2">9078b0f36522f21a9e8e1aadac48ed9c</data>
    </node>
    <node id="&quot;SAMPLE&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"sample is a subset of data used for analysis or visualization, such as calculating absolute deviation."</data>
      <data key="d2">9078b0f36522f21a9e8e1aadac48ed9c</data>
    </node>
    <node id="&quot;ABSOLUTE DEVIATION&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Absolute deviation is the absolute difference between the true values and the predicted values in a machine learning model."
"Absolute deviation is a measure of the difference between the True value and the ESN prediction in data analysis or modeling."</data>
      <data key="d2">9078b0f36522f21a9e8e1aadac48ed9c,ee83abbbbc707d8131952b2b01ebc268</data>
    </node>
    <node id="&quot;MODEL-0&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Model-0 is a specific machine learning model being processed to make predictions."
"Model-0 is a machine learning model that is processing data points and has a processing speed of 7576.01 iterations per second."</data>
      <data key="d2">9078b0f36522f21a9e8e1aadac48ed9c,c122738fd421d3d662f759af5a0a23f3</data>
    </node>
    <node id="&quot;X_TEST1&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"X_test1 is a variable representing the input data for Model-0 to make predictions on."
"X_test1 is a dataset used as input for the Model-0."</data>
      <data key="d2">9078b0f36522f21a9e8e1aadac48ed9c,c122738fd421d3d662f759af5a0a23f3</data>
    </node>
    <node id="&quot;Y_TEST1&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"y_test1 is a dataset containing the actual values that the Model-0's predictions are compared against."
"y_test1 represents the actual values in a prediction task."</data>
      <data key="d2">c122738fd421d3d662f759af5a0a23f3,d8022c6a3caf781300e2abc1dfd2ed44</data>
    </node>
    <node id="&quot;Y_PRED1&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"y_pred1 is a dataset containing the predicted values generated by the Model-0."
"y_pred1 represents the predicted values in a prediction task."</data>
      <data key="d2">c122738fd421d3d662f759af5a0a23f3,d8022c6a3caf781300e2abc1dfd2ed44</data>
    </node>
    <node id="&quot;ACCURACY&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Accuracy is a measure of how often a model's predictions are correct."</data>
      <data key="d2">c122738fd421d3d662f759af5a0a23f3</data>
    </node>
    <node id="&quot;PRECISION&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Precision is a measure of how good a model is at identifying true positives."</data>
      <data key="d2">c122738fd421d3d662f759af5a0a23f3</data>
    </node>
    <node id="&quot;RECALL&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Recall is a measure of how good a model is at identifying true positives and true negatives."</data>
      <data key="d2">c122738fd421d3d662f759af5a0a23f3</data>
    </node>
    <node id="&quot;MEAN SQUARED ERROR&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Mean Squared Error is a measure of how far off a model's predictions are from the actual values."</data>
      <data key="d2">c122738fd421d3d662f759af5a0a23f3</data>
    </node>
    <node id="&quot;R^2 OR RSQUARE&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"R^2 or rsquare is a statistical measure of how well a model's predicted values match the actual values."</data>
      <data key="d2">c122738fd421d3d662f759af5a0a23f3</data>
    </node>
    <node id="&quot;NRMSE OR NRMSE&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"NRMSE or nrmse is a measure of the average magnitude of the errors in a model's predictions, normalized by the range of the actual values."</data>
      <data key="d2">c122738fd421d3d662f759af5a0a23f3</data>
    </node>
    <node id="&quot;RSQUARE&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"rsquare is a statistical measure that indicates the proportion of the variance in the dependent variable that is predictable from the independent variable(s)."
"rsquare is a metric used to evaluate the performance of a machine learning model, mentioned in the provided code."</data>
      <data key="d2">0753d4e507badadd900c522ee03ad28d,d8022c6a3caf781300e2abc1dfd2ed44</data>
    </node>
    <node id="&quot;NRMSE&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"NRMSE is a measure of the differences between predicted values and actual values, normalized by the range or mean of the actual values. It provides a dimensionless measure of prediction accuracy."
"nrmse is a metric used to evaluate the performance of a machine learning model, mentioned in the provided code."
"NRMSE is a metric used to evaluate the performance of a model, representing the normalized root mean square error."</data>
      <data key="d2">0753d4e507badadd900c522ee03ad28d,82ff270b1bbdfe0ee11e603de1e326c7,d8022c6a3caf781300e2abc1dfd2ed44</data>
    </node>
    <node id="&quot;ONE-TIMESTEP-AHEAD FORECASTING TASK&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"One-timestep-ahead forecasting task is a prediction task that involves predicting the next value in a time series based on the current and previous values."
"This task involves predicting the next time step in a time series based on the current and past data."</data>
      <data key="d2">0ae9f3cf96547c05eff54812cb72ac31,d8022c6a3caf781300e2abc1dfd2ed44</data>
    </node>
    <node id="&quot;CLOSED LOOP GENERATIVE MODE&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Closed loop generative mode is a system where the output of the system is fed back into the input, creating a continuous loop of generation and feedback."
"Closed Loop Generative Mode is a system where the output of the model is fed back as input for subsequent prediction."
"Closed loop generative mode involves running the ESN on its own predictions to generate new data."</data>
      <data key="d2">05ba4f2e1a9472bd286417154cb0c0d4,0ae9f3cf96547c05eff54812cb72ac31,d8022c6a3caf781300e2abc1dfd2ed44</data>
    </node>
    <node id="&quot;NP.VSTACK()&quot;">
      <data key="d0">"FUNCTION"</data>
      <data key="d1">"np.vstack() is a function that stacks arrays vertically (row-wise), concatenating arrays along the first axis (rows)."</data>
      <data key="d2">05ba4f2e1a9472bd286417154cb0c0d4</data>
    </node>
    <node id="&quot;NP.ZEROS()&quot;">
      <data key="d0">"FUNCTION"</data>
      <data key="d1">"np.zeros() is a function that creates an array of the specified shape filled with zeros."
"np.zeros() is a function that creates an array of a specified shape filled with zeros."</data>
      <data key="d2">05ba4f2e1a9472bd286417154cb0c0d4,d55aca098e1ba2aea26a4bf33cc2d4a2</data>
    </node>
    <node id="&quot;ONLINE LEARNING&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Online Learning is a method that updates the parameters of a model incrementally with each new sample of data, allowing the model to adapt and continuously improve as new data becomes available."
"Online Learning is a method in Machine Learning where the model is updated incrementally as new data becomes available, allowing for real-time adaptation."
"Online Learning is a process that allows for the continuous updating of a model using new data as it becomes available."</data>
      <data key="d2">1b9bc5f1bd54d2b0c90359b6ed022bb6,6de297d888d10db4c987b5eafc6398b2,d55aca098e1ba2aea26a4bf33cc2d4a2</data>
    </node>
    <node id="&quot;OFFLINE LEARNING&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Offline Learning is a method that requires the entire dataset to be available before training a model, which may not be suitable for scenarios with continuous data streams."
"Offline Learning is a method in Machine Learning where the model is trained on a complete dataset before making predictions, allowing for batch processing."</data>
      <data key="d2">6de297d888d10db4c987b5eafc6398b2,d55aca098e1ba2aea26a4bf33cc2d4a2</data>
    </node>
    <node id="&quot;FORCE ALGORITHM&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"The First Order Reduced and Controlled Error (FORCE) algorithm is a learning algorithm that focuses on reducing the output error and maintaining it small, while minimizing the number of modifications needed to keep the error small."
"FORCE Algorithm is a learning rule used to update the readout parameters at every timestep of input series in the ESN model."
"FORCE Algorithm is a learning rule used to update the readout parameters at every timestep of input series, developed by Sussillo and Abott in 2009."</data>
      <data key="d2">1b9bc5f1bd54d2b0c90359b6ed022bb6,424bf7c7b82dc966139c25f7c9ccffb7,d55aca098e1ba2aea26a4bf33cc2d4a2</data>
    </node>
    <node id="&quot;ZIP()&quot;">
      <data key="d0">"FUNCTION"</data>
      <data key="d1">"zip() is a function that combines multiple iterables into a single iterable, allowing elements from each iterable to be accessed together."</data>
      <data key="d2">d55aca098e1ba2aea26a4bf33cc2d4a2</data>
    </node>
    <node id="&quot;X_GEN&quot;">
      <data key="d0" />
      <data key="d1">
"X_gen is a variable representing the generated values of the input data in the time series."</data>
      <data key="d2">593306edfb8d4c7ef4b99d24fa009970,d55aca098e1ba2aea26a4bf33cc2d4a2</data>
    </node>
    <node id="&quot;LEARNING ALGORITHM&quot;">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">d55aca098e1ba2aea26a4bf33cc2d4a2</data>
    </node>
    <node id="&quot;ENUMERATE&quot;">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">d55aca098e1ba2aea26a4bf33cc2d4a2</data>
    </node>
    <node id="&quot;FIRST ORDER REDUCED AND CONTROLLED ERROR (FORCE) ALGORITHM&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"The FORCE algorithm is a learning algorithm that reduces output error and maintains it small, focusing on decreasing the number of modifications needed to keep the error small."</data>
      <data key="d2">4d8b9e762d08c8cdf5189130be11021e</data>
    </node>
    <node id="&quot;ZIP() FUNCTION&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"The zip() function is a built-in Python function that returns an iterator of tuples, pairing items from input iterables."</data>
      <data key="d2">4d8b9e762d08c8cdf5189130be11021e</data>
    </node>
    <node id="&quot;ENUMERATE() FUNCTION&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"The enumerate() function is a built-in Python function that adds a counter to an iterable, producing pairs of an index and a value."</data>
      <data key="d2">4d8b9e762d08c8cdf5189130be11021e</data>
    </node>
    <node id="&quot;LORENZ CHAOTIC ATTRACTOR&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Lorenz chaotic attractors are solutions to the Lorenz system of differential equations that exhibit chaotic behavior, demonstrating how small differences in initial conditions can lead to vastly different outcomes."
"Lorenz Chaotic Attractor is a mathematical model used to describe chaotic systems, mentioned in the text."
"Lorenz chaotic attractor is a mathematical model used to describe the behavior of a system of differential equations, often used as a test case for dynamical systems."</data>
      <data key="d2">4d114857b77ff15b495bb6456c9ad30c,af2db1cc5ab6b16acae2c93d3facb668,b483c6bbce54156c724905b340aa2e85</data>
    </node>
    <node id="&quot;LORENZ SYSTEM&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"The Lorenz system is a set of differential equations used to model atmospheric convection, which can exhibit chaotic behavior."
"The Lorenz system is a set of ordinary differential equations that describe a flow of fluid in a 3D space. It is known for its chaotic behavior and is represented by the Lorenz attractor."</data>
      <data key="d2">4d114857b77ff15b495bb6456c9ad30c,d4080e34001a0ebe22f20efdb204240b</data>
    </node>
    <node id="&quot;EDWARD LORENZ&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Edward Lorenz is a meteorologist and mathematician who discovered Lorenz chaotic attractors while studying atmospheric convection."</data>
      <data key="d2">4d114857b77ff15b495bb6456c9ad30c</data>
    </node>
    <node id="&quot;H&#201;NON MAP&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"The H&#233;non map is a mathematical function that generates complex patterns and chaotic behavior, named after Michel H&#233;non."
"The H&#233;non map is a discrete-time dynamical system known for its chaotic behavior, which models the Poincar&#233; section of the Lorenz model."
"The H&#233;non map is a mathematical model that exhibits chaotic behavior, often used to illustrate complex dynamics."
"H&#233;non Map is a mathematical model used to describe chaotic systems, mentioned in the text."
"H&#233;non map is a discrete-time dynamical system that exhibits chaotic behavior, often used for testing and comparing the performance of numerical methods."</data>
      <data key="d2">4d114857b77ff15b495bb6456c9ad30c,9ada201f787cd4e88cd18dae60de346d,af2db1cc5ab6b16acae2c93d3facb668,b483c6bbce54156c724905b340aa2e85,d4080e34001a0ebe22f20efdb204240b</data>
    </node>
    <node id="&quot;H&#201;NON&#8211;POMEAU ATTRACTOR/MAP&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"The H&#233;non&#8211;Pomeau attractor/map is an alternative name for the H&#233;non map, which generates complex patterns and chaotic behavior."</data>
      <data key="d2">4d114857b77ff15b495bb6456c9ad30c</data>
    </node>
    <node id="&quot;MICHEL H&#201;NON&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Michel H&#233;non is a French mathematician who introduced the H&#233;non map in 1976."</data>
      <data key="d2">4d114857b77ff15b495bb6456c9ad30c</data>
    </node>
    <node id="&quot;LORENZ ATTRACTOR&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"The Lorenz attractor is a visual representation of the chaotic behavior in the Lorenz system, resembling the shape of a butterfly."</data>
      <data key="d2">d4080e34001a0ebe22f20efdb204240b</data>
    </node>
    <node id="&quot;H&#201;NON STRANGE ATTRACTOR&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"The H&#233;non strange attractor is a fractal structure exhibited by the H&#233;non map, known for its unique and complex shape."
"The H&#233;non strange attractor is a fractal structure that is the attractor of the H&#233;non map, a mathematical model that models the Lorenz model."</data>
      <data key="d2">9ada201f787cd4e88cd18dae60de346d,d4080e34001a0ebe22f20efdb204240b</data>
    </node>
    <node id="&quot;LOGISTIC MAP&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"The Logistic map is a polynomial mapping of degree 1, used to model population growth in a simple way."
"The logistic map is a polynomial mapping of degree 2 that models population dynamics with reproduction and density-dependent mortality, showing chaotic behavior for certain values of a parameter."
"Logistic Map is a mathematical model used to describe chaotic systems, mentioned in the text."
"Logistic map is a discrete-time dynamical system that models population growth, often used to study the onset of chaotic behavior."</data>
      <data key="d2">9ada201f787cd4e88cd18dae60de346d,af2db1cc5ab6b16acae2c93d3facb668,b483c6bbce54156c724905b340aa2e85,d4080e34001a0ebe22f20efdb204240b</data>
    </node>
    <node id="&quot;LORENZ SYSTEM WIKIPEDIA PAGE&quot;">
      <data key="d0">"LOCATION"</data>
      <data key="d1">"The Lorenz system Wikipedia page is a webpage providing information about the Lorenz system and its mathematical representation."</data>
      <data key="d2">d4080e34001a0ebe22f20efdb204240b</data>
    </node>
    <node id="&quot;H&#201;NON MAP WIKIPEDIA PAGE&quot;">
      <data key="d0">"LOCATION"</data>
      <data key="d1">"The H&#233;non map Wikipedia page is a webpage providing information about the H&#233;non map and its chaotic behavior."</data>
      <data key="d2">d4080e34001a0ebe22f20efdb204240b</data>
    </node>
    <node id="&quot;LORENZ MODEL&quot;">
      <data key="d0" />
      <data key="d1">
"The Lorenz model is a system of ordinary differential equations that describes the flow of fluid in a three-dimensional space, known for its chaotic behavior."</data>
      <data key="d2">9ada201f787cd4e88cd18dae60de346d,d4080e34001a0ebe22f20efdb204240b</data>
    </node>
    <node id="&quot;DOUBLE SCROLL ATTRACTOR&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Double scroll attractors, also known as Chua's attractors, are strange attractors observed in a chaotic electronic circuit called Chua's circuit, characterized by a system of three nonlinear ordinary differential equations and a piecewise-linear equation."
"Double scroll attractors are strange attractors observed in a chaotic electronic circuit called Chua's circuit, characterized by a system of three nonlinear ordinary differential equations and a piecewise-linear equation. They resemble two interconnected rings in three-dimensional space and exhibit fractal-like structures."
"The Double Scroll Attractor is a mathematical concept used in the example, representing a complex system of equations."
"Double Scroll Attractor is a mathematical model used to describe chaotic systems, mentioned in the text."
"Double scroll attractor is a mathematical model used to describe the behavior of a system of differential equations, often used to study the dynamics of coupled oscillators."</data>
      <data key="d2">538ff8c18495002c85cbc9020b0146f9,91704ce63f9ba41247fdc452a7a62ba6,9ada201f787cd4e88cd18dae60de346d,af2db1cc5ab6b16acae2c93d3facb668,b483c6bbce54156c724905b340aa2e85</data>
    </node>
    <node id="&quot;CHUA'S CIRCUIT&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Chua's circuit is an electronic circuit that exhibits chaotic behavior, in which double scroll attractors, also known as Chua's attractors, are observed."
"Chua's circuit is an electronic circuit that exhibits chaotic behavior, in which the Double scroll attractor is observed."</data>
      <data key="d2">538ff8c18495002c85cbc9020b0146f9,9ada201f787cd4e88cd18dae60de346d</data>
    </node>
    <node id="&quot;CHAOTIC BEHAVIOR&quot;">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">9ada201f787cd4e88cd18dae60de346d</data>
    </node>
    <node id="&quot;SCIKIT-LEARN&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"scikit-learn is a machine learning library for Python that provides simple and efficient tools for data analysis and modeling."
"Scikit-Learn is a machine learning library in Python that provides simple and efficient tools for data mining and data analysis."
"Scikit-learn is a popular machine learning library that provides various algorithms and tools for data analysis and modeling."
"scikit-learn is a machine learning library in Python that provides simple and efficient tools for data analysis and modeling."
"scikit-learn is a machine learning library that implements various classifiers such as RidgeClassifier, LogisticRegression, and Perceptron."
"Scikit-learn is a library used for machine learning in Python, providing implementations for RidgeClassifier, LogisticRegression, and Perceptron."
"scikit-learn is mentioned as a library that offers a simple API to apply ML techniques, but it lacks flexibility and is not meant to create complex neural networks operating on timeseries, with feedback loops and online learning rules."
"scikit-learn is a machine learning library in Python that provides simple and efficient tools for data mining and data analysis."
"scikit-learn is an open-source machine learning library for Python, which offers a high-level object-oriented API for end-to-end training, similar to the functionality provided by reservoirpy for Reservoir Computing."
"scikit-learn is a machine learning library that provides tools for data analysis and modeling."
"scikit-learn is a machine learning library that experiences have been shared from in a conference."
"Scikit-Learn is a library used for machine learning in Python, providing tools for data analysis and modeling."
"Scikit-learn is a library used for machine learning tasks, providing algorithms such as RidgeClassifier, LogisticRegression, and Perceptron."</data>
      <data key="d2">0036fb6f489e13c0db0f1c02bf3323be,295606b4bc5d12929a913a3c79f93734,538ff8c18495002c85cbc9020b0146f9,82de30f43839f4985de20a981b524af1,8c66981c9d2009113219bbf2681f664c,b130d3d59f0d3a2bb4feac9fdb85ed5b,bc2d4d6bb706c3d06ffd2c9c2f362104,c05906c1f12c4edfc32a04aa9935067e,ce7b58ffc7f43f36bc78154597d01903,d58662ee42c14a0787d839ebfd0a6e9b,d622f95153798af8bb6f485db54aaea3,eebc9d7d2b66e3898b7d068c38fd200f,f5358a50d00a1cac02dd4ad8fcb167ee</data>
    </node>
    <node id="&quot;MODULENOTFOUNDERROR&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"ModuleNotFoundError is a Python exception that occurs when an imported module cannot be found."</data>
      <data key="d2">538ff8c18495002c85cbc9020b0146f9</data>
    </node>
    <node id="&quot;GLOB.GLOB()&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"glob.glob() is a Python function that retrieves all file paths matching a specified pattern and returns a list of those paths."
"glob.glob() is a function that retrieves all file paths matching a specified pattern and returns them as a list."</data>
      <data key="d2">538ff8c18495002c85cbc9020b0146f9,fb40afaf160923869aba1456b3a1ddca</data>
    </node>
    <node id="&quot;FILE PATHS&quot;">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">538ff8c18495002c85cbc9020b0146f9</data>
    </node>
    <node id="&quot;IKIT-LEARN&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"ikit-learn is a machine learning library that provides tools for data analysis and modeling."</data>
      <data key="d2">fb40afaf160923869aba1456b3a1ddca</data>
    </node>
    <node id="&quot;PARALLEL()&quot;">
      <data key="d0">"FUNCTION"</data>
      <data key="d1">"Parallel() is a function from the Joblib library that enables parallel processing, allowing for the concurrent execution of tasks."</data>
      <data key="d2">fb40afaf160923869aba1456b3a1ddca</data>
    </node>
    <node id="&quot;DELAYED()&quot;">
      <data key="d0">"FUNCTION"</data>
      <data key="d1">"delayed() is a function from the Joblib library that creates a lazy evaluation of the function it wraps, enabling parallel processing."
"delayed() is a function in Joblib used to create a lazy evaluation of the function it wraps, allowing for concurrent execution of tasks."</data>
      <data key="d2">f3b5b178557c4991ab5b81d869a4752e,fb40afaf160923869aba1456b3a1ddca</data>
    </node>
    <node id="&quot;PD.READ_CSV()&quot;">
      <data key="d0">"FUNCTION"</data>
      <data key="d1">"pd.read_csv() is a function from the pandas library that reads a CSV file and returns a DataFrame."</data>
      <data key="d2">fb40afaf160923869aba1456b3a1ddca</data>
    </node>
    <node id="&quot;R4-DATA/EXPERIMENTS/&quot;">
      <data key="d0">"DIRECTORY"</data>
      <data key="d1">"r4-data/experiments/ is a directory where files are located for data analysis and modeling."</data>
      <data key="d2">fb40afaf160923869aba1456b3a1ddca</data>
    </node>
    <node id="&quot;PD.READ_CSV&quot;">
      <data key="d0">"FUNCTION"</data>
      <data key="d1">"pd.read_csv is a function in the pandas library used to read a CSV file and return a DataFrame."</data>
      <data key="d2">f3b5b178557c4991ab5b81d869a4752e</data>
    </node>
    <node id="&quot;PARALLEL&quot;">
      <data key="d0">"FUNCTION"</data>
      <data key="d1">"parallel is a function in Joblib used to run tasks concurrently, allowing for faster data loading and processing."</data>
      <data key="d2">f3b5b178557c4991ab5b81d869a4752e</data>
    </node>
    <node id="&quot;NP.ROLL&quot;">
      <data key="d0">"FUNCTION"</data>
      <data key="d1">"np.roll is a function in the NumPy library used to shift the elements of an array by a specified number of positions."
"np.roll is a function that circularly shifts the elements of an array by a specified number of positions."</data>
      <data key="d2">584889d2db258e32e7f673d3c0a0e603,f3b5b178557c4991ab5b81d869a4752e</data>
    </node>
    <node id="&quot;RMSE&quot;">
      <data key="d0">"FUNCTION"</data>
      <data key="d1">"rmse is a function used to calculate the Root Mean Square Error, a common metric for evaluating the performance of a model."

"RMSE is the Root Mean Square Error, a metric used to evaluate the performance of the Echo State Network."

"RMSE stands for Root Mean Squared Error, a metric used to evaluate the performance of a prediction model."
"RMSE stands for Root Mean Square Error, which is a measure of the differences between values predicted by a model and the values observed."</data>
      <data key="d2">251a50c2ae8ceea4fd7da1127cc5f461,584889d2db258e32e7f673d3c0a0e603,bf4eaad93f89884d02cdad6a50f145a6,d15f6d075c072f0335b5332f11c00299,f3b5b178557c4991ab5b81d869a4752e,f730c6800099724052a2d061f3cd8c2e</data>
    </node>
    <node id="&quot;ARRAY ELEMENTS&quot;">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">f3b5b178557c4991ab5b81d869a4752e</data>
    </node>
    <node id="&quot;MODEL PERFORMANCE&quot;">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">f3b5b178557c4991ab5b81d869a4752e</data>
    </node>
    <node id="&quot;ROOT MEAN SQUARED ERROR (RMSE)&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"RMSE is a statistical measure that quantifies the average magnitude of the errors between predicted and actual values."
"Root Mean Squared Error (RMSE) is a loss function used to evaluate the quality of parameters in optimization algorithms, such as hyperopt."
"RMSE is a loss function used to evaluate the quality of parameters in optimization algorithms, such as hyperopt."</data>
      <data key="d2">251a50c2ae8ceea4fd7da1127cc5f461,4f7b43545046f0e6f9b6fb3816da1d79,584889d2db258e32e7f673d3c0a0e603</data>
    </node>
    <node id="&quot;AVERAGED RMSE&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Averaged RMSE is the average of the Root Mean Squared Errors, providing an overall measure of prediction accuracy."
"Averaged RMSE is a metric used to evaluate the performance of a model, with a lower value indicating better accuracy."</data>
      <data key="d2">1e8ee805d22cd143d2372d300997d253,584889d2db258e32e7f673d3c0a0e603</data>
    </node>
    <node id="&quot;AVERAGED RMSE (WITH THRESHOLD)&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Averaged RMSE (with threshold) is a variant of Averaged RMSE that considers only predictions within a specific range, providing a more focused measure of prediction accuracy."</data>
      <data key="d2">584889d2db258e32e7f673d3c0a0e603</data>
    </node>
    <node id="&quot;GLOB.GLOB&quot;">
      <data key="d0">"FUNCTION"</data>
      <data key="d1">"glob.glob is a function that finds all pathnames matching a specified pattern, allowing for the retrieval of files with a specific extension."</data>
      <data key="d2">584889d2db258e32e7f673d3c0a0e603</data>
    </node>
    <node id="&quot;SORTED&quot;">
      <data key="d0">"FUNCTION"</data>
      <data key="d1">"sorted is a function that sorts the elements of a list in ascending order."</data>
      <data key="d2">584889d2db258e32e7f673d3c0a0e603</data>
    </node>
    <node id="&quot;LBR.FEATURE.MFCC&quot;">
      <data key="d0">"FUNCTION"</data>
      <data key="d1">"lbr.feature.mfcc is a function that computes the Mel-frequency cepstral coefficients (MFCCs) of a given audio signal, which are commonly used for speech and audio processing tasks."</data>
      <data key="d2">584889d2db258e32e7f673d3c0a0e603</data>
    </node>
    <node id="&quot;CIRCULAR SHIFT&quot;">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">584889d2db258e32e7f673d3c0a0e603</data>
    </node>
    <node id="&quot;FILE RETRIEVAL&quot;">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">584889d2db258e32e7f673d3c0a0e603</data>
    </node>
    <node id="&quot;ASCENDING ORDER&quot;">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">584889d2db258e32e7f673d3c0a0e603</data>
    </node>
    <node id="&quot;SPEECH AND AUDIO PROCESSING&quot;">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">584889d2db258e32e7f673d3c0a0e603</data>
    </node>
    <node id="&quot;SORTED() FUNCTION&quot;">
      <data key="d0">"TECHNOLOGY"</data>
      <data key="d1">"The sorted() function is a built-in Python function that sorts elements in a list in ascending order."</data>
      <data key="d2">7bea9e814256104a2d7ede466ddc3364</data>
    </node>
    <node id="&quot;GLOB.GLOB() FUNCTION&quot;">
      <data key="d0">"TECHNOLOGY"</data>
      <data key="d1">"The glob.glob() function is a Python function that finds all pathnames matching a specified pattern according to the rules used by the Unix shell, making it useful for file operations."</data>
      <data key="d2">7bea9e814256104a2d7ede466ddc3364</data>
    </node>
    <node id="&quot;MFCCS&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"MFCCs (Mel-Frequency Cepstral Coefficients) are features commonly used in speech and audio processing to capture the spectral properties of an audio signal."
</data>
      <data key="d2">7bea9e814256104a2d7ede466ddc3364,e3828ad4e78d575fabb543e0eab86160</data>
    </node>
    <node id="&quot;LIBROSA LIBRARY&quot;">
      <data key="d0">"TECHNOLOGY"</data>
      <data key="d1">"The librosa library is a Python library for analyzing audio and music. It has functions for extracting MFCCs and other features from audio signals."</data>
      <data key="d2">7bea9e814256104a2d7ede466ddc3364</data>
    </node>
    <node id="&quot;DELTA&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Delta refers to a change or difference, but in the provided text, the term 'delta' is not explicitly defined or used in the context of audio processing or MFCCs."
"Delta is a feature extraction technique used to capture the rate of change of MFCC coefficients over time."</data>
      <data key="d2">7bea9e814256104a2d7ede466ddc3364,adfade0d7bc85c6420e61ecd1ce7095c</data>
    </node>
    <node id="&quot;LIBROSA&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"librosa is a Python library used for analyzing audio and music, providing functions for feature extraction and processing."
"librosa is a Python library for audio and music analysis, which provides functions for calculating Mel-Frequency Cepstral Coefficients (MFCCs) and their delta coefficients."
"librosa is a Python library for audio and music analysis, used for processing audio data."
"Librosa is a Python library for audio and music analysis, used for processing audio data in the text."</data>
      <data key="d2">1e8ee805d22cd143d2372d300997d253,7c8a0a6b9506a584f1c98495097d48ee,aea362ee35c2a3a01b76020d0b892cbd,e3828ad4e78d575fabb543e0eab86160</data>
    </node>
    <node id="&quot;MEL-FREQUENCY CEPSTRAL COEFFICIENTS (MFCCS)&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"MFCCs are a type of feature used in audio signal processing to capture the spectral properties of the audio signal."
"MFCCs are a feature extraction technique used in audio and speech processing, representing the short-term power spectrum of a signal."</data>
      <data key="d2">7c8a0a6b9506a584f1c98495097d48ee,e3828ad4e78d575fabb543e0eab86160</data>
    </node>
    <node id="&quot;DELTA COEFFICIENTS&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Delta Coefficients are derived from the MFCCs and capture the temporal dynamics of the MFCCs, enhancing the feature set for tasks like audio and speech processing."
"Delta coefficients are the first-order differences of the MFCCs, capturing the temporal dynamics of the MFCCs and enhancing the feature set for tasks like audio and speech processing."
"Delta coefficients are a measure of the rate of change of a signal, used in audio and music analysis."</data>
      <data key="d2">7c8a0a6b9506a584f1c98495097d48ee,aea362ee35c2a3a01b76020d0b892cbd,e3828ad4e78d575fabb543e0eab86160</data>
    </node>
    <node id="&quot;SECOND-ORDER DIFFERENCES (OR DELTA-DELTAS)&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Second-order differences (or delta-deltas) of the MFCCs are the second-order derivatives of the input feature matrix, capturing the acceleration or the rate of change of the delta coefficients."</data>
      <data key="d2">7c8a0a6b9506a584f1c98495097d48ee</data>
    </node>
    <node id="&quot;EDGE EFFECTS&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Edge effects refer to artifacts or distortions that occur at the boundaries of a signal, which can affect the accuracy of analysis."</data>
      <data key="d2">aea362ee35c2a3a01b76020d0b892cbd</data>
    </node>
    <node id="&quot;DATAFRAME&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"DataFrame is a two-dimensional labeled data structure with columns of potentially different types, used for data manipulation and analysis."</data>
      <data key="d2">aea362ee35c2a3a01b76020d0b892cbd</data>
    </node>
    <node id="&quot;NAMED TUPLES&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Named tuples are a subclass of the built-in tuple type that have fields accessible by attribute lookup as well as being indexable and iterable."</data>
      <data key="d2">aea362ee35c2a3a01b76020d0b892cbd</data>
    </node>
    <node id="&quot;ONE-HOT ENCODING&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"One-hot encoding is a process of converting categorical data variables so they can be provided to machine learning algorithms, which require numerical input."</data>
      <data key="d2">aea362ee35c2a3a01b76020d0b892cbd</data>
    </node>
    <node id="&quot;CATEGORICAL DATA&quot;">
      <data key="d0" />
      <data key="d1">
"Categorical data is data that consists of labels or categories, rather than numerical values. In the given example, the phrase labels are categorical data that is transformed into a binary matrix representation using the OneHotEncoder function."</data>
      <data key="d2">aea362ee35c2a3a01b76020d0b892cbd,d5477dbd84525291f2e017ae618de222</data>
    </node>
    <node id="&quot;ONEHOTENCODER&quot;">
      <data key="d0">"TECHNOLOGY"</data>
      <data key="d1">"OneHotEncoder is a function used for transforming categorical data into a binary matrix representation, which is useful for feeding categorical data into machine learning models."
"OneHotEncoder is a function used for converting categorical data into a format that can be used by machine learning algorithms."
"OneHotEncoder is a function from the scikit-learn library used for one-hot encoding of categorical variables."</data>
      <data key="d2">71366a4c7e791080872ba783d3787bd7,84a64dd2c683e779d55aaccea16b1032,d5477dbd84525291f2e017ae618de222</data>
    </node>
    <node id="&quot;SPARSE_OUTPUT&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"sparse_output is a parameter of the OneHotEncoder function that determines whether the output should be a sparse matrix or a dense array. A sparse matrix is a data structure that only stores non-zero elements, which can be more memory-efficient for large datasets with many zeros."
"sparse_output is a parameter in the OneHotEncoder function that specifies the format of the resulting one-hot encoded matrix."</data>
      <data key="d2">84a64dd2c683e779d55aaccea16b1032,d5477dbd84525291f2e017ae618de222</data>
    </node>
    <node id="&quot;MACHINE LEARNING MODELS&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Machine learning models are algorithms that can learn patterns from data and make predictions or decisions based on that learning. One-hot encoding is a preprocessing step that can make categorical data more suitable for feeding into machine learning models."</data>
      <data key="d2">d5477dbd84525291f2e017ae618de222</data>
    </node>
    <node id="&quot;FLATTEN()&quot;">
      <data key="d0">"FUNCTION"</data>
      <data key="d1">"flatten() is a function that converts a multi-dimensional array into a one-dimensional array."</data>
      <data key="d2">84a64dd2c683e779d55aaccea16b1032</data>
    </node>
    <node id="&quot;ARGMAX()&quot;">
      <data key="d0">"FUNCTION"</data>
      <data key="d1">"argmax() is a function that returns the indices of the maximum values along the specified axis."</data>
      <data key="d2">84a64dd2c683e779d55aaccea16b1032</data>
    </node>
    <node id="&quot;HYPEROPT&quot;">
      <data key="d0">"TECHNOLOGY"</data>
      <data key="d1">"Hyperopt is a Python library used for optimizing hyperparameters of machine learning models."
"Hyperopt is a Python library used for optimizing hyperparameters of machine learning models, leveraging algorithms like random search, grid search, and Bayesian optimization."
"Hyperopt is a library used for hyperparameter optimization, mentioned in the text."
"Hyperopt is a Python library used for hyperparameter optimization, which is being used in the context of Echo State Networks."
"Hyperopt is a library used by ReservoirPy for searching the best set of hyperparameters that minimize the loss function."
"Hyperopt is a Python library for hyperparameter optimization, which may be used in the Python Notebooks for reservoir computing."
"Hyperopt is a Python library for hyperparameter optimization, which can be used with ReservoirPy."
"Hyperopt is a tool used for hyperparameter optimization, mentioned in the text."
"Hyperopt is a Python library used for hyperparameter optimization, which involves finding the best combination of parameters for a given model or function."
"Hyperopt is a tool used to approximate a function and find a minimum, mentioned in the text."
"Hyperopt is a Python library used for hyperparameter optimization, mentioned in the provided text."
"Hyperopt is a Python library used for hyperparameter optimization."
"Hyperopt is a tool used for hyperparameter optimization, which is mentioned in the text."
"Hyperopt is a tool mentioned for optimizing parameters, which uses a random distribution of parameters and enough trials to increase the chance of finding a relevant minimum."
"Hyperopt is a Python library for optimizing the hyperparameters of machine learning algorithms, mentioned in the text."
"Hyperopt is a python library for optimizing the hyperparameters of machine learning algorithms, authored by James Bergstra, Dan Yamins, and David D Cox."
"Hyperopt is a Python library for hyperparameter optimization, which is used in the provided code to explore different sets of parameters."
"Hyperopt is a tool used for hyperparameter optimization, which is being used to explore different sets of parameters."
"Hyperopt is a Python library for hyperparameter optimization, which is mentioned in the text."
"Hyperopt is a Python library for hyperparameter optimization, mentioned in the text."</data>
      <data key="d2">0753d4e507badadd900c522ee03ad28d,0982b8d1eb1e636b19fa2e9d9361e566,0a9b132ecb1c4b63fdbb0e144295362e,0b6c69085074b2cf23267eb149068b9f,11749b7d0fdadf05ea29da6025618407,251a50c2ae8ceea4fd7da1127cc5f461,25743a99f36f3e56551ffafbba8d15c4,280cbdf53022bbaed48ccb34ebe142bc,3b4d50c051c177770830f7c0a6b3dd69,46913f0d73ba0b8cecfdf42bde9862f4,65ba78d1f678e080bd930319c54234ef,6a6d88a8f9731e1ed05b786e0a9ba6dc,75e530c1a04e30b373dc7cc68e3ad819,82de30f43839f4985de20a981b524af1,82ff270b1bbdfe0ee11e603de1e326c7,84a64dd2c683e779d55aaccea16b1032,870f29520f7a1c42eecb0c4ff855f09e,9abdbd696e340cb5dd8c66ac5cd30c67,a3a74dc4754a8c8b0730f808285893e2,c5413fef3b2d7e4d688c66e6046b56c7</data>
    </node>
    <node id="&quot;NP.ARGMAX()&quot;">
      <data key="d0">"FUNCTION"</data>
      <data key="d1">"np.argmax() is a function that returns the indices of the maximum values along the specified axis."</data>
      <data key="d2">3b4d50c051c177770830f7c0a6b3dd69</data>
    </node>
    <node id="&quot;RESERVOIRPY.HYPER&quot;">
      <data key="d0">"MODULE"</data>
      <data key="d1">"reservoirpy.hyper is a module in the ReservoirPy library designed for optimizing hyperparameters of Echo State Networks (ESNs)."</data>
      <data key="d2">3b4d50c051c177770830f7c0a6b3dd69</data>
    </node>
    <node id="&quot;UNITS&quot;">
      <data key="d0">"HYPERPARAMETER"</data>
      <data key="d1">"UNITS is a hyperparameter that refers to the number of neurons inside the reservoir of an Echo State Network (ESN)."
"UNITS is a hyperparameter that refers to the number of neurons inside the reservoir."
"Units refer to the number of processing elements in the reservoir of Reservoir Computing."
"units refers to the number of neurons in the reservoir of the ESN."
"Units refer to the number of nodes in the Reservoir component of the ESN model."
"UNITS is a term used to refer to a specific number of units or components in the Reservoir system."</data>
      <data key="d2">09198e939639c229c2c97555f65b12a7,3b4d50c051c177770830f7c0a6b3dd69,72e6eee633bcb5b1458c4cee3975cee1,8ecf03267c90a64376f5040307d98195,a8df60a94e25d863b436f47f4f8e6a6d,bba680a0a7dd439bd5b0fe1547ffe040</data>
    </node>
    <node id="&quot;SPECTRAL_RADIUS&quot;">
      <data key="d0">"HYPERPARAMETER"</data>
      <data key="d1">"SPECTRAL_RADIUS is a hyperparameter that refers to the maximum absolute eigenvalue of the reservoir matrix in an Echo State Network (ESN). It affects the stability and chaos of the dynamics."
"SPECTRAL_RADIUS is a hyperparameter that refers to the maximum absolute eigenvalue of the reservoir matrix, influencing the dynamics' stability and chaos."
"spectral_radius is a parameter used to set the spectral radius of the reservoir's weight matrix in the ESN."
"SPECTRAL_RADIUS is a mathematical concept used in the text, likely in the context of the Reservoir system."</data>
      <data key="d2">09198e939639c229c2c97555f65b12a7,3b4d50c051c177770830f7c0a6b3dd69,a8df60a94e25d863b436f47f4f8e6a6d,bba680a0a7dd439bd5b0fe1547ffe040</data>
    </node>
    <node id="&quot;CORRELATION&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Correlation is a statistical relationship between two variables, ranging from -1 to 1, indicating the degree and direction of their relationship."
"Correlation is a measure used to determine the relationship between two variables, in this context, the correlation between reservoir states and inputs."
"Correlation is a statistical concept used to measure the relationship between two variables, which is mentioned in the text."</data>
      <data key="d2">8553a88d9aaf4f71d359c721a1f6fa70,a8df60a94e25d863b436f47f4f8e6a6d,b957e1bf5bf175c7630222ca742c7933</data>
    </node>
    <node id="&quot;NP.CORRCOEF()&quot;">
      <data key="d0">"FUNCTION"</data>
      <data key="d1">"np.corrcoef() is a function used to calculate the Pearson correlation coefficient matrix between two or more variables."</data>
      <data key="d2">a8df60a94e25d863b436f47f4f8e6a6d</data>
    </node>
    <node id="&quot;INPUT_SCALING&quot;">
      <data key="d0">"HYPERPARAMETER"</data>
      <data key="d1">"INPUT_SCALING is a hyperparameter that refers to a coefficient applied to the inputs of the reservoir, influencing the correlation between states and inputs."
"INPUT_SCALING is a hyperparameter that adjusts the gain of the inputs to the reservoir, influencing the correlation between states and inputs."
"input_scaling is a parameter explored by hp_space that represents the input scaling, fixed to 1.0 in the provided configuration."
"input_scaling is a parameter explored by hp_space, fixed to 1.0."
"input_scaling is a parameter that specifies the input scaling, which is fixed."
"input_scaling is a parameter used to scale the input data in the ESN."</data>
      <data key="d2">09198e939639c229c2c97555f65b12a7,5cea9edfd65fcfa25a081554300b28cc,76f47f241e255f9f36646409d2ec30f1,80033e741d8e10abdcfe20dd17192152,a8df60a94e25d863b436f47f4f8e6a6d,adfc38e9dc5e6fd0fe67ce83dfa1f154</data>
    </node>
    <node id="&quot;PERSON CORRELATION COEFFICIENT&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Person Correlation Coefficient is a statistical measure used to determine the linear relationship between two continuous variables."</data>
      <data key="d2">76f47f241e255f9f36646409d2ec30f1</data>
    </node>
    <node id="&quot;RC_CONNECTIVITY&quot;">
      <data key="d0">"HYPERPARAMETER"</data>
      <data key="d1">"RC_CONNECTIVITY is a hyperparameter that determines the density of the reservoir's internal matrix."
"RC_CONNECTIVITY is a term used in the text, likely referring to the connectivity or interconnection of units within the Reservoir system."</data>
      <data key="d2">76f47f241e255f9f36646409d2ec30f1,bba680a0a7dd439bd5b0fe1547ffe040</data>
    </node>
    <node id="&quot;INPUT_CONNECTIVITY&quot;">
      <data key="d0">"HYPERPARAMETER"</data>
      <data key="d1">"INPUT_CONNECTIVITY is a hyperparameter that determines the density of the reservoir's input matrix."
"input_connectivity is a parameter used to set the sparsity of the input-to-reservoir weight matrix in the ESN."
"INPUT_CONNECTIVITY is a term used in the text, likely referring to the connection or interaction of external inputs with the Reservoir system."</data>
      <data key="d2">09198e939639c229c2c97555f65b12a7,76f47f241e255f9f36646409d2ec30f1,bba680a0a7dd439bd5b0fe1547ffe040</data>
    </node>
    <node id="&quot;REGULARIZATION&quot;">
      <data key="d0">"HYPERPARAMETER"</data>
      <data key="d1">"REGULARIZATION is a hyperparameter that represents the regularization coefficient for ridge regression."
"Regularization is a technique used to smooth the ESN Models and reduce overfitting, leading to smaller output weights."
"Regularization is a parameter in Reservoir Computing used to prevent overfitting and improve the generalization of the model."
"regularization is a parameter used to control the amount of regularization in the Ridge readout of the ESN."
"Regularization is a technique used in the ESN model to prevent overfitting and improve generalization."</data>
      <data key="d2">09198e939639c229c2c97555f65b12a7,2386633041e820b604fc4457264b5a33,5972cf7d440b1c3fdc0f05fca305f18d,72e6eee633bcb5b1458c4cee3975cee1,76f47f241e255f9f36646409d2ec30f1</data>
    </node>
    <node id="&quot;LEAK_RATE&quot;">
      <data key="d0">"HYPERPARAMETER"</data>
      <data key="d1">"LEAK_RATE is a hyperparameter that controls the time constant of the ESN, influencing the inertia and recall of previous states."
"LEAK_RATE is a hyperparameter that controls the time constant of a system, influencing its inertia and recall of previous states."
"leak_rate is a parameter used to control the leakage of the reservoir's neurons in the ESN."
"LEAK_RATE is a term used in the text, likely referring to a rate of information loss or decay in the Reservoir system."</data>
      <data key="d2">09198e939639c229c2c97555f65b12a7,3c4d88c41f6efbfccea6f8814bf8430e,76f47f241e255f9f36646409d2ec30f1,bba680a0a7dd439bd5b0fe1547ffe040</data>
    </node>
    <node id="&quot;DOUBLE-SCROLL ATTRACTOR&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Double-Scroll Attractor is a type of chaotic attractor observed in certain nonlinear dynamical systems."
"A Double-Scroll Attractor is a type of chaotic attractor observed in certain nonlinear dynamical systems, characterized by its distinctive shape of intertwined scrolls or spirals."
"Double-Scroll Attractor is a mathematical concept used in the example, representing a complex system of differential equations."</data>
      <data key="d2">2d8ea1123f365fb047b024022ba4fdc4,3c4d88c41f6efbfccea6f8814bf8430e,76f47f241e255f9f36646409d2ec30f1</data>
    </node>
    <node id="&quot;DOUBLESCROLL() FUNCTION&quot;">
      <data key="d0">"TECHNOLOGY"</data>
      <data key="d1">"The doublescroll() function is used to simulate the dynamics of a system that generates a Double-Scroll Attractor."</data>
      <data key="d2">3c4d88c41f6efbfccea6f8814bf8430e</data>
    </node>
    <node id="&quot;.CIVIDIS() FUNCTION&quot;">
      <data key="d0">"TECHNOLOGY"</data>
      <data key="d1">"The .cividis() function is used to obtain a color in a system or process."</data>
      <data key="d2">3c4d88c41f6efbfccea6f8814bf8430e</data>
    </node>
    <node id="&quot;RK23&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"RK23 is a system that generates a double-scroll attractor, used for simulation and analysis."</data>
      <data key="d2">7c7818502732457fb71aacdd9a90ee36</data>
    </node>
    <node id="&quot;THE OPTIMIZATION ALGORITHM&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"The Optimization Algorithm is a process that seeks to find the best parameters to minimize a loss function, such as RMSE (Root Mean Squared Error)."</data>
      <data key="d2">7c7818502732457fb71aacdd9a90ee36</data>
    </node>
    <node id="&quot;THE OBJECTIVE FUNCTION&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"The Objective Function is defined as the function to be optimized, which measures the quality of the parameters chosen in the Optimization Algorithm."</data>
      <data key="d2">7c7818502732457fb71aacdd9a90ee36</data>
    </node>
    <node id="&quot;THE LOSS FUNCTION&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"The Loss Function is RMSE (Root Mean Squared Error), used to evaluate the quality of the parameters chosen in the Optimization Algorithm."</data>
      <data key="d2">7c7818502732457fb71aacdd9a90ee36</data>
    </node>
    <node id="&quot;R-SQUARED (R^2)&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"R-squared (R^2) is an additional metric used to assess the goodness of fit of a model."</data>
      <data key="d2">4f7b43545046f0e6f9b6fb3816da1d79</data>
    </node>
    <node id="&quot;OBJECTIVE FUNCTION&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Objective Function is a function used to evaluate the quality of parameters in optimization algorithms, such as hyperopt. In this context, it refers to the Root Mean Squared Error (RMSE) and R-squared (R^2) functions."
"Objective Function is a function that calculates the loss or error of a machine learning model, which ReservoirPy uses to optimize hyperparameters."
"The objective function is a function that defines the goal of the optimization process in ReservoirPy."
"The Objective Function is the function that the Optimization Algorithm aims to optimize, measuring the performance of the forecasting task."
"The Objective Function is the function that is being optimized in hyperparameter optimization, which in this case is the Root Mean Squared Error (RMSE) loss function."
"The Objective Function is a function that defines the goal to be optimized, mentioned in the text."
"The objective function is a part of the provided code, used to evaluate and optimize the performance of a machine learning model."</data>
      <data key="d2">0753d4e507badadd900c522ee03ad28d,11749b7d0fdadf05ea29da6025618407,251a50c2ae8ceea4fd7da1127cc5f461,4f7b43545046f0e6f9b6fb3816da1d79,91704ce63f9ba41247fdc452a7a62ba6,9abdbd696e340cb5dd8c66ac5cd30c67,d4684af3c445d312afe4d838abc45502</data>
    </node>
    <node id="&quot;HYPERPARAMETER OPTIMIZATION&quot;">
      <data key="d0">"EVENT"</data>
      <data key="d1">"Hyperparameter Optimization is the process of finding the best hyperparameters for a machine learning model, which is facilitated by ReservoirPy."
"Hyperparameter Optimization is a process that involves finding the best hyperparameters for a machine learning model to improve its performance."
"Hyperparameter Optimization is the process of finding the best hyperparameters for a machine learning model, such as Echo State Networks, to improve its performance."
"Hyperparameter Optimization is the process of finding the best hyperparameters for a machine learning model."
"Hyperparameter Optimization is the process of finding the best combination of parameters for a model, which is facilitated by Objective Functions in this context."</data>
      <data key="d2">0113164912437e96423379cb9c039f56,46913f0d73ba0b8cecfdf42bde9862f4,bd4cf5e35045463b7f0d8da82debc122,d4684af3c445d312afe4d838abc45502,f70c7d3d89baaabbeaad57b58e379e08</data>
    </node>
    <node id="&quot;CONFIG FILE&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Config File is a JSON file that defines the hyperparameters and settings for the hyperparameter optimization process, which is used in ReservoirPy."</data>
      <data key="d2">d4684af3c445d312afe4d838abc45502</data>
    </node>
    <node id="&quot;DATASET&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Dataset is the data used for training and testing a machine learning model, which is split into training and testing sets in the objective function."
"dataset is an object that contains the data used for training and testing an Echo State Network (ESN)."
"The dataset is the input data used for training and evaluating machine learning models in ReservoirPy."
"Dataset is the collection of data used for training and testing the machine learning model."
"Dataset is a variable used to store the input and target data for training and testing, which is mentioned in the text."</data>
      <data key="d2">0982b8d1eb1e636b19fa2e9d9361e566,1db191f05801d40d5a346febd10d3352,9abdbd696e340cb5dd8c66ac5cd30c67,d4684af3c445d312afe4d838abc45502,f70c7d3d89baaabbeaad57b58e379e08</data>
    </node>
    <node id="&quot;CONFIGURATION FILE&quot;">
      <data key="d0">"FILE"</data>
      <data key="d1">"The Configuration File is a JSON file that defines the hyperparameters and settings for the Hyperparameter Optimization process."</data>
      <data key="d2">bd4cf5e35045463b7f0d8da82debc122</data>
    </node>
    <node id="&quot;RANDOM SEARCH ALGORITHM&quot;">
      <data key="d0">"TECHNIQUE"</data>
      <data key="d1">"Random Search Algorithm is a technique used in Hyperparameter Optimization to randomly choose parameters within a specified range, maximizing the chances of reaching a local minimum."
"Random Search Algorithm is a method mentioned for hyperparameter optimization, which involves randomly choosing parameters within a specified range."
"Random Search Algorithm is a method used to optimize parameters by randomly choosing values within a specified range."</data>
      <data key="d2">0a9b132ecb1c4b63fdbb0e144295362e,25743a99f36f3e56551ffafbba8d15c4,bd4cf5e35045463b7f0d8da82debc122</data>
    </node>
    <node id="&quot;GRID SEARCH&quot;">
      <data key="d0">"TECHNIQUE"</data>
      <data key="d1">"Grid Search is a technique used in Hyperparameter Optimization that involves a systematic search through a manually specified subset of the hyperparameter space of a learning algorithm."
"Grid Search is a hyperparameter tuning technique used to find the best combination of parameters for a model."
"Grid Search is a method mentioned for hyperparameter optimization, which involves systematically searching through a grid of parameters."
"Grid Search is a method mentioned as adding a bias during optimization, which could prevent finding a relevant minimum."</data>
      <data key="d2">0a9b132ecb1c4b63fdbb0e144295362e,25743a99f36f3e56551ffafbba8d15c4,b3361508c3e49b5bb3089f10e31d2c81,bd4cf5e35045463b7f0d8da82debc122</data>
    </node>
    <node id="&quot;PARAMETERS&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Parameters are variables that can be adjusted to optimize a model or algorithm, mentioned in the text."</data>
      <data key="d2">6a6d88a8f9731e1ed05b786e0a9ba6dc</data>
    </node>
    <node id="&quot;LOSS&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Loss is a measure of the error or discrepancy between the predicted and actual values in a model, mentioned in the text."
"Loss is a measure of the error or discrepancy between predicted and actual values in a machine learning model."
"Loss is a metric used to evaluate the performance of the machine learning model, representing the error between predicted and actual values."
"Loss is a metric used to evaluate the performance of the machine learning model during training."
"Loss is a measure of the error or discrepancy between the predicted and actual values in a model."</data>
      <data key="d2">136d135c710f6cf78a4c536d43276fe1,6a6d88a8f9731e1ed05b786e0a9ba6dc,716940af834825642e01a3cb59a7e006,75e530c1a04e30b373dc7cc68e3ad819,f70c7d3d89baaabbeaad57b58e379e08</data>
    </node>
    <node id="&quot;EXPERIMENTATION&quot;">
      <data key="d0">"EVENT"</data>
      <data key="d1">"Experimentation refers to the process of testing and optimizing parameters, mentioned in the text."
"Experimentation refers to the process of designing and conducting experiments to test hypotheses, gather data, and make decisions."</data>
      <data key="d2">251a50c2ae8ceea4fd7da1127cc5f461,6a6d88a8f9731e1ed05b786e0a9ba6dc</data>
    </node>
    <node id="&quot;HINAUT, X.&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Hinaut, X. is an author of a guide on hyperparameter exploration mentioned in the text."
"Hinaut, X. is an author mentioned in the text, contributing to a guide on exploring hyper-parameters for Echo State Networks."</data>
      <data key="d2">088d2280349d652200861994c09d7dd5,6a6d88a8f9731e1ed05b786e0a9ba6dc</data>
    </node>
    <node id="&quot;TROUVAIN, N.&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Trouvain, N. is a co-author of a guide on hyperparameter exploration mentioned in the text."
"Trouvain, N. is an author mentioned in the text, contributing to a guide on exploring hyper-parameters for Echo State Networks."</data>
      <data key="d2">088d2280349d652200861994c09d7dd5,6a6d88a8f9731e1ed05b786e0a9ba6dc</data>
    </node>
    <node id="&quot;ICANN 2021&quot;">
      <data key="d0">"EVENT"</data>
      <data key="d1">"ICANN 2021 is the conference where a guide on hyperparameter exploration was presented, mentioned in the text."
"ICANN 2021 is the event where the paper 'Which Hype for My New Task? Hints and Random Search for Echo State Networks Hyperparameters' was presented."
"ICANN 2021 is an event mentioned in the text, where papers on Canary Song Decoder and Echo State Networks Hyperparameters were presented."
"ICANN 2021 is an event mentioned where a guide on how to explore hyper-parameters for a task was presented."</data>
      <data key="d2">20b16c2e1cb8813ade96fea5f9591631,25743a99f36f3e56551ffafbba8d15c4,46913f0d73ba0b8cecfdf42bde9862f4,6a6d88a8f9731e1ed05b786e0a9ba6dc</data>
    </node>
    <node id="&quot;XAVIER HINAUT&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Xavier Hinaut is an author of the paper, contributing to the research and development of hyperparameter optimization for Echo State Networks."
"Xavier Hinaut is a contact person for the library and a co-author on a paper about Reservoirpy."
"Xavier Hinaut is an author of ReservoirPy and a contributor to the library."
"Xavier Hinaut is a developer of ReservoirPy, a library for designing Echo State Networks."
"Xavier Hinaut is an author of a guide on how to explore hyper-parameters for a task, mentioned in the text."
"Xavier Hinaut is a contributor to reservoirpy, working at Inria Bordeaux Sud-Ouest, IMN, LaBRI."
"Xavier Hinaut is an author of the paper, working at Inria Bordeaux Sud-Ouest."
"Xavier Hinaut is an author of a research paper on canary song decoder: transduction and implicit segmentation with esns and ltsms."</data>
      <data key="d2">136559fd2a1fbef4cc8a6b11abcb3eef,18910a60b2547ec3133340f42c45bb47,20b16c2e1cb8813ade96fea5f9591631,25743a99f36f3e56551ffafbba8d15c4,296bb6eb4ef7d170f7224efcccbbbaf7,2a197220a94bac0b44fc0b07712e45ba,46913f0d73ba0b8cecfdf42bde9862f4,7751d435f46a6d4027a1c96edabb9626</data>
    </node>
    <node id="&quot;NICOLAS TROUVAIN&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Nicolas Trouvain is an author of the paper, contributing to the research and development of hyperparameter optimization for Echo State Networks."
"Nicolas Trouvain is an author of a guide on how to explore hyper-parameters for a task, mentioned in the text."</data>
      <data key="d2">25743a99f36f3e56551ffafbba8d15c4,46913f0d73ba0b8cecfdf42bde9862f4</data>
    </node>
    <node id="&quot;HP_SPACE&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"hp_space is a configuration parameter in the hyperopt file that defines the ranges of parameters explored."
"hp_space is a parameter exploration space used for hyperparameter optimization."
"hp_space is a parameter that specifies the ranges of parameters explored."</data>
      <data key="d2">5cea9edfd65fcfa25a081554300b28cc,80033e741d8e10abdcfe20dd17192152,adfc38e9dc5e6fd0fe67ce83dfa1f154</data>
    </node>
    <node id="&quot;N&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"N is a parameter explored by hp_space that represents the number of neurons, fixed to 500 in the provided configuration."
"N is a parameter that specifies the number of neurons, which is fixed to 500."</data>
      <data key="d2">5cea9edfd65fcfa25a081554300b28cc,adfc38e9dc5e6fd0fe67ce83dfa1f154</data>
    </node>
    <node id="&quot;SR&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"sr is a parameter explored by hp_space that represents the spectral radius, log-uniformly distributed between 1e-2 and 10."
"sr is a parameter that specifies the spectral radius, which is log-uniformly distributed between 1e-2 and 10."
"Sr is a hyperparameter representing the spectral radius in the machine learning model."
"SR likely refers to Support Vector Regression, a regression model that uses support vectors to find the best fit line."</data>
      <data key="d2">136d135c710f6cf78a4c536d43276fe1,5cea9edfd65fcfa25a081554300b28cc,adfc38e9dc5e6fd0fe67ce83dfa1f154,f70c7d3d89baaabbeaad57b58e379e08</data>
    </node>
    <node id="&quot;LR&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"lr is a parameter explored by hp_space that represents the leaking rate, log-uniformly distributed between 1e-3 and 1."
"lr is a parameter that specifies the leaking rate, which is log-uniformly distributed between 1e-3 and 1."
"Lr is a hyperparameter representing the learning rate in the machine learning model."
"LR likely refers to Logistic Regression, a statistical model used for binary classification."</data>
      <data key="d2">136d135c710f6cf78a4c536d43276fe1,5cea9edfd65fcfa25a081554300b28cc,adfc38e9dc5e6fd0fe67ce83dfa1f154,f70c7d3d89baaabbeaad57b58e379e08</data>
    </node>
    <node id="&quot;JSAN.DUMP()&quot;">
      <data key="d0">"FUNCTION"</data>
      <data key="d1">"jsan.dump() is a function used to serialize a Python object and write it as a JSON-formatted stream to a file."</data>
      <data key="d2">80033e741d8e10abdcfe20dd17192152</data>
    </node>
    <node id="&quot;TRAINING SERIES&quot;">
      <data key="d0">"DATA"</data>
      <data key="d1">"training series is a subset of the dataset used for training an ESN on timeseries."
"training series is a subset of the dataset used for training an Echo State Network (ESN)."</data>
      <data key="d2">1db191f05801d40d5a346febd10d3352,80033e741d8e10abdcfe20dd17192152</data>
    </node>
    <node id="&quot;TESTING SERIES&quot;">
      <data key="d0">"DATA"</data>
      <data key="d1">"testing series is a subset of the dataset used for evaluating the performance of the trained ESN."
"testing series is a subset of the dataset used to evaluate the performance of an Echo State Network (ESN) after training."</data>
      <data key="d2">1db191f05801d40d5a346febd10d3352,80033e741d8e10abdcfe20dd17192152</data>
    </node>
    <node id="&quot;K-FOLD&quot;">
      <data key="d0">"TECHNIQUE"</data>
      <data key="d1">"K-fold is a cross-validation technique used to assess the model's performance by splitting the data into K equal parts and training the model K times, each time using a different part as the testing set."</data>
      <data key="d2">80033e741d8e10abdcfe20dd17192152</data>
    </node>
    <node id="&quot;JSON.DUMP&quot;">
      <data key="d0">"FUNCTION"</data>
      <data key="d1">"json.dump is a Python function used to serialize a Python object and write it as a JSON-formatted stream to a file."</data>
      <data key="d2">1db191f05801d40d5a346febd10d3352</data>
    </node>
    <node id="&quot;HYPEROPT_CONFIG&quot;">
      <data key="d0">"OBJECT"</data>
      <data key="d1">"hyperopt_config is an object that contains configuration settings for hyperparameter optimization."
"Hyperopt_config is a configuration file used to define the parameters for hyperparameter optimization."
"Hyperopt_config is the configuration file used for hyperparameter optimization."</data>
      <data key="d2">1db191f05801d40d5a346febd10d3352,75e530c1a04e30b373dc7cc68e3ad819,f70c7d3d89baaabbeaad57b58e379e08</data>
    </node>
    <node id="&quot;OBJECTIVE&quot;">
      <data key="d0">"FUNCTION"</data>
      <data key="d1">"objective is a function that defines the objective to be optimized during hyperparameter optimization."
"Objective is the function used to evaluate the performance of the machine learning model during hyperparameter optimization."
"Objective is a variable used to store the objective function for hyperparameter optimization, which is mentioned in the text."</data>
      <data key="d2">0982b8d1eb1e636b19fa2e9d9361e566,1db191f05801d40d5a346febd10d3352,f70c7d3d89baaabbeaad57b58e379e08</data>
    </node>
    <node id="&quot;RESEARCH&quot;">
      <data key="d0">"FUNCTION"</data>
      <data key="d1">"research is a function in ReservoirPy used to perform hyperparameter optimization and return the best configuration."</data>
      <data key="d2">1db191f05801d40d5a346febd10d3352</data>
    </node>
    <node id="&quot;FORCE LEARNING&quot;">
      <data key="d0">"METHOD"</data>
      <data key="d1">"FORCE learning is a method used for online training of an Echo State Network (ESN)."</data>
      <data key="d2">1db191f05801d40d5a346febd10d3352</data>
    </node>
    <node id="&quot;BACKPROPAGATION-DECORRELATION&quot;">
      <data key="d0">"METHOD"</data>
      <data key="d1">"backpropagation-decorrelation is a method used for training an Echo State Network (ESN) to minimize output error while preserving echo state properties."</data>
      <data key="d2">1db191f05801d40d5a346febd10d3352</data>
    </node>
    <node id="&quot;RESERVOIR ADAPTATION&quot;">
      <data key="d0">"METHOD"</data>
      <data key="d1">"reservoir adaptation is a method used for training an Echo State Network (ESN) by modifying internal reservoir parameters based on performance metrics."</data>
      <data key="d2">1db191f05801d40d5a346febd10d3352</data>
    </node>
    <node id="&quot;JSON FILE&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"The JSON file is a configuration file used by ReservoirPy to specify the details of the hyperparameter optimization process."</data>
      <data key="d2">9abdbd696e340cb5dd8c66ac5cd30c67</data>
    </node>
    <node id="&quot;LOSS FUNCTION&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"The loss function is a function used to evaluate the performance of machine learning models during the hyperparameter optimization process in ReservoirPy."
"The Loss Function is a metric used to evaluate the performance of a model, mentioned in the text."</data>
      <data key="d2">11749b7d0fdadf05ea29da6025618407,9abdbd696e340cb5dd8c66ac5cd30c67</data>
    </node>
    <node id="&quot;HYPERPARAMETERS&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Hyperparameters are the variables that are set before training a machine learning model in ReservoirPy, and their values can significantly impact the model's performance."
"Hyperparameters are settings that can be adjusted to optimize the performance of a reservoir computing network, and ReservoirPy includes tools for exploring these."
"Hyperparameters are configuration settings that are not learned from data, but are set manually or through a hyperparameter optimization process."
"Hyperparameters are parameters that are set before the learning process begins, and their values can significantly impact the performance of the model."</data>
      <data key="d2">2d8ea1123f365fb047b024022ba4fdc4,73e81fd6509a2ba400a8435793ade3c5,9abdbd696e340cb5dd8c66ac5cd30c67,d1047d9e322054de394b880adaf6b536</data>
    </node>
    <node id="&quot;HYPER-PARAMETER EXPLORATION&quot;">
      <data key="d0">"EVENT"</data>
      <data key="d1">"Hyper-parameter Exploration is the process of searching through a space of possible hyper-parameters to find the best combination for a given task."
"Hyper-parameter Exploration is an event where various parameters are explored to optimize a model's performance."</data>
      <data key="d2">136d135c710f6cf78a4c536d43276fe1,716940af834825642e01a3cb59a7e006</data>
    </node>
    <node id="&quot;REGRESSION TASK&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"A Regression Task is a type of machine learning problem where the goal is to predict a continuous value based on input data."</data>
      <data key="d2">716940af834825642e01a3cb59a7e006</data>
    </node>
    <node id="&quot;R^2 SCORE&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"R^2 Score is a statistical measure that represents the proportion of the variance for a dependent variable that is explained by an independent variable or variables in a regression model."
"R^2 Score is a metric used to evaluate the performance of the Echo State Network, representing the proportion of the variance in the dependent variable that is predictable from the independent variable."</data>
      <data key="d2">716940af834825642e01a3cb59a7e006,f730c6800099724052a2d061f3cd8c2e</data>
    </node>
    <node id="&quot;LEARNING RATE&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Learning Rate is a hyper-parameter in machine learning algorithms that determines how quickly the model learns from the training data."</data>
      <data key="d2">716940af834825642e01a3cb59a7e006</data>
    </node>
    <node id="&quot;RIDGE REGULARIZATION&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Ridge Regularization is a technique used to prevent overfitting in machine learning models by adding a penalty term to the loss function."
"Ridge Regularization is a technique mentioned in the text, used to avoid overfitting in the Ridge Readout."
"The Ridge Regularization is a fixed parameter with a log-uniform distribution between 1e-8 and 1e1."</data>
      <data key="d2">5d3baa9818a4e01fe1196c43378a2cea,65ba78d1f678e080bd930319c54234ef,716940af834825642e01a3cb59a7e006</data>
    </node>
    <node id="&quot;REGRESSION&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Regression is a task that involves predicting a continuous value based on input data, modeling the relationship between input variables and a continuous output variable."
"Regression is a statistical technique used for approximating a function g, where g operates on the real numbers."</data>
      <data key="d2">1c462a6eef00aac37dc1ab33a689b930,9261efcc24379d9c0b2d35a2fde8275d</data>
    </node>
    <node id="&quot;CLASSIFICATION&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Classification is a task that involves assigning input data to one of several predefined categories or classes, predicting the category to which new data points belong."
"Classification is the process of categorizing data into distinct classes or categories."
"Classification is a method used in sequence-to-vector models to assign a single label to each input sequence."
"Classification is a problem where the codomain of a function g is a finite set, requiring the assignment of data points to specific categories."
"Classification is the process of assigning time series patterns to specific categories, such as identifying a word based on hand movements."</data>
      <data key="d2">1c462a6eef00aac37dc1ab33a689b930,423d3b5ec1acc9a4cb448a15d3b6b595,9261efcc24379d9c0b2d35a2fde8275d,a6f2502b5336ffc8606e1167b2813004,c05906c1f12c4edfc32a04aa9935067e</data>
    </node>
    <node id="&quot;REGRESSION MODELS&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Regression Models are statistical methods used to predict a continuous variable, such as rainfall amount or sunlight intensity."</data>
      <data key="d2">d1617d5101da7c02e732e53860c49383</data>
    </node>
    <node id="&quot;LOGISTIC REGRESSION&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Logistic Regression is a statistical method used to predict probabilities, often used as part of a classifier."</data>
      <data key="d2">d1617d5101da7c02e732e53860c49383</data>
    </node>
    <node id="&quot;SVM&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"SVM, or Support Vector Machines, are a type of classification algorithm that predicts outcomes without providing probabilities."</data>
      <data key="d2">d1617d5101da7c02e732e53860c49383</data>
    </node>
    <node id="&quot;LINEAR PREDICTION COEFFICIENT (LPC)&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Linear Prediction Coefficient (LPC) refers to the coefficients derived from the linear prediction model, used to predict the current sample of a signal based on its previous samples."</data>
      <data key="d2">d1617d5101da7c02e732e53860c49383</data>
    </node>
    <node id="&quot;LINEAR PREDICTIVE CODING (LPC)&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Linear Predictive Coding (LPC) is a method that uses Linear Prediction Coefficients to represent the spectral envelope of a speech signal in a compressed form."
"LPC is a method used to represent the spectral envelope of a speech signal in a compressed form, using Linear Prediction Coefficients."</data>
      <data key="d2">c1ba6d7a4f4bd16c4fd25baf07c9747c,d1617d5101da7c02e732e53860c49383</data>
    </node>
    <node id="&quot;CEPSTRAL DOMAIN&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"The Cepstral Domain is a signal processing technique used to analyze signals, but its specific definition is not provided in the text."
"The cepstral domain is a representation of a signal that highlights periodic structures in the frequency domain, resulting from taking the inverse Fourier transform of the logarithm of the signal's spectrum."</data>
      <data key="d2">c1ba6d7a4f4bd16c4fd25baf07c9747c,d1617d5101da7c02e732e53860c49383</data>
    </node>
    <node id="&quot;CLASSIFICATION ALGORITHMS&quot;">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">d1617d5101da7c02e732e53860c49383</data>
    </node>
    <node id="&quot;LINEAR PREDICTION COEFFICIENTS&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Linear Prediction Coefficients are the result of the Linear Predictive Coding process, used for signal representation and analysis."</data>
      <data key="d2">c1ba6d7a4f4bd16c4fd25baf07c9747c</data>
    </node>
    <node id="&quot;RESERVOIRPY LIBRARY&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"The ReservoirPy library is a collection of tools and functions used for data analysis and machine learning tasks, including the `japanese_vowels()` function."</data>
      <data key="d2">c1ba6d7a4f4bd16c4fd25baf07c9747c</data>
    </node>
    <node id="&quot;LINEAR PREDICTION COEFFICIENTS (LPCS)&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Linear Prediction Coefficients (LPCs) are features used in the Japanese Vowels dataset, representing a method for analyzing speech signals."</data>
      <data key="d2">9f7337ee2d87543ced3b99dcae344b13</data>
    </node>
    <node id="&quot;SPEAKER IDENTIFIERS&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Speaker identifiers are labels used in the Japanese Vowels dataset to classify spoken utterances to their respective speakers."</data>
      <data key="d2">9f7337ee2d87543ced3b99dcae344b13</data>
    </node>
    <node id="&quot;BOXPLOT&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"A boxplot is a graphical representation used to demonstrate the locality, spread, and skewness of numerical data through their quartiles."</data>
      <data key="d2">9f7337ee2d87543ced3b99dcae344b13</data>
    </node>
    <node id="&quot;RESERVOIRPY NODES&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"ReservoirPy Nodes are a software component used for processing sequences, such as audio data."</data>
      <data key="d2">a6f2502b5336ffc8606e1167b2813004</data>
    </node>
    <node id="&quot;SCIKITLEARNNODE&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"ScikitLearnNode is a component in ReservoirPy that allows the integration of Scikit-Learn models into ReservoirPy workflows."
"ScikitLearnNode is a component in ReservoirPy that allows integration of Scikit-Learn models into ReservoirPy workflows."
"ScikitLearnNode is a tool used to train and use models from the Scikit-learn library. It follows the same syntax as other offline readout nodes and can have its parameters specified using a dictionary."
"ScikitLearnNode is a technology used for offline readout nodes in machine learning, allowing for the training and prediction of models."
"ScikitLearnNode is a component of the ReservoirPy library that allows the use of any model from the scikit-learn library as a regular offline readout node."
"ScikitLearnNode is a concept used in data analysis or modeling, likely referring to a node or component that interfaces with the scikit-learn library."
"ScikitLearnNode is a library that provides a simple interface to various machine learning models in scikit-learn."
"ScikitLearnNode is a component used in the code to create a machine learning model for prediction."
"ScikitLearnNode is a library or module used for machine learning tasks, such as initializing nodes with specific models."</data>
      <data key="d2">2cba60e2f36479613bb0243a19f3a3b4,35631fbf2ad11c53d75cb9b42e2c39b4,84cacfea14ea9ff46a34150e77a0767a,861c28cb739722ddeb0babb7e1427409,8c66981c9d2009113219bbf2681f664c,c05906c1f12c4edfc32a04aa9935067e,dc3bd3697a140b64d70e0e3ac6db6c7e,dddc79e4cd04d2d07e35930dd8458168,ee83abbbbc707d8131952b2b01ebc268</data>
    </node>
    <node id="&quot;LASSO REGRESSION&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Lasso Regression is a method used for estimation and variable selection in high-dimensional contexts, compensating for the shortcomings of linear regression."
"LASSO Regression is a statistical method that builds on the advantages of Linear Regression, with a main advantage being its ability to carry out variable selection, which is valuable in the presence of a large number of variables."
"Lasso Regression is a type of linear regression that uses shrinkage to reduce the complexity of the model and prevent overfitting."
"Lasso Regression is a machine learning model used for regression tasks, which involves predicting a continuous output variable based on input variables."</data>
      <data key="d2">84cacfea14ea9ff46a34150e77a0767a,861c28cb739722ddeb0babb7e1427409,8c66981c9d2009113219bbf2681f664c,b11a9f7777c0232bfa7323ae82ad139b</data>
    </node>
    <node id="&quot;LINEAR_MODEL.LASSO&quot;">
      <data key="d0">"TECHNOLOGY"</data>
      <data key="d1">"linear_model.Lasso is a specific machine learning model used for regression analysis, which is mentioned in the context of ScikitLearnNode."</data>
      <data key="d2">dddc79e4cd04d2d07e35930dd8458168</data>
    </node>
    <node id="&quot;STR()&quot;">
      <data key="d0">"FUNCTION"</data>
      <data key="d1">"str() is a built-in Python function used to convert a value into a string."</data>
      <data key="d2">dddc79e4cd04d2d07e35930dd8458168</data>
    </node>
    <node id="&quot;INSTANCE&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"An instance refers to a single data point or observation in a dataset, which is used for training or prediction in machine learning."
"An instance is a single data point in a dataset, consisting of a set of features or attributes that describe the data point."</data>
      <data key="d2">b130d3d59f0d3a2bb4feac9fdb85ed5b,dddc79e4cd04d2d07e35930dd8458168</data>
    </node>
    <node id="&quot;OUTPUT FEATURE&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"An output feature is a measurable property or characteristic that a machine learning model is designed to predict."
"An output feature is a measurable property or characteristic that a machine learning model is designed to predict."</data>
      <data key="d2">b130d3d59f0d3a2bb4feac9fdb85ed5b,dddc79e4cd04d2d07e35930dd8458168</data>
    </node>
    <node id="&quot;REGRESSION METHODS&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Regression Methods are statistical techniques used to model the relationship between a dependent variable and one or more independent variables."
"Regression Methods are statistical techniques used for predicting a continuous outcome variable based on one or more predictor variables."</data>
      <data key="d2">b130d3d59f0d3a2bb4feac9fdb85ed5b,dadca3c89b34dc48a60c53367ab55768</data>
    </node>
    <node id="&quot;MULTIPLE OUTPUT FEATURES&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Multiple output features refer to the situation where a machine learning model is required to predict more than one dependent variable or target variable."</data>
      <data key="d2">b130d3d59f0d3a2bb4feac9fdb85ed5b</data>
    </node>
    <node id="&quot;CLASSIFICATION TASKS&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Classification Tasks involve categorizing data into distinct classes or categories based on features or attributes."</data>
      <data key="d2">dadca3c89b34dc48a60c53367ab55768</data>
    </node>
    <node id="&quot;RIDGECLASSIFIER&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"RidgeClassifier is a machine learning algorithm used for classification tasks, which applies a regularization term to the loss function to prevent overfitting."
"RidgeClassifier is a model from scikit-learn used for classification tasks."
"RidgeClassifier is a classifier implemented in the scikit-learn library, used for handling outlier data and making decisions."
"RidgeClassifier is a model from Scikit-learn used for classification tasks."
"RidgeClassifier is a model from the ScikitLearn library used for classification tasks."
"RidgeClassifier is a machine learning algorithm used for classification tasks, provided by the Scikit-learn library."</data>
      <data key="d2">0036fb6f489e13c0db0f1c02bf3323be,2cba60e2f36479613bb0243a19f3a3b4,35631fbf2ad11c53d75cb9b42e2c39b4,d58662ee42c14a0787d839ebfd0a6e9b,dadca3c89b34dc48a60c53367ab55768,f5358a50d00a1cac02dd4ad8fcb167ee</data>
    </node>
    <node id="&quot;LOGISTICREGRESSION&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"LogisticRegression is a machine learning algorithm used for classification tasks, which models the probability of a data point belonging to a particular class."
"LogisticRegression is a model from scikit-learn used for classification tasks."
"LogisticRegression is a classifier implemented in the scikit-learn library, used for making predictions based on input data."
"LogisticRegression is a model from Scikit-learn used for classification tasks."
"LogisticRegression is a model from the ScikitLearn library used for classification tasks."
"LogisticRegression is a machine learning algorithm used for classification tasks, provided by the Scikit-learn library."</data>
      <data key="d2">0036fb6f489e13c0db0f1c02bf3323be,2cba60e2f36479613bb0243a19f3a3b4,35631fbf2ad11c53d75cb9b42e2c39b4,d58662ee42c14a0787d839ebfd0a6e9b,dadca3c89b34dc48a60c53367ab55768,f5358a50d00a1cac02dd4ad8fcb167ee</data>
    </node>
    <node id="&quot;OUTLIER DATA&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Outlier Data are data points that significantly differ from other observations and can have a significant impact on the decision boundary in regression tasks."</data>
      <data key="d2">dadca3c89b34dc48a60c53367ab55768</data>
    </node>
    <node id="&quot;DECISION BOUNDARY&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Decision Boundary is the line or surface that separates different classes or categories in a classification task."
"Decision Boundary refers to the boundary that separates different classes or categories in a classification problem."</data>
      <data key="d2">d58662ee42c14a0787d839ebfd0a6e9b,dadca3c89b34dc48a60c53367ab55768</data>
    </node>
    <node id="&quot;JAPANESE_VOWELS() FUNCTION&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"japanese_vowels() function is a function used for data processing, specifically for handling Japanese vowel data."</data>
      <data key="d2">dadca3c89b34dc48a60c53367ab55768</data>
    </node>
    <node id="&quot;REPEAT_TARGETS PARAMETER&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"repeat_targets parameter is a parameter used in the japanese_vowels() function to ensure that one label is obtained per timestep, not one label per utterance."</data>
      <data key="d2">dadca3c89b34dc48a60c53367ab55768</data>
    </node>
    <node id="&quot;ARGMAX() FUNCTION&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"argmax() function is a function used to find the indices of the maximum values along an axis in a given array."</data>
      <data key="d2">dadca3c89b34dc48a60c53367ab55768</data>
    </node>
    <node id="&quot;JAPANESE_VOWELS&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"japanese_vowels is a function used to obtain data for machine learning tasks."
"japanese_vowels is a dataset used for training and testing machine learning models."
"japanese_vowels is a dataset mentioned in the text, but its specific characteristics or purpose are not clearly defined."</data>
      <data key="d2">2cba60e2f36479613bb0243a19f3a3b4,9414efd266e7135a2cdd7461a888b045,b3361508c3e49b5bb3089f10e31d2c81</data>
    </node>
    <node id="&quot;NP.ARGMAX&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"np.argmax is a function from the NumPy library used to find the indices of the maximum values along an axis."</data>
      <data key="d2">b3361508c3e49b5bb3089f10e31d2c81</data>
    </node>
    <node id="&quot;RANDOM SEARCH&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Random Search is a hyperparameter tuning technique that samples more efficiently and does not waste evaluations on dimensions that do not significantly impact performance."
"Random Search is a method used for hyperparameter exploration that samples more efficiently and does not waste evaluations on dimensions that do not significantly impact performance."
"Random Search is a method used by Hyperopt to choose different sets of parameters for exploration."</data>
      <data key="d2">4a9f33fa18891b67267b7615d61caaac,82ff270b1bbdfe0ee11e603de1e326c7,b3361508c3e49b5bb3089f10e31d2c81</data>
    </node>
    <node id="&quot;ECHO STATE PROPERTY (ESP)&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"The Echo State Property (ESP) is a theoretical condition in Reservoir Computing that states the spectral radius should be less than 1 to ensure a contracting system without inputs."
"Echo State Property (ESP) is a theoretical condition stating that the spectral radius should be less than 1 to ensure a contracting system without inputs. However, in practice, with non-linear reservoirs, the optimal spectral radius can be greater than 1."</data>
      <data key="d2">4a9f33fa18891b67267b7615d61caaac,b3361508c3e49b5bb3089f10e31d2c81</data>
    </node>
    <node id="&quot;KEY HYPERPARAMETERS&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Key Hyperparameters in Reservoir Computing include the spectral radius (SR), input scaling (IS), leaking rate (LR), number of units in the reservoir, and feedback scaling (if feedback from readout units to the reservoir is used)."</data>
      <data key="d2">4a9f33fa18891b67267b7615d61caaac</data>
    </node>
    <node id="&quot;HYPERPARAMETER EXPLORATION&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Hyperparameter Exploration is the process of finding the best hyperparameters for a machine learning model."</data>
      <data key="d2">1315547792fcb5d618913a4c7ac03511</data>
    </node>
    <node id="&quot;MACKEY-GLASS TIME SERIES PREDICTION&quot;">
      <data key="d0">"TASK"</data>
      <data key="d1">"Mackey-Glass Time Series Prediction is a task used to illustrate the proposed hyperparameter search method."</data>
      <data key="d2">1315547792fcb5d618913a4c7ac03511</data>
    </node>
    <node id="&quot;LORENZ TIME SERIES PREDICTION&quot;">
      <data key="d0">"TASK"</data>
      <data key="d1">"Lorenz Time Series Prediction is a task used to illustrate the proposed hyperparameter search method."</data>
      <data key="d2">1315547792fcb5d618913a4c7ac03511</data>
    </node>
    <node id="&quot;HYPERPARAMETER INTERDEPENDENCY PLOTS&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Hyperparameter Interdependency Plots are visual tools used to evaluate the loss as a function of all explored hyperparameters and their interactions."
"Hyperparameter Interdependency Plots are a visualization technique used to evaluate the loss as a function of all explored hyperparameters and their interactions."</data>
      <data key="d2">1315547792fcb5d618913a4c7ac03511,4ea4de00090795130d7ae12a57a729ec</data>
    </node>
    <node id="&quot;HYPERPARAMETER SEARCH METHOD&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Hyperparameter Search Method is a technique used to optimize the performance of machine learning models by finding the best combination of hyperparameters."</data>
      <data key="d2">4ea4de00090795130d7ae12a57a729ec</data>
    </node>
    <node id="&quot;MACKEY-GLASS TIME SERIES&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Mackey-Glass Time Series is a type of chaotic time series used for prediction tasks."
"The Mackey-Glass Time Series is a non-linear, non-periodic, and non-random data set that resembles ECG rhythms, stocks, and weather."
"Mackey-Glass Time Series is a dataset used for demonstrating data preprocessing and analysis techniques, as seen in the provided code."
"Mackey-Glass Time Series is a concept used in time series analysis, referring to a chaotic time series generated by a system of differential equations."</data>
      <data key="d2">4ea4de00090795130d7ae12a57a729ec,b2beacacc8c190393e4583a69518378c,eebc9d7d2b66e3898b7d068c38fd200f,fac681bdc38ae5829173c747ee6240fa</data>
    </node>
    <node id="&quot;LORENZ TIME SERIES&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Lorenz Time Series is a type of chaotic time series used for prediction tasks."</data>
      <data key="d2">4ea4de00090795130d7ae12a57a729ec</data>
    </node>
    <node id="&quot;TEST DOCUMENT RECEPTION&quot;">
      <data key="d0">"EVENT"</data>
      <data key="d1">"Test Document Reception is a test to see if the recipients receive the documents."</data>
      <data key="d2">4ea4de00090795130d7ae12a57a729ec</data>
    </node>
    <node id="&quot;API REFERENCE&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"API reference is a documentation section that provides information about the methods and functions available in a software library or framework."</data>
      <data key="d2">8c66981c9d2009113219bbf2681f664c</data>
    </node>
    <node id="&quot;SCIKITLEARN&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"ScikitLearn is an organization that provides a machine learning library, including the Lasso Regression model used in the code."</data>
      <data key="d2">b11a9f7777c0232bfa7323ae82ad139b</data>
    </node>
    <node id="&quot;MACKEY-GLASS TASK&quot;">
      <data key="d0">"EVENT"</data>
      <data key="d1">"The Mackey-Glass task is a time series prediction problem used in the code for testing the model's performance."
"The Mackey-Glass task is a time series prediction problem used to test the model."</data>
      <data key="d2">b11a9f7777c0232bfa7323ae82ad139b,b3c8de6f33c2ebb84f0d2797933d0cad</data>
    </node>
    <node id="&quot;THE MODEL&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"The model is a reservoir model created using ReservoirPy, which is trained on the Mackey-Glass task."</data>
      <data key="d2">b3c8de6f33c2ebb84f0d2797933d0cad</data>
    </node>
    <node id="&quot;THE AUTHOR&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"The author is the individual who creates the model and evaluates its performance."</data>
      <data key="d2">b3c8de6f33c2ebb84f0d2797933d0cad</data>
    </node>
    <node id="&quot;CASTING(MG, FORECAST=10, TEST_SIZE=0.2)&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"casting(mg, forecast=10, test_size=0.2) is a data analysis or modeling process, likely involving a team or organization."</data>
      <data key="d2">ee83abbbbc707d8131952b2b01ebc268</data>
    </node>
    <node id="&quot;ESN PREDICTION&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"ESN prediction is a method used in data analysis or modeling, likely a part of the casting(mg, forecast=10, test_size=0.2) process."</data>
      <data key="d2">ee83abbbbc707d8131952b2b01ebc268</data>
    </node>
    <node id="&quot;TRUE VALUE&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"True value is the actual or observed value in data analysis or modeling, compared to the ESN prediction."</data>
      <data key="d2">ee83abbbbc707d8131952b2b01ebc268</data>
    </node>
    <node id="&quot;LINEAR_MODEL.PASSIVEAGGRESSIVEREGRESSOR&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"linear_model.PassiveAggressiveRegressor is a machine learning model used in data analysis or modeling, likely a part of the ScikitLearnNode concept."</data>
      <data key="d2">ee83abbbbc707d8131952b2b01ebc268</data>
    </node>
    <node id="&quot;RSQUARE(Y_TEST, Y_PRED)&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"rsquare(y_test, y_pred) is a statistical measure used in data analysis or modeling to evaluate the goodness of fit of a model."</data>
      <data key="d2">ee83abbbbc707d8131952b2b01ebc268</data>
    </node>
    <node id="&quot;NRMSE(Y_TEST, Y_PRED)&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"nrmse(y_test, y_pred) is a statistical measure used in data analysis or modeling to evaluate the accuracy of a model."</data>
      <data key="d2">ee83abbbbc707d8131952b2b01ebc268</data>
    </node>
    <node id="&quot;PASSIVEAGGRESSIVEREGRESSOR&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"PassiveAggressiveRegressor is a model from scikit-learn used for regression tasks."
"PassiveAggressiveRegressor is a regression model from scikit-learn, used for online learning."
"PassiveAggressiveRegressor is a model from the ScikitLearn library used for regression tasks."</data>
      <data key="d2">2cba60e2f36479613bb0243a19f3a3b4,35631fbf2ad11c53d75cb9b42e2c39b4,52d001cd1786e3d9f36e0c57538bc21e</data>
    </node>
    <node id="&quot;NP.FLOAT64&quot;">
      <data key="d0">"DATA TYPE"</data>
      <data key="d1">"np.float64 is a data type used to represent 64-bit floating-point numbers."</data>
      <data key="d2">00648b24263129fdae8652f1a3339041</data>
    </node>
    <node id="&quot;PYTHON&quot;">
      <data key="d0">"TECHNOLOGY"</data>
      <data key="d1">"Python is the programming language used for ReservoirPy, and it is based on Python scientific modules."
"Python is a programming language commonly used in Machine Learning and data analysis due to its simplicity, readability, and extensive libraries."
"Python is the programming language used to create ReservoirPy."</data>
      <data key="d2">4d87a0d12ce76c7a493a24e1c4b06a83,6de297d888d10db4c987b5eafc6398b2,74c073137c970e32982756d008532cb8</data>
    </node>
    <node id="&quot;PYTHON 3.8&quot;">
      <data key="d0">"TECHNOLOGY"</data>
      <data key="d1">"Python 3.8 is a version of Python that ReservoirPy supports."</data>
      <data key="d2">d1047d9e322054de394b880adaf6b536</data>
    </node>
    <node id="&quot;@RESERVOIRPY&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"@reservoirpy is a Twitter handle that shares updates and new releases about ReservoirPy."</data>
      <data key="d2">d1047d9e322054de394b880adaf6b536</data>
    </node>
    <node id="&quot;OFFICIAL DOCUMENTATION&quot;">
      <data key="d0">"EVENT"</data>
      <data key="d1">"Official Documentation is a resource provided by ReservoirPy to learn more about its features, API, and installation process."</data>
      <data key="d2">d1047d9e322054de394b880adaf6b536</data>
    </node>
    <node id="&quot;USER GUIDE&quot;">
      <data key="d0">"EVENT"</data>
      <data key="d1">"User Guide is a resource provided by ReservoirPy that offers tutorials for learning how to use its features."
"User Guide is a resource that provides tutorials and instructions for using ReservoirPy."</data>
      <data key="d2">a2b183778107462d474c53e4ec0a9221,d1047d9e322054de394b880adaf6b536</data>
    </node>
    <node id="&quot;DEEP RESERVOIR&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Deep Reservoir is a type of architecture that ReservoirPy supports, consisting of multiple reservoirs, readouts, and complex feedback loops."</data>
      <data key="d2">d1047d9e322054de394b880adaf6b536</data>
    </node>
    <node id="&quot;MACKEY-GLASS&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Mackey-Glass is a chaotic timeseries used as an example in the ReservoirPy documentation for predicting chaotic behavior."
"Mackey-Glass is a chaotic system used as an example for timeseries prediction."</data>
      <data key="d2">0b6c69085074b2cf23267eb149068b9f,d1047d9e322054de394b880adaf6b536</data>
    </node>
    <node id="&quot;DEEP-ESN ARCHITECTURE&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Deep-ESN Architecture is a type of Echo State Network that uses multiple layers to improve prediction accuracy."</data>
      <data key="d2">a2b183778107462d474c53e4ec0a9221</data>
    </node>
    <node id="&quot;PYTHON NOTEBOOKS&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Python Notebooks are a web-based interactive computing platform used for data analysis and visualization."</data>
      <data key="d2">0b6c69085074b2cf23267eb149068b9f</data>
    </node>
    <node id="&quot;PIP&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Pip is a package manager for Python, used to install and manage Python packages and libraries."
"pip is a package installer for Python, used to install ReservoirPy and its dependencies."</data>
      <data key="d2">0b6c69085074b2cf23267eb149068b9f,c5413fef3b2d7e4d688c66e6046b56c7</data>
    </node>
    <node id="&quot;TIMESERIES PREDICTION&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Timeseries Prediction is the process of forecasting future values based on past observations."</data>
      <data key="d2">0b6c69085074b2cf23267eb149068b9f</data>
    </node>
    <node id="&quot;REQUIREMENTS FILE&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"The requirements file lists the packages needed for running Python Notebooks in the tutorials folder."</data>
      <data key="d2">c5413fef3b2d7e4d688c66e6046b56c7</data>
    </node>
    <node id="&quot;TUTORIAL FOLDER&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"The Tutorial folder contains tutorials in Jupyter Notebooks, demonstrating the use of ReservoirPy."</data>
      <data key="d2">c5413fef3b2d7e4d688c66e6046b56c7</data>
    </node>
    <node id="&quot;EXAMPLES FOLDER&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"The Examples folder contains examples and papers with codes, also in Jupyter Notebooks, showcasing the applications of ReservoirPy."
"The Examples folder contains examples of complex use cases from the literature, which can be used to learn more about the capabilities of ReservoirPy and to see how it can be used to solve complex problems."</data>
      <data key="d2">c5413fef3b2d7e4d688c66e6046b56c7,ead6383a44acd8ebd17907b85a910455</data>
    </node>
    <node id="&quot;HYPERPACKAGE&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"The Hyperpackage is an optional feature of ReservoirPy that enables the use of Hyperopt for hyperparameter optimization."</data>
      <data key="d2">c5413fef3b2d7e4d688c66e6046b56c7</data>
    </node>
    <node id="&quot;TROUVAIN ET AL.&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Trouvain et al. are authors of a paper on exploring hyperparameters with ReservoirPy and Hyperopt."</data>
      <data key="d2">280cbdf53022bbaed48ccb34ebe142bc</data>
    </node>
    <node id="&quot;HINAUT ET AL.&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Hinaut et al. are authors of a paper providing advice on exploring hyperparameters for reservoirs."</data>
      <data key="d2">280cbdf53022bbaed48ccb34ebe142bc</data>
    </node>
    <node id="&quot;LEGER ET AL.&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Leger et al. are authors of a paper using ReservoirPy for meta reinforcement learning."</data>
      <data key="d2">280cbdf53022bbaed48ccb34ebe142bc</data>
    </node>
    <node id="&quot;CHAIX-EICHEL ET AL.&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Chaix-Eichel et al. are authors of a paper using ReservoirPy for implicit learning and explicit representations."</data>
      <data key="d2">280cbdf53022bbaed48ccb34ebe142bc</data>
    </node>
    <node id="&quot;PAGLIARINI ET AL.&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Pagliarini et al. are authors of papers using ReservoirPy for vocal sensorimotor modeling and low-dimensional GAN generation."
"Pagliarini et al. are the authors of papers on Canary Vocal Sensorimotor Model with RNN Decoder and Low-dimensional GAN Generator, and What does the Canary Say? Low-Dimensional GAN Applied to Birdsong."</data>
      <data key="d2">20b16c2e1cb8813ade96fea5f9591631,280cbdf53022bbaed48ccb34ebe142bc</data>
    </node>
    <node id="&quot;EXPLORING HYPERPARAMETERS&quot;">
      <data key="d0">"EVENT"</data>
      <data key="d1">"Exploring Hyperparameters is the process of optimizing model parameters, mentioned in the text."</data>
      <data key="d2">280cbdf53022bbaed48ccb34ebe142bc</data>
    </node>
    <node id="&quot;TROUVAIN &amp; HINAUT&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Trouvain &amp; Hinaut are the authors of a paper on Canary Song Decoder, Transduction, and Implicit Segmentation with ESNs and LTSMs."</data>
      <data key="d2">20b16c2e1cb8813ade96fea5f9591631</data>
    </node>
    <node id="&quot;ICDL 2021&quot;">
      <data key="d0">"EVENT"</data>
      <data key="d1">"ICDL 2021 is an event mentioned in the text, where a paper on Canary Vocal Sensorimotor Model with RNN Decoder and Low-dimensional GAN Generator was presented."</data>
      <data key="d2">20b16c2e1cb8813ade96fea5f9591631</data>
    </node>
    <node id="&quot;HAL PREPRINT&quot;">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">20b16c2e1cb8813ade96fea5f9591631</data>
    </node>
    <node id="&quot;MNEMOSYNE GROUP&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Mnemosyne group is a part of Inria that supports the development of ReservoirPy."
"Mnemosyne group is a part of Inria that supports the development of ReservoirPy."</data>
      <data key="d2">296bb6eb4ef7d170f7224efcccbbbaf7,2a197220a94bac0b44fc0b07712e45ba</data>
    </node>
    <node id="&quot;BORDEAUX&quot;">
      <data key="d0">"GEO"</data>
      <data key="d1">"Bordeaux is a city in France where Inria and the Mnemosyne group are located."
"Bordeaux is the location where Inria supports the development of ReservoirPy."</data>
      <data key="d2">296bb6eb4ef7d170f7224efcccbbbaf7,2a197220a94bac0b44fc0b07712e45ba</data>
    </node>
    <node id="&quot;FRANCE&quot;">
      <data key="d0">"GEO"</data>
      <data key="d1">"France is a country where Inria and the Mnemosyne group are located."</data>
      <data key="d2">2a197220a94bac0b44fc0b07712e45ba</data>
    </node>
    <node id="&quot;ICANN 2020&quot;">
      <data key="d0">"EVENT"</data>
      <data key="d1">"ICANN 2020 is an international conference where ReservoirPy was presented."
"ICANN 2020 is the conference where the ReservoirPy package was presented."</data>
      <data key="d2">296bb6eb4ef7d170f7224efcccbbbaf7,2a197220a94bac0b44fc0b07712e45ba</data>
    </node>
    <node id="&quot;NATHAN TROUVAIN&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Nathan Trouvain is an author of ReservoirPy and a contributor to the library."
"Nathan Trouvain is a developer of ReservoirPy, a library for designing Echo State Networks."
"Nathan Trouvain is a contributor to reservoirpy, working at Inria Bordeaux Sud-Ouest, IMN, LaBRI."
"Nathan Trouvain is an author of a research paper on canary song decoder: transduction and implicit segmentation with esns and ltsms."</data>
      <data key="d2">18910a60b2547ec3133340f42c45bb47,296bb6eb4ef7d170f7224efcccbbbaf7,2a197220a94bac0b44fc0b07712e45ba,7751d435f46a6d4027a1c96edabb9626</data>
    </node>
    <node id="&quot;LUCA PEDRELLI&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Luca Pedrelli is an author of ReservoirPy and a contributor to the library."
"Luca Pedrelli is a developer of ReservoirPy, a library for designing Echo State Networks."</data>
      <data key="d2">296bb6eb4ef7d170f7224efcccbbbaf7,2a197220a94bac0b44fc0b07712e45ba</data>
    </node>
    <node id="&quot;THANH TRUNG DINH&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Thanh Trung Dinh is an author of ReservoirPy and a contributor to the library."
"Thanh Trung Dinh is a developer of ReservoirPy, a library for designing Echo State Networks."</data>
      <data key="d2">296bb6eb4ef7d170f7224efcccbbbaf7,2a197220a94bac0b44fc0b07712e45ba</data>
    </node>
    <node id="&quot;MACKEY-GLASS TIMES&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Mackey-Glass Times are a time series data set commonly used for testing and benchmarking time series prediction methods."</data>
      <data key="d2">73e81fd6509a2ba400a8435793ade3c5</data>
    </node>
    <node id="&quot;AUTHOR&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"The author is not explicitly mentioned, but they present a basic example of optimizing hyperparameters using Hyperopt and ReservoirPy.hyper tools."
"The author is the person who wrote the text, discussing the use of Hyperopt and other concepts."
"The author is the person who wrote the code and is using the ESN model for time series prediction and forecasting."
"The author is the individual who wrote the text, demonstrating expertise in machine learning and data visualization."
"The author is the person who wrote the code and is performing the ESN test, but their name is not explicitly mentioned."
"The author is the individual who wrote the text, demonstrating expertise in machine learning and time series analysis."
"The author is the person who wrote the code, using ReservoirPy to create and work with reservoir computing models."
"The author is the individual who wrote the text, not explicitly mentioned."
"The author of the text discusses the Echo State Network (ESN) and its applications, comparing it to other methods such as Gaussian Process Model and various implementations."</data>
      <data key="d2">069ae9388dfd52fec9c184c7168f64dd,11749b7d0fdadf05ea29da6025618407,29aad23ce67e778ac31d4fb287fd20c7,73e81fd6509a2ba400a8435793ade3c5,76963fa19a9caab847e50167f71c86a2,973d44d321c7ceee7add295c60b085d2,a4b801e70cf2ba3a3101d34899450087,e7d249cdab85dc69b631d43ac6b62915,fd81bdceb3e2b91ac2605a3d201d1eb4</data>
    </node>
    <node id="&quot;MATPLOTLIB.PYPLOT&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"matplotlib.pyplot is a library used for creating visualizations in Python."</data>
      <data key="d2">94fd1ebf256db17e4ac2255b89caa473</data>
    </node>
    <node id="&quot;ECHO STATE PROPERTY&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Echo State Property is a theoretical assumption that a spectral radius close to 1 allows the reservoir states to be less affected by their initial conditions, while having good memorization properties."
"Echo State Property is a property of a reservoir, which is supposed to allow the reservoir states to be less affected by their initial conditions while having good memorization properties."
"The Echo State Property is a concept that relates to the asymptotic properties of the excited reservoir dynamics and the driving signal."</data>
      <data key="d2">1f30b86a46d4819603edc730df816c49,82f7e4647b9da5d5063fe92613f4fbcb,a9f53979e9dbe6b936ff3374c73006dd</data>
    </node>
    <node id="&quot;INPUT SCALING&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Input Scaling is a coefficient applied on W_(in) and adding a gain to the inputs of a reservoir, affecting its dynamics."
"Input Scaling is a coefficient applied on W_(in) and adding a gain to the inputs of the reservoir, influencing the reservoir's behavior."
"Input Scaling is a parameter used in Reservoir Computing to adjust the influence of each variable in a multivariate time-series."
"Input Scaling is a parameter in Reservoir Computing that adjusts the influence of each variable in a multivariate time-series."
"Input Scaling is a parameter mentioned in the text, which is fixed."
"Input Scaling is a parameter used to control the magnitude of the input data in the Echo State Network (ESN) model."
"Input scaling is a process or technique used in the text, likely in the context of adjusting the magnitude or intensity of external inputs to the Reservoir system."
"Input Scaling is a technique used in neural networks to adjust the input data to improve the network's performance."
"Input Scaling is a parameter in Reservoir Computing that adjusts the strength of the input signal to the reservoir."
"The Input Scaling is a fixed parameter with a value of 1.0."</data>
      <data key="d2">0a9b132ecb1c4b63fdbb0e144295362e,1365a36c76afc697ac626fd0f784804a,1f30b86a46d4819603edc730df816c49,26d78bc91458f47d4053954505c45f92,65ba78d1f678e080bd930319c54234ef,82f7e4647b9da5d5063fe92613f4fbcb,8553a88d9aaf4f71d359c721a1f6fa70,8ecf03267c90a64376f5040307d98195,b957e1bf5bf175c7630222ca742c7933,bba680a0a7dd439bd5b0fe1547ffe040</data>
    </node>
    <node id="&quot;STABLE DYNAMICS&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Stable Dynamics refers to a state where the reservoir's dynamics are predictable and consistent over time."</data>
      <data key="d2">1f30b86a46d4819603edc730df816c49</data>
    </node>
    <node id="&quot;CHAOTIC DYNAMICS&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Chaotic Dynamics refers to a state where the reservoir's dynamics are unpredictable and highly sensitive to initial conditions."</data>
      <data key="d2">1f30b86a46d4819603edc730df816c49</data>
    </node>
    <node id="&quot;TIME-SERIES DATA&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Time-series Data is a sequence of data points collected at regular time intervals, which is being processed using Reservoir Computing."
"Time-series Data refers to a sequence of data points collected at regular time intervals."
"Time-series Data is a sequence of data points collected at regular time intervals, which is being processed using Reservoir Computing."</data>
      <data key="d2">26d78bc91458f47d4053954505c45f92,8553a88d9aaf4f71d359c721a1f6fa70,8ecf03267c90a64376f5040307d98195</data>
    </node>
    <node id="&quot;MULTIVARIATE TIME-SERIES&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Multivariate Time-series is a type of time-series data that consists of multiple variables or dimensions, each of which may have a different influence on the reservoir state."</data>
      <data key="d2">8553a88d9aaf4f71d359c721a1f6fa70</data>
    </node>
    <node id="&quot;RC CONNECTIVITY&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"RC Connectivity is a parameter in Reservoir Computing that determines the sparsity of the connections between the reservoir units."
"RC Connectivity is a term used in the context of a neural network, likely referring to the connectivity between reservoir and readout components."</data>
      <data key="d2">8ecf03267c90a64376f5040307d98195,b957e1bf5bf175c7630222ca742c7933</data>
    </node>
    <node id="&quot;INPUT CONNECTIVITY&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Input Connectivity is a parameter in Reservoir Computing that determines the sparsity of the connections between the input variables and the reservoir units."
"Input Connectivity is a parameter used to control the connection between the input data and the reservoir in the Echo State Network (ESN) model."
"Input Connectivity is a parameter in the ESN model that determines the density of connections between input nodes and reservoir nodes."
"Input Connectivity is a term used in the context of a neural network, likely referring to the connections between input and reservoir components."
"Input Connectivity is a parameter in Reservoir Computing that determines the connections between the input signal and the neurons in the reservoir."</data>
      <data key="d2">1365a36c76afc697ac626fd0f784804a,26d78bc91458f47d4053954505c45f92,72e6eee633bcb5b1458c4cee3975cee1,8ecf03267c90a64376f5040307d98195,b957e1bf5bf175c7630222ca742c7933</data>
    </node>
    <node id="&quot;OPTIMIZATION TOOLS&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Optimization Tools are used to find the best values for hyperparameters, improving the performance of the model."</data>
      <data key="d2">2d8ea1123f365fb047b024022ba4fdc4</data>
    </node>
    <node id="&quot;OPTIMIZATION ALGORITHM&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"The Optimization Algorithm is a method used to find the best parameters for a given task, such as forecasting the Double Scroll Attractor."</data>
      <data key="d2">91704ce63f9ba41247fdc452a7a62ba6</data>
    </node>
    <node id="&quot;R&#178;&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"R&#178; is a metric used to measure the proportion of the variance in the dependent variable that is predictable from the independent variable(s)."
"R&#178; is a statistical metric used to measure the proportion of the variance in the dependent variable that is predictable from the independent variable(s), mentioned in the text."</data>
      <data key="d2">11749b7d0fdadf05ea29da6025618407,251a50c2ae8ceea4fd7da1127cc5f461</data>
    </node>
    <node id="&quot;R2&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"R-squared (R2) is a metric used to evaluate the performance of the machine learning model, representing the proportion of the variance in the target variable that is predictable from the input variables."</data>
      <data key="d2">75e530c1a04e30b373dc7cc68e3ad819</data>
    </node>
    <node id="&quot;HYPEROPT-MULTISCROLL&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"hyperopt-multiscroll is an experimentation name, likely a project or initiative."</data>
      <data key="d2">adfc38e9dc5e6fd0fe67ce83dfa1f154</data>
    </node>
    <node id="&quot;HP_MAX_EVALS&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"hp_max_evals is a parameter that specifies the number of different sets of parameters hyperopt has to try."</data>
      <data key="d2">adfc38e9dc5e6fd0fe67ce83dfa1f154</data>
    </node>
    <node id="&quot;HP_METHOD&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"hp_method is a parameter that specifies the method used by hyperopt to choose sets of parameters."</data>
      <data key="d2">adfc38e9dc5e6fd0fe67ce83dfa1f154</data>
    </node>
    <node id="&quot;INSTANCES_PER_TRIAL&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"instances_per_trial is a parameter that specifies how many random ESN will be tried with each set of parameters."</data>
      <data key="d2">adfc38e9dc5e6fd0fe67ce83dfa1f154</data>
    </node>
    <node id="&quot;REGULARIZATION PARAMETER&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Regularization Parameter is a parameter mentioned in the text, which is fixed."</data>
      <data key="d2">0a9b132ecb1c4b63fdbb0e144295362e</data>
    </node>
    <node id="&quot;RANDOM SEED&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Random Seed is a parameter mentioned in the text, which is used for the ESN initialization."
"The Random Seed is a parameter used for the ESN initialization, with a value of 1234."</data>
      <data key="d2">0a9b132ecb1c4b63fdbb0e144295362e,65ba78d1f678e080bd930319c54234ef</data>
    </node>
    <node id="&quot;ICANN&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"ICANN is an organization mentioned in the text, where a guide on exploring hyper-parameters for Echo State Networks was published."</data>
      <data key="d2">088d2280349d652200861994c09d7dd5</data>
    </node>
    <node id="&quot;Y&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Y is a variable or feature used in the time series forecasting process, often the target variable to be predicted."
"Y is a variable representing the target data used for training the ESN node."
"Y is a variable representing the future values of the sine wave, which is used as target data for the ESN model."
"y is the target data used for training and prediction in the ESN."
"Y is a variable used to represent output or target data in the context of data analysis and machine learning."</data>
      <data key="d2">09198e939639c229c2c97555f65b12a7,09ea760dd2f000c961d1cfd4ea795da5,31ee481e47ac3a0b970199e72a0e0d31,e396354e3a9be76616392af11f56e671,f70c7d3d89baaabbeaad57b58e379e08</data>
    </node>
    <node id="&quot;FORECAST&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Forecast is the process of predicting future values based on past observations."
"Forecast is a variable used to set the forecasting horizon, which is mentioned in the text."</data>
      <data key="d2">0982b8d1eb1e636b19fa2e9d9361e566,f70c7d3d89baaabbeaad57b58e379e08</data>
    </node>
    <node id="&quot;TRAIN_LEN&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Train_len is the length of the training data used for training the machine learning model."
"Train_len is a variable used to set the length of the training data, which is mentioned in the text."</data>
      <data key="d2">0982b8d1eb1e636b19fa2e9d9361e566,f70c7d3d89baaabbeaad57b58e379e08</data>
    </node>
    <node id="&quot;METRIC&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Metric is a measure used to evaluate the performance of the machine learning model, such as R&#178; score."</data>
      <data key="d2">f70c7d3d89baaabbeaad57b58e379e08</data>
    </node>
    <node id="&quot;R&#178; SCORE&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"R&#178; Score is a statistical measure that represents the proportion of the variance for a dependent variable that is explained by an independent variable or variables in a regression model."</data>
      <data key="d2">136d135c710f6cf78a4c536d43276fe1</data>
    </node>
    <node id="&quot;STATISTICS&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Statistics is a branch of mathematics that deals with the collection, analysis, interpretation, presentation, and organization of data."
"Statistics is mentioned as a field where time series analysis is commonly used."
"Statistics is a field that focuses on data analysis and inference, including transferring knowledge about a sample to the whole population."</data>
      <data key="d2">423d3b5ec1acc9a4cb448a15d3b6b595,70c3a879c0f6e6b76a13d02d67bce1a8,a2b394d556da06b8c14dd2f5e106343b</data>
    </node>
    <node id="&quot;SIGNAL PROCESSING&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Signal Processing is a field of study that deals with the analysis, manipulation, and synthesis of signals."
"Signal Processing is an area where ESNs have been widely used due to their ability to mix well with non-digital computer substrates."</data>
      <data key="d2">4b89d9404fd683ecd03d5846ee2d86ce,70c3a879c0f6e6b76a13d02d67bce1a8</data>
    </node>
    <node id="&quot;PATTERN RECOGNITION&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Pattern Recognition is a field of study that deals with the automatic discovery of patterns in data."</data>
      <data key="d2">70c3a879c0f6e6b76a13d02d67bce1a8</data>
    </node>
    <node id="&quot;ECONOMETRICS&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Econometrics is a branch of economics that uses statistical methods and econometric theory to relate variables and assess their economic significance."
"Econometrics is mentioned as a field where time series analysis is used for forecasting."</data>
      <data key="d2">70c3a879c0f6e6b76a13d02d67bce1a8,a2b394d556da06b8c14dd2f5e106343b</data>
    </node>
    <node id="&quot;MATHEMATICAL FINANCE&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Mathematical Finance is a field that applies mathematical methods to financial markets."</data>
      <data key="d2">70c3a879c0f6e6b76a13d02d67bce1a8</data>
    </node>
    <node id="&quot;WEATHER FORECASTING&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Weather Forecasting is the application of science and technology to predict the weather at a future time and a given location."</data>
      <data key="d2">70c3a879c0f6e6b76a13d02d67bce1a8</data>
    </node>
    <node id="&quot;EARTHQUAKE PREDICTION&quot;">
      <data key="d0">"EVENT"</data>
      <data key="d1">"Earthquake Prediction is the use of scientific methods to forecast the occurrence, location, and magnitude of earthquakes."</data>
      <data key="d2">70c3a879c0f6e6b76a13d02d67bce1a8</data>
    </node>
    <node id="&quot;STOCHASTIC MODEL&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"A Stochastic Model is a mathematical representation of a system that accounts for uncertainty, often used in Time Series Analysis."</data>
      <data key="d2">8e69dad9d25c6b8f037f22592687e195</data>
    </node>
    <node id="&quot;FREQUENCY-DOMAIN METHODS&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Frequency-domain Methods are techniques used in Time Series Analysis that involve analyzing data in the frequency domain, including Spectral Analysis and Wavelet Analysis."</data>
      <data key="d2">c7d17582a93a296eaaf9b9fca737ba51</data>
    </node>
    <node id="&quot;TIME-DOMAIN METHODS&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Time-domain Methods are techniques used in Time Series Analysis that involve analyzing data in the time domain, including Auto-correlation and Cross-correlation Analysis."</data>
      <data key="d2">c7d17582a93a296eaaf9b9fca737ba51</data>
    </node>
    <node id="&quot;PARAMETRIC METHODS&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Parametric Methods are approaches in Time Series Analysis that assume the underlying stationary stochastic process has a certain structure, described using a small number of parameters."
"Parametric Methods assume that the underlying stationary stochastic process has a certain structure, described using a small number of parameters."</data>
      <data key="d2">c087c124713c7ade4223617d95928cbf,c7d17582a93a296eaaf9b9fca737ba51</data>
    </node>
    <node id="&quot;NON-PARAMETRIC METHODS&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Non-parametric Methods are approaches in Time Series Analysis that do not assume the underlying structure of the stochastic process, explicitly estimating the covariance or spectrum of the process."
"Non-Parametric Methods explicitly estimate the covariance or the spectrum of the process without assuming any particular structure."</data>
      <data key="d2">c087c124713c7ade4223617d95928cbf,c7d17582a93a296eaaf9b9fca737ba51</data>
    </node>
    <node id="&quot;LINEAR METHODS&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Linear Methods are a type of time series analysis that assumes a linear relationship between variables."</data>
      <data key="d2">c087c124713c7ade4223617d95928cbf</data>
    </node>
    <node id="&quot;NON-LINEAR METHODS&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Non-Linear Methods are a type of time series analysis that does not assume a linear relationship between variables."</data>
      <data key="d2">c087c124713c7ade4223617d95928cbf</data>
    </node>
    <node id="&quot;UNIVARIATE METHODS&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Univariate Methods are a type of time series analysis that focuses on a single variable."</data>
      <data key="d2">c087c124713c7ade4223617d95928cbf</data>
    </node>
    <node id="&quot;MULTIVARIATE METHODS&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Multivariate Methods are a type of time series analysis that involves multiple variables."</data>
      <data key="d2">c087c124713c7ade4223617d95928cbf</data>
    </node>
    <node id="&quot;PANEL DATA&quot;">
      <data key="d0">"EVENT"</data>
      <data key="d1">"Panel Data is a general class of multidimensional data set, which includes Time Series data."</data>
      <data key="d2">c087c124713c7ade4223617d95928cbf</data>
    </node>
    <node id="&quot;UNITED STATES&quot;">
      <data key="d0">"GEO"</data>
      <data key="d1">"The United States is mentioned in the context of tuberculosis incidence."
"The United States is mentioned in the context of Tuberculosis incidence data."</data>
      <data key="d2">4b75a8a7637b05307e62f309c682d43b,a2b394d556da06b8c14dd2f5e106343b</data>
    </node>
    <node id="&quot;TUBERCULOSIS&quot;">
      <data key="d0">"EVENT"</data>
      <data key="d1">"Tuberculosis is mentioned as a disease with incidence rates being analyzed."
"Tuberculosis is a disease mentioned in the text, with incidence data being analyzed."</data>
      <data key="d2">4b75a8a7637b05307e62f309c682d43b,a2b394d556da06b8c14dd2f5e106343b</data>
    </node>
    <node id="&quot;QUANTITATIVE FINANCE&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Quantitative Finance is mentioned as a field where time series analysis is used for forecasting."</data>
      <data key="d2">a2b394d556da06b8c14dd2f5e106343b</data>
    </node>
    <node id="&quot;CORPORATE DATA ANALYSTS&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Corporate Data Analysts are mentioned in the text, with challenges related to exploratory time series analysis being discussed."</data>
      <data key="d2">4b75a8a7637b05307e62f309c682d43b</data>
    </node>
    <node id="&quot;SERIES ANALYSIS&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Series Analysis is a technique used to discover patterns in data over time."</data>
      <data key="d2">630c86e110e2dabbe068f446b619cef3</data>
    </node>
    <node id="&quot;HEAT MAP MATRICES&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Heat Map Matrices are visual tools used to represent time series data, helping to overcome challenges in data analysis."</data>
      <data key="d2">630c86e110e2dabbe068f446b619cef3</data>
    </node>
    <node id="&quot;CURVE FITTING&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Curve Fitting is a technique used to construct a curve that best fits a series of data points, subject to constraints."
"Curve Fitting is a technique used to approximate a function when only a set of points is provided, and the function is an operation on the real numbers."</data>
      <data key="d2">630c86e110e2dabbe068f446b619cef3,9ec0dac4c72bcc2c78c7df43b9969fe7</data>
    </node>
    <node id="&quot;SMOOTHING&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Smoothing is a method used in curve fitting to construct a 'smooth' function that approximately fits the data."</data>
      <data key="d2">630c86e110e2dabbe068f446b619cef3</data>
    </node>
    <node id="&quot;PROCESSES&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Processes are the underlying activities or phenomena being analyzed or studied."</data>
      <data key="d2">630c86e110e2dabbe068f446b619cef3</data>
    </node>
    <node id="&quot;ECONOMIC TIME SERIES&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Economic Time Series refers to the collection and analysis of data points indexed in time order, used for various economic purposes."</data>
      <data key="d2">bde7c826c746ece93a512a0cf167fa3e</data>
    </node>
    <node id="&quot;FUNCTION APPROXIMATION&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Function Approximation is the process of selecting a function from a well-defined class that closely matches a target function."
"Function Approximation is the process of selecting a function from a well-defined class that closely matches a target function."</data>
      <data key="d2">472b44b36407c9a89cf5c51459188263,9ec0dac4c72bcc2c78c7df43b9969fe7</data>
    </node>
    <node id="&quot;POLYNOMIAL INTERPOLATION&quot;">
      <data key="d0">"TECHNOLOGY"</data>
      <data key="d1">"Polynomial Interpolation is a method that fits piecewise polynomial functions into time intervals to estimate values."</data>
      <data key="d2">472b44b36407c9a89cf5c51459188263</data>
    </node>
    <node id="&quot;SPLINE INTERPOLATION&quot;">
      <data key="d0">"TECHNOLOGY"</data>
      <data key="d1">"Spline Interpolation is a method that uses piecewise continuous functions composed of many polynomials to estimate values."</data>
      <data key="d2">472b44b36407c9a89cf5c51459188263</data>
    </node>
    <node id="&quot;POLYNOMIAL REGRESSION&quot;">
      <data key="d0">"TECHNOLOGY"</data>
      <data key="d1">"Polynomial Regression is a method that uses a single polynomial to model an entire data set."</data>
      <data key="d2">472b44b36407c9a89cf5c51459188263</data>
    </node>
    <node id="&quot;APPROXIMATION THEORY&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Approximation Theory is a branch of numerical analysis that investigates how certain known functions can be approximated by a specific class of functions."</data>
      <data key="d2">9ec0dac4c72bcc2c78c7df43b9969fe7</data>
    </node>
    <node id="&quot;CLASSIFICATION PROBLEM&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Classification Problem is a problem where the target function has a finite codomain, and the task is to categorize data points into these classes."</data>
      <data key="d2">9ec0dac4c72bcc2c78c7df43b9969fe7</data>
    </node>
    <node id="&quot;ONLINE TIME SERIES APPROXIMATION&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Online Time Series Approximation is a problem that requires summarizing data in one-pass and constructing an approximate representation of the time series."
"Online Time Series Approximation is a problem that involves summarizing data in one-pass and constructing an approximate representation to support various time series queries with error bounds."</data>
      <data key="d2">9261efcc24379d9c0b2d35a2fde8275d,9ec0dac4c72bcc2c78c7df43b9969fe7</data>
    </node>
    <node id="&quot;STATISTICAL LEARNING THEORY&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Statistical Learning Theory is a unified framework that encompasses various statistical problems, including regression and classification."
"Statistical Learning Theory is a field that focuses on increasing the capacity of models by optimizing various biases, including manual experimentation."</data>
      <data key="d2">2a2a93486d6198ce228e77e120dc3c0c,9261efcc24379d9c0b2d35a2fde8275d</data>
    </node>
    <node id="&quot;HAND MOVEMENTS IN SIGN&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Hand Movements in Sign is a technique used for identifying words based on a series of hand movements."</data>
      <data key="d2">9261efcc24379d9c0b2d35a2fde8275d</data>
    </node>
    <node id="&quot;WORLD WAR II&quot;">
      <data key="d0">"EVENT"</data>
      <data key="d1">"World War II is a significant historical event that accelerated the development of mathematical techniques and technologies."</data>
      <data key="d2">423d3b5ec1acc9a4cb448a15d3b6b595</data>
    </node>
    <node id="&quot;NORBERT WIENER&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Norbert Wiener was a mathematician who made significant contributions to signal processing and filtering during World War II."</data>
      <data key="d2">423d3b5ec1acc9a4cb448a15d3b6b595</data>
    </node>
    <node id="&quot;RUDOLF E. K&#193;LM&#193;N&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Rudolf E. K&#225;lm&#225;n was an electrical engineer who developed the Kalman filter, a mathematical tool for signal estimation and prediction."</data>
      <data key="d2">423d3b5ec1acc9a4cb448a15d3b6b595</data>
    </node>
    <node id="&quot;DENNIS GABOR&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Dennis Gabor was an electrical engineer who contributed to the development of signal processing and spectral density estimation during World War II."</data>
      <data key="d2">423d3b5ec1acc9a4cb448a15d3b6b595</data>
    </node>
    <node id="&quot;SIGNAL ESTIMATION&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Signal Estimation is the approach of analyzing and filtering signals in the frequency domain using techniques like the Fourier transform and spectral density estimation."</data>
      <data key="d2">423d3b5ec1acc9a4cb448a15d3b6b595</data>
    </node>
    <node id="&quot;SEGMENTATION&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Segmentation is the process of splitting a time-series into a sequence of segments, each with its own characteristic properties."</data>
      <data key="d2">423d3b5ec1acc9a4cb448a15d3b6b595</data>
    </node>
    <node id="&quot;DIGITAL SIGNAL PROCESSING&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Digital Signal Processing is a field mentioned in the text, potentially referring to a company or organization."</data>
      <data key="d2">5d6a266e9d567f013be17768c04cbc09</data>
    </node>
    <node id="&quot;TIME-SERIES SEGMENTATION&quot;">
      <data key="d0">"EVENT"</data>
      <data key="d1">"Time-Series Segmentation is a process mentioned in the text, involving the identification and characterization of segments in a time-series."</data>
      <data key="d2">5d6a266e9d567f013be17768c04cbc09</data>
    </node>
    <node id="&quot;CHANGE-POINT DETECTION&quot;">
      <data key="d0">"EVENT"</data>
      <data key="d1">"Change-Point Detection is a method mentioned in the text, used in time-series segmentation to identify segment boundary points."</data>
      <data key="d2">5d6a266e9d567f013be17768c04cbc09</data>
    </node>
    <node id="&quot;MARKOV JUMP LINEAR SYSTEM&quot;">
      <data key="d0">"EVENT"</data>
      <data key="d1">"Markov Jump Linear System is a more sophisticated modeling approach mentioned in the text, used to represent time-series data."</data>
      <data key="d2">5d6a266e9d567f013be17768c04cbc09</data>
    </node>
    <node id="&quot;TIME-SERIES CLUSTERING&quot;">
      <data key="d0">"EVENT"</data>
      <data key="d1">"Time-Series Clustering is a process mentioned in the text, which may involve subsequence clustering."</data>
      <data key="d2">5d6a266e9d567f013be17768c04cbc09</data>
    </node>
    <node id="&quot;SUBSEQUENCE TIME-SERIES CLUSTERING&quot;">
      <data key="d0">"EVENT"</data>
      <data key="d1">"Subsequence Time-Series Clustering is a specific type of clustering mentioned in the text, with findings about unstable clusters and non-descriptive cluster centers."</data>
      <data key="d2">5d6a266e9d567f013be17768c04cbc09</data>
    </node>
    <node id="&quot;AUTOREGRESSIVE (AR) MODELS&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Autoregressive (AR) Models are statistical models that depend linearly on previous data points."</data>
      <data key="d2">a000a3fbf1f8fad62e4c25b495858c79</data>
    </node>
    <node id="&quot;INTEGRATED (I) MODELS&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Integrated (I) Models are statistical models used to model variations in the level of a process."</data>
      <data key="d2">a000a3fbf1f8fad62e4c25b495858c79</data>
    </node>
    <node id="&quot;MOVING-AVERAGE (MA) MODELS&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Moving-Average (MA) Models are statistical models that depend linearly on previous data points."</data>
      <data key="d2">a000a3fbf1f8fad62e4c25b495858c79</data>
    </node>
    <node id="&quot;AUTOREGRESSIVE MOVING-AVERAGE (ARMA) MODELS&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Autoregressive Moving-Average (ARMA) Models are statistical models that combine Autoregressive and Moving-Average concepts."</data>
      <data key="d2">a000a3fbf1f8fad62e4c25b495858c79</data>
    </node>
    <node id="&quot;AUTOREGRESSIVE INTEGRATED MOVING-AVERAGE (ARIMA) MODELS&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Autoregressive Integrated Moving-Average (ARIMA) Models are statistical models that combine Autoregressive and Integrated concepts with Moving-Average."</data>
      <data key="d2">a000a3fbf1f8fad62e4c25b495858c79</data>
    </node>
    <node id="&quot;AUTOREGRESSIVE FRACTIONALLY INTEGRATED MOVING-AVERAGE (ARFIMA) MODELS&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Autoregressive Fractionally Integrated Moving-Average (ARFIMA) Models are statistical models that generalize Autoregressive, Integrated, and Moving-Average concepts."</data>
      <data key="d2">a000a3fbf1f8fad62e4c25b495858c79</data>
    </node>
    <node id="&quot;VECTOR-VALUED DATA&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Vector-Valued Data refers to data points that are multi-dimensional, allowing for more complex modeling."</data>
      <data key="d2">a000a3fbf1f8fad62e4c25b495858c79</data>
    </node>
    <node id="&quot;MULTIVARIATE TIME-SERIES MODELS&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Multivariate Time-Series Models are statistical models that extend univariate models to deal with Vector-Valued Data."
"Multivariate Time-Series Models are extensions of ARIMA and ARFIMA Models that can handle vector-valued data."</data>
      <data key="d2">a000a3fbf1f8fad62e4c25b495858c79,e5e350429a2ca41c6bfd4aa812e4c391</data>
    </node>
    <node id="&quot;ARIMA MODELS&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"ARIMA Models are a type of time series model that combines autoregressive and moving-average components."</data>
      <data key="d2">e5e350429a2ca41c6bfd4aa812e4c391</data>
    </node>
    <node id="&quot;ARFIMA MODELS&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"ARFIMA Models are an extension of ARIMA Models that generalizes them to include fractionally integrated components."</data>
      <data key="d2">e5e350429a2ca41c6bfd4aa812e4c391</data>
    </node>
    <node id="&quot;VAR MODELS&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"VAR Models are a type of Multivariate Time-Series Model that stands for Vector Autoregression."</data>
      <data key="d2">e5e350429a2ca41c6bfd4aa812e4c391</data>
    </node>
    <node id="&quot;EXOGENOUS TIME-SERIES MODELS&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Exogenous Time-Series Models are extensions of ARIMA and ARFIMA Models that account for the influence of a 'forcing' time-series."</data>
      <data key="d2">e5e350429a2ca41c6bfd4aa812e4c391</data>
    </node>
    <node id="&quot;KANTZ AND SCHREIBER&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Kantz and Schreiber are mentioned as references for nonlinear time series analysis."</data>
      <data key="d2">e5e350429a2ca41c6bfd4aa812e4c391</data>
    </node>
    <node id="&quot;ABARBANEL&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Abarbanel is mentioned as a reference for nonlinear time series analysis."</data>
      <data key="d2">e5e350429a2ca41c6bfd4aa812e4c391</data>
    </node>
    <node id="&quot;NONLINEAR TIME SERIES ANALYSIS&quot;">
      <data key="d0">"EVENT"</data>
      <data key="d1">"Nonlinear Time Series Analysis is mentioned as a topic of interest due to its potential for producing chaotic time series and its advantage in empirical investigations."</data>
      <data key="d2">e5e350429a2ca41c6bfd4aa812e4c391</data>
    </node>
    <node id="&quot;NON-LINEAR TIME SERIES MODELS&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Non-linear Time Series Models are a category of models used to analyze and predict time series data that deviate from linear patterns."</data>
      <data key="d2">7b54e70c4e190dec8a2da85292b3e4af</data>
    </node>
    <node id="&quot;AUTOREGRESSIVE CONDITIONAL HETEROSKEDASTICITY (ARCH)&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Autoregressive Conditional Heteroskedasticity (ARCH) is a subcategory of Non-linear Time Series Models that focuses on modeling changes in variability over time."</data>
      <data key="d2">7b54e70c4e190dec8a2da85292b3e4af</data>
    </node>
    <node id="&quot;GARCH&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"GARCH (Generalized Autoregressive Conditional Heteroskedasticity) is a specific model within Autoregressive Conditional Heteroskedasticity (ARCH) that predicts variability based on recent past values of the observed series."</data>
      <data key="d2">7b54e70c4e190dec8a2da85292b3e4af</data>
    </node>
    <node id="&quot;TARCH&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"TARCH (Threshold Autoregressive Conditional Heteroskedasticity) is a variant of GARCH that incorporates a threshold to model asymmetric volatility patterns."</data>
      <data key="d2">7b54e70c4e190dec8a2da85292b3e4af</data>
    </node>
    <node id="&quot;EGARCH&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"EGARCH (Exponential Generalized Autoregressive Conditional Heteroskedasticity) is a modification of GARCH that allows for the modeling of long-term memory effects in time series data."</data>
      <data key="d2">7b54e70c4e190dec8a2da85292b3e4af</data>
    </node>
    <node id="&quot;FIGARCH&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"FIGARCH (Fractionally Integrated Generalized Autoregressive Conditional Heteroskedasticity) is an extension of GARCH that incorporates fractional integration to handle non-stationary data."</data>
      <data key="d2">7b54e70c4e190dec8a2da85292b3e4af</data>
    </node>
    <node id="&quot;CGARCH&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"CGARCH (Conditional Generalized Autoregressive Conditional Heteroskedasticity) is a generalization of GARCH that allows for the modeling of conditional correlations and volatilities in multivariate time series data."</data>
      <data key="d2">7b54e70c4e190dec8a2da85292b3e4af</data>
    </node>
    <node id="&quot;WAVELET TRANSFORM BASED METHODS&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Wavelet Transform Based Methods are a category of techniques used in model-free analyses to decompose time series data and illustrate time dependence at multiple scales."</data>
      <data key="d2">7b54e70c4e190dec8a2da85292b3e4af</data>
    </node>
    <node id="&quot;LOCALLY STATIONARY WAVELETS&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Locally Stationary Wavelets are a subcategory of Wavelet Transform Based Methods that allow for the modeling of non-stationary data by adapting the wavelet basis to local characteristics."</data>
      <data key="d2">7b54e70c4e190dec8a2da85292b3e4af</data>
    </node>
    <node id="&quot;WAVELET DECOMPOSED NEURAL NETWORKS&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Wavelet Decomposed Neural Networks are a combination of Wavelet Transform Based Methods and Neural Networks that decompose time series data at multiple scales and use neural networks for modeling and prediction."</data>
      <data key="d2">7b54e70c4e190dec8a2da85292b3e4af</data>
    </node>
    <node id="&quot;MARKOV SWITCHING MULTIFRACTAL (MSMF)&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Markov Switching Multifractal (MSMF) techniques are a category of models used to model volatility in financial time series data, incorporating switching between multiple regimes and multifractal analysis."</data>
      <data key="d2">7b54e70c4e190dec8a2da85292b3e4af</data>
    </node>
    <node id="&quot;VOLATILITY MODELING&quot;">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">7b54e70c4e190dec8a2da85292b3e4af</data>
    </node>
    <node id="&quot;WAVELET TRANSFORM&quot;">
      <data key="d0">"TECHNOLOGY"</data>
      <data key="d1">"Wavelet Transform is a mathematical tool used for time-frequency analysis, gaining favor in recent work on model-free analyses."</data>
      <data key="d2">f5ca4e75341eb9da478381a489ae6058</data>
    </node>
    <node id="&quot;MULTISCALE TECHNIQUES&quot;">
      <data key="d0">"TECHNOLOGY"</data>
      <data key="d1">"Multiscale Techniques are used to decompose a given time series, illustrating time dependence at multiple scales."</data>
      <data key="d2">f5ca4e75341eb9da478381a489ae6058</data>
    </node>
    <node id="&quot;HIDDEN MARKOV MODEL&quot;">
      <data key="d0">"TECHNOLOGY"</data>
      <data key="d1">"Hidden Markov Model is a statistical model used for modeling time series data, such as speech recognition."</data>
      <data key="d2">f5ca4e75341eb9da478381a489ae6058</data>
    </node>
    <node id="&quot;SKTIME&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Sktime is a Python package that collects various time series models."</data>
      <data key="d2">f5ca4e75341eb9da478381a489ae6058</data>
    </node>
    <node id="&quot;ERGODICITY&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Ergodicity is a condition in time-series analysis that implies stationarity, but the converse is not necessarily the case."
"Ergodicity is a condition in time-series analysis that implies stationarity."</data>
      <data key="d2">cd814464801a2b4d72fc06b10de5e865,f5ca4e75341eb9da478381a489ae6058</data>
    </node>
    <node id="&quot;STATIONARITY&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Stationarity is a condition in time-series analysis that classifies into strict stationarity and wide-sense or second-order stationarity."
"Stationarity is a condition in time-series analysis that can be classified into strict and wide-sense or second-order stationarity."</data>
      <data key="d2">cd814464801a2b4d72fc06b10de5e865,f5ca4e75341eb9da478381a489ae6058</data>
    </node>
    <node id="&quot;TIME-SERIES ANALYSIS&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Time-series Analysis is a field that deals with the analysis of time-series data, using various notations and conditions."</data>
      <data key="d2">cd814464801a2b4d72fc06b10de5e865</data>
    </node>
    <node id="&quot;TIME-FREQUENCY ANALYSIS&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Time-frequency Analysis is a technique used to deal with situations where the amplitudes of frequency components change with time in time-series data."</data>
      <data key="d2">cd814464801a2b4d72fc06b10de5e865</data>
    </node>
    <node id="&quot;TOOLS FOR TIME-SERIES ANALYSIS&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Tools for Time-series Analysis include measures, visualization techniques, and time-frequency analysis methods."</data>
      <data key="d2">cd814464801a2b4d72fc06b10de5e865</data>
    </node>
    <node id="&quot;TIME-SERIES METRICS&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Time-series Metrics are features that can be used for time series classification or regression analysis."
"Time-series Metrics refers to the specific measures or features used for time series classification or regression analysis."</data>
      <data key="d2">a9c0a1c4d1c08c2c79806dc970186e79,cd814464801a2b4d72fc06b10de5e865</data>
    </node>
    <node id="&quot;VISUALIZATION TECHNIQUES&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Visualization Techniques for time series include overlapping and separated charts, with overlapping charts displaying all time series on the same layout."</data>
      <data key="d2">cd814464801a2b4d72fc06b10de5e865</data>
    </node>
    <node id="&quot;MEASURES&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Measures is a category of tools for investigating time-series data, which includes metrics and features for time series classification or regression analysis."</data>
      <data key="d2">a9c0a1c4d1c08c2c79806dc970186e79</data>
    </node>
    <node id="&quot;VISUALIZATION&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Visualization is a category of tools for investigating time-series data, which includes charts for displaying time series data."
"Visualization is the representation of data in a graphical format to facilitate understanding and interpretation."</data>
      <data key="d2">a9c0a1c4d1c08c2c79806dc970186e79,d15f6d075c072f0335b5332f11c00299</data>
    </node>
    <node id="&quot;OVERLAPPING CHARTS&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Overlapping Charts is a type of visualization that displays multiple time series on the same layout."</data>
      <data key="d2">a9c0a1c4d1c08c2c79806dc970186e79</data>
    </node>
    <node id="&quot;SEPARATED CHARTS&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Separated Charts is a type of visualization that displays multiple time series on different layouts, but aligned for comparison."</data>
      <data key="d2">a9c0a1c4d1c08c2c79806dc970186e79</data>
    </node>
    <node id="&quot;BRAIDED GRAPHS&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Braided Graphs is a type of overlapping chart used for visualizing time series data."</data>
      <data key="d2">a9c0a1c4d1c08c2c79806dc970186e79</data>
    </node>
    <node id="&quot;LINE CHARTS&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Line Charts is a type of overlapping chart used for visualizing time series data."</data>
      <data key="d2">a9c0a1c4d1c08c2c79806dc970186e79</data>
    </node>
    <node id="&quot;SLOPE GRAPHS&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Slope Graphs is a type of overlapping chart used for visualizing time series data."</data>
      <data key="d2">a9c0a1c4d1c08c2c79806dc970186e79</data>
    </node>
    <node id="&quot;GAPCHART&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"GapChart is a type of overlapping chart used for visualizing time series data."</data>
      <data key="d2">a9c0a1c4d1c08c2c79806dc970186e79</data>
    </node>
    <node id="&quot;HORIZON GRAPHS&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Horizon Graphs is a type of separated chart used for visualizing time series data."</data>
      <data key="d2">a9c0a1c4d1c08c2c79806dc970186e79</data>
    </node>
    <node id="&quot;REDUCED LINE CHART&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Reduced Line Chart, also known as Small Multiples, is a type of separated chart used for visualizing time series data."</data>
      <data key="d2">a9c0a1c4d1c08c2c79806dc970186e79</data>
    </node>
    <node id="&quot;SILHOUETTE GRAPH&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Silhouette Graph is a type of separated chart used for visualizing time series data."</data>
      <data key="d2">a9c0a1c4d1c08c2c79806dc970186e79</data>
    </node>
    <node id="&quot;CIRCULAR SILHOUETTE GRAPH&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Circular Silhouette Graph is a type of separated chart used for visualizing time series data, which is a variation of the Silhouette Graph."</data>
      <data key="d2">a9c0a1c4d1c08c2c79806dc970186e79</data>
    </node>
    <node id="&quot;ECHO STATE NETWORK&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Echo State Network is a type of recurrent neural network architecture developed for supervised learning."
"Echo State Network is a type of recurrent neural network that uses a high-dimensional dynamical system to reconstruct desired outputs."
"The Echo State Network is a type of recurrent neural network used in the ESN Models."
"The Echo State Network is a type of recurrent neural network mentioned in the text, with control parameters and reservoir size as key components."
"Echo State Network is a type of recurrent neural network used for time series prediction and data analysis."
"Echo State Network is a type of recurrent neural network used for time series prediction and data analysis."
"Echo State Network is a type of recurrent neural network used for tasks such as time series prediction and pattern recognition."
"Echo State Network is a type of reservoir computer that uses a recurrent neural network with a sparsely connected hidden layer."</data>
      <data key="d2">29f9b2e5fa311519b18e7aef31c68d0a,2dca9849c50a439b0637cf370afde7dd,5972cf7d440b1c3fdc0f05fca305f18d,688ebc7151bc148ac24dc7e2727d7afe,6daefaa8fbd5c1492f2d832d79841463,804bd76fa6f4950ef9a5cf8f0025fc1c,cc7c60d8e36838743d509a97c9ac3a4b,dcd6355fc1ed8a61a1b70c50ce60fd36</data>
    </node>
    <node id="&quot;HERBERT JAEGER&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Herbert Jaeger is a researcher associated with the development of Echo State Networks."
"Herbert Jaeger is an author of a research paper on controlling recurrent neural networks by conceptors."
"Herbert Jaeger is a researcher who published a paper on controlling recurrent neural networks by conceptors."</data>
      <data key="d2">546551fd625e354e9afe1245e060bed3,804bd76fa6f4950ef9a5cf8f0025fc1c,c8b7bd13cf99920ecce56cb563910cb3</data>
    </node>
    <node id="&quot;JACOBS UNIVERSITY BREMEN&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Jacobs University Bremen is the institution where Herbert Jaeger is affiliated."</data>
      <data key="d2">804bd76fa6f4950ef9a5cf8f0025fc1c</data>
    </node>
    <node id="&quot;BREMEN&quot;">
      <data key="d0">"GEO"</data>
      <data key="d1">"Bremen is a city in Germany where Jacobs University is located."</data>
      <data key="d2">804bd76fa6f4950ef9a5cf8f0025fc1c</data>
    </node>
    <node id="&quot;GERMANY&quot;">
      <data key="d0">"GEO"</data>
      <data key="d1">"Germany is the country where Bremen and Jacobs University are located."</data>
      <data key="d2">804bd76fa6f4950ef9a5cf8f0025fc1c</data>
    </node>
    <node id="&quot;LIQUID STATE MACHINES&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Liquid State Machines are a type of recurrent neural network developed by Wolfgang Maass, which share similarities with Echo State Networks."
"Liquid State Machines are a type of system developed by Wolfgang Maass that are related to Echo State Networks and Reservoir Computing."
"LSM is a type of machine learning model developed independently by Wolfgang Maass, used for reservoir computing."</data>
      <data key="d2">158f53cd85edbb4f2e4c77b78c5e7acc,804bd76fa6f4950ef9a5cf8f0025fc1c,b32958d42199d47252887dc7be40ab5a</data>
    </node>
    <node id="&quot;WOLFGANG MAASS&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Wolfgang Maass is a researcher associated with the development of Liquid State Machines."
"Wolfgang Maass is a co-author of a scientific paper on a specific topic, but the relationship description and strength are not explicitly stated in the text."
"Wolfgang Maass is an author of a research paper on emergence of complex computational structures from chaotic neural networks."
"Wolfgang Maass is a researcher who independently developed Liquid State Machines, which are related to Echo State Networks and Reservoir Computing."
"Wolfgang Maass is a researcher who independently developed Liquid State Machines and Echo State Networks."</data>
      <data key="d2">158f53cd85edbb4f2e4c77b78c5e7acc,804bd76fa6f4950ef9a5cf8f0025fc1c,b32958d42199d47252887dc7be40ab5a,c8b7bd13cf99920ecce56cb563910cb3,ce7b58ffc7f43f36bc78154597d01903</data>
    </node>
    <node id="&quot;BACKPROPAGATION DECORRELATION LEARNING RULE&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Backpropagation Decorrelation learning rule is a method for training recurrent neural networks, developed by Schiller and Steil."
"The Backpropagation Decorrelation learning rule is a method for training RNNs, which has been demonstrated by Schiller and Steil to be related to Reservoir Computing."
"Backpropagation Decorrelation learning rule is a method used for training Recurrent Neural Networks, mentioned in the context of reservoir computing."</data>
      <data key="d2">158f53cd85edbb4f2e4c77b78c5e7acc,804bd76fa6f4950ef9a5cf8f0025fc1c,b32958d42199d47252887dc7be40ab5a</data>
    </node>
    <node id="&quot;PETER F. DOMINEY&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Peter F. Dominey is a researcher who has investigated a related mechanism in the context of modeling sequence processing in mammalian brains, especially speech recognition in the human brain."
"Peter F. Dominey is a researcher in cognitive neuroscience who has investigated mechanisms related to reservoir computing, such as speech recognition in the human brain."
"Peter F. Dominey is a researcher who analyzed a process related to the modeling of sequence processing in the mammalian brain, including speech recognition in the human brain."</data>
      <data key="d2">804bd76fa6f4950ef9a5cf8f0025fc1c,88ff8a7687e01f40b2c9d151b6e83d64,b32958d42199d47252887dc7be40ab5a</data>
    </node>
    <node id="&quot;SCHILLER&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Schiller is a researcher mentioned in the text, contributing to the understanding of reservoir computing."</data>
      <data key="d2">88ff8a7687e01f40b2c9d151b6e83d64</data>
    </node>
    <node id="&quot;STEIL&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Steil is a researcher mentioned in the text, contributing to the understanding of reservoir computing."
"Steil is mentioned as the author of the Intrinsic Plasticity mechanism for reservoirs in ReservoirPy."</data>
      <data key="d2">88ff8a7687e01f40b2c9d151b6e83d64,fcac967511cf2b019fd856e23d2e91d9</data>
    </node>
    <node id="&quot;K. KIRBY&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"K. Kirby is a researcher who exposed the concept of reservoir computing in a conference contribution."
"K. Kirby is a researcher who disclosed the concept of reservoir computing in a conference contribution."</data>
      <data key="d2">88ff8a7687e01f40b2c9d151b6e83d64,b32958d42199d47252887dc7be40ab5a</data>
    </node>
    <node id="&quot;L. SCHOMAKER&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"L. Schomaker is a researcher who described a method of obtaining a desired target output from an RNN by learning to combine signals from a randomly configured ensemble of spiking neural oscillators."
"L. Schomaker is a researcher who contributed to the development of the reservoir computing idea."
"L. Schomaker is a researcher who described how a desired target output could be obtained from an RNN by learning to combine signals from a randomly configured ensemble of spiking neural oscillators."
"L. Schomaker is a researcher who described a formulation of the reservoir computing idea known today, involving the use of a randomly configured ensemble of spiking neural oscillators."</data>
      <data key="d2">88ff8a7687e01f40b2c9d151b6e83d64,a3368f9cab1f65643dba089af5a1f95e,a621b44739e0cb4379645a4a58f16697,b32958d42199d47252887dc7be40ab5a</data>
    </node>
    <node id="&quot;TRAINING METHODS&quot;">
      <data key="d0">"EVENT"</data>
      <data key="d1">"Training Methods refer to the processes used to adapt the weights of a reservoir computing network."</data>
      <data key="d2">88ff8a7687e01f40b2c9d151b6e83d64</data>
    </node>
    <node id="&quot;SEQUENCE PROCESSING&quot;">
      <data key="d0">"EVENT"</data>
      <data key="d1">"Sequence Processing is a task mentioned in the text, which has been modelled using reservoir computing in cognitive neuroscience."
</data>
      <data key="d2">88ff8a7687e01f40b2c9d151b6e83d64,b32958d42199d47252887dc7be40ab5a</data>
    </node>
    <node id="&quot;RNN&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"RNN is an abbreviation for Recurrent Neural Network, a type of neural network used in the reservoir computing idea."
"RNN is a type of neural network mentioned in the text, which the Echo State Networks are designed to train."
"RNN stands for Recurrent Neural Network, a type of neural network used by Baidu and Google in their machine learning models."
"RNN is a type of neural network that corresponds to a linear chain, a special case of recursive neural networks."
"RNN is a type of neural network used in deep learning systems, such as Second-order RNNs and Long short-term memory (LSTM)."
"RNN is a type of neural network architecture that processes sequential data, with variants such as LSTM and IndRNN addressing the vanishing gradients problem."</data>
      <data key="d2">1aec5b03f663d1614b2ecbf97981a5c2,4470a7f7ad60a2866b31907a2a3ca96e,486e4b71bf02f756450ab727db88f821,7b6ff30ef255db2d2c68326d78cf0115,a621b44739e0cb4379645a4a58f16697,f0b3b2a88425b0563005400ea246528b</data>
    </node>
    <node id="&quot;TRAINING INPUT-OUTPUT SEQUENCE&quot;">
      <data key="d0">"EVENT"</data>
      <data key="d1">"The Training Input-Output Sequence is a set of data used to train the RNN to behave as a tunable frequency generator."</data>
      <data key="d2">a621b44739e0cb4379645a4a58f16697</data>
    </node>
    <node id="&quot;RESERVOIR COMPUTING IDEA&quot;">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">a621b44739e0cb4379645a4a58f16697</data>
    </node>
    <node id="&quot;SCHMIDHUBER ET AL.&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Schmidhuber et al. is a group of researchers mentioned in the text, who have used margin-maximization criteria in the context of Echo State Networks."</data>
      <data key="d2">f0b3b2a88425b0563005400ea246528b</data>
    </node>
    <node id="&quot;SIGMOID UNIT&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Sigmoid Unit is a type of neuron mentioned in the text, which is used in the basic discrete-time echo state network."</data>
      <data key="d2">f0b3b2a88425b0563005400ea246528b</data>
    </node>
    <node id="&quot;SIGMOID FUNCTION&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Sigmoid Function is a mathematical function used in the Echo State Network to map input values to a specific range, typically between 0 and 1."</data>
      <data key="d2">cc7c60d8e36838743d509a97c9ac3a4b</data>
    </node>
    <node id="&quot;RESERVOIR WEIGHT MATRIX&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Reservoir Weight Matrix is a matrix used in the Echo State Network to update the reservoir state."
"The Reservoir Weight Matrix is a component of a Recurrent Neural Network (RNN) that affects its behavior."</data>
      <data key="d2">3b592e5ac113a5c031925f91a182baa6,cc7c60d8e36838743d509a97c9ac3a4b</data>
    </node>
    <node id="&quot;INPUT WEIGHT MATRIX&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Input Weight Matrix is a matrix used in the Echo State Network to map input signals to the reservoir state."</data>
      <data key="d2">cc7c60d8e36838743d509a97c9ac3a4b</data>
    </node>
    <node id="&quot;OUTPUT FEEDBACK MATRIX&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Output Feedback Matrix is a matrix used in the Echo State Network to provide feedback from the output signal to the reservoir state."</data>
      <data key="d2">cc7c60d8e36838743d509a97c9ac3a4b</data>
    </node>
    <node id="&quot;LOGISTIC SIGMOID&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Logistic Sigmoid is a type of sigmoid function that maps input values to a range between 0 and 1."</data>
      <data key="d2">cc7c60d8e36838743d509a97c9ac3a4b</data>
    </node>
    <node id="&quot;TANH FUNCTION&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Tanh Function is a type of sigmoid function that maps input values to a range between -1 and 1."</data>
      <data key="d2">cc7c60d8e36838743d509a97c9ac3a4b</data>
    </node>
    <node id="&quot;STATE COLLECTION MATRIX&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"State Collection Matrix is a data structure used to store extended system states during the training of the ESN."</data>
      <data key="d2">f18a060e6d2bb1da70432cbc71378770</data>
    </node>
    <node id="&quot;INPUT SEQUENCE&quot;">
      <data key="d0">"EVENT"</data>
      <data key="d1">"Input Sequence is a sequence of inputs used to drive the ESN during the state harvesting stage of training."</data>
      <data key="d2">f18a060e6d2bb1da70432cbc71378770</data>
    </node>
    <node id="&quot;OUTPUT SEQUENCE&quot;">
      <data key="d0">"EVENT"</data>
      <data key="d1">"Output Sequence is a sequence of outputs obtained from the ESN during the training stage, which may involve teacher forcing."</data>
      <data key="d2">f18a060e6d2bb1da70432cbc71378770</data>
    </node>
    <node id="&quot;SYSTEM EQUATIONS&quot;">
      <data key="d0">"EVENT"</data>
      <data key="d1">"System Equations are the mathematical equations used to describe the behavior of the ESN, including the reservoir and input states, and the output activation function."
"System Equations are mathematical representations used in the model to describe its behavior."</data>
      <data key="d2">6a4432cd530b28770e2b903fe242a0d1,f18a060e6d2bb1da70432cbc71378770</data>
    </node>
    <node id="&quot;OUTPUT FEEDBACK&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Output Feedback is a feature of the model that involves writing correct outputs into the output units during the generation of system states."</data>
      <data key="d2">6a4432cd530b28770e2b903fe242a0d1</data>
    </node>
    <node id="&quot;DESIRED OUTPUTS&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Desired Outputs are the target values that the model aims to produce."</data>
      <data key="d2">6a4432cd530b28770e2b903fe242a0d1</data>
    </node>
    <node id="&quot;DESIRED OUTPUT WEIGHTS&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Desired Output Weights are the linear regression weights of the desired outputs on the harvested extended states."</data>
      <data key="d2">6a4432cd530b28770e2b903fe242a0d1</data>
    </node>
    <node id="&quot;PSEUDOINVERSE&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Pseudoinverse is a mathematical operation used to compute the desired output weights in the model."
"The Pseudoinverse is a mathematical concept used in the computation of output weights in the context of a reservoir."</data>
      <data key="d2">6a4432cd530b28770e2b903fe242a0d1,a9f53979e9dbe6b936ff3374c73006dd</data>
    </node>
    <node id="&quot;LINEAR SIGNAL PROCESSING&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Linear Signal Processing is a concept mentioned as a method for computing output weights."</data>
      <data key="d2">a9f53979e9dbe6b936ff3374c73006dd</data>
    </node>
    <node id="&quot;ADDITIVE-SIGMOID NEURON RESERVOIRS&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Additive-Sigmoid Neuron Reservoirs are a type of reservoir mentioned in the context of the Echo State Property."</data>
      <data key="d2">a9f53979e9dbe6b936ff3374c73006dd</data>
    </node>
    <node id="&quot;JAEGER 2003&quot;">
      <data key="d0">"EVENT"</data>
      <data key="d1">"Jaeger 2003 is a reference mentioned as a source for online adaptive methods used to compute output weights."</data>
      <data key="d2">a9f53979e9dbe6b936ff3374c73006dd</data>
    </node>
    <node id="&quot;OUTPUT WEIGHTS&quot;">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">a9f53979e9dbe6b936ff3374c73006dd</data>
    </node>
    <node id="&quot;ESP&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"ESP stands for Echo State Property, which is a characteristic of a Reservoir Weight Matrix in the context of Recurrent Neural Networks."</data>
      <data key="d2">3b592e5ac113a5c031925f91a182baa6</data>
    </node>
    <node id="&quot;JAEGER&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Jaeger is a researcher mentioned in the text, contributing to the understanding of Echo State Properties and Recurrent Neural Networks."
"Jaeger is a person mentioned in the text, likely a researcher or author."
"Jaeger is a researcher mentioned in the text, contributing to the theoretical research on Echo State Networks."
"Jaeger is a person mentioned in the text who has contributed to the development of Echo State Networks."
"Jaeger is a person mentioned in the text, likely a researcher or author."
"Jaeger is not explicitly mentioned in the text, but the context suggests that he might be associated with Echo State Networks or Reservoir Computing."
"Jaeger is a researcher who contributed to the development of Reservoir Computing and Echo State Networks."
"Jaeger is a person who firstly formulated the concept of RC networks within the ML community."
"Jaeger is mentioned as the author of Echo State Networks (ESNs), a popular flavor of RC."
"Jaeger is a researcher mentioned in the context of Echo State Networks, a type of recurrent neural network."
"Jaeger is a person who proposed a mechanism for controlling the dynamics of reservoirs in 2014."
"Jaeger is a researcher and developer of the Echo State Network (ESN) model, which is used in the provided code."</data>
      <data key="d2">257d4cf08ffc32b99856b6e31fa4221e,295606b4bc5d12929a913a3c79f93734,2dca9849c50a439b0637cf370afde7dd,3b592e5ac113a5c031925f91a182baa6,418f92b0dd08e03a20637ffec8193bfc,52d001cd1786e3d9f36e0c57538bc21e,5a9eaff8c67e594f49fae0318a502c6a,6de297d888d10db4c987b5eafc6398b2,a1adb5de4156f0a4a448caf79056e886,bc2d4d6bb706c3d06ffd2c9c2f362104,d4563a00dc04ebf7bcf01e5062fde46f,eafe89ad19a57846f953a1dfcf8571f8</data>
    </node>
    <node id="&quot;BUEHNER&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Buehner is a researcher mentioned in the text, contributing to the algebraic conditions for additive-sigmoid neuron reservoirs."</data>
      <data key="d2">3b592e5ac113a5c031925f91a182baa6</data>
    </node>
    <node id="&quot;YILDIZ&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Yildiz is a researcher mentioned in the text, contributing to the algebraic conditions for a specific subclass of reservoirs."</data>
      <data key="d2">3b592e5ac113a5c031925f91a182baa6</data>
    </node>
    <node id="&quot;MANJUNATH&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Manjunath is a researcher mentioned in the text, exploring the relationship between input signal characteristics and the ESP."</data>
      <data key="d2">3b592e5ac113a5c031925f91a182baa6</data>
    </node>
    <node id="&quot;LEAKY INTEGRATOR NEURONS&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Leaky Integrator Neurons are a type of neuron mentioned in the text, and their algebraic conditions are spelled out in a research paper by Jaeger et al."</data>
      <data key="d2">3b592e5ac113a5c031925f91a182baa6</data>
    </node>
    <node id="&quot;MANJUNATH AND JAEGER&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Manjunath and Jaeger are the authors of a study exploring the relationship between input signal characteristics and the ESP."</data>
      <data key="d2">d4563a00dc04ebf7bcf01e5062fde46f</data>
    </node>
    <node id="&quot;INPUT SIGNAL&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Input Signal refers to the signal used as input in the context of Echo State Networks and memory capacity."</data>
      <data key="d2">d4563a00dc04ebf7bcf01e5062fde46f</data>
    </node>
    <node id="&quot;OUTPUT SIGNAL&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Output Signal refers to the signal produced by the Echo State Network as a result of processing the input signal."</data>
      <data key="d2">d4563a00dc04ebf7bcf01e5062fde46f</data>
    </node>
    <node id="&quot;MEMORY CAPACITY&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Memory Capacity is a term used to describe the ability of an Echo State Network to retain and recall information from past input signals."</data>
      <data key="d2">d4563a00dc04ebf7bcf01e5062fde46f</data>
    </node>
    <node id="&quot;WHITE&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"White is a researcher mentioned in the text, contributing to the theoretical research on Echo State Networks."</data>
      <data key="d2">5a9eaff8c67e594f49fae0318a502c6a</data>
    </node>
    <node id="&quot;SOMPOLINSKY&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Sompolinsky is a researcher mentioned in the text, contributing to the theoretical research on Echo State Networks."</data>
      <data key="d2">5a9eaff8c67e594f49fae0318a502c6a</data>
    </node>
    <node id="&quot;HERMANS&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Hermans is a researcher mentioned in the text, contributing to the theoretical research on Echo State Networks."</data>
      <data key="d2">5a9eaff8c67e594f49fae0318a502c6a</data>
    </node>
    <node id="&quot;SCHRAUWEN&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Schrauwen is a researcher mentioned in the text, contributing to the theoretical research on Echo State Networks."</data>
      <data key="d2">5a9eaff8c67e594f49fae0318a502c6a</data>
    </node>
    <node id="&quot;SCHMIDHUBER&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Schmidhuber is a researcher mentioned in the text, contributing to the theoretical research on Echo State Networks and their limitations."
"Schmidhuber is a researcher who contributed to the development of Long Short Term Memory (LSTM) cells for training Recurrent Neural Networks."
"Schmidhuber is a researcher who developed methods for training recurrent neural networks."
"Schmidhuber is a person who contributed to the development of recurrent neural networks in the 1980s and early 1990s."</data>
      <data key="d2">0bb54b1de8d2297293defe94addb8076,5a9eaff8c67e594f49fae0318a502c6a,6bbaf3df0fa2fac979f6d6a64abb2e91,6de297d888d10db4c987b5eafc6398b2</data>
    </node>
    <node id="&quot;MAASS&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Maass is a researcher mentioned in the text, contributing to the theoretical research on Echo State Networks and their ability to realize unbounded memory spans."
"Maass is a researcher who contributed to the development of Echo State Networks and their applications in Machine Learning."</data>
      <data key="d2">5a9eaff8c67e594f49fae0318a502c6a,6de297d888d10db4c987b5eafc6398b2</data>
    </node>
    <node id="&quot;NATSCHLAEGER&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Natschlaeger is a researcher mentioned in the text, contributing to the theoretical research on Echo State Networks."</data>
      <data key="d2">5a9eaff8c67e594f49fae0318a502c6a</data>
    </node>
    <node id="&quot;MARKRAM&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Markram is a researcher mentioned in the text, contributing to the theoretical research on Echo State Networks."</data>
      <data key="d2">5a9eaff8c67e594f49fae0318a502c6a</data>
    </node>
    <node id="&quot;BOUNDED MEMORY&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Bounded Memory refers to the limitation of Echo State Networks in handling tasks that require unbounded-time memory."</data>
      <data key="d2">5a9eaff8c67e594f49fae0318a502c6a</data>
    </node>
    <node id="&quot;UNBOUNDED MEMORY SPANS&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Unbounded Memory Spans refer to the ability of Echo State Networks to handle tasks that require memory spans beyond their initial size."</data>
      <data key="d2">5a9eaff8c67e594f49fae0318a502c6a</data>
    </node>
    <node id="&quot;MAASS, JOSHI &amp; SONTAG&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Maass, Joshi &amp; Sontag are the authors of a research paper on ESNs and their theoretical properties."</data>
      <data key="d2">e805d3f438bd9c485639f1c69f917ae5</data>
    </node>
    <node id="&quot;PASCANU &amp; JAEGER&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Pascanu &amp; Jaeger are the authors of a research paper on an ESN-based model of working memory."</data>
      <data key="d2">e805d3f438bd9c485639f1c69f917ae5</data>
    </node>
    <node id="&quot;MAASS, NATSCHLAEGER &amp; MARKRAM&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Maass, Natschlaeger &amp; Markram are the authors of a research paper on Liquid State Machines, a theoretical framework related to ESNs."</data>
      <data key="d2">e805d3f438bd9c485639f1c69f917ae5</data>
    </node>
    <node id="&quot;NONLINEAR MODELING TASKS&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Nonlinear Modeling Tasks refer to the practical application of ESNs in complex, nonlinear systems."</data>
      <data key="d2">e805d3f438bd9c485639f1c69f917ae5</data>
    </node>
    <node id="&quot;TEST ERROR&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Test Error refers to the performance metric used to evaluate the accuracy of a model on unseen data."</data>
      <data key="d2">e805d3f438bd9c485639f1c69f917ae5</data>
    </node>
    <node id="&quot;VALIDATION SET&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"The Validation Set is a portion of the original training data withheld for monitoring the performance of a model during training."
"The Validation Set is a portion of the original training data withheld for evaluating the performance of the ESN Models."</data>
      <data key="d2">5972cf7d440b1c3fdc0f05fca305f18d,e805d3f438bd9c485639f1c69f917ae5</data>
    </node>
    <node id="&quot;ESN MODELS&quot;">
      <data key="d0" />
      <data key="d1">
"ESN Models are a type of machine learning model used for prediction and data analysis."</data>
      <data key="d2">5972cf7d440b1c3fdc0f05fca305f18d,e805d3f438bd9c485639f1c69f917ae5</data>
    </node>
    <node id="&quot;STATE NOISE&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"State Noise is a method of adding noise to the states of the Echo State Network, which can have the additional benefit of stabilizing solutions in models with output feedback."</data>
      <data key="d2">5972cf7d440b1c3fdc0f05fca305f18d</data>
    </node>
    <node id="&quot;IDENTITY MATRIX&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"The Identity Matrix is a mathematical concept used in the text to describe a specific method."</data>
      <data key="d2">2dca9849c50a439b0637cf370afde7dd</data>
    </node>
    <node id="&quot;LUKO&#352;EVI&#268;IUS&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Luko&#353;evi&#269;ius is a person mentioned in the text who has written about practical techniques for optimizing Echo State Networks."</data>
      <data key="d2">2dca9849c50a439b0637cf370afde7dd</data>
    </node>
    <node id="&quot;REAL-TIME RECURRENT LEARNING ALGORITHM&quot;">
      <data key="d0">"EVENT"</data>
      <data key="d1">"The Real-time Recurrent Learning Algorithm is an algorithm mentioned in the text for supervised training of RNNs."</data>
      <data key="d2">2dca9849c50a439b0637cf370afde7dd</data>
    </node>
    <node id="&quot;REAL-TIME RECURRENT LEARNING&quot;">
      <data key="d0">"ALGORITHM"</data>
      <data key="d1">"Real-time Recurrent Learning is a supervised training algorithm for RNNs that adapts all connections using gradient descent, known since the early 1990s."
"Real-Time Recurrent Learning is a method developed for training recurrent neural networks."
"Real-Time Recurrent Learning is a learning algorithm for Recurrent Neural Networks that operates in real-time."</data>
      <data key="d2">2a2a93486d6198ce228e77e120dc3c0c,6bbaf3df0fa2fac979f6d6a64abb2e91,a4b801e70cf2ba3a3101d34899450087</data>
    </node>
    <node id="&quot;BACKPROPAGATION THROUGH TIME&quot;">
      <data key="d0">"ALGORITHM"</data>
      <data key="d1">"Backpropagation Through Time is a supervised training algorithm for RNNs that adapts all connections using gradient descent, introduced in 1990."
"Backpropagation Through Time (BPTT) is a method used in training recurrent neural networks to calculate gradients."
"Backpropagation through Time is a method developed for training recurrent neural networks."
"Backpropagation Through Time is a learning algorithm for Recurrent Neural Networks."</data>
      <data key="d2">0bb54b1de8d2297293defe94addb8076,2a2a93486d6198ce228e77e120dc3c0c,6bbaf3df0fa2fac979f6d6a64abb2e91,a4b801e70cf2ba3a3101d34899450087</data>
    </node>
    <node id="&quot;EXTENDED KALMAN FILTERING BASED METHODS&quot;">
      <data key="d0">"ALGORITHM"</data>
      <data key="d1">"Extended Kalman Filtering Based Methods is a supervised training algorithm for RNNs that adapts all connections, introduced in 2004."</data>
      <data key="d2">2a2a93486d6198ce228e77e120dc3c0c</data>
    </node>
    <node id="&quot;ATIYA-PARLOS ALGORITHM&quot;">
      <data key="d0">"ALGORITHM"</data>
      <data key="d1">"The Atiya-Parlos Algorithm is a supervised training algorithm for RNNs that adapts all connections using gradient descent, introduced in 2000."</data>
      <data key="d2">2a2a93486d6198ce228e77e120dc3c0c</data>
    </node>
    <node id="&quot;DEEP LEARNING&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Deep Learning is a subset of machine learning that involves training deep neural networks with multiple layers."</data>
      <data key="d2">eafe89ad19a57846f953a1dfcf8571f8</data>
    </node>
    <node id="&quot;HAAS&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Haas is a person mentioned in the text, likely a researcher or author."
"Haas is a researcher and developer of the Echo State Network (ESN) model, which is used in the provided code."</data>
      <data key="d2">52d001cd1786e3d9f36e0c57538bc21e,eafe89ad19a57846f953a1dfcf8571f8</data>
    </node>
    <node id="&quot;DOYA&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Doya is a person mentioned in the text, likely a researcher or author."</data>
      <data key="d2">eafe89ad19a57846f953a1dfcf8571f8</data>
    </node>
    <node id="&quot;KUDITHIPUDI ET AL.&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Kudithipudi et al. are a group of researchers mentioned in the text."</data>
      <data key="d2">eafe89ad19a57846f953a1dfcf8571f8</data>
    </node>
    <node id="&quot;ANTONELO&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Antonelo is a person mentioned in the text, likely a researcher or author."</data>
      <data key="d2">eafe89ad19a57846f953a1dfcf8571f8</data>
    </node>
    <node id="&quot;2010&quot;">
      <data key="d0">"EVENT"</data>
      <data key="d1">"2010 is the year mentioned when Echo State Networks started to gain relevance and popularity."</data>
      <data key="d2">257d4cf08ffc32b99856b6e31fa4221e</data>
    </node>
    <node id="&quot;OPTICAL MICROCHIPS&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Optical Microchips are a type of non-digital computational substrate that has been used in conjunction with Echo State Networks."
"Optical Microchips are a type of non-digital computer substrate that can be used as a reservoir in ESNs."
"Optical Microchips are a type of object used as a nonlinear reservoir."</data>
      <data key="d2">257d4cf08ffc32b99856b6e31fa4221e,4b89d9404fd683ecd03d5846ee2d86ce,7767d42e08c8eab856e8e3025c692309</data>
    </node>
    <node id="&quot;MECHANICAL NANO-OSCILLATORS&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Mechanical Nano-oscillators are a type of non-digital computational substrate that has been used in conjunction with Echo State Networks."</data>
      <data key="d2">257d4cf08ffc32b99856b6e31fa4221e</data>
    </node>
    <node id="&quot;MEMRISTOR-BASED NEUROMORPHIC MICROCHIPS&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Memristor-based Neuromorphic Microchips are a type of non-digital computational substrate that has been used in conjunction with Echo State Networks."</data>
      <data key="d2">257d4cf08ffc32b99856b6e31fa4221e</data>
    </node>
    <node id="&quot;CARBON-NANOTUBE / POLYMER MIXTURES&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Carbon-nanotube / Polymer Mixtures are a type of non-digital computational substrate that has been used in conjunction with Echo State Networks."</data>
      <data key="d2">257d4cf08ffc32b99856b6e31fa4221e</data>
    </node>
    <node id="&quot;ARTIFICIAL SOFT LIMBS&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Artificial Soft Limbs are a type of non-digital computational substrate that has been used in conjunction with Echo State Networks."
"Artificial Soft Limbs are a type of non-digital computer substrate that can be used as a reservoir in ESNs."
"Artificial Soft Limbs are a type of object used as a nonlinear reservoir."</data>
      <data key="d2">257d4cf08ffc32b99856b6e31fa4221e,4b89d9404fd683ecd03d5846ee2d86ce,7767d42e08c8eab856e8e3025c692309</data>
    </node>
    <node id="&quot;BIOSIGNAL PROCESSING&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Biosignal Processing is an application area where Echo State Networks have been used."</data>
      <data key="d2">257d4cf08ffc32b99856b6e31fa4221e</data>
    </node>
    <node id="&quot;REMOTE SENSING&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Remote Sensing is an application area where Echo State Networks have been used."</data>
      <data key="d2">257d4cf08ffc32b99856b6e31fa4221e</data>
    </node>
    <node id="&quot;ROBOT MOTOR CONTROL&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Robot Motor Control is an application area where Echo State Networks have been used."</data>
      <data key="d2">257d4cf08ffc32b99856b6e31fa4221e</data>
    </node>
    <node id="&quot;B&#220;RGER ET AL.&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"B&#252;rger et al. is a group of researchers mentioned in the text."</data>
      <data key="d2">dbca0570761b1698d32f0c0bfb593b1a</data>
    </node>
    <node id="&quot;DALE ET AL.&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Dale et al. is a group of researchers mentioned in the text."</data>
      <data key="d2">dbca0570761b1698d32f0c0bfb593b1a</data>
    </node>
    <node id="&quot;NAKAJIMA, HAUSER AND PFEIFER&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Nakajima, Hauser and Pfeifer is a group of researchers mentioned in the text."</data>
      <data key="d2">dbca0570761b1698d32f0c0bfb593b1a</data>
    </node>
    <node id="&quot;ESN METHODS&quot;">
      <data key="d0">"TECHNIQUE"</data>
      <data key="d1">"ESN methods are a type of computational method mentioned in the text."</data>
      <data key="d2">dbca0570761b1698d32f0c0bfb593b1a</data>
    </node>
    <node id="&quot;LIQUID STATE MACHINE&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Liquid State Machine is a concept mentioned in the text."
"Liquid State Machine is a variant of Echo State Networks for spiking neurons."</data>
      <data key="d2">423cdb622c47fa8cec25f22eb9f9f01f,dbca0570761b1698d32f0c0bfb593b1a</data>
    </node>
    <node id="&quot;RECURRENT NEURAL NETWORKS&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Recurrent Neural Networks is a concept mentioned in the text."
"Recurrent Neural Networks are mentioned in the text as a component of Reservoir Computing."
"Recurrent Neural Networks are a type of neural network that processes sequential data by maintaining an internal state, allowing them to capture and model long-term dependencies."
"Recurrent Neural Networks (RNNs) are a type of neural network that process sequential data, consisting of a network of recurrently connected neurons."

"Recurrent Neural Networks are a type of neural network that use a feedback loop to maintain an internal state over time, allowing them to process sequential data."
"Recurrent neural networks are a type of artificial neural network that have connections that allow information to persist, enabling them to capture and model sequential data."

"Recurrent Neural Networks are a type of neural network that use an internal memory to process sequential data."
"Recurrent Neural Networks are a type of neural network that operates on the linear progression of time, combining the previous time step and a hidden representation into the representation for the current time step."
"Recurrent Neural Networks are a type of dynamic system used for training and prediction tasks, with learning algorithms such as backpropagation through time and real-time recurrent learning."</data>
      <data key="d2">0bb54b1de8d2297293defe94addb8076,0f59288ce2aaf33e468cdc3877cefd85,136559fd2a1fbef4cc8a6b11abcb3eef,158f53cd85edbb4f2e4c77b78c5e7acc,2bdd28d9e151597072c8490db69b9941,2f1161d1f711d264529aa7bddf81959b,6de297d888d10db4c987b5eafc6398b2,9e61c22432d6984a19da5840f64d417d,bc2d4d6bb706c3d06ffd2c9c2f362104,dbca0570761b1698d32f0c0bfb593b1a,f59839daadfb1f3832bb9f8d201a7126</data>
    </node>
    <node id="&quot;INRIA BORDEAUX SUD-OUEST&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Inria Bordeaux Sud-Ouest is an organization where Nathan Trouvain and Xavier Hinaut work, contributing to reservoirpy."
"Inria Bordeaux Sud-Ouest is a research organization mentioned in the text, which is part of the IMN and LaBRI."</data>
      <data key="d2">136559fd2a1fbef4cc8a6b11abcb3eef,18910a60b2547ec3133340f42c45bb47</data>
    </node>
    <node id="&quot;IMN&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"IMN is a department at Inria Bordeaux Sud-Ouest where Nathan Trouvain and Xavier Hinaut work, contributing to reservoirpy."</data>
      <data key="d2">18910a60b2547ec3133340f42c45bb47</data>
    </node>
    <node id="&quot;LABRI&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"LaBRI is a research unit at Inria Bordeaux Sud-Ouest where Nathan Trouvain and Xavier Hinaut work, contributing to reservoirpy."</data>
      <data key="d2">18910a60b2547ec3133340f42c45bb47</data>
    </node>
    <node id="&quot;RESERVOIR COMPUTING (RC)&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Reservoir Computing (RC) is a field that reservoirpy operates in, focusing on the design and training of models, particularly Echo State Networks (ESNs)."</data>
      <data key="d2">18910a60b2547ec3133340f42c45bb47</data>
    </node>
    <node id="&quot;DOMINEY&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Dominey is a researcher who contributed to the development of Reservoir Computing and its applications in signal processing."
"Dominey is a person who contributed to the concept of RC networks in the Neuroscience field."</data>
      <data key="d2">418f92b0dd08e03a20637ffec8193bfc,6de297d888d10db4c987b5eafc6398b2</data>
    </node>
    <node id="&quot;BUONOMANO&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Buonomano is a researcher who contributed to the development of Reservoir Computing and its applications in neuroscience."</data>
      <data key="d2">6de297d888d10db4c987b5eafc6398b2</data>
    </node>
    <node id="&quot;HOCHREITER&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Hochreiter is a researcher who contributed to the development of Long Short Term Memory (LSTM) cells for training Recurrent Neural Networks."
"Hochreiter is a researcher who developed methods for training recurrent neural networks."
"Hochreiter is a person who contributed to the development of recurrent neural networks in the 1980s and early 1990s."</data>
      <data key="d2">0bb54b1de8d2297293defe94addb8076,6bbaf3df0fa2fac979f6d6a64abb2e91,6de297d888d10db4c987b5eafc6398b2</data>
    </node>
    <node id="&quot;LONG SHORT TERM MEMORY&quot;">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">6de297d888d10db4c987b5eafc6398b2</data>
    </node>
    <node id="&quot;RC NETWORKS&quot;">
      <data key="d0">"TECHNOLOGY"</data>
      <data key="d1">"RC networks are a type of technology that use a reservoir of computations based on non-linear combinations of inputs."</data>
      <data key="d2">418f92b0dd08e03a20637ffec8193bfc</data>
    </node>
    <node id="&quot;MAASS ET AL.&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Maass et al. is an organization that contributed to the formulation of RC networks within the ML community."</data>
      <data key="d2">418f92b0dd08e03a20637ffec8193bfc</data>
    </node>
    <node id="&quot;BUONOMANO AND MERZENICH&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Buonomano and Merzenich is an organization that contributed to the concept of RC networks in the Neuroscience field."</data>
      <data key="d2">418f92b0dd08e03a20637ffec8193bfc</data>
    </node>
    <node id="&quot;DEEP LEARNING FRAMEWORKS&quot;">
      <data key="d0">"TECHNOLOGY"</data>
      <data key="d1">"Deep Learning frameworks are technologies that are commonly used to replicate RNN techniques."
"Deep Learning frameworks are mentioned as tools that can be used to easily replicate RNN techniques, but they are not commonly used for RC models."</data>
      <data key="d2">295606b4bc5d12929a913a3c79f93734,418f92b0dd08e03a20637ffec8193bfc</data>
    </node>
    <node id="&quot;LSTMS&quot;">
      <data key="d0">"TECHNOLOGY"</data>
      <data key="d1">"LSTMs are a type of technology that competes with state-of-the-art RNN methods like RNNs."</data>
      <data key="d2">418f92b0dd08e03a20637ffec8193bfc</data>
    </node>
    <node id="&quot;TROUVAIN AND HINAUT&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Trouvain and Hinaut are mentioned as the authors of a paper comparing methods, including RNN techniques like LSTMs, with RC models."</data>
      <data key="d2">295606b4bc5d12929a913a3c79f93734</data>
    </node>
    <node id="&quot;RNN TECHNIQUES&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"RNN techniques are mentioned as methods that can be easily replicated using popular Deep Learning frameworks, such as LSTMs."</data>
      <data key="d2">295606b4bc5d12929a913a3c79f93734</data>
    </node>
    <node id="&quot;RC MODELS&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"RC models are mentioned as methods that are often implemented from scratch due to a lack of common libraries, and they do not benefit from the automatic differentiation features of Deep Learning tools."
"RC models are constructed using Reservoir Computing methods, which can be implemented using nodes from the reservoirpy library or by creating new ones."</data>
      <data key="d2">295606b4bc5d12929a913a3c79f93734,d622f95153798af8bb6f485db54aaea3</data>
    </node>
    <node id="&quot;ML TECHNIQUES&quot;">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">295606b4bc5d12929a913a3c79f93734</data>
    </node>
    <node id="&quot;RECURRENT OPERATOR&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"A Recurrent Operator is a node that maps its internal state and input vector to the next state."</data>
      <data key="d2">dc46bcef51e88747b544f7efb111203a</data>
    </node>
    <node id="&quot;NODE&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"A Node is a recurrent operator that can carry parameters and has a defined function for mapping internal state and input vector to the next state."
"Node is a class in reservoirpy that represents a unit in a network, which can be used for high-level object-oriented API or defined as functions for custom training/inference policies."</data>
      <data key="d2">b03e2cc6fe2648e792c1d5f1ec5773a3,dc46bcef51e88747b544f7efb111203a</data>
    </node>
    <node id="&quot;LMS&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"LMS is a tool in reservoirpy that learns connections using Least Mean Square for a readout layer of neurons, allowing online learning."</data>
      <data key="d2">b03e2cc6fe2648e792c1d5f1ec5773a3</data>
    </node>
    <node id="&quot;RLS&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"RLS is a tool in reservoirpy that learns connections using Recursive Least Square for a readout layer of neurons, allowing online learning."</data>
      <data key="d2">b03e2cc6fe2648e792c1d5f1ec5773a3</data>
    </node>
    <node id="&quot;INTRINSIC PLASTICITY&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Intrinsic Plasticity is a mechanism in reservoirpy that allows for adaptive learning in reservoirs."</data>
      <data key="d2">b03e2cc6fe2648e792c1d5f1ec5773a3</data>
    </node>
    <node id="&quot;NON-LINEAR VECTOR AUTOREGRESSIVE MACHINE&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Non-Linear Vector Autoregressive machine is a recent reservoir reformulation in reservoirpy."</data>
      <data key="d2">b03e2cc6fe2648e792c1d5f1ec5773a3</data>
    </node>
    <node id="&quot;HOERZER ET AL. (2014)&quot;">
      <data key="d0">"EVENT"</data>
      <data key="d1">"Hoerzer et al. (2014) is a reference to a study that uses LMS for online learning."</data>
      <data key="d2">b03e2cc6fe2648e792c1d5f1ec5773a3</data>
    </node>
    <node id="&quot;SUSSILLO AND ABBOTT (2009)&quot;">
      <data key="d0">"EVENT"</data>
      <data key="d1">"Sussillo and Abbott (2009) is a reference to a study that uses RLS for online learning."</data>
      <data key="d2">b03e2cc6fe2648e792c1d5f1ec5773a3</data>
    </node>
    <node id="&quot;STEIL (2007)&quot;">
      <data key="d0">"EVENT"</data>
      <data key="d1">"Steil (2007) is a reference to a study that introduces the Intrinsic Plasticity mechanism for reservoirs."</data>
      <data key="d2">b03e2cc6fe2648e792c1d5f1ec5773a3</data>
    </node>
    <node id="&quot;SCHRAUWEN ET AL. (2008)&quot;">
      <data key="d0">"EVENT"</data>
      <data key="d1">"Schrauwen et al. (2008) is a reference to a study that further explores the Intrinsic Plasticity mechanism for reservoirs."</data>
      <data key="d2">b03e2cc6fe2648e792c1d5f1ec5773a3</data>
    </node>
    <node id="&quot;GAUTHIER ET AL. (202&quot;">
      <data key="d0">"EVENT"</data>
      <data key="d1">"Gauthier et al. (202) is a reference to a study that introduces the Non-Linear Vector Autoregressive machine."</data>
      <data key="d2">b03e2cc6fe2648e792c1d5f1ec5773a3</data>
    </node>
    <node id="&quot;SUSSILLO AND ABBOTT&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Sussillo and Abbott are mentioned in the context of the Recursive Least Square learning algorithm used in ReservoirPy."</data>
      <data key="d2">fcac967511cf2b019fd856e23d2e91d9</data>
    </node>
    <node id="&quot;SCHRAUWEN ET AL.&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Schrauwen et al. are mentioned as the authors of a reservoir reformulation used in ReservoirPy."</data>
      <data key="d2">fcac967511cf2b019fd856e23d2e91d9</data>
    </node>
    <node id="&quot;GAUTHIER ET AL.&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Gauthier et al. are mentioned as the authors of the Non-Linear Vector Autoregressive machine used in ReservoirPy."</data>
      <data key="d2">fcac967511cf2b019fd856e23d2e91d9</data>
    </node>
    <node id="&quot;PYRCN&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"PyRCN is a related open-source software mentioned for comparison with ReservoirPy."
"PyRCN is an open-source library that defines a complete interface to train Extreme Learning Machine (ELM), a network similar to ESN where recurrence has been removed."
"PyRCN is a software that defines a complete interface to train Extreme Learning Machine (ELM) and allows the design of complex models."</data>
      <data key="d2">15e969cdc81fd313d389558850d0c8ec,a1adb5de4156f0a4a448caf79056e886,fcac967511cf2b019fd856e23d2e91d9</data>
    </node>
    <node id="&quot;ECHOTORCH&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"EchoTorch is a related open-source software mentioned for comparison with ReservoirPy."
"EchoTorch is an open-source software that allows users to manipulate conceptors, a mechanism enabling to control the dynamics of reservoirs proposed by Jaeger (2014)."</data>
      <data key="d2">15e969cdc81fd313d389558850d0c8ec,fcac967511cf2b019fd856e23d2e91d9</data>
    </node>
    <node id="&quot;RESERVOIRCOMPUTING.JL&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"ReservoirComputing.jl is a related open-source software mentioned for comparison with ReservoirPy."
"ReservoirComputing.jl is an open-source library for reservoir computing in Julia, a high-level, high-performance dynamic programming language."
"ReservoirComputing.jl is a software mentioned in Table 1, which allows the design of complex models."
"ReservoirComputing.jl is a library mentioned in the text, likely used for reservoir computing tasks."
"ReservoirComputing.jl is an efficient Julia-based implementation of various types of echo state networks."</data>
      <data key="d2">15e969cdc81fd313d389558850d0c8ec,a1adb5de4156f0a4a448caf79056e886,a4b801e70cf2ba3a3101d34899450087,d7ac2f6fb13af389417785f2f3152c52,fcac967511cf2b019fd856e23d2e91d9</data>
    </node>
    <node id="&quot;PYTORCH-ES&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Pytorch-es is a related open-source software mentioned for comparison with ReservoirPy."</data>
      <data key="d2">fcac967511cf2b019fd856e23d2e91d9</data>
    </node>
    <node id="&quot;PYTORCH-ESN&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Pytorch-esn is an open-source library for Echo State Networks (ESNs) implemented in PyTorch, a popular machine learning library."</data>
      <data key="d2">15e969cdc81fd313d389558850d0c8ec</data>
    </node>
    <node id="&quot;DEEPESN&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"DeepESN is an open-source library for deep Echo State Networks (ESNs), a type of recurrent neural network."</data>
      <data key="d2">15e969cdc81fd313d389558850d0c8ec</data>
    </node>
    <node id="&quot;RCNET&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"RCNet is a library for reservoir computing, providing features such as online learning and delayed connections."</data>
      <data key="d2">15e969cdc81fd313d389558850d0c8ec</data>
    </node>
    <node id="&quot;LSM&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"LSM is an open-source library specializing in handling spiking neural networks."
"LSM is a software that specializes in handling spiking neural networks, mentioned in the context of PyRCN."</data>
      <data key="d2">15e969cdc81fd313d389558850d0c8ec,a1adb5de4156f0a4a448caf79056e886</data>
    </node>
    <node id="&quot;OGER&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Oger is a historical package for reservoir computing, no longer maintained."
"Oger is the publication source for the research paper on modular learning architectures for large-scale sequential processing."</data>
      <data key="d2">15e969cdc81fd313d389558850d0c8ec,b8d8b71875a9ccc508b40fe4aad8d796</data>
    </node>
    <node id="&quot;ELM&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"ELM is a network similar to ESN where recurrence has been removed, mentioned in the context of PyRCN."</data>
      <data key="d2">a1adb5de4156f0a4a448caf79056e886</data>
    </node>
    <node id="&quot;JAMES BERGSTRA&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"James Bergstra is a contributor to reservoirpy, known for his work on optimizing machine learning algorithms."
"James Bergstra is an author of Hyperopt, a python library for optimizing the hyperparameters of machine learning algorithms."</data>
      <data key="d2">82de30f43839f4985de20a981b524af1,a3a74dc4754a8c8b0730f808285893e2</data>
    </node>
    <node id="&quot;DAN YAMINS&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Dan Yamins is a contributor to reservoirpy, known for his work on optimizing machine learning algorithms."
"Dan Yamins is an author of Hyperopt, a python library for optimizing the hyperparameters of machine learning algorithms."</data>
      <data key="d2">82de30f43839f4985de20a981b524af1,a3a74dc4754a8c8b0730f808285893e2</data>
    </node>
    <node id="&quot;DAVID D COX&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"David D Cox is a contributor to reservoirpy, known for his work on optimizing machine learning algorithms."
"David D Cox is an author of Hyperopt, a python library for optimizing the hyperparameters of machine learning algorithms."</data>
      <data key="d2">82de30f43839f4985de20a981b524af1,a3a74dc4754a8c8b0730f808285893e2</data>
    </node>
    <node id="&quot;PROCEED&quot;">
      <data key="d0">"EVENT"</data>
      <data key="d1">"Proceed is an event mentioned in the text, likely a conference or publication, where the Hyperopt library is presented."</data>
      <data key="d2">a3a74dc4754a8c8b0730f808285893e2</data>
    </node>
    <node id="&quot;LARS BUITINCK&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Lars Buitinck is an author of a paper on API design for machine learning software, highlighting experiences from the scikit-learn project."</data>
      <data key="d2">82de30f43839f4985de20a981b524af1</data>
    </node>
    <node id="&quot;DV BUONOMANO&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"DV Buonomano is an author of a scientific paper on temporal information transformation into a spatial code by a neural network."
"DV Buonomano is an author of a scientific paper on transforming temporal information into a spatial code using a neural network."</data>
      <data key="d2">82de30f43839f4985de20a981b524af1,ce7b58ffc7f43f36bc78154597d01903</data>
    </node>
    <node id="&quot;M. M. MERZENICH&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"M. M. Merzenich is an author of a scientific paper on temporal information transformation into a spatial code by a neural network."
"M. M. Merzenich is a co-author of a scientific paper on transforming temporal information into a spatial code using a neural network."</data>
      <data key="d2">82de30f43839f4985de20a981b524af1,ce7b58ffc7f43f36bc78154597d01903</data>
    </node>
    <node id="&quot;P. DOMINEY&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"P. Dominey is an author of a scientific paper on complex sensory-motor systems."
"P. Dominey is an author of a scientific paper on complex sensory-motor sequence learning based on recurrent state representation and reinforcement learning."</data>
      <data key="d2">82de30f43839f4985de20a981b524af1,ce7b58ffc7f43f36bc78154597d01903</data>
    </node>
    <node id="&quot;API DESIGN FOR MACHINE LEARNING SOFTWARE&quot;">
      <data key="d0">"EVENT"</data>
      <data key="d1">"API Design for Machine Learning Software is a paper that highlights experiences from the scikit-learn project, authored by Lars Buitinck and others."</data>
      <data key="d2">82de30f43839f4985de20a981b524af1</data>
    </node>
    <node id="&quot;TEMPORAL INFORMATION TRANSFORMATION&quot;">
      <data key="d0">"EVENT"</data>
      <data key="d1">"Temporal Information Transformation is a scientific concept explored in a paper authored by DV Buonomano and M. M. Merzenich."</data>
      <data key="d2">82de30f43839f4985de20a981b524af1</data>
    </node>
    <node id="&quot;COMPLEX SENSORY-MOTOR SYSTEMS&quot;">
      <data key="d0">"EVENT"</data>
      <data key="d1">"Complex Sensory-Motor Systems is a scientific concept explored in a paper authored by P. Dominey."</data>
      <data key="d2">82de30f43839f4985de20a981b524af1</data>
    </node>
    <node id="&quot;C. GALLICCHIO&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"C. Gallicchio is an author of a scientific paper on designing deep echo state networks."</data>
      <data key="d2">ce7b58ffc7f43f36bc78154597d01903</data>
    </node>
    <node id="&quot;A. MICHELI&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"A. Micheli is a co-author of a scientific paper on designing deep echo state networks."</data>
      <data key="d2">ce7b58ffc7f43f36bc78154597d01903</data>
    </node>
    <node id="&quot;L. PEDRELLI&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"L. Pedrelli is a co-author of a scientific paper on designing deep echo state networks."</data>
      <data key="d2">ce7b58ffc7f43f36bc78154597d01903</data>
    </node>
    <node id="&quot;SEPP HOCHREITER&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Sepp Hochreiter is an author of a scientific paper on long short-term memory."
"Sepp Hochreiter is an author of a research paper on long short-term memory."</data>
      <data key="d2">c8b7bd13cf99920ecce56cb563910cb3,ce7b58ffc7f43f36bc78154597d01903</data>
    </node>
    <node id="&quot;J&#220;RGEN SCHMIDHUBER&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"J&#252;rgen Schmidhuber is a co-author of a scientific paper on long short-term memory."
"J&#252;rgen Schmidhuber is an author of a research paper on long short-term memory."</data>
      <data key="d2">c8b7bd13cf99920ecce56cb563910cb3,ce7b58ffc7f43f36bc78154597d01903</data>
    </node>
    <node id="&quot;DANIEL J. GAUTHIER&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Daniel J. Gauthier is an author of a scientific paper on next generation reservoir computing."</data>
      <data key="d2">ce7b58ffc7f43f36bc78154597d01903</data>
    </node>
    <node id="&quot;ERIK BOLLT&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Erik Bollt is a co-author of a scientific paper on next generation reservoir computing."</data>
      <data key="d2">ce7b58ffc7f43f36bc78154597d01903</data>
    </node>
    <node id="&quot;AARON GRIFFITH&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Aaron Griffith is a co-author of a scientific paper on next generation reservoir computing."</data>
      <data key="d2">ce7b58ffc7f43f36bc78154597d01903</data>
    </node>
    <node id="&quot;WENDSON A. S. BARBOSA&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Wendson A. S. Barbosa is a co-author of a scientific paper on next generation reservoir computing."</data>
      <data key="d2">ce7b58ffc7f43f36bc78154597d01903</data>
    </node>
    <node id="&quot;GREGOR M. HOERZER&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Gregor M. Hoerzer is an author of a scientific paper on a specific topic, but the relationship description and strength are not explicitly stated in the text."
"Gregor M. Hoerzer is an author of a research paper on emergence of complex computational structures from chaotic neural networks."</data>
      <data key="d2">c8b7bd13cf99920ecce56cb563910cb3,ce7b58ffc7f43f36bc78154597d01903</data>
    </node>
    <node id="&quot;ROBERT LEGENSTEIN&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Robert Legenstein is a co-author of a scientific paper on a specific topic, but the relationship description and strength are not explicitly stated in the text."
"Robert Legenstein is an author of a research paper on emergence of complex computational structures from chaotic neural networks."</data>
      <data key="d2">c8b7bd13cf99920ecce56cb563910cb3,ce7b58ffc7f43f36bc78154597d01903</data>
    </node>
    <node id="&quot;S. BARBOSA&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"S. Barbosa is an author of a research paper on next generation reservoir computing."</data>
      <data key="d2">c8b7bd13cf99920ecce56cb563910cb3</data>
    </node>
    <node id="&quot;GUANG-BIN HUANG&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Guang-Bin Huang is an author of a research paper on extreme learning machines."</data>
      <data key="d2">c8b7bd13cf99920ecce56cb563910cb3</data>
    </node>
    <node id="&quot;DIAN HUI WANG&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Dian Hui Wang is an author of a research paper on extreme learning machines."</data>
      <data key="d2">c8b7bd13cf99920ecce56cb563910cb3</data>
    </node>
    <node id="&quot;YUAN LAN&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Yuan Lan is an author of a research paper on extreme learning machines."</data>
      <data key="d2">c8b7bd13cf99920ecce56cb563910cb3</data>
    </node>
    <node id="&quot;HINAUT H. TROUVAIN&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Hinaut H. Trouvain is an author of a research paper on the echo state approach to analyzing and training recurrent neural networks."</data>
      <data key="d2">c8b7bd13cf99920ecce56cb563910cb3</data>
    </node>
    <node id="&quot;JACQUES KAISER&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Jacques Kaiser is an author of a research paper mentioned in the text."
"Jacques Kaiser is a researcher who published a paper on scaling up liquid state machines to predict over address events from dynamic vision sensors."</data>
      <data key="d2">546551fd625e354e9afe1245e060bed3,c8b7bd13cf99920ecce56cb563910cb3</data>
    </node>
    <node id="&quot;RAINER STAL&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Rainer Stal is an author of a research paper mentioned in the text."
"Rainer Stal is a researcher who published a paper on scaling up liquid state machines."</data>
      <data key="d2">546551fd625e354e9afe1245e060bed3,c8b7bd13cf99920ecce56cb563910cb3</data>
    </node>
    <node id="&quot;NEURAL COMPUTATION&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Neural Computation is a journal where a research paper on long short-term memory was published."</data>
      <data key="d2">c8b7bd13cf99920ecce56cb563910cb3</data>
    </node>
    <node id="&quot;GMD TECH. REPORT&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"GMD Tech. Report is a research report published by the German National Research Center for Information Technology."</data>
      <data key="d2">c8b7bd13cf99920ecce56cb563910cb3</data>
    </node>
    <node id="&quot;CORR&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"CoRR is a research archive where a paper on controlling recurrent neural networks by conceptors is published."</data>
      <data key="d2">c8b7bd13cf99920ecce56cb563910cb3</data>
    </node>
    <node id="&quot;INT. J. MACH. LEARN. &amp; CYBER.&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Int. J. Mach. Learn. &amp; Cyber. is a journal where a research paper on extreme learning machines is published."</data>
      <data key="d2">c8b7bd13cf99920ecce56cb563910cb3</data>
    </node>
    <node id="&quot;GERMAN NATIONAL RESEARCH CENTER FOR INFORMATION TECHNOLOGY GMD&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"GMD is a German research center that published a report on the 'echo state' approach for training recurrent neural networks."</data>
      <data key="d2">546551fd625e354e9afe1245e060bed3</data>
    </node>
    <node id="&quot;ANAND SUBRAMONEY&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Anand Subramoney is a researcher who published a paper on scaling up liquid state machines."</data>
      <data key="d2">546551fd625e354e9afe1245e060bed3</data>
    </node>
    <node id="&quot;ARNE ROENNAU&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Arne Roennau is a researcher who published a paper on scaling up liquid state machines."</data>
      <data key="d2">546551fd625e354e9afe1245e060bed3</data>
    </node>
    <node id="&quot;R&#220;DIGER DILL-MANN&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"R&#252;diger Dill-mann is a researcher who published a paper on scaling up liquid state machines."</data>
      <data key="d2">546551fd625e354e9afe1245e060bed3</data>
    </node>
    <node id="&quot;W. MAASS&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"W. Maass is a researcher who published a paper on real-time computing without stable states: A new framework for neural computation based on perturbations."</data>
      <data key="d2">546551fd625e354e9afe1245e060bed3</data>
    </node>
    <node id="&quot;T. NATSCHL&#168;AGER&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"T. Natschl&#168;ager is a researcher who published a paper on real-time computing without stable states."</data>
      <data key="d2">546551fd625e354e9afe1245e060bed3</data>
    </node>
    <node id="&quot;H. MARKRAM&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"H. Markram is a researcher who published a paper on real-time computing without stable states."</data>
      <data key="d2">546551fd625e354e9afe1245e060bed3</data>
    </node>
    <node id="&quot;FRANCESCO MARTINUZZI&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Francesco Martinuzzi is a researcher who published a paper on reservoircomputing.jl:"</data>
      <data key="d2">546551fd625e354e9afe1245e060bed3</data>
    </node>
    <node id="&quot;CHRIS RACKAUCKAS&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Chris Rackauckas is a researcher who published a paper on reservoircomputing.jl:"</data>
      <data key="d2">546551fd625e354e9afe1245e060bed3</data>
    </node>
    <node id="&quot;ANAS ABDELREHIM&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Anas Abdelrehim is a researcher who published a paper on reservoircomputing.jl:"</data>
      <data key="d2">546551fd625e354e9afe1245e060bed3</data>
    </node>
    <node id="&quot;MIGUEL D. MAHECHA&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Miguel D. Mahecha is a researcher who published a paper on reservoircomputing.jl:"</data>
      <data key="d2">546551fd625e354e9afe1245e060bed3</data>
    </node>
    <node id="&quot;KARIN MORA&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Karin Mora is a researcher who published a paper on reservoircomputing.jl:"</data>
      <data key="d2">546551fd625e354e9afe1245e060bed3</data>
    </node>
    <node id="&quot;BONN, GERMANY&quot;">
      <data key="d0">"GEO"</data>
      <data key="d1">"Bonn, Germany is the location where German National Research Center for Information Technology GMD is based."</data>
      <data key="d2">546551fd625e354e9afe1245e060bed3</data>
    </node>
    <node id="&quot;GMD TECH. REPORT, 148:34, 2001&quot;">
      <data key="d0">"EVENT"</data>
      <data key="d1">"GMD Tech. Report, 148:34, 2001 is a report published by German National Research Center for Information Technology GMD on the 'echo state' approach for training recurrent neural networks."</data>
      <data key="d2">546551fd625e354e9afe1245e060bed3</data>
    </node>
    <node id="&quot;CORR, ABS/1403.3369, 2014&quot;">
      <data key="d0">"EVENT"</data>
      <data key="d1">"CoRR, abs/1403.3369, 2014 is a paper published by Herbert Jaeger on controlling recurrent neural networks by conceptors."</data>
      <data key="d2">546551fd625e354e9afe1245e060bed3</data>
    </node>
    <node id="&quot;BIOINSPIRATION &amp; BIOMIMETICS, 12(5):055001, SEP 2017&quot;">
      <data key="d0">"EVENT"</data>
      <data key="d1">"Bioinspiration &amp; Biomimetics, 12(5):055001, sep 2017 is a paper published by Jacques Kaiser and others on scaling up liquid state machines to predict over address events from dynamic vision sensors."</data>
      <data key="d2">546551fd625e354e9afe1245e060bed3</data>
    </node>
    <node id="&quot;NEURAL COMPUTATION, 14(11):2531&#8211;2560, 2002&quot;">
      <data key="d0">"EVENT"</data>
      <data key="d1">"Neural computation, 14(11):2531&#8211;2560, 2002 is a paper published by W. Maass and others on real-time computing without stable states: A new framework for neural computation based on perturbations."</data>
      <data key="d2">546551fd625e354e9afe1245e060bed3</data>
    </node>
    <node id="&quot;W. MAASS, T. NATSCHL&#168;AGER, AND H. MARKRAM&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"This entity is a group of authors who contributed to a research paper on real-time computing without stable states."</data>
      <data key="d2">ea62f994886333282704a19ebf0469ea</data>
    </node>
    <node id="&quot;FRANCESCO MARTINUZZI, CHRIS RACKAUCKAS, ANAS ABDELREHIM, MIGUEL D. MAHECHA, AND KARIN MORA&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"This entity is a group of authors who developed a library for reservoir computing models, published in 2022."</data>
      <data key="d2">ea62f994886333282704a19ebf0469ea</data>
    </node>
    <node id="&quot;NILS SCHAETTI&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Nils Schaetti is the developer of Echotorch, a reservoir computing library with pytorch, published in 2018."</data>
      <data key="d2">ea62f994886333282704a19ebf0469ea</data>
    </node>
    <node id="&quot;BENJAMIN SCHRAUWEN, MARION WARDERMANN, DAVID VERSTRAETEN, JOCHEN J. STEIL, AND DIRK STROOBANDT&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"This entity is a group of authors who published a research paper on improving reservoirs using intrinsic plasticity in 2008."</data>
      <data key="d2">ea62f994886333282704a19ebf0469ea</data>
    </node>
    <node id="&quot;JOCHEN J STEIL&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Jochen J Steil is an author who published a research paper on online reservoir adaptation by intrinsic plasticity for backpropagation&#8211;decorrelation and echo state learning in 2007."
"Jochen J Steil is an author of a research paper on online reservoir adaptation using intrinsic plasticity."</data>
      <data key="d2">7751d435f46a6d4027a1c96edabb9626,ea62f994886333282704a19ebf0469ea</data>
    </node>
    <node id="&quot;PETER STEINER, AZARAKHSH JALALVAND, SIMON STONE, AND PETER BIRKHOLZ&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"This entity is a group of authors who developed Pyrcn, a toolbox for exploration and analysis of reservoir computing models."</data>
      <data key="d2">ea62f994886333282704a19ebf0469ea</data>
    </node>
    <node id="&quot;REAL-TIME COMPUTING WITHOUT STABLE STATES PAPER&quot;">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">ea62f994886333282704a19ebf0469ea</data>
    </node>
    <node id="&quot;RESERVOIRCOMPUTING.JL LIBRARY&quot;">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">ea62f994886333282704a19ebf0469ea</data>
    </node>
    <node id="&quot;ECHOTORCH LIBRARY&quot;">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">ea62f994886333282704a19ebf0469ea</data>
    </node>
    <node id="&quot;IMPROVING RESERVOIRS PAPER&quot;">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">ea62f994886333282704a19ebf0469ea</data>
    </node>
    <node id="&quot;ONLINE RESERVOIR ADAPTATION PAPER&quot;">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">ea62f994886333282704a19ebf0469ea</data>
    </node>
    <node id="&quot;PYRCN TOOLBOX&quot;">
      <data key="d0" />
      <data key="d1">
"Pyrcn Toolbox is a toolbox for exploration and application of reservoir computing networks, developed by a group of authors."</data>
      <data key="d2">7751d435f46a6d4027a1c96edabb9626,ea62f994886333282704a19ebf0469ea</data>
    </node>
    <node id="&quot;PETER STEINER&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Peter Steiner is an author of a toolbox for exploration and application of reservoir computing networks."</data>
      <data key="d2">7751d435f46a6d4027a1c96edabb9626</data>
    </node>
    <node id="&quot;AZARAKHSH JALALVAND&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Azarakhsh Jalalvand is an author of a toolbox for exploration and application of reservoir computing networks."</data>
      <data key="d2">7751d435f46a6d4027a1c96edabb9626</data>
    </node>
    <node id="&quot;SIMON STONE&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Simon Stone is an author of a toolbox for exploration and application of reservoir computing networks."</data>
      <data key="d2">7751d435f46a6d4027a1c96edabb9626</data>
    </node>
    <node id="&quot;PETER BIRKHOLZ&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Peter Birkholz is an author of a toolbox for exploration and application of reservoir computing networks."</data>
      <data key="d2">7751d435f46a6d4027a1c96edabb9626</data>
    </node>
    <node id="&quot;DAVID SUSSILLO&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"David Sussillo is an author of a research paper on generating coherent patterns of activity from chaotic neural networks."</data>
      <data key="d2">7751d435f46a6d4027a1c96edabb9626</data>
    </node>
    <node id="&quot;L. F. ABBOTT&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"L. F. Abbott is an author of a research paper on generating coherent patterns of activity from chaotic neural networks."</data>
      <data key="d2">7751d435f46a6d4027a1c96edabb9626</data>
    </node>
    <node id="&quot;DAVID VERSTRAETEN&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"David Verstraeten is an author of a research paper on oger: modular learning architectures for large-scale sequential processing."</data>
      <data key="d2">7751d435f46a6d4027a1c96edabb9626</data>
    </node>
    <node id="&quot;BENJAMIN SCHRAUWEN&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Benjamin Schrauwen is an author of a research paper on oger: modular learning architectures for large-scale sequential processing."</data>
      <data key="d2">7751d435f46a6d4027a1c96edabb9626</data>
    </node>
    <node id="&quot;SANDER DIELEMAN&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Sander Dieleman is an author of a research paper on oger: modular learning architectures for large-scale sequential processing."</data>
      <data key="d2">7751d435f46a6d4027a1c96edabb9626</data>
    </node>
    <node id="&quot;PHILEMON BRAKEL&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Philemon Brakel is an author of a research paper on oger: modular learning architectures for large-scale sequential processing."</data>
      <data key="d2">7751d435f46a6d4027a1c96edabb9626</data>
    </node>
    <node id="&quot;PIETER BUTENEERS&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Pieter Buteneers is an author of a research paper on oger: modular learning architectures for large-scale sequential processing."</data>
      <data key="d2">7751d435f46a6d4027a1c96edabb9626</data>
    </node>
    <node id="&quot;DEJAN PECEVSKI&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Dejan Pecevski is an author of a research paper on oger: modular learning architectures for large-scale sequential processing."</data>
      <data key="d2">7751d435f46a6d4027a1c96edabb9626</data>
    </node>
    <node id="&quot;COHERENT PATTERNS RESEARCH&quot;">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">7751d435f46a6d4027a1c96edabb9626</data>
    </node>
    <node id="&quot;CANARY SONG DECODER RESEARCH&quot;">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">7751d435f46a6d4027a1c96edabb9626</data>
    </node>
    <node id="&quot;OGER RESEARCH&quot;">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">7751d435f46a6d4027a1c96edabb9626</data>
    </node>
    <node id="&quot;VERSTRAETEN, BENJAMIN&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Verstraeten, Benjamin is an author of a research paper on modular learning architectures for large-scale sequential processing."</data>
      <data key="d2">b8d8b71875a9ccc508b40fe4aad8d796</data>
    </node>
    <node id="&quot;SCHRAUWEN, SANDER&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Schrauwen, Sander is an author of a research paper on modular learning architectures for large-scale sequential processing."</data>
      <data key="d2">b8d8b71875a9ccc508b40fe4aad8d796</data>
    </node>
    <node id="&quot;DIELEMAN, PHILEMON&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Dieleman, Philemon is an author of a research paper on modular learning architectures for large-scale sequential processing."</data>
      <data key="d2">b8d8b71875a9ccc508b40fe4aad8d796</data>
    </node>
    <node id="&quot;BRAKEL, PIETER&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Brakel, Pieter is an author of a research paper on modular learning architectures for large-scale sequential processing."</data>
      <data key="d2">b8d8b71875a9ccc508b40fe4aad8d796</data>
    </node>
    <node id="&quot;BUTE-NEERS, AND DEJAN PECEVSKI&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Bute-neers, and Dejan Pecevski are additional authors of a research paper on modular learning architectures for large-scale sequential processing."</data>
      <data key="d2">b8d8b71875a9ccc508b40fe4aad8d796</data>
    </node>
    <node id="&quot;THE JOURNAL OF MACHINE LEARNING RESEARCH&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"The Journal of Machine Learning Research is the publication source for the research paper on modular learning architectures for large-scale sequential processing."</data>
      <data key="d2">b8d8b71875a9ccc508b40fe4aad8d796</data>
    </node>
    <node id="&quot;MODULAR LEARNING ARCHITECTURES FOR LARGE-SCALE SEQUENTIAL PROCESSING&quot;">
      <data key="d0">"EVENT"</data>
      <data key="d1">"Modular Learning Architectures for Large-Scale Sequential Processing is the title of a research paper published in The Journal of Machine Learning Research."</data>
      <data key="d2">b8d8b71875a9ccc508b40fe4aad8d796</data>
    </node>
    <node id="&quot;DIRECTED ACYCLIC GRAPH&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Directed Acyclic Graph is a type of graph with no cycles, used in the context of neural networks."</data>
      <data key="d2">f59839daadfb1f3832bb9f8d201a7126</data>
    </node>
    <node id="&quot;STRICTLY FEEDFORWARD NEURAL NETWORK&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Strictly Feedforward Neural Network is a type of neural network that processes information in a single direction, without loops."</data>
      <data key="d2">f59839daadfb1f3832bb9f8d201a7126</data>
    </node>
    <node id="&quot;INFINITE IMPULSE RECURRENT NETWORK&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Infinite Impulse Recurrent Network is a type of neural network with a directed cyclic graph structure, which cannot be unrolled."</data>
      <data key="d2">f59839daadfb1f3832bb9f8d201a7126</data>
    </node>
    <node id="&quot;FINITE IMPULSE NETWORK&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Finite Impulse Network is a type of neural network that may include additional stored states and controlled states."</data>
      <data key="d2">f59839daadfb1f3832bb9f8d201a7126</data>
    </node>
    <node id="&quot;FEEDBACK NEURAL NETWORK&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Feedback Neural Network is a type of neural network that incorporates feedback loops or controlled states, such as Long Short-Term Memory networks and Gated Recurrent Units."</data>
      <data key="d2">f59839daadfb1f3832bb9f8d201a7126</data>
    </node>
    <node id="&quot;ISING MODEL&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Ising Model is a recurrent neural network architecture developed by Wilhelm Lenz and Ernst Ising in 1925, which was later made adaptive by Shun&#8217;ichi Amari in 1972."</data>
      <data key="d2">f59839daadfb1f3832bb9f8d201a7126</data>
    </node>
    <node id="&quot;DAVID RUMELHART&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"David Rumelhart is a researcher who made significant contributions to the development of recurrent neural networks in 1986."
"David Rumelhart is a person who contributed to the development of neural networks in 1986."</data>
      <data key="d2">b31ca51b419f7270ee5f4910c90ea331,f59839daadfb1f3832bb9f8d201a7126</data>
    </node>
    <node id="&quot;NEURAL HISTORY COMPRESSOR SYSTEM&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Neural History Compressor System is a system that used a recurrent neural network to solve a 'Very Deep Learning' task in 1993, requiring more than 1000 subsequent layers."</data>
      <data key="d2">f59839daadfb1f3832bb9f8d201a7126</data>
    </node>
    <node id="&quot;LONG SHORT-TERM MEMORY&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Long Short-Term Memory is a type of recurrent neural network that addresses the vanishing gradient problem and is used to store and process information over long sequences."
"Long Short-Term Memory is an example of second-order RNNs that uses higher order weights and states, allowing for a direct mapping to a finite-state machine."
"Long Short-Term Memory is a type of Recurrent Neural Network that uses a mechanism to retain information over long sequences."</data>
      <data key="d2">2bdd28d9e151597072c8490db69b9941,b888c4ebe914c1dfa26682de69de9de9,f59839daadfb1f3832bb9f8d201a7126</data>
    </node>
    <node id="&quot;GATED RECURRENT UNITS&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Gated Recurrent Units is a type of recurrent neural network that uses gated states to control the flow of information, similar to Long Short-Term Memory networks."</data>
      <data key="d2">f59839daadfb1f3832bb9f8d201a7126</data>
    </node>
    <node id="&quot;SHUN&#8217;ICHI AMARI&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Shun&#8217;ichi Amari is a person who made a neural network adaptive in 1972."</data>
      <data key="d2">b31ca51b419f7270ee5f4910c90ea331</data>
    </node>
    <node id="&quot;HOCHREITER AND SCHMIDHUBER&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Hochreiter and Schmidhuber are a team of researchers who invented Long Short-Term Memory (LSTM) networks in 1997."</data>
      <data key="d2">b31ca51b419f7270ee5f4910c90ea331</data>
    </node>
    <node id="&quot;LSTM&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Long Short-Term Memory (LSTM) networks are a type of neural network invented by Hochreiter and Schmidhuber in 1997."
"LSTM stands for Long Short-Term Memory, a type of RNN used by Google in their machine learning models."
"LSTM is a type of recurrent neural network (RNN) that can handle long delays between significant events and mix low and high-frequency components."
"LSTM is an abbreviation for Long Short-Term Memory, a type of Recurrent Neural Network that uses a mechanism to retain information over long sequences."
"LSTM is a variant of RNN that addresses the vanishing gradients problem by using a gating mechanism to selectively forget or remember information."
"LSTM is a type of recurrent neural network (RNN) that attempts to overcome problems such as the vanishing gradient problem."
"LSTM is a type of recurrent neural network architecture that addresses the vanishing gradient problem."
"LSTM is a type of recurrent neural network architecture that addresses some of the issues found in traditional RNNs."</data>
      <data key="d2">10112a11d47463e2aad7352c52922d61,1aec5b03f663d1614b2ecbf97981a5c2,2bdd28d9e151597072c8490db69b9941,486e4b71bf02f756450ab727db88f821,4b89d9404fd683ecd03d5846ee2d86ce,88405de18768775d8bce062ea467bd7f,b31ca51b419f7270ee5f4910c90ea331,b48d5212c060453a846e21cdb98dbd7d</data>
    </node>
    <node id="&quot;BAIDU&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Baidu is a Chinese company that used CTC-trained RNNs to break the 2S09 Switchboard Hub5&#8217;00 speech recognition dataset in 2014."
"Baidu is a Chinese company that used CTC-trained RNNs to improve speech recognition performance."</data>
      <data key="d2">486e4b71bf02f756450ab727db88f821,b31ca51b419f7270ee5f4910c90ea331</data>
    </node>
    <node id="&quot;GOOGLE&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Google is a company that used LSTM networks in its speech recognition and Android systems."
"Google is a company that used CTC-trained LSTM for speech recognition and improved machine translation, language modeling, and multilingual language processing."</data>
      <data key="d2">486e4b71bf02f756450ab727db88f821,b31ca51b419f7270ee5f4910c90ea331</data>
    </node>
    <node id="&quot;CTC-TRAINED RNNS&quot;">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">b31ca51b419f7270ee5f4910c90ea331</data>
    </node>
    <node id="&quot;2S09 SWITCHBOARD HUB5&#8217;00&quot;">
      <data key="d0">"EVENT"</data>
      <data key="d1">"2S09 Switchboard Hub5&#8217;00 is a speech recognition dataset that Baidu used to break a benchmark."</data>
      <data key="d2">486e4b71bf02f756450ab727db88f821</data>
    </node>
    <node id="&quot;CTC&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"CTC stands for Connectionist Temporal Classification, a method used by Baidu and Google in their machine learning models."

"CTC is a training method used for recurrent neural networks (RNNs) that achieves both alignment and recognition."</data>
      <data key="d2">4470a7f7ad60a2866b31907a2a3ca96e,486e4b71bf02f756450ab727db88f821,b48d5212c060453a846e21cdb98dbd7d</data>
    </node>
    <node id="&quot;CNN&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"CNN stands for Convolutional Neural Network, a type of neural network used in combination with LSTM for automatic image captioning."</data>
      <data key="d2">486e4b71bf02f756450ab727db88f821</data>
    </node>
    <node id="&quot;ELMAN NETWORKS&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Elman Networks are a type of neural network with additional context units, allowing them to maintain a sort of state and perform tasks such as sequence prediction."</data>
      <data key="d2">bf4dccb5096a917a6a71f0cc224e4d7c</data>
    </node>
    <node id="&quot;JORDAN NETWORKS&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Jordan Networks are a type of neural network mentioned in the text, but no further details are provided about their characteristics or functions."</data>
      <data key="d2">bf4dccb5096a917a6a71f0cc224e4d7c</data>
    </node>
    <node id="&quot;HIDDEN LAYER&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Hidden Layer refers to the intermediate layer of neurons in a neural network that processes the input data."</data>
      <data key="d2">bf4dccb5096a917a6a71f0cc224e4d7c</data>
    </node>
    <node id="&quot;CONTEXT UNITS&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Context Units are a set of neurons in an Elman Network that save a copy of the previous values of the hidden units, allowing the network to maintain a sort of state."</data>
      <data key="d2">bf4dccb5096a917a6a71f0cc224e4d7c</data>
    </node>
    <node id="&quot;SEQUENCE PREDICTION&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Sequence Prediction is a task that neural networks, such as Elman Networks, can perform by maintaining a sort of state."</data>
      <data key="d2">bf4dccb5096a917a6a71f0cc224e4d7c</data>
    </node>
    <node id="&quot;ELMAN NETWORK&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Elman Network is a type of recurrent neural network that uses context units to maintain a sort of state, allowing it to perform tasks such as sequence-prediction."</data>
      <data key="d2">fb7999a4b39733c28630293d3659d7eb</data>
    </node>
    <node id="&quot;JORDAN NETWORK&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Jordan Network is a type of recurrent neural network that uses context units, also known as the state layer, which have a recurrent connection to themselves."
"Jordan Network is a type of recurrent neural network (RNN) that uses a specific structure and training method."</data>
      <data key="d2">8b12ccb4afc119b3357ceff10e04ce9f,fb7999a4b39733c28630293d3659d7eb</data>
    </node>
    <node id="&quot;GEOFFREY HINTON&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Geoffrey Hinton is not explicitly mentioned in the text, but he is a well-known figure in the field of neural networks and is often associated with the development of recurrent neural networks."</data>
      <data key="d2">fb7999a4b39733c28630293d3659d7eb</data>
    </node>
    <node id="&quot;JEFF ELMAN&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Jeff Elman is the inventor of Elman Networks, a type of recurrent neural network that uses context units to maintain a sort of state."</data>
      <data key="d2">fb7999a4b39733c28630293d3659d7eb</data>
    </node>
    <node id="&quot;SIMPLE RECURRENT NETWORKS&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Simple Recurrent Networks is a term used to refer to both Elman Networks and Jordan Networks, as they are similar in structure and function."</data>
      <data key="d2">fb7999a4b39733c28630293d3659d7eb</data>
    </node>
    <node id="&quot;XT&quot;">
      <data key="d0">"VARIABLE"</data>
      <data key="d1">"xt is a variable used in the equations of the Jordan Network and Hopfield Network."</data>
      <data key="d2">8b12ccb4afc119b3357ceff10e04ce9f</data>
    </node>
    <node id="&quot;HT&quot;">
      <data key="d0">"VARIABLE"</data>
      <data key="d1">"ht is a variable used in the equations of the Jordan Network and Hopfield Network."</data>
      <data key="d2">8b12ccb4afc119b3357ceff10e04ce9f</data>
    </node>
    <node id="&quot;YT&quot;">
      <data key="d0">"VARIABLE"</data>
      <data key="d1">"yt is a variable used in the equations of the Jordan Network and Hopfield Network."</data>
      <data key="d2">8b12ccb4afc119b3357ceff10e04ce9f</data>
    </node>
    <node id="&quot;WW&quot;">
      <data key="d0">"VARIABLE"</data>
      <data key="d1">"WW is a variable used in the equations of the Jordan Network and Hopfield Network."</data>
      <data key="d2">8b12ccb4afc119b3357ceff10e04ce9f</data>
    </node>
    <node id="&quot;UU&quot;">
      <data key="d0">"VARIABLE"</data>
      <data key="d1">"UU is a variable used in the equations of the Jordan Network and Hopfield Network."</data>
      <data key="d2">8b12ccb4afc119b3357ceff10e04ce9f</data>
    </node>
    <node id="&quot;BB&quot;">
      <data key="d0">"VARIABLE"</data>
      <data key="d1">"bb is a variable used in the equations of the Jordan Network and Hopfield Network."</data>
      <data key="d2">8b12ccb4afc119b3357ceff10e04ce9f</data>
    </node>
    <node id="&quot;&#931;H&quot;">
      <data key="d0">"FUNCTION"</data>
      <data key="d1">"&#963;h is a function used in the equations of the Jordan Network and Hopfield Network."</data>
      <data key="d2">8b12ccb4afc119b3357ceff10e04ce9f</data>
    </node>
    <node id="&quot;&#931;Y&quot;">
      <data key="d0">"FUNCTION"</data>
      <data key="d1">"&#963;y is a function used in the equations of the Jordan Network and Hopfield Network."</data>
      <data key="d2">8b12ccb4afc119b3357ceff10e04ce9f</data>
    </node>
    <node id="&quot;BIDIRECTIONAL ASSOCIATIVE MEMORY (BAM) NETWORK&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"BAM Network is a variant of Hopfield Network that stores associative data as a vector, allowing for bi-directional information flow."</data>
      <data key="d2">a8c0edd2cdddb7d6d899284063b541f5</data>
    </node>
    <node id="&quot;BART KOSKO&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Bart Kosko is the author of the Bidirectional Associative Memory (BAM) Network."</data>
      <data key="d2">a8c0edd2cdddb7d6d899284063b541f5</data>
    </node>
    <node id="&quot;RECENTLY&quot;">
      <data key="d0">"EVENT"</data>
      <data key="d1">"Recently refers to a time period when stochastic BAM models using Markov stepping were optimized for increased network stability and relevance to real-world applications."</data>
      <data key="d2">a8c0edd2cdddb7d6d899284063b541f5</data>
    </node>
    <node id="&quot;BAM NETWORK&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"BAM Network is a type of neural network with two layers that can be driven as inputs to recall an association and produce an output on the other layer."</data>
      <data key="d2">423cdb622c47fa8cec25f22eb9f9f01f</data>
    </node>
    <node id="&quot;INDEPENDENTLY RECURRENT NEURAL NETWORK&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Independently Recurrent Neural Network is a type of neural network that addresses the gradient vanishing and exploding problems in the traditional fully connected RNN."</data>
      <data key="d2">423cdb622c47fa8cec25f22eb9f9f01f</data>
    </node>
    <node id="&quot;RECURSIVE NEURAL NETWORK&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Recursive Neural Network is a type of neural network created by applying the same set of weights recursively over a differentiable graph-like structure by traversing."
"Recursive Neural Network is a type of neural network that applies the same set of weights recursively over a differentiable graph-like structure."</data>
      <data key="d2">423cdb622c47fa8cec25f22eb9f9f01f,7b6ff30ef255db2d2c68326d78cf0115</data>
    </node>
    <node id="&quot;NEURAL HISTORY COMPRESSOR&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Neural History Compressor is an unsupervised stack of RNNs that learns to predict its next input from the previous inputs and compresses information for higher-level RNNs."
"The Neural History Compressor is a system composed of unsupervised RNNs that learns to predict and compress inputs, effectively minimizing the description length of data."</data>
      <data key="d2">7b6ff30ef255db2d2c68326d78cf0115,bd72a9eaf7c983a7512698f83535aa22</data>
    </node>
    <node id="&quot;AUTOMATIC DIFFERENTIATION&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Automatic Differentiation is a method used to compute derivatives of functions, often used in training recursive neural networks."</data>
      <data key="d2">7b6ff30ef255db2d2c68326d78cf0115</data>
    </node>
    <node id="&quot;LINEAR CHAIN&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Linear Chain refers to the structure of a RNN, which is a sequence of nodes connected in a linear order."</data>
      <data key="d2">7b6ff30ef255db2d2c68326d78cf0115</data>
    </node>
    <node id="&quot;DISTRIBUTED REPRESENTATIONS&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Distributed Representations refer to the way information is represented in a neural network, such as logical terms in the case of recursive neural networks."</data>
      <data key="d2">7b6ff30ef255db2d2c68326d78cf0115</data>
    </node>
    <node id="&quot;CONSCIOUS CHUNKER&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"The Conscious Chunker is a higher-level RNN within the Neural History Compressor that studies a compressed representation of the information from the lower-level RNN, allowing for easy classification of deep sequences with long intervals between important events."</data>
      <data key="d2">bd72a9eaf7c983a7512698f83535aa22</data>
    </node>
    <node id="&quot;SUBCONSCIOUS AUTOMATIZER&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"The Subconscious Automatizer is a lower-level RNN within the Neural History Compressor that learns to predict or imitate the hidden units of the Conscious Chunker, helping it to learn appropriate, rarely changing memories across long intervals."</data>
      <data key="d2">bd72a9eaf7c983a7512698f83535aa22</data>
    </node>
    <node id="&quot;CHUNKER&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Chunker is a higher-level component in a system that learns to predict and compress inputs unpredictable by a lower-level automatizer."</data>
      <data key="d2">b888c4ebe914c1dfa26682de69de9de9</data>
    </node>
    <node id="&quot;AUTOMATIZER&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Automatizer is a lower-level component in a system that learns to predict or imitate inputs based on the hidden units of the chunker."</data>
      <data key="d2">b888c4ebe914c1dfa26682de69de9de9</data>
    </node>
    <node id="&quot;GENERATIVE MODEL&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Generative Model is a system that partially overcame the vanishing gradient problem in neural networks and solved a 'Very Deep Learning' task in 1993."</data>
      <data key="d2">b888c4ebe914c1dfa26682de69de9de9</data>
    </node>
    <node id="&quot;SECOND-ORDER RNNS&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Second-order RNNs use higher order weights and states, allowing a direct mapping to a finite-state machine, with examples including Long Short-Term Memory."
"Second-order RNNs are a type of deep learning system that uses higher order weights for mapping to a finite-state machine."</data>
      <data key="d2">4470a7f7ad60a2866b31907a2a3ca96e,b888c4ebe914c1dfa26682de69de9de9</data>
    </node>
    <node id="&quot;VANISHING GRADIENT PROBLEM&quot;">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">b888c4ebe914c1dfa26682de69de9de9</data>
    </node>
    <node id="&quot;LONG SHORT-TERM MEMORY (LSTM)&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Long short-term memory (LSTM) is a deep learning system that avoids the vanishing gradient problem and can learn tasks requiring memories of events from thousands of time steps earlier."</data>
      <data key="d2">4470a7f7ad60a2866b31907a2a3ca96e</data>
    </node>
    <node id="&quot;FINITE-STATE MACHINE&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Finite-state machine is a model of computation that can be used to describe the behavior of Second-order RNNs."</data>
      <data key="d2">4470a7f7ad60a2866b31907a2a3ca96e</data>
    </node>
    <node id="&quot;CONNECTIONIST TEMPORAL CLASSIFICATION (CTC)&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Connectionist Temporal Classification (CTC) is a method used to train stacks of LSTM RNNs to find an RNN weight matrix that maximizes the probability of label sequences in a training set."</data>
      <data key="d2">4470a7f7ad60a2866b31907a2a3ca96e</data>
    </node>
    <node id="&quot;HMM&quot;">
      <data key="d0">"TECHNOLOGY"</data>
      <data key="d1">"HMM is a statistical model that assumes the underlying system is a Markov process with hidden states."</data>
      <data key="d2">b48d5212c060453a846e21cdb98dbd7d</data>
    </node>
    <node id="&quot;GRUS&quot;">
      <data key="d0">"TECHNOLOGY"</data>
      <data key="d1">"GRUs are a type of gating mechanism in recurrent neural networks (RNNs) introduced in 2014, similar to LSTM but with fewer parameters."</data>
      <data key="d2">b48d5212c060453a846e21cdb98dbd7d</data>
    </node>
    <node id="&quot;BI-DIRECTIONAL RNNS&quot;">
      <data key="d0">"TECHNOLOGY"</data>
      <data key="d1">"Bi-directional RNNs are a type of recurrent neural network (RNN) that uses a finite sequence to predict or label each element based on its past and future contexts."
"Bi-directional RNNs are a type of Recurrent Neural Network that use a finite sequence to predict or label each element of the sequence based on the element&#8217;s past and future contexts."</data>
      <data key="d2">2bdd28d9e151597072c8490db69b9941,b48d5212c060453a846e21cdb98dbd7d</data>
    </node>
    <node id="&quot;CONTINUOUS-TIME RECURRENT NEURAL NETWORK&quot;">
      <data key="d0">"TECHNOLOGY"</data>
      <data key="d1">"A Continuous-time Recurrent Neural Network is a type of neural network that uses a system of ordinary differential equations to model the effects on a neuron of the incoming inputs."</data>
      <data key="d2">2bdd28d9e151597072c8490db69b9941</data>
    </node>
    <node id="&quot;CTRNN&quot;">
      <data key="d0">"TECHNOLOGY"</data>
      <data key="d1">"CTRNN is an abbreviation for Continuous-time Recurrent Neural Network, a type of neural network that uses a system of ordinary differential equations to model the effects on a neuron of the incoming inputs."</data>
      <data key="d2">2bdd28d9e151597072c8490db69b9941</data>
    </node>
    <node id="&quot;EVOLUTIONARY ROBOTICS&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Evolutionary Robotics is a field that applies principles of evolution and natural selection to the design and control of robots."</data>
      <data key="d2">2bdd28d9e151597072c8490db69b9941</data>
    </node>
    <node id="&quot;HIERARCHICAL RECURRENT NEURAL NETWORK&quot;">
      <data key="d0">"TECHNOLOGY"</data>
      <data key="d1">"Hierarchical Recurrent Neural Network is a type of Recurrent Neural Network that uses multiple layers to process data at different levels of abstraction."</data>
      <data key="d2">2bdd28d9e151597072c8490db69b9941</data>
    </node>
    <node id="&quot;HRNN&quot;">
      <data key="d0">"TECHNOLOGY"</data>
      <data key="d1">"HRNN is an abbreviation for Hierarchical Recurrent Neural Network, a type of Recurrent Neural Network that uses multiple layers to process data at different levels of abstraction."</data>
      <data key="d2">2bdd28d9e151597072c8490db69b9941</data>
    </node>
    <node id="&quot;SHANNON SAMPLING THEOREM&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"The Shannon sampling theorem is a principle in signal processing that determines the minimum sampling rate required to accurately represent a continuous-time signal."</data>
      <data key="d2">9e61c22432d6984a19da5840f64d417d</data>
    </node>
    <node id="&quot;HIERARCHICAL RECURRENT NEURAL NETWORKS&quot;">
      <data key="d0">"TECHNOLOGY"</data>
      <data key="d1">"Hierarchical recurrent neural networks are a type of recurrent neural network that decompose hierarchical behavior into useful subprograms, inspired by theories of memory presented by philosopher Henri Bergson."</data>
      <data key="d2">9e61c22432d6984a19da5840f64d417d</data>
    </node>
    <node id="&quot;CONSUMER PRICE INDEX&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"The consumer price index (CPI) is a measure that examines the weighted average of price changes of a basket of consumer goods and services, with applications in forecasting and inflation prediction."</data>
      <data key="d2">9e61c22432d6984a19da5840f64d417d</data>
    </node>
    <node id="&quot;RECURRENT MULTILAYER PERCEPTRON NETWORK&quot;">
      <data key="d0">"TECHNOLOGY"</data>
      <data key="d1">"A recurrent multilayer perceptron network (RMLP network) is a type of artificial neural network that consists of cascaded subnetworks, each containing multiple layers of nodes, with feedback connections in the last layer."</data>
      <data key="d2">9e61c22432d6984a19da5840f64d417d</data>
    </node>
    <node id="&quot;US CPI-U INDEX&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"The US CPI-U index is a dataset used for evaluating inflation prediction methods."</data>
      <data key="d2">c7ca22e82a3823afda793ad30077348e</data>
    </node>
    <node id="&quot;HRNN MODEL&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"The HRNN model is a prediction method that outperforms established methods in evaluating the US CPI-U index."</data>
      <data key="d2">c7ca22e82a3823afda793ad30077348e</data>
    </node>
    <node id="&quot;RMLP NETWORK&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"The RMLP network is a type of neural network consisting of cascaded subnetworks with feed-forward and feedback connections."</data>
      <data key="d2">c7ca22e82a3823afda793ad30077348e</data>
    </node>
    <node id="&quot;MTRNN&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"The MTRNN is a neural-based computational model that simulates the functional hierarchy of the brain through self-organization."</data>
      <data key="d2">c7ca22e82a3823afda793ad30077348e</data>
    </node>
    <node id="&quot;NT&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"NT is a shorthand for Neural Turing machines, a type of neural network model that can perform complex computations."</data>
      <data key="d2">c7ca22e82a3823afda793ad30077348e</data>
    </node>
    <node id="&quot;HAWKINS&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Hawkins is a researcher mentioned in the text, known for his work on the memory-prediction theory of brain function."</data>
      <data key="d2">0f59288ce2aaf33e468cdc3877cefd85</data>
    </node>
    <node id="&quot;NEURAL TURING MACHINES&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Neural Turing machines are a method for extending recurrent neural networks, allowing them to interact with external memory resources."</data>
      <data key="d2">0f59288ce2aaf33e468cdc3877cefd85</data>
    </node>
    <node id="&quot;DIFFERENTIABLE NEURAL COMPUTERS&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Differentiable neural computers are an extension of Neural Turing machines, allowing for the usage of fuzzy amounts of each memory address and a record of chronology."</data>
      <data key="d2">0f59288ce2aaf33e468cdc3877cefd85</data>
    </node>
    <node id="&quot;NEURAL NETWORK PUSHDOWN AUTOMATA&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Neural network pushdown automata are similar to Neural Turing machines, but tapes are replaced by analog stacks that are differentiable and trained."
"Neural Network Pushdown Automata are a type of machine learning model that uses differentiable and trainable analog stacks, similar in complexity to recognizers of context-free grammars."</data>
      <data key="d2">0f59288ce2aaf33e468cdc3877cefd85,671755b49cf8893c9fcf9c9c05777ea6</data>
    </node>
    <node id="&quot;MEMRISTIVE NETWORKS&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Memristive networks are described as a system of cortical neural networks that use memristive devices for memory storage and processing."
"Memristive Networks are a particular type of physical neural network that have similar properties to Hopfield networks, with continuous dynamics, limited memory capacity, and natural relaxation via the minimization of a function."
"Memristive Networks are a type of physical neural network with similar properties to Little-Hopfield networks, characterized by continuous dynamics, limited memory capacity, and natural relaxation."</data>
      <data key="d2">0f59288ce2aaf33e468cdc3877cefd85,5445391448d4ac43471e2bce5eb41a70,671755b49cf8893c9fcf9c9c05777ea6</data>
    </node>
    <node id="&quot;GREG SNIDER&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Greg Snider is a researcher mentioned in the text, working at HP Labs and describing a system of cortical neural networks."
"Greg Snider is a researcher at HP Labs who describes a system of cortical computing with memristive nanodevices."</data>
      <data key="d2">0f59288ce2aaf33e468cdc3877cefd85,671755b49cf8893c9fcf9c9c05777ea6</data>
    </node>
    <node id="&quot;HP LABS&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"HP Labs is an organization mentioned in the text, where Greg Snider works on neural network systems."
"HP Labs is an organization where Greg Snider works on cortical computing systems with memristive nanodevices."</data>
      <data key="d2">0f59288ce2aaf33e468cdc3877cefd85,671755b49cf8893c9fcf9c9c05777ea6</data>
    </node>
    <node id="&quot;MEMORY-PREDICTION THEORY&quot;">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">0f59288ce2aaf33e468cdc3877cefd85</data>
    </node>
    <node id="&quot;DARPA'S SYNAPSE PROJECT&quot;">
      <data key="d0">"EVENT"</data>
      <data key="d1">"DARPA's SyNAPSE Project is a funded research initiative that aims to develop neuromorphic architectures based on memristive systems, collaborating with IBM Research, HP Labs, and the Boston University Department of Cognitive and Neural Systems (CNS)."</data>
      <data key="d2">671755b49cf8893c9fcf9c9c05777ea6</data>
    </node>
    <node id="&quot;IBM RESEARCH&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"IBM Research is an organization collaborating with HP Labs and the Boston University Department of Cognitive and Neural Systems (CNS) in DARPA's SyNAPSE Project."</data>
      <data key="d2">671755b49cf8893c9fcf9c9c05777ea6</data>
    </node>
    <node id="&quot;BOSTON UNIVERSITY DEPARTMENT OF COGNITIVE AND NEURAL SYSTEMS (CNS)&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"The Boston University Department of Cognitive and Neural Systems (CNS) is an organization collaborating with IBM Research and HP Labs in DARPA's SyNAPSE Project."</data>
      <data key="d2">671755b49cf8893c9fcf9c9c05777ea6</data>
    </node>
    <node id="&quot;LITTLE-HOPFIELD NETWORKS&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Little-Hopfield Networks are a type of neural network that Memristive Networks are compared to, known for their continuous dynamics and limited memory capacity."</data>
      <data key="d2">5445391448d4ac43471e2bce5eb41a70</data>
    </node>
    <node id="&quot;RESISTOR-CAPACITOR NETWORK&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Resistor-Capacitor Network is mentioned as a type of network that Memristive Networks have a more interesting non-linear behavior compared to."</data>
      <data key="d2">5445391448d4ac43471e2bce5eb41a70</data>
    </node>
    <node id="&quot;NEUROMORPHIC ENGINEERING&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Neuromorphic Engineering is a field mentioned in the context of engineering analog memristive networks, where the device behavior depends on the circuit wiring or topology."</data>
      <data key="d2">5445391448d4ac43471e2bce5eb41a70</data>
    </node>
    <node id="&quot;CARAVELLI-TRAVERSA-DI VENTRA EQUATION&quot;">
      <data key="d0">"EVENT"</data>
      <data key="d1">"The Caravelli-Traversa-Di Ventra Equation is mentioned as a method used to study the evolution of memristive networks analytically."</data>
      <data key="d2">5445391448d4ac43471e2bce5eb41a70</data>
    </node>
    <node id="&quot;MODERN LIBRARIES&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Modern Libraries are mentioned as providers of runtime-optimized implementations for recurrent neural networks."</data>
      <data key="d2">5445391448d4ac43471e2bce5eb41a70</data>
    </node>
    <node id="&quot;WERBOS&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Werbos is a researcher who developed methods for training recurrent neural networks."
"Werbos is a person who contributed to the development of recurrent neural networks in the 1980s and early 1990s."</data>
      <data key="d2">0bb54b1de8d2297293defe94addb8076,6bbaf3df0fa2fac979f6d6a64abb2e91</data>
    </node>
    <node id="&quot;WILLIAMS&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Williams is a researcher who developed methods for training recurrent neural networks."
"Williams is a person who contributed to the development of recurrent neural networks in the 1980s and early 1990s."</data>
      <data key="d2">0bb54b1de8d2297293defe94addb8076,6bbaf3df0fa2fac979f6d6a64abb2e91</data>
    </node>
    <node id="&quot;ROBINSON&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Robinson is a researcher who developed methods for training recurrent neural networks."
"Robinson is a person who contributed to the development of recurrent neural networks in the 1980s and early 1990s."</data>
      <data key="d2">0bb54b1de8d2297293defe94addb8076,6bbaf3df0fa2fac979f6d6a64abb2e91</data>
    </node>
    <node id="&quot;PEARLMUTTER&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Pearlmutter is a researcher who developed methods for training recurrent neural networks."
"Pearlmutter is a person who contributed to the development of recurrent neural networks in the 1980s and early 1990s."</data>
      <data key="d2">0bb54b1de8d2297293defe94addb8076,6bbaf3df0fa2fac979f6d6a64abb2e91</data>
    </node>
    <node id="&quot;BPTT&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"BPTT is a method for training RNNs that uses backpropagation through time, with a time-complexity of O(number of weights) per time step."
"BPTT is a backpropagation through time algorithm used in training recurrent neural networks."</data>
      <data key="d2">1aec5b03f663d1614b2ecbf97981a5c2,88405de18768775d8bce062ea467bd7f</data>
    </node>
    <node id="&quot;RTRL&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"RTRL is a method for training RNNs that uses real-time recursive learning, with a time-complexity of O(number of hidden x number of weights) per time step for computing Jacobian matrices."
"RTRL is a real-time recurrent learning algorithm used in training recurrent neural networks."</data>
      <data key="d2">1aec5b03f663d1614b2ecbf97981a5c2,88405de18768775d8bce062ea467bd7f</data>
    </node>
    <node id="&quot;INDRNN&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"IndRNN is a variant of RNN that reduces the context of a neuron to its own past state, allowing for the exploration of cross-neuron information in following layers."
"IndRNN is an independently recurrent neural network that reduces the context of a neuron to its own past state, allowing for the learning of memories of different ranges."</data>
      <data key="d2">1aec5b03f663d1614b2ecbf97981a5c2,88405de18768775d8bce062ea467bd7f</data>
    </node>
    <node id="&quot;CRBP&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"CRBP is an on-line algorithm that implements and combines BPTT and RTRL paradigms for locally recurrent networks, minimizing the global error term."</data>
      <data key="d2">88405de18768775d8bce062ea467bd7f</data>
    </node>
    <node id="&quot;SIGNAL-FLOW GRAPHS&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Signal-Flow Graphs is a method used for gradient information computation in RNNs with arbitrary architectures, based on diagrammatic derivation."</data>
      <data key="d2">88405de18768775d8bce062ea467bd7f</data>
    </node>
    <node id="&quot;LEE&#8217;S THEOREM&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Lee&#8217;s Theorem is a mathematical concept used in network sensitivity calculations."</data>
      <data key="d2">88405de18768775d8bce062ea467bd7f</data>
    </node>
    <node id="&quot;GLOBAL OPTIMIZATION METHODS&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Global Optimization Methods are techniques used to train the weights in a neural network, modeled as a non-linear optimization problem."</data>
      <data key="d2">88405de18768775d8bce062ea467bd7f</data>
    </node>
    <node id="&quot;WAN&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Wan is a person mentioned as a contributor to the development of RNNs."</data>
      <data key="d2">7ede01f521333d9e39fc34a245103242</data>
    </node>
    <node id="&quot;BEAUFAYS&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Beaufays is a person mentioned as a contributor to the development of RNNs."</data>
      <data key="d2">7ede01f521333d9e39fc34a245103242</data>
    </node>
    <node id="&quot;CAMPOLUCCI&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Campolucci is a person mentioned as a contributor to the development of RNNs."</data>
      <data key="d2">7ede01f521333d9e39fc34a245103242</data>
    </node>
    <node id="&quot;UNCINI&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Uncini is a person mentioned as a contributor to the development of RNNs."</data>
      <data key="d2">7ede01f521333d9e39fc34a245103242</data>
    </node>
    <node id="&quot;PIAZZA&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Piazza is a person mentioned as a contributor to the development of RNNs."</data>
      <data key="d2">7ede01f521333d9e39fc34a245103242</data>
    </node>
    <node id="&quot;GENETIC ALGORITHMS&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Genetic Algorithms are a global optimization method mentioned for training RNNs."
"Genetic Algorithms are a global optimization method used for training RNNs, evolving multiple neural networks to minimize the mean-squared error."</data>
      <data key="d2">797480b3d8c00dbb7f02fccb2ab8256a,7ede01f521333d9e39fc34a245103242</data>
    </node>
    <node id="&quot;SIMULATED ANNEALING&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Simulated Annealing is a global optimization technique that may be used to seek a good set of weights for RNNs."</data>
      <data key="d2">797480b3d8c00dbb7f02fccb2ab8256a</data>
    </node>
    <node id="&quot;PARTICLE SWARM OPTIMIZATION&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Particle Swarm Optimization is a global optimization technique that may be used for training RNNs, seeking a good set of weights."</data>
      <data key="d2">797480b3d8c00dbb7f02fccb2ab8256a</data>
    </node>
    <node id="&quot;DYNAMICAL SYSTEMS THEORY&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Dynamical Systems Theory is a field that may be used for analyzing the behavior of RNNs, which can appear chaotic."
"Dynamical Systems Theory is a field of mathematics used to analyze chaotic behavior in systems."</data>
      <data key="d2">2f1161d1f711d264529aa7bddf81959b,797480b3d8c00dbb7f02fccb2ab8256a</data>
    </node>
    <node id="&quot;RECURSIVE NEURAL NETWORKS&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Recursive Neural Networks are a type of neural network that operate on any hierarchical structure, combining child representations into parent representations."
"Recursive Neural Networks are a type of neural network that operates on hierarchical structures, combining child representations into parent representations."</data>
      <data key="d2">2f1161d1f711d264529aa7bddf81959b,797480b3d8c00dbb7f02fccb2ab8256a</data>
    </node>
    <node id="&quot;FINITE IMPULSE RESPONSE FILTERS&quot;">
      <data key="d0">"TECHNOLOGY"</data>
      <data key="d1">"Finite Impulse Response Filters are a type of filter that can be implemented as a nonlinear version of Recurrent Neural Networks."</data>
      <data key="d2">2f1161d1f711d264529aa7bddf81959b</data>
    </node>
    <node id="&quot;INFINITE IMPULSE RESPONSE FILTERS&quot;">
      <data key="d0">"TECHNOLOGY"</data>
      <data key="d1">"Infinite Impulse Response Filters are a type of filter that can be implemented as a nonlinear version of Recurrent Neural Networks."</data>
      <data key="d2">2f1161d1f711d264529aa7bddf81959b</data>
    </node>
    <node id="&quot;NONLINEAR AUTOREGRESSIVE EXOGENOUS MODEL (NARX)&quot;">
      <data key="d0">"TECHNOLOGY"</data>
      <data key="d1">"Nonlinear Autoregressive Exogenous Model (NARX) is a type of model that can be implemented as a nonlinear version of Recurrent Neural Networks."</data>
      <data key="d2">2f1161d1f711d264529aa7bddf81959b</data>
    </node>
    <node id="&quot;SILENCING MECHANISM&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Silencing Mechanism is a biological mechanism exhibited in neurons with a relatively high frequency spiking activity, used in a more biological-based model for memory-based learning."</data>
      <data key="d2">2f1161d1f711d264529aa7bddf81959b</data>
    </node>
    <node id="&quot;LIBRARIES&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Libraries are mentioned in the text, but no specific library is named."
"Libraries are mentioned as a source of external links, but no further details are provided about their role or activities.")&lt;|COMPLETE|&gt;</data>
      <data key="d2">07d8f04f437c25358d3df4e745af77d4,2f1161d1f711d264529aa7bddf81959b</data>
    </node>
    <node id="&quot;APPLICATIONS&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Applications of recurrent neural networks are mentioned, but no specific applications are named."</data>
      <data key="d2">2f1161d1f711d264529aa7bddf81959b</data>
    </node>
    <node id="&quot;REFERENCES&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"References are mentioned in the text, but no specific references are named."</data>
      <data key="d2">2f1161d1f711d264529aa7bddf81959b</data>
    </node>
    <node id="&quot;MACKEY-GLASS EQUATIONS&quot;">
      <data key="d0">"EVENT"</data>
      <data key="d1">"Mackey-Glass Equations are a set of delayed differential equations used to describe the temporal behavior of physiological signals."
"Mackey-Glass Equations are a set of delayed differential equations used to describe the temporal behavior of physiological signals."</data>
      <data key="d2">238049de5f28dca3e857a46a8b1bed03,2f4c992d69812866e6fce6dbb52d8612</data>
    </node>
    <node id="&quot;PHYSIOLOGICAL SIGNALS&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Physiological Signals are biological signals used to describe the behavior of different physiological systems, such as the relative quantity of mature blood cells over time."</data>
      <data key="d2">2f4c992d69812866e6fce6dbb52d8612</data>
    </node>
    <node id="&quot;MATPLOTLIB&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Matplotlib is a library used for creating visualizations in Python, as mentioned in the text."
"Matplotlib is a library used for creating visualizations in Python, used to plot the sine wave data."
"Matplotlib is a library used for creating visualizations in Python, which is used in the provided code for plotting data."
"Matplotlib is a library used for creating visualizations, such as the sine wave plot."
"Matplotlib is a library used for creating visualizations in Python."
"Matplotlib is a library used for creating static, animated, and interactive visualizations in Python."
"Matplotlib is a library used for creating visualizations in Python."
"Matplotlib is a popular data visualization library in Python used to create the timeseries and phase diagram plots."
"Matplotlib is a popular data visualization library in Python."
"Matplotlib is a library used for creating visualizations in the provided code."</data>
      <data key="d2">2f4c992d69812866e6fce6dbb52d8612,34b9ce80a22112b32e063179511af6e0,4073cafddb73621f26061385c5570659,50d4e4aab1823b8df6573ccf227f24d0,71f966d00b6d0eceb580d00b9cb86b1e,8294eed5fc10df1c118f9afa266910e4,8648b5740b93d805f139d9745e1171e8,a58317c7e13f27d513fc7671fd187ecb,c5c29ba06a5cc70a086c2c2c8858e5aa,e396354e3a9be76616392af11f56e671</data>
    </node>
    <node id="&quot;TAU&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Tau is a parameter in the Mackey-Glass Equations that controls the chaotic behavior of the equations."
"Tau is a time delay parameter used in the Mackey-Glass Equation and the Phase Diagram."</data>
      <data key="d2">238049de5f28dca3e857a46a8b1bed03,518f1e492b92054cf2f5c5289444da02</data>
    </node>
    <node id="&quot;PHASE DIAGRAM&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"A Phase Diagram is a graphical representation of the behavior of a system, showing how its variables change over time or under different conditions."</data>
      <data key="d2">518f1e492b92054cf2f5c5289444da02</data>
    </node>
    <node id="&quot;TASK 1: 10 TIMESTEPS AHEAD FORECAST&quot;">
      <data key="d0">"EVENT"</data>
      <data key="d1">"Task 1 involves predicting P(t+10) given P(t) in the Mackey-Glass Time Series using Reservoir Computing."</data>
      <data key="d2">fac681bdc38ae5829173c747ee6240fa</data>
    </node>
    <node id="&quot;DATA PREPROCESSING&quot;">
      <data key="d0">"EVENT"</data>
      <data key="d1">"Data Preprocessing is the step of preparing the Mackey-Glass Time Series data for use in Task 1, which includes visualizing the training and testing data."
"Data Preprocessing is the step of loading and processing the data to prepare it for analysis."
"Data Preprocessing is the process of cleaning, transforming, and preparing data for analysis."
"Data Preprocessing is the process of transforming raw data into a format that can be used for analysis, as shown in the provided code."
"Data Preprocessing refers to the steps taken to clean and prepare the data for use in the Echo State Network (ESN) model."</data>
      <data key="d2">1365a36c76afc697ac626fd0f784804a,8677349b328abac82fa1cfc91c856a6c,b2beacacc8c190393e4583a69518378c,c5c29ba06a5cc70a086c2c2c8858e5aa,fac681bdc38ae5829173c747ee6240fa</data>
    </node>
    <node id="&quot;TIME SERIES PREDICTION&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Time Series Prediction is the process of forecasting future values based on past data points."
"Time Series Prediction is the task that the ESN network is used for, which involves forecasting future values based on past data."
"Time Series Prediction is the task of forecasting future values based on past observations, which is the primary application of the ESN model."
"Time Series Prediction is the task of forecasting future values based on past observations."
"Time Series Prediction is the task of forecasting future values based on past observations, a common application of reservoir computing models."
"Time Series Prediction refers to the use of a sequence of data points collected at regular time intervals to predict future values."
"Time Series Prediction is the task being performed using the ESN model, as indicated by the code and the context."
"Time Series Prediction is the task of forecasting future values based on past observations, which the ESN model is used for in the provided code."
"Time Series Prediction is the task of forecasting future values based on past observations, which is a common application of reservoir computing models."
"Time Series Prediction is the main task the model is designed for, involving the prediction of future values based on past data."
"Time Series Prediction is a task that involves forecasting future values based on past observations."</data>
      <data key="d2">0113164912437e96423379cb9c039f56,10112a11d47463e2aad7352c52922d61,2336a57d055095c6ffa9d156ddee0096,29f9b2e5fa311519b18e7aef31c68d0a,36e4df75a46fb977f9516f2d2f1f9bc2,46dcc47b4358d3895c1eeb1182c6f997,7b9936d57ece8ba985947a7aca12e2c7,cc1fb6ca5695434ad0279c2606e928af,eb7a223eeb120e3fcc45a96a6018707d,f0c8d4d322d73f46464e3e9f6914f2ee,fd81bdceb3e2b91ac2605a3d201d1eb4</data>
    </node>
    <node id="&quot;X_TRAIN1&quot;">
      <data key="d0">"DATA"</data>
      <data key="d1">"X_train1 is a dataset used for training the ESN neural network."
"X_train1 is a subset of the input data used for training the ESN."</data>
      <data key="d2">09198e939639c229c2c97555f65b12a7,993a69efae014a8f8d6ec0c235104d46</data>
    </node>
    <node id="&quot;Y_TRAIN1&quot;">
      <data key="d0">"DATA"</data>
      <data key="d1">"y_train1 is a dataset used for training the ESN neural network, representing the target output."
"y_train1 is a subset of the target data used for training the ESN."</data>
      <data key="d2">09198e939639c229c2c97555f65b12a7,993a69efae014a8f8d6ec0c235104d46</data>
    </node>
    <node id="&quot;TEST&quot;">
      <data key="d0">"EVENT"</data>
      <data key="d1">"Test is the process of evaluating the performance of the trained ESN network on new data."</data>
      <data key="d2">cc1fb6ca5695434ad0279c2606e928af</data>
    </node>
    <node id="&quot;DENSITY OF RESERVOIR INTERNAL MATRIX&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Density of Reservoir Internal Matrix is a parameter in Reservoir Computing that affects the complexity of the internal connections within the reservoir."</data>
      <data key="d2">2386633041e820b604fc4457264b5a33</data>
    </node>
    <node id="&quot;DENSITY OF RESERVOIR INPUT MATRIX&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Density of Reservoir Input Matrix is a parameter in Reservoir Computing that affects the complexity of the connections between the input and the reservoir."</data>
      <data key="d2">2386633041e820b604fc4457264b5a33</data>
    </node>
    <node id="&quot;PLOT GENERATION FUNCTION&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Plot Generation Function is a function used to visualize the generated timeseries data, comparing it with the real data and displaying metrics such as R-squared."</data>
      <data key="d2">2386633041e820b604fc4457264b5a33</data>
    </node>
    <node id="&quot;NP&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"np is a library in Python used for numerical computations."</data>
      <data key="d2">593306edfb8d4c7ef4b99d24fa009970</data>
    </node>
    <node id="&quot;PLT&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"plt is a library in Python used for creating visualizations."</data>
      <data key="d2">593306edfb8d4c7ef4b99d24fa009970</data>
    </node>
    <node id="&quot;X_T&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"X_t is a variable representing the true values of the input data in the time series."</data>
      <data key="d2">593306edfb8d4c7ef4b99d24fa009970</data>
    </node>
    <node id="&quot;ONE-TIMESTEP-AHEAD FORECAST&quot;">
      <data key="d0">"EVENT"</data>
      <data key="d1">"One-timestep-ahead forecast is a prediction method where the next value in the time series is predicted based on the current value."
"One-timestep-ahead Forecast is the task of predicting the next data point in a time series."</data>
      <data key="d2">29aad23ce67e778ac31d4fb287fd20c7,593306edfb8d4c7ef4b99d24fa009970</data>
    </node>
    <node id="&quot;GENERATIVE MODE&quot;">
      <data key="d0">"EVENT"</data>
      <data key="d1">"Generative mode is a method used to generate new data points in the time series based on the learned model."
"Generative Mode is a process in which the ESN model generates new time series data without external inputs."
"Generative Mode is a concept used in the context of data analysis and machine learning, referring to a mode of operation that generates new data based on learned patterns."
"Generative Mode is a method used in the text, which involves generating timeseries data based on certain parameters."
"Generative Mode is a task where the model generates new data points based on learned patterns."</data>
      <data key="d2">29aad23ce67e778ac31d4fb287fd20c7,424bf7c7b82dc966139c25f7c9ccffb7,593306edfb8d4c7ef4b99d24fa009970,70db98fabc82fc96ecf8cc2c023b586b,e396354e3a9be76616392af11f56e671</data>
    </node>
    <node id="&quot;SUSSILLO AND ABOTT&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Sussillo and Abott are the authors of the FORCE Algorithm, which is used in the ESN model for online learning."</data>
      <data key="d2">424bf7c7b82dc966139c25f7c9ccffb7</data>
    </node>
    <node id="&quot;SUSSILLO&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Sussillo is a contributor to the FORCE Algorithm, developed with Abott in 2009."</data>
      <data key="d2">1b9bc5f1bd54d2b0c90359b6ed022bb6</data>
    </node>
    <node id="&quot;ABOTT&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Abott is a contributor to the FORCE Algorithm, developed with Sussillo in 2009."</data>
      <data key="d2">1b9bc5f1bd54d2b0c90359b6ed022bb6</data>
    </node>
    <node id="&quot;ROBOT FALLING&quot;">
      <data key="d0">"EVENT"</data>
      <data key="d1">"Robot Falling is a use case mentioned in the text, where data from a robot falling is used to demonstrate the use of Echo State Networks (ESNs)."
"Robot falling is an event mentioned in the text, which involves the use of data from a robot that has fallen to analyze its behavior."</data>
      <data key="d2">af2db1cc5ab6b16acae2c93d3facb668,b483c6bbce54156c724905b340aa2e85</data>
    </node>
    <node id="&quot;ZENODO&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Zenodo is a platform mentioned in the text, where data for the Robot Falling use case can be found."
"Zenodo is a platform mentioned in the text, where data for the robot falling use case can be found."
"Zenodo is a platform for sharing research data, with a record available for the canary song decoding use case."
"Zenodo is a platform where the data is found, hosting various research outputs and data."</data>
      <data key="d2">8677349b328abac82fa1cfc91c856a6c,af2db1cc5ab6b16acae2c93d3facb668,b483c6bbce54156c724905b340aa2e85,d15f6d075c072f0335b5332f11c00299</data>
    </node>
    <node id="&quot;ROBOT&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"The robot is the subject of the data analysis, with features such as 'left_ankle_pitch' and 'right_hip_yaw' being monitored."</data>
      <data key="d2">90fa1052aec4e6374867e9a2951fb3c4</data>
    </node>
    <node id="&quot;FALL INDICATOR&quot;">
      <data key="d0">"EVENT"</data>
      <data key="d1">"The fall indicator is an event that the robot is being monitored for, with the objective of preventing falls."</data>
      <data key="d2">90fa1052aec4e6374867e9a2951fb3c4</data>
    </node>
    <node id="&quot;FORCE MAGNITUDE&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Force magnitude is a concept that is being measured and analyzed in the context of the robot's data."</data>
      <data key="d2">90fa1052aec4e6374867e9a2951fb3c4</data>
    </node>
    <node id="&quot;PYTHON CODE&quot;">
      <data key="d0">"TECHNOLOGY"</data>
      <data key="d1">"Python Code is used to analyze and visualize data, perform calculations, and display results."</data>
      <data key="d2">d15f6d075c072f0335b5332f11c00299</data>
    </node>
    <node id="&quot;CANARY SONG DECODING&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Canary Song Decoding is the process of analyzing and classifying temporal motifs in canary songs to identify different phrases and silence."
"Canary Song Decoding is a use case that involves analyzing a canary's song to extract information."
"Canary Song Decoding is the process of analyzing and interpreting a canary song, as discussed in Chapter 5."</data>
      <data key="d2">1e8ee805d22cd143d2372d300997d253,d15f6d075c072f0335b5332f11c00299,e7d249cdab85dc69b631d43ac6b62915</data>
    </node>
    <node id="&quot;THE DATA&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"The Data refers to the temporal motifs to classify found on Zenodo, which includes phrases and silence."</data>
      <data key="d2">8677349b328abac82fa1cfc91c856a6c</data>
    </node>
    <node id="&quot;LIBRISPEECH DATASET&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"The Librispeech Dataset is a collection of audio files and annotations used for speech recognition and analysis."</data>
      <data key="d2">adfade0d7bc85c6420e61ecd1ce7095c</data>
    </node>
    <node id="&quot;MFCC&quot;">
      <data key="d0">"TECHNOLOGY"</data>
      <data key="d1">"MFCC (Mel-Frequency Cepstral Coefficients) is a feature extraction technique used to represent the short-term power spectrum of a sound."
"MFCC (Mel-frequency cepstral coefficients) is a feature extraction technique used in the data analysis process."</data>
      <data key="d2">9a54cf00618f7dcfb151c8dc8f7471bd,adfade0d7bc85c6420e61ecd1ce7095c</data>
    </node>
    <node id="&quot;DELTA-DELTA&quot;">
      <data key="d0">"TECHNOLOGY"</data>
      <data key="d1">"Delta-Delta is a feature extraction technique used to capture the rate of change of Delta coefficients over time."</data>
      <data key="d2">adfade0d7bc85c6420e61ecd1ce7095c</data>
    </node>
    <node id="&quot;LOAD_DATA&quot;">
      <data key="d0">"FUNCTION"</data>
      <data key="d1">"load_data is a function used to load audio files and annotations from the Librispeech Dataset, extracting MFCC, Delta, and Delta-Delta features."
"load_data is a function used to load and preprocess audio data, which is a key step in the data analysis process."</data>
      <data key="d2">9a54cf00618f7dcfb151c8dc8f7471bd,adfade0d7bc85c6420e61ecd1ce7095c</data>
    </node>
    <node id="&quot;SPECIAL NODE E&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Special Node E is a unique node within the ESN network, playing a significant role in the training process."</data>
      <data key="d2">894d59d781535ca85389c4226715c007</data>
    </node>
    <node id="&quot;SPECIAL NODE&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Special Node is a component of the Echo State Network (ESN) that allows parallelization of states computations, improving training efficiency."</data>
      <data key="d2">d0b9bbbd7257712eafd2eda5db1d0a8d</data>
    </node>
    <node id="&quot;SKLEARN&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Sklearn is a library used for importing metrics, which may be used for evaluating the performance of the trained ESN model."
"sklearn is a popular machine learning library that provides tools for data analysis and model training."
"Sklearn is a machine learning library in Python, used for preprocessing data and encoding labels in the text."
"Sklearn is a Python library for machine learning, mentioned in the text."</data>
      <data key="d2">1e8ee805d22cd143d2372d300997d253,870f29520f7a1c42eecb0c4ff855f09e,9fdaabd6c7e893a275a3848c10007477,d0b9bbbd7257712eafd2eda5db1d0a8d</data>
    </node>
    <node id="&quot;ONE_HOT&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"one_hot is a variable representing the one-hot encoding used to transform the target data into a format suitable for training the ESN system."
"one_hot is a technique used for encoding categorical variables, converting them into a binary matrix representation."</data>
      <data key="d2">1db5e6cd356c6066227de5e273de1abe,80c9f51870e239404ed671ef0374f191</data>
    </node>
    <node id="&quot;VOCAB&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"vocab is a variable representing the vocabulary used to map the predicted output to the corresponding target value."
"vocab is a vocabulary or dictionary used for mapping between numerical and categorical representations of data."</data>
      <data key="d2">1db5e6cd356c6066227de5e273de1abe,80c9f51870e239404ed671ef0374f191</data>
    </node>
    <node id="&quot;AVERAGE ACCURACY&quot;">
      <data key="d0">"EVENT"</data>
      <data key="d1">"Average Accuracy is a metric that measures the overall performance of a model, calculated as the mean accuracy."</data>
      <data key="d2">eb4cbfc924325a7ec01e566ffac75ac3</data>
    </node>
    <node id="&quot;STANDARD DEVIATION&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Standard Deviation is a metric that measures the amount of variation or dispersion of a set of values."</data>
      <data key="d2">eb4cbfc924325a7ec01e566ffac75ac3</data>
    </node>
    <node id="&quot;ADVANCED FEATURES&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Advanced Features refers to the capabilities of ReservoirPy beyond basic usage, such as input-to-readout connections and custom weight matrices.""Advanced Features refers to the capabilities of ReservoirPy beyond basic usage, such as input-to-readout connections, feedback connections, custom weight matrices, parallelization, and 'deep' architectures."</data>
      <data key="d2">ead6383a44acd8ebd17907b85a910455</data>
      <data key="d3">"CONCEPT"</data>
    </node>
    <node id="&quot;DIRECT CONNECTIONS&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Direct Connections refer to the presence of input-to-readout connections in more advanced ESNs."</data>
      <data key="d2">ead6383a44acd8ebd17907b85a910455</data>
    </node>
    <node id="&quot;LONG TERM FORECASTING&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Long term forecasting refers to the ability to predict data over long periods of time using feedback connections."</data>
      <data key="d2">ead6383a44acd8ebd17907b85a910455</data>
    </node>
    <node id="&quot;CUSTOM WEIGHT MATRICES&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Custom weight matrices are matrices used to create more complex ESNs, which can be useful for tasks such as image classification or modeling complex systems."</data>
      <data key="d2">ead6383a44acd8ebd17907b85a910455</data>
    </node>
    <node id="&quot;'DEEP' ARCHITECTURES&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"'Deep' architectures are architectures created by stacking multiple ESNs together, which can be useful for tasks such as image classification or modeling complex systems."</data>
      <data key="d2">ead6383a44acd8ebd17907b85a910455</data>
    </node>
    <node id="&quot;MODEL CREATION&quot;">
      <data key="d0">"EVENT"</data>
      <data key="d1">"Model creation is the process of building a neural network model, including defining nodes, connections, and parameters."</data>
      <data key="d2">f1fc6fbc8158d3da070d55544041a2ca</data>
    </node>
    <node id="&quot;CONNECTION CHAINING&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Connection chaining is the process of connecting nodes in a sequential manner, using operators such as &gt;&gt;."</data>
      <data key="d2">f1fc6fbc8158d3da070d55544041a2ca</data>
    </node>
    <node id="&quot;CONNECTION MERGE&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Connection merge is the process of combining connections from multiple nodes to a single node, using operators such as &amp;."</data>
      <data key="d2">f1fc6fbc8158d3da070d55544041a2ca</data>
    </node>
    <node id="&quot;CONCATENATE&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Concatenate is a concept used in the model, which combines multiple inputs into a single vector."</data>
      <data key="d2">cf15a09e77b695a117e1cca05461aea2</data>
    </node>
    <node id="&quot;ESN_MODEL&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"ESN model is a concept that combines data, reservoir, and readout nodes, with the ability to handle feedback connections and multiple inputs."
"esn_model is a machine learning model constructed using the Reservoir and Ridge organizations."</data>
      <data key="d2">751b176a8d6149a853e597c65a6fe0cf,cf15a09e77b695a117e1cca05461aea2</data>
    </node>
    <node id="&quot;MODEL.RUN()&quot;">
      <data key="d0">"TECHNOLOGY"</data>
      <data key="d1">"Model.run() is a method used to make predictions using a trained model, such as an Echo State Network (ESN), on new input data."</data>
      <data key="d2">b338d2dcc1fe6ccf42407444c02cad7c</data>
    </node>
    <node id="&quot;FEEDBACK&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Feedback refers to the process of using the output of a system as input to the same system, influencing its behavior."</data>
      <data key="d2">b338d2dcc1fe6ccf42407444c02cad7c</data>
    </node>
    <node id="&quot;FEEDBACK TIMESERIES&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Feedback Timeseries is a sequence of data used to influence the behavior of a system, such as an Echo State Network (ESN), during the prediction phase."</data>
      <data key="d2">b338d2dcc1fe6ccf42407444c02cad7c</data>
    </node>
    <node id="&quot;TIMESTEPS&quot;">
      <data key="d0">"EVENT"</data>
      <data key="d1">"Timesteps are discrete points in a time series, used in the context of the ESN model for prediction and generation."
"Timesteps refer to the discrete time intervals at which data is processed or analyzed."</data>
      <data key="d2">38b3e8ea0ec280360770513327b0d9d3,9e84667b4aeb0789808517f0912043ce</data>
    </node>
    <node id="&quot;READOUTS&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Readouts are components of the ESN model that hold parameters and perform output calculations."
"Readouts are components used in the ReservoirPy library, which hold parameters stored as Numpy arrays or Scipy sparse matrices."</data>
      <data key="d2">38b3e8ea0ec280360770513327b0d9d3,ff860bc63e3d697a6183c0b850689048</data>
    </node>
    <node id="&quot;RESERVOIRS&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Reservoirs are components of the ESN model that hold parameters and perform internal computations."
"Reservoirs are components used in the ReservoirPy library, which hold parameters stored as Numpy arrays or Scipy sparse matrices."</data>
      <data key="d2">38b3e8ea0ec280360770513327b0d9d3,ff860bc63e3d697a6183c0b850689048</data>
    </node>
    <node id="&quot;INITIALIZER FUNCTIONS&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Initializer Functions are used to initialize parameters in the ESN model, taking the shape of the parameter matrix as input and returning an array or a Scipy matrix."</data>
      <data key="d2">38b3e8ea0ec280360770513327b0d9d3</data>
    </node>
    <node id="&quot;CUSTOM INITIALIZER FUNCTIONS&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Custom Initializer Functions are used to initialize parameters in reservoirs or readouts, allowing for custom weight matrix creation."</data>
      <data key="d2">ff860bc63e3d697a6183c0b850689048</data>
    </node>
    <node id="&quot;CONNECTIVITY&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Connectivity is a property of a matrix in mathematics, which is mentioned in the context of initializing weight matrices."
"connectivity is a parameter used to set the sparsity of the reservoir's weight matrix in the ESN."
"Connectivity is a parameter used to control the sparsity and structure of the reservoir in the Echo State Network (ESN) model."
"Connectivity is a parameter in the Reservoir component of the ESN model that determines the density of connections between nodes."</data>
      <data key="d2">09198e939639c229c2c97555f65b12a7,1365a36c76afc697ac626fd0f784804a,72e6eee633bcb5b1458c4cee3975cee1,ff860bc63e3d697a6183c0b850689048</data>
    </node>
    <node id="&quot;SCIPY.STATS&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Scipy.stats is a module within the Scipy library used for statistical functions, which is mentioned in the context of initializer functions."
"scipy.stats is a module that provides functions for statistical analysis and probability distributions."</data>
      <data key="d2">96c47d9b671ce319abe9c6ba2b8ae122,ff860bc63e3d697a6183c0b850689048</data>
    </node>
    <node id="&quot;NORMAL&quot;">
      <data key="d0">"FUNCTION"</data>
      <data key="d1">"normal is a function from the reservoirpy.mat_gen module that creates a dense matrix from a Gaussian distribution."
"normal is a function used to generate dense matrices from a normal distribution."</data>
      <data key="d2">3a3b7a67b23341dcd1b04ec5b61683f6,96c47d9b671ce319abe9c6ba2b8ae122</data>
    </node>
    <node id="&quot;UNIFORM&quot;">
      <data key="d0">"FUNCTION"</data>
      <data key="d1">"uniform is a function from the reservoirpy.mat_gen module that creates a sparse matrix from a uniform distribution."
"uniform is a function used to generate sparse matrices from a uniform distribution."</data>
      <data key="d2">3a3b7a67b23341dcd1b04ec5b61683f6,96c47d9b671ce319abe9c6ba2b8ae122</data>
    </node>
    <node id="&quot;BERNOULLI DISTRIBUTION&quot;">
      <data key="d0">"EVENT"</data>
      <data key="d1">"Bernoulli Distribution is a type of probability distribution used to generate matrices."</data>
      <data key="d2">d5e39e29b61f6ea0ffe0c868ba7a4252</data>
    </node>
    <node id="&quot;STANDARD RESERVOIR&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Standard Reservoir is a type of node in ReservoirPy, which is used as a base for creating other nodes such as ESN."</data>
      <data key="d2">3bee7b78d0ab9582cc9bffe9e305df2e</data>
    </node>
    <node id="&quot;SEQUENCES OF INPUTS&quot;">
      <data key="d0">"EVENT"</data>
      <data key="d1">"Sequences of Inputs are independent data sequences used for processing, with 500 sequences, each 1000 timesteps long and 50-dimensional."</data>
      <data key="d2">3bee7b78d0ab9582cc9bffe9e305df2e</data>
    </node>
    <node id="&quot;SEQUENCES OF TARGETS&quot;">
      <data key="d0">"EVENT"</data>
      <data key="d1">"Sequences of Targets are corresponding data sequences to the Inputs, with 500 sequences, each 1000 timesteps long and 40-dimensional."</data>
      <data key="d2">3bee7b78d0ab9582cc9bffe9e305df2e</data>
    </node>
    <node id="&quot;SEQUENTIAL BACKEND&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Sequential Backend is a component of the ESN model that processes data in a sequential manner."</data>
      <data key="d2">f0c8d4d322d73f46464e3e9f6914f2ee</data>
    </node>
    <node id="&quot;MULTIPROCESSING BACKEND&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Multiprocessing Backend is a component of the ESN model that processes data in parallel using multiple cores."</data>
      <data key="d2">f0c8d4d322d73f46464e3e9f6914f2ee</data>
    </node>
    <node id="&quot;DEEP ECHO STATE NETWORKS&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Deep Echo State Networks are a type of model mentioned in the text, which contain nodes and connections."</data>
      <data key="d2">59b469bdd618b3f36b3547f4f2b8a862</data>
    </node>
    <node id="&quot;RESERVOIR1&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"reservoir1 is a component in a system, likely a part of a larger organization or system."
"Reservoir1 is a component in a reservoir model, used for data processing and analysis."</data>
      <data key="d2">2fa8f7c2f23059f64f6d2452b6e7af49,8648b5740b93d805f139d9745e1171e8</data>
    </node>
    <node id="&quot;RESERVOIR2&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"reservoir2 is a component in a system, likely a part of a larger organization or system."
"Reservoir2 is a component in a reservoir model, used for data processing and analysis."</data>
      <data key="d2">2fa8f7c2f23059f64f6d2452b6e7af49,8648b5740b93d805f139d9745e1171e8</data>
    </node>
    <node id="&quot;RESERVOIR3&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"reservoir3 is a component in a system, likely a part of a larger organization or system."
"Reservoir3 is a component in a reservoir model, used for data processing and analysis."</data>
      <data key="d2">2fa8f7c2f23059f64f6d2452b6e7af49,8648b5740b93d805f139d9745e1171e8</data>
    </node>
    <node id="&quot;READOUT1&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"readout1 is a component in a system, likely a part of a larger organization or system."</data>
      <data key="d2">2fa8f7c2f23059f64f6d2452b6e7af49</data>
    </node>
    <node id="&quot;READOUT2&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"readout2 is a component in a system, likely a part of a larger organization or system."</data>
      <data key="d2">2fa8f7c2f23059f64f6d2452b6e7af49</data>
    </node>
    <node id="&quot;TUTORIAL&quot;">
      <data key="d0">"EVENT"</data>
      <data key="d1">"The text describes a tutorial on how to create an Echo State Network (ESN) with ReservoirPy."</data>
      <data key="d2">74c073137c970e32982756d008532cb8</data>
    </node>
    <node id="&quot;REGULARIZED RIDGE REGRESSION&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Regularized Ridge Regression is a simple linear regression algorithm used to train the connections between the readout and the reservoir."
"Regularized Ridge Regression is a learning algorithm used to train the readout of an ESN."</data>
      <data key="d2">711ec1b4879d910d0df0a477c9e240ba,cdc64af0dde941250d89b191d0666c9b</data>
    </node>
    <node id="&quot;RESERVOIR CLASS&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Reservoir class is a component of the ReservoirPy library used to create a reservoir for an ESN."</data>
      <data key="d2">9b360c6a33aafa6827417de5bd4faa82</data>
    </node>
    <node id="&quot;SINE WAVE&quot;">
      <data key="d0">"EVENT"</data>
      <data key="d1">"A sine wave is a mathematical curve that describes a smooth periodic oscillation, used as input data for the reservoir."
"Sine Wave is a mathematical function that generates a continuous wave-like pattern, used as an example in the text."
"Sine Wave is a mathematical function used as an example in the text, with a blue wave representing the current values and a red wave representing the future values."
"A sine wave is a mathematical curve that describes a smooth periodic oscillation, which is used as input data in the provided code."
"Sine Wave is a mathematical function that describes a smooth, continuous oscillation."
"A Sine Wave is a mathematical function used in the provided text to generate data."</data>
      <data key="d2">2bcc39da2ecef3011cc3da428fca5dd5,34b9ce80a22112b32e063179511af6e0,5366a81a025c098744b5d6f1432c2fbc,71f966d00b6d0eceb580d00b9cb86b1e,a58317c7e13f27d513fc7671fd187ecb,f2d5625f36aa4cb036089ce89ec607eb</data>
    </node>
    <node id="&quot;INPUT TIMESERIES&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Input Timeseries is a data series used as input for training a machine learning model."</data>
      <data key="d2">5366a81a025c098744b5d6f1432c2fbc</data>
    </node>
    <node id="&quot;TARGET TIMESERIES&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Target Timeseries is a data series that the machine learning model is trained to predict based on the Input Timeseries."</data>
      <data key="d2">5366a81a025c098744b5d6f1432c2fbc</data>
    </node>
    <node id="&quot;ONE-TIMESTEP-AHEAD PREDICTION TASK&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"One-timestep-ahead Prediction Task is a machine learning task where the goal is to predict the next timestep of a timeseries based on its current timestep."</data>
      <data key="d2">5366a81a025c098744b5d6f1432c2fbc</data>
    </node>
    <node id="&quot;PREDICTIONS&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Predictions refer to the output of the ESN model, which attempts to forecast the next value in a timeseries."</data>
      <data key="d2">7b294b788fe5ee385d08c4aabe2ca71d</data>
    </node>
    <node id="&quot;RUNNING&quot;">
      <data key="d0">"EVENT"</data>
      <data key="d1">"Running is the process of using the trained ESN Model to make predictions on unseen data."</data>
      <data key="d2">8ade7819a5f8d1ec26e9bdbd059142e6</data>
    </node>
    <node id="&quot;RESERVOIR COMPUTING MODEL&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"A Reservoir Computing Model is a type of artificial neural network used for time series prediction and data analysis."</data>
      <data key="d2">71f966d00b6d0eceb580d00b9cb86b1e</data>
    </node>
    <node id="&quot;CONCAT&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Concat is a function used to combine multiple data streams into a single stream."</data>
      <data key="d2">c82c9d05b211ff65131f70eb8cb13513</data>
    </node>
    <node id="&quot;FORCED FEEDBACKS&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Forced Feedbacks are a technique used in reservoir computing models to control the internal dynamics of the model."</data>
      <data key="d2">c82c9d05b211ff65131f70eb8cb13513</data>
    </node>
    <node id="&quot;FITTING&quot;">
      <data key="d0">"EVENT"</data>
      <data key="d1">"Fitting is the process of training a reservoir computing model to learn patterns and relationships in the data."</data>
      <data key="d2">c82c9d05b211ff65131f70eb8cb13513</data>
    </node>
    <node id="&quot;FIT METHOD&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Fit Method is used to train the echo state network model by optimizing the parameters of the readout layer."</data>
      <data key="d2">ed28ba3543e07641536ff1eb5e0749dd</data>
    </node>
    <node id="&quot;RUN METHOD&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Run Method is used to generate predictions or forecasts using the trained echo state network model."</data>
      <data key="d2">ed28ba3543e07641536ff1eb5e0749dd</data>
    </node>
    <node id="&quot;WARMUP&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Warmup is a technique used to initialize the reservoir with a sequence of input data before making predictions or forecasts."</data>
      <data key="d2">ed28ba3543e07641536ff1eb5e0749dd</data>
    </node>
    <node id="&quot;NORMAL_W&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"normal_w is a concept or variable used in the provided code, likely representing a function for generating normal distribution weights."</data>
      <data key="d2">751b176a8d6149a853e597c65a6fe0cf</data>
    </node>
    <node id="&quot;RESERVOIRPY.NODES.RESERVOIR&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"reservoirpy.nodes.Reservoir is an organization or module used in the provided code, likely a part of a larger machine learning framework."</data>
      <data key="d2">751b176a8d6149a853e597c65a6fe0cf</data>
    </node>
    <node id="&quot;RESERVOIRPY.MAT&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"reservoirpy.mat is an organization or module used in the provided code, likely a part of a larger machine learning framework."</data>
      <data key="d2">751b176a8d6149a853e597c65a6fe0cf</data>
    </node>
    <node id="&quot;BERNOULLI&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Bernoulli refers to a probability distribution that models a random variable that can take on two possible outcomes, such as success or failure, with a given probability of success."</data>
      <data key="d2">7b9936d57ece8ba985947a7aca12e2c7</data>
    </node>
    <node id="&quot;HIERARCHICAL ESN&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Hierarchical ESN is a type of echo state network (ESN) that uses multiple reservoirs and readouts to improve performance."
"Hierarchical ESN is a type of reservoir computing model mentioned in the text, consisting of multiple reservoirs and readouts."</data>
      <data key="d2">00d22666fe697ffb66c2392939f45b39,e39809b687cd044a7918eca37727a188</data>
    </node>
    <node id="&quot;SEQUENTIAL&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Sequential is a library or framework mentioned in the text, potentially used for data processing."</data>
      <data key="d2">e39809b687cd044a7918eca37727a188</data>
    </node>
    <node id="&quot;MULTI-INPUTS&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Multi-inputs is a term used in the context of reservoir computing, referring to the use of multiple data streams or inputs in the model."</data>
      <data key="d2">e39809b687cd044a7918eca37727a188</data>
    </node>
    <node id="&quot;PLOTTING FUNCTION&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"The Plotting Function is used to visualize data, such as timeseries and phase diagrams."</data>
      <data key="d2">c5c29ba06a5cc70a086c2c2c8858e5aa</data>
    </node>
    <node id="&quot;FIRST ECHO STATE NETWORK&quot;">
      <data key="d0">"EVENT"</data>
      <data key="d1">"The construction and training of the first Echo State Network is described in the provided text."</data>
      <data key="d2">41fa16855df7da666dc6fc38d2f8ee53</data>
    </node>
    <node id="&quot;CHAPTER 2&quot;">
      <data key="d0">"EVENT"</data>
      <data key="d1">"Chapter 2 is a section of the text that discusses the use of a generative mode in the context of data analysis."</data>
      <data key="d2">e396354e3a9be76616392af11f56e671</data>
    </node>
    <node id="&quot;REAL TIMESERIES DATA&quot;">
      <data key="d0">"DATA"</data>
      <data key="d1">"Real Timeseries Data is the actual sequence of data points used for comparison in the text."</data>
      <data key="d2">70db98fabc82fc96ecf8cc2c023b586b</data>
    </node>
    <node id="&quot;X_TRAIN3&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"X_train3 is a dataset used for training a model."</data>
      <data key="d2">0c5a253fb2bcebe8674581a5dc12fd96</data>
    </node>
    <node id="&quot;Y_TRAIN3&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"y_train3 is a dataset used for training a model."</data>
      <data key="d2">0c5a253fb2bcebe8674581a5dc12fd96</data>
    </node>
    <node id="&quot;X_TEST3&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"X_test3 is a dataset used for testing a model."</data>
      <data key="d2">0c5a253fb2bcebe8674581a5dc12fd96</data>
    </node>
    <node id="&quot;Y_TEST3&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"y_test3 is a dataset used for testing a model."</data>
      <data key="d2">0c5a253fb2bcebe8674581a5dc12fd96</data>
    </node>
    <node id="&quot;CHAPTER 3&quot;">
      <data key="d0">"EVENT"</data>
      <data key="d1">"Chapter 3 is a section discussing online learning."</data>
      <data key="d2">0c5a253fb2bcebe8674581a5dc12fd96</data>
    </node>
    <node id="&quot;FORCE&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"FORCE is a node used in the reservoir network."
"FORCE is a readout algorithm used in reservoir computing networks."
"FORCE is a type of readout algorithm used in the Echo State Network (ESN) model."</data>
      <data key="d2">0c5a253fb2bcebe8674581a5dc12fd96,1365a36c76afc697ac626fd0f784804a,324a8f3fb4d19b91457a99999e6d3d17</data>
    </node>
    <node id="&quot;RESERVOIR COMPUTING NETWORKS&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Reservoir Computing Networks are a type of recurrent neural network that use a reservoir to process input data."</data>
      <data key="d2">324a8f3fb4d19b91457a99999e6d3d17</data>
    </node>
    <node id="&quot;TESTING DATA&quot;">
      <data key="d0">"EVENT"</data>
      <data key="d1">"Testing Data refers to the data used to evaluate the performance of the trained Echo State Network (ESN) model."</data>
      <data key="d2">1365a36c76afc697ac626fd0f784804a</data>
    </node>
    <node id="&quot;LEAK RATE&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Leak Rate is a parameter used to control the rate at which information is lost from the reservoir in the Echo State Network (ESN) model."
"Leak Rate is a parameter in the Reservoir component of the ESN model that controls the rate of information leakage."
"Leak Rate is a parameter used in the design of recurrent neural networks, which is mentioned in the text."</data>
      <data key="d2">1365a36c76afc697ac626fd0f784804a,72e6eee633bcb5b1458c4cee3975cee1,b957e1bf5bf175c7630222ca742c7933</data>
    </node>
    <node id="&quot;TQDM&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"tqdm is a library that provides a progress bar for loops, used in the provided code to monitor the progress of data loading."</data>
      <data key="d2">9fdaabd6c7e893a275a3848c10007477</data>
    </node>
    <node id="&quot;DATA SCIENTIST&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"The provided code is written by a Data Scientist who is using machine learning tools and techniques to analyze and model data."</data>
      <data key="d2">9fdaabd6c7e893a275a3848c10007477</data>
    </node>
    <node id="&quot;TRAINING THE ESN&quot;">
      <data key="d0">"EVENT"</data>
      <data key="d1">"Training the ESN refers to the process of fitting the ESN model to the training data, allowing it to learn patterns and make predictions."</data>
      <data key="d2">eb7a223eeb120e3fcc45a96a6018707d</data>
    </node>
    <node id="&quot;ROBOT PERFORMANCE EVALUATION&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Robot Performance Evaluation is a process that involves comparing predicted and actual outcomes to assess the model's accuracy."</data>
      <data key="d2">e7d249cdab85dc69b631d43ac6b62915</data>
    </node>
    <node id="&quot;ROBOT PERFORMANCE&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Robot Performance refers to the accuracy and effectiveness of a robot in its tasks."</data>
      <data key="d2">e7d249cdab85dc69b631d43ac6b62915</data>
    </node>
    <node id="&quot;CANARY SONG&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Canary Song refers to the song produced by a canary, which may contain hidden information."</data>
      <data key="d2">e7d249cdab85dc69b631d43ac6b62915</data>
    </node>
    <node id="&quot;CHAPTER 5&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Chapter 5 is a section of the text that discusses a use case in the wild, specifically decoding a canary song."</data>
      <data key="d2">1e8ee805d22cd143d2372d300997d253</data>
    </node>
    <node id="&quot;IPYTHON&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"IPython is an open-source project that provides a rich environment for interactive computing and data visualization."</data>
      <data key="d2">1e8ee805d22cd143d2372d300997d253</data>
    </node>
    <node id="&quot;PANDAS&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Pandas is a software library for data manipulation and analysis, used for handling and processing data in the text."</data>
      <data key="d2">1e8ee805d22cd143d2372d300997d253</data>
    </node>
    <node id="&quot;LIFTER&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"lifter is a parameter used in the MFCC feature extraction process, indicating its role in the data analysis."</data>
      <data key="d2">9a54cf00618f7dcfb151c8dc8f7471bd</data>
    </node>
    <node id="&quot;N_MFCC&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"n_mfcc is a parameter used in the MFCC feature extraction process, indicating its role in the data analysis."</data>
      <data key="d2">9a54cf00618f7dcfb151c8dc8f7471bd</data>
    </node>
    <node id="&quot;LBR.FEATURE.DELTA&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"lbr.feature.delta is a function used to calculate the delta features of a signal, which are used for feature extraction."</data>
      <data key="d2">71366a4c7e791080872ba783d3787bd7</data>
    </node>
    <node id="&quot;NP.VSTACK&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"np.vstack is a function from the NumPy library used to vertically stack arrays."
"np.vstack is a NumPy function used to vertically stack arrays, which is used in the context of one-hot encoding and inverse transformations."</data>
      <data key="d2">1db5e6cd356c6066227de5e273de1abe,71366a4c7e791080872ba783d3787bd7</data>
    </node>
    <node id="&quot;NP.ARRAY&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"np.array is a function from the NumPy library used to create a NumPy array from an input."</data>
      <data key="d2">71366a4c7e791080872ba783d3787bd7</data>
    </node>
    <node id="&quot;INPUTS SCALING&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Inputs Scaling is a parameter in the ESN model that scales the input data to a suitable range."</data>
      <data key="d2">72e6eee633bcb5b1458c4cee3975cee1</data>
    </node>
    <node id="&quot;OUTPUTS&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"outputs are the predicted results generated by a model, which are compared to the actual targets for evaluation."</data>
      <data key="d2">1db5e6cd356c6066227de5e273de1abe</data>
    </node>
    <node id="&quot;RESERVOIR CONNECTIVITY&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Reservoir Connectivity is a parameter in Reservoir Computing that determines the interconnections between neurons in the reservoir."</data>
      <data key="d2">26d78bc91458f47d4053954505c45f92</data>
    </node>
    <node id="&quot;LEAKING RATES&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Leaking Rates are parameters used in the simulations run by the Reservoir organization."</data>
      <data key="d2">548c454b31f852543b600df173bd44ab</data>
    </node>
    <node id="&quot;DOUBLESCROLL&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Doublescroll is a mathematical concept used to generate data for simulations, with parameters such as timesteps and initial conditions."</data>
      <data key="d2">548c454b31f852543b600df173bd44ab</data>
    </node>
    <node id="&quot;OPTIMIZE HYPERPARAMETERS&quot;">
      <data key="d0">"EVENT"</data>
      <data key="d1">"Optimize Hyperparameters is an event or process where the parameters of a system, such as the Reservoir organization's simulations, are adjusted to improve performance or accuracy."</data>
      <data key="d2">548c454b31f852543b600df173bd44ab</data>
    </node>
    <node id="&quot;OBJECTIVE FUNCTIONS&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Objective Functions are used to evaluate the performance of reservoir computing models and guide the search for optimal parameters."</data>
      <data key="d2">0113164912437e96423379cb9c039f56</data>
    </node>
    <node id="&quot;R-SQUARED&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"R-squared is a metric used to evaluate the performance of a model, representing the proportion of the variance in the dependent variable that is predictable from the independent variable."</data>
      <data key="d2">82ff270b1bbdfe0ee11e603de1e326c7</data>
    </node>
    <node id="&quot;RANDOM METHOD&quot;">
      <data key="d0">"EVENT"</data>
      <data key="d1">"The Random Method is the method used by Hyperopt to choose different sets of parameters."</data>
      <data key="d2">65ba78d1f678e080bd930319c54234ef</data>
    </node>
    <node id="&quot;CHOICE&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Choice is a parameter in the Hyperopt configuration, which is mentioned in the text."</data>
      <data key="d2">0982b8d1eb1e636b19fa2e9d9361e566</data>
    </node>
    <node id="&quot;LOGUNIFORM&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Loguniform is a parameter in the Hyperopt configuration, which is mentioned in the text."</data>
      <data key="d2">0982b8d1eb1e636b19fa2e9d9361e566</data>
    </node>
    <node id="&quot;BEST&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Best is a variable used to store the best hyperparameters found by the hyperparameter optimization process, which is mentioned in the text."</data>
      <data key="d2">0982b8d1eb1e636b19fa2e9d9361e566</data>
    </node>
    <node id="&quot;RESEARCH PAPER&quot;">
      <data key="d0">"EVENT"</data>
      <data key="d1">"The text appears to be a research paper or a documentation, as it discusses methods and results."</data>
      <data key="d2">870f29520f7a1c42eecb0c4ff855f09e</data>
    </node>
    <node id="&quot;SKLEARN.METRICS&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"sklearn.metrics is a library in Python used for evaluating machine learning models."</data>
      <data key="d2">9414efd266e7135a2cdd7461a888b045</data>
    </node>
    <node id="&quot;LPC (CEPSTRA)&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"LPC (cepstra) is a feature extraction method used in speech processing, which is used in the task of analyzing speaker data."</data>
      <data key="d2">688ebc7151bc148ac24dc7e2727d7afe</data>
    </node>
    <node id="&quot;SPEAKER DATA&quot;">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">688ebc7151bc148ac24dc7e2727d7afe</data>
    </node>
    <node id="&quot;LINEAR MODEL&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Linear Model is a component of ScikitLearnNode used to create a machine learning model for prediction."
"Linear Model is a concept used in machine learning, referring to models that predict a target variable based on a linear combination of input variables."</data>
      <data key="d2">dc3bd3697a140b64d70e0e3ac6db6c7e,eebc9d7d2b66e3898b7d068c38fd200f</data>
    </node>
    <node id="&quot;LASSO&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Lasso is a type of linear model used in the code for prediction."
"Lasso is a type of Linear Model that uses shrinkage to reduce the complexity of the model and prevent overfitting."</data>
      <data key="d2">dc3bd3697a140b64d70e0e3ac6db6c7e,eebc9d7d2b66e3898b7d068c38fd200f</data>
    </node>
    <node id="&quot;ACCURACY SCORE&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Accuracy Score is a metric used in the code to evaluate the performance of the prediction model."</data>
      <data key="d2">dc3bd3697a140b64d70e0e3ac6db6c7e</data>
    </node>
    <node id="&quot;SCIKIT-LEARN NODE&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Scikit-learn Node is a wrapper for using scikit-learn models in a node-based system."</data>
      <data key="d2">52d001cd1786e3d9f36e0c57538bc21e</data>
    </node>
    <node id="&quot;RESERVOIR MODEL&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"The Reservoir Model is a computing model that uses a reservoir of neurons to process data."</data>
      <data key="d2">0970cd32ce54f6ee1180ab237fdcefe1</data>
    </node>
    <node id="&quot;SK RIDGE&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"SK Ridge is a model used in the Reservoir Model, which is a type of regression algorithm."</data>
      <data key="d2">0970cd32ce54f6ee1180ab237fdcefe1</data>
    </node>
    <node id="&quot;SK LOGISTIC&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"SK Logistic is a model used in the Reservoir Model, which is a type of classification algorithm."</data>
      <data key="d2">0970cd32ce54f6ee1180ab237fdcefe1</data>
    </node>
    <node id="&quot;SK PERCEPTRON&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"SK Perceptron is a model used in the Reservoir Model, which is a type of binary classification algorithm."</data>
      <data key="d2">0970cd32ce54f6ee1180ab237fdcefe1</data>
    </node>
    <node id="&quot;SPEAKER&quot;">
      <data key="d0">"PERSON"</data>
      <data key="d1">"Speaker is a role or entity that is being predicted or classified by the Reservoir Model."</data>
      <data key="d2">0970cd32ce54f6ee1180ab237fdcefe1</data>
    </node>
    <node id="&quot;RESERVOIR COMPUTER&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Reservoir Computer is a type of computer system that uses a recurrent neural network with a sparsely connected hidden layer."</data>
      <data key="d2">dcd6355fc1ed8a61a1b70c50ce60fd36</data>
    </node>
    <node id="&quot;SPARSELY CONNECTED HIDDEN LAYER&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Sparsely Connected Hidden Layer is a component of a neural network with typically 1% connectivity."</data>
      <data key="d2">dcd6355fc1ed8a61a1b70c50ce60fd36</data>
    </node>
    <node id="&quot;AURESERVOIR&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"aureservoir is an efficient C++ library for various kinds of echo state networks with python/numpy bindings."
"aureservoir is an efficient C++ library for various kinds of echo state networks with python/numpy bindings."</data>
      <data key="d2">a4b801e70cf2ba3a3101d34899450087,dcd6355fc1ed8a61a1b70c50ce60fd36</data>
    </node>
    <node id="&quot;GAUSSIAN PROCESS MODEL&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Gaussian Process Model is a statistical model that uses Gaussian priors and an ESN-driven kernel function."</data>
      <data key="d2">a4b801e70cf2ba3a3101d34899450087</data>
    </node>
    <node id="&quot;MATLAB CODE&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Matlab code is an efficient implementation of an echo state network in Matlab."</data>
      <data key="d2">a4b801e70cf2ba3a3101d34899450087</data>
    </node>
    <node id="&quot;PYESN&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"pyESN is a simple echo state networks implementation in Python."</data>
      <data key="d2">a4b801e70cf2ba3a3101d34899450087</data>
    </node>
    <node id="&quot;SCHILLER AND STEIL&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"Schiller and Steil are researchers who demonstrated the use of the Backpropagation Decorrelation learning rule for RNNs, which is related to Reservoir Computing."
"Schiller and Steil are a research team that demonstrated the dominance of output weight changes in conventional training approaches for RNNs."</data>
      <data key="d2">158f53cd85edbb4f2e4c77b78c5e7acc,b32958d42199d47252887dc7be40ab5a</data>
    </node>
    <node id="&quot;DIFFERENTIAL EQUATIONS&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Differential Equations are mathematical equations that describe the relationship between a function and its derivatives."</data>
      <data key="d2">10112a11d47463e2aad7352c52922d61</data>
    </node>
    <node id="&quot;RANDOM, NONLINEAR MEDIUM&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"The fixed RNN acts as a random, nonlinear medium whose dynamic response is used as a signal base."</data>
      <data key="d2">10112a11d47463e2aad7352c52922d61</data>
    </node>
    <node id="&quot;AUTODIFFERENTIATION&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Autodifferentiation is a technique used in deep learning libraries to compute gradients automatically."
"Autodifferentiation is a technique used in deep learning libraries to automatically compute gradients, which has improved the efficiency and stability of neural network training."</data>
      <data key="d2">10112a11d47463e2aad7352c52922d61,4b89d9404fd683ecd03d5846ee2d86ce</data>
    </node>
    <node id="&quot;GRU&quot;">
      <data key="d0">"ORGANIZATION"</data>
      <data key="d1">"GRU is a type of recurrent neural network architecture that is similar to LSTM but with fewer gates."
"GRU is a type of recurrent neural network architecture that is similar to LSTM and is also used to address issues found in traditional RNNs."</data>
      <data key="d2">10112a11d47463e2aad7352c52922d61,4b89d9404fd683ecd03d5846ee2d86ce</data>
    </node>
    <node id="&quot;MECHANICAL NANOOSCILLATORS&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Mechanical Nanooscillators are a type of non-digital computer substrate that can be used as a reservoir in ESNs."
"Mechanical Nanooscillators are a type of object used as a nonlinear reservoir."</data>
      <data key="d2">4b89d9404fd683ecd03d5846ee2d86ce,7767d42e08c8eab856e8e3025c692309</data>
    </node>
    <node id="&quot;POLYMER MIXTURES&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Polymer Mixtures are a type of non-digital computer substrate that can be used as a reservoir in ESNs."
"Polymer Mixtures are a type of object used as a nonlinear reservoir."</data>
      <data key="d2">4b89d9404fd683ecd03d5846ee2d86ce,7767d42e08c8eab856e8e3025c692309</data>
    </node>
    <node id="&quot;NONLINEAR RESERVOIR&quot;">
      <data key="d0">"CONCEPT"</data>
      <data key="d1">"Nonlinear Reservoir is a concept used to describe the objects mentioned, which are used in a nonlinear context."</data>
      <data key="d2">7767d42e08c8eab856e8e3025c692309</data>
    </node>
    <edge source="&quot;RESERVOIR COMPUTING&quot;" target="&quot;CLASSIFICATION TASK&quot;">
      <data key="d4">2.0</data>
      <data key="d5">"Reservoir Computing is well-suited to Classification Tasks, as mentioned in the text."
"Reservoir Computing is also well-suited for classification tasks, as it captures the dynamic behavior of input sequences, providing rich representations for categorizing inputs into discrete classes."</data>
      <data key="d6">716940af834825642e01a3cb59a7e006,86a136730a696f1a817bd530dbff778d</data>
    </edge>
    <edge source="&quot;RESERVOIR COMPUTING&quot;" target="&quot;ECHO STATE NETWORKS&quot;">
      <data key="d4">4.0</data>
      <data key="d5">"Echo State Networks are a type of Reservoir Computing architecture."
"Echo State Networks are a type of Recurrent Neural Network that is based on the principles of Reservoir Computing."
"Echo State Networks are a type of neural network that falls under the concept of Reservoir Computing."
"Reservoir Computing is the underlying idea used in the construction of Echo State Networks, which are a variant of reservoir computing."</data>
      <data key="d6">158f53cd85edbb4f2e4c77b78c5e7acc,6de297d888d10db4c987b5eafc6398b2,8e16fc97c32c39d7961b52e21b99dc53,a3368f9cab1f65643dba089af5a1f95e</data>
    </edge>
    <edge source="&quot;RESERVOIR COMPUTING&quot;" target="&quot;RECURRENT NEURAL NETWORK&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Reservoir Computing is a type of Recurrent Neural Network architecture."</data>
      <data key="d6">8e16fc97c32c39d7961b52e21b99dc53</data>
    </edge>
    <edge source="&quot;RESERVOIR COMPUTING&quot;" target="&quot;SUPPORT VECTOR MACHINES&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Reservoir Computing is similar to Support Vector Machines in transforming inputs into dynamic, non-linear, high-dimensional representations."</data>
      <data key="d6">8e16fc97c32c39d7961b52e21b99dc53</data>
    </edge>
    <edge source="&quot;RESERVOIR COMPUTING&quot;" target="&quot;TIME SERIES FORECASTING&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Reservoir Computing is used in Time Series Forecasting tasks."</data>
      <data key="d6">8e16fc97c32c39d7961b52e21b99dc53</data>
    </edge>
    <edge source="&quot;RESERVOIR COMPUTING&quot;" target="&quot;SEQUENCE GENERATION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Reservoir Computing is used in Sequence Generation tasks."</data>
      <data key="d6">8e16fc97c32c39d7961b52e21b99dc53</data>
    </edge>
    <edge source="&quot;RESERVOIR COMPUTING&quot;" target="&quot;INRIA&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Inria has published a document on Reservoir Computing and maintains a reservoirPy page and a github repository."</data>
      <data key="d6">8e16fc97c32c39d7961b52e21b99dc53</data>
    </edge>
    <edge source="&quot;RESERVOIR COMPUTING&quot;" target="&quot;FEEDBACK CONNECTIONS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Feedback Connections in Reservoir Computing architectures help stabilize and control the activity of neurons in the reservoir."</data>
      <data key="d6">b5b73413fbe4ab8b61c4a939fe6c6a2b</data>
    </edge>
    <edge source="&quot;RESERVOIR COMPUTING&quot;" target="&quot;RESERVOIR NEURONS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Reservoir Neurons in Reservoir Computing architectures process input signals, and their connections do not need to be trained as they are predefined."</data>
      <data key="d6">b5b73413fbe4ab8b61c4a939fe6c6a2b</data>
    </edge>
    <edge source="&quot;RESERVOIR COMPUTING&quot;" target="&quot;RANDOM HIGH-DIMENSIONAL VECTOR&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Reservoir Computing uses a reservoir to generate a Random High-Dimensional Vector, which captures intricate patterns and dynamics of the input data."</data>
      <data key="d6">82a734e7c7ada95b1c99783140dd7168</data>
    </edge>
    <edge source="&quot;RESERVOIR COMPUTING&quot;" target="&quot;TIMESTEP&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Reservoir Computing processes data in discrete timesteps to make predictions or analyze time series data."</data>
      <data key="d6">56cde5dc9d350498c1544cd57733ca8f</data>
    </edge>
    <edge source="&quot;RESERVOIR COMPUTING&quot;" target="&quot;INPUT DATA&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Input Data is used as the input for the Reservoir Computing model to make predictions or analyze time series data."</data>
      <data key="d6">56cde5dc9d350498c1544cd57733ca8f</data>
    </edge>
    <edge source="&quot;RESERVOIR COMPUTING&quot;" target="&quot;STATE VECTOR&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The State Vector is the output of the Reservoir Computing model, representing the internal state of the reservoir at a given time."</data>
      <data key="d6">56cde5dc9d350498c1544cd57733ca8f</data>
    </edge>
    <edge source="&quot;RESERVOIR COMPUTING&quot;" target="&quot;NULL VECTOR&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Reservoir Computing often initializes the internal state of the reservoir to a null vector."</data>
      <data key="d6">baeb61b8c35e75d37a338fafd6a417fa</data>
    </edge>
    <edge source="&quot;RESERVOIR COMPUTING&quot;" target="&quot;SHAPE ATTRIBUTE&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The shape attribute is used to determine the size and structure of arrays in reservoir computing, such as the state vector."</data>
      <data key="d6">baeb61b8c35e75d37a338fafd6a417fa</data>
    </edge>
    <edge source="&quot;RESERVOIR COMPUTING&quot;" target="&quot;EMPTY FUNCTION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The empty function is used to create a new array without initializing the entries in reservoir computing, allowing for later data filling."</data>
      <data key="d6">baeb61b8c35e75d37a338fafd6a417fa</data>
    </edge>
    <edge source="&quot;RESERVOIR COMPUTING&quot;" target="&quot;OUTPUT DIMENSION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The output dimension is a key concept in reservoir computing, specifying the size of the output and used to determine the size of the state vector."</data>
      <data key="d6">baeb61b8c35e75d37a338fafd6a417fa</data>
    </edge>
    <edge source="&quot;RESERVOIR COMPUTING&quot;" target="&quot;FITTING PROCESS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Fitting Process is a common step in Reservoir Computing, where models learn the connections from the reservoir to the readout neurons based on the provided data."</data>
      <data key="d6">87757855658e1d198ec49a3290760dd5</data>
    </edge>
    <edge source="&quot;RESERVOIR COMPUTING&quot;" target="&quot;DEEP ARCHITECTURE&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Deep Architecture in reservoir computing refers to a model that contains multiple layers of reservoirs, connected in a hierarchical manner."</data>
      <data key="d6">a16039f06e545c915f8e7668c39c3e5c</data>
    </edge>
    <edge source="&quot;RESERVOIR COMPUTING&quot;" target="&quot;MACHINE LEARNING&quot;">
      <data key="d4">2.0</data>
      <data key="d5">"Reservoir Computing is a type of machine learning model that falls under the broader field of Machine Learning."
"Reservoir Computing is a field of Machine Learning that focuses on training Recurrent Neural Networks efficiently."</data>
      <data key="d6">6de297d888d10db4c987b5eafc6398b2,a16039f06e545c915f8e7668c39c3e5c</data>
    </edge>
    <edge source="&quot;RESERVOIR COMPUTING&quot;" target="&quot;COMPLEX MODELS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Complex Models are a subset of Reservoir Computing, focusing on more sophisticated and intricate models."</data>
      <data key="d6">22499cd4a0b7216dad5b05eb109fcb73</data>
    </edge>
    <edge source="&quot;RESERVOIR COMPUTING&quot;" target="&quot;REGRESSION TASK&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Reservoir Computing is well-suited for regression tasks, as it efficiently handles temporal and sequential data, making it ideal for predicting continuous outputs."</data>
      <data key="d6">716940af834825642e01a3cb59a7e006</data>
    </edge>
    <edge source="&quot;RESERVOIR COMPUTING&quot;" target="&quot;REGRESSION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Reservoir Computing is well-suited for regression tasks, as it efficiently handles temporal and sequential data, making it ideal for predicting continuous outputs."</data>
      <data key="d6">1c462a6eef00aac37dc1ab33a689b930</data>
    </edge>
    <edge source="&quot;RESERVOIR COMPUTING&quot;" target="&quot;CLASSIFICATION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Reservoir Computing is also well-suited for classification tasks, as it captures the dynamic behavior of input sequences, providing rich representations for categorizing inputs into discrete classes."</data>
      <data key="d6">1c462a6eef00aac37dc1ab33a689b930</data>
    </edge>
    <edge source="&quot;RESERVOIR COMPUTING&quot;" target="&quot;GRID SEARCH&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Grid Search is considered suboptimal for hyperparameter tuning in Reservoir Computing due to its inefficiency in sampling and poor coverage in important dimensions."</data>
      <data key="d6">b3361508c3e49b5bb3089f10e31d2c81</data>
    </edge>
    <edge source="&quot;RESERVOIR COMPUTING&quot;" target="&quot;RANDOM SEARCH&quot;">
      <data key="d4">2.0</data>
      <data key="d5">"Random Search is a more efficient hyperparameter tuning technique for Reservoir Computing compared to Grid Search, as it samples more efficiently and does not waste evaluations on dimensions that do not significantly impact performance."
"Random Search is a method used for hyperparameter exploration in Reservoir Computing, allowing for efficient sampling and optimization."</data>
      <data key="d6">4a9f33fa18891b67267b7615d61caaac,b3361508c3e49b5bb3089f10e31d2c81</data>
    </edge>
    <edge source="&quot;RESERVOIR COMPUTING&quot;" target="&quot;ECHO STATE PROPERTY (ESP)&quot;">
      <data key="d4">2.0</data>
      <data key="d5">"The Echo State Property (ESP) is a theoretical condition in Reservoir Computing that should not be strictly adhered to, as it may not be practical or necessary for all applications."
"Echo State Property (ESP) is a theoretical condition that applies to Reservoir Computing, but in practice, other conditions may be more optimal."</data>
      <data key="d6">4a9f33fa18891b67267b7615d61caaac,b3361508c3e49b5bb3089f10e31d2c81</data>
    </edge>
    <edge source="&quot;RESERVOIR COMPUTING&quot;" target="&quot;KEY HYPERPARAMETERS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Key Hyperparameters have a significant impact on the performance of Reservoir Computing tasks and should be focused on during hyperparameter exploration."</data>
      <data key="d6">4a9f33fa18891b67267b7615d61caaac</data>
    </edge>
    <edge source="&quot;RESERVOIR COMPUTING&quot;" target="&quot;ESN&quot;">
      <data key="d4">2.0</data>
      <data key="d5">"ESN is a type of reservoir used in the context of Reservoir Computing."
"ESN is a type of reservoir computing model."</data>
      <data key="d6">069ae9388dfd52fec9c184c7168f64dd,f730c6800099724052a2d061f3cd8c2e</data>
    </edge>
    <edge source="&quot;RESERVOIR COMPUTING&quot;" target="&quot;RESERVOIRPY&quot;">
      <data key="d4">3.0</data>
      <data key="d5">"ReservoirPy is a library that supports reservoir computing, which includes the use of Echo State Networks (ESNs) for timeseries prediction."
"Reservoirpy is a library specifically used for reservoir computing."
"ReservoirPy is a library for generating matrices used in reservoir computing."</data>
      <data key="d6">0b6c69085074b2cf23267eb149068b9f,2f4c992d69812866e6fce6dbb52d8612,ef85a7b1ca82dc1446ea71964d607a73</data>
    </edge>
    <edge source="&quot;RESERVOIR COMPUTING&quot;" target="&quot;INPUT SCALING&quot;">
      <data key="d4">3.0</data>
      <data key="d5">"Input Scaling is a parameter used in Reservoir Computing to adjust the influence of each variable in a multivariate time-series."
"Input Scaling is a parameter used in Reservoir Computing to adjust the influence of each variable in a multivariate time-series."
"Input Scaling is a parameter used in Reservoir Computing to adjust the strength of the input signal to the reservoir."</data>
      <data key="d6">26d78bc91458f47d4053954505c45f92,8553a88d9aaf4f71d359c721a1f6fa70,8ecf03267c90a64376f5040307d98195</data>
    </edge>
    <edge source="&quot;RESERVOIR COMPUTING&quot;" target="&quot;LEAKING RATE&quot;">
      <data key="d4">3.0</data>
      <data key="d5">"Leaking Rate is a parameter used in Reservoir Computing to control the rate at which the reservoir state decays over time."
"Leaking Rate is a parameter used in Reservoir Computing to control the decay of the reservoir's state over time."
"Leaking Rate is a parameter used in Reservoir Computing to control the rate at which information is lost from the reservoir."</data>
      <data key="d6">26d78bc91458f47d4053954505c45f92,8553a88d9aaf4f71d359c721a1f6fa70,8ecf03267c90a64376f5040307d98195</data>
    </edge>
    <edge source="&quot;RESERVOIR COMPUTING&quot;" target="&quot;CORRELATION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Correlation is a measure used in Reservoir Computing to determine the relationship between reservoir states and inputs."</data>
      <data key="d6">8553a88d9aaf4f71d359c721a1f6fa70</data>
    </edge>
    <edge source="&quot;RESERVOIR COMPUTING&quot;" target="&quot;TIME-SERIES DATA&quot;">
      <data key="d4">3.0</data>
      <data key="d5">"Reservoir Computing is being used to process Time-series Data."
"Reservoir Computing is used for processing Time-series Data."
"Time-series Data is being processed using Reservoir Computing to analyze and understand the underlying patterns and dynamics."</data>
      <data key="d6">26d78bc91458f47d4053954505c45f92,8553a88d9aaf4f71d359c721a1f6fa70,8ecf03267c90a64376f5040307d98195</data>
    </edge>
    <edge source="&quot;RESERVOIR COMPUTING&quot;" target="&quot;MULTIVARIATE TIME-SERIES&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Reservoir Computing is being used to process Multivariate Time-series Data, which consists of multiple variables or dimensions."</data>
      <data key="d6">8553a88d9aaf4f71d359c721a1f6fa70</data>
    </edge>
    <edge source="&quot;RESERVOIR COMPUTING&quot;" target="&quot;SPECTRAL RADIUS&quot;">
      <data key="d4">2.0</data>
      <data key="d5">"Spectral Radius is a parameter used in Reservoir Computing to determine the stability and speed of the reservoir's dynamics."
"Spectral Radius is a parameter used in Reservoir Computing to determine the stability and dynamics of the reservoir."</data>
      <data key="d6">26d78bc91458f47d4053954505c45f92,8ecf03267c90a64376f5040307d98195</data>
    </edge>
    <edge source="&quot;RESERVOIR COMPUTING&quot;" target="&quot;UNITS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Units refer to the number of processing elements in the reservoir of Reservoir Computing."</data>
      <data key="d6">8ecf03267c90a64376f5040307d98195</data>
    </edge>
    <edge source="&quot;RESERVOIR COMPUTING&quot;" target="&quot;RC CONNECTIVITY&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"RC Connectivity is a parameter used in Reservoir Computing to determine the sparsity of the connections between the reservoir units."</data>
      <data key="d6">8ecf03267c90a64376f5040307d98195</data>
    </edge>
    <edge source="&quot;RESERVOIR COMPUTING&quot;" target="&quot;INPUT CONNECTIVITY&quot;">
      <data key="d4">2.0</data>
      <data key="d5">"Input Connectivity is a parameter used in Reservoir Computing to determine the sparsity of the connections between the input variables and the reservoir units."
"Input Connectivity is a parameter used in Reservoir Computing to determine the connections between the input signal and the neurons in the reservoir."</data>
      <data key="d6">26d78bc91458f47d4053954505c45f92,8ecf03267c90a64376f5040307d98195</data>
    </edge>
    <edge source="&quot;RESERVOIR COMPUTING&quot;" target="&quot;ECHO STATE NETWORK&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Echo State Networks are a type of recurrent neural network architecture that falls under the umbrella term of Reservoir Computing."</data>
      <data key="d6">804bd76fa6f4950ef9a5cf8f0025fc1c</data>
    </edge>
    <edge source="&quot;RESERVOIR COMPUTING&quot;" target="&quot;LIQUID STATE MACHINES&quot;">
      <data key="d4">2.0</data>
      <data key="d5">"Liquid State Machines are a type of recurrent neural network architecture that falls under the umbrella term of Reservoir Computing."
"Liquid State Machines are a type of system that falls under the concept of Reservoir Computing."</data>
      <data key="d6">158f53cd85edbb4f2e4c77b78c5e7acc,804bd76fa6f4950ef9a5cf8f0025fc1c</data>
    </edge>
    <edge source="&quot;RESERVOIR COMPUTING&quot;" target="&quot;SCHILLER&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Schiller contributes to the understanding of reservoir computing by showing that dominant changes in traditional training methods are in the output weights."</data>
      <data key="d6">88ff8a7687e01f40b2c9d151b6e83d64</data>
    </edge>
    <edge source="&quot;RESERVOIR COMPUTING&quot;" target="&quot;STEIL&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Steil contributes to the understanding of reservoir computing by showing that dominant changes in traditional training methods are in the output weights."</data>
      <data key="d6">88ff8a7687e01f40b2c9d151b6e83d64</data>
    </edge>
    <edge source="&quot;RESERVOIR COMPUTING&quot;" target="&quot;PETER F. DOMINEY&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Peter F. Dominey has investigated mechanisms related to reservoir computing, such as speech recognition in the human brain."</data>
      <data key="d6">88ff8a7687e01f40b2c9d151b6e83d64</data>
    </edge>
    <edge source="&quot;RESERVOIR COMPUTING&quot;" target="&quot;K. KIRBY&quot;">
      <data key="d4">2.0</data>
      <data key="d5">"K. Kirby introduced the concept of reservoir computing in a conference contribution."
"K. Kirby disclosed the concept of reservoir computing in a conference contribution."</data>
      <data key="d6">88ff8a7687e01f40b2c9d151b6e83d64,b32958d42199d47252887dc7be40ab5a</data>
    </edge>
    <edge source="&quot;RESERVOIR COMPUTING&quot;" target="&quot;L. SCHOMAKER&quot;">
      <data key="d4">2.0</data>
      <data key="d5">"L. Schomaker described a method of obtaining a desired target output from an RNN by learning to combine signals from a randomly configured ensemble of spiking neural oscillators."
"L. Schomaker described a formulation of the reservoir computing idea known today, which involves the use of a randomly configured ensemble of spiking neural oscillators."</data>
      <data key="d6">88ff8a7687e01f40b2c9d151b6e83d64,a3368f9cab1f65643dba089af5a1f95e</data>
    </edge>
    <edge source="&quot;RESERVOIR COMPUTING&quot;" target="&quot;SEQUENCE PROCESSING&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Sequence Processing has been modelled using reservoir computing in cognitive neuroscience."</data>
      <data key="d6">88ff8a7687e01f40b2c9d151b6e83d64</data>
    </edge>
    <edge source="&quot;RESERVOIR COMPUTING&quot;" target="&quot;RECURRENT NEURAL NETWORKS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Reservoir Computing is a paradigm for training Recurrent Neural Networks while keeping the recurrent layer untrained."</data>
      <data key="d6">6de297d888d10db4c987b5eafc6398b2</data>
    </edge>
    <edge source="&quot;RESERVOIR COMPUTING&quot;" target="&quot;JAEGER&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Jaeger is a researcher who made significant contributions to the development of Reservoir Computing and Echo State Networks."</data>
      <data key="d6">6de297d888d10db4c987b5eafc6398b2</data>
    </edge>
    <edge source="&quot;RESERVOIR COMPUTING&quot;" target="&quot;DOMINEY&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Dominey is a researcher who made significant contributions to the development of Reservoir Computing and its applications in signal processing."</data>
      <data key="d6">6de297d888d10db4c987b5eafc6398b2</data>
    </edge>
    <edge source="&quot;RESERVOIR COMPUTING&quot;" target="&quot;BUONOMANO&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Buonomano is a researcher who made significant contributions to the development of Reservoir Computing and its applications in neuroscience."</data>
      <data key="d6">6de297d888d10db4c987b5eafc6398b2</data>
    </edge>
    <edge source="&quot;RESERVOIR COMPUTING&quot;" target="&quot;RC MODELS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Reservoir Computing is the method used to construct RC models."</data>
      <data key="d6">d622f95153798af8bb6f485db54aaea3</data>
    </edge>
    <edge source="&quot;RESERVOIR COMPUTING&quot;" target="&quot;MACKEY-GLASS TIMESERIES&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Reservoir Computing is used for chaotic timeseries forecasting, specifically mentioned to be used with Mackey-Glass Timeseries."</data>
      <data key="d6">2f4c992d69812866e6fce6dbb52d8612</data>
    </edge>
    <edge source="&quot;RESERVOIR COMPUTING&quot;" target="&quot;NUMPY&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Numpy is a library used in the context of reservoir computing, as it is mentioned in the text."</data>
      <data key="d6">2f4c992d69812866e6fce6dbb52d8612</data>
    </edge>
    <edge source="&quot;RESERVOIR COMPUTING&quot;" target="&quot;MATPLOTLIB&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Matplotlib is a library used in the context of reservoir computing, as it is mentioned in the text."</data>
      <data key="d6">2f4c992d69812866e6fce6dbb52d8612</data>
    </edge>
    <edge source="&quot;RESERVOIR COMPUTING&quot;" target="&quot;TASK 1: 10 TIMESTEPS AHEAD FORECAST&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Reservoir Computing is the method used in Task 1 to predict 10 timesteps ahead in the Mackey-Glass Time Series."</data>
      <data key="d6">fac681bdc38ae5829173c747ee6240fa</data>
    </edge>
    <edge source="&quot;RESERVOIR COMPUTING&quot;" target="&quot;DENSITY OF RESERVOIR INTERNAL MATRIX&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Density of Reservoir Internal Matrix is a parameter used in the Reservoir Computing method."</data>
      <data key="d6">2386633041e820b604fc4457264b5a33</data>
    </edge>
    <edge source="&quot;RESERVOIR COMPUTING&quot;" target="&quot;DENSITY OF RESERVOIR INPUT MATRIX&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Density of Reservoir Input Matrix is a parameter used in the Reservoir Computing method."</data>
      <data key="d6">2386633041e820b604fc4457264b5a33</data>
    </edge>
    <edge source="&quot;RESERVOIR COMPUTING&quot;" target="&quot;REGULARIZATION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Regularization is a parameter used in the Reservoir Computing method."</data>
      <data key="d6">2386633041e820b604fc4457264b5a33</data>
    </edge>
    <edge source="&quot;RESERVOIR COMPUTING&quot;" target="&quot;SEED&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Seed is a parameter used in the Reservoir Computing method."</data>
      <data key="d6">2386633041e820b604fc4457264b5a33</data>
    </edge>
    <edge source="&quot;RESERVOIR COMPUTING&quot;" target="&quot;PLOT GENERATION FUNCTION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Plot Generation Function is used in conjunction with the Reservoir Computing method for visualizing the generated timeseries data."</data>
      <data key="d6">2386633041e820b604fc4457264b5a33</data>
    </edge>
    <edge source="&quot;RESERVOIR COMPUTING&quot;" target="&quot;TIMESTEPS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Reservoir Computing processes data in discrete timesteps."</data>
      <data key="d6">9e84667b4aeb0789808517f0912043ce</data>
    </edge>
    <edge source="&quot;RESERVOIR COMPUTING&quot;" target="&quot;FEATURES&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Reservoir Computing takes arrays of shape (timesteps, features) as input."</data>
      <data key="d6">9e84667b4aeb0789808517f0912043ce</data>
    </edge>
    <edge source="&quot;RESERVOIR COMPUTING&quot;" target="&quot;STATES&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Reservoir Computing returns an array of shape (timesteps, states), representing the internal representations or memory of a reservoir node."</data>
      <data key="d6">9e84667b4aeb0789808517f0912043ce</data>
    </edge>
    <edge source="&quot;RESERVOIR COMPUTING&quot;" target="&quot;RIDGE READOUT&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Reservoir Computing is the method used to train the Ridge Readout."</data>
      <data key="d6">f2d5625f36aa4cb036089ce89ec607eb</data>
    </edge>
    <edge source="&quot;RESERVOIR COMPUTING&quot;" target="&quot;RIDGE&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Ridge is used as a regression model in the reservoir computing model."</data>
      <data key="d6">069ae9388dfd52fec9c184c7168f64dd</data>
    </edge>
    <edge source="&quot;RESERVOIR COMPUTING&quot;" target="&quot;RESERVOIR CONNECTIVITY&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Reservoir Connectivity is a parameter used in Reservoir Computing to determine the interconnections between neurons in the reservoir."</data>
      <data key="d6">26d78bc91458f47d4053954505c45f92</data>
    </edge>
    <edge source="&quot;RESERVOIR COMPUTING&quot;" target="&quot;BACKPROPAGATION DECORRELATION LEARNING RULE&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Backpropagation Decorrelation learning rule is a method for training RNNs that has been demonstrated to be related to Reservoir Computing."</data>
      <data key="d6">158f53cd85edbb4f2e4c77b78c5e7acc</data>
    </edge>
    <edge source="&quot;JAPANESE VOWEL DATASET&quot;" target="&quot;MALE SPEAKERS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Japanese Vowel Dataset is composed of utterances from 9 different male speakers."</data>
      <data key="d6">86a136730a696f1a817bd530dbff778d</data>
    </edge>
    <edge source="&quot;JAPANESE VOWEL DATASET&quot;" target="&quot;M. KUDO&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"M. Kudo is a reference mentioned in the text regarding the Japanese Vowel Dataset."</data>
      <data key="d6">86a136730a696f1a817bd530dbff778d</data>
    </edge>
    <edge source="&quot;JAPANESE VOWEL DATASET&quot;" target="&quot;J. TOYAMA&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"J. Toyama is a reference mentioned in the text regarding the Japanese Vowel Dataset."</data>
      <data key="d6">86a136730a696f1a817bd530dbff778d</data>
    </edge>
    <edge source="&quot;JAPANESE VOWEL DATASET&quot;" target="&quot;M. SHIMBO&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"M. Shimbo is a reference mentioned in the text regarding the Japanese Vowel Dataset."</data>
      <data key="d6">86a136730a696f1a817bd530dbff778d</data>
    </edge>
    <edge source="&quot;M. KUDO&quot;" target="&quot;MULTIDIMENSIONAL CURVE CLASSIFICATION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"M. Kudo is a co-author of a reference that discusses the technique of multidimensional curve classification."</data>
      <data key="d6">7cd25eb11825d9b9c2978d248997c3fe</data>
    </edge>
    <edge source="&quot;J. TOYAMA&quot;" target="&quot;MULTIDIMENSIONAL CURVE CLASSIFICATION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"J. Toyama is a co-author of a reference that discusses the technique of multidimensional curve classification."</data>
      <data key="d6">7cd25eb11825d9b9c2978d248997c3fe</data>
    </edge>
    <edge source="&quot;M. SHIMBO&quot;" target="&quot;MULTIDIMENSIONAL CURVE CLASSIFICATION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"M. Shimbo is a co-author of a reference that discusses the technique of multidimensional curve classification."</data>
      <data key="d6">7cd25eb11825d9b9c2978d248997c3fe</data>
    </edge>
    <edge source="&quot;CLASSIFICATION TASK&quot;" target="&quot;RIDGECLASSIFIER&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"RidgeClassifier is a model used for the machine learning task of Classification."</data>
      <data key="d6">f5358a50d00a1cac02dd4ad8fcb167ee</data>
    </edge>
    <edge source="&quot;CLASSIFICATION TASK&quot;" target="&quot;LOGISTICREGRESSION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"LogisticRegression is a model used for the machine learning task of Classification."</data>
      <data key="d6">f5358a50d00a1cac02dd4ad8fcb167ee</data>
    </edge>
    <edge source="&quot;CLASSIFICATION TASK&quot;" target="&quot;PERCEPTRON&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Perceptron is a model used for the machine learning task of Classification."</data>
      <data key="d6">f5358a50d00a1cac02dd4ad8fcb167ee</data>
    </edge>
    <edge source="&quot;CLASSIFICATION TASK&quot;" target="&quot;RESERVOIR&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Reservoir concept is used in the machine learning task of Classification."</data>
      <data key="d6">f5358a50d00a1cac02dd4ad8fcb167ee</data>
    </edge>
    <edge source="&quot;UCI MACHINE LEARNING REPOSITORY&quot;" target="&quot;JAPANESE VOWELS DATASET&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"UCI Machine Learning Repository is the source of the Japanese Vowels Dataset, providing the audio signals for analysis."</data>
      <data key="d6">7cd25eb11825d9b9c2978d248997c3fe</data>
    </edge>
    <edge source="&quot;JAPANESE VOWELS DATASET&quot;" target="&quot;RESERVOIRPY LIBRARY&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Japanese Vowels Dataset is used in the ReservoirPy Library, specifically in the `japanese_vowels()` function for classification tasks."</data>
      <data key="d6">c1ba6d7a4f4bd16c4fd25baf07c9747c</data>
    </edge>
    <edge source="&quot;JAPANESE VOWELS DATASET&quot;" target="&quot;RESERVOIRPY&quot;">
      <data key="d4">2.0</data>
      <data key="d5">"ReservoirPy provides the Japanese Vowels dataset, which is used for classification tasks involving spoken utterances."
"ReservoirPy is used to analyze the Japanese Vowels Dataset."</data>
      <data key="d6">870f29520f7a1c42eecb0c4ff855f09e,9f7337ee2d87543ced3b99dcae344b13</data>
    </edge>
    <edge source="&quot;JAPANESE VOWELS DATASET&quot;" target="&quot;LINEAR PREDICTION COEFFICIENTS (LPCS)&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Japanese Vowels dataset uses Linear Prediction Coefficients (LPCs) as features to analyze speech signals."</data>
      <data key="d6">9f7337ee2d87543ced3b99dcae344b13</data>
    </edge>
    <edge source="&quot;JAPANESE VOWELS DATASET&quot;" target="&quot;SPEAKER IDENTIFIERS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Japanese Vowels dataset uses speaker identifiers as labels to classify spoken utterances to their respective speakers."</data>
      <data key="d6">9f7337ee2d87543ced3b99dcae344b13</data>
    </edge>
    <edge source="&quot;JAPANESE VOWELS DATASET&quot;" target="&quot;BOXPLOT&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"A boxplot is a graphical representation used to visualize and analyze the distribution of data in the Japanese Vowels dataset."</data>
      <data key="d6">9f7337ee2d87543ced3b99dcae344b13</data>
    </edge>
    <edge source="&quot;JAPANESE VOWELS DATASET&quot;" target="&quot;SEQUENCE-TO-SEQUENCE ENCODING&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Sequence-to-sequence encoding is a method used to solve tasks involving the Japanese Vowels dataset, such as classifying spoken utterances."</data>
      <data key="d6">9f7337ee2d87543ced3b99dcae344b13</data>
    </edge>
    <edge source="&quot;JAPANESE VOWELS DATASET&quot;" target="&quot;SCIKITLEARNNODE&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Japanese Vowels Dataset is used to demonstrate the machine learning models provided by ScikitLearnNode."</data>
      <data key="d6">35631fbf2ad11c53d75cb9b42e2c39b4</data>
    </edge>
    <edge source="&quot;JAPANESE VOWELS DATASET&quot;" target="&quot;SCIKIT-LEARN&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Japanese Vowels Dataset is used in the context of machine learning tasks, and scikit-learn provides classifiers for handling this data."</data>
      <data key="d6">d58662ee42c14a0787d839ebfd0a6e9b</data>
    </edge>
    <edge source="&quot;JAPANESE VOWELS DATASET&quot;" target="&quot;SKLEARN&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Sklearn is used to calculate accuracy score for the Japanese Vowels Dataset."</data>
      <data key="d6">870f29520f7a1c42eecb0c4ff855f09e</data>
    </edge>
    <edge source="&quot;JAPANESE VOWELS DATASET&quot;" target="&quot;RESEARCH PAPER&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Japanese Vowels Dataset is used in the research paper."</data>
      <data key="d6">870f29520f7a1c42eecb0c4ff855f09e</data>
    </edge>
    <edge source="&quot;MULTIDIMENSIONAL CURVE CLASSIFICATION&quot;" target="&quot;PATTERN RECOGNITION LETTERS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Multidimensional Curve Classification is a technique discussed in a reference published in Pattern Recognition Letters."</data>
      <data key="d6">7cd25eb11825d9b9c2978d248997c3fe</data>
    </edge>
    <edge source="&quot;CEPSTRA&quot;" target="&quot;RESERVOIRPY&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"cepstra is a feature extraction technique used in the ReservoirPy library for processing audio data."</data>
      <data key="d6">79d5959f3f6471cad55498ab4a8a3176</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;SEQUENCE-TO-SEQUENCE MODEL&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Sequence-to-sequence model is a type of machine learning model used in the ReservoirPy library for processing sequences, such as audio data."</data>
      <data key="d6">79d5959f3f6471cad55498ab4a8a3176</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;SIMPLE ECHO STATE NETWORK&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"ReservoirPy is used to build the Simple Echo State Network model."</data>
      <data key="d6">75c1234e634cf2c009a116e4ee6c053e</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;SEQUENCE-TO-VECTOR MODEL&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"ReservoirPy is used to create Sequence-to-Vector Models for data analysis and prediction."</data>
      <data key="d6">64b0ff9558a0f4794c16619aa76354c4</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;DATA ANALYSIS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"ReservoirPy is used for creating reservoir computing models, which are used for data analysis."</data>
      <data key="d6">64b0ff9558a0f4794c16619aa76354c4</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;PREDICTION&quot;">
      <data key="d4">2.0</data>
      <data key="d5">"ReservoirPy is used for creating reservoir computing models, which are used for prediction."
"ReservoirPy is used to make predictions about future data using trained reservoir computing models."</data>
      <data key="d6">64b0ff9558a0f4794c16619aa76354c4,c82c9d05b211ff65131f70eb8cb13513</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;RESERVOIR&quot;">
      <data key="d4">14.0</data>
      <data key="d5">"ReservoirPy is used to create and train reservoir computing models, which include the Reservoir component."
"ReservoirPy is a library that creates and works with reservoir computing networks, including reservoirs."
"ReservoirPy provides the Reservoir node, which implements the reservoir computing concept."
"Reservoirpy is a library that provides the Reservoir component for reservoir computing models."
"reservoirpy contains the Reservoir tool for high dimensional embedding of timeseries."
"reservoirpy is a toolbox that contains different architectures of reservoirs, which are a key component of Reservoir Computing algorithms."
"ReservoirPy is a library that provides functionality for creating and working with reservoirs in reservoir computing models."
"ReservoirPy provides the Reservoir node, which can be triggered on single timesteps or complete timeseries."
"ReservoirPy contains a node for creating Reservoirs, which are a component of ESNs."
"ReservoirPy is used to create and work with reservoir computing models, which include the Reservoir component."
"Reservoirpy is used to generate matrices for a concept called Reservoir."
"ReservoirPy is used to create and configure reservoirs, which are a core component of echo state networks (ESNs)."
"ReservoirPy is used for creating reservoir computing models, which include reservoirs as components."
"ReservoirPy is used to create and configure reservoir computing networks, including the reservoir component."</data>
      <data key="d6">00d22666fe697ffb66c2392939f45b39,0e0afab060f214d46062c9886e762002,1ea13fb2c1fff4954b699a8e2377f99f,2336a57d055095c6ffa9d156ddee0096,324a8f3fb4d19b91457a99999e6d3d17,3a3b7a67b23341dcd1b04ec5b61683f6,3ae4ccee74392bfe317d8132e99a3aa9,6daefaa8fbd5c1492f2d832d79841463,94fd1ebf256db17e4ac2255b89caa473,b03e2cc6fe2648e792c1d5f1ec5773a3,c82c9d05b211ff65131f70eb8cb13513,cb71a9bc3b00e7abcd1a53004abdea69,e39809b687cd044a7918eca37727a188,f5358a50d00a1cac02dd4ad8fcb167ee</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;RIDGE&quot;">
      <data key="d4">13.0</data>
      <data key="d5">"ReservoirPy is used to create and train reservoir computing models, which include the Ridge component for training the readout."
"Reservoirpy is a library that provides the Ridge component for reservoir computing models."
"reservoirpy contains the Ridge tool that learns connections through Tikhonov linear regression."
"reservoirpy includes the Ridge concept, which is used as a readout in the provided code example."
"ReservoirPy includes the Ridge regularization technique, which can be used to prevent overfitting in machine learning models."
"Ridge is a type of node within the ReservoirPy library or framework."
"ReservoirPy is a library that provides functionality for creating and working with Ridge regression models."
"ReservoirPy contains a node for creating Ridge readouts, which are used for regularization in machine learning."
"ReservoirPy is used to create and work with reservoir computing models that include the Ridge component for data prediction and analysis."
"Ridge is a type of linear regression used in ReservoirPy for tasks such as time series prediction and data analysis."
"ReservoirPy is used to create and configure ridge readouts, which are used in the readout stage of echo state networks (ESNs)."
"ReservoirPy is used for creating reservoir computing models, which include Ridge as a type of readout or output layer."
"ReservoirPy is used to create and work with Ridge, a component in a reservoir model."</data>
      <data key="d6">00d22666fe697ffb66c2392939f45b39,1ea13fb2c1fff4954b699a8e2377f99f,2336a57d055095c6ffa9d156ddee0096,3ae4ccee74392bfe317d8132e99a3aa9,3bee7b78d0ab9582cc9bffe9e305df2e,6daefaa8fbd5c1492f2d832d79841463,7b9936d57ece8ba985947a7aca12e2c7,7f70879016c133fe58e4838172a69613,8648b5740b93d805f139d9745e1171e8,94fd1ebf256db17e4ac2255b89caa473,b03e2cc6fe2648e792c1d5f1ec5773a3,c82c9d05b211ff65131f70eb8cb13513,e39809b687cd044a7918eca37727a188</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;INPUT&quot;">
      <data key="d4">4.0</data>
      <data key="d5">"ReservoirPy is used to create and train reservoir computing models, which include the Input component for feeding input sequences into the model."
"ReservoirPy is used to create and work with reservoir computing models that include the Input component for providing data to be processed and analyzed."
"ReservoirPy is used for creating reservoir computing models, which include input data or signals as components."
"ReservoirPy is used to create and work with Input, a component in a reservoir model."</data>
      <data key="d6">1ea13fb2c1fff4954b699a8e2377f99f,8648b5740b93d805f139d9745e1171e8,c82c9d05b211ff65131f70eb8cb13513,e39809b687cd044a7918eca37727a188</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;JAPANESE VOWELS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Japanese Vowels dataset is used for training and testing the reservoir computing model created using ReservoirPy."</data>
      <data key="d6">1ea13fb2c1fff4954b699a8e2377f99f</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;ECHO STATE NETWORKS&quot;">
      <data key="d4">4.0</data>
      <data key="d5">"ReservoirPy is a library that includes the development of Echo State Networks."
"ReservoirPy is a library used for creating and analyzing reservoir computing systems, including Echo State Networks."
"ReservoirPy is a library used for creating and working with echo state networks."
"ReservoirPy is a library used for building and training Echo State Networks."</data>
      <data key="d6">41fa16855df7da666dc6fc38d2f8ee53,73e81fd6509a2ba400a8435793ade3c5,83fafb2423a01afae7e522917d79ace9,ed28ba3543e07641536ff1eb5e0749dd</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;RESERVOIRPY DOCUMENTATION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"ReservoirPy documentation is a resource where more information about the library and its components can be found."</data>
      <data key="d6">83fafb2423a01afae7e522917d79ace9</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;ESNS&quot;">
      <data key="d4">2.0</data>
      <data key="d5">"ReservoirPy is used for creating Echo State Networks."
"ReservoirPy is a library for creating and training Echo State Networks (ESNs)."</data>
      <data key="d6">6be085e79e86abc5b1a7eaff6bda1ec5,7f2d69f9a9baca70ffd25a6865189206</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;REAL-VALUED CONTINUOUS DATA&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"ReservoirPy requires Real-Valued Continuous Data to be formatted as NumPy arrays of shape (timesteps, features) to avoid unexpected results or errors."</data>
      <data key="d6">e94f386a2ed7de2156b4864797cc199e</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;DISCRETE NUMERIC DATA&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"ReservoirPy requires Discrete Numeric Data to be formatted as NumPy arrays of shape (timesteps, features) to avoid unexpected results or errors."</data>
      <data key="d6">e94f386a2ed7de2156b4864797cc199e</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;DISCRETE SYMBOLIC DATA&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"ReservoirPy requires Discrete Symbolic Data to be formatted as NumPy arrays of shape (timesteps, features) to avoid unexpected results or errors."</data>
      <data key="d6">e94f386a2ed7de2156b4864797cc199e</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;NUMPY ARRAY&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"ReservoirPy stores data in Numpy arrays, which are powerful n-dimensional array objects."</data>
      <data key="d6">f838f4cbb7060f4409ba2d174a396fb1</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;NUMPY&quot;">
      <data key="d4">10.0</data>
      <data key="d5">"NumPy is a fundamental package used by ReservoirPy for scientific computing and for storing data in N-dimensional arrays."
"ReservoirPy allows parameters to be initialized using Numpy arrays or sparse matrices of correct shape."
"ReservoirPy uses Numpy for data storage and manipulation."
"Numpy is a library used for numerical computing in ReservoirPy, and it is used to store and manipulate data."
"ReservoirPy uses Numpy for handling and processing the sine wave data."
"ReservoirPy uses Numpy for numerical computations and handling arrays."
"ReservoirPy uses Numpy to generate and manipulate matrices."
"ReservoirPy uses Numpy for numerical computing, such as creating and manipulating arrays and matrices."
"Numpy is used in ReservoirPy for numerical computing."
"NumPy is used in the ReservoirPy library for numerical computing tasks."</data>
      <data key="d6">34b9ce80a22112b32e063179511af6e0,37549a8af907ce182bd36eec43002a7d,50d4e4aab1823b8df6573ccf227f24d0,5732296d26c7a572dc90d4af1172626a,74c073137c970e32982756d008532cb8,7b9936d57ece8ba985947a7aca12e2c7,8648b5740b93d805f139d9745e1171e8,a58317c7e13f27d513fc7671fd187ecb,ef85a7b1ca82dc1446ea71964d607a73,fe90abb0dde126fafbf44782aeb6738c</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;SCIPY&quot;">
      <data key="d4">6.0</data>
      <data key="d5">"SciPy is used by ReservoirPy for scientific and technical computing, providing algorithms and functions for optimization and integration."
"ReservoirPy uses Scipy for mathematical functions and convenience functions, such as for optimization and statistics."
"ReservoirPy uses Scipy for computations."
"Scipy is a library used for scientific computing in ReservoirPy, and it is used in computations within the library."
"ReservoirPy uses Scipy to generate sparse matrices."
"ReservoirPy may use Scipy for additional mathematical functions and optimization."</data>
      <data key="d6">37549a8af907ce182bd36eec43002a7d,5732296d26c7a572dc90d4af1172626a,74c073137c970e32982756d008532cb8,7b9936d57ece8ba985947a7aca12e2c7,ef85a7b1ca82dc1446ea71964d607a73,fe90abb0dde126fafbf44782aeb6738c</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;GITHUB&quot;">
      <data key="d4">2.0</data>
      <data key="d5">"ReservoirPy is a Python library for reservoir computing, and its documentation can be found on GitHub."
"ReservoirPy encourages users to propose new implementations, which are added to the GitHub repository."</data>
      <data key="d6">77c3759b4ed32509aaf1403c6fa8030f,fcac967511cf2b019fd856e23d2e91d9</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;ECHO STATE NETWORKS (ESNS)&quot;">
      <data key="d4">6.0</data>
      <data key="d5">"ReservoirPy is a library used for creating and analyzing Echo State Networks (ESNs)."
"ReservoirPy is used to create and work with Echo State Networks (ESNs)."
"reservoirpy is a tool that focuses on the design and training of Echo State Networks (ESNs), which are a type of model in the field of Reservoir Computing (RC)."
"ReservoirPy is a library used for training and running Echo State Networks (ESNs)."
"ReservoirPy supports the creation and use of Echo State Networks (ESNs)."
"ReservoirPy is a library used to create Echo State Networks (ESNs)."</data>
      <data key="d6">01f8dd8235ba0d4cf0837b5ea958ec95,18910a60b2547ec3133340f42c45bb47,37549a8af907ce182bd36eec43002a7d,74c073137c970e32982756d008532cb8,a2b183778107462d474c53e4ec0a9221,af2db1cc5ab6b16acae2c93d3facb668</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;NP.PI&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"np.pi is a mathematical constant used in a line of code within the context of the ReservoirPy library."</data>
      <data key="d6">01f8dd8235ba0d4cf0837b5ea958ec95</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;CONTEXT MANAGER&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Context Manager is a concept used in the ReservoirPy library, allowing for temporary modifications of the reservoir's state without permanently altering it."</data>
      <data key="d6">58330f62da357197950f63388e4ceaff</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;FROM_STATE&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The 'from_state' parameter in ReservoirPy is used to initialize the reservoir with a specific state at the start of a simulation or training process."</data>
      <data key="d6">58330f62da357197950f63388e4ceaff</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;WITH_STATE&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The 'with_state' parameter in ReservoirPy is used to temporarily change the state of the reservoir for operations inside a block of code."</data>
      <data key="d6">58330f62da357197950f63388e4ceaff</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;PARALLELIZATION&quot;">
      <data key="d4">2.0</data>
      <data key="d5">"ReservoirPy supports the use of parallelization to train and run multiple reservoirs or nodes simultaneously, enhancing computational efficiency."
"ReservoirPy supports parallelization, allowing for faster training of ESNs."</data>
      <data key="d6">a16039f06e545c915f8e7668c39c3e5c,ead6383a44acd8ebd17907b85a910455</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;DEEP ARCHITECTURES&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Deep Architectures are models that can be created and worked with using the ReservoirPy library."</data>
      <data key="d6">8965403859beb43a6ab7e5c8c916b857</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;INPUT-TO-READOUT CONNECTIONS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Input-to-readout connections are a feature implemented in the ReservoirPy library for Echo State Networks."</data>
      <data key="d6">8965403859beb43a6ab7e5c8c916b857</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;ECHO STATE NETWORK (ESN)&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"ReservoirPy is a software library used for creating and working with Echo State Networks (ESNs), which include the Reservoir and Readout Layer components."</data>
      <data key="d6">4da651284dbab3f68dc3cae41e6e0311</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;RESERVOIRPY.MAT_GEN&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"ReservoirPy is the parent organization of the reservoirpy.mat_gen submodule."</data>
      <data key="d6">8f2f2cfd667a304a288723de779c9bee</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;ESN&quot;">
      <data key="d4">12.0</data>
      <data key="d5">"ESN is a type of recurrent neural network that can be created and worked with using the ReservoirPy library."
"ReservoirPy is a library that includes the implementation of Echo State Networks (ESNs) for timeseries prediction."
"reservoirpy is used to create an Echo State Network (ESN) for training and forecasting."
"ReservoirPy is used to create and work with Echo State Networks (ESNs), which are used for prediction and generation tasks."
"ReservoirPy provides a special node for Echo State Networks (ESN), which can be used for offline training with ridge regression in a distributed way."
"ESN is a type of node within the ReservoirPy library or framework."
"ReservoirPy is mentioned for creating and working with ESNs, including the Reservoir and Ridge nodes."
"ReservoirPy is used for creating and training ESNs, which are a type of recurrent neural network."
"ReservoirPy is used to create and train Echo State Networks (ESNs), which are used for time series prediction and analysis."
"ESN is a type of recurrent neural network used in ReservoirPy for tasks such as time series prediction and data analysis."
"ReservoirPy is used to create and train echo state networks (ESNs), which are a type of recurrent neural network."
"ESN is a machine learning model developed by the ReservoirPy library."</data>
      <data key="d6">00d22666fe697ffb66c2392939f45b39,09ea760dd2f000c961d1cfd4ea795da5,0b6c69085074b2cf23267eb149068b9f,3ae4ccee74392bfe317d8132e99a3aa9,3bee7b78d0ab9582cc9bffe9e305df2e,593080a95ef7640b3925b07cad1bedd4,7b9936d57ece8ba985947a7aca12e2c7,7f70879016c133fe58e4838172a69613,cdc64af0dde941250d89b191d0666c9b,d7ac2f6fb13af389417785f2f3152c52,eb7a223eeb120e3fcc45a96a6018707d,fe90abb0dde126fafbf44782aeb6738c</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;UNITS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"ReservoirPy uses the UNITS hyperparameter to configure the number of neurons inside the reservoir."</data>
      <data key="d6">a8df60a94e25d863b436f47f4f8e6a6d</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;SPECTRAL_RADIUS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"ReservoirPy uses the SPECTRAL_RADIUS hyperparameter to influence the dynamics' stability and chaos."</data>
      <data key="d6">a8df60a94e25d863b436f47f4f8e6a6d</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;INPUT_SCALING&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"ReservoirPy uses the INPUT_SCALING hyperparameter to influence the correlation between states and inputs."</data>
      <data key="d6">a8df60a94e25d863b436f47f4f8e6a6d</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;OBJECTIVE FUNCTION&quot;">
      <data key="d4">3.0</data>
      <data key="d5">"ReservoirPy accepts objective functions, such as the Root Mean Squared Error (RMSE) and R-squared (R^2), to optimize parameters."
"ReservoirPy accepts Objective Functions with certain conventions, such as the requirement for a 'loss' key in the returned dictionary."
"The objective function is used by ReservoirPy to define the goal of the hyperparameter optimization process."</data>
      <data key="d6">4f7b43545046f0e6f9b6fb3816da1d79,9abdbd696e340cb5dd8c66ac5cd30c67,d4684af3c445d312afe4d838abc45502</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;HYPERPARAMETER OPTIMIZATION&quot;">
      <data key="d4">2.0</data>
      <data key="d5">"ReservoirPy is used for the process of Hyperparameter Optimization."
"ReservoirPy is a library used for Hyperparameter Optimization."</data>
      <data key="d6">d4684af3c445d312afe4d838abc45502,f70c7d3d89baaabbeaad57b58e379e08</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;HYPEROPT&quot;">
      <data key="d4">5.0</data>
      <data key="d5">"ReservoirPy uses Hyperopt to search for the best set of hyperparameters that minimize the loss function."
"ReservoirPy can be used with Hyperopt for hyperparameter optimization."
"reservoirpy is mentioned in the context of Hyperopt, a Python library for optimizing machine learning algorithms."
"ReservoirPy is mentioned in the context of using Hyperopt for hyperparameter optimization."
"ReservoirPy is used in conjunction with Hyperopt for hyperparameter optimization."</data>
      <data key="d6">0982b8d1eb1e636b19fa2e9d9361e566,870f29520f7a1c42eecb0c4ff855f09e,9abdbd696e340cb5dd8c66ac5cd30c67,a3a74dc4754a8c8b0730f808285893e2,c5413fef3b2d7e4d688c66e6046b56c7</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;DATASET&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The dataset is the input data used for training and evaluating machine learning models in ReservoirPy."</data>
      <data key="d6">9abdbd696e340cb5dd8c66ac5cd30c67</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;JSON FILE&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The JSON file is a configuration file used by ReservoirPy to specify the details of the hyperparameter optimization process."</data>
      <data key="d6">9abdbd696e340cb5dd8c66ac5cd30c67</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;LOSS FUNCTION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The loss function is used by ReservoirPy to evaluate the performance of machine learning models during the hyperparameter optimization process."</data>
      <data key="d6">9abdbd696e340cb5dd8c66ac5cd30c67</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;HYPERPARAMETERS&quot;">
      <data key="d4">3.0</data>
      <data key="d5">"Hyperparameters are the variables that are set before training a machine learning model in ReservoirPy, and their values can significantly impact the model's performance."
"ReservoirPy includes tools for exploring and optimizing Hyperparameters."
"ReservoirPy provides tools for optimizing hyperparameters, such as the Leaking Rate, to improve the performance of the model."</data>
      <data key="d6">2d8ea1123f365fb047b024022ba4fdc4,9abdbd696e340cb5dd8c66ac5cd30c67,d1047d9e322054de394b880adaf6b536</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;HYPER-PARAMETER EXPLORATION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"ReservoirPy is used for hyper-parameter exploration, which involves searching through a space of possible hyper-parameters to find the best combination for a given task."</data>
      <data key="d6">716940af834825642e01a3cb59a7e006</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;SCIKITLEARNNODE&quot;">
      <data key="d4">2.0</data>
      <data key="d5">"ReservoirPy includes the ScikitLearnNode component, which allows for the integration of Scikit-Learn models into ReservoirPy workflows."
"ScikitLearnNode is a component of the ReservoirPy library, which is used for creating and training reservoir computing networks."</data>
      <data key="d6">8c66981c9d2009113219bbf2681f664c,c05906c1f12c4edfc32a04aa9935067e</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;THE AUTHOR&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The author uses ReservoirPy to create and train the model."</data>
      <data key="d6">b3c8de6f33c2ebb84f0d2797933d0cad</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;SCIKIT-LEARN&quot;">
      <data key="d4">5.0</data>
      <data key="d5">"ReservoirPy is used in conjunction with scikit-learn for creating and working with reservoirs, which are used in machine learning and data processing."
"ReservoirPy is used in conjunction with Scikit-learn to create machine learning models."
"reservoirpy and scikit-learn both offer high-level APIs for machine learning tasks, but reservoirpy is specifically designed for Reservoir Computing."
"scikit-learn tools are integrated within reservoirpy in a transparent way, indicating a relationship between the two organizations."
"ReservoirPy is used to integrate with Scikit-Learn, allowing the use of Scikit-Learn's machine learning models within ReservoirPy's reservoir computing framework."</data>
      <data key="d6">82de30f43839f4985de20a981b524af1,d58662ee42c14a0787d839ebfd0a6e9b,d622f95153798af8bb6f485db54aaea3,eebc9d7d2b66e3898b7d068c38fd200f,f5358a50d00a1cac02dd4ad8fcb167ee</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;PYTHON 3.8&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"ReservoirPy supports Python 3.8 and higher."</data>
      <data key="d6">d1047d9e322054de394b880adaf6b536</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;@RESERVOIRPY&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"@reservoirpy shares updates and new releases about ReservoirPy."</data>
      <data key="d6">d1047d9e322054de394b880adaf6b536</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;OFFICIAL DOCUMENTATION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Official Documentation is a resource provided by ReservoirPy to learn more about its features, API, and installation process."</data>
      <data key="d6">d1047d9e322054de394b880adaf6b536</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;USER GUIDE&quot;">
      <data key="d4">2.0</data>
      <data key="d5">"User Guide is a resource provided by ReservoirPy that offers tutorials for learning how to use its features."
"ReservoirPy comes with a User Guide that provides tutorials and instructions for using the library."</data>
      <data key="d6">a2b183778107462d474c53e4ec0a9221,d1047d9e322054de394b880adaf6b536</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;DEEP RESERVOIR&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"ReservoirPy supports the creation of Deep Reservoir architectures."</data>
      <data key="d6">d1047d9e322054de394b880adaf6b536</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;MACKEY-GLASS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Mackey-Glass is used as an example in the ReservoirPy documentation for predicting chaotic behavior."</data>
      <data key="d6">d1047d9e322054de394b880adaf6b536</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;DEEP-ESN ARCHITECTURE&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"ReservoirPy is used to create and work with Deep-ESN Architectures."</data>
      <data key="d6">a2b183778107462d474c53e4ec0a9221</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;MACKEY-GLASS TIMESERIES&quot;">
      <data key="d4">4.0</data>
      <data key="d5">"ReservoirPy provides a dataset generator for creating Mackey-Glass Timeseries."
"reservoirpy is used for forecasting with the Mackey-Glass timeseries in the example section."
"reservoirpy is used to train and predict the Mackey-Glass timeseries in the provided code example."
"ReservoirPy is used to create and work with reservoirs, which are used in the provided code to analyze the Mackey-Glass Timeseries dataset."</data>
      <data key="d6">4073cafddb73621f26061385c5570659,6daefaa8fbd5c1492f2d832d79841463,a1adb5de4156f0a4a448caf79056e886,a2b183778107462d474c53e4ec0a9221</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;PYTHON NOTEBOOKS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Python Notebooks are used in the tutorials folder of ReservoirPy for data analysis and visualization, demonstrating the library's capabilities."</data>
      <data key="d6">0b6c69085074b2cf23267eb149068b9f</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;PIP&quot;">
      <data key="d4">2.0</data>
      <data key="d5">"Pip is used to install and manage ReservoirPy, a Python library for reservoir computing."
"ReservoirPy is installed using pip, a package installer for Python."</data>
      <data key="d6">0b6c69085074b2cf23267eb149068b9f,c5413fef3b2d7e4d688c66e6046b56c7</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;REQUIREMENTS FILE&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The requirements file lists the packages needed for running Python Notebooks in the tutorials folder, which includes ReservoirPy."</data>
      <data key="d6">c5413fef3b2d7e4d688c66e6046b56c7</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;TUTORIAL FOLDER&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Tutorial folder contains tutorials in Jupyter Notebooks, demonstrating the use of ReservoirPy."</data>
      <data key="d6">c5413fef3b2d7e4d688c66e6046b56c7</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;EXAMPLES FOLDER&quot;">
      <data key="d4">2.0</data>
      <data key="d5">"The Examples folder contains examples and papers with codes, also in Jupyter Notebooks, showcasing the applications of ReservoirPy."
"The Examples folder contains examples of complex use cases from the literature, which can be used to learn more about the capabilities of ReservoirPy."</data>
      <data key="d6">c5413fef3b2d7e4d688c66e6046b56c7,ead6383a44acd8ebd17907b85a910455</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;HYPERPACKAGE&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Hyperpackage is an optional feature of ReservoirPy that enables the use of Hyperopt for hyperparameter optimization."</data>
      <data key="d6">c5413fef3b2d7e4d688c66e6046b56c7</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;TROUVAIN ET AL.&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Trouvain et al. are authors of a paper that uses ReservoirPy for exploring hyperparameters."</data>
      <data key="d6">280cbdf53022bbaed48ccb34ebe142bc</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;HINAUT ET AL.&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Hinaut et al. are authors of a paper that provides advice on exploring hyperparameters for reservoirs using ReservoirPy."</data>
      <data key="d6">280cbdf53022bbaed48ccb34ebe142bc</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;LEGER ET AL.&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Leger et al. are authors of a paper that uses ReservoirPy for meta reinforcement learning."</data>
      <data key="d6">280cbdf53022bbaed48ccb34ebe142bc</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;CHAIX-EICHEL ET AL.&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Chaix-Eichel et al. are authors of a paper that uses ReservoirPy for implicit learning and explicit representations."</data>
      <data key="d6">280cbdf53022bbaed48ccb34ebe142bc</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;PAGLIARINI ET AL.&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Pagliarini et al. are authors of papers that use ReservoirPy for vocal sensorimotor modeling and low-dimensional GAN generation."</data>
      <data key="d6">280cbdf53022bbaed48ccb34ebe142bc</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;TROUVAIN &amp; HINAUT&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Trouvain &amp; Hinaut are mentioned as the authors of a paper that cites ReservoirPy."</data>
      <data key="d6">20b16c2e1cb8813ade96fea5f9591631</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;INRIA&quot;">
      <data key="d4">2.0</data>
      <data key="d5">"ReservoirPy is developed and supported by Inria."
"ReservoirPy is developed and supported by Inria."</data>
      <data key="d6">296bb6eb4ef7d170f7224efcccbbbaf7,2a197220a94bac0b44fc0b07712e45ba</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;MNEMOSYNE GROUP&quot;">
      <data key="d4">2.0</data>
      <data key="d5">"ReservoirPy is developed and supported by the Mnemosyne group within Inria."
"ReservoirPy is developed in the Mnemosyne group at Inria."</data>
      <data key="d6">296bb6eb4ef7d170f7224efcccbbbaf7,2a197220a94bac0b44fc0b07712e45ba</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;ICANN 2020&quot;">
      <data key="d4">2.0</data>
      <data key="d5">"ReservoirPy was presented at ICANN 2020."
"ReservoirPy is presented at ICANN 2020."</data>
      <data key="d6">296bb6eb4ef7d170f7224efcccbbbaf7,2a197220a94bac0b44fc0b07712e45ba</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;NATHAN TROUVAIN&quot;">
      <data key="d4">3.0</data>
      <data key="d5">"Nathan Trouvain is an author and contributor to ReservoirPy."
"Nathan Trouvain is a developer of ReservoirPy."
"Nathan Trouvain is a contributor to reservoirpy, working on its development and contributing to its focus on Reservoir Computing (RC) and Echo State Networks (ESNs)."</data>
      <data key="d6">18910a60b2547ec3133340f42c45bb47,296bb6eb4ef7d170f7224efcccbbbaf7,2a197220a94bac0b44fc0b07712e45ba</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;LUCA PEDRELLI&quot;">
      <data key="d4">2.0</data>
      <data key="d5">"Luca Pedrelli is an author and contributor to ReservoirPy."
"Luca Pedrelli is a developer of ReservoirPy."</data>
      <data key="d6">296bb6eb4ef7d170f7224efcccbbbaf7,2a197220a94bac0b44fc0b07712e45ba</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;THANH TRUNG DINH&quot;">
      <data key="d4">2.0</data>
      <data key="d5">"Thanh Trung Dinh is an author and contributor to ReservoirPy."
"Thanh Trung Dinh is a developer of ReservoirPy."</data>
      <data key="d6">296bb6eb4ef7d170f7224efcccbbbaf7,2a197220a94bac0b44fc0b07712e45ba</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;XAVIER HINAUT&quot;">
      <data key="d4">3.0</data>
      <data key="d5">"Xavier Hinaut is an author and contributor to ReservoirPy."
"Xavier Hinaut is a developer of ReservoirPy."
"Xavier Hinaut is a contributor to reservoirpy, working on its development and contributing to its focus on Reservoir Computing (RC) and Echo State Networks (ESNs)."</data>
      <data key="d6">18910a60b2547ec3133340f42c45bb47,296bb6eb4ef7d170f7224efcccbbbaf7,2a197220a94bac0b44fc0b07712e45ba</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;BORDEAUX&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"ReservoirPy is developed at Bordeaux, France."</data>
      <data key="d6">296bb6eb4ef7d170f7224efcccbbbaf7</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;LEAKING RATE&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"ReservoirPy uses the Leaking Rate parameter to control the time constant of the ESN."</data>
      <data key="d6">2d8ea1123f365fb047b024022ba4fdc4</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;DOUBLE SCROLL ATTRACTOR&quot;">
      <data key="d4">2.0</data>
      <data key="d5">"The example demonstrates the use of ReservoirPy to forecast the Double Scroll Attractor."
"ReservoirPy provides the Double scroll attractor as a test case for dynamical systems."</data>
      <data key="d6">91704ce63f9ba41247fdc452a7a62ba6,b483c6bbce54156c724905b340aa2e85</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;TIME SERIES FORECASTING&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"ReservoirPy is a library used for Time Series Forecasting."</data>
      <data key="d6">f70c7d3d89baaabbeaad57b58e379e08</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;RESERVOIR COMPUTING (RC)&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"reservoirpy is a tool for Reservoir Computing (RC), focusing on the design and training of models, particularly Echo State Networks (ESNs)."</data>
      <data key="d6">18910a60b2547ec3133340f42c45bb47</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;PYTHON&quot;">
      <data key="d4">2.0</data>
      <data key="d5">"ReservoirPy is a Python library that provides tools and algorithms for implementing Reservoir Computing."
"ReservoirPy is implemented in Python."</data>
      <data key="d6">6de297d888d10db4c987b5eafc6398b2,74c073137c970e32982756d008532cb8</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;JAEGER&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Reservoirpy is tailored for RC networks design, with a focus on Echo State Networks (ESNs) developed by Jaeger."</data>
      <data key="d6">295606b4bc5d12929a913a3c79f93734</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;RC MODELS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"reservoirpy contains various implementations of Reservoir Computing tools that can be used to construct RC models."</data>
      <data key="d6">d622f95153798af8bb6f485db54aaea3</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;NODE&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Node is a class in reservoirpy that represents a unit in a network."</data>
      <data key="d6">b03e2cc6fe2648e792c1d5f1ec5773a3</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;LMS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"reservoirpy contains the LMS tool that learns connections using Least Mean Square for online learning."</data>
      <data key="d6">b03e2cc6fe2648e792c1d5f1ec5773a3</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;RLS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"reservoirpy contains the RLS tool that learns connections using Recursive Least Square for online learning."</data>
      <data key="d6">b03e2cc6fe2648e792c1d5f1ec5773a3</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;INTRINSIC PLASTICITY&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"reservoirpy contains nodes implementing the Intrinsic Plasticity mechanism for reservoirs."</data>
      <data key="d6">b03e2cc6fe2648e792c1d5f1ec5773a3</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;NON-LINEAR VECTOR AUTOREGRESSIVE MACHINE&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"reservoirpy contains the Non-Linear Vector Autoregressive machine for reservoir reformulations."</data>
      <data key="d6">b03e2cc6fe2648e792c1d5f1ec5773a3</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;SUSSILLO AND ABBOTT&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"ReservoirPy uses the Recursive Least Square learning algorithm developed by Sussillo and Abbott."</data>
      <data key="d6">fcac967511cf2b019fd856e23d2e91d9</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;STEIL&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"ReservoirPy includes nodes implementing the Intrinsic Plasticity mechanism developed by Steil."</data>
      <data key="d6">fcac967511cf2b019fd856e23d2e91d9</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;SCHRAUWEN ET AL.&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"ReservoirPy includes a reservoir reformulation developed by Schrauwen et al."</data>
      <data key="d6">fcac967511cf2b019fd856e23d2e91d9</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;GAUTHIER ET AL.&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"ReservoirPy includes the Non-Linear Vector Autoregressive machine developed by Gauthier et al."</data>
      <data key="d6">fcac967511cf2b019fd856e23d2e91d9</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;PYRCN&quot;">
      <data key="d4">2.0</data>
      <data key="d5">"ReservoirPy is compared to PyRCN, another open-source software for reservoir computing."
"Reservoirpy and PyRCN are compared in terms of their ability to train Extreme Learning Machine (ELM)."</data>
      <data key="d6">15e969cdc81fd313d389558850d0c8ec,fcac967511cf2b019fd856e23d2e91d9</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;ECHOTORCH&quot;">
      <data key="d4">2.0</data>
      <data key="d5">"ReservoirPy is compared to EchoTorch, another open-source software for reservoir computing."
"Reservoirpy is compared to EchoTorch in terms of their support for manipulating conceptors."</data>
      <data key="d6">15e969cdc81fd313d389558850d0c8ec,fcac967511cf2b019fd856e23d2e91d9</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;RESERVOIRCOMPUTING.JL&quot;">
      <data key="d4">2.0</data>
      <data key="d5">"ReservoirPy is compared to ReservoirComputing.jl, another open-source software for reservoir computing."
"Reservoirpy and ReservoirComputing.jl are compared in terms of their availability in different programming languages."</data>
      <data key="d6">15e969cdc81fd313d389558850d0c8ec,fcac967511cf2b019fd856e23d2e91d9</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;PYTORCH-ES&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"ReservoirPy is compared to Pytorch-es, another open-source software for reservoir computing."</data>
      <data key="d6">fcac967511cf2b019fd856e23d2e91d9</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;PYTORCH-ESN&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Reservoirpy and Pytorch-esn are compared in terms of their implementation of Echo State Networks (ESNs)."</data>
      <data key="d6">15e969cdc81fd313d389558850d0c8ec</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;DEEPESN&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Reservoirpy is compared to DeepESN in terms of their support for deep Echo State Networks (ESNs)."</data>
      <data key="d6">15e969cdc81fd313d389558850d0c8ec</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;RCNET&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Reservoirpy and RCNet are compared in terms of their support for online learning and delayed connections."</data>
      <data key="d6">15e969cdc81fd313d389558850d0c8ec</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;LSM&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Reservoirpy is compared to LSM in terms of their specialization in handling spiking neural networks."</data>
      <data key="d6">15e969cdc81fd313d389558850d0c8ec</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;OGER&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Reservoirpy is compared to Oger, a historical package that is no longer maintained."</data>
      <data key="d6">15e969cdc81fd313d389558850d0c8ec</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;ECHO STATE NETWORK&quot;">
      <data key="d4">2.0</data>
      <data key="d5">"reservoirpy is used to create an Echo State Network in the provided code example, which is a type of recurrent neural network."
"ReservoirPy is a library that provides tools for building and training Echo State Networks."</data>
      <data key="d6">29f9b2e5fa311519b18e7aef31c68d0a,6daefaa8fbd5c1492f2d832d79841463</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;JAMES BERGSTRA&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"James Bergstra is a contributor to reservoirpy."</data>
      <data key="d6">a3a74dc4754a8c8b0730f808285893e2</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;DAN YAMINS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Dan Yamins is a contributor to reservoirpy."</data>
      <data key="d6">a3a74dc4754a8c8b0730f808285893e2</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;DAVID D COX&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"David D Cox is a contributor to reservoirpy."</data>
      <data key="d6">a3a74dc4754a8c8b0730f808285893e2</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;MACKEY-GLASS EQUATIONS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"ReservoirPy is a library used to work with the Mackey-Glass Equations."</data>
      <data key="d6">238049de5f28dca3e857a46a8b1bed03</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;LORENZ CHAOTIC ATTRACTOR&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"ReservoirPy provides the Lorenz chaotic attractor as a test case for dynamical systems."</data>
      <data key="d6">b483c6bbce54156c724905b340aa2e85</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;H&#201;NON MAP&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"ReservoirPy provides the H&#233;non map as a test case for dynamical systems."</data>
      <data key="d6">b483c6bbce54156c724905b340aa2e85</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;LOGISTIC MAP&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"ReservoirPy provides the Logistic map as a test case for dynamical systems."</data>
      <data key="d6">b483c6bbce54156c724905b340aa2e85</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;ADVANCED FEATURES&quot;">
      <data key="d4">2.0</data>
      <data key="d5">"ReservoirPy provides advanced features such as input-to-readout connections and custom weight matrices.""ReservoirPy provides advanced features such as input-to-readout connections, feedback connections, custom weight matrices, parallelization, and 'deep' architectures."</data>
      <data key="d6">ead6383a44acd8ebd17907b85a910455</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;CUSTOM INITIALIZER FUNCTIONS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"ReservoirPy allows for the use of custom initializer functions to create reservoirs and readouts with customizable weight matrices."</data>
      <data key="d6">ff860bc63e3d697a6183c0b850689048</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;SCIPY.STATS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"reservoirpy uses functions from scipy.stats to create weights from probability distributions."</data>
      <data key="d6">96c47d9b671ce319abe9c6ba2b8ae122</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;RANDOM_SPARSE&quot;">
      <data key="d4">2.0</data>
      <data key="d5">"reservoirpy includes the random_sparse function to create random sparse matrix initializers."
"random_sparse is a function provided by Reservoirpy to generate random sparse matrices."</data>
      <data key="d6">3a3b7a67b23341dcd1b04ec5b61683f6,96c47d9b671ce319abe9c6ba2b8ae122</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;NORMAL&quot;">
      <data key="d4">2.0</data>
      <data key="d5">"reservoirpy includes the normal function to create dense matrices from a Gaussian distribution."
"normal is a function provided by Reservoirpy to generate dense matrices from a normal distribution."</data>
      <data key="d6">3a3b7a67b23341dcd1b04ec5b61683f6,96c47d9b671ce319abe9c6ba2b8ae122</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;UNIFORM&quot;">
      <data key="d4">2.0</data>
      <data key="d5">"reservoirpy includes the uniform function to create sparse matrices from a uniform distribution."
"uniform is a function provided by Reservoirpy to generate sparse matrices from a uniform distribution."</data>
      <data key="d6">3a3b7a67b23341dcd1b04ec5b61683f6,96c47d9b671ce319abe9c6ba2b8ae122</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;NORMAL DISTRIBUTION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"ReservoirPy uses a function from Numpy to generate matrices from a Normal Distribution."</data>
      <data key="d6">d5e39e29b61f6ea0ffe0c868ba7a4252</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;UNIFORM DISTRIBUTION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"ReservoirPy uses a function from the library to generate matrices from a Uniform Distribution."</data>
      <data key="d6">d5e39e29b61f6ea0ffe0c868ba7a4252</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;BERNOULLI DISTRIBUTION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"ReservoirPy uses a function from the library to generate matrices from a Bernoulli Distribution."</data>
      <data key="d6">d5e39e29b61f6ea0ffe0c868ba7a4252</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;STANDARD RESERVOIR&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Standard Reservoir is a type of node within the ReservoirPy library or framework."</data>
      <data key="d6">3bee7b78d0ab9582cc9bffe9e305df2e</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;DEEP ESN&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Deep ESN models are created and worked with using the ReservoirPy library."</data>
      <data key="d6">2336a57d055095c6ffa9d156ddee0096</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;TUTORIAL&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The tutorial demonstrates how to use ReservoirPy to create an Echo State Network (ESN) and work with timeseries data."</data>
      <data key="d6">74c073137c970e32982756d008532cb8</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;RESERVOIR CLASS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"ReservoirPy includes the Reservoir class, which is used to create reservoirs for ESNs."</data>
      <data key="d6">9b360c6a33aafa6827417de5bd4faa82</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;MATPLOTLIB&quot;">
      <data key="d4">4.0</data>
      <data key="d5">"ReservoirPy uses Matplotlib for visualizing the activation of the reservoir."
"ReservoirPy uses Matplotlib for creating visualizations of reservoir neuron activation."
"Matplotlib is used in ReservoirPy for creating visualizations."
"Matplotlib is used in the ReservoirPy library for creating visualizations of the Mackey-Glass Equation."</data>
      <data key="d6">34b9ce80a22112b32e063179511af6e0,50d4e4aab1823b8df6573ccf227f24d0,8648b5740b93d805f139d9745e1171e8,a58317c7e13f27d513fc7671fd187ecb</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;SINE WAVE&quot;">
      <data key="d4">2.0</data>
      <data key="d5">"The reservoir is run on a sine wave as input data."
"A sine wave is used as input data for the reservoir created using ReservoirPy."</data>
      <data key="d6">34b9ce80a22112b32e063179511af6e0,a58317c7e13f27d513fc7671fd187ecb</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;RESERVOIR NEURONS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Reservoir neurons are components of the reservoir created using ReservoirPy, which process and store information from the input data."</data>
      <data key="d6">a58317c7e13f27d513fc7671fd187ecb</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;ESN MODEL&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"ReservoirPy is used to create the ESN Model, which includes components like Reservoir and Ridge."</data>
      <data key="d6">8294eed5fc10df1c118f9afa266910e4</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;RESERVOIR COMPUTING MODEL&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"ReservoirPy is used to create and work with Reservoir Computing Models."</data>
      <data key="d6">71f966d00b6d0eceb580d00b9cb86b1e</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;CONCAT&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"ReservoirPy is used to create and work with reservoir computing models that include the Concat function for combining multiple data streams into a single stream."</data>
      <data key="d6">c82c9d05b211ff65131f70eb8cb13513</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;FEEDBACK CONNECTIONS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"ReservoirPy is used to create and work with reservoir computing models that utilize Feedback Connections to improve data processing and prediction."</data>
      <data key="d6">c82c9d05b211ff65131f70eb8cb13513</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;FORCED FEEDBACKS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"ReservoirPy is used to create and work with reservoir computing models that utilize Forced Feedbacks to control the internal dynamics of the model."</data>
      <data key="d6">c82c9d05b211ff65131f70eb8cb13513</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;FITTING&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"ReservoirPy is used to train reservoir computing models, which is a process known as Fitting."</data>
      <data key="d6">c82c9d05b211ff65131f70eb8cb13513</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;NP.RANDOM.NORMAL&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Reservoirpy uses np.random.normal to generate random numbers from a normal distribution."</data>
      <data key="d6">3a3b7a67b23341dcd1b04ec5b61683f6</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;PLT.HIST&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"plt.hist is used to plot a histogram of the weights distribution in the Reservoir matrix generated by Reservoirpy."</data>
      <data key="d6">3a3b7a67b23341dcd1b04ec5b61683f6</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;BERNOULLI&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Bernoulli distribution is used in the creation of random matrices in ReservoirPy."</data>
      <data key="d6">7b9936d57ece8ba985947a7aca12e2c7</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;SEQUENTIAL&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Sequential is mentioned in the context of using the ReservoirPy library for data processing."</data>
      <data key="d6">e39809b687cd044a7918eca37727a188</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;RESERVOIR1&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"ReservoirPy is used to create and work with Reservoir1, a component in a reservoir model."</data>
      <data key="d6">8648b5740b93d805f139d9745e1171e8</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;RESERVOIR2&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"ReservoirPy is used to create and work with Reservoir2, a component in a reservoir model."</data>
      <data key="d6">8648b5740b93d805f139d9745e1171e8</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;RESERVOIR3&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"ReservoirPy is used to create and work with Reservoir3, a component in a reservoir model."</data>
      <data key="d6">8648b5740b93d805f139d9745e1171e8</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;DATA&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"ReservoirPy is used to create and work with Data, a component in a reservoir model."</data>
      <data key="d6">8648b5740b93d805f139d9745e1171e8</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;MODEL&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"ReservoirPy is used to create and work with Model, a component in a reservoir model."</data>
      <data key="d6">8648b5740b93d805f139d9745e1171e8</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;MACKEY-GLASS EQUATION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"ReservoirPy is used for timeseries forecasting of the Mackey-Glass Equation."</data>
      <data key="d6">50d4e4aab1823b8df6573ccf227f24d0</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;DATA PREPROCESSING&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"ReservoirPy is used for data preprocessing, such as converting the Mackey-Glass Time Series dataset into a forecasting format."</data>
      <data key="d6">b2beacacc8c190393e4583a69518378c</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;FORECASTING&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"ReservoirPy is used for forecasting, as demonstrated in the provided code using the ReservoirPy library to convert the Mackey-Glass Time Series dataset into a forecasting format."</data>
      <data key="d6">b2beacacc8c190393e4583a69518378c</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;FIRST ECHO STATE NETWORK&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The provided text discusses the construction and training of the first Echo State Network using the ReservoirPy library."</data>
      <data key="d6">41fa16855df7da666dc6fc38d2f8ee53</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;FORCE&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"ReservoirPy supports the use of the FORCE readout algorithm in reservoir computing networks."</data>
      <data key="d6">324a8f3fb4d19b91457a99999e6d3d17</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;AUTHOR&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The author uses the ReservoirPy library to create and work with reservoir computing models."</data>
      <data key="d6">069ae9388dfd52fec9c184c7168f64dd</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;SPECTRAL RADIUS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The concept of Spectral Radius is used in the provided code when creating reservoirs using the ReservoirPy library."</data>
      <data key="d6">4073cafddb73621f26061385c5570659</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;OBJECTIVE FUNCTIONS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"ReservoirPy is used to define and optimize Objective Functions for reservoir computing models."</data>
      <data key="d6">0113164912437e96423379cb9c039f56</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;TIME SERIES PREDICTION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"ReservoirPy is used for the task of Time Series Prediction, which is a common application of reservoir computing models."</data>
      <data key="d6">0113164912437e96423379cb9c039f56</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;RESEARCH PAPER&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"ReservoirPy is a key tool mentioned in the research paper."</data>
      <data key="d6">870f29520f7a1c42eecb0c4ff855f09e</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;RIDGECLASSIFIER&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"ReservoirPy is used to create a reservoir computing model that includes the RidgeClassifier algorithm for classification tasks."</data>
      <data key="d6">0036fb6f489e13c0db0f1c02bf3323be</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;LOGISTICREGRESSION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"ReservoirPy is used to create a reservoir computing model that includes the LogisticRegression algorithm for classification tasks."</data>
      <data key="d6">0036fb6f489e13c0db0f1c02bf3323be</data>
    </edge>
    <edge source="&quot;RESERVOIRPY&quot;" target="&quot;PERCEPTRON&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"ReservoirPy is used to create a reservoir computing model that includes the Perceptron algorithm for classification tasks."</data>
      <data key="d6">0036fb6f489e13c0db0f1c02bf3323be</data>
    </edge>
    <edge source="&quot;SEQUENCE-TO-SEQUENCE MODEL&quot;" target="&quot;TRANSDUCTION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Transduction is the process used in sequence-to-sequence models for encoding sequences, such as audio data, into new sequences in the output space."</data>
      <data key="d6">79d5959f3f6471cad55498ab4a8a3176</data>
    </edge>
    <edge source="&quot;SEQUENCE-TO-SEQUENCE MODEL&quot;" target="&quot;JAPANESE VOWELS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Sequence-to-Sequence Model is used to solve a task involving the recognition and modeling of Japanese Vowels."</data>
      <data key="d6">688ebc7151bc148ac24dc7e2727d7afe</data>
    </edge>
    <edge source="&quot;TRANSDUCTION&quot;" target="&quot;CLASSIFICATION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Transduction and Classification are two different methods used in sequence modeling, with Transduction generating a sequence of output labels and Classification assigning a single label to each input sequence."</data>
      <data key="d6">c05906c1f12c4edfc32a04aa9935067e</data>
    </edge>
    <edge source="&quot;TRANSDUCTION&quot;" target="&quot;JAPANESE_VOWELS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The japanese_vowels dataset is used for training and testing a machine learning model called Transduction, which is a sequence-to-sequence model."</data>
      <data key="d6">9414efd266e7135a2cdd7461a888b045</data>
    </edge>
    <edge source="&quot;SIMPLE ECHO STATE NETWORK&quot;" target="&quot;SEQUENCE-TO-SEQUENCE ENCODING&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Simple Echo State Network is trained using the Sequence-to-Sequence Encoding method."</data>
      <data key="d6">75c1234e634cf2c009a116e4ee6c053e</data>
    </edge>
    <edge source="&quot;SIMPLE ECHO STATE NETWORK&quot;" target="&quot;TRAINING&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Simple Echo State Network is trained to learn the relationship between input and output sequences."</data>
      <data key="d6">75c1234e634cf2c009a116e4ee6c053e</data>
    </edge>
    <edge source="&quot;SIMPLE ECHO STATE NETWORK&quot;" target="&quot;PREDICTION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The trained Simple Echo State Network is used to make predictions based on input sequences."</data>
      <data key="d6">75c1234e634cf2c009a116e4ee6c053e</data>
    </edge>
    <edge source="&quot;SEQUENCE-TO-SEQUENCE ENCODING&quot;" target="&quot;RESERVOIRPY NODES&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"ReservoirPy Nodes use Sequence-to-Sequence Encoding for tasks such as converting a sequence of audio data into a sequence of labels."</data>
      <data key="d6">a6f2502b5336ffc8606e1167b2813004</data>
    </edge>
    <edge source="&quot;SEQUENCE-TO-SEQUENCE ENCODING&quot;" target="&quot;CLASSIFICATION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Sequence-to-Sequence Encoding is not typically used for classification tasks, as it is designed for generating sequences of output labels."</data>
      <data key="d6">a6f2502b5336ffc8606e1167b2813004</data>
    </edge>
    <edge source="&quot;TRAINING&quot;" target="&quot;ESN&quot;">
      <data key="d4">3.0</data>
      <data key="d5">"ESN is trained on a dataset during the Training process."
"ESN is trained using the input data to optimize its parameters and improve its ability to make accurate predictions."
"ESN is used for training, which is the process of learning patterns and making predictions using a neural network model."</data>
      <data key="d6">36e4df75a46fb977f9516f2d2f1f9bc2,894d59d781535ca85389c4226715c007,cc1fb6ca5695434ad0279c2606e928af</data>
    </edge>
    <edge source="&quot;TRAINING&quot;" target="&quot;DEEP ECHO STATE NETWORKS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Deep Echo State Networks are trained through the process of delivering targets to each readout."</data>
      <data key="d6">59b469bdd618b3f36b3547f4f2b8a862</data>
    </edge>
    <edge source="&quot;TRAINING&quot;" target="&quot;RIDGE READOUT&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Ridge Readout undergoes the Training process to learn the Sine Wave sequence."</data>
      <data key="d6">f2d5625f36aa4cb036089ce89ec607eb</data>
    </edge>
    <edge source="&quot;TRAINING&quot;" target="&quot;ESN MODEL&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The ESN Model is trained during the Training event, initializing nodes and training the Ridge readout."</data>
      <data key="d6">8ade7819a5f8d1ec26e9bdbd059142e6</data>
    </edge>
    <edge source="&quot;TRAINING&quot;" target="&quot;RESERVOIR&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Training is the process of adjusting the reservoir's parameters to improve its performance in processing input data."</data>
      <data key="d6">324a8f3fb4d19b91457a99999e6d3d17</data>
    </edge>
    <edge source="&quot;PREDICTION&quot;" target="&quot;TIME SERIES&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Prediction is mentioned in the context of Time Series, referring to forecasting future data points."</data>
      <data key="d6">14bccd672d2f8dd2cd7300581c8844fb</data>
    </edge>
    <edge source="&quot;PREDICTION&quot;" target="&quot;SEED&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Seed is mentioned in the context of making predictions reproducible, as it initializes a random number generator."</data>
      <data key="d6">14bccd672d2f8dd2cd7300581c8844fb</data>
    </edge>
    <edge source="&quot;PREDICTION&quot;" target="&quot;ESN&quot;">
      <data key="d4">2.0</data>
      <data key="d5">"The ESN generates Predictions by using the learned patterns and dynamics of the Input Data to generate future values of the timeseries."
"The trained ESN model is used for the Prediction process, which involves predicting future values of the sine wave."</data>
      <data key="d6">09ea760dd2f000c961d1cfd4ea795da5,693e4d1e43289f46866236c10207a17e</data>
    </edge>
    <edge source="&quot;PREDICTION&quot;" target="&quot;FORECASTING&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Prediction is a broader concept that includes forecasting, which involves making specific predictions about future data points."</data>
      <data key="d6">9261efcc24379d9c0b2d35a2fde8275d</data>
    </edge>
    <edge source="&quot;PREDICTION&quot;" target="&quot;ESN MODEL&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The ESN model is used for predicting the next 100 steps of a timeseries, based on its last 10 steps."</data>
      <data key="d6">8c520b4037fe01ffce62d46b67175e67</data>
    </edge>
    <edge source="&quot;PREDICTION&quot;" target="&quot;X&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"X is used as input data for the Prediction process, which involves using the trained ESN model to predict future values of the sine wave."</data>
      <data key="d6">09ea760dd2f000c961d1cfd4ea795da5</data>
    </edge>
    <edge source="&quot;SPEAKER LABELING&quot;" target="&quot;SEQUENCE-TO-VECTOR MODEL&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Sequence-to-Vector Models are used for Speaker Labeling, which is a part of data analysis and classification of sequential patterns."</data>
      <data key="d6">64b0ff9558a0f4794c16619aa76354c4</data>
    </edge>
    <edge source="&quot;SEQUENCE-TO-VECTOR MODEL&quot;" target="&quot;RESERVOIRPY NODES&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"ReservoirPy Nodes can also use Sequence-to-Vector Model for tasks such as classifying sequential patterns."</data>
      <data key="d6">a6f2502b5336ffc8606e1167b2813004</data>
    </edge>
    <edge source="&quot;SEQUENCE-TO-VECTOR MODEL&quot;" target="&quot;CLASSIFICATION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Sequence-to-Vector Model is commonly used for classification tasks, as it allows for the assignment of a single label to each input sequence."</data>
      <data key="d6">a6f2502b5336ffc8606e1167b2813004</data>
    </edge>
    <edge source="&quot;DATA ANALYSIS&quot;" target="&quot;ECHO STATE NETWORK&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Echo State Networks are also used for Data Analysis tasks, such as pattern recognition and classification."</data>
      <data key="d6">29f9b2e5fa311519b18e7aef31c68d0a</data>
    </edge>
    <edge source="&quot;DATA ANALYSIS&quot;" target="&quot;PYTHON CODE&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Python Code is used to analyze data in the context of data analysis tasks."</data>
      <data key="d6">d15f6d075c072f0335b5332f11c00299</data>
    </edge>
    <edge source="&quot;DATA ANALYSIS&quot;" target="&quot;RMSE&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"RMSE is a measure used in data analysis to evaluate the accuracy of predictions."</data>
      <data key="d6">d15f6d075c072f0335b5332f11c00299</data>
    </edge>
    <edge source="&quot;DATA ANALYSIS&quot;" target="&quot;CANARY SONG DECODING&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Canary Song Decoding involves the analysis and classification of temporal motifs in canary songs."</data>
      <data key="d6">d15f6d075c072f0335b5332f11c00299</data>
    </edge>
    <edge source="&quot;DATA ANALYSIS&quot;" target="&quot;ESN&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"ESN is a type of recurrent neural network commonly used for data analysis."</data>
      <data key="d6">7b9936d57ece8ba985947a7aca12e2c7</data>
    </edge>
    <edge source="&quot;DATA ANALYSIS&quot;" target="&quot;DATA SCIENTIST&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Data Scientist is performing Data Analysis to inspect, clean, transform, and model data."</data>
      <data key="d6">9fdaabd6c7e893a275a3848c10007477</data>
    </edge>
    <edge source="&quot;RIDGE&quot;" target="&quot;RESERVOIR&quot;">
      <data key="d4">3.0</data>
      <data key="d5">"The Reservoir component generates internal states used for training the Ridge component of the readout."
"Reservoir and Ridge are components used together in the provided code, likely as part of a machine learning model."
"The Reservoir is used in conjunction with Ridge, a regularization technique, to handle the processing of Time Series Data."</data>
      <data key="d6">0753d4e507badadd900c522ee03ad28d,1ea13fb2c1fff4954b699a8e2377f99f,2bcc39da2ecef3011cc3da428fca5dd5</data>
    </edge>
    <edge source="&quot;RIDGE&quot;" target="&quot;HP_SPACE&quot;">
      <data key="d4">3.0</data>
      <data key="d5">"hp_space is the configuration parameter that explores the ridge parameter, but its configuration is not explicitly mentioned in the given text."
"hp_space is used to explore the ridge parameter."
"hp_space is associated with the parameter ridge, which specifies a regularization parameter."</data>
      <data key="d6">5cea9edfd65fcfa25a081554300b28cc,80033e741d8e10abdcfe20dd17192152,adfc38e9dc5e6fd0fe67ce83dfa1f154</data>
    </edge>
    <edge source="&quot;RIDGE&quot;" target="&quot;ESN&quot;">
      <data key="d4">11.0</data>
      <data key="d5">"The ESN uses a Ridge readout layer to read out the desired output from the activations of the reservoir."
"ESN is composed of a Ridge component for readout and training."
"ESN uses Ridge regularization to prevent overfitting and improve generalization."
"Ridge is used as a regularization technique in the Echo State Network for regression tasks."
"The Ridge is a type of readout used in the Echo State Network (ESN) system for making predictions."
"Ridge is a regularization technique that can be used in an Echo State Network (ESN) to prevent overfitting."
"Ridge is used in conjunction with ESN for processing sequences of inputs and targets."
"Ridge is a type of readout used in the ESN model for time series prediction."
"Ridge is a type of regularization used in the ESN model to prevent overfitting."
"ESN uses a Ridge readout for training and prediction."
"ESN uses Ridge regularization to prevent overfitting and improve generalization."</data>
      <data key="d6">09198e939639c229c2c97555f65b12a7,09ea760dd2f000c961d1cfd4ea795da5,36e4df75a46fb977f9516f2d2f1f9bc2,3bee7b78d0ab9582cc9bffe9e305df2e,72e6eee633bcb5b1458c4cee3975cee1,7f70879016c133fe58e4838172a69613,80c9f51870e239404ed671ef0374f191,993a69efae014a8f8d6ec0c235104d46,bf4eaad93f89884d02cdad6a50f145a6,f0c8d4d322d73f46464e3e9f6914f2ee,f7f7dbc1e69b3b0e801bc5ba9c0cabca</data>
    </edge>
    <edge source="&quot;RIDGE&quot;" target="&quot;HYPERPARAMETER OPTIMIZATION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Ridge is a hyperparameter representing the regularization term in the machine learning model, which is optimized during Hyperparameter Optimization."</data>
      <data key="d6">f70c7d3d89baaabbeaad57b58e379e08</data>
    </edge>
    <edge source="&quot;RIDGE&quot;" target="&quot;HYPER-PARAMETER EXPLORATION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Ridge is a regularization technique used in Hyper-parameter Exploration to prevent overfitting."</data>
      <data key="d6">136d135c710f6cf78a4c536d43276fe1</data>
    </edge>
    <edge source="&quot;RIDGE&quot;" target="&quot;ESNS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Ridge is a type of readout layer used in ESNs, which estimates the output based on the reservoir's state."</data>
      <data key="d6">f1fc6fbc8158d3da070d55544041a2ca</data>
    </edge>
    <edge source="&quot;RIDGE&quot;" target="&quot;FEEDBACK CONNECTIONS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Ridge component of ESNs can be connected through feedback connections."</data>
      <data key="d6">7f2d69f9a9baca70ffd25a6865189206</data>
    </edge>
    <edge source="&quot;RIDGE&quot;" target="&quot;Y_TRAIN&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Ridge component of the ESN model is trained using the training target data (Y_train)."</data>
      <data key="d6">7f2d69f9a9baca70ffd25a6865189206</data>
    </edge>
    <edge source="&quot;RIDGE&quot;" target="&quot;MODEL&quot;">
      <data key="d4">3.0</data>
      <data key="d5">"The Ridge is used for training the readout component of the Model, which is responsible for making predictions based on the reservoir's output."
"The Ridge component is a part of the Model, contributing to its regularization and prediction capabilities."
"The Model uses the Ridge component for output prediction."</data>
      <data key="d6">3ff318aebcb07ca141d0a40730d96c7c,46dcc47b4358d3895c1eeb1182c6f997,a0feae89e52a4291db0a512a3a102d8e</data>
    </edge>
    <edge source="&quot;RIDGE&quot;" target="&quot;ESN MODEL&quot;">
      <data key="d4">2.0</data>
      <data key="d5">"The Ridge is a component of the ESN model, with a ridge parameter of 1e-7."
"The ESN Model contains a Ridge node, which is used as a readout for making predictions."</data>
      <data key="d6">8ade7819a5f8d1ec26e9bdbd059142e6,8c520b4037fe01ffce62d46b67175e67</data>
    </edge>
    <edge source="&quot;RIDGE&quot;" target="&quot;DEEP ECHO STATE NETWORKS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Deep Echo State Networks are constructed using components of type Ridge."</data>
      <data key="d6">59b469bdd618b3f36b3547f4f2b8a862</data>
    </edge>
    <edge source="&quot;RIDGE&quot;" target="&quot;DEEP ESN&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Deep ESN models use Ridge regression models for making predictions."</data>
      <data key="d6">2336a57d055095c6ffa9d156ddee0096</data>
    </edge>
    <edge source="&quot;RIDGE&quot;" target="&quot;INPUT TIMESERIES&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Ridge is trained using an Input Timeseries as input."</data>
      <data key="d6">5366a81a025c098744b5d6f1432c2fbc</data>
    </edge>
    <edge source="&quot;RIDGE&quot;" target="&quot;TARGET TIMESERIES&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Ridge is trained to create a mapping from Input Timeseries to Target Timeseries."</data>
      <data key="d6">5366a81a025c098744b5d6f1432c2fbc</data>
    </edge>
    <edge source="&quot;RIDGE&quot;" target="&quot;ONE-TIMESTEP-AHEAD PREDICTION TASK&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Ridge is used to solve a One-timestep-ahead Prediction Task, predicting the next timestep of a timeseries based on its current timestep."</data>
      <data key="d6">5366a81a025c098744b5d6f1432c2fbc</data>
    </edge>
    <edge source="&quot;RIDGE&quot;" target="&quot;ESN_MODEL&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Ridge organization is used to construct the esn_model."</data>
      <data key="d6">751b176a8d6149a853e597c65a6fe0cf</data>
    </edge>
    <edge source="&quot;RIDGE&quot;" target="&quot;HIERARCHICAL ESN&quot;">
      <data key="d4">2.0</data>
      <data key="d5">"Ridge readouts are used in the construction of hierarchical echo state networks (ESNs)."
"Hierarchical ESN is a type of reservoir computing model that includes multiple Ridge readouts."</data>
      <data key="d6">00d22666fe697ffb66c2392939f45b39,e39809b687cd044a7918eca37727a188</data>
    </edge>
    <edge source="&quot;RIDGE&quot;" target="&quot;REGULARIZATION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The amount of regularization in the Ridge readout is controlled using the regularization parameter in the ESN."</data>
      <data key="d6">09198e939639c229c2c97555f65b12a7</data>
    </edge>
    <edge source="&quot;RIDGE&quot;" target="&quot;HYPEROPT&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Ridge is a parameter mentioned in the Hyperopt configuration."</data>
      <data key="d6">0982b8d1eb1e636b19fa2e9d9361e566</data>
    </edge>
    <edge source="&quot;RESERVOIR&quot;" target="&quot;INPUT&quot;">
      <data key="d4">2.0</data>
      <data key="d5">"The Reservoir component generates internal states based on input sequences from the Input component."
"The input data is processed by the reservoir component of the model."</data>
      <data key="d6">1ea13fb2c1fff4954b699a8e2377f99f,58115d5a63315a84d9c8d4e6ddc98ffd</data>
    </edge>
    <edge source="&quot;RESERVOIR&quot;" target="&quot;STATES_TRAIN&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"states_train are generated using the reservoir component, potentially representing a relationship between input data and states."</data>
      <data key="d6">b101b38a87b2fcac0ff450a4e3f22143</data>
    </edge>
    <edge source="&quot;RESERVOIR&quot;" target="&quot;X_TEST&quot;">
      <data key="d4">2.0</data>
      <data key="d5">"X_test is used to generate states using the reservoir component, potentially representing a relationship between input data and states."
"The Reservoir component processes the testing input data."</data>
      <data key="d6">b101b38a87b2fcac0ff450a4e3f22143,dc3bd3697a140b64d70e0e3ac6db6c7e</data>
    </edge>
    <edge source="&quot;RESERVOIR&quot;" target="&quot;ECHO STATE NETWORKS&quot;">
      <data key="d4">3.0</data>
      <data key="d5">"Echo State Networks consist of a reservoir component, which is a pool of randomly connected neurons."
"Echo State Networks consist of a Reservoir that receives input signals and transforms them into high-dimensional representations."
"Reservoir is a component of an echo state network that stores and processes information."</data>
      <data key="d6">0e6f0f7cd882a638ecb571ef36068868,83fafb2423a01afae7e522917d79ace9,ed28ba3543e07641536ff1eb5e0749dd</data>
    </edge>
    <edge source="&quot;RESERVOIR&quot;" target="&quot;RANDOM HIGH-DIMENSIONAL VECTOR&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Random High-Dimensional Vector refers to the activations of the reservoir in Echo State Networks, which capture intricate patterns and dynamics of the input data."</data>
      <data key="d6">0e6f0f7cd882a638ecb571ef36068868</data>
    </edge>
    <edge source="&quot;RESERVOIR&quot;" target="&quot;FROM_STATE&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"from_state is a parameter used to initialize the reservoir with a specific state at the start of a simulation or training process."</data>
      <data key="d6">cb71a9bc3b00e7abcd1a53004abdea69</data>
    </edge>
    <edge source="&quot;RESERVOIR&quot;" target="&quot;WITH_STATE&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"with_state is a parameter used to continue the simulation or training process from a specific state, updating the reservoir's state during its operation."</data>
      <data key="d6">cb71a9bc3b00e7abcd1a53004abdea69</data>
    </edge>
    <edge source="&quot;RESERVOIR&quot;" target="&quot;RUN(X)&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"run(X) is a method that processes the entire timeseries X through the reservoir node, updating the reservoir's state at each timestep based on the input data."</data>
      <data key="d6">cb71a9bc3b00e7abcd1a53004abdea69</data>
    </edge>
    <edge source="&quot;RESERVOIR&quot;" target="&quot;RECURRENT NETWORK&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Recurrent network is a type of artificial neural network characterized by bi-directional flow of information, which is a characteristic of reservoirs."</data>
      <data key="d6">cb71a9bc3b00e7abcd1a53004abdea69</data>
    </edge>
    <edge source="&quot;RESERVOIR&quot;" target="&quot;READOUT NODE&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Reservoir provides internal states to the Readout Node, which uses them to make predictions."</data>
      <data key="d6">fa082948fa919150e9c06c6f5c1b53b0</data>
    </edge>
    <edge source="&quot;RESERVOIR&quot;" target="&quot;INPUT DATA&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Input Data is processed by the Reservoir, generating dynamic representations that can be utilized by the model."</data>
      <data key="d6">4da651284dbab3f68dc3cae41e6e0311</data>
    </edge>
    <edge source="&quot;RESERVOIR&quot;" target="&quot;READOUT LAYER&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Reservoir processes the input data and generates dynamic representations that are then utilized by the Readout Layer."</data>
      <data key="d6">4da651284dbab3f68dc3cae41e6e0311</data>
    </edge>
    <edge source="&quot;RESERVOIR&quot;" target="&quot;ONE-TO-MANY CONNECTIONS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Reservoir component can be connected to multiple subsequent nodes using One-to-Many Connections, allowing the same input data to be processed in different ways, enhancing the model's ability to capture various aspects of the data."</data>
      <data key="d6">a35f6cae32a3d24b18ee17ec0471a9d4</data>
    </edge>
    <edge source="&quot;RESERVOIR&quot;" target="&quot;FEEDBACK CONNECTION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Feedback Connection mechanism allows the Reservoir to access the state of the Readout with a one-timestep delay."</data>
      <data key="d6">333ecf478bfbd4291de9f193bbf0443a</data>
    </edge>
    <edge source="&quot;RESERVOIR&quot;" target="&quot;IN-PLACE FEEDBACK CONNECTION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The In-place Feedback Connection variant allows the Reservoir to directly hold the reference to the Readout node's state without creating a copy."</data>
      <data key="d6">333ecf478bfbd4291de9f193bbf0443a</data>
    </edge>
    <edge source="&quot;RESERVOIR&quot;" target="&quot;READOUT&quot;">
      <data key="d4">7.0</data>
      <data key="d5">"The Reservoir receives feedback from the Readout, using the most recent output information for current processing.""The Readout sends its state to the Reservoir for feedback, allowing the Reservoir to remember and incorporate past decisions or predictions."
"The reservoir's output is used by the readout to generate predictions in Echo State Networks (ESNs)."
"The output of the reservoir component is fed into the readout component of the model."
"The reservoir node processes the data and sends the output to the readout node in the ESN model."
"The Reservoir is mentioned as providing data to the Readout, which learns connections from the reservoir to the readout neurons."
"The reservoir processes input data, and the readout algorithm is used to extract meaningful information from the reservoir's output."</data>
      <data key="d6">0d922ae20673124fc4588949e3863ed0,324a8f3fb4d19b91457a99999e6d3d17,333ecf478bfbd4291de9f193bbf0443a,58115d5a63315a84d9c8d4e6ddc98ffd,cf15a09e77b695a117e1cca05461aea2,d25cd385546ec6a033287e75d65a551a</data>
    </edge>
    <edge source="&quot;RESERVOIR&quot;" target="&quot;FORCED FEEDBACK&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"In Forced Feedback for Echo State Networks (ESNs), the reservoir receives feedback from Teacher Vectors."</data>
      <data key="d6">0d922ae20673124fc4588949e3863ed0</data>
    </edge>
    <edge source="&quot;RESERVOIR&quot;" target="&quot;ECHO STATE NETWORKS (ESNS)&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Reservoir in an ESN helps preserve information and capture temporal dynamics, contributing to accurate predictions."</data>
      <data key="d6">4b78fdc153f982e64291112395c316c7</data>
    </edge>
    <edge source="&quot;RESERVOIR&quot;" target="&quot;ESN&quot;">
      <data key="d4">14.0</data>
      <data key="d5">"The ESN is made of a Reservoir, which is a random recurrent network used to encode inputs in a high-dimensional space."
"The ESN system relies on the reservoir having the echo state property for its correct functioning."
"ESN is composed of a Reservoir component for processing input data."
"ESN is composed of a Reservoir component that stores and processes information."
"ESN is composed of a Reservoir component that processes input data and generates a high-dimensional state space."
"Echo State Networks utilize a Reservoir component to process and store input data."
"The Reservoir is a component of the Echo State Network (ESN) system, used for processing input data."
"Reservoir is a component of an Echo State Network (ESN), which processes input data for prediction and generation tasks."
"Reservoir is a component of the ESN model that stores and processes data."
"ESN is composed of a Reservoir component."
"The Reservoir is a component used in the creation of an ESN."
"The ESN model is composed of a reservoir and a readout, with the reservoir processing input data."
"ESN is composed of a Reservoir component that processes input data."
"ESN is composed of a Reservoir component that processes input data."</data>
      <data key="d6">09198e939639c229c2c97555f65b12a7,36e4df75a46fb977f9516f2d2f1f9bc2,6a4432cd530b28770e2b903fe242a0d1,72e6eee633bcb5b1458c4cee3975cee1,7b294b788fe5ee385d08c4aabe2ca71d,7f70879016c133fe58e4838172a69613,80c9f51870e239404ed671ef0374f191,993a69efae014a8f8d6ec0c235104d46,9b360c6a33aafa6827417de5bd4faa82,bf4eaad93f89884d02cdad6a50f145a6,cc1fb6ca5695434ad0279c2606e928af,cdc64af0dde941250d89b191d0666c9b,f0c8d4d322d73f46464e3e9f6914f2ee,f7f7dbc1e69b3b0e801bc5ba9c0cabca</data>
    </edge>
    <edge source="&quot;RESERVOIR&quot;" target="&quot;SPECTRAL RADIUS&quot;">
      <data key="d4">5.0</data>
      <data key="d5">"The spectral radius is a property of the Reservoir component in the reservoir computing model."
"Spectral Radius is a property of the Reservoir, with a value close to 1 having theoretical implications for the reservoir states."
"The Spectral Radius parameter is used to control the dynamics of the reservoir in the Echo State Network (ESN) model."
"The Spectral Radius parameter determines the stability of the Reservoir component of the ESN model."
"The Reservoir component's Spectral Radius is mentioned, indicating its role in the network."</data>
      <data key="d6">1365a36c76afc697ac626fd0f784804a,72e6eee633bcb5b1458c4cee3975cee1,82f7e4647b9da5d5063fe92613f4fbcb,94fd1ebf256db17e4ac2255b89caa473,b957e1bf5bf175c7630222ca742c7933</data>
    </edge>
    <edge source="&quot;RESERVOIR&quot;" target="&quot;MACKEY-GLASS TIMESERIES&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Mackey-Glass timeseries is used as inputs for the Reservoir component in the reservoir computing model."</data>
      <data key="d6">94fd1ebf256db17e4ac2255b89caa473</data>
    </edge>
    <edge source="&quot;RESERVOIR&quot;" target="&quot;INPUT SCALING&quot;">
      <data key="d4">4.0</data>
      <data key="d5">"Input Scaling is applied to a reservoir, affecting its dynamics and potentially influencing its ability to process input data."
"Input Scaling is a parameter of the Reservoir that influences the reservoir's behavior."
"The Reservoir system undergoes Input scaling as a process."
"The Reservoir component is adjusted using Input Scaling to improve the network's performance."</data>
      <data key="d6">1f30b86a46d4819603edc730df816c49,82f7e4647b9da5d5063fe92613f4fbcb,b957e1bf5bf175c7630222ca742c7933,bba680a0a7dd439bd5b0fe1547ffe040</data>
    </edge>
    <edge source="&quot;RESERVOIR&quot;" target="&quot;ECHO STATE PROPERTY&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Echo State Property is a property of the Reservoir, which is supposed to allow the reservoir states to be less affected by their initial conditions while having good memorization properties."</data>
      <data key="d6">82f7e4647b9da5d5063fe92613f4fbcb</data>
    </edge>
    <edge source="&quot;RESERVOIR&quot;" target="&quot;ESNS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Reservoir is a component of ESNs that processes input data and generates a rich representation for the readout layer."</data>
      <data key="d6">f1fc6fbc8158d3da070d55544041a2ca</data>
    </edge>
    <edge source="&quot;RESERVOIR&quot;" target="&quot;ESN MODEL&quot;">
      <data key="d4">3.0</data>
      <data key="d5">"The ESN Model includes the reservoir component for processing the input data."
"The Reservoir is a component of the ESN model, with a learning rate of 0.5 and a spectral radius of 0.9."
"The ESN Model contains a Reservoir node, which processes input data."</data>
      <data key="d6">58115d5a63315a84d9c8d4e6ddc98ffd,8ade7819a5f8d1ec26e9bdbd059142e6,8c520b4037fe01ffce62d46b67175e67</data>
    </edge>
    <edge source="&quot;RESERVOIR&quot;" target="&quot;DATA&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Data is the input to the reservoir node in the ESN model."</data>
      <data key="d6">cf15a09e77b695a117e1cca05461aea2</data>
    </edge>
    <edge source="&quot;RESERVOIR&quot;" target="&quot;FEEDBACK CONNECTIONS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Reservoir component of ESNs can be connected through feedback connections."</data>
      <data key="d6">7f2d69f9a9baca70ffd25a6865189206</data>
    </edge>
    <edge source="&quot;RESERVOIR&quot;" target="&quot;X_TRAIN&quot;">
      <data key="d4">2.0</data>
      <data key="d5">"The Reservoir component of the ESN model processes the training input data (X_train)."
"The Reservoir component processes the training input data."</data>
      <data key="d6">7f2d69f9a9baca70ffd25a6865189206,dc3bd3697a140b64d70e0e3ac6db6c7e</data>
    </edge>
    <edge source="&quot;RESERVOIR&quot;" target="&quot;X&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Reservoir component of the ESN model processes the input data (X)."</data>
      <data key="d6">7f2d69f9a9baca70ffd25a6865189206</data>
    </edge>
    <edge source="&quot;RESERVOIR&quot;" target="&quot;MODEL&quot;">
      <data key="d4">4.0</data>
      <data key="d5">"The Reservoir is a component of the Model, which stores and processes information from input data."
"The Reservoir component is a part of the Model, contributing to its time series prediction capabilities."
"The Model uses the Reservoir component for processing input data."
"The Model is composed of a Reservoir, which is a recurrent neural network structure used for processing input data."</data>
      <data key="d6">3ff318aebcb07ca141d0a40730d96c7c,46dcc47b4358d3895c1eeb1182c6f997,a0feae89e52a4291db0a512a3a102d8e,eebc9d7d2b66e3898b7d068c38fd200f</data>
    </edge>
    <edge source="&quot;RESERVOIR&quot;" target="&quot;DEEP ECHO STATE NETWORKS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Deep Echo State Networks are constructed using components of type Reservoir."</data>
      <data key="d6">59b469bdd618b3f36b3547f4f2b8a862</data>
    </edge>
    <edge source="&quot;RESERVOIR&quot;" target="&quot;DEEP ESN&quot;">
      <data key="d4">2.0</data>
      <data key="d5">"Deep ESN models use multiple reservoirs to process input data."
"Deep ESN is a type of reservoir computing model that includes multiple interconnected reservoirs."</data>
      <data key="d6">2336a57d055095c6ffa9d156ddee0096,e39809b687cd044a7918eca37727a188</data>
    </edge>
    <edge source="&quot;RESERVOIR&quot;" target="&quot;TIMESTEP&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Reservoir can be triggered on a single timestep of data, which is used as input for the node."</data>
      <data key="d6">0e0afab060f214d46062c9886e762002</data>
    </edge>
    <edge source="&quot;RESERVOIR&quot;" target="&quot;TIMESERIES&quot;">
      <data key="d4">2.0</data>
      <data key="d5">"Reservoir can also be triggered on complete timeseries, which is another form of input for the node."
"The Reservoir processes the Timeseries to gather the activations of its neurons."</data>
      <data key="d6">0e0afab060f214d46062c9886e762002,c4f5a27caf9dd9c1d972492c1147efa0</data>
    </edge>
    <edge source="&quot;RESERVOIR&quot;" target="&quot;NEURONS&quot;">
      <data key="d4">2.0</data>
      <data key="d5">"Reservoir is a recurrent neural network consisting of individual neurons, which can be triggered and activated."
"The Reservoir is composed of Neurons, which evolve in time following the input timeseries."</data>
      <data key="d6">0e0afab060f214d46062c9886e762002,c4f5a27caf9dd9c1d972492c1147efa0</data>
    </edge>
    <edge source="&quot;RESERVOIR&quot;" target="&quot;RIDGE READOUT&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Reservoir is connected to the Ridge Readout, as the input timeseries for training the readout."</data>
      <data key="d6">5d3baa9818a4e01fe1196c43378a2cea</data>
    </edge>
    <edge source="&quot;RESERVOIR&quot;" target="&quot;TIME SERIES DATA&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Reservoir is used to process Time Series Data, such as a Sine Wave."</data>
      <data key="d6">2bcc39da2ecef3011cc3da428fca5dd5</data>
    </edge>
    <edge source="&quot;RESERVOIR&quot;" target="&quot;ESN_MODEL&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Reservoir organization is used to construct the esn_model."</data>
      <data key="d6">751b176a8d6149a853e597c65a6fe0cf</data>
    </edge>
    <edge source="&quot;RESERVOIR&quot;" target="&quot;HIERARCHICAL ESN&quot;">
      <data key="d4">2.0</data>
      <data key="d5">"Reservoirs are used in the construction of hierarchical echo state networks (ESNs)."
"Hierarchical ESN is a type of reservoir computing model that includes multiple reservoirs."</data>
      <data key="d6">00d22666fe697ffb66c2392939f45b39,e39809b687cd044a7918eca37727a188</data>
    </edge>
    <edge source="&quot;RESERVOIR&quot;" target="&quot;UNITS&quot;">
      <data key="d4">3.0</data>
      <data key="d5">"The Reservoir component of the ESN has a specified number of units or neurons."
"The Reservoir component of the ESN model consists of a specified number of Units."
"The Reservoir system is composed of a specific number of UNITS."</data>
      <data key="d6">09198e939639c229c2c97555f65b12a7,72e6eee633bcb5b1458c4cee3975cee1,bba680a0a7dd439bd5b0fe1547ffe040</data>
    </edge>
    <edge source="&quot;RESERVOIR&quot;" target="&quot;INPUT_SCALING&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Input data is scaled using the input_scaling parameter in the Reservoir component of the ESN."</data>
      <data key="d6">09198e939639c229c2c97555f65b12a7</data>
    </edge>
    <edge source="&quot;RESERVOIR&quot;" target="&quot;SPECTRAL_RADIUS&quot;">
      <data key="d4">2.0</data>
      <data key="d5">"The spectral radius of the reservoir's weight matrix is set using the spectral_radius parameter in the ESN."
"The Reservoir system is characterized by the SPECTRAL_RADIUS."</data>
      <data key="d6">09198e939639c229c2c97555f65b12a7,bba680a0a7dd439bd5b0fe1547ffe040</data>
    </edge>
    <edge source="&quot;RESERVOIR&quot;" target="&quot;LEAK_RATE&quot;">
      <data key="d4">2.0</data>
      <data key="d5">"The leakage of the reservoir's neurons is controlled using the leak_rate parameter in the ESN."
"The Reservoir system experiences information loss or decay at the LEAK_RATE."</data>
      <data key="d6">09198e939639c229c2c97555f65b12a7,bba680a0a7dd439bd5b0fe1547ffe040</data>
    </edge>
    <edge source="&quot;RESERVOIR&quot;" target="&quot;CONNECTIVITY&quot;">
      <data key="d4">3.0</data>
      <data key="d5">"The sparsity of the reservoir's weight matrix is set using the connectivity parameter in the ESN."
"The Connectivity parameter is used to control the sparsity and structure of the reservoir in the Echo State Network (ESN) model."
"The Connectivity parameter determines the density of connections between nodes in the Reservoir component of the ESN model."</data>
      <data key="d6">09198e939639c229c2c97555f65b12a7,1365a36c76afc697ac626fd0f784804a,72e6eee633bcb5b1458c4cee3975cee1</data>
    </edge>
    <edge source="&quot;RESERVOIR&quot;" target="&quot;INPUT_CONNECTIVITY&quot;">
      <data key="d4">2.0</data>
      <data key="d5">"The sparsity of the input-to-reservoir weight matrix is set using the input_connectivity parameter in the ESN."
"The Reservoir system interacts with external inputs at the INPUT_CONNECTIVITY level."</data>
      <data key="d6">09198e939639c229c2c97555f65b12a7,bba680a0a7dd439bd5b0fe1547ffe040</data>
    </edge>
    <edge source="&quot;RESERVOIR&quot;" target="&quot;SEED&quot;">
      <data key="d4">2.0</data>
      <data key="d5">"The random number generator in the ESN is initialized using the seed parameter."
"The Reservoir system is initialized with a specific SEED value."</data>
      <data key="d6">09198e939639c229c2c97555f65b12a7,bba680a0a7dd439bd5b0fe1547ffe040</data>
    </edge>
    <edge source="&quot;RESERVOIR&quot;" target="&quot;GENERATIVE MODE&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Generative Mode uses a Reservoir component to generate timeseries data."</data>
      <data key="d6">70db98fabc82fc96ecf8cc2c023b586b</data>
    </edge>
    <edge source="&quot;RESERVOIR&quot;" target="&quot;FORCE&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"FORCE is a node used in the Reservoir network."</data>
      <data key="d6">0c5a253fb2bcebe8674581a5dc12fd96</data>
    </edge>
    <edge source="&quot;RESERVOIR&quot;" target="&quot;RESERVOIR COMPUTING NETWORKS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Reservoir Computing Networks are a type of recurrent neural network that use a reservoir to process input data."</data>
      <data key="d6">324a8f3fb4d19b91457a99999e6d3d17</data>
    </edge>
    <edge source="&quot;RESERVOIR&quot;" target="&quot;ECHO STATE NETWORK (ESN)&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Echo State Network (ESN) model consists of a reservoir component that stores and processes information from the input data."</data>
      <data key="d6">1365a36c76afc697ac626fd0f784804a</data>
    </edge>
    <edge source="&quot;RESERVOIR&quot;" target="&quot;LEAK RATE&quot;">
      <data key="d4">3.0</data>
      <data key="d5">"The Leak Rate parameter is used to control the rate at which information is lost from the reservoir in the Echo State Network (ESN) model."
"The Leak Rate parameter controls the rate of information leakage in the Reservoir component of the ESN model."
"The Reservoir component's Leak Rate is mentioned, indicating its role in the network."</data>
      <data key="d6">1365a36c76afc697ac626fd0f784804a,72e6eee633bcb5b1458c4cee3975cee1,b957e1bf5bf175c7630222ca742c7933</data>
    </edge>
    <edge source="&quot;RESERVOIR&quot;" target="&quot;INPUT CONNECTIVITY&quot;">
      <data key="d4">2.0</data>
      <data key="d5">"The Input Connectivity parameter is used to control the connection between the input data and the reservoir in the Echo State Network (ESN) model."
"The Reservoir component is connected to the input through Input Connectivity."</data>
      <data key="d6">1365a36c76afc697ac626fd0f784804a,b957e1bf5bf175c7630222ca742c7933</data>
    </edge>
    <edge source="&quot;RESERVOIR&quot;" target="&quot;RC_CONNECTIVITY&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Reservoir system's units are interconnected at the RC_CONNECTIVITY level."</data>
      <data key="d6">bba680a0a7dd439bd5b0fe1547ffe040</data>
    </edge>
    <edge source="&quot;RESERVOIR&quot;" target="&quot;RC CONNECTIVITY&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Reservoir component is connected to other components through RC Connectivity."</data>
      <data key="d6">b957e1bf5bf175c7630222ca742c7933</data>
    </edge>
    <edge source="&quot;RESERVOIR&quot;" target="&quot;LEAKING RATES&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Reservoir organization uses Leaking Rates as parameters in their simulations."</data>
      <data key="d6">548c454b31f852543b600df173bd44ab</data>
    </edge>
    <edge source="&quot;RESERVOIR&quot;" target="&quot;DOUBLESCROLL&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Reservoir organization uses the Doublescroll concept to generate data for their simulations."</data>
      <data key="d6">548c454b31f852543b600df173bd44ab</data>
    </edge>
    <edge source="&quot;RESERVOIR&quot;" target="&quot;OPTIMIZE HYPERPARAMETERS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Reservoir organization is involved in the process of Optimizing Hyperparameters, likely to improve the accuracy or performance of their simulations."</data>
      <data key="d6">548c454b31f852543b600df173bd44ab</data>
    </edge>
    <edge source="&quot;RESERVOIR&quot;" target="&quot;SCIKITLEARNNODE&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"ScikitLearnNode is mentioned in the context of using a Reservoir component, but the nature of their relationship is not explicitly stated."</data>
      <data key="d6">2cba60e2f36479613bb0243a19f3a3b4</data>
    </edge>
    <edge source="&quot;INPUT&quot;" target="&quot;NEURAL NETWORKS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Neural Networks process data or information fed into them as input."</data>
      <data key="d6">bf4dccb5096a917a6a71f0cc224e4d7c</data>
    </edge>
    <edge source="&quot;INPUT&quot;" target="&quot;ESNS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Input is a node in ESNs that represents the input data to be processed."</data>
      <data key="d6">f1fc6fbc8158d3da070d55544041a2ca</data>
    </edge>
    <edge source="&quot;INPUT&quot;" target="&quot;READOUT&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The input data is also directly fed into the readout component of the model."</data>
      <data key="d6">58115d5a63315a84d9c8d4e6ddc98ffd</data>
    </edge>
    <edge source="&quot;INPUT&quot;" target="&quot;ESN MODEL&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The ESN Model takes the input data as one of its components."</data>
      <data key="d6">58115d5a63315a84d9c8d4e6ddc98ffd</data>
    </edge>
    <edge source="&quot;INPUT&quot;" target="&quot;ESN&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Input is a component of the ESN model that provides data to the reservoir."</data>
      <data key="d6">f0c8d4d322d73f46464e3e9f6914f2ee</data>
    </edge>
    <edge source="&quot;INPUT&quot;" target="&quot;DEEP ECHO STATE NETWORKS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Deep Echo State Networks are constructed using components of type Input."</data>
      <data key="d6">59b469bdd618b3f36b3547f4f2b8a862</data>
    </edge>
    <edge source="&quot;INPUT&quot;" target="&quot;DEEP ESN&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Input data is fed into Deep ESN models for processing and prediction."</data>
      <data key="d6">2336a57d055095c6ffa9d156ddee0096</data>
    </edge>
    <edge source="&quot;INPUT&quot;" target="&quot;NUMPY&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Numpy is used to create and manipulate input data for echo state networks (ESNs)."</data>
      <data key="d6">00d22666fe697ffb66c2392939f45b39</data>
    </edge>
    <edge source="&quot;INPUT&quot;" target="&quot;HIERARCHICAL ESN&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Input data is fed into hierarchical echo state networks (ESNs) for processing and prediction."</data>
      <data key="d6">00d22666fe697ffb66c2392939f45b39</data>
    </edge>
    <edge source="&quot;INPUT&quot;" target="&quot;MULTI-INPUTS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Multi-inputs refers to the use of multiple data streams or inputs in a reservoir computing model."</data>
      <data key="d6">e39809b687cd044a7918eca37727a188</data>
    </edge>
    <edge source="&quot;JAPANESE VOWELS&quot;" target="&quot;MODEL&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Japanese Vowels dataset is used for training and testing the Model."</data>
      <data key="d6">a0feae89e52a4291db0a512a3a102d8e</data>
    </edge>
    <edge source="&quot;Y_TRAIN&quot;" target="&quot;STATES_TRAIN&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Y_train and states_train are used together in the training process, potentially representing a relationship between labels and states."</data>
      <data key="d6">b101b38a87b2fcac0ff450a4e3f22143</data>
    </edge>
    <edge source="&quot;Y_TRAIN&quot;" target="&quot;X_TRAIN&quot;">
      <data key="d4">3.0</data>
      <data key="d5">"X_train and Y_train are components of a machine learning model used for training, where X_train contains data and Y_train contains corresponding labels or targets."
"X_train and y_train are subsets of the input and output data used for training the ESN."
"X_train and Y_train are datasets used together for training machine learning models, with X_train containing input features and Y_train containing target labels."</data>
      <data key="d6">0036fb6f489e13c0db0f1c02bf3323be,71366a4c7e791080872ba783d3787bd7,b3361508c3e49b5bb3089f10e31d2c81</data>
    </edge>
    <edge source="&quot;Y_TRAIN&quot;" target="&quot;JAPANESE_VOWELS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The japanese_vowels function is used to obtain labels or targets for training data, which is stored in Y_train."</data>
      <data key="d6">b3361508c3e49b5bb3089f10e31d2c81</data>
    </edge>
    <edge source="&quot;Y_TRAIN&quot;" target="&quot;NP.ARGMAX&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The np.argmax function is used to find the indices of the maximum values along an axis in Y_train, which may be used for processing labels or targets."</data>
      <data key="d6">b3361508c3e49b5bb3089f10e31d2c81</data>
    </edge>
    <edge source="&quot;Y_TRAIN&quot;" target="&quot;MODEL&quot;">
      <data key="d4">3.0</data>
      <data key="d5">"The machine learning model is trained using the y_train dataset, which contains the target values."
"The Y_train dataset is used to train the readout component of the Model, enabling it to make predictions based on the reservoir's output."
"Y_train is used for training the Model."</data>
      <data key="d6">3ff318aebcb07ca141d0a40730d96c7c,75e530c1a04e30b373dc7cc68e3ad819,a0feae89e52a4291db0a512a3a102d8e</data>
    </edge>
    <edge source="&quot;Y_TRAIN&quot;" target="&quot;TIME SERIES FORECASTING&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Y_train is a subset of the Y variable used for training the machine learning model in the Time Series Forecasting process."</data>
      <data key="d6">f70c7d3d89baaabbeaad57b58e379e08</data>
    </edge>
    <edge source="&quot;Y_TRAIN&quot;" target="&quot;ESN&quot;">
      <data key="d4">2.0</data>
      <data key="d5">"The Echo State Network (ESN) system is trained using the y_train target data."
"ESN is trained using a subset of the target data, y_train."</data>
      <data key="d6">72e6eee633bcb5b1458c4cee3975cee1,80c9f51870e239404ed671ef0374f191</data>
    </edge>
    <edge source="&quot;Y_TRAIN&quot;" target="&quot;MODEL.FIT()&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Model.fit() is used to train a model on the target data from Y_train, which can be used as feedback during the prediction phase."</data>
      <data key="d6">b338d2dcc1fe6ccf42407444c02cad7c</data>
    </edge>
    <edge source="&quot;Y_TRAIN&quot;" target="&quot;ESN_MODEL&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The esn_model is trained using the Y_train data output."</data>
      <data key="d6">751b176a8d6149a853e597c65a6fe0cf</data>
    </edge>
    <edge source="&quot;Y_TRAIN&quot;" target="&quot;NP.ARRAY&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"np.array is used to create a NumPy array from the output data for training the ESN."</data>
      <data key="d6">71366a4c7e791080872ba783d3787bd7</data>
    </edge>
    <edge source="&quot;Y_TRAIN&quot;" target="&quot;ONEHOTENCODER&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"OneHotEncoder is used for one-hot encoding of categorical variables in the output data for training the ESN."</data>
      <data key="d6">71366a4c7e791080872ba783d3787bd7</data>
    </edge>
    <edge source="&quot;Y_TRAIN&quot;" target="&quot;DATASET&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Y_train is a variable used to store the training target data in the dataset."</data>
      <data key="d6">0982b8d1eb1e636b19fa2e9d9361e566</data>
    </edge>
    <edge source="&quot;Y_TRAIN&quot;" target="&quot;SCIKITLEARNNODE&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The ScikitLearnNode component is trained using the training output data."</data>
      <data key="d6">dc3bd3697a140b64d70e0e3ac6db6c7e</data>
    </edge>
    <edge source="&quot;Y_TRAIN&quot;" target="&quot;RESERVOIR MODEL&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Reservoir Model is trained using the Y_train dataset, which contains the target values."</data>
      <data key="d6">0970cd32ce54f6ee1180ab237fdcefe1</data>
    </edge>
    <edge source="&quot;STATES_TRAIN&quot;" target="&quot;READOUT&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"states_train are used to train the readout component, potentially representing a relationship between states and predictions."</data>
      <data key="d6">b101b38a87b2fcac0ff450a4e3f22143</data>
    </edge>
    <edge source="&quot;STATES_TRAIN&quot;" target="&quot;Y_PRED&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"states_train are used to generate predictions using the readout component, potentially representing a relationship between states and predictions."</data>
      <data key="d6">b101b38a87b2fcac0ff450a4e3f22143</data>
    </edge>
    <edge source="&quot;READOUT&quot;" target="&quot;ECHO STATE NETWORKS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Echo State Networks consist of a readout component, which is a single layer of neurons that decodes the reservoir's activations to perform a task."</data>
      <data key="d6">83fafb2423a01afae7e522917d79ace9</data>
    </edge>
    <edge source="&quot;READOUT&quot;" target="&quot;ESN&quot;">
      <data key="d4">4.0</data>
      <data key="d5">"ESN uses a Readout component to produce the final output prediction."
"Echo State Networks utilize a Readout component to transform the internal state of the network into output predictions."
"ESN is composed of a Readout component."
"The ESN model is composed of a reservoir and a readout, with the readout making predictions based on the output of the reservoir."</data>
      <data key="d6">7b294b788fe5ee385d08c4aabe2ca71d,bf4eaad93f89884d02cdad6a50f145a6,cc1fb6ca5695434ad0279c2606e928af,cdc64af0dde941250d89b191d0666c9b</data>
    </edge>
    <edge source="&quot;READOUT&quot;" target="&quot;ESN MODEL&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The ESN Model uses the readout component to produce the output data."</data>
      <data key="d6">58115d5a63315a84d9c8d4e6ddc98ffd</data>
    </edge>
    <edge source="&quot;READOUT&quot;" target="&quot;CONCATENATE&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The concatenate node combines multiple data inputs and sends the output to the readout node in the ESN model."</data>
      <data key="d6">cf15a09e77b695a117e1cca05461aea2</data>
    </edge>
    <edge source="&quot;READOUT&quot;" target="&quot;REGULARIZED RIDGE REGRESSION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Readout component of an ESN is trained using Regularized Ridge Regression."</data>
      <data key="d6">cdc64af0dde941250d89b191d0666c9b</data>
    </edge>
    <edge source="&quot;READOUT&quot;" target="&quot;LINEAR REGRESSION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Readout is trained using Linear Regression, a statistical method."</data>
      <data key="d6">d25cd385546ec6a033287e75d65a551a</data>
    </edge>
    <edge source="&quot;READOUT&quot;" target="&quot;ECHO STATE NETWORK (ESN)&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Echo State Network (ESN) model consists of a readout component that maps the reservoir's output to the desired output."</data>
      <data key="d6">1365a36c76afc697ac626fd0f784804a</data>
    </edge>
    <edge source="&quot;READOUT&quot;" target="&quot;FORCE&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The FORCE algorithm is used as the readout algorithm in the Echo State Network (ESN) model."</data>
      <data key="d6">1365a36c76afc697ac626fd0f784804a</data>
    </edge>
    <edge source="&quot;X_TEST&quot;" target="&quot;Y_TEST&quot;">
      <data key="d4">3.0</data>
      <data key="d5">"X_test and Y_test are components of a machine learning model used for testing, where X_test contains data and Y_test contains corresponding labels or targets."
"X_test and y_test are subsets of the input and output data used for testing the ESN."
"X_test and Y_test are datasets used together for testing trained machine learning models, with X_test containing input features and Y_test containing target labels."</data>
      <data key="d6">0036fb6f489e13c0db0f1c02bf3323be,71366a4c7e791080872ba783d3787bd7,b3361508c3e49b5bb3089f10e31d2c81</data>
    </edge>
    <edge source="&quot;X_TEST&quot;" target="&quot;MODEL&quot;">
      <data key="d4">2.0</data>
      <data key="d5">"The machine learning model is tested using the x_test dataset."
"X_test is used for testing the Model's performance."</data>
      <data key="d6">75e530c1a04e30b373dc7cc68e3ad819,a0feae89e52a4291db0a512a3a102d8e</data>
    </edge>
    <edge source="&quot;X_TEST&quot;" target="&quot;TIME SERIES FORECASTING&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"X_test is a subset of the X variable used for testing the performance of the trained machine learning model in the Time Series Forecasting process."</data>
      <data key="d6">f70c7d3d89baaabbeaad57b58e379e08</data>
    </edge>
    <edge source="&quot;X_TEST&quot;" target="&quot;ESN&quot;">
      <data key="d4">2.0</data>
      <data key="d5">"The Echo State Network (ESN) system is evaluated using the X_test input data."
"ESN is tested using a subset of the input data, X_test."</data>
      <data key="d6">72e6eee633bcb5b1458c4cee3975cee1,80c9f51870e239404ed671ef0374f191</data>
    </edge>
    <edge source="&quot;X_TEST&quot;" target="&quot;DATASET&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"X_test is a variable used to store the testing input data in the dataset."</data>
      <data key="d6">0982b8d1eb1e636b19fa2e9d9361e566</data>
    </edge>
    <edge source="&quot;X_TEST&quot;" target="&quot;RESERVOIR MODEL&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Reservoir Model is tested using the X_test dataset."</data>
      <data key="d6">0970cd32ce54f6ee1180ab237fdcefe1</data>
    </edge>
    <edge source="&quot;Y_PRED&quot;" target="&quot;Y_TEST&quot;">
      <data key="d4">2.0</data>
      <data key="d5">"Y_pred and Y_test are compared using the accuracy_score function, potentially representing a relationship between predicted labels and true labels."
"The testing output data is compared to the predicted output data to evaluate the performance of the prediction model."</data>
      <data key="d6">b101b38a87b2fcac0ff450a4e3f22143,dc3bd3697a140b64d70e0e3ac6db6c7e</data>
    </edge>
    <edge source="&quot;Y_PRED&quot;" target="&quot;NP.ABS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"np.abs is used to compute the absolute difference between the 'y_test' and 'y_pred' arrays."</data>
      <data key="d6">9078b0f36522f21a9e8e1aadac48ed9c</data>
    </edge>
    <edge source="&quot;Y_PRED&quot;" target="&quot;NP.CONCATENATE&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"np.concatenate is used to combine arrays containing the predicted values generated by a model."</data>
      <data key="d6">00648b24263129fdae8652f1a3339041</data>
    </edge>
    <edge source="&quot;Y_PRED&quot;" target="&quot;NP.FLOAT64&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"np.float64 is used to represent the predicted values generated by a model as 64-bit floating-point numbers."</data>
      <data key="d6">00648b24263129fdae8652f1a3339041</data>
    </edge>
    <edge source="&quot;Y_PRED&quot;" target="&quot;SCIKITLEARNNODE&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The ScikitLearnNode component generates the predicted output data."</data>
      <data key="d6">dc3bd3697a140b64d70e0e3ac6db6c7e</data>
    </edge>
    <edge source="&quot;Y_PRED&quot;" target="&quot;ACCURACY SCORE&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Accuracy Score metric is calculated using the predicted output data."</data>
      <data key="d6">dc3bd3697a140b64d70e0e3ac6db6c7e</data>
    </edge>
    <edge source="&quot;Y_TEST&quot;" target="&quot;NP.ABS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"np.abs is used to compute the absolute difference between the 'y_test' and 'y_pred' arrays."</data>
      <data key="d6">9078b0f36522f21a9e8e1aadac48ed9c</data>
    </edge>
    <edge source="&quot;Y_TEST&quot;" target="&quot;NP.ARGMAX&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The np.argmax function is used to find the indices of the maximum values along an axis in Y_test, which may be used for processing labels or targets."</data>
      <data key="d6">b3361508c3e49b5bb3089f10e31d2c81</data>
    </edge>
    <edge source="&quot;Y_TEST&quot;" target="&quot;NP.CONCATENATE&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"np.concatenate is used to combine arrays containing the actual values used for testing the performance of a model."</data>
      <data key="d6">00648b24263129fdae8652f1a3339041</data>
    </edge>
    <edge source="&quot;Y_TEST&quot;" target="&quot;NP.FLOAT64&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"np.float64 is used to represent the actual values used for testing the performance of a model as 64-bit floating-point numbers."</data>
      <data key="d6">00648b24263129fdae8652f1a3339041</data>
    </edge>
    <edge source="&quot;Y_TEST&quot;" target="&quot;MODEL&quot;">
      <data key="d4">2.0</data>
      <data key="d5">"The machine learning model is tested using the y_test dataset, which contains the actual target values."
"Y_test is used for testing the Model's performance."</data>
      <data key="d6">75e530c1a04e30b373dc7cc68e3ad819,a0feae89e52a4291db0a512a3a102d8e</data>
    </edge>
    <edge source="&quot;Y_TEST&quot;" target="&quot;TIME SERIES FORECASTING&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Y_test is a subset of the Y variable used for testing the performance of the trained machine learning model in the Time Series Forecasting process."</data>
      <data key="d6">f70c7d3d89baaabbeaad57b58e379e08</data>
    </edge>
    <edge source="&quot;Y_TEST&quot;" target="&quot;ESN&quot;">
      <data key="d4">2.0</data>
      <data key="d5">"The Echo State Network (ESN) system is evaluated using the y_test target data."
"ESN is tested using a subset of the target data, y_test."</data>
      <data key="d6">72e6eee633bcb5b1458c4cee3975cee1,80c9f51870e239404ed671ef0374f191</data>
    </edge>
    <edge source="&quot;Y_TEST&quot;" target="&quot;ONE_HOT&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The y_test target data is transformed using one-hot encoding."</data>
      <data key="d6">80c9f51870e239404ed671ef0374f191</data>
    </edge>
    <edge source="&quot;Y_TEST&quot;" target="&quot;OUTPUTS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"y_test is the actual target data compared to the predicted outputs to evaluate the performance of the ESN model."</data>
      <data key="d6">1db5e6cd356c6066227de5e273de1abe</data>
    </edge>
    <edge source="&quot;Y_TEST&quot;" target="&quot;DATASET&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Y_test is a variable used to store the testing target data in the dataset."</data>
      <data key="d6">0982b8d1eb1e636b19fa2e9d9361e566</data>
    </edge>
    <edge source="&quot;Y_TEST&quot;" target="&quot;ACCURACY SCORE&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Accuracy Score metric is calculated using the testing output data."</data>
      <data key="d6">dc3bd3697a140b64d70e0e3ac6db6c7e</data>
    </edge>
    <edge source="&quot;Y_TEST&quot;" target="&quot;ACCURACY_SCORE&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"accuracy_score is used to evaluate the performance of trained machine learning models by comparing their predictions with the actual labels in the Y_test dataset."</data>
      <data key="d6">0036fb6f489e13c0db0f1c02bf3323be</data>
    </edge>
    <edge source="&quot;Y_TEST&quot;" target="&quot;RESERVOIR MODEL&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Reservoir Model is tested using the Y_test dataset, which contains the actual target values."</data>
      <data key="d6">0970cd32ce54f6ee1180ab237fdcefe1</data>
    </edge>
    <edge source="&quot;ACCURACY_SCORE&quot;" target="&quot;MODEL&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"accuracy_score is used to evaluate the performance of a model by comparing its predictions to the actual values."</data>
      <data key="d6">00648b24263129fdae8652f1a3339041</data>
    </edge>
    <edge source="&quot;ACCURACY_SCORE&quot;" target="&quot;ESN&quot;">
      <data key="d4">2.0</data>
      <data key="d5">"ESN's performance is evaluated using the accuracy_score function."
"accuracy_score is used to evaluate the performance of the ESN model, comparing predicted outputs to actual targets."</data>
      <data key="d6">1db5e6cd356c6066227de5e273de1abe,72e6eee633bcb5b1458c4cee3975cee1</data>
    </edge>
    <edge source="&quot;ACCURACY_SCORE&quot;" target="&quot;SKLEARN.METRICS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"sklearn.metrics is a library that provides the accuracy_score metric for evaluating machine learning models."</data>
      <data key="d6">9414efd266e7135a2cdd7461a888b045</data>
    </edge>
    <edge source="&quot;DR. STEPHEN GROSSBERG&quot;" target="&quot;BOSTON UNIVERSITY&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Dr. Stephen Grossberg is affiliated with Boston University, where he conducts research on recurrent neural networks."</data>
      <data key="d6">5e20e3cd48e20db98711d9948014c2d8</data>
    </edge>
    <edge source="&quot;DR. STEPHEN GROSSBERG&quot;" target="&quot;ARTIFICIAL NEURAL NETWORKS (ARNN)&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Dr. Stephen Grossberg's research focuses on recurrent neural networks, including artificial neural networks (aRNN) used in technological applications."</data>
      <data key="d6">5e20e3cd48e20db98711d9948014c2d8</data>
    </edge>
    <edge source="&quot;DR. STEPHEN GROSSBERG&quot;" target="&quot;BIOLOGICAL RECURRENT NEURAL NETWORKS (BRNN)&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Dr. Stephen Grossberg's research also includes biological recurrent neural networks (bRNN) found in the brain."</data>
      <data key="d6">5e20e3cd48e20db98711d9948014c2d8</data>
    </edge>
    <edge source="&quot;MCCULLOCH-PITTS MODEL&quot;" target="&quot;BINARY SYSTEMS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The McCulloch-Pitts Model is a classical model used to describe the interaction of nodes in Binary Systems."</data>
      <data key="d6">5838adba6968ede203f6820ddc368bc4</data>
    </edge>
    <edge source="&quot;MCCULLOCH-PITTS MODEL&quot;" target="&quot;JOHN VON NEUMANN&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The McCulloch-Pitts Model had a significant influence on John von Neumann's development of the digital computer."</data>
      <data key="d6">25eb64dbb12dee61a753085741ee91d4</data>
    </edge>
    <edge source="&quot;MCCULLOCH-PITTS MODEL&quot;" target="&quot;WARREN MCCULLOCH&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Warren McCulloch, along with Walter Pitts, developed the McCulloch-Pitts Model."</data>
      <data key="d6">25eb64dbb12dee61a753085741ee91d4</data>
    </edge>
    <edge source="&quot;MCCULLOCH-PITTS MODEL&quot;" target="&quot;WALTER PITTS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Walter Pitts, along with Warren McCulloch, developed the McCulloch-Pitts Model."</data>
      <data key="d6">25eb64dbb12dee61a753085741ee91d4</data>
    </edge>
    <edge source="&quot;LINEAR SYSTEMS&quot;" target="&quot;CONTINUOUS-NONLINEAR SYSTEMS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Linear Systems and Continuous-Nonlinear Systems are different types of recurrent neural networks that use different methods to combine inputs and produce outputs."</data>
      <data key="d6">5838adba6968ede203f6820ddc368bc4</data>
    </edge>
    <edge source="&quot;CONTINUOUS-NONLINEAR SYSTEMS&quot;" target="&quot;GROSSBERG&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Grossberg has made contributions to the development of Continuous-Nonlinear Systems."</data>
      <data key="d6">5838adba6968ede203f6820ddc368bc4</data>
    </edge>
    <edge source="&quot;SHORT-TERM MEMORY (STM)&quot;" target="&quot;NODES&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Nodes in a network have activities or traces that are used to store and process information in Short-Term Memory (STM)."</data>
      <data key="d6">5838adba6968ede203f6820ddc368bc4</data>
    </edge>
    <edge source="&quot;NODES&quot;" target="&quot;CONCAT NODE&quot;">
      <data key="d4">2.0</data>
      <data key="d5">"A Concat Node aggregates multiple input vectors into a single concatenated vector, allowing subsequent nodes that can only process a single input to handle the combined data.""Nodes can be connected to a Concat Node to handle multiple inputs, while most nodes are designed to process a single input vector."</data>
      <data key="d6">e9f7bc2274e59b0767e1172a848ddca9</data>
    </edge>
    <edge source="&quot;GROSSBERG&quot;" target="&quot;ADAPTIVE BEHAVIOR&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Grossberg discovered laws of Adaptive Behavior in real time."</data>
      <data key="d6">3235445917507f02710bd66cc8368194</data>
    </edge>
    <edge source="&quot;GROSSBERG&quot;" target="&quot;ROCKEFELLER INSTITUTE&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Grossberg was a student at Rockefeller Institute and published a monograph about his research there."</data>
      <data key="d6">3235445917507f02710bd66cc8368194</data>
    </edge>
    <edge source="&quot;GROSSBERG&quot;" target="&quot;COLLEGE FRESHMAN&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Grossberg introduced the paradigm of using nonlinear systems of differential equations while he was a College Freshman."</data>
      <data key="d6">3235445917507f02710bd66cc8368194</data>
    </edge>
    <edge source="&quot;GROSSBERG&quot;" target="&quot;ADDITIVE MODEL&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Additive Model was developed by Grossberg, who made significant contributions to its development and application.")</data>
      <data key="d6">df77d35da87a38cae0984a42b9a1d41c</data>
    </edge>
    <edge source="&quot;GROSSBERG&quot;" target="&quot;NEURAL NETWORKS&quot;">
      <data key="d4">2.0</data>
      <data key="d5">"Grossberg is a researcher contributing to the development of Neural Networks, contributing to the development of the Additive Model and the STM Equation."
"Grossberg is mentioned in the context of reviews related to Neural Networks, indicating his expertise and contributions in the field."</data>
      <data key="d6">47d1d12642cdab6e9a5d21c184f83c9c,4c7e78f7237cb3420e70c7749bb259f9</data>
    </edge>
    <edge source="&quot;GROSSBERG&quot;" target="&quot;STM&quot;">
      <data key="d4">4.0</data>
      <data key="d5">"Grossberg introduced the generalized STM equation, which includes terms such as LTM and MTM that are part of the STM system."
"Grossberg contributed to the development of Short-Term Memory, a component that stores input patterns persistently."
"Grossberg's theorems showed how the choice of feedback signal function transforms an input pattern before it is stored persistently in STM."
"Grossberg's work is mentioned in relation to STM, but the nature of their relationship is not explicitly stated."</data>
      <data key="d6">3a64c8c26895f111f00a349dd69bb505,653b7986c4757bd5d0a251369187efa6,7ba0dfde8cc54bb1dcf66b46fcdd88f8,fba20e559e6ecb61ebbf3a805e6d072c</data>
    </edge>
    <edge source="&quot;GROSSBERG&quot;" target="&quot;STM EQUATION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Grossberg is mentioned as a researcher who has contributed to the development of neural models, including the STM Equation."</data>
      <data key="d6">3281409fdcd18b09ca3109260ddb96d9</data>
    </edge>
    <edge source="&quot;GROSSBERG&quot;" target="&quot;GATED DIPOLE OPPONENT PROCESSING NETWORK&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Grossberg has contributed to the understanding of the Gated Dipole Opponent Processing Network and its functions."</data>
      <data key="d6">be0954a6263de67c84da3141d95de445</data>
    </edge>
    <edge source="&quot;GROSSBERG&quot;" target="&quot;ADAPTIVE WEIGHTS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Grossberg is a researcher who has developed adaptive weights, which are mentioned in the text."</data>
      <data key="d6">24771832864aa38abd6aebec04b13a10</data>
    </edge>
    <edge source="&quot;GROSSBERG&quot;" target="&quot;LTM TRACES&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Grossberg is a researcher who has contributed to the development of LTM traces, which are mentioned in the text."</data>
      <data key="d6">24771832864aa38abd6aebec04b13a10</data>
    </edge>
    <edge source="&quot;GROSSBERG&quot;" target="&quot;OUTSTAR LEARNING&quot;">
      <data key="d4">2.0</data>
      <data key="d5">"Grossberg introduced Outstar Learning as a variant of gated steepest descent learning for spatial pattern learning."
"Outstar Learning was introduced by Grossberg for spatial pattern learning."</data>
      <data key="d6">97ad8d6e6e3bf27ae6a7b457af9b312e,b286a9022774f24a400744b2a1b08bab</data>
    </edge>
    <edge source="&quot;GROSSBERG&quot;" target="&quot;INSTAR LEARNING&quot;">
      <data key="d4">2.0</data>
      <data key="d5">"Grossberg also used Instar Learning in his research."
"Instar Learning was used by Grossberg for learning bottom-up adaptive filters in Self-Organizing Map (SOM) models."</data>
      <data key="d6">97ad8d6e6e3bf27ae6a7b457af9b312e,b286a9022774f24a400744b2a1b08bab</data>
    </edge>
    <edge source="&quot;GROSSBERG&quot;" target="&quot;ART&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Grossberg introduced ART, which uses Instars and Outstars for learning."</data>
      <data key="d6">43cf5e32e2df964318d03574e6cd6cdc</data>
    </edge>
    <edge source="&quot;GROSSBERG&quot;" target="&quot;HECHT-NIELSEN&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Grossberg's work on Instars and Outstars was referred to by Hecht-Nielsen as a counterpropagation network."</data>
      <data key="d6">43cf5e32e2df964318d03574e6cd6cdc</data>
    </edge>
    <edge source="&quot;GROSSBERG&quot;" target="&quot;ON-CENTER OFF-SURROUND NETWORK&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Grossberg proposed the on-center off-surround network as a solution to the noise-saturation dilemma."</data>
      <data key="d6">7beb44dd43aea0791fcb35806356ddb3</data>
    </edge>
    <edge source="&quot;GROSSBERG&quot;" target="&quot;SHUNTING NETWORK&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Grossberg has generalized the feedforward on-center off-surround shunting network equations, generating many useful properties."</data>
      <data key="d6">f290960776c5ec561653e90d2ac6751b</data>
    </edge>
    <edge source="&quot;GROSSBERG&quot;" target="&quot;SHUNTING NETWORK EQUATIONS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Grossberg is a researcher who generalized the feedforward on-center off-surround shunting network equations."</data>
      <data key="d6">f2468cda326d1ca11c98f2fbde186400</data>
    </edge>
    <edge source="&quot;GROSSBERG&quot;" target="&quot;(V^+)&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Grossberg is mentioned in relation to (V^+), possibly indicating their contribution to the concept."</data>
      <data key="d6">91f030f6c14c673e6d029c9bf1a66515</data>
    </edge>
    <edge source="&quot;GROSSBERG&quot;" target="&quot;(V^-)&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Grossberg is mentioned in relation to (V^-), possibly indicating their contribution to the concept."</data>
      <data key="d6">91f030f6c14c673e6d029c9bf1a66515</data>
    </edge>
    <edge source="&quot;GROSSBERG&quot;" target="&quot;RCF&quot;">
      <data key="d4">2.0</data>
      <data key="d5">"Grossberg is mentioned in the context of developing a Recurrent Competitive Field, a type of recurrent neural network."
"Grossberg has been mentioned in the context of shunting dynamics, which is a property of RCF."</data>
      <data key="d6">2cbd29d6f0019f0c85bee43779ae8f4d,3a64c8c26895f111f00a349dd69bb505</data>
    </edge>
    <edge source="&quot;GROSSBERG&quot;" target="&quot;BRNN&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Grossberg's work is mentioned in the context of a bidirectional Recurrent Neural Network, suggesting his contributions to the field."</data>
      <data key="d6">3a64c8c26895f111f00a349dd69bb505</data>
    </edge>
    <edge source="&quot;GROSSBERG&quot;" target="&quot;BUBBLE&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Grossberg's theorems proved the use of sigmoid signal functions to generate a self-normalizing bubble, or partial contrast-enhancement, above a quenching threshold."</data>
      <data key="d6">7ba0dfde8cc54bb1dcf66b46fcdd88f8</data>
    </edge>
    <edge source="&quot;GROSSBERG&quot;" target="&quot;RECURRENT NONLINEAR DYNAMICAL SYSTEMS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Grossberg's theorems began the mathematical classification of recurrent nonlinear dynamical systems, which are applicable to various fields."</data>
      <data key="d6">7ba0dfde8cc54bb1dcf66b46fcdd88f8</data>
    </edge>
    <edge source="&quot;GROSSBERG&quot;" target="&quot;COMPETITIVE LEARNING (CL)&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Grossberg is an author who has developed the Competitive Learning (CL) model."</data>
      <data key="d6">2cbd29d6f0019f0c85bee43779ae8f4d</data>
    </edge>
    <edge source="&quot;GROSSBERG&quot;" target="&quot;ADAPTIVE RESONANCE THEORY (ART)&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Grossberg is an author who has developed the Adaptive Resonance Theory (ART) model."</data>
      <data key="d6">2cbd29d6f0019f0c85bee43779ae8f4d</data>
    </edge>
    <edge source="&quot;GROSSBERG&quot;" target="&quot;COMPETITIVE SYSTEM&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Grossberg developed a mathematical method to classify the dynamics of competitive systems."</data>
      <data key="d6">3334f6dcd53b71cf3ceb7648ead24d5a</data>
    </edge>
    <edge source="&quot;GROSSBERG&quot;" target="&quot;MAY AND LEONARD MODEL&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Grossberg's method was applied to study the May and Leonard Model, which is an example of a competitive system."</data>
      <data key="d6">3334f6dcd53b71cf3ceb7648ead24d5a</data>
    </edge>
    <edge source="&quot;GROSSBERG&quot;" target="&quot;VOTING PARADOX&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Grossberg introduced the Voting Paradox in 1975 and studied it using a method of bRNNs."</data>
      <data key="d6">0af3b52f2586c4e957aee493160223ba</data>
    </edge>
    <edge source="&quot;GROSSBERG&quot;" target="&quot;LIAPUNOV FUNCTIONAL&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Grossberg introduced the Liapunov Functional as a mathematical tool to analyze the behavior of systems."</data>
      <data key="d6">0af3b52f2586c4e957aee493160223ba</data>
    </edge>
    <edge source="&quot;GROSSBERG&quot;" target="&quot;SOCIAL CHAOS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Grossberg's work focuses on the problem of Social Chaos, considering how complicated a system can be and still generate order."</data>
      <data key="d6">0af3b52f2586c4e957aee493160223ba</data>
    </edge>
    <edge source="&quot;GROSSBERG&quot;" target="&quot;ALLIGOOD ET AL.&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Alligood et al. is mentioned in the context of Grossberg's research on the trade-off between global consensus and local signals."</data>
      <data key="d6">597668e07c7554bd2d0cb29399285a39</data>
    </edge>
    <edge source="&quot;GROSSBERG&quot;" target="&quot;SYSTEM (21)&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Grossberg introduced a class of bRNNs, known as System (21), which generates globally-consistent decision-making."</data>
      <data key="d6">597668e07c7554bd2d0cb29399285a39</data>
    </edge>
    <edge source="&quot;GROSSBERG&quot;" target="&quot;NEURAL NETWORK COMPONENTS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Grossberg is mentioned in the text as a co-author in multiple references related to the neural network and its components, suggesting a relationship or connection between the person and the concept."</data>
      <data key="d6">9b30fc06ca06f49c2faa238da7eddc6f</data>
    </edge>
    <edge source="&quot;GROSSBERG&quot;" target="&quot;LAMINART FAMILY&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Grossberg is a researcher associated with the LAMINART Family model."</data>
      <data key="d6">6648b18760b8b182e1097ad15c4df685</data>
    </edge>
    <edge source="&quot;GROSSBERG&quot;" target="&quot;LIST PARSE MODEL&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Grossberg is a researcher associated with the LIST PARSE Model."</data>
      <data key="d6">6648b18760b8b182e1097ad15c4df685</data>
    </edge>
    <edge source="&quot;GROSSBERG&quot;" target="&quot;CARTWORD MODEL&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Grossberg is a researcher associated with the cARTWORD Model."</data>
      <data key="d6">6648b18760b8b182e1097ad15c4df685</data>
    </edge>
    <edge source="&quot;GROSSBERG&quot;" target="&quot;TELOS MODEL&quot;">
      <data key="d4">2.0</data>
      <data key="d5">"Grossberg is a researcher associated with the TELOS Model."
"Grossberg is a co-author of the study that introduces the TELOS Model."</data>
      <data key="d6">6648b18760b8b182e1097ad15c4df685,75495c1fc835d41adf5afcb01e8e520a</data>
    </edge>
    <edge source="&quot;GROSSBERG&quot;" target="&quot;LISTELOS MODEL&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Grossberg is not explicitly mentioned in the context of the lisTELOS Model."</data>
      <data key="d6">75495c1fc835d41adf5afcb01e8e520a</data>
    </edge>
    <edge source="&quot;GROSSBERG&quot;" target="&quot;SPATIAL PATTERN LEARNING&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Grossberg is mentioned in the context of Spatial Pattern Learning, indicating his involvement in research on this topic."</data>
      <data key="d6">5d6b6e0d1a9ace28e21dce2cb0ac78c0</data>
    </edge>
    <edge source="&quot;GROSSBERG&quot;" target="&quot;SIGNAL TRANSMISSION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Grossberg is mentioned in the context of Signal Transmission, indicating his research on this topic."</data>
      <data key="d6">5d6b6e0d1a9ace28e21dce2cb0ac78c0</data>
    </edge>
    <edge source="&quot;GROSSBERG&quot;" target="&quot;UNBIASED SPATIAL PATTERN LEARNING THEOREM&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Grossberg is a researcher who has contributed to the development of the Unbiased Spatial Pattern Learning Theorem."</data>
      <data key="d6">4959d1559344e462a6a7463fd3273659</data>
    </edge>
    <edge source="&quot;GROSSBERG&quot;" target="&quot;PAVLOVIAN CONDITIONING&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Grossberg has made contributions to the field of Pavlovian Conditioning, as evidenced by his research on associative learning and pattern recognition."</data>
      <data key="d6">c486b91dc15a126174fe546094568aaa</data>
    </edge>
    <edge source="&quot;GROSSBERG&quot;" target="&quot;GENERALIZED ADDITIVE MODEL&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Grossberg's research on associative learning and pattern recognition may have led to his involvement in the development of the Generalized Additive Model."</data>
      <data key="d6">c486b91dc15a126174fe546094568aaa</data>
    </edge>
    <edge source="&quot;GROSSBERG&quot;" target="&quot;OUTSTAR LEARNING THEOREM&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Grossberg's research on associative learning and pattern recognition may have contributed to the development of the Outstar Learning Theorem, which is a specific case of the Generalized Additive Model."</data>
      <data key="d6">c486b91dc15a126174fe546094568aaa</data>
    </edge>
    <edge source="&quot;GROSSBERG&quot;" target="&quot;GROSSBERG AND SOMERS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Grossberg and Somers is a collaboration between researchers Grossberg and Somers, who have published on the topic of resynchronizing activities in networks."</data>
      <data key="d6">c486b91dc15a126174fe546094568aaa</data>
    </edge>
    <edge source="&quot;GROSSBERG&quot;" target="&quot;GROSSBERG AND GRUNEWALD&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Grossberg and Grunewald is a collaboration between researchers Grossberg and Grunewald, who have published on the topic of resynchronizing activities in networks."</data>
      <data key="d6">c486b91dc15a126174fe546094568aaa</data>
    </edge>
    <edge source="&quot;GROSSBERG&quot;" target="&quot;YAZDANBAKHSH AND GROSSBERG&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Yazdanbakhsh and Grossberg is a collaboration between researchers Yazdanbakhsh and Grossberg, who have published on the topic of resynchronizing activities in laminar cortical circuits."</data>
      <data key="d6">c486b91dc15a126174fe546094568aaa</data>
    </edge>
    <edge source="&quot;GROSSBERG&quot;" target="&quot;COMPETITIVE LEARNING OR SELF-ORGANIZING MAP NETWORK&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Grossberg has developed the Competitive Learning or Self-Organizing Map Network."</data>
      <data key="d6">644602009dec8474bb5cd4702b391d3e</data>
    </edge>
    <edge source="&quot;GROSSBERG&quot;" target="&quot;ADAPTIVE RESONANCE THEORY&quot;">
      <data key="d4">4.0</data>
      <data key="d5">"Adaptive Resonance Theory was introduced by Grossberg."
"Grossberg introduced Adaptive Resonance Theory in 1976."
"Grossberg coined the term 'stability-plasticity dilemma' in relation to Adaptive Resonance Theory, indicating their association."
"Adaptive Resonance Theory is developed by Grossberg, who is also mentioned for his contributions to other areas of cognitive science."</data>
      <data key="d6">01e2a32da700813f593038a23a618e55,3d5b88f7f81ed9e14f07335bbef17020,554e8565591507441cecaa652cb926db,644602009dec8474bb5cd4702b391d3e</data>
    </edge>
    <edge source="&quot;GROSSBERG&quot;" target="&quot;PASSIVE DECAY ASSOCIATIVE LAW&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Grossberg proposed the use of the Passive Decay Associative Law in his learning models."</data>
      <data key="d6">01e2a32da700813f593038a23a618e55</data>
    </edge>
    <edge source="&quot;GROSSBERG&quot;" target="&quot;SCHOLARPEDIA&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Grossberg is mentioned in the text as having his work reviewed on Scholarpedia, indicating a connection between his contributions and the online encyclopedia."</data>
      <data key="d6">3d5b88f7f81ed9e14f07335bbef17020</data>
    </edge>
    <edge source="&quot;GROSSBERG&quot;" target="&quot;WORKING MEMORY&quot;">
      <data key="d4">3.0</data>
      <data key="d5">"Grossberg is known for his contributions to the understanding of Working Memory and its representation as Item-and-Order WM."
"Grossberg has contributed to the analysis of working memories, including the proof that simple rules generate working memories that can support stable learning and long-term memory of list chunks."
"Grossberg developed the Working Memory model, which explains the storage and retrieval of items in short-term memory, considering factors such as activity levels and noise."</data>
      <data key="d6">1976b19f768a8fdf37207b680c3b2b40,5c4e24fc9bd10d0bd59a84d56f960cf9,b69b23b14e0feccb488ba5412db0824c</data>
    </edge>
    <edge source="&quot;GROSSBERG&quot;" target="&quot;ITEM-AND-ORDER MODELS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Grossberg predicted that Item-and-Order models embody two constraints: the LTM Invariance Principle and the Normalization Rule."</data>
      <data key="d6">4364aa6091e1966365fa889b34f5cf90</data>
    </edge>
    <edge source="&quot;GROSSBERG&quot;" target="&quot;LTM INVARIANCE PRINCIPLE&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Grossberg predicted the LTM Invariance Principle to ensure stable learning and memory of list chunks."</data>
      <data key="d6">dcd38cdc6195b2bbf41d936af0bf1f5f</data>
    </edge>
    <edge source="&quot;GROSSBERG&quot;" target="&quot;NORMALIZATION RULE&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Grossberg predicted the Normalization Rule to support stable learning and memory of list chunks."</data>
      <data key="d6">dcd38cdc6195b2bbf41d936af0bf1f5f</data>
    </edge>
    <edge source="&quot;GROSSBERG&quot;" target="&quot;BRADSKI ET AL.&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Bradski et al. cited Grossberg's work in their mathematical proof of Item-and-Order working memory patterns."</data>
      <data key="d6">c3257facbf1b0a5da49d6a115f66df87</data>
    </edge>
    <edge source="&quot;GROSSBERG&quot;" target="&quot;WORKING MEMORY DESIGN&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Grossberg predicted that all working memories have a similar design to enable stable list chunks to be learned, which is supported by the accumulating evidence."</data>
      <data key="d6">1c0f47f0b77faab56cbeba0e1e3e7e70</data>
    </edge>
    <edge source="&quot;GROSSBERG&quot;" target="&quot;AGAM ET AL.&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Grossberg's predictions about working memory networks and list chunking networks are supported by the data reported by Agam et al."</data>
      <data key="d6">97a9ce754fa34aaf01d6cce57560b247</data>
    </edge>
    <edge source="&quot;GROSSBERG&quot;" target="&quot;MILLER&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Miller's work on immediate memory span is referenced in the context of Grossberg's predictions about working memory networks."</data>
      <data key="d6">97a9ce754fa34aaf01d6cce57560b247</data>
    </edge>
    <edge source="&quot;GROSSBERG&quot;" target="&quot;MURDOCK&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Murdock's work on recall patterns is referenced in the context of Grossberg's predictions about working memory networks."</data>
      <data key="d6">97a9ce754fa34aaf01d6cce57560b247</data>
    </edge>
    <edge source="&quot;GROSSBERG&quot;" target="&quot;IMMEDIATE MEMORY SPAN&quot;">
      <data key="d4">2.0</data>
      <data key="d5">"Grossberg distinguished between the Immediate Memory Span and the Transient Memory Span, suggesting a more dynamic and temporary holding capacity for items in memory."
"Grossberg has distinguished between the Immediate Memory Span and the Transient Memory Span."</data>
      <data key="d6">b69b23b14e0feccb488ba5412db0824c,c580fa74e3c36285cfae7df56340a990</data>
    </edge>
    <edge source="&quot;GROSSBERG&quot;" target="&quot;SERIAL VERBAL LEARNING&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Grossberg's work on Serial Verbal Learning highlights the influence of associative and competitive mechanisms in the learning and remembering of verbal sequences."</data>
      <data key="d6">b69b23b14e0feccb488ba5412db0824c</data>
    </edge>
    <edge source="&quot;GROSSBERG&quot;" target="&quot;TMS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Grossberg proved that the TMS is smaller than the IMS."</data>
      <data key="d6">392028b79561bd7471cb68e7c9258b1e</data>
    </edge>
    <edge source="&quot;GROSSBERG&quot;" target="&quot;COMMAND CELLS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Grossberg proposed the inclusion of command cells in circuits to allow for sensitivity to environmental feedback."</data>
      <data key="d6">7aeda101aa8aba76f319932f0bd568f7</data>
    </edge>
    <edge source="&quot;GROSSBERG&quot;" target="&quot;AVALANCHE&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Grossberg is mentioned in the context of describing mechanisms that modulate Avalanche performance."</data>
      <data key="d6">88a3f14024e29666891496bb6cd7d0e4</data>
    </edge>
    <edge source="&quot;GROSSBERG&quot;" target="&quot;COGEM THEORY&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Grossberg is mentioned in the context of proposing the Cognitive-Emotional-Motor theory of reinforcement learning."</data>
      <data key="d6">88a3f14024e29666891496bb6cd7d0e4</data>
    </edge>
    <edge source="&quot;GROSSBERG&quot;" target="&quot;SELF-ORGANIZING AVALANCHE&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Grossberg is associated with the development and analysis of Self-Organizing Avalanches."</data>
      <data key="d6">2ea6b3379a87077d75e5c45024f4f3e2</data>
    </edge>
    <edge source="&quot;GROSSBERG&quot;" target="&quot;CONTEXT-SENSITIVE SELF-ORGANIZING AVALANCHE&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Grossberg's work on Self-Organizing Avalanches has led to the development of Context-Sensitive Self-Organizing Avalanches."</data>
      <data key="d6">2ea6b3379a87077d75e5c45024f4f3e2</data>
    </edge>
    <edge source="&quot;FRANK ROSENBLATT&quot;" target="&quot;CLASSICAL PERCEPTRON MODEL&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Frank Rosenblatt developed the continuous-time STM equation used in the classical Perceptron model."</data>
      <data key="d6">25eb64dbb12dee61a753085741ee91d4</data>
    </edge>
    <edge source="&quot;FRANK CAIANIELLO&quot;" target="&quot;BINARY STM EQUATION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Frank Caianiello developed a binary STM equation influenced by activities at multiple times in the past."</data>
      <data key="d6">25eb64dbb12dee61a753085741ee91d4</data>
    </edge>
    <edge source="&quot;CAIANIELLO&quot;" target="&quot;STM&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Caianiello's work introduced equations to change the weights in a learning model, which is mentioned in relation to STM."</data>
      <data key="d6">9e901f71d0d2339294da133518f2162f</data>
    </edge>
    <edge source="&quot;ROSENBLATT&quot;" target="&quot;LTM&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Rosenblatt's work introduced equations to change the weights in a learning model, which are referred to as LTM traces."</data>
      <data key="d6">9e901f71d0d2339294da133518f2162f</data>
    </edge>
    <edge source="&quot;ROSENBLATT&quot;" target="&quot;LTM EQUATIONS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Rosenblatt developed the LTM equations used for pattern classification."</data>
      <data key="d6">7c556574ea1f1f26ee3ad2a63d56b8e7</data>
    </edge>
    <edge source="&quot;WIDROW&quot;" target="&quot;ADELINE&quot;">
      <data key="d4">2.0</data>
      <data key="d5">"Widrow introduced the gradient descent Adeline adaptive pattern recognition machine."
"Widrow developed the gradient descent Adeline adaptive pattern recognition machine."</data>
      <data key="d6">7c556574ea1f1f26ee3ad2a63d56b8e7,9e901f71d0d2339294da133518f2162f</data>
    </edge>
    <edge source="&quot;ANDERSON&quot;" target="&quot;NEURAL PATTERN RECOGNITION&quot;">
      <data key="d4">2.0</data>
      <data key="d5">"Anderson described neural pattern recognition using a spatial cross-correlation function."
"Anderson initially described neural pattern recognition using a spatial cross-correlation function."</data>
      <data key="d6">7c556574ea1f1f26ee3ad2a63d56b8e7,9e901f71d0d2339294da133518f2162f</data>
    </edge>
    <edge source="&quot;STM&quot;" target="&quot;LTM&quot;">
      <data key="d4">6.0</data>
      <data key="d5">"STM and LTM are mentioned in the text in relation to uncoupled interactions in learning models."
"STM includes LTM as a type of memory system, which changes at a slower rate than STM."
"LTM traces learn to match the pattern of activities, or STM traces, of cells across the network."
"STM and LTM are mentioned together in the context of unifying their interactions, suggesting a relationship between the two types of memory."
"STM and LTM are mentioned together in the text, suggesting a relationship or connection between the two components of the neural network."
"STM and LTM interact with each other during Neuronal Learning, allowing the learning of spatial patterns."</data>
      <data key="d6">53f5bc3f4c71310c593a23aef01d1633,653b7986c4757bd5d0a251369187efa6,97ad8d6e6e3bf27ae6a7b457af9b312e,9b30fc06ca06f49c2faa238da7eddc6f,9e901f71d0d2339294da133518f2162f,b881b9051ad24c6a16b468803fba51d3</data>
    </edge>
    <edge source="&quot;STM&quot;" target="&quot;MTM&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"STM includes MTM as a type of memory system, which changes at a rate intermediate between STM and LTM."</data>
      <data key="d6">653b7986c4757bd5d0a251369187efa6</data>
    </edge>
    <edge source="&quot;STM&quot;" target="&quot;WILSON-COWAN MODEL&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Wilson-Cowan Model uses a sigmoid of sums that is multiplied by a shunting term, which is a characteristic of the STM equation."</data>
      <data key="d6">653b7986c4757bd5d0a251369187efa6</data>
    </edge>
    <edge source="&quot;STM&quot;" target="&quot;LTM TRACES&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"STM traces are mentioned in the text as influencing the learning of LTM traces, which are not Hebbian learning."</data>
      <data key="d6">24771832864aa38abd6aebec04b13a10</data>
    </edge>
    <edge source="&quot;STM&quot;" target="&quot;LEABRA MODEL&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"STM is a component used in the Leabra model, which temporarily stores and processes information."</data>
      <data key="d6">b40ff9b93414391d5e4b3c06dfe02bc9</data>
    </edge>
    <edge source="&quot;STM&quot;" target="&quot;THE BRAIN&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"STM is mentioned as a component of the brain that enables it to process and learn from spatial and temporal patterns of information."</data>
      <data key="d6">0d925896ce2bf9b73be90d8fa5ddb402</data>
    </edge>
    <edge source="&quot;STM&quot;" target="&quot;BRNN&quot;">
      <data key="d4">2.0</data>
      <data key="d5">"STM is mentioned in relation to bRNN, possibly indicating a connection or relationship between the two concepts."
"Short-Term Memory is a component mentioned in the context of a bidirectional Recurrent Neural Network."</data>
      <data key="d6">3a64c8c26895f111f00a349dd69bb505,91f030f6c14c673e6d029c9bf1a66515</data>
    </edge>
    <edge source="&quot;STM&quot;" target="&quot;BUBBLE&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The bubble refers to a self-normalizing process that occurs during the storage of input patterns in STM."</data>
      <data key="d6">7ba0dfde8cc54bb1dcf66b46fcdd88f8</data>
    </edge>
    <edge source="&quot;STM&quot;" target="&quot;INPUTS I_I AND J_I&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"STM is mentioned as storing patterns in signals, and the ability to do so is influenced by the variables I_i and J_i, which are set to zero during the storage process."</data>
      <data key="d6">b4f6256f3430f1aa72ca8092809ebba1</data>
    </edge>
    <edge source="&quot;STM&quot;" target="&quot;A&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"STM is mentioned in relation to the variable A, with its storage being influenced by the comparison between A and B."</data>
      <data key="d6">8da881a4f375e8a524fd0bf46ae2279e</data>
    </edge>
    <edge source="&quot;STM&quot;" target="&quot;B&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"STM is mentioned in relation to the variable B, with its storage being influenced by the comparison between A and B."</data>
      <data key="d6">8da881a4f375e8a524fd0bf46ae2279e</data>
    </edge>
    <edge source="&quot;STM&quot;" target="&quot;X(T)&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"STM is mentioned in relation to the function x(t), with its storage being influenced by the presence or absence of input patterns."</data>
      <data key="d6">8da881a4f375e8a524fd0bf46ae2279e</data>
    </edge>
    <edge source="&quot;STM&quot;" target="&quot;SIGNAL FUNCTION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"STM requires a Signal Function that can suppress noise and store more than one feature or category, which is a challenge addressed in the text."</data>
      <data key="d6">35551dc55b5522082b778171ff6d1bf9</data>
    </edge>
    <edge source="&quot;STM&quot;" target="&quot;SIGMOID SIGNAL FUNCTION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"STM stores partially contrast-enhanced patterns, which are enhanced using a Sigmoid Signal Function."</data>
      <data key="d6">6a47ed5881928d48cdcb74e40867a711</data>
    </edge>
    <edge source="&quot;STM&quot;" target="&quot;QUENCHING THRESHOLD&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Quenching Threshold converts the network into a tunable filter, facilitating storage of inputs in STM."</data>
      <data key="d6">6a47ed5881928d48cdcb74e40867a711</data>
    </edge>
    <edge source="&quot;STM&quot;" target="&quot;NEURONAL LEARNING&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"STM is a component involved in the process of Neuronal Learning."</data>
      <data key="d6">b881b9051ad24c6a16b468803fba51d3</data>
    </edge>
    <edge source="&quot;STM&quot;" target="&quot;GENERALIZED ADDITIVE RNNS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"STM is a component of the Generalized Additive RNNs architecture that sends axons to other cells."</data>
      <data key="d6">5812b5d4bcdfbf80de28dca56a6559b3</data>
    </edge>
    <edge source="&quot;STM&quot;" target="&quot;WM&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"WM is composed of Short-Term Memory, which stores information temporarily for immediate use."</data>
      <data key="d6">c580fa74e3c36285cfae7df56340a990</data>
    </edge>
    <edge source="&quot;LTM&quot;" target="&quot;HEBB&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Hebb's learning postulate assumes the wrong processing unit; it is not the strength of an individual connection, but a distributed pattern of LTM traces."</data>
      <data key="d6">97ad8d6e6e3bf27ae6a7b457af9b312e</data>
    </edge>
    <edge source="&quot;LTM&quot;" target="&quot;LEABRA MODEL&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"LTM is a component used in the Leabra model, which stores and retrieves information over an extended period."</data>
      <data key="d6">b40ff9b93414391d5e4b3c06dfe02bc9</data>
    </edge>
    <edge source="&quot;LTM&quot;" target="&quot;THE BRAIN&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"LTM is mentioned as a component of the brain that enables it to store and retrieve learned information."</data>
      <data key="d6">0d925896ce2bf9b73be90d8fa5ddb402</data>
    </edge>
    <edge source="&quot;LTM&quot;" target="&quot;NEURONAL LEARNING&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"LTM is a component involved in the process of Neuronal Learning."</data>
      <data key="d6">b881b9051ad24c6a16b468803fba51d3</data>
    </edge>
    <edge source="&quot;LTM&quot;" target="&quot;GENERALIZED ADDITIVE RNNS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"LTM is a component of the Generalized Additive RNNs architecture that receives axons from other cells."</data>
      <data key="d6">5812b5d4bcdfbf80de28dca56a6559b3</data>
    </edge>
    <edge source="&quot;LTM&quot;" target="&quot;WM&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"WM also interacts with Long-Term Memory, which stores information for long-term retention and retrieval."</data>
      <data key="d6">c580fa74e3c36285cfae7df56340a990</data>
    </edge>
    <edge source="&quot;LTM&quot;" target="&quot;TMS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"LTM is mentioned as a factor that biases working memory toward more primacy dominance, which may influence the comparison between the TMS and the IMS."</data>
      <data key="d6">392028b79561bd7471cb68e7c9258b1e</data>
    </edge>
    <edge source="&quot;PERCEPTRON&quot;" target="&quot;CLASSIFICATION TASKS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Perceptron is a suitable algorithm for binary Classification Tasks, separating data points into two classes."</data>
      <data key="d6">dadca3c89b34dc48a60c53367ab55768</data>
    </edge>
    <edge source="&quot;PERCEPTRON&quot;" target="&quot;SCIKITLEARNNODE&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"ScikitLearnNode provides an interface to the Perceptron model from scikit-learn."</data>
      <data key="d6">35631fbf2ad11c53d75cb9b42e2c39b4</data>
    </edge>
    <edge source="&quot;PERCEPTRON&quot;" target="&quot;SCIKIT-LEARN&quot;">
      <data key="d4">3.0</data>
      <data key="d5">"scikit-learn implements the Perceptron classifier, which can be used for binary classification tasks."
"Scikit-learn provides the Perceptron model for classification tasks."
"Perceptron is a machine learning algorithm provided by the Scikit-learn library."</data>
      <data key="d6">0036fb6f489e13c0db0f1c02bf3323be,d58662ee42c14a0787d839ebfd0a6e9b,f5358a50d00a1cac02dd4ad8fcb167ee</data>
    </edge>
    <edge source="&quot;KOHONEN&quot;" target="&quot;NEURAL NETWORK RESEARCH&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Kohonen made a transition from linear algebra concepts to more biologically motivated studies in neural network research."</data>
      <data key="d6">7c556574ea1f1f26ee3ad2a63d56b8e7</data>
    </edge>
    <edge source="&quot;KOHONEN&quot;" target="&quot;INSTAR LEARNING&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Instar Learning was also used by Kohonen in his applications of the Self-Organizing Map (SOM) model."</data>
      <data key="d6">b286a9022774f24a400744b2a1b08bab</data>
    </edge>
    <edge source="&quot;KOHONEN&quot;" target="&quot;SOM MODEL&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Kohonen used Instar Learning in his applications of the SOM model."</data>
      <data key="d6">43cf5e32e2df964318d03574e6cd6cdc</data>
    </edge>
    <edge source="&quot;KOHONEN&quot;" target="&quot;SELF-ORGANIZING MAP (SOM)&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Kohonen is an author who has developed the Self-Organizing Map (SOM) model."</data>
      <data key="d6">2cbd29d6f0019f0c85bee43779ae8f4d</data>
    </edge>
    <edge source="&quot;HARTLINE&quot;" target="&quot;STEADY STATE HARTLINE-RATLIFF MODEL&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Hartline's neurophysiological experiments led to the development of the steady state Hartline-Ratliff model."</data>
      <data key="d6">7c556574ea1f1f26ee3ad2a63d56b8e7</data>
    </edge>
    <edge source="&quot;NEURAL NETWORK RESEARCH&quot;" target="&quot;ADDITIVE MODEL&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Additive Model has been a cornerstone of neural network research, contributing to various fields and applications.")</data>
      <data key="d6">df77d35da87a38cae0984a42b9a1d41c</data>
    </edge>
    <edge source="&quot;HARTLINE-RATLIFF MODEL&quot;" target="&quot;H.K. HARTLINE&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"H.K. Hartline is a key figure in the development of the Hartline-Ratliff Model, which he co-authored with J.A. Ratliff."</data>
      <data key="d6">48763056731d01884b6cf37bf0e0d0db</data>
    </edge>
    <edge source="&quot;HARTLINE-RATLIFF MODEL&quot;" target="&quot;J.A. RATLIFF&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"J.A. Ratliff extended the steady-state Hartline-Ratliff model to a dynamical model, contributing to its development."</data>
      <data key="d6">48763056731d01884b6cf37bf0e0d0db</data>
    </edge>
    <edge source="&quot;HARTLINE-RATLIFF MODEL&quot;" target="&quot;LIMULUS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Neurophysiological experiments on the lateral eye of the Limulus inspired the development of the Hartline-Ratliff Model."</data>
      <data key="d6">48763056731d01884b6cf37bf0e0d0db</data>
    </edge>
    <edge source="&quot;J.A. RATLIFF&quot;" target="&quot;ADDITIVE MODEL&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Additive Model is described as a precursor of the dynamical model developed by J.A. Ratliff."</data>
      <data key="d6">48763056731d01884b6cf37bf0e0d0db</data>
    </edge>
    <edge source="&quot;ADDITIVE MODEL&quot;" target="&quot;COMPUTATIONAL ANALYSIS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Additive Model is applied in the Computational Analysis, where it is used to analyze and understand complex systems."</data>
      <data key="d6">9ed5e24bce2907e0ffa4acbe066dbfff</data>
    </edge>
    <edge source="&quot;ADDITIVE MODEL&quot;" target="&quot;MAIN TERM&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Additive Model consists of a Main Term, which is the primary term in the equation."</data>
      <data key="d6">9ed5e24bce2907e0ffa4acbe066dbfff</data>
    </edge>
    <edge source="&quot;ADDITIVE MODEL&quot;" target="&quot;POSITIVE FEEDBACK TERM&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Additive Model includes a Positive Feedback Term, which represents the influence of positive feedback on the system."</data>
      <data key="d6">9ed5e24bce2907e0ffa4acbe066dbfff</data>
    </edge>
    <edge source="&quot;ADDITIVE MODEL&quot;" target="&quot;NEGATIVE FEEDBACK TERM&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Additive Model includes a Negative Feedback Term, which represents the influence of negative feedback on the system."</data>
      <data key="d6">9ed5e24bce2907e0ffa4acbe066dbfff</data>
    </edge>
    <edge source="&quot;ADDITIVE MODEL&quot;" target="&quot;INPUT TERM&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Additive Model includes an Input Term, which represents external inputs to the system."</data>
      <data key="d6">9ed5e24bce2907e0ffa4acbe066dbfff</data>
    </edge>
    <edge source="&quot;ADDITIVE MODEL&quot;" target="&quot;COMPUTATIONAL VISION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Additive Model has been used in computational analyses of vision, contributing to recognition and analysis in this field.")</data>
      <data key="d6">df77d35da87a38cae0984a42b9a1d41c</data>
    </edge>
    <edge source="&quot;ADDITIVE MODEL&quot;" target="&quot;LEARNING&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Additive Model has been used in learning applications, contributing to decision-making and analysis in this field.")</data>
      <data key="d6">df77d35da87a38cae0984a42b9a1d41c</data>
    </edge>
    <edge source="&quot;ADDITIVE MODEL&quot;" target="&quot;SPEECH AND LANGUAGE ANALYSIS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Additive Model has been used in the analysis of temporal order in speech and language, contributing to understanding and control in this field.")</data>
      <data key="d6">df77d35da87a38cae0984a42b9a1d41c</data>
    </edge>
    <edge source="&quot;ADDITIVE MODEL&quot;" target="&quot;SENSORY-MOTOR CONTROL&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Additive Model has been used in the analysis and control of sensory-motor functions, contributing to understanding and control in this field.")</data>
      <data key="d6">df77d35da87a38cae0984a42b9a1d41c</data>
    </edge>
    <edge source="&quot;ADDITIVE MODEL&quot;" target="&quot;NEURAL NETWORKS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Additive Model is a concept used in the study and development of Neural Networks."</data>
      <data key="d6">47d1d12642cdab6e9a5d21c184f83c9c</data>
    </edge>
    <edge source="&quot;ADDITIVE MODEL&quot;" target="&quot;STM EQUATION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Additive Model is another variant of the STM Equation, with different parameter values."</data>
      <data key="d6">3281409fdcd18b09ca3109260ddb96d9</data>
    </edge>
    <edge source="&quot;ADDITIVE MODEL&quot;" target="&quot;HOPFIELD&quot;">
      <data key="d4">2.0</data>
      <data key="d5">"Hopfield stated a Liapunov function for the Additive Model, which is mentioned in the context of Cohen and Grossberg's generalization."
"The Additive Model has been erroneously called the Hopfield network, despite its earlier publications and the Liapunov function's earlier publication."</data>
      <data key="d6">98173c1c0fcd64ceb914e0dd6b366b30,d4afac3b7aed3d6e11ff5eaf34589c2d</data>
    </edge>
    <edge source="&quot;ADDITIVE MODEL&quot;" target="&quot;LIAPUNOV FUNCTION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Hopfield stated a Liapunov function for the Additive Model."</data>
      <data key="d6">be0954a6263de67c84da3141d95de445</data>
    </edge>
    <edge source="&quot;ADDITIVE MODEL&quot;" target="&quot;RCF&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Additive Model does not exhibit the self-normalization properties that arise from RCF shunting dynamics."</data>
      <data key="d6">2cbd29d6f0019f0c85bee43779ae8f4d</data>
    </edge>
    <edge source="&quot;HUGH EVERETT&quot;" target="&quot;NEURAL NETWORKS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Hugh Everett extended a steady-state model to a dynamical model, which is a precursor to the Neural Networks studied by John Hopfield."</data>
      <data key="d6">caf44d8df044312829ae3fe56df0c440</data>
    </edge>
    <edge source="&quot;ANDREW HODGKIN&quot;" target="&quot;NEURAL NETWORKS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Andrew Hodgkin and Alan Huxley's study of the squid giant axon in 1952 provides a foundation for the Neural Networks studied by John Hopfield."</data>
      <data key="d6">caf44d8df044312829ae3fe56df0c440</data>
    </edge>
    <edge source="&quot;ANDREW HODGKIN&quot;" target="&quot;SQUID GIANT AXON&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Andrew Hodgkin and Alan Huxley studied the squid giant axon in 1952."</data>
      <data key="d6">caf44d8df044312829ae3fe56df0c440</data>
    </edge>
    <edge source="&quot;ALAN HUXLEY&quot;" target="&quot;SQUID GIANT AXON&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Alan Huxley and Andrew Hodgkin studied the squid giant axon in 1952."</data>
      <data key="d6">caf44d8df044312829ae3fe56df0c440</data>
    </edge>
    <edge source="&quot;JOHN HOPFIELD&quot;" target="&quot;NEURAL NETWORKS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"John Hopfield derived neural networks that form the foundation of most current biological neural network research in 1982."</data>
      <data key="d6">caf44d8df044312829ae3fe56df0c440</data>
    </edge>
    <edge source="&quot;JOHN HOPFIELD&quot;" target="&quot;RECURRENT NEURAL NETWORK&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The term 'infinite impulse response' is associated with Hopfield networks, which are a type of recurrent neural network developed by John Hopfield."</data>
      <data key="d6">f5b970cf7201f4a918d8bd6a1267657c</data>
    </edge>
    <edge source="&quot;NEURAL NETWORKS&quot;" target="&quot;USHER&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Usher is a researcher contributing to the development and study of Neural Networks."</data>
      <data key="d6">47d1d12642cdab6e9a5d21c184f83c9c</data>
    </edge>
    <edge source="&quot;NEURAL NETWORKS&quot;" target="&quot;MCCLELLAND&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"McClelland is a researcher contributing to the development and study of Neural Networks."</data>
      <data key="d6">47d1d12642cdab6e9a5d21c184f83c9c</data>
    </edge>
    <edge source="&quot;NEURAL NETWORKS&quot;" target="&quot;HOPFIELD&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Hopfield is a researcher contributing to the development of Neural Networks, specifically the Hopfield model."</data>
      <data key="d6">47d1d12642cdab6e9a5d21c184f83c9c</data>
    </edge>
    <edge source="&quot;NEURAL NETWORKS&quot;" target="&quot;STM EQUATION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The STM Equation is a concept used in the modeling of individual neurons within Neural Networks."</data>
      <data key="d6">47d1d12642cdab6e9a5d21c184f83c9c</data>
    </edge>
    <edge source="&quot;NEURAL NETWORKS&quot;" target="&quot;STANLEY GROSSBERG&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Stanley Grossberg's research has significantly contributed to the field of Neural Networks, particularly in the areas of learning theories and spatial pattern learning."</data>
      <data key="d6">be49e9beb2d7cc985fe9f6517fa0f4fe</data>
    </edge>
    <edge source="&quot;NEURAL NETWORKS&quot;" target="&quot;DAVID RUMELHART&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"David Rumelhart contributed to the development of neural networks in 1986."</data>
      <data key="d6">b31ca51b419f7270ee5f4910c90ea331</data>
    </edge>
    <edge source="&quot;NEURAL NETWORKS&quot;" target="&quot;SEQUENCE PREDICTION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Neural Networks, such as Elman Networks, can perform tasks such as sequence prediction by maintaining a sort of state."</data>
      <data key="d6">bf4dccb5096a917a6a71f0cc224e4d7c</data>
    </edge>
    <edge source="&quot;NEURAL NETWORKS&quot;" target="&quot;HIDDEN LAYER&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Neural Networks have an intermediate layer of neurons, known as the hidden layer, that processes the input data."</data>
      <data key="d6">bf4dccb5096a917a6a71f0cc224e4d7c</data>
    </edge>
    <edge source="&quot;COMPUTATIONAL ANALYSIS&quot;" target="&quot;MATHEMATICAL PROCESSES&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Computational Analysis may involve Mathematical Processes, which involve the application of mathematical concepts and techniques."</data>
      <data key="d6">9ed5e24bce2907e0ffa4acbe066dbfff</data>
    </edge>
    <edge source="&quot;COMPUTATIONAL ANALYSIS&quot;" target="&quot;COMPUTATIONAL PROCESSES&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Computational Analysis may involve Computational Processes, which involve the use of computers and algorithms to perform calculations and simulations."</data>
      <data key="d6">9ed5e24bce2907e0ffa4acbe066dbfff</data>
    </edge>
    <edge source="&quot;HOPFIELD MODEL&quot;" target="&quot;HOPFIELD&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Hopfield Model was developed by Hopfield, which is a simplified version of the Additive Model.")</data>
      <data key="d6">df77d35da87a38cae0984a42b9a1d41c</data>
    </edge>
    <edge source="&quot;HOPFIELD&quot;" target="&quot;LIAPUNOV FUNCTION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Hopfield published a special case of the Additive Model and Liapunov function, asserting that trajectories approach equilibria."</data>
      <data key="d6">98173c1c0fcd64ceb914e0dd6b366b30</data>
    </edge>
    <edge source="&quot;STM EQUATION&quot;" target="&quot;SHUNTING MODEL&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Shunting Model is a variant of the STM Equation, with specific parameter values."</data>
      <data key="d6">3281409fdcd18b09ca3109260ddb96d9</data>
    </edge>
    <edge source="&quot;STM EQUATION&quot;" target="&quot;FAST INHIBITION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The STM Equation assumes Fast Inhibition, a feature that assumes inhibitory interneurons respond instantly."</data>
      <data key="d6">3281409fdcd18b09ca3109260ddb96d9</data>
    </edge>
    <edge source="&quot;STM EQUATION&quot;" target="&quot;SLOWER INHIBITION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The STM Equation can also consider Slower Inhibition, which accounts for the temporal evolution of inhibitory interneuronal activities."</data>
      <data key="d6">3281409fdcd18b09ca3109260ddb96d9</data>
    </edge>
    <edge source="&quot;STM TRACES&quot;" target="&quot;SOURCE CELLS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"STM Traces represent activities in a neural system, originating from Source Cells."</data>
      <data key="d6">18be9bfe53d3b9c1e15c1c8238674459</data>
    </edge>
    <edge source="&quot;STM TRACES&quot;" target="&quot;GENERALIZED ADDITIVE SYSTEM&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"STM Traces are a component of the Generalized Additive System."</data>
      <data key="d6">8bb0e63353e66a2c60a878028beff5f9</data>
    </edge>
    <edge source="&quot;STM TRACES&quot;" target="&quot;LTM TRACES&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"STM Traces and LTM Traces are components of the same system, the Generalized Additive System."</data>
      <data key="d6">8bb0e63353e66a2c60a878028beff5f9</data>
    </edge>
    <edge source="&quot;SHUNTING MODEL&quot;" target="&quot;FEEDFORWARD ON-CENTER NETWORK&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The cells in the Feedforward On-Center Network obey a simple version of the Shunting Model, as defined in equation (8)."</data>
      <data key="d6">68b4b33f0da5edc9dcb301a08821b352</data>
    </edge>
    <edge source="&quot;COWAN&quot;" target="&quot;IMS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Cowan reviewed experimental data supporting the existence of a four plus or minus one WM capacity limit for the IMS."</data>
      <data key="d6">392028b79561bd7471cb68e7c9258b1e</data>
    </edge>
    <edge source="&quot;MTM&quot;" target="&quot;LEABRA MODEL&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"MTM is a component used in the Leabra model, which stores and retrieves information for a moderate duration."</data>
      <data key="d6">b40ff9b93414391d5e4b3c06dfe02bc9</data>
    </edge>
    <edge source="&quot;COHEN AND GROSSBERG&quot;" target="&quot;ADDITIVE AND SHUNTING MODELS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Cohen and Grossberg derived a Liapunov function for a generalization of the Additive and Shunting Models."</data>
      <data key="d6">d4afac3b7aed3d6e11ff5eaf34589c2d</data>
    </edge>
    <edge source="&quot;COHEN AND GROSSBERG&quot;" target="&quot;MEDIUM-TERM MEMORY (MTM)&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Cohen and Grossberg's work involves the concept of Medium-term memory (MTM), which they describe as habituative transmitter gates."</data>
      <data key="d6">d4afac3b7aed3d6e11ff5eaf34589c2d</data>
    </edge>
    <edge source="&quot;COHEN AND GROSSBERG&quot;" target="&quot;COHEN-GROSSBERG SYSTEMS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Cohen and Grossberg are the researchers who developed Cohen-Grossberg Systems."</data>
      <data key="d6">4b48be5db14c2e681ef8f4ee7de4b847</data>
    </edge>
    <edge source="&quot;COHEN AND GROSSBERG&quot;" target="&quot;LIAPUNOV METHODS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Cohen and Grossberg used Liapunov Methods as inspiration in their research."</data>
      <data key="d6">4b48be5db14c2e681ef8f4ee7de4b847</data>
    </edge>
    <edge source="&quot;COHEN AND GROSSBERG&quot;" target="&quot;MASKING FIELD MODEL&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Cohen and Grossberg developed the Masking Field Model, which is a specific model within the broader context of their research."</data>
      <data key="d6">4b48be5db14c2e681ef8f4ee7de4b847</data>
    </edge>
    <edge source="&quot;COHEN AND GROSSBERG&quot;" target="&quot;GLOBAL EQUILIBRIUM&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Cohen and Grossberg attempted to prove Global Equilibrium by showing that all Cohen-Grossberg systems generate jump trees, and thus no jump cycles."</data>
      <data key="d6">4a78ff105fdd9a4b0d01ccf1e5816c74</data>
    </edge>
    <edge source="&quot;COHEN AND GROSSBERG&quot;" target="&quot;COHEN-GROSSBERG LIAPUNOV FUNCTION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Cohen and Grossberg developed the Cohen-Grossberg Liapunov Function to prove the existence of global equilibria."</data>
      <data key="d6">4a78ff105fdd9a4b0d01ccf1e5816c74</data>
    </edge>
    <edge source="&quot;COHEN AND GROSSBERG&quot;" target="&quot;LIAPUNOV FUNCTION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Cohen and Grossberg proposed a Liapunov function that includes the Additive Model and Shunting Model."</data>
      <data key="d6">98173c1c0fcd64ceb914e0dd6b366b30</data>
    </edge>
    <edge source="&quot;COHEN AND GROSSBERG&quot;" target="&quot;BURTON&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Cohen and Grossberg's work has been referenced by Burton in their work."</data>
      <data key="d6">98173c1c0fcd64ceb914e0dd6b366b30</data>
    </edge>
    <edge source="&quot;COHEN AND GROSSBERG&quot;" target="&quot;BURWICK&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Cohen and Grossberg's work has been referenced by Burwick in their work."</data>
      <data key="d6">98173c1c0fcd64ceb914e0dd6b366b30</data>
    </edge>
    <edge source="&quot;COHEN AND GROSSBERG&quot;" target="&quot;GUO ET AL.&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Cohen and Grossberg's work has been referenced by Guo et al. in their work."</data>
      <data key="d6">98173c1c0fcd64ceb914e0dd6b366b30</data>
    </edge>
    <edge source="&quot;LIAPUNOV FUNCTION&quot;" target="&quot;COHEN-GROSSBERG MODEL&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Liapunov Function is a mathematical concept used to analyze the stability of the Cohen-Grossberg Model."</data>
      <data key="d6">be0954a6263de67c84da3141d95de445</data>
    </edge>
    <edge source="&quot;LIAPUNOV FUNCTION&quot;" target="&quot;KOSKO&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Kosko used the Liapunov function developed by Cohen and Grossberg to prove global convergence of the system he defined."</data>
      <data key="d6">01e2a32da700813f593038a23a618e55</data>
    </edge>
    <edge source="&quot;COHEN-GROSSBERG MODEL&quot;" target="&quot;KOSKO&quot;">
      <data key="d4">2.0</data>
      <data key="d5">"Kosko has adapted the Cohen-Grossberg Model."
"Kosko adapted the Cohen-Grossberg model to define a system that combines STM and LTM."</data>
      <data key="d6">01e2a32da700813f593038a23a618e55,644602009dec8474bb5cd4702b391d3e</data>
    </edge>
    <edge source="&quot;MEDIUM-TERM MEMORY&quot;" target="&quot;GATED DIPOLE OPPONENT PROCESSING NETWORK&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Medium-term Memory traces enable reset events to occur in the Gated Dipole Opponent Processing Network."</data>
      <data key="d6">be0954a6263de67c84da3141d95de445</data>
    </edge>
    <edge source="&quot;ADAPTIVE RESONANCE THEORY&quot;" target="&quot;COMPETITIVE LEARNING&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Adaptive Resonance Theory was introduced to propose how top-down learned expectations and attentional focusing could dynamically stabilize learning in a Competitive Learning model."</data>
      <data key="d6">01e2a32da700813f593038a23a618e55</data>
    </edge>
    <edge source="&quot;ADAPTIVE RESONANCE THEORY&quot;" target="&quot;SELF-ORGANIZING MAP&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Adaptive Resonance Theory was introduced as an alternative learning model to Self-Organizing Map."</data>
      <data key="d6">01e2a32da700813f593038a23a618e55</data>
    </edge>
    <edge source="&quot;ADAPTIVE RESONANCE THEORY&quot;" target="&quot;BAM&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"BAM was inspired by Adaptive Resonance Theory, indicating a connection between the two entities."</data>
      <data key="d6">554e8565591507441cecaa652cb926db</data>
    </edge>
    <edge source="&quot;ADAPTIVE RESONANCE THEORY&quot;" target="&quot;CARPENTER&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Carpenter has discussed the problem of catastrophic forgetting in relation to Adaptive Resonance Theory, indicating their connection."</data>
      <data key="d6">554e8565591507441cecaa652cb926db</data>
    </edge>
    <edge source="&quot;ADAPTIVE RESONANCE THEORY&quot;" target="&quot;FRENCH&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"French has also discussed the problem of catastrophic forgetting in relation to Adaptive Resonance Theory, indicating their connection."</data>
      <data key="d6">554e8565591507441cecaa652cb926db</data>
    </edge>
    <edge source="&quot;ADAPTIVE RESONANCE THEORY&quot;" target="&quot;PAGE&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Page has discussed the problem of catastrophic forgetting in relation to Adaptive Resonance Theory, indicating their connection."</data>
      <data key="d6">554e8565591507441cecaa652cb926db</data>
    </edge>
    <edge source="&quot;ADAPTIVE RESONANCE THEORY&quot;" target="&quot;DESIMONE&quot;">
      <data key="d4">2.0</data>
      <data key="d5">"Desimone has discussed the operation of attention via a form of self-normalizing 'biased competition' in relation to Adaptive Resonance Theory, indicating their connection."
"Desimone is mentioned in the text as having contributed to the concept of self-normalizing biased competition, which is related to Adaptive Resonance Theory."</data>
      <data key="d6">3d5b88f7f81ed9e14f07335bbef17020,554e8565591507441cecaa652cb926db</data>
    </edge>
    <edge source="&quot;VISUAL PERCEPTION&quot;" target="&quot;NORMALIZATION RULE&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Normalization Rule underlies many properties of limited capacity processing in the brain, notably in visual perception."</data>
      <data key="d6">c8c573c11d0f29d207b3b639a9466518</data>
    </edge>
    <edge source="&quot;VISUAL PERCEPTION&quot;" target="&quot;WEBER LAW&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Weber Law describes the relationship between the perceived intensity of a stimulus and its physical intensity in the context of visual perception."</data>
      <data key="d6">8202e13f45a323970b361921f923c605</data>
    </edge>
    <edge source="&quot;VISUAL PERCEPTION&quot;" target="&quot;BRIGHTNESS CONSTANCY&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Brightness Constancy is a property of visual perception that ensures objects appear the same brightness regardless of their surrounding luminance."</data>
      <data key="d6">8202e13f45a323970b361921f923c605</data>
    </edge>
    <edge source="&quot;VISUAL PERCEPTION&quot;" target="&quot;BRIGHTNESS CONTRAST&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Brightness Contrast is a visual phenomenon that occurs when increasing the luminance of inputs to the off-surround makes the on-center look darker."</data>
      <data key="d6">8202e13f45a323970b361921f923c605</data>
    </edge>
    <edge source="&quot;GUTOWSKI&quot;" target="&quot;MTM TRACE&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Gutowski is mentioned in the context of the MTM Trace."</data>
      <data key="d6">c73b76e10166042ccaba5603ed67f380</data>
    </edge>
    <edge source="&quot;OGMEN AND GAGN&#201;&quot;" target="&quot;MTM TRACE&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Ogmen and Gagn&#233; are mentioned in the context of the MTM Trace."</data>
      <data key="d6">c73b76e10166042ccaba5603ed67f380</data>
    </edge>
    <edge source="&quot;ABBOTT ET AL.&quot;" target="&quot;MTM TRACE&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Abbott et al. are mentioned in the context of the MTM Trace."</data>
      <data key="d6">c73b76e10166042ccaba5603ed67f380</data>
    </edge>
    <edge source="&quot;TSODYKS AND MARKRAM&quot;" target="&quot;MTM TRACE&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Tsodyks and Markram are mentioned in the context of the MTM Trace."</data>
      <data key="d6">c73b76e10166042ccaba5603ed67f380</data>
    </edge>
    <edge source="&quot;GAUDIANO AND GROSSBERG&quot;" target="&quot;MASS ACTION INTERACTION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Gaudiano and Grossberg are mentioned in the context of the Mass Action Interaction."</data>
      <data key="d6">c73b76e10166042ccaba5603ed67f380</data>
    </edge>
    <edge source="&quot;GAUDIANO AND GROSSBERG&quot;" target="&quot;MASS ACTION TERM&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Gaudiano and Grossberg have contributed to the complexity of the mass action term, which is mentioned in the text."</data>
      <data key="d6">24771832864aa38abd6aebec04b13a10</data>
    </edge>
    <edge source="&quot;GROSSBERG AND SEITZ&quot;" target="&quot;MASS ACTION INTERACTION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Grossberg and Seitz are mentioned in the context of the Mass Action Interaction."</data>
      <data key="d6">c73b76e10166042ccaba5603ed67f380</data>
    </edge>
    <edge source="&quot;MTM TRACE&quot;" target="&quot;HABITUATIVE TRANSMITTER GATE&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The MTM Trace is described in relation to the Habituative Transmitter Gate."</data>
      <data key="d6">c73b76e10166042ccaba5603ed67f380</data>
    </edge>
    <edge source="&quot;MTM TRACE&quot;" target="&quot;MASS ACTION INTERACTION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The MTM Trace is described in relation to the Mass Action Interaction."</data>
      <data key="d6">c73b76e10166042ccaba5603ed67f380</data>
    </edge>
    <edge source="&quot;LTM TRACES&quot;" target="&quot;GENERALIZED ADDITIVE SYSTEM&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"LTM Traces are a component of the Generalized Additive System."</data>
      <data key="d6">8bb0e63353e66a2c60a878028beff5f9</data>
    </edge>
    <edge source="&quot;OUTSTAR LEARNING&quot;" target="&quot;INSTAR LEARNING&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Outstar Learning and Instar Learning are dual networks in the sense that they are the same, except for reversing which cells are sampling and which are sampled."</data>
      <data key="d6">b286a9022774f24a400744b2a1b08bab</data>
    </edge>
    <edge source="&quot;HEBBIAN TRACES&quot;" target="&quot;LONG-TERM MEMORY (LTM)&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Hebbian Traces are a type of connection strength in neural networks that are stored in Long-Term Memory (LTM)."</data>
      <data key="d6">b286a9022774f24a400744b2a1b08bab</data>
    </edge>
    <edge source="&quot;SELF-ORGANIZING MAP (SOM)&quot;" target="&quot;RCF&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Self-Organizing Map (SOM) has been developed by Kohonen, and it utilizes shunting dynamics in some versions, which is a property of RCF."</data>
      <data key="d6">2cbd29d6f0019f0c85bee43779ae8f4d</data>
    </edge>
    <edge source="&quot;O&#8217;REILLY&quot;" target="&quot;LEABRA MODEL&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"O&#8217;Reilly is a person mentioned in the context of the Leabra model, likely as a co-author or developer."</data>
      <data key="d6">b40ff9b93414391d5e4b3c06dfe02bc9</data>
    </edge>
    <edge source="&quot;MUNAKATA&quot;" target="&quot;LEABRA MODEL&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Munakata is a person mentioned in the context of the Leabra model, likely as a co-author or developer."</data>
      <data key="d6">b40ff9b93414391d5e4b3c06dfe02bc9</data>
    </edge>
    <edge source="&quot;O&#8217;REILLY AND MUNAKATA&quot;" target="&quot;THE BRAIN&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"O&#8217;Reilly and Munakata are mentioned in the context of the Leabra model, which is used to explain how the brain processes spatial patterns."</data>
      <data key="d6">0d925896ce2bf9b73be90d8fa5ddb402</data>
    </edge>
    <edge source="&quot;THE BRAIN&quot;" target="&quot;SPATIAL PATTERNS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The brain is described as an organization that processes spatial patterns of information."</data>
      <data key="d6">0d925896ce2bf9b73be90d8fa5ddb402</data>
    </edge>
    <edge source="&quot;THE BRAIN&quot;" target="&quot;TEMPORAL PATTERNS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The brain is described as an organization that processes temporal patterns of information."</data>
      <data key="d6">0d925896ce2bf9b73be90d8fa5ddb402</data>
    </edge>
    <edge source="&quot;NEURONS&quot;" target="&quot;BRAINS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Neurons are a component of brains that have evolved network designs to process variable input intensities."</data>
      <data key="d6">31080b985ce23ef751d488d0f7b9eff6</data>
    </edge>
    <edge source="&quot;NEURONS&quot;" target="&quot;NOISE-SATURATION DILEMMA&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Neurons face the challenge of maintaining sensitivity to input patterns while dealing with variable input intensities, as described in the Noise-Saturation Dilemma."</data>
      <data key="d6">31080b985ce23ef751d488d0f7b9eff6</data>
    </edge>
    <edge source="&quot;NEURONS&quot;" target="&quot;MEMBRANE&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Membrane, or shunting, is a concept mentioned in the context of neuronal network design, which neurons are a part of."</data>
      <data key="d6">31080b985ce23ef751d488d0f7b9eff6</data>
    </edge>
    <edge source="&quot;NOISE-SATURATION DILEMMA&quot;" target="&quot;ON-CENTER OFF-SURROUND NETWORK&quot;">
      <data key="d4">2.0</data>
      <data key="d5">"The On-center Off-Surround Network is a solution to the Noise-Saturation Dilemma, enabling neurons to retain sensitivity to the relative sizes of their inputs across the network."
"The on-center off-surround network is proposed as a solution to the noise-saturation dilemma."</data>
      <data key="d6">31080b985ce23ef751d488d0f7b9eff6,7beb44dd43aea0791fcb35806356ddb3</data>
    </edge>
    <edge source="&quot;SPATIAL PATTERN&quot;" target="&quot;NETWORK OF CELLS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The spatial pattern of inputs is processed by the network of cells."</data>
      <data key="d6">7beb44dd43aea0791fcb35806356ddb3</data>
    </edge>
    <edge source="&quot;RELATIVE SIZE&quot;" target="&quot;TOTAL INPUT SIZE&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The relative size of each input is a constant fraction of the total input size."</data>
      <data key="d6">7beb44dd43aea0791fcb35806356ddb3</data>
    </edge>
    <edge source="&quot;CELL (V_I)&quot;" target="&quot;INPUT (I_I)&quot;">
      <data key="d4">2.0</data>
      <data key="d5">"Each cell in the network maintains sensitivity to the relative size of its inputs."
"Cell (v_i) maintains sensitivity to its input size (I_i), and increasing I_i increases the sensitivity of the cell."</data>
      <data key="d6">7beb44dd43aea0791fcb35806356ddb3,fe551b6e0c32ef0fb9ac0a07ff64d6ba</data>
    </edge>
    <edge source="&quot;CELL (V_I)&quot;" target="&quot;INPUT (I_K)&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Cell (v_i) competes with other inputs (I_k) to activate itself, and increasing any I_k decreases the sensitivity of the cell."</data>
      <data key="d6">fe551b6e0c32ef0fb9ac0a07ff64d6ba</data>
    </edge>
    <edge source="&quot;CELL (V_I)&quot;" target="&quot;KUFFLER&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Cell (v_i) is described as having an on-center off-surround anatomy, which was reported by Kuffler in the cat retina."</data>
      <data key="d6">fe551b6e0c32ef0fb9ac0a07ff64d6ba</data>
    </edge>
    <edge source="&quot;KUFFLER&quot;" target="&quot;ON-CENTER OFF-SURROUND ANATOMY&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Kuffler reported on the presence of On-Center Off-Surround Anatomies in the cat retina in 1953."</data>
      <data key="d6">9d40ff29a29b7422b2b0c76b957c54f3</data>
    </edge>
    <edge source="&quot;ON-CENTER OFF-SURROUND ANATOMY&quot;" target="&quot;CELLS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"On-Center Off-Surround Anatomy activates and inhibits cells through time."</data>
      <data key="d6">9d40ff29a29b7422b2b0c76b957c54f3</data>
    </edge>
    <edge source="&quot;CELLS&quot;" target="&quot;INPUTS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Inputs can excite or inhibit cells, with all inputs competing among themselves while trying to activate their own cell."</data>
      <data key="d6">9d40ff29a29b7422b2b0c76b957c54f3</data>
    </edge>
    <edge source="&quot;INPUTS&quot;" target="&quot;FEATURES&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Features describe aspects of an input, which are examples from a dataset passed to a model."</data>
      <data key="d6">54b1174770e13d4a2bc0916db477cc56</data>
    </edge>
    <edge source="&quot;INPUTS&quot;" target="&quot;STATES&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"States describe the current situation in a dynamic system, which can be influenced by inputs from a dataset."</data>
      <data key="d6">54b1174770e13d4a2bc0916db477cc56</data>
    </edge>
    <edge source="&quot;FEEDFORWARD ON-CENTER NETWORK&quot;" target="&quot;FIXED SPATIAL PATTERN&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"A fixed spatial pattern is presented to the Feedforward On-Center Network, influencing the equilibrium values of the cells."</data>
      <data key="d6">68b4b33f0da5edc9dcb301a08821b352</data>
    </edge>
    <edge source="&quot;EQUATION (13)&quot;" target="&quot;OFF-SURROUND&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Off-surround is an inhibitory input mentioned in Equation (13) that multiplies Variable x_i, preventing saturation."</data>
      <data key="d6">04e132fa3a85e95e1e6164428852446e</data>
    </edge>
    <edge source="&quot;VARIABLE X_I&quot;" target="&quot;INPUT I&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Input I is an external factor that affects the behavior of Variable x_i, as described in the text."</data>
      <data key="d6">04e132fa3a85e95e1e6164428852446e</data>
    </edge>
    <edge source="&quot;VARIABLE X_I&quot;" target="&quot;MASS ACTION NETWORKS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Variable x_i is described as a variable that exhibits characteristics of Mass Action Networks, where both the steady state and the rate of change depend upon input strength."</data>
      <data key="d6">04e132fa3a85e95e1e6164428852446e</data>
    </edge>
    <edge source="&quot;ACTIVITIES (X_I)&quot;" target="&quot;INPUT STRENGTH (I)&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The behavior of Activities (x_i) is influenced by Input Strength (I), with both their steady state and rate of change being affected."</data>
      <data key="d6">c8c573c11d0f29d207b3b639a9466518</data>
    </edge>
    <edge source="&quot;ACTIVITIES (X_I)&quot;" target="&quot;TOTAL ACTIVITY (X)&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The total activity (x) is the sum of all Activities (x_i)."</data>
      <data key="d6">c8c573c11d0f29d207b3b639a9466518</data>
    </edge>
    <edge source="&quot;INPUT STRENGTH (I)&quot;" target="&quot;TOTAL ACTIVITY (X)&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The total activity (x) increases as Input Strength (I) increases, approaching a constant (B)."</data>
      <data key="d6">c8c573c11d0f29d207b3b639a9466518</data>
    </edge>
    <edge source="&quot;TOTAL ACTIVITY (X)&quot;" target="&quot;NORMALIZATION RULE&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Normalization Rule is a conservation law that ensures the total activity (x) remains constant."</data>
      <data key="d6">c8c573c11d0f29d207b3b639a9466518</data>
    </edge>
    <edge source="&quot;NORMALIZATION RULE&quot;" target="&quot;LTM INVARIANCE PRINCIPLE&quot;">
      <data key="d4">2.0</data>
      <data key="d5">"The LTM Invariance Principle and the Normalization Rule are two constraints predicted by Grossberg for stable learning and memory of list chunks."
"Both the LTM Invariance Principle and the Normalization Rule are predicted by Grossberg to support stable learning and memory of list chunks."</data>
      <data key="d6">4364aa6091e1966365fa889b34f5cf90,dcd38cdc6195b2bbf41d936af0bf1f5f</data>
    </edge>
    <edge source="&quot;NORMALIZATION RULE&quot;" target="&quot;RCFS&quot;">
      <data key="d4">2.0</data>
      <data key="d5">"The Normalization Rule is likely realized by specialized RCFs, which are not explicitly defined in the text."
"RCFs are predicted to follow the Normalization Rule, which suggests a tendency to normalize total network activity."</data>
      <data key="d6">4364aa6091e1966365fa889b34f5cf90,c38beddeac1d3cac8282ad59bc835788</data>
    </edge>
    <edge source="&quot;NORMALIZATION RULE&quot;" target="&quot;WORKING MEMORY&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Normalization Rule is a principle that applies to working memories, ensuring their limited capacity and activity redistribution when new items are stored."</data>
      <data key="d6">1976b19f768a8fdf37207b680c3b2b40</data>
    </edge>
    <edge source="&quot;SHIFT PROPERTY&quot;" target="&quot;SYSTEM&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Shift Property causes the entire response curve of a system to shift without a loss of sensitivity."</data>
      <data key="d6">8202e13f45a323970b361921f923c605</data>
    </edge>
    <edge source="&quot;NORMALIZATION PROPERTY&quot;" target="&quot;LIMITED CAPACITY PROCESSING&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Normalization Property underlies many properties of limited capacity processing in the brain, such as visual perception and cognition."</data>
      <data key="d6">8202e13f45a323970b361921f923c605</data>
    </edge>
    <edge source="&quot;NORMALIZATION PROPERTY&quot;" target="&quot;WORKING MEMORY&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Normalization Property is a property that limits the capacity of working memory, which holds and manipulates information for immediate use in cognitive tasks."</data>
      <data key="d6">8202e13f45a323970b361921f923c605</data>
    </edge>
    <edge source="&quot;WORKING MEMORY&quot;" target="&quot;SHORT-TERM MEMORY&quot;">
      <data key="d4">2.0</data>
      <data key="d5">"Working Memory is described as a network that temporarily stores a sequence of events in Short-Term Memory."
"Working Memory temporarily stores information that is later transferred to Short-Term Memory for immediate use."</data>
      <data key="d6">3d5b88f7f81ed9e14f07335bbef17020,5c4e24fc9bd10d0bd59a84d56f960cf9</data>
    </edge>
    <edge source="&quot;WORKING MEMORY&quot;" target="&quot;BADDELEY&quot;">
      <data key="d4">2.0</data>
      <data key="d5">"Baddeley is mentioned in the text as a contributor to the understanding of Working Memory and Short-Term Memory, which are related concepts."
"Baddeley is known for his contributions to the understanding of Working Memory and its role in temporarily storing information."</data>
      <data key="d6">3d5b88f7f81ed9e14f07335bbef17020,5c4e24fc9bd10d0bd59a84d56f960cf9</data>
    </edge>
    <edge source="&quot;WORKING MEMORY&quot;" target="&quot;COGNITIVE SCIENTISTS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Cognitive Scientists are studying the processes of Working Memory to understand how it temporarily stores and manipulates information."</data>
      <data key="d6">5c4e24fc9bd10d0bd59a84d56f960cf9</data>
    </edge>
    <edge source="&quot;WORKING MEMORY&quot;" target="&quot;EVENT SEQUENCES&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Working Memory is capable of temporarily storing sequences of events, which are grouped into List Chunks."</data>
      <data key="d6">5c4e24fc9bd10d0bd59a84d56f960cf9</data>
    </edge>
    <edge source="&quot;WORKING MEMORY&quot;" target="&quot;LONG-TERM MEMORY&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Working Memory and Long-Term Memory are related as cognitive systems that support stable learning and the retention of information over time."</data>
      <data key="d6">1976b19f768a8fdf37207b680c3b2b40</data>
    </edge>
    <edge source="&quot;WORKING MEMORY&quot;" target="&quot;RCFS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"RCFs are mentioned as a type of network that can be embodied by specialized recurrent on-center off-surround shunting networks, which are related to the functioning of working memories."</data>
      <data key="d6">1976b19f768a8fdf37207b680c3b2b40</data>
    </edge>
    <edge source="&quot;SHUNTING NETWORK&quot;" target="&quot;NEUROPHYSIOLOGY&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Shunting Network has the form of the membrane equation on which cellular neurophysiology is based, indicating a connection between the two fields."</data>
      <data key="d6">f290960776c5ec561653e90d2ac6751b</data>
    </edge>
    <edge source="&quot;WERBLIN&quot;" target="&quot;MUDPUPPY NECTURUS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Werblin has studied the retina of the mudpuppy Necturus, finding a shift property similar to that described in the shunting network equations."</data>
      <data key="d6">f290960776c5ec561653e90d2ac6751b</data>
    </edge>
    <edge source="&quot;RETINA&quot;" target="&quot;MUDPUPPY NECTURUS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Retina is a part of the mudpuppy Necturus that has been studied for its shift property in response to off-surround input."</data>
      <data key="d6">f290960776c5ec561653e90d2ac6751b</data>
    </edge>
    <edge source="&quot;HODGKIN AND HUXLEY&quot;" target="&quot;MEMBRANE EQUATION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Hodgkin and Huxley are known for their work on the membrane equation in neurophysiology."</data>
      <data key="d6">f2468cda326d1ca11c98f2fbde186400</data>
    </edge>
    <edge source="&quot;HODGKIN AND HUXLEY&quot;" target="&quot;SIGNAL PROPAGATION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Hodgkin and Huxley proposed a model of signal propagation along axons and its effect on postsynaptic cells."</data>
      <data key="d6">a94f07c842345c77af089558b0786bfe</data>
    </edge>
    <edge source="&quot;SHUNTING NETWORK EQUATIONS&quot;" target="&quot;MEMBRANE EQUATION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Shunting Equation has the form of the membrane equation, which is based on the work of Hodgkin and Huxley."</data>
      <data key="d6">f2468cda326d1ca11c98f2fbde186400</data>
    </edge>
    <edge source="&quot;MEMBRANE EQUATION&quot;" target="&quot;SODIUM CHANNEL&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Sodium Channel contributes to the Membrane Equation as an excitatory saturation voltage."</data>
      <data key="d6">768cec2f00889d1e375cb4955c58ad60</data>
    </edge>
    <edge source="&quot;MEMBRANE EQUATION&quot;" target="&quot;POTASSIUM CHANNEL&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Potassium Channel contributes to the Membrane Equation as an inhibitory saturation voltage."</data>
      <data key="d6">768cec2f00889d1e375cb4955c58ad60</data>
    </edge>
    <edge source="&quot;MEMBRANE EQUATION&quot;" target="&quot;ION CHANNEL&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Ion Channel is a general term for types of proteins that contribute to the Membrane Equation, such as Sodium Channel and Potassium Channel."</data>
      <data key="d6">768cec2f00889d1e375cb4955c58ad60</data>
    </edge>
    <edge source="&quot;SODIUM CHANNEL&quot;" target="&quot;POTASSIUM CHANNEL&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Sodium Channel and Potassium Channel are both ion channels that contribute to the Membrane Equation, representing different types of ionic conductances."</data>
      <data key="d6">768cec2f00889d1e375cb4955c58ad60</data>
    </edge>
    <edge source="&quot;(20)&quot;" target="&quot;(V^+)&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"(20) is mentioned in relation to (V^+), possibly indicating a connection or relationship between the two concepts."</data>
      <data key="d6">91f030f6c14c673e6d029c9bf1a66515</data>
    </edge>
    <edge source="&quot;(20)&quot;" target="&quot;(V^-)&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"(20) is mentioned in relation to (V^-), possibly indicating a connection or relationship between the two concepts."</data>
      <data key="d6">91f030f6c14c673e6d029c9bf1a66515</data>
    </edge>
    <edge source="&quot;(20)&quot;" target="&quot;(V^P)&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"(20) is mentioned in relation to (V^p), possibly indicating a connection or relationship between the two concepts."</data>
      <data key="d6">91f030f6c14c673e6d029c9bf1a66515</data>
    </edge>
    <edge source="&quot;BRNN&quot;" target="&quot;RCF&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Recurrent Competitive Field is a type of recurrent neural network mentioned in the context of a bidirectional Recurrent Neural Network."</data>
      <data key="d6">3a64c8c26895f111f00a349dd69bb505</data>
    </edge>
    <edge source="&quot;RCF&quot;" target="&quot;DOUGLAS ET AL.&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Douglas et al. have applied shunting properties to simulate data about the properties of the cortical circuits that subserve visual perception, which is a property of RCF."</data>
      <data key="d6">2cbd29d6f0019f0c85bee43779ae8f4d</data>
    </edge>
    <edge source="&quot;RCF&quot;" target="&quot;GROSSBERG AND MINGOLLA&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Grossberg and Mingolla have applied shunting properties in their research, which is a property of RCF."</data>
      <data key="d6">2cbd29d6f0019f0c85bee43779ae8f4d</data>
    </edge>
    <edge source="&quot;RCF&quot;" target="&quot;GROSSBERG AND TODOROVIC&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Grossberg and Todorovic have applied shunting properties in their research, which is a property of RCF."</data>
      <data key="d6">2cbd29d6f0019f0c85bee43779ae8f4d</data>
    </edge>
    <edge source="&quot;RCF&quot;" target="&quot;HEEGER&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Heeger has applied shunting properties in their research, which is a property of RCF."</data>
      <data key="d6">2cbd29d6f0019f0c85bee43779ae8f4d</data>
    </edge>
    <edge source="&quot;RCF&quot;" target="&quot;MCLAUGHLIN ET AL.&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"McLaughlin et al. have applied shunting properties in their research, which is a property of RCF."</data>
      <data key="d6">2cbd29d6f0019f0c85bee43779ae8f4d</data>
    </edge>
    <edge source="&quot;RCF&quot;" target="&quot;COMPETITIVE LEARNING (CL)&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Competitive Learning (CL) has been developed by Grossberg and others, and it utilizes shunting dynamics, which is a property of RCF."</data>
      <data key="d6">2cbd29d6f0019f0c85bee43779ae8f4d</data>
    </edge>
    <edge source="&quot;RCF&quot;" target="&quot;ADAPTIVE RESONANCE THEORY (ART)&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Adaptive Resonance Theory (ART) has been developed by Grossberg, and it does not utilize shunting dynamics, which is not a property of RCF."</data>
      <data key="d6">2cbd29d6f0019f0c85bee43779ae8f4d</data>
    </edge>
    <edge source="&quot;RCF&quot;" target="&quot;PALMA ET AL.&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Palma et al. have shown that an RCF with spiking neurons can replicate key properties of the Grossberg (1973) theorems for rate-based neurons, which is a property of RCF."</data>
      <data key="d6">2cbd29d6f0019f0c85bee43779ae8f4d</data>
    </edge>
    <edge source="&quot;RCF&quot;" target="&quot;SPARSE STABLE CATEGORY LEARNING THEOREM&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"RCF stands for Recurrent Competitive Filter, which is a mechanism used in the Sparse Stable Category Learning Theorem to allow multiple Instars to compete with each other."</data>
      <data key="d6">be49e9beb2d7cc985fe9f6517fa0f4fe</data>
    </edge>
    <edge source="&quot;FUNCTION F(W)&quot;" target="&quot;EQUATIONS (21) AND (22)&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Function f(w) is used in the mathematical equations (21) and (22) mentioned in the text."</data>
      <data key="d6">b4f6256f3430f1aa72ca8092809ebba1</data>
    </edge>
    <edge source="&quot;NETWORK&quot;" target="&quot;HILL FUNCTION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Hill Function is used to analyze the behavior of the Network, providing insights into its response to different signal functions."</data>
      <data key="d6">0ae1c3b9a183835b90295e9712b9656d</data>
    </edge>
    <edge source="&quot;NETWORK&quot;" target="&quot;EQUILIBRIUM POINTS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Network's behavior is described in terms of its equilibrium points, which are the stable states of the system."</data>
      <data key="d6">d69baa85c856a1c0b5446a9c9fcd31b8</data>
    </edge>
    <edge source="&quot;NETWORK&quot;" target="&quot;SIGNAL&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Network's behavior is mentioned in relation to a signal, but the specific relationship is not explicitly described."</data>
      <data key="d6">d69baa85c856a1c0b5446a9c9fcd31b8</data>
    </edge>
    <edge source="&quot;SIGNAL FUNCTION&quot;" target="&quot;BIOLOGY&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Signal Functions in biology are studied and must be bounded, as mentioned in the text."</data>
      <data key="d6">35551dc55b5522082b778171ff6d1bf9</data>
    </edge>
    <edge source="&quot;LINEAR SIGNAL FUNCTION&quot;" target="&quot;NOISE&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"A Linear Signal Function amplifies noise, making it more prominent in the Network's output."</data>
      <data key="d6">0ae1c3b9a183835b90295e9712b9656d</data>
    </edge>
    <edge source="&quot;SLOWER-THAN-LINEAR SIGNAL FUNCTION&quot;" target="&quot;NOISE&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"A Slower-than-Linear Signal Function also amplifies noise, similar to a Linear Signal Function."</data>
      <data key="d6">0ae1c3b9a183835b90295e9712b9656d</data>
    </edge>
    <edge source="&quot;FASTER-THAN-LINEAR SIGNAL FUNCTION&quot;" target="&quot;NOISE&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"A Faster-than-Linear Signal Function suppresses noise, improving the Network's ability to distinguish differences in inputs."</data>
      <data key="d6">0ae1c3b9a183835b90295e9712b9656d</data>
    </edge>
    <edge source="&quot;NOISE SUPPRESSION&quot;" target="&quot;SIGMOID SIGNAL FUNCTION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Noise Suppression is achieved using a Sigmoid Signal Function, which combines faster-than-linear and slower-than-linear properties."</data>
      <data key="d6">6a47ed5881928d48cdcb74e40867a711</data>
    </edge>
    <edge source="&quot;CORTICAL MODELS&quot;" target="&quot;RCFS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Cortical Models are used for studying shunting dynamics, which involve the analysis of RCFs."</data>
      <data key="d6">6a47ed5881928d48cdcb74e40867a711</data>
    </edge>
    <edge source="&quot;RCFS&quot;" target="&quot;HABITUATIVE GATES&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Habituative Gates multiply recurrent signals in RCFs, enhancing their impact and potentially leading to persistent oscillations."</data>
      <data key="d6">53f5bc3f4c71310c593a23aef01d1633</data>
    </edge>
    <edge source="&quot;RCFS&quot;" target="&quot;LTM INVARIANCE PRINCIPLE&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"RCFs are predicted to obey the LTM Invariance Principle, suggesting that they are specialized versions of a common network design."</data>
      <data key="d6">c38beddeac1d3cac8282ad59bc835788</data>
    </edge>
    <edge source="&quot;COMPETITIVE LEARNING (CL)&quot;" target="&quot;VON DER MALSBURG&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"von der Malsburg is an author who has developed a version of the CL model that does not utilize shunting dynamics."</data>
      <data key="d6">2cbd29d6f0019f0c85bee43779ae8f4d</data>
    </edge>
    <edge source="&quot;MAY AND LEONARD MODEL&quot;" target="&quot;VOTING PARADOX&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The May and Leonard Model is used to study the Voting Paradox, a phenomenon that occurs in competitive systems."</data>
      <data key="d6">3334f6dcd53b71cf3ceb7648ead24d5a</data>
    </edge>
    <edge source="&quot;COMPETITIVE SYSTEM&quot;" target="&quot;VOTING PARADOX&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Voting Paradox is a phenomenon that occurs in competitive systems, where the outcome of a vote can be influenced by the voting strategy of a minority group."</data>
      <data key="d6">3334f6dcd53b71cf3ceb7648ead24d5a</data>
    </edge>
    <edge source="&quot;SYSTEM (21)&quot;" target="&quot;ADAPTATION LEVEL SYSTEMS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"System (21) is a special case of Adaptation Level Systems."</data>
      <data key="d6">edd10f4a8bda41294ef582dc7f048ad5</data>
    </edge>
    <edge source="&quot;ADAPTATION LEVEL SYSTEMS&quot;" target="&quot;STATE-DEPENDENT AMPLIFICATION FUNCTION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"State-dependent Amplification Function is used in the equations defining the behavior of Adaptation Level Systems."</data>
      <data key="d6">edd10f4a8bda41294ef582dc7f048ad5</data>
    </edge>
    <edge source="&quot;ADAPTATION LEVEL SYSTEMS&quot;" target="&quot;SELF-SIGNAL FUNCTION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Self-signal Function is used in the equations defining the behavior of Adaptation Level Systems."</data>
      <data key="d6">edd10f4a8bda41294ef582dc7f048ad5</data>
    </edge>
    <edge source="&quot;ADAPTATION LEVEL SYSTEMS&quot;" target="&quot;STATE-DEPENDENT ADAPTATION LEVEL&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"State-dependent Adaptation Level is used in the equations defining the behavior of Adaptation Level Systems."</data>
      <data key="d6">edd10f4a8bda41294ef582dc7f048ad5</data>
    </edge>
    <edge source="&quot;THEOREM&quot;" target="&quot;COMPETITIVE MARKET&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Theorem is applied to prove the stability of a price in a Competitive Market."</data>
      <data key="d6">0c9db6cd87deaca2e432c260d775349c</data>
    </edge>
    <edge source="&quot;COHEN-GROSSBERG SYSTEMS&quot;" target="&quot;GLOBAL EQUILIBRIUM&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Cohen-Grossberg Systems are the subject of research aimed at proving Global Equilibrium."</data>
      <data key="d6">4b48be5db14c2e681ef8f4ee7de4b847</data>
    </edge>
    <edge source="&quot;COHEN-GROSSBERG SYSTEMS&quot;" target="&quot;JUMP TREES&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Cohen-Grossberg Systems are hypothesized to generate jump trees, which are relevant to the proof of Global Equilibrium."</data>
      <data key="d6">4b48be5db14c2e681ef8f4ee7de4b847</data>
    </edge>
    <edge source="&quot;COHEN-GROSSBERG SYSTEMS&quot;" target="&quot;COHEN-GROSSBERG LIAPUNOV FUNCTION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Cohen-Grossberg Systems are mathematical models that use the Cohen-Grossberg Liapunov Function to prove the existence of global equilibria."</data>
      <data key="d6">4a78ff105fdd9a4b0d01ccf1e5816c74</data>
    </edge>
    <edge source="&quot;HOPFIELD NETWORK&quot;" target="&quot;JOHN J. HOPFIELD&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"John J. Hopfield is a researcher who published the Hopfield Network model."</data>
      <data key="d6">643e65a5f4132289cfd1d5b954043642</data>
    </edge>
    <edge source="&quot;HOPFIELD NETWORK&quot;" target="&quot;COHEN-GROSSBERG-HOPFIELD MODEL&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Hopfield Network is often referred to as the Cohen-Grossberg-Hopfield Model."</data>
      <data key="d6">643e65a5f4132289cfd1d5b954043642</data>
    </edge>
    <edge source="&quot;HOPFIELD NETWORK&quot;" target="&quot;SYNCHRONIZED OSCILLATIONS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Hopfield Network is described as a neural network that can undergo synchronized oscillations."</data>
      <data key="d6">643e65a5f4132289cfd1d5b954043642</data>
    </edge>
    <edge source="&quot;HOPFIELD NETWORK&quot;" target="&quot;ISING MODEL&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Hopfield Network was developed based on the work of Shun&#8217;ichi Amari, who made the Ising Model adaptive in 1972."</data>
      <data key="d6">f59839daadfb1f3832bb9f8d201a7126</data>
    </edge>
    <edge source="&quot;HOPFIELD NETWORK&quot;" target="&quot;SHUN&#8217;ICHI AMARI&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Shun&#8217;ichi Amari made the Hopfield network adaptive in 1972."</data>
      <data key="d6">b31ca51b419f7270ee5f4910c90ea331</data>
    </edge>
    <edge source="&quot;HOPFIELD NETWORK&quot;" target="&quot;BIDIRECTIONAL ASSOCIATIVE MEMORY (BAM) NETWORK&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Bidirectional Associative Memory (BAM) Network is a variant of Hopfield Network."</data>
      <data key="d6">a8c0edd2cdddb7d6d899284063b541f5</data>
    </edge>
    <edge source="&quot;COHEN-GROSSBERG-HOPFIELD MODEL&quot;" target="&quot;DAVID COHEN&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"David Cohen is a contributor to the Cohen-Grossberg-Hopfield Model."</data>
      <data key="d6">643e65a5f4132289cfd1d5b954043642</data>
    </edge>
    <edge source="&quot;COHEN-GROSSBERG-HOPFIELD MODEL&quot;" target="&quot;MICHAEL I. GROSSBERG&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Michael I. Grossberg is a contributor to the Cohen-Grossberg-Hopfield Model."</data>
      <data key="d6">643e65a5f4132289cfd1d5b954043642</data>
    </edge>
    <edge source="&quot;EXCITATORY FEEDBACK SIGNALS&quot;" target="&quot;SHUNTING NETWORKS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Excitatory Feedback Signals stimulate other populations in Shunting Networks, contributing to their persistent oscillations."</data>
      <data key="d6">53f5bc3f4c71310c593a23aef01d1633</data>
    </edge>
    <edge source="&quot;INHIBITORY INTERNEURONS&quot;" target="&quot;SHUNTING NETWORKS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Shunting Networks use fast-acting Inhibitory Interneurons to regulate their activity and potentially lead to persistent oscillations."</data>
      <data key="d6">53f5bc3f4c71310c593a23aef01d1633</data>
    </edge>
    <edge source="&quot;HABITUATIVE GATES&quot;" target="&quot;SLOW INHIBITORY INTERNEURONS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Slow Inhibitory Interneurons and Habituative Gates are mentioned together in the text, suggesting a relationship or connection between the two concepts."</data>
      <data key="d6">9b30fc06ca06f49c2faa238da7eddc6f</data>
    </edge>
    <edge source="&quot;BRNNS&quot;" target="&quot;RNNS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"RNNs and bRNNs are mentioned together in the text, suggesting a relationship or connection between the two types of neural networks."</data>
      <data key="d6">9b30fc06ca06f49c2faa238da7eddc6f</data>
    </edge>
    <edge source="&quot;BRNNS&quot;" target="&quot;CEREBRAL CORTEX&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Cerebral Cortex is mentioned in the text as working with bRNNs, suggesting a relationship or connection between the two concepts."</data>
      <data key="d6">9b30fc06ca06f49c2faa238da7eddc6f</data>
    </edge>
    <edge source="&quot;RNNS&quot;" target="&quot;BACKPROPAGATION OF ERROR&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"RNNs utilize the method of Backpropagation of Error to train their models and estimate gradients."</data>
      <data key="d6">001240f9b2caf047ee61a89e03f7b309</data>
    </edge>
    <edge source="&quot;RNNS&quot;" target="&quot;GRADIENT DESCENT&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"RNNs face problems with gradient descent-based training, such as bifurcations and slow convergence."</data>
      <data key="d6">eafe89ad19a57846f953a1dfcf8571f8</data>
    </edge>
    <edge source="&quot;RNNS&quot;" target="&quot;ESNS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"ESNs are introduced as an alternative to RNNs due to their fast and simple training algorithms, outperforming other methods in benchmark tasks."</data>
      <data key="d6">eafe89ad19a57846f953a1dfcf8571f8</data>
    </edge>
    <edge source="&quot;RNNS&quot;" target="&quot;DEEP LEARNING FRAMEWORKS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"RNNs are often replicated using popular Deep Learning frameworks."</data>
      <data key="d6">418f92b0dd08e03a20637ffec8193bfc</data>
    </edge>
    <edge source="&quot;RNNS&quot;" target="&quot;LSTMS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"LSTMs are a type of technology that competes with state-of-the-art RNN methods like RNNs."</data>
      <data key="d6">418f92b0dd08e03a20637ffec8193bfc</data>
    </edge>
    <edge source="&quot;RNNS&quot;" target="&quot;WAN&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Wan is a contributor to the development of RNNs."</data>
      <data key="d6">7ede01f521333d9e39fc34a245103242</data>
    </edge>
    <edge source="&quot;RNNS&quot;" target="&quot;BEAUFAYS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Beaufays is a contributor to the development of RNNs."</data>
      <data key="d6">7ede01f521333d9e39fc34a245103242</data>
    </edge>
    <edge source="&quot;RNNS&quot;" target="&quot;CAMPOLUCCI&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Campolucci is a contributor to the development of RNNs."</data>
      <data key="d6">7ede01f521333d9e39fc34a245103242</data>
    </edge>
    <edge source="&quot;RNNS&quot;" target="&quot;UNCINI&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Uncini is a contributor to the development of RNNs."</data>
      <data key="d6">7ede01f521333d9e39fc34a245103242</data>
    </edge>
    <edge source="&quot;RNNS&quot;" target="&quot;PIAZZA&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Piazza is a contributor to the development of RNNs."</data>
      <data key="d6">7ede01f521333d9e39fc34a245103242</data>
    </edge>
    <edge source="&quot;RNNS&quot;" target="&quot;GENETIC ALGORITHMS&quot;">
      <data key="d4">2.0</data>
      <data key="d5">"Genetic Algorithms are a global optimization method mentioned for training RNNs."
"Genetic Algorithms are used for training RNNs, evolving multiple neural networks to minimize the mean-squared error."</data>
      <data key="d6">797480b3d8c00dbb7f02fccb2ab8256a,7ede01f521333d9e39fc34a245103242</data>
    </edge>
    <edge source="&quot;RNNS&quot;" target="&quot;SIMULATED ANNEALING&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Simulated Annealing is a global optimization technique that may be used to seek a good set of weights for RNNs."</data>
      <data key="d6">797480b3d8c00dbb7f02fccb2ab8256a</data>
    </edge>
    <edge source="&quot;RNNS&quot;" target="&quot;PARTICLE SWARM OPTIMIZATION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Particle Swarm Optimization is a global optimization technique that may be used for training RNNs, seeking a good set of weights."</data>
      <data key="d6">797480b3d8c00dbb7f02fccb2ab8256a</data>
    </edge>
    <edge source="&quot;RNNS&quot;" target="&quot;DYNAMICAL SYSTEMS THEORY&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Dynamical Systems Theory may be used for analyzing the behavior of RNNs, which can appear chaotic."</data>
      <data key="d6">797480b3d8c00dbb7f02fccb2ab8256a</data>
    </edge>
    <edge source="&quot;RNNS&quot;" target="&quot;RECURSIVE NEURAL NETWORKS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"RNNs are a specific type of Recursive Neural Network that operate on the linear progression of time."</data>
      <data key="d6">797480b3d8c00dbb7f02fccb2ab8256a</data>
    </edge>
    <edge source="&quot;RNNS&quot;" target="&quot;SCHILLER AND STEIL&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Schiller and Steil demonstrated the dominance of output weight changes in conventional training approaches for RNNs."</data>
      <data key="d6">b32958d42199d47252887dc7be40ab5a</data>
    </edge>
    <edge source="&quot;RNNS&quot;" target="&quot;L. SCHOMAKER&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"L. Schomaker described how a desired target output could be obtained from an RNN by learning to combine signals from a randomly configured ensemble of spiking neural oscillators."</data>
      <data key="d6">b32958d42199d47252887dc7be40ab5a</data>
    </edge>
    <edge source="&quot;LAMINAR COMPUTING&quot;" target="&quot;LAMINART FAMILY&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Laminar Computing is mentioned in the text as a computational paradigm that the LAMINART Family of models illustrate, suggesting a relationship or connection between the two concepts."</data>
      <data key="d6">9b30fc06ca06f49c2faa238da7eddc6f</data>
    </edge>
    <edge source="&quot;LAMINART FAMILY&quot;" target="&quot;CAO&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Cao is a researcher associated with the LAMINART Family model."</data>
      <data key="d6">6648b18760b8b182e1097ad15c4df685</data>
    </edge>
    <edge source="&quot;LAMINART FAMILY&quot;" target="&quot;RAIZADA&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Raizada is a researcher associated with the LAMINART Family model."</data>
      <data key="d6">6648b18760b8b182e1097ad15c4df685</data>
    </edge>
    <edge source="&quot;CARPENTER&quot;" target="&quot;RECURRENT SIGNALS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Carpenter is mentioned in the text as a co-author in a reference related to the recurrent signals in the neural network, suggesting a relationship or connection between the person and the concept."</data>
      <data key="d6">9b30fc06ca06f49c2faa238da7eddc6f</data>
    </edge>
    <edge source="&quot;CAO&quot;" target="&quot;VISUAL CORTEX INTERACTION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Cao is mentioned in the text as a co-author in a reference related to the visual cortex and its interaction, suggesting a relationship or connection between the person and the concept."</data>
      <data key="d6">9b30fc06ca06f49c2faa238da7eddc6f</data>
    </edge>
    <edge source="&quot;RAIZADA&quot;" target="&quot;VISUAL CORTEX INTERACTION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Raizada is mentioned in the text as a co-author in a reference related to the visual cortex and its interaction, suggesting a relationship or connection between the person and the concept."</data>
      <data key="d6">9b30fc06ca06f49c2faa238da7eddc6f</data>
    </edge>
    <edge source="&quot;VERSACE&quot;" target="&quot;VISUAL CORTEX INTERACTION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Versace is mentioned in the text as a co-author in a reference related to the visual cortex and its interaction, suggesting a relationship or connection between the person and the concept."</data>
      <data key="d6">9b30fc06ca06f49c2faa238da7eddc6f</data>
    </edge>
    <edge source="&quot;LIST PARSE MODEL&quot;" target="&quot;PEARSON&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Pearson is a researcher associated with the LIST PARSE Model."</data>
      <data key="d6">6648b18760b8b182e1097ad15c4df685</data>
    </edge>
    <edge source="&quot;CARTWORD MODEL&quot;" target="&quot;KAZEROUNIAN&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Kazerounian is a researcher associated with the cARTWORD Model."</data>
      <data key="d6">6648b18760b8b182e1097ad15c4df685</data>
    </edge>
    <edge source="&quot;KAZEROUNIAN&quot;" target="&quot;TELOS MODEL&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Kazerounian is a co-author of the study that introduces the TELOS Model."</data>
      <data key="d6">75495c1fc835d41adf5afcb01e8e520a</data>
    </edge>
    <edge source="&quot;KAZEROUNIAN&quot;" target="&quot;LISTELOS MODEL&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Kazerounian is not explicitly mentioned in the context of the lisTELOS Model."</data>
      <data key="d6">75495c1fc835d41adf5afcb01e8e520a</data>
    </edge>
    <edge source="&quot;TELOS MODEL&quot;" target="&quot;PFC&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"PFC is a part of the brain mentioned in the context of the TELOS Model."</data>
      <data key="d6">6648b18760b8b182e1097ad15c4df685</data>
    </edge>
    <edge source="&quot;TELOS MODEL&quot;" target="&quot;FEF&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"FEF is a part of the brain mentioned in the context of the TELOS Model."</data>
      <data key="d6">6648b18760b8b182e1097ad15c4df685</data>
    </edge>
    <edge source="&quot;TELOS MODEL&quot;" target="&quot;PPC&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"PPC is a part of the brain mentioned in the context of the TELOS Model."</data>
      <data key="d6">6648b18760b8b182e1097ad15c4df685</data>
    </edge>
    <edge source="&quot;TELOS MODEL&quot;" target="&quot;ITA&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"ITa is a part of the brain mentioned in the context of the TELOS Model."</data>
      <data key="d6">6648b18760b8b182e1097ad15c4df685</data>
    </edge>
    <edge source="&quot;TELOS MODEL&quot;" target="&quot;ITP&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"ITp is a part of the brain mentioned in the context of the TELOS Model."</data>
      <data key="d6">6648b18760b8b182e1097ad15c4df685</data>
    </edge>
    <edge source="&quot;TELOS MODEL&quot;" target="&quot;BG&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"BG is a part of the brain mentioned in the context of the TELOS Model."</data>
      <data key="d6">6648b18760b8b182e1097ad15c4df685</data>
    </edge>
    <edge source="&quot;TELOS MODEL&quot;" target="&quot;LISTELOS MODEL&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Both models are related as they both deal with learning and choice of eye movements, but the lisTELOS Model involves sequences of saccadic eye movements and a different spatial working memory structure."</data>
      <data key="d6">75495c1fc835d41adf5afcb01e8e520a</data>
    </edge>
    <edge source="&quot;TELOS MODEL&quot;" target="&quot;PREFRONTAL CORTEX&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Prefrontal Cortex is a key component of the TELOS Model."</data>
      <data key="d6">75495c1fc835d41adf5afcb01e8e520a</data>
    </edge>
    <edge source="&quot;TELOS MODEL&quot;" target="&quot;FRONTAL EYE FIELDS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Frontal Eye Fields are involved in the TELOS Model."</data>
      <data key="d6">75495c1fc835d41adf5afcb01e8e520a</data>
    </edge>
    <edge source="&quot;LISTELOS MODEL&quot;" target="&quot;PREFRONTAL CORTEX&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Prefrontal Cortex is a key component of the lisTELOS Model, storing sequences of saccadic eye movement commands."</data>
      <data key="d6">75495c1fc835d41adf5afcb01e8e520a</data>
    </edge>
    <edge source="&quot;LISTELOS MODEL&quot;" target="&quot;FRONTAL EYE FIELDS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Frontal Eye Fields are involved in the lisTELOS Model."</data>
      <data key="d6">75495c1fc835d41adf5afcb01e8e520a</data>
    </edge>
    <edge source="&quot;POSTERIOR PARIETAL CORTEX (PPC)&quot;" target="&quot;FRONTAL EYE FIELDS (FEF)&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"PPC and FEF interact to carry out specific operations."</data>
      <data key="d6">89a24f37cf198d043ccd6b6b795dc232</data>
    </edge>
    <edge source="&quot;POSTERIOR PARIETAL CORTEX (PPC)&quot;" target="&quot;BASAL GANGLIA (BG)&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"PPC and BG interact to carry out specific operations."</data>
      <data key="d6">89a24f37cf198d043ccd6b6b795dc232</data>
    </edge>
    <edge source="&quot;POSTERIOR PARIETAL CORTEX (PPC)&quot;" target="&quot;SUPERIOR COLLICULUS (SC)&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"PPC and SC interact to carry out specific operations."</data>
      <data key="d6">89a24f37cf198d043ccd6b6b795dc232</data>
    </edge>
    <edge source="&quot;POSTERIOR PARIETAL CORTEX (PPC)&quot;" target="&quot;ARTSCAN&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The ARTSCAN model involves interactions between Posterior Parietal Cortex (PPC) and other brain regions in simulating view-invariant object learning and visual search."</data>
      <data key="d6">db27e91f327c97c16df11a500cdeab4d</data>
    </edge>
    <edge source="&quot;POSTERIOR PARIETAL CORTEX (PPC)&quot;" target="&quot;ARTSCENE SEARCH&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The ARTSCENE Search model involves interactions between Posterior Parietal Cortex (PPC) and other brain regions in simulating object and spatial contextual cueing of visual search."</data>
      <data key="d6">db27e91f327c97c16df11a500cdeab4d</data>
    </edge>
    <edge source="&quot;SUPERIOR COLLICULUS (SC)&quot;" target="&quot;ARTSCAN&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The ARTSCAN model involves interactions between Superior Colliculus (SC) and other brain regions in simulating view-invariant object learning and visual search."</data>
      <data key="d6">db27e91f327c97c16df11a500cdeab4d</data>
    </edge>
    <edge source="&quot;SUPERIOR COLLICULUS (SC)&quot;" target="&quot;ARTSCENE SEARCH&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The ARTSCENE Search model involves interactions between Superior Colliculus (SC) and other brain regions in simulating object and spatial contextual cueing of visual search."</data>
      <data key="d6">db27e91f327c97c16df11a500cdeab4d</data>
    </edge>
    <edge source="&quot;MOTIVATOR MODEL&quot;" target="&quot;INFEROTEMPORAL (IT) CORTEX&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"MOTIVATOR Model interacts with IT Cortex in cognitive-emotional interactions."</data>
      <data key="d6">89a24f37cf198d043ccd6b6b795dc232</data>
    </edge>
    <edge source="&quot;MOTIVATOR MODEL&quot;" target="&quot;RHINAL (RHIN) CORTEX&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"MOTIVATOR Model interacts with RHIN Cortex in cognitive-emotional interactions."</data>
      <data key="d6">89a24f37cf198d043ccd6b6b795dc232</data>
    </edge>
    <edge source="&quot;MOTIVATOR MODEL&quot;" target="&quot;LATERAL ORBITOFRONTAL CORTEX (ORBL)&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"MOTIVATOR Model interacts with ORBl in cognitive-emotional interactions."</data>
      <data key="d6">89a24f37cf198d043ccd6b6b795dc232</data>
    </edge>
    <edge source="&quot;MOTIVATOR MODEL&quot;" target="&quot;MEDIAL ORBITOFRONTAL CORTEX (ORBM)&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"MOTIVATOR Model interacts with ORBm in cognitive-emotional interactions."</data>
      <data key="d6">89a24f37cf198d043ccd6b6b795dc232</data>
    </edge>
    <edge source="&quot;MOTIVATOR MODEL&quot;" target="&quot;AMYGDALA (AMYGD)&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"MOTIVATOR Model interacts with AMYGD in cognitive-emotional interactions."</data>
      <data key="d6">89a24f37cf198d043ccd6b6b795dc232</data>
    </edge>
    <edge source="&quot;MOTIVATOR MODEL&quot;" target="&quot;LATERAL HYPOTHALAMUS (LH)&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"MOTIVATOR Model interacts with LH in cognitive-emotional interactions."</data>
      <data key="d6">89a24f37cf198d043ccd6b6b795dc232</data>
    </edge>
    <edge source="&quot;MOTIVATOR MODEL&quot;" target="&quot;BASAL GANGLIA&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"MOTIVATOR Model interacts with Basal Ganglia in cognitive-emotional interactions."</data>
      <data key="d6">89a24f37cf198d043ccd6b6b795dc232</data>
    </edge>
    <edge source="&quot;BASAL GANGLIA&quot;" target="&quot;REWARD EXPECTATION FILTER&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Reward Expectation Filter modulates the reward value of stimuli in the Basal Ganglia, which is involved in movement, emotion, and motivation."</data>
      <data key="d6">db27e91f327c97c16df11a500cdeab4d</data>
    </edge>
    <edge source="&quot;BASAL GANGLIA&quot;" target="&quot;SONGBIRD SINGING&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Basal ganglia circuits modulate song performance in songbirds."</data>
      <data key="d6">44ddf121af4b66da2bfd6b2ac0637a23</data>
    </edge>
    <edge source="&quot;BASAL GANGLIA&quot;" target="&quot;ANDALMAN AND FEE&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Andalman and Fee have studied the modulation of song performance by basal ganglia circuits in songbirds."</data>
      <data key="d6">44ddf121af4b66da2bfd6b2ac0637a23</data>
    </edge>
    <edge source="&quot;BASAL GANGLIA&quot;" target="&quot;FLEXIBLE PERFORMANCE&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Basal Ganglia modulates song performance, indicating its role in flexible performance."</data>
      <data key="d6">7aeda101aa8aba76f319932f0bd568f7</data>
    </edge>
    <edge source="&quot;ARTSCAN MODEL&quot;" target="&quot;VISUAL CORTEX V1&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"ARTSCAN Model interacts with Visual Cortex V1 during view-invariant object learning and visual search."</data>
      <data key="d6">89a24f37cf198d043ccd6b6b795dc232</data>
    </edge>
    <edge source="&quot;ARTSCAN MODEL&quot;" target="&quot;VISUAL CORTEX V2&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"ARTSCAN Model interacts with Visual Cortex V2 during view-invariant object learning and visual search."</data>
      <data key="d6">89a24f37cf198d043ccd6b6b795dc232</data>
    </edge>
    <edge source="&quot;ARTSCAN MODEL&quot;" target="&quot;VISUAL CORTEX V3A&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"ARTSCAN Model interacts with Visual Cortex V3A during view-invariant object learning and visual search."</data>
      <data key="d6">89a24f37cf198d043ccd6b6b795dc232</data>
    </edge>
    <edge source="&quot;ARTSCAN MODEL&quot;" target="&quot;VISUAL CORTEX V4&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"ARTSCAN Model interacts with Visual Cortex V4 during view-invariant object learning and visual search."</data>
      <data key="d6">89a24f37cf198d043ccd6b6b795dc232</data>
    </edge>
    <edge source="&quot;ARTSCAN MODEL&quot;" target="&quot;PREFRONTAL CORTEX (PFC)&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"ARTSCAN Model interacts with Prefrontal Cortex (PFC) during view-invariant object learning and visual search."</data>
      <data key="d6">89a24f37cf198d043ccd6b6b795dc232</data>
    </edge>
    <edge source="&quot;ARTSCAN MODEL&quot;" target="&quot;POSTERIOR PARIETAL CORTEX&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"ARTSCAN Model interacts with Posterior Parietal Cortex during view-invariant object learning and visual search."</data>
      <data key="d6">89a24f37cf198d043ccd6b6b795dc232</data>
    </edge>
    <edge source="&quot;PREFRONTAL CORTEX (PFC)&quot;" target="&quot;ARTSCAN&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The ARTSCAN model involves interactions between Prefrontal Cortex (PFC) and other brain regions in simulating view-invariant object learning and visual search."</data>
      <data key="d6">db27e91f327c97c16df11a500cdeab4d</data>
    </edge>
    <edge source="&quot;ARTSCAN&quot;" target="&quot;VISUAL CORTICES V1, V2, V3A, AND V4&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The ARTSCAN model simulates view-invariant object learning and visual search during unconstrained saccadic eye movements, involving interactions between Visual Cortices V1, V2, V3A, and V4."</data>
      <data key="d6">db27e91f327c97c16df11a500cdeab4d</data>
    </edge>
    <edge source="&quot;ARTSCAN&quot;" target="&quot;LATERAL INTRAPARIETAL AREA (LIP)&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The ARTSCAN model involves interactions between Lateral Intraparietal Area (LIP) and other brain regions in simulating view-invariant object learning and visual search."</data>
      <data key="d6">db27e91f327c97c16df11a500cdeab4d</data>
    </edge>
    <edge source="&quot;ARTSCAN&quot;" target="&quot;POSTERIOR AND ANTERIOR INFEROTEMPORAL CORTEX (PIT, AIT)&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The ARTSCAN model involves interactions between Posterior and Anterior Inferotemporal Cortex (pIT, aIT) and other brain regions in simulating view-invariant object learning and visual search."</data>
      <data key="d6">db27e91f327c97c16df11a500cdeab4d</data>
    </edge>
    <edge source="&quot;ARTSCENE SEARCH&quot;" target="&quot;VISUAL CORTICES V1, V2, AND V4&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The ARTSCENE Search model simulates object and spatial contextual cueing of visual search for desired objects in a scene, involving interactions between Visual Cortices V1, V2, and V4."</data>
      <data key="d6">db27e91f327c97c16df11a500cdeab4d</data>
    </edge>
    <edge source="&quot;ARTSCENE SEARCH&quot;" target="&quot;VENTRAL AND DORSOLATERAL PREFRONTAL CORTEX (VPFC, DLPFC)&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The ARTSCENE Search model involves interactions between Ventral and Dorsolateral Prefrontal Cortex (VPFC, DLPFC) and other brain regions in simulating object and spatial contextual cueing of visual search."</data>
      <data key="d6">db27e91f327c97c16df11a500cdeab4d</data>
    </edge>
    <edge source="&quot;ARTSCENE SEARCH&quot;" target="&quot;PERIRHINAL CORTEX (PRC)&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The ARTSCENE Search model involves interactions between Perirhinal Cortex (PRC) and other brain regions in simulating object and spatial contextual cueing of visual search."</data>
      <data key="d6">db27e91f327c97c16df11a500cdeab4d</data>
    </edge>
    <edge source="&quot;ARTSCENE SEARCH&quot;" target="&quot;PARAHIPPOCAMPAL CORTEX (PHC)&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The ARTSCENE Search model involves interactions between Parahippocampal Cortex (PHC) and other brain regions in simulating object and spatial contextual cueing of visual search."</data>
      <data key="d6">db27e91f327c97c16df11a500cdeab4d</data>
    </edge>
    <edge source="&quot;ARTSCENE SEARCH&quot;" target="&quot;POSTERIOR AND ANTERIOR INFEROTEMPORAL CORTEX (ITA, ITP)&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The ARTSCENE Search model involves interactions between Posterior and Anterior Inferotemporal Cortex (ITa, ITp) and other brain regions in simulating object and spatial contextual cueing of visual search."</data>
      <data key="d6">db27e91f327c97c16df11a500cdeab4d</data>
    </edge>
    <edge source="&quot;GRIDPLACEMAP&quot;" target="&quot;BRAIN REGIONS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The GridPlaceMap model simulates the formation of a grid cell representation of space, involving interactions between various brain regions."</data>
      <data key="d6">db27e91f327c97c16df11a500cdeab4d</data>
    </edge>
    <edge source="&quot;NEURONAL LEARNING&quot;" target="&quot;MATHEMATICAL THEOREMS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Mathematical Theorems serve as a foundation for the learning capabilities demonstrated in the architectures mentioned in the text."</data>
      <data key="d6">b881b9051ad24c6a16b468803fba51d3</data>
    </edge>
    <edge source="&quot;MATHEMATICAL THEOREMS&quot;" target="&quot;GENERALIZED ADDITIVE RNNS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The learning capabilities of the Generalized Additive RNNs architecture are based on a foundation of Mathematical Theorems."</data>
      <data key="d6">5812b5d4bcdfbf80de28dca56a6559b3</data>
    </edge>
    <edge source="&quot;SPATIAL PATTERN LEARNING&quot;" target="&quot;OUTSTAR LEARNING THEOREM&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Outstar Learning Theorem is a learning theory that allows for the identification and learning of spatial patterns."</data>
      <data key="d6">be49e9beb2d7cc985fe9f6517fa0f4fe</data>
    </edge>
    <edge source="&quot;SPATIAL PATTERN LEARNING&quot;" target="&quot;SPARSE STABLE CATEGORY LEARNING THEOREM&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Sparse Stable Category Learning Theorem also allows for the identification and learning of spatial patterns, using multiple Instars competing with each other via a RCF."</data>
      <data key="d6">be49e9beb2d7cc985fe9f6517fa0f4fe</data>
    </edge>
    <edge source="&quot;SIGNAL VELOCITY&quot;" target="&quot;AXON LENGTH&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Signal Velocity is not directly controlled by Axon Length, but they can be related through Axon Diameter."</data>
      <data key="d6">18be9bfe53d3b9c1e15c1c8238674459</data>
    </edge>
    <edge source="&quot;AXON LENGTH&quot;" target="&quot;AXON DIAMETER&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Longer axons are often thicker, with Axon Diameter influencing Axon Length."</data>
      <data key="d6">18be9bfe53d3b9c1e15c1c8238674459</data>
    </edge>
    <edge source="&quot;GENERALIZED ADDITIVE SYSTEM&quot;" target="&quot;SAMPLED CELLS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Sampled Cells are a component of the Generalized Additive System."</data>
      <data key="d6">8bb0e63353e66a2c60a878028beff5f9</data>
    </edge>
    <edge source="&quot;GENERALIZED ADDITIVE SYSTEM&quot;" target="&quot;SAMPLING CELLS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Sampling Cells are a component of the Generalized Additive System."</data>
      <data key="d6">8bb0e63353e66a2c60a878028beff5f9</data>
    </edge>
    <edge source="&quot;GENERALIZED ADDITIVE SYSTEM&quot;" target="&quot;SIGNAL FUNCTIONAL&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Signal Functional is a component of the Generalized Additive System."</data>
      <data key="d6">8bb0e63353e66a2c60a878028beff5f9</data>
    </edge>
    <edge source="&quot;GENERALIZED ADDITIVE SYSTEM&quot;" target="&quot;SAMPLING FUNCTIONAL&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Sampling Functional is a component of the Generalized Additive System."</data>
      <data key="d6">8bb0e63353e66a2c60a878028beff5f9</data>
    </edge>
    <edge source="&quot;GENERALIZED ADDITIVE SYSTEM&quot;" target="&quot;DECAY FUNCTIONAL&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Decay Functional is a component of the Generalized Additive System."</data>
      <data key="d6">8bb0e63353e66a2c60a878028beff5f9</data>
    </edge>
    <edge source="&quot;SAMPLED CELLS&quot;" target="&quot;SAMPLING CELLS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Sampled Cells and Sampling Cells are components of the same system, the Generalized Additive System."</data>
      <data key="d6">8bb0e63353e66a2c60a878028beff5f9</data>
    </edge>
    <edge source="&quot;SIGNAL FUNCTIONAL&quot;" target="&quot;SAMPLING FUNCTIONAL&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Signal Functional and the Sampling Functional are components of the same system, the Generalized Additive System, and they both represent spike-based signaling terms."</data>
      <data key="d6">8bb0e63353e66a2c60a878028beff5f9</data>
    </edge>
    <edge source="&quot;UNBIASED SPATIAL PATTERN LEARNING THEOREM&quot;" target="&quot;CONDITIONED STIMULI (CS)&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Unbiased Spatial Pattern Learning Theorem proves how unbiased learning may occur in response to correlated Conditioned Stimuli."</data>
      <data key="d6">4959d1559344e462a6a7463fd3273659</data>
    </edge>
    <edge source="&quot;UNBIASED SPATIAL PATTERN LEARNING THEOREM&quot;" target="&quot;UNCONDITIONED STIMULI (US)&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Unbiased Spatial Pattern Learning Theorem proves how unbiased learning may occur in response to correlated Unconditioned Stimuli."</data>
      <data key="d6">4959d1559344e462a6a7463fd3273659</data>
    </edge>
    <edge source="&quot;UNBIASED SPATIAL PATTERN LEARNING THEOREM&quot;" target="&quot;SELF-ORGANIZING AVALANCHE&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Self-Organizing Avalanche system learns its sampling cells and output spatial patterns through the guarantee of the Unbiased Spatial Pattern Learning Theorem."</data>
      <data key="d6">6e8f1f4e6c7865b14f3b5665aa62e12e</data>
    </edge>
    <edge source="&quot;OUTSTAR LEARNING THEOREM&quot;" target="&quot;STANLEY GROSSBERG&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Stanley Grossberg proposed the Outstar Learning Theorem, which explains how a series of Outstars can learn an arbitrary spatiotemporal pattern."</data>
      <data key="d6">be49e9beb2d7cc985fe9f6517fa0f4fe</data>
    </edge>
    <edge source="&quot;OUTSTAR LEARNING THEOREM&quot;" target="&quot;LEARNING THEORIES&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Outstar Learning Theorem is a theoretical framework that explains how systems can learn and adapt to new spatiotemporal patterns."</data>
      <data key="d6">be49e9beb2d7cc985fe9f6517fa0f4fe</data>
    </edge>
    <edge source="&quot;STANLEY GROSSBERG&quot;" target="&quot;SPARSE STABLE CATEGORY LEARNING THEOREM&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Stanley Grossberg also proposed the Sparse Stable Category Learning Theorem, which involves the use of the dual network to the Outstar, the Instar, to form a Competitive Learning or Self-Organizing Map network."</data>
      <data key="d6">be49e9beb2d7cc985fe9f6517fa0f4fe</data>
    </edge>
    <edge source="&quot;SPARSE STABLE CATEGORY LEARNING THEOREM&quot;" target="&quot;INSTAR&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Instar is the dual network to the Outstar, which is used in the Sparse Stable Category Learning Theorem to form a Competitive Learning or Self-Organizing Map network."</data>
      <data key="d6">be49e9beb2d7cc985fe9f6517fa0f4fe</data>
    </edge>
    <edge source="&quot;SPARSE STABLE CATEGORY LEARNING THEOREM&quot;" target="&quot;LEARNING THEORIES&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Sparse Stable Category Learning Theorem is another theoretical framework that explains how systems can learn and adapt to new patterns, using a competitive learning mechanism."</data>
      <data key="d6">be49e9beb2d7cc985fe9f6517fa0f4fe</data>
    </edge>
    <edge source="&quot;SPARSE STABLE CATEGORY LEARNING THEOREM&quot;" target="&quot;COMPETITIVE LEARNING&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Competitive Learning is a mechanism used in the Sparse Stable Category Learning Theorem to allow multiple Instars to compete with each other."</data>
      <data key="d6">be49e9beb2d7cc985fe9f6517fa0f4fe</data>
    </edge>
    <edge source="&quot;SPARSE STABLE CATEGORY LEARNING THEOREM&quot;" target="&quot;SELF-ORGANIZING MAP&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Self-Organizing Map is a type of artificial neural network that is formed as a result of the Sparse Stable Category Learning Theorem, allowing for the representation of the structure of input data."</data>
      <data key="d6">be49e9beb2d7cc985fe9f6517fa0f4fe</data>
    </edge>
    <edge source="&quot;KOSKO&quot;" target="&quot;SHORT-TERM MEMORY&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Kosko's adapted system combines Short-Term Memory (STM) and Long-Term Memory (LTM)."</data>
      <data key="d6">01e2a32da700813f593038a23a618e55</data>
    </edge>
    <edge source="&quot;KOSKO&quot;" target="&quot;LONG-TERM MEMORY&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Kosko's adapted system combines Short-Term Memory (STM) and Long-Term Memory (LTM)."</data>
      <data key="d6">01e2a32da700813f593038a23a618e55</data>
    </edge>
    <edge source="&quot;LIST CHUNKS&quot;" target="&quot;SELF-ORGANIZING AVALANCHE&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Self-Organizing Avalanches can learn List Chunks, which are sensitive to whole sequences of previous events."</data>
      <data key="d6">2ea6b3379a87077d75e5c45024f4f3e2</data>
    </edge>
    <edge source="&quot;LIST CHUNKS&quot;" target="&quot;CONTEXT-SENSITIVE SELF-ORGANIZING AVALANCHE&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Context-Sensitive Self-Organizing Avalanches utilize List Chunks as sampling cells and planning nodes."</data>
      <data key="d6">2ea6b3379a87077d75e5c45024f4f3e2</data>
    </edge>
    <edge source="&quot;LIST CHUNKS&quot;" target="&quot;SERIAL LEARNING&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"List Chunks are units that are introduced to explain sequence-sensitive contextual control in Serial Learning."</data>
      <data key="d6">cdd2935776d71ef9fd3a33979af0b9b5</data>
    </edge>
    <edge source="&quot;GROSSBERG AND PEARSON&quot;" target="&quot;ITEM-ORDER-RANK WORKING MEMORIES&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Grossberg and Pearson are the authors of a model that generalizes Item-and-Order working memories to include rank information."</data>
      <data key="d6">c38beddeac1d3cac8282ad59bc835788</data>
    </edge>
    <edge source="&quot;FRONTAL CORTEX&quot;" target="&quot;ITEM-AND-ORDER WORKING MEMORY&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Frontal Cortex is mentioned in the context of Item-and-Order Working Memory, suggesting its involvement in this cognitive function."</data>
      <data key="d6">296fa3812e2c81f685d8cdc403cb03dd</data>
    </edge>
    <edge source="&quot;FRONTAL CORTEX&quot;" target="&quot;SONGBIRD SINGING&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Frontal cortex circuits modulate song performance in songbirds."</data>
      <data key="d6">44ddf121af4b66da2bfd6b2ac0637a23</data>
    </edge>
    <edge source="&quot;FRONTAL CORTEX&quot;" target="&quot;ANDALMAN AND FEE&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Andalman and Fee have studied the modulation of song performance by frontal cortex circuits in songbirds."</data>
      <data key="d6">44ddf121af4b66da2bfd6b2ac0637a23</data>
    </edge>
    <edge source="&quot;FRONTAL CORTEX&quot;" target="&quot;FLEXIBLE PERFORMANCE&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Frontal Cortex modulates song performance, indicating its role in flexible performance."</data>
      <data key="d6">7aeda101aa8aba76f319932f0bd568f7</data>
    </edge>
    <edge source="&quot;ITEM-AND-ORDER WORKING MEMORY&quot;" target="&quot;ITEM-ORDER-RANK WORKING MEMORY&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Item-Order-Rank Working Memory is a variant or extension of Item-and-Order Working Memory, sharing a similar conceptual framework."</data>
      <data key="d6">296fa3812e2c81f685d8cdc403cb03dd</data>
    </edge>
    <edge source="&quot;ITEM-AND-ORDER WORKING MEMORY&quot;" target="&quot;FREE RECALL&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Free Recall data were a source of inspiration for the discovery of Item-and-Order Working Memory, as the patterns observed in free recall influenced the design of this cognitive model."</data>
      <data key="d6">296fa3812e2c81f685d8cdc403cb03dd</data>
    </edge>
    <edge source="&quot;BRADSKI ET AL.&quot;" target="&quot;STORE 1 MODEL&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Bradski et al. defined the STORE 1 model, which is a member of the STORE model family."</data>
      <data key="d6">392028b79561bd7471cb68e7c9258b1e</data>
    </edge>
    <edge source="&quot;BOARDMAN AND BULLOCK&quot;" target="&quot;ITEM-AND-ORDER WM&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Boardman and Bullock have developed variants of the Item-and-Order working memory design."</data>
      <data key="d6">c3257facbf1b0a5da49d6a115f66df87</data>
    </edge>
    <edge source="&quot;HOUGHTON AND HARTLEY&quot;" target="&quot;ITEM-AND-ORDER WM&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Houghton and Hartley have contributed to the Item-and-Order working memory design."</data>
      <data key="d6">c3257facbf1b0a5da49d6a115f66df87</data>
    </edge>
    <edge source="&quot;PAGE AND NORRIS&quot;" target="&quot;ITEM-AND-ORDER WM&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Page and Norris have developed variants of the Item-and-Order working memory design."</data>
      <data key="d6">c3257facbf1b0a5da49d6a115f66df87</data>
    </edge>
    <edge source="&quot;RHODES ET AL.&quot;" target="&quot;ITEM-AND-ORDER WM&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Rhodes et al. have developed variants of the Item-and-Order working memory design."</data>
      <data key="d6">c3257facbf1b0a5da49d6a115f66df87</data>
    </edge>
    <edge source="&quot;HOUGHTON&quot;" target="&quot;ITEM-AND-ORDER WM&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Houghton has referred to Item-and-Order models as Competitive Queuing models."</data>
      <data key="d6">c3257facbf1b0a5da49d6a115f66df87</data>
    </edge>
    <edge source="&quot;FARRELL AND LEWANDOWSKY&quot;" target="&quot;ITEM-AND-ORDER WM&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Farrell and Lewandowsky have provided experimental support for Item-and-Order working memory properties."</data>
      <data key="d6">c3257facbf1b0a5da49d6a115f66df87</data>
    </edge>
    <edge source="&quot;AVERBECK ET AL.&quot;" target="&quot;ITEM-AND-ORDER WM&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Averbeck et al. have reported neurophysiological evidence supporting the primacy gradient in Item-and-Order working memory."</data>
      <data key="d6">c3257facbf1b0a5da49d6a115f66df87</data>
    </edge>
    <edge source="&quot;AVERBECK ET AL.&quot;" target="&quot;PRIMACY GRADIENT&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Averbeck et al. reported the first neurophysiological evidence of a primacy gradient in sequential copying movements."</data>
      <data key="d6">1c0f47f0b77faab56cbeba0e1e3e7e70</data>
    </edge>
    <edge source="&quot;AVERBECK ET AL.&quot;" target="&quot;INHIBITION OF THE MOST ACTIVE CELL&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Averbeck et al. reported neurophysiological evidence of inhibition of the most active cell after its command is read out in sequential copying movements."</data>
      <data key="d6">1c0f47f0b77faab56cbeba0e1e3e7e70</data>
    </edge>
    <edge source="&quot;ITEM-AND-ORDER WM&quot;" target="&quot;AGAM ET AL.&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Agam et al. reported psychophysical evidence of Item-and-Order WM properties in humans as they perform sequential copying movements."</data>
      <data key="d6">1c0f47f0b77faab56cbeba0e1e3e7e70</data>
    </edge>
    <edge source="&quot;JONES ET AL.&quot;" target="&quot;VERBAL WM&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Jones et al. reported similar performance characteristics to those of verbal WM for a spatial serial recall task."</data>
      <data key="d6">1c0f47f0b77faab56cbeba0e1e3e7e70</data>
    </edge>
    <edge source="&quot;MILLER&quot;" target="&quot;IMMEDIATE MEMORY SPAN&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Miller proposed the concept of the Immediate Memory Span, which is the limited number of items that can be held in short-term memory."</data>
      <data key="d6">b69b23b14e0feccb488ba5412db0824c</data>
    </edge>
    <edge source="&quot;VON RESTORFF&quot;" target="&quot;ISOLATION EFFECTS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Von Restorff is known for studying the effects of similarity and distinctiveness in visual perception, leading to the concept of isolation effects, which can also be caused by mechanisms in the Working Memory model."</data>
      <data key="d6">b69b23b14e0feccb488ba5412db0824c</data>
    </edge>
    <edge source="&quot;TMS&quot;" target="&quot;VISUAL SHORT TERM MEMORY&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Visual short term memory is mentioned in relation to the discussion of working memory and long-term memory, which may be related to the TMS."</data>
      <data key="d6">392028b79561bd7471cb68e7c9258b1e</data>
    </edge>
    <edge source="&quot;STORE 1 MODEL&quot;" target="&quot;SKI ET AL.&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Ski et al. are the authors of the STORE 1 Model, having introduced and developed it in their studies."</data>
      <data key="d6">9c685cea284029fa1f27ebaa280615a5</data>
    </edge>
    <edge source="&quot;STORE 1 MODEL&quot;" target="&quot;1992&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The STORE 1 Model was introduced by Ski et al. in 1992."</data>
      <data key="d6">9c685cea284029fa1f27ebaa280615a5</data>
    </edge>
    <edge source="&quot;STORE 1 MODEL&quot;" target="&quot;1994&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Ski et al. further developed the STORE 1 Model in 1994."</data>
      <data key="d6">9c685cea284029fa1f27ebaa280615a5</data>
    </edge>
    <edge source="&quot;SERIAL LEARNING&quot;" target="&quot;YOUNG&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Young expresses skepticism about the usefulness of Serial Learning methods for studying verbal learning processes."</data>
      <data key="d6">cdd2935776d71ef9fd3a33979af0b9b5</data>
    </edge>
    <edge source="&quot;SERIAL LEARNING&quot;" target="&quot;UNDERWOOD&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Underwood criticizes the applicability of Serial Learning methods in verbal learning research."</data>
      <data key="d6">cdd2935776d71ef9fd3a33979af0b9b5</data>
    </edge>
    <edge source="&quot;SERIAL LEARNING&quot;" target="&quot;VERBAL LEARNING&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Serial Learning is a method that can influence Verbal Learning, as new verbal units are synthesized and the context of previous events can determine subsequent responses."</data>
      <data key="d6">cdd2935776d71ef9fd3a33979af0b9b5</data>
    </edge>
    <edge source="&quot;AVALANCHE&quot;" target="&quot;HVC-RA NETWORK&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Avalanche is a type of circuit that occurs within the HVC-RA Network, which controls songbird singing."</data>
      <data key="d6">44ddf121af4b66da2bfd6b2ac0637a23</data>
    </edge>
    <edge source="&quot;AVALANCHE&quot;" target="&quot;COMMAND CELLS&quot;">
      <data key="d4">2.0</data>
      <data key="d5">"The Avalanche circuit requires command cells for sensitivity to environmental feedback."
"Command Cells are mentioned in the context of the Avalanche system that can determine which ritualistic behavior the system will activate."</data>
      <data key="d6">7aeda101aa8aba76f319932f0bd568f7,88a3f14024e29666891496bb6cd7d0e4</data>
    </edge>
    <edge source="&quot;AVALANCHE&quot;" target="&quot;OUTSTARS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Outstars within the Avalanche circuit can fire only if activated by a command cell."</data>
      <data key="d6">7aeda101aa8aba76f319932f0bd568f7</data>
    </edge>
    <edge source="&quot;AVALANCHE&quot;" target="&quot;REWARD&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Reward is mentioned in the context of events that can be evaluated by the Avalanche network to determine what actions are important."</data>
      <data key="d6">88a3f14024e29666891496bb6cd7d0e4</data>
    </edge>
    <edge source="&quot;AVALANCHE&quot;" target="&quot;PUNISHMENT&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Punishment is mentioned in the context of events that can be evaluated by the Avalanche network to determine what actions are important."</data>
      <data key="d6">88a3f14024e29666891496bb6cd7d0e4</data>
    </edge>
    <edge source="&quot;HVC-RA NETWORK&quot;" target="&quot;SONGBIRD SINGING&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The HVC-RA Network, which includes an Avalanche-type circuit, controls songbird singing."</data>
      <data key="d6">44ddf121af4b66da2bfd6b2ac0637a23</data>
    </edge>
    <edge source="&quot;COMMAND CELLS&quot;" target="&quot;STEIN&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Stein has studied the role of command cells in controlling the rhythmic beating of crayfish swimmerets."</data>
      <data key="d6">7aeda101aa8aba76f319932f0bd568f7</data>
    </edge>
    <edge source="&quot;COMMAND CELLS&quot;" target="&quot;CARLSON&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Carlson is mentioned in the context of studying the behavior of command cells in invertebrates."</data>
      <data key="d6">88a3f14024e29666891496bb6cd7d0e4</data>
    </edge>
    <edge source="&quot;COMMAND CELLS&quot;" target="&quot;DETHIER&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Dethier is mentioned in the context of studying the behavior of command cells in invertebrates."</data>
      <data key="d6">88a3f14024e29666891496bb6cd7d0e4</data>
    </edge>
    <edge source="&quot;COGEM THEORY&quot;" target="&quot;REWARD&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Reward is mentioned in the context of the Cognitive-Emotional-Motor theory of reinforcement learning."</data>
      <data key="d6">88a3f14024e29666891496bb6cd7d0e4</data>
    </edge>
    <edge source="&quot;COGEM THEORY&quot;" target="&quot;PUNISHMENT&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Punishment is mentioned in the context of the Cognitive-Emotional-Motor theory of reinforcement learning."</data>
      <data key="d6">88a3f14024e29666891496bb6cd7d0e4</data>
    </edge>
    <edge source="&quot;SELF-ORGANIZING AVALANCHE&quot;" target="&quot;DR. PAUL GROSSBERG&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Dr. Paul Grossberg is mentioned as a researcher who has contributed to the development of the Self-Organizing Avalanche system."</data>
      <data key="d6">6e8f1f4e6c7865b14f3b5665aa62e12e</data>
    </edge>
    <edge source="&quot;YOUNG&quot;" target="&quot;ESP&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Young contributes to the algebraic conditions for additive-sigmoid neuron reservoirs, which may be relevant to the ESP.")</data>
      <data key="d6">3b592e5ac113a5c031925f91a182baa6</data>
    </edge>
    <edge source="&quot;YOUNG (1968)&quot;" target="&quot;CLASSICAL SERIAL LEARNING DATA&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Young (1968) expressed concerns about the limitations of serial learning methods in relation to the classical serial learning data."</data>
      <data key="d6">54e2e54daeae6bcf60e5f0b98040259d</data>
    </edge>
    <edge source="&quot;UNDERWOOD (1966)&quot;" target="&quot;CLASSICAL SERIAL LEARNING DATA&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Underwood (1966) highlighted the success of a theory in relation to the classical serial learning data."</data>
      <data key="d6">54e2e54daeae6bcf60e5f0b98040259d</data>
    </edge>
    <edge source="&quot;CLASSICAL SERIAL LEARNING DATA&quot;" target="&quot;GROSSBERG (1969C)&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Grossberg (1969c) provided explanations and simulations of the classical serial learning data."</data>
      <data key="d6">54e2e54daeae6bcf60e5f0b98040259d</data>
    </edge>
    <edge source="&quot;CLASSICAL SERIAL LEARNING DATA&quot;" target="&quot;GROSSBERG AND PEPE (1970, 1971)&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Grossberg and Pepe (1970, 1971) contributed to the explanations and simulations of the classical serial learning data."</data>
      <data key="d6">54e2e54daeae6bcf60e5f0b98040259d</data>
    </edge>
    <edge source="&quot;CLASSICAL SERIAL LEARNING DATA&quot;" target="&quot;GROSSBERG (1978A, 1993)&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Grossberg (1978a, 1993) reviewed the explanations and simulations of the classical serial learning data."</data>
      <data key="d6">54e2e54daeae6bcf60e5f0b98040259d</data>
    </edge>
    <edge source="&quot;ECHO STATE NETWORKS&quot;" target="&quot;WIKIPEDIA PAGE&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Wikipedia page is a resource where more information about Echo State Networks can be found."</data>
      <data key="d6">83fafb2423a01afae7e522917d79ace9</data>
    </edge>
    <edge source="&quot;ECHO STATE NETWORKS&quot;" target="&quot;RANDOM HIGH-DIMENSIONAL VECTOR&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Echo State Networks use a reservoir to generate a Random High-Dimensional Vector, which is then used for efficient learning and decoding."</data>
      <data key="d6">82a734e7c7ada95b1c99783140dd7168</data>
    </edge>
    <edge source="&quot;ECHO STATE NETWORKS&quot;" target="&quot;READOUT LAYER&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Echo State Networks include a Readout Layer that is trained to decode the high-dimensional activation vectors from the reservoir and produce accurate predictions."</data>
      <data key="d6">0e6f0f7cd882a638ecb571ef36068868</data>
    </edge>
    <edge source="&quot;ECHO STATE NETWORKS&quot;" target="&quot;GITHUB&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The text mentions resources on GitHub, such as the first tutorial on Echo State Networks, which provides additional information about the topic."</data>
      <data key="d6">0e6f0f7cd882a638ecb571ef36068868</data>
    </edge>
    <edge source="&quot;ECHO STATE NETWORKS&quot;" target="&quot;INPUT-TO-READOUT CONNECTIONS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Input-to-readout connections are a feature used in Echo State Networks to enhance the model's ability to capture and utilize relevant input data."</data>
      <data key="d6">8965403859beb43a6ab7e5c8c916b857</data>
    </edge>
    <edge source="&quot;ECHO STATE NETWORKS&quot;" target="&quot;HYPEROPT&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Hyperopt is used in the paper to optimize the hyperparameters of Echo State Networks."</data>
      <data key="d6">46913f0d73ba0b8cecfdf42bde9862f4</data>
    </edge>
    <edge source="&quot;ECHO STATE NETWORKS&quot;" target="&quot;HYPERPARAMETER OPTIMIZATION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Hyperparameter Optimization is the process of finding the best hyperparameters for Echo State Networks to improve their performance."</data>
      <data key="d6">46913f0d73ba0b8cecfdf42bde9862f4</data>
    </edge>
    <edge source="&quot;ECHO STATE NETWORKS&quot;" target="&quot;HYPERPARAMETERS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The text discusses the importance of understanding and optimizing hyperparameters in the context of Echo State Networks."</data>
      <data key="d6">73e81fd6509a2ba400a8435793ade3c5</data>
    </edge>
    <edge source="&quot;ECHO STATE NETWORKS&quot;" target="&quot;MACKEY-GLASS TIMES&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The text uses the Mackey-Glass Times data set for testing and benchmarking Echo State Networks."</data>
      <data key="d6">73e81fd6509a2ba400a8435793ade3c5</data>
    </edge>
    <edge source="&quot;ECHO STATE NETWORKS&quot;" target="&quot;RNN&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Echo State Networks are designed to train RNNs, as mentioned in the text."</data>
      <data key="d6">f0b3b2a88425b0563005400ea246528b</data>
    </edge>
    <edge source="&quot;ECHO STATE NETWORKS&quot;" target="&quot;SCHMIDHUBER ET AL.&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Schmidhuber et al. have used margin-maximization criteria in the context of Echo State Networks, as mentioned in the text."</data>
      <data key="d6">f0b3b2a88425b0563005400ea246528b</data>
    </edge>
    <edge source="&quot;ECHO STATE NETWORKS&quot;" target="&quot;SIGMOID UNIT&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Echo State Networks use Sigmoid Units in their basic discrete-time structure, as mentioned in the text."</data>
      <data key="d6">f0b3b2a88425b0563005400ea246528b</data>
    </edge>
    <edge source="&quot;ECHO STATE NETWORKS&quot;" target="&quot;JAEGER&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Jaeger has contributed to the theoretical research on Echo State Networks."</data>
      <data key="d6">5a9eaff8c67e594f49fae0318a502c6a</data>
    </edge>
    <edge source="&quot;ECHO STATE NETWORKS&quot;" target="&quot;WHITE&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"White has contributed to the theoretical research on Echo State Networks."</data>
      <data key="d6">5a9eaff8c67e594f49fae0318a502c6a</data>
    </edge>
    <edge source="&quot;ECHO STATE NETWORKS&quot;" target="&quot;SOMPOLINSKY&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Sompolinsky has contributed to the theoretical research on Echo State Networks."</data>
      <data key="d6">5a9eaff8c67e594f49fae0318a502c6a</data>
    </edge>
    <edge source="&quot;ECHO STATE NETWORKS&quot;" target="&quot;HERMANS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Hermans has contributed to the theoretical research on Echo State Networks."</data>
      <data key="d6">5a9eaff8c67e594f49fae0318a502c6a</data>
    </edge>
    <edge source="&quot;ECHO STATE NETWORKS&quot;" target="&quot;SCHRAUWEN&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Schrauwen has contributed to the theoretical research on Echo State Networks."</data>
      <data key="d6">5a9eaff8c67e594f49fae0318a502c6a</data>
    </edge>
    <edge source="&quot;ECHO STATE NETWORKS&quot;" target="&quot;SCHMIDHUBER&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Schmidhuber has contributed to the theoretical research on Echo State Networks and their limitations."</data>
      <data key="d6">5a9eaff8c67e594f49fae0318a502c6a</data>
    </edge>
    <edge source="&quot;ECHO STATE NETWORKS&quot;" target="&quot;MAASS&quot;">
      <data key="d4">2.0</data>
      <data key="d5">"Maass has contributed to the theoretical research on Echo State Networks and their ability to realize unbounded memory spans."
"Maass is a researcher who made significant contributions to the development of Echo State Networks and their applications in Machine Learning."</data>
      <data key="d6">5a9eaff8c67e594f49fae0318a502c6a,6de297d888d10db4c987b5eafc6398b2</data>
    </edge>
    <edge source="&quot;ECHO STATE NETWORKS&quot;" target="&quot;NATSCHLAEGER&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Natschlaeger has contributed to the theoretical research on Echo State Networks."</data>
      <data key="d6">5a9eaff8c67e594f49fae0318a502c6a</data>
    </edge>
    <edge source="&quot;ECHO STATE NETWORKS&quot;" target="&quot;MARKRAM&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Markram has contributed to the theoretical research on Echo State Networks."</data>
      <data key="d6">5a9eaff8c67e594f49fae0318a502c6a</data>
    </edge>
    <edge source="&quot;ECHO STATE NETWORKS&quot;" target="&quot;BOUNDED MEMORY&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Echo State Networks are limited by their bounded memory capacity."</data>
      <data key="d6">5a9eaff8c67e594f49fae0318a502c6a</data>
    </edge>
    <edge source="&quot;ECHO STATE NETWORKS&quot;" target="&quot;UNBOUNDED MEMORY SPANS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Echo State Networks can realize unbounded memory spans through the use of output units with feedback to the reservoir."</data>
      <data key="d6">5a9eaff8c67e594f49fae0318a502c6a</data>
    </edge>
    <edge source="&quot;ECHO STATE NETWORKS&quot;" target="&quot;2010&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Echo State Networks started to gain relevance and popularity around the year 2010."</data>
      <data key="d6">257d4cf08ffc32b99856b6e31fa4221e</data>
    </edge>
    <edge source="&quot;ECHO STATE NETWORKS&quot;" target="&quot;OPTICAL MICROCHIPS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Echo State Networks have been used in conjunction with Optical Microchips as a computational principle."</data>
      <data key="d6">257d4cf08ffc32b99856b6e31fa4221e</data>
    </edge>
    <edge source="&quot;ECHO STATE NETWORKS&quot;" target="&quot;MECHANICAL NANO-OSCILLATORS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Echo State Networks have been used in conjunction with Mechanical Nano-oscillators as a computational principle."</data>
      <data key="d6">257d4cf08ffc32b99856b6e31fa4221e</data>
    </edge>
    <edge source="&quot;ECHO STATE NETWORKS&quot;" target="&quot;MEMRISTOR-BASED NEUROMORPHIC MICROCHIPS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Echo State Networks have been used in conjunction with Memristor-based Neuromorphic Microchips as a computational principle."</data>
      <data key="d6">257d4cf08ffc32b99856b6e31fa4221e</data>
    </edge>
    <edge source="&quot;ECHO STATE NETWORKS&quot;" target="&quot;CARBON-NANOTUBE / POLYMER MIXTURES&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Echo State Networks have been used in conjunction with Carbon-nanotube / Polymer Mixtures as a computational principle."</data>
      <data key="d6">257d4cf08ffc32b99856b6e31fa4221e</data>
    </edge>
    <edge source="&quot;ECHO STATE NETWORKS&quot;" target="&quot;ARTIFICIAL SOFT LIMBS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Echo State Networks have been used in conjunction with Artificial Soft Limbs as a computational principle."</data>
      <data key="d6">257d4cf08ffc32b99856b6e31fa4221e</data>
    </edge>
    <edge source="&quot;ECHO STATE NETWORKS&quot;" target="&quot;BIOSIGNAL PROCESSING&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Echo State Networks have been used in the application area of Biosignal Processing."</data>
      <data key="d6">257d4cf08ffc32b99856b6e31fa4221e</data>
    </edge>
    <edge source="&quot;ECHO STATE NETWORKS&quot;" target="&quot;REMOTE SENSING&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Echo State Networks have been used in the application area of Remote Sensing."</data>
      <data key="d6">257d4cf08ffc32b99856b6e31fa4221e</data>
    </edge>
    <edge source="&quot;ECHO STATE NETWORKS&quot;" target="&quot;ROBOT MOTOR CONTROL&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Echo State Networks have been used in the application area of Robot Motor Control."</data>
      <data key="d6">257d4cf08ffc32b99856b6e31fa4221e</data>
    </edge>
    <edge source="&quot;ECHO STATE NETWORKS&quot;" target="&quot;BAM NETWORK&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"BAM Network and Echo State Networks are both types of neural networks, with BAM Network having two layers and Echo State Networks having a sparsely connected random hidden layer."</data>
      <data key="d6">423cdb622c47fa8cec25f22eb9f9f01f</data>
    </edge>
    <edge source="&quot;ECHO STATE NETWORKS&quot;" target="&quot;LIQUID STATE MACHINE&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Liquid State Machine is a variant of Echo State Networks for spiking neurons."</data>
      <data key="d6">423cdb622c47fa8cec25f22eb9f9f01f</data>
    </edge>
    <edge source="&quot;ECHO STATE NETWORKS&quot;" target="&quot;RIDGE REGRESSION&quot;">
      <data key="d4">2.0</data>
      <data key="d5">"Ridge Regression is a method used in echo state networks for regression analysis to prevent overfitting."
"Ridge Regression is mentioned as a component used in the construction of Echo State Networks."</data>
      <data key="d6">41fa16855df7da666dc6fc38d2f8ee53,ed28ba3543e07641536ff1eb5e0749dd</data>
    </edge>
    <edge source="&quot;ECHO STATE NETWORKS&quot;" target="&quot;FIT METHOD&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Fit Method is used to train the echo state network model by optimizing the parameters of the readout layer."</data>
      <data key="d6">ed28ba3543e07641536ff1eb5e0749dd</data>
    </edge>
    <edge source="&quot;ECHO STATE NETWORKS&quot;" target="&quot;RUN METHOD&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Run Method is used to generate predictions or forecasts using the trained echo state network model."</data>
      <data key="d6">ed28ba3543e07641536ff1eb5e0749dd</data>
    </edge>
    <edge source="&quot;ECHO STATE NETWORKS&quot;" target="&quot;WARMUP&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Warmup is a technique used in echo state networks to initialize the reservoir with a sequence of input data before making predictions or forecasts."</data>
      <data key="d6">ed28ba3543e07641536ff1eb5e0749dd</data>
    </edge>
    <edge source="&quot;ECHO STATE NETWORKS&quot;" target="&quot;RECURRENT NEURAL NETWORKS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Echo State Networks are a type of Recurrent Neural Network that operates a random, large, fixed, recurring network with the input signal."</data>
      <data key="d6">158f53cd85edbb4f2e4c77b78c5e7acc</data>
    </edge>
    <edge source="&quot;ECHO STATE NETWORKS&quot;" target="&quot;RECURRENT NEURAL NETWORKS (RNNS)&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Recurrent Neural Networks (RNNs) act as a random, nonlinear medium whose dynamic response is used as a signal base in echo state networks."</data>
      <data key="d6">a3368f9cab1f65643dba089af5a1f95e</data>
    </edge>
    <edge source="&quot;ECHO STATE NETWORKS&quot;" target="&quot;DIFFERENTIAL EQUATIONS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Echo State Networks can include physical models defined by differential equations."</data>
      <data key="d6">10112a11d47463e2aad7352c52922d61</data>
    </edge>
    <edge source="&quot;ECHO STATE NETWORKS&quot;" target="&quot;RANDOM, NONLINEAR MEDIUM&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Echo State Networks use a fixed RNN as a random, nonlinear medium to process input signals."</data>
      <data key="d6">10112a11d47463e2aad7352c52922d61</data>
    </edge>
    <edge source="&quot;ECHO STATE NETWORKS&quot;" target="&quot;TIME SERIES PREDICTION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Echo State Networks have been shown to perform well on time series prediction tasks."</data>
      <data key="d6">10112a11d47463e2aad7352c52922d61</data>
    </edge>
    <edge source="&quot;ECHO STATE NETWORKS&quot;" target="&quot;AUTODIFFERENTIATION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Autodifferentiation is a technique used in deep learning libraries that has made Echo State Networks less error-prone and faster to train."</data>
      <data key="d6">10112a11d47463e2aad7352c52922d61</data>
    </edge>
    <edge source="&quot;ECHO STATE NETWORKS&quot;" target="&quot;LSTM&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"LSTM is a type of recurrent neural network architecture that has been developed to address the unique selling point of Echo State Networks, which has been lost with the advent of autodifferentiation libraries."</data>
      <data key="d6">10112a11d47463e2aad7352c52922d61</data>
    </edge>
    <edge source="&quot;ECHO STATE NETWORKS&quot;" target="&quot;GRU&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"GRU is a type of recurrent neural network architecture that is similar to LSTM and has also been developed to address the limitations of Echo State Networks."</data>
      <data key="d6">10112a11d47463e2aad7352c52922d61</data>
    </edge>
    <edge source="&quot;RECURRENT NEURAL NETWORK&quot;" target="&quot;RESERVOIR NODE&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"A Recurrent Neural Network contains reservoir nodes, which are responsible for updating the reservoir's state and transforming the input data into high-dimensional representations."</data>
      <data key="d6">e1bf3df1ff001613df1451d6d8bf3ee4</data>
    </edge>
    <edge source="&quot;RECURRENT NEURAL NETWORK&quot;" target="&quot;ARTIFICIAL NEURAL NETWORK&quot;">
      <data key="d4">2.0</data>
      <data key="d5">"A Recurrent Neural Network is a type of Artificial Neural Network that processes sequences of inputs using internal state and allows outputs from some nodes to affect future inputs to the same nodes."
"Recurrent Neural Networks are a type of Artificial Neural Network, characterized by the direction of the flow of information between their layers."</data>
      <data key="d6">e1bf3df1ff001613df1451d6d8bf3ee4,f5b970cf7201f4a918d8bd6a1267657c</data>
    </edge>
    <edge source="&quot;RECURRENT NEURAL NETWORK&quot;" target="&quot;HANDWRITING RECOGNITION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Recurrent Neural Networks are suitable for tasks such as handwriting recognition due to their ability to process arbitrary sequences of inputs."</data>
      <data key="d6">f5b970cf7201f4a918d8bd6a1267657c</data>
    </edge>
    <edge source="&quot;RECURRENT NEURAL NETWORK&quot;" target="&quot;SPEECH RECOGNITION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Recurrent Neural Networks are also suitable for tasks such as speech recognition due to their ability to process arbitrary sequences of inputs."</data>
      <data key="d6">f5b970cf7201f4a918d8bd6a1267657c</data>
    </edge>
    <edge source="&quot;RECURRENT NEURAL NETWORK&quot;" target="&quot;TIME SERIES&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"A time series is mentioned as input to the Recurrent Neural Network, which processes all entries of the time series through the layers of the neural network."</data>
      <data key="d6">5445391448d4ac43471e2bce5eb41a70</data>
    </edge>
    <edge source="&quot;RECURRENT NEURAL NETWORK&quot;" target="&quot;MODERN LIBRARIES&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Modern Libraries are mentioned as providers of runtime-optimized implementations for recurrent neural networks."</data>
      <data key="d6">5445391448d4ac43471e2bce5eb41a70</data>
    </edge>
    <edge source="&quot;RECURRENT NEURAL NETWORK&quot;" target="&quot;ECHO STATE NETWORK&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Echo State Network uses a Recurrent Neural Network."</data>
      <data key="d6">dcd6355fc1ed8a61a1b70c50ce60fd36</data>
    </edge>
    <edge source="&quot;TIME SERIES FORECASTING&quot;" target="&quot;TIME SERIES ANALYSIS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Time Series Analysis is a fundamental method used in Time Series Forecasting, which involves using a model to predict future values based on previously observed values."</data>
      <data key="d6">dc76db79c20c315f30e0297619904b6f</data>
    </edge>
    <edge source="&quot;TIME SERIES FORECASTING&quot;" target="&quot;STOCHASTIC MODELS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Stochastic Models are used in Time Series Forecasting to account for the relationship between observations close together in time."</data>
      <data key="d6">e94f386a2ed7de2156b4864797cc199e</data>
    </edge>
    <edge source="&quot;TIME SERIES FORECASTING&quot;" target="&quot;REAL-VALUED CONTINUOUS DATA&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Real-Valued Continuous Data is a type of data that can be used in Time Series Forecasting."</data>
      <data key="d6">e94f386a2ed7de2156b4864797cc199e</data>
    </edge>
    <edge source="&quot;TIME SERIES FORECASTING&quot;" target="&quot;DISCRETE NUMERIC DATA&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Discrete Numeric Data is a type of data that can be used in Time Series Forecasting."</data>
      <data key="d6">e94f386a2ed7de2156b4864797cc199e</data>
    </edge>
    <edge source="&quot;TIME SERIES FORECASTING&quot;" target="&quot;DISCRETE SYMBOLIC DATA&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Discrete Symbolic Data is a type of data that can be used in Time Series Forecasting."</data>
      <data key="d6">e94f386a2ed7de2156b4864797cc199e</data>
    </edge>
    <edge source="&quot;TIME SERIES FORECASTING&quot;" target="&quot;FEEDBACK CONNECTION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Feedback connections enable the network to remember and utilize past information for current processing, which is beneficial for time series forecasting tasks."</data>
      <data key="d6">57a27a1504a5ef7d330172c0ac1085c9</data>
    </edge>
    <edge source="&quot;TIME SERIES FORECASTING&quot;" target="&quot;'&lt;&lt;' OPERATOR&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Time series forecasting uses the '&lt;&lt;' operator to incorporate previous predictions into current processing."</data>
      <data key="d6">c4b54c2da2dda7e660de7bd6de6f13b4</data>
    </edge>
    <edge source="&quot;TIME SERIES FORECASTING&quot;" target="&quot;CLOSED LOOP GENERATIVE MODE&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Closed Loop Generative Mode is a method used in Time Series Forecasting where the output of the model is fed back as input for subsequent prediction."</data>
      <data key="d6">05ba4f2e1a9472bd286417154cb0c0d4</data>
    </edge>
    <edge source="&quot;TIME SERIES FORECASTING&quot;" target="&quot;NP.VSTACK()&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"np.vstack() is used in Time Series Forecasting to combine arrays for plotting as a single timeseries."</data>
      <data key="d6">05ba4f2e1a9472bd286417154cb0c0d4</data>
    </edge>
    <edge source="&quot;TIME SERIES FORECASTING&quot;" target="&quot;X&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"X is a variable used in the Time Series Forecasting process."</data>
      <data key="d6">f70c7d3d89baaabbeaad57b58e379e08</data>
    </edge>
    <edge source="&quot;TIME SERIES FORECASTING&quot;" target="&quot;Y&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Y is a variable used in the Time Series Forecasting process."</data>
      <data key="d6">f70c7d3d89baaabbeaad57b58e379e08</data>
    </edge>
    <edge source="&quot;TIME SERIES FORECASTING&quot;" target="&quot;X_TRAIN&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"X_train is a subset of the X variable used for training the machine learning model in the Time Series Forecasting process."</data>
      <data key="d6">f70c7d3d89baaabbeaad57b58e379e08</data>
    </edge>
    <edge source="&quot;TIME SERIES FORECASTING&quot;" target="&quot;FORECAST&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Forecast is the process of predicting future values based on past observations in the Time Series Forecasting process."</data>
      <data key="d6">f70c7d3d89baaabbeaad57b58e379e08</data>
    </edge>
    <edge source="&quot;TIME SERIES FORECASTING&quot;" target="&quot;TRAIN_LEN&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Train_len is the length of the training data used for training the machine learning model in the Time Series Forecasting process."</data>
      <data key="d6">f70c7d3d89baaabbeaad57b58e379e08</data>
    </edge>
    <edge source="&quot;TIME SERIES FORECASTING&quot;" target="&quot;DATASET&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Dataset is the collection of data used for training and testing the machine learning model in the Time Series Forecasting process."</data>
      <data key="d6">f70c7d3d89baaabbeaad57b58e379e08</data>
    </edge>
    <edge source="&quot;TIME SERIES FORECASTING&quot;" target="&quot;LOSS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Loss is a metric used to evaluate the performance of the machine learning model during training in the Time Series Forecasting process."</data>
      <data key="d6">f70c7d3d89baaabbeaad57b58e379e08</data>
    </edge>
    <edge source="&quot;TIME SERIES FORECASTING&quot;" target="&quot;TIME SERIES&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Time Series Forecasting is the use of a model to predict future values in a Time Series."</data>
      <data key="d6">70c3a879c0f6e6b76a13d02d67bce1a8</data>
    </edge>
    <edge source="&quot;TIME SERIES FORECASTING&quot;" target="&quot;ESN MODEL&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Echo State Network (ESN) model is used for Time Series Forecasting, which is the primary task performed by the ESN Model."</data>
      <data key="d6">52d001cd1786e3d9f36e0c57538bc21e</data>
    </edge>
    <edge source="&quot;INRIA&quot;" target="&quot;XAVIER HINAUT&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Xavier Hinaut is a contact person for the library and works at INRIA."</data>
      <data key="d6">20b16c2e1cb8813ade96fea5f9591631</data>
    </edge>
    <edge source="&quot;INRIA&quot;" target="&quot;BORDEAUX&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Inria is located at Bordeaux, France."</data>
      <data key="d6">2a197220a94bac0b44fc0b07712e45ba</data>
    </edge>
    <edge source="&quot;RESERVOIRPY DOCUMENTATION&quot;" target="&quot;ESNS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"ReservoirPy documentation provides information about creating Echo State Networks."</data>
      <data key="d6">6be085e79e86abc5b1a7eaff6bda1ec5</data>
    </edge>
    <edge source="&quot;RESERVOIRPY DOCUMENTATION&quot;" target="&quot;NP.PI&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The ReservoirPy documentation is mentioned in the context of np.pi, suggesting that it may contain information about np.pi."</data>
      <data key="d6">475ca77684df5045266ddf079f2e37f1</data>
    </edge>
    <edge source="&quot;WIKIPEDIA PAGE&quot;" target="&quot;ESNS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Wikipedia page provides information about Echo State Networks."</data>
      <data key="d6">6be085e79e86abc5b1a7eaff6bda1ec5</data>
    </edge>
    <edge source="&quot;ESNS&quot;" target="&quot;MAASS, JOSHI &amp; SONTAG&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Maass, Joshi &amp; Sontag are the authors of a research paper that contributes to the theoretical properties of ESNs."</data>
      <data key="d6">e805d3f438bd9c485639f1c69f917ae5</data>
    </edge>
    <edge source="&quot;ESNS&quot;" target="&quot;PASCANU &amp; JAEGER&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Pascanu &amp; Jaeger are the authors of a research paper that introduces an ESN-based model of working memory."</data>
      <data key="d6">e805d3f438bd9c485639f1c69f917ae5</data>
    </edge>
    <edge source="&quot;ESNS&quot;" target="&quot;MAASS, NATSCHLAEGER &amp; MARKRAM&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Maass, Natschlaeger &amp; Markram are the authors of a research paper on Liquid State Machines, which is a theoretical framework related to ESNs."</data>
      <data key="d6">e805d3f438bd9c485639f1c69f917ae5</data>
    </edge>
    <edge source="&quot;ESNS&quot;" target="&quot;NONLINEAR MODELING TASKS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"ESNs are a type of neural network used in practical nonlinear modeling tasks."</data>
      <data key="d6">e805d3f438bd9c485639f1c69f917ae5</data>
    </edge>
    <edge source="&quot;ESNS&quot;" target="&quot;STATISTICAL LEARNING THEORY&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Statistical Learning Theory provides the theoretical foundation for optimizing biases in ESNs, which are known to outperform other RNN training algorithms."</data>
      <data key="d6">2a2a93486d6198ce228e77e120dc3c0c</data>
    </edge>
    <edge source="&quot;ESNS&quot;" target="&quot;REAL-TIME RECURRENT LEARNING&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Real-time Recurrent Learning is a slower and more prone-to-disruption RNN training algorithm that ESNs have outperformed."</data>
      <data key="d6">2a2a93486d6198ce228e77e120dc3c0c</data>
    </edge>
    <edge source="&quot;ESNS&quot;" target="&quot;BACKPROPAGATION THROUGH TIME&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Backpropagation Through Time is a slower and more prone-to-disruption RNN training algorithm that ESNs have outperformed."</data>
      <data key="d6">2a2a93486d6198ce228e77e120dc3c0c</data>
    </edge>
    <edge source="&quot;ESNS&quot;" target="&quot;EXTENDED KALMAN FILTERING BASED METHODS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Extended Kalman Filtering Based Methods is a slower and more prone-to-disruption RNN training algorithm that ESNs have outperformed."</data>
      <data key="d6">2a2a93486d6198ce228e77e120dc3c0c</data>
    </edge>
    <edge source="&quot;ESNS&quot;" target="&quot;ATIYA-PARLOS ALGORITHM&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Atiya-Parlos Algorithm is a slower and more prone-to-disruption RNN training algorithm that ESNs have outperformed."</data>
      <data key="d6">2a2a93486d6198ce228e77e120dc3c0c</data>
    </edge>
    <edge source="&quot;ESNS&quot;" target="&quot;DEEP LEARNING&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"ESNs are still a viable alternative when the modeled system is not too complex and fast, cheap, and adaptive training is desired, especially in applications like biosignal processing and remote sensing."</data>
      <data key="d6">eafe89ad19a57846f953a1dfcf8571f8</data>
    </edge>
    <edge source="&quot;ESNS&quot;" target="&quot;INPUT-TO-READOUT CONNECTIONS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Input-to-readout connections are a feature of ESNs that allow for more complex data processing."</data>
      <data key="d6">f1fc6fbc8158d3da070d55544041a2ca</data>
    </edge>
    <edge source="&quot;ESNS&quot;" target="&quot;MODEL CREATION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Model creation is the process of building a neural network model, including defining nodes, connections, and parameters, which is used in ESNs."</data>
      <data key="d6">f1fc6fbc8158d3da070d55544041a2ca</data>
    </edge>
    <edge source="&quot;ESNS&quot;" target="&quot;FEEDBACK CONNECTIONS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"ESNs utilize feedback connections to allow nodes to access the state of other nodes with a time delay."</data>
      <data key="d6">7f2d69f9a9baca70ffd25a6865189206</data>
    </edge>
    <edge source="&quot;ESNS&quot;" target="&quot;WOLFGANG MAASS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Wolfgang Maass independently developed Echo State Networks."</data>
      <data key="d6">b32958d42199d47252887dc7be40ab5a</data>
    </edge>
    <edge source="&quot;FEATURE&quot;" target="&quot;LABEL&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Features are attributes used to predict labels."</data>
      <data key="d6">6be085e79e86abc5b1a7eaff6bda1ec5</data>
    </edge>
    <edge source="&quot;HOUSE PRICE MODEL&quot;" target="&quot;LABELS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The House Price Model is designed to predict the Labels, which are the actual prices of the houses."</data>
      <data key="d6">8c15845717f6b8610fe30ac08cc78b4e</data>
    </edge>
    <edge source="&quot;HOUSE PRICE MODEL&quot;" target="&quot;RECURRENT NEURAL NETWORK (RNN)&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The House Price Model may utilize a Recurrent Neural Network (RNN) to process and learn patterns from the data, improving its ability to make accurate predictions."</data>
      <data key="d6">8c15845717f6b8610fe30ac08cc78b4e</data>
    </edge>
    <edge source="&quot;RECURRENT NEURAL NETWORK (RNN)&quot;" target="&quot;ECHO STATE NETWORK (ESN)&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Echo State Network (ESN) belongs to the Recurrent Neural Network (RNN) family."</data>
      <data key="d6">a4b801e70cf2ba3a3101d34899450087</data>
    </edge>
    <edge source="&quot;RECURRENT NEURAL NETWORK (RNN)&quot;" target="&quot;BACKPROPAGATION THROUGH TIME&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Backpropagation Through Time is a learning algorithm for Recurrent Neural Networks."</data>
      <data key="d6">a4b801e70cf2ba3a3101d34899450087</data>
    </edge>
    <edge source="&quot;RECURRENT NEURAL NETWORK (RNN)&quot;" target="&quot;REAL-TIME RECURRENT LEARNING&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Real-Time Recurrent Learning is a learning algorithm for Recurrent Neural Networks."</data>
      <data key="d6">a4b801e70cf2ba3a3101d34899450087</data>
    </edge>
    <edge source="&quot;RECURRENT NEURAL NETWORKS (RNNS)&quot;" target="&quot;CONVOLUTIONAL NEURAL NETWORKS (CNNS)&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"RNNs and CNNs are both types of neural networks, but they belong to different classes, with RNNs being infinite impulse response networks and CNNs being finite impulse response networks."</data>
      <data key="d6">04b89ad6396cb78ca75689473c47a247</data>
    </edge>
    <edge source="&quot;RECURRENT NEURAL NETWORKS (RNNS)&quot;" target="&quot;LONG SHORT-TERM MEMORY NETWORKS (LSTMS)&quot;">
      <data key="d4">2.0</data>
      <data key="d5">"LSTMs are a type of RNN that incorporates controlled storage mechanisms to manage and update information over time."
"RNNs use LSTMs to address the vanishing gradient problem and better capture long-term dependencies in sequential data."</data>
      <data key="d6">04b89ad6396cb78ca75689473c47a247,24a607f45ad989d81411fed4f2941884</data>
    </edge>
    <edge source="&quot;RECURRENT NEURAL NETWORKS (RNNS)&quot;" target="&quot;GATED RECURRENT UNITS (GRUS)&quot;">
      <data key="d4">2.0</data>
      <data key="d5">"GRUs are a type of RNN that uses gated states to manage and update information over time, similar to LSTMs."
"RNNs use GRUs to selectively update and reset hidden states, making them more efficient in processing long sequences of data."</data>
      <data key="d6">04b89ad6396cb78ca75689473c47a247,24a607f45ad989d81411fed4f2941884</data>
    </edge>
    <edge source="&quot;RECURRENT NEURAL NETWORKS (RNNS)&quot;" target="&quot;FEEDBACK NEURAL NETWORKS (FNNS)&quot;">
      <data key="d4">2.0</data>
      <data key="d5">"FNNs are neural networks that incorporate time delays or feedback loops, replacing standard storage mechanisms, which is a concept related to RNNs."
"RNNs can be classified as Feedback Neural Networks due to their use of time delays or feedback loops."</data>
      <data key="d6">04b89ad6396cb78ca75689473c47a247,24a607f45ad989d81411fed4f2941884</data>
    </edge>
    <edge source="&quot;RECURRENT NEURAL NETWORKS (RNNS)&quot;" target="&quot;TURING CAPABILITIES&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Turing Capabilities refer to the theoretical ability of RNNs to mimic the computational power of a Turing machine."</data>
      <data key="d6">04b89ad6396cb78ca75689473c47a247</data>
    </edge>
    <edge source="&quot;RECURRENT NEURAL NETWORKS (RNNS)&quot;" target="&quot;HANDWRITING RECOGNITION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"RNNs are particularly useful for Handwriting Recognition, as they can process unsegmented, connected handwriting."</data>
      <data key="d6">24a607f45ad989d81411fed4f2941884</data>
    </edge>
    <edge source="&quot;RECURRENT NEURAL NETWORKS (RNNS)&quot;" target="&quot;SPEECH RECOGNITION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"RNNs are also useful for Speech Recognition, as they can recognize and process spoken language."</data>
      <data key="d6">24a607f45ad989d81411fed4f2941884</data>
    </edge>
    <edge source="&quot;RECURRENT NEURAL NETWORKS (RNNS)&quot;" target="&quot;SEQUENTIAL DATA&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"RNNs are designed to process sequential data, such as time series or natural language."</data>
      <data key="d6">24a607f45ad989d81411fed4f2941884</data>
    </edge>
    <edge source="&quot;RECURRENT NEURAL NETWORKS (RNNS)&quot;" target="&quot;SCIPY&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"RNNs are a type of technology used in scientific and technical computing, as they are implemented in various applications within the field, such as language translation, natural language processing (NLP), speech recognition, and image captioning."</data>
      <data key="d6">4246748fef7001ea0bd03ac702565b0d</data>
    </edge>
    <edge source="&quot;RECURRENT NEURAL NETWORKS (RNNS)&quot;" target="&quot;TEACHER FORCING&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Teacher Forcing is commonly used in training Recurrent Neural Networks (RNNs) to improve their ability to learn sequential data."</data>
      <data key="d6">d0a69d653d08e58959dd8d0f2033e697</data>
    </edge>
    <edge source="&quot;SPEECH RECOGNITION&quot;" target="&quot;FEEDBACK CONNECTION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Feedback connections allow the network to access and utilize previous phoneme activations, which is useful for improving the accuracy of speech recognition tasks."</data>
      <data key="d6">57a27a1504a5ef7d330172c0ac1085c9</data>
    </edge>
    <edge source="&quot;SPEECH RECOGNITION&quot;" target="&quot;'&lt;&lt;' OPERATOR&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Speech recognition uses the '&lt;&lt;' operator to incorporate previous phoneme activations into current processing."</data>
      <data key="d6">c4b54c2da2dda7e660de7bd6de6f13b4</data>
    </edge>
    <edge source="&quot;TIME SERIES&quot;" target="&quot;DATA POINTS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Time Series is composed of a sequence of Data Points collected at successive equally spaced points in time."</data>
      <data key="d6">8a015d76b241ce06eb72867bbb712edd</data>
    </edge>
    <edge source="&quot;TIME SERIES&quot;" target="&quot;TIME SERIES ANALYSIS&quot;">
      <data key="d4">2.0</data>
      <data key="d5">"Time Series Analysis is the process of analyzing Time Series data to extract meaningful statistics and characteristics."
"Time Series Analysis is the process of analyzing Time Series data."</data>
      <data key="d6">70c3a879c0f6e6b76a13d02d67bce1a8,8a015d76b241ce06eb72867bbb712edd</data>
    </edge>
    <edge source="&quot;TIME SERIES&quot;" target="&quot;NUMPY&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"NumPy is mentioned in the context of formatting data for Time Series analysis."</data>
      <data key="d6">14bccd672d2f8dd2cd7300581c8844fb</data>
    </edge>
    <edge source="&quot;TIME SERIES&quot;" target="&quot;MATHEMATICS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Time Series is a concept that originates from the field of Mathematics."</data>
      <data key="d6">70c3a879c0f6e6b76a13d02d67bce1a8</data>
    </edge>
    <edge source="&quot;TIME SERIES&quot;" target="&quot;STATISTICS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Time Series is commonly used in the field of Statistics for analysis and forecasting."</data>
      <data key="d6">70c3a879c0f6e6b76a13d02d67bce1a8</data>
    </edge>
    <edge source="&quot;TIME SERIES&quot;" target="&quot;SIGNAL PROCESSING&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Time Series is a type of data that is often analyzed in the field of Signal Processing."</data>
      <data key="d6">70c3a879c0f6e6b76a13d02d67bce1a8</data>
    </edge>
    <edge source="&quot;TIME SERIES&quot;" target="&quot;PATTERN RECOGNITION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Time Series data may be used in the field of Pattern Recognition to discover patterns and relationships."</data>
      <data key="d6">70c3a879c0f6e6b76a13d02d67bce1a8</data>
    </edge>
    <edge source="&quot;TIME SERIES&quot;" target="&quot;ECONOMETRICS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Time Series data is used in the field of Econometrics to relate variables and assess their economic significance."</data>
      <data key="d6">70c3a879c0f6e6b76a13d02d67bce1a8</data>
    </edge>
    <edge source="&quot;TIME SERIES&quot;" target="&quot;MATHEMATICAL FINANCE&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Time Series data is used in Mathematical Finance to make predictions and assess risk."</data>
      <data key="d6">70c3a879c0f6e6b76a13d02d67bce1a8</data>
    </edge>
    <edge source="&quot;TIME SERIES&quot;" target="&quot;WEATHER FORECASTING&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Time Series data is used in Weather Forecasting to predict weather patterns."</data>
      <data key="d6">70c3a879c0f6e6b76a13d02d67bce1a8</data>
    </edge>
    <edge source="&quot;TIME SERIES&quot;" target="&quot;EARTHQUAKE PREDICTION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Time Series data is used in Earthquake Prediction to forecast the occurrence, location, and magnitude of earthquakes."</data>
      <data key="d6">70c3a879c0f6e6b76a13d02d67bce1a8</data>
    </edge>
    <edge source="&quot;TIME SERIES&quot;" target="&quot;REGRESSION ANALYSIS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Regression Analysis is often used to test relationships between different Time Series."</data>
      <data key="d6">70c3a879c0f6e6b76a13d02d67bce1a8</data>
    </edge>
    <edge source="&quot;TIME SERIES&quot;" target="&quot;ESN&quot;">
      <data key="d4">2.0</data>
      <data key="d5">"ESN is used for predicting and forecasting Time Series data."
"The ESN model is used for analyzing and making predictions about Time Series data."</data>
      <data key="d6">29aad23ce67e778ac31d4fb287fd20c7,76963fa19a9caab847e50167f71c86a2</data>
    </edge>
    <edge source="&quot;TIME SERIES&quot;" target="&quot;ESN MODEL&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The ESN Model is used to predict future values in a Time Series, as demonstrated in the provided text."</data>
      <data key="d6">973d44d321c7ceee7add295c60b085d2</data>
    </edge>
    <edge source="&quot;TIME SERIES ANALYSIS&quot;" target="&quot;MATHEMATICS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Mathematics provides the foundation for Time Series analysis, as it deals with the mathematical concepts and methods used in this field."</data>
      <data key="d6">8a015d76b241ce06eb72867bbb712edd</data>
    </edge>
    <edge source="&quot;TIME SERIES ANALYSIS&quot;" target="&quot;REGRESSION ANALYSIS&quot;">
      <data key="d4">2.0</data>
      <data key="d5">"Time Series Analysis and Regression Analysis are often used together to analyze and test relationships between different time series."
"Regression Analysis is not typically called Time Series Analysis, as Time Series Analysis specifically refers to relationships between different points in time within a single series."</data>
      <data key="d6">8e69dad9d25c6b8f037f22592687e195,dc76db79c20c315f30e0297619904b6f</data>
    </edge>
    <edge source="&quot;TIME SERIES ANALYSIS&quot;" target="&quot;CROSS-SECTIONAL STUDIES&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Time Series Analysis and Cross-Sectional Studies are distinct methods, with time series data having a natural temporal ordering."</data>
      <data key="d6">dc76db79c20c315f30e0297619904b6f</data>
    </edge>
    <edge source="&quot;TIME SERIES ANALYSIS&quot;" target="&quot;SPATIAL DATA ANALYSIS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Time Series Analysis and Spatial Data Analysis are different methods, with time series data focusing on temporal ordering and spatial data analysis focusing on geographical locations."</data>
      <data key="d6">dc76db79c20c315f30e0297619904b6f</data>
    </edge>
    <edge source="&quot;TIME SERIES ANALYSIS&quot;" target="&quot;STOCHASTIC MODELS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Stochastic Models are used in Time Series Analysis to reflect the fact that observations close together in time will be more closely related than observations further apart."</data>
      <data key="d6">dc76db79c20c315f30e0297619904b6f</data>
    </edge>
    <edge source="&quot;TIME SERIES ANALYSIS&quot;" target="&quot;TIME REVERSIBILITY&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Time Reversibility is a characteristic of time series models used in Time Series Analysis, expressing values for a given period as deriving from past values, rather than future values."</data>
      <data key="d6">dc76db79c20c315f30e0297619904b6f</data>
    </edge>
    <edge source="&quot;TIME SERIES ANALYSIS&quot;" target="&quot;STOCHASTIC MODEL&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Stochastic Model is often used in Time Series Analysis to account for uncertainty in the data."</data>
      <data key="d6">8e69dad9d25c6b8f037f22592687e195</data>
    </edge>
    <edge source="&quot;TIME SERIES ANALYSIS&quot;" target="&quot;TIME SERIES DATA&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Time Series Analysis is applied to Time Series Data, which have a natural temporal ordering."</data>
      <data key="d6">8e69dad9d25c6b8f037f22592687e195</data>
    </edge>
    <edge source="&quot;TIME SERIES ANALYSIS&quot;" target="&quot;FREQUENCY-DOMAIN METHODS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Time Series Analysis includes techniques such as Spectral Analysis and Wavelet Analysis, which are classified as Frequency-domain Methods."</data>
      <data key="d6">c7d17582a93a296eaaf9b9fca737ba51</data>
    </edge>
    <edge source="&quot;TIME SERIES ANALYSIS&quot;" target="&quot;TIME-DOMAIN METHODS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Time Series Analysis includes techniques such as Auto-correlation and Cross-correlation Analysis, which are classified as Time-domain Methods."</data>
      <data key="d6">c7d17582a93a296eaaf9b9fca737ba51</data>
    </edge>
    <edge source="&quot;TIME SERIES ANALYSIS&quot;" target="&quot;PARAMETRIC METHODS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Time Series Analysis includes approaches that assume the underlying structure of the stochastic process, such as Parametric Methods."</data>
      <data key="d6">c7d17582a93a296eaaf9b9fca737ba51</data>
    </edge>
    <edge source="&quot;TIME SERIES ANALYSIS&quot;" target="&quot;NON-PARAMETRIC METHODS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Time Series Analysis includes approaches that do not assume the underlying structure of the stochastic process, such as Non-parametric Methods."</data>
      <data key="d6">c7d17582a93a296eaaf9b9fca737ba51</data>
    </edge>
    <edge source="&quot;TIME SERIES ANALYSIS&quot;" target="&quot;TUBERCULOSIS&quot;">
      <data key="d4">2.0</data>
      <data key="d5">"Time Series Analysis is used to analyze tuberculosis incidence rates."
"Time Series Analysis is used to analyze data on Tuberculosis incidence."</data>
      <data key="d6">4b75a8a7637b05307e62f309c682d43b,a2b394d556da06b8c14dd2f5e106343b</data>
    </edge>
    <edge source="&quot;TIME SERIES ANALYSIS&quot;" target="&quot;STATISTICS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Statistics is a field where Time Series Analysis is commonly used."</data>
      <data key="d6">a2b394d556da06b8c14dd2f5e106343b</data>
    </edge>
    <edge source="&quot;TIME SERIES ANALYSIS&quot;" target="&quot;ECONOMETRICS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Econometrics is a field where Time Series Analysis is used for forecasting."</data>
      <data key="d6">a2b394d556da06b8c14dd2f5e106343b</data>
    </edge>
    <edge source="&quot;TIME SERIES ANALYSIS&quot;" target="&quot;QUANTITATIVE FINANCE&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Quantitative Finance is a field where Time Series Analysis is used for forecasting."</data>
      <data key="d6">a2b394d556da06b8c14dd2f5e106343b</data>
    </edge>
    <edge source="&quot;TIME SERIES ANALYSIS&quot;" target="&quot;CORPORATE DATA ANALYSTS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Corporate Data Analysts face challenges in using exploratory time series analysis techniques."</data>
      <data key="d6">4b75a8a7637b05307e62f309c682d43b</data>
    </edge>
    <edge source="&quot;REGRESSION ANALYSIS&quot;" target="&quot;CURVE FITTING&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Regression Analysis is a statistical technique used in Curve Fitting to infer relationships among two or more variables."</data>
      <data key="d6">630c86e110e2dabbe068f446b619cef3</data>
    </edge>
    <edge source="&quot;CROSS-SECTIONAL STUDIES&quot;" target="&quot;TEMPORAL ORDERING&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Temporal Ordering is a characteristic of time series data that distinguishes it from cross-sectional studies, which do not have a natural ordering of observations."</data>
      <data key="d6">dc76db79c20c315f30e0297619904b6f</data>
    </edge>
    <edge source="&quot;NUMPY&quot;" target="&quot;API&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"NumPy is an open-source organization that provides a library for working with arrays in Python, which can be accessed through an API."</data>
      <data key="d6">14bccd672d2f8dd2cd7300581c8844fb</data>
    </edge>
    <edge source="&quot;NUMPY&quot;" target="&quot;SCIPY&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"SciPy builds on NumPy and provides a large collection of algorithms and functions for scientific and technical computing."</data>
      <data key="d6">4246748fef7001ea0bd03ac702565b0d</data>
    </edge>
    <edge source="&quot;NUMPY&quot;" target="&quot;ESN&quot;">
      <data key="d4">4.0</data>
      <data key="d5">"Numpy is used to initialize parameters in ESN, such as bias vectors and other arrays or matrices."
"Numpy is used to create arrays and perform mathematical operations in the context of Echo State Networks."
"The ESN model uses Numpy for numerical computing, such as working with arrays and matrices."
"Numpy is mentioned in the context of ESNs for numerical computations."</data>
      <data key="d6">1cbfde86d1258f2b267135412e50a590,38b3e8ea0ec280360770513327b0d9d3,593080a95ef7640b3925b07cad1bedd4,cdc64af0dde941250d89b191d0666c9b</data>
    </edge>
    <edge source="&quot;NUMPY&quot;" target="&quot;RESERVOIRS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Numpy is used to store and manipulate parameters in reservoirs."</data>
      <data key="d6">ff860bc63e3d697a6183c0b850689048</data>
    </edge>
    <edge source="&quot;NUMPY&quot;" target="&quot;READOUTS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Numpy is used to store and manipulate parameters in readouts."</data>
      <data key="d6">ff860bc63e3d697a6183c0b850689048</data>
    </edge>
    <edge source="&quot;NUMPY&quot;" target="&quot;NORMAL DISTRIBUTION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Numpy provides a function to generate matrices from a Normal Distribution."</data>
      <data key="d6">d5e39e29b61f6ea0ffe0c868ba7a4252</data>
    </edge>
    <edge source="&quot;NUMPY&quot;" target="&quot;UNIFORM DISTRIBUTION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Numpy provides a function to generate matrices from a Uniform Distribution."</data>
      <data key="d6">d5e39e29b61f6ea0ffe0c868ba7a4252</data>
    </edge>
    <edge source="&quot;NUMPY&quot;" target="&quot;BERNOULLI DISTRIBUTION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Numpy is not explicitly mentioned in the context of generating matrices from a Bernoulli Distribution."</data>
      <data key="d6">d5e39e29b61f6ea0ffe0c868ba7a4252</data>
    </edge>
    <edge source="&quot;NUMPY&quot;" target="&quot;ESN MODEL&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Numpy is used for numerical computations in the ESN Model, such as array manipulations."</data>
      <data key="d6">8294eed5fc10df1c118f9afa266910e4</data>
    </edge>
    <edge source="&quot;NUMPY&quot;" target="&quot;SINE WAVE&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Numpy is used to generate a Sine Wave, which is used as input data in the provided text."</data>
      <data key="d6">71f966d00b6d0eceb580d00b9cb86b1e</data>
    </edge>
    <edge source="&quot;NUMPY&quot;" target="&quot;MACKEY-GLASS TIMESERIES&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Numpy is used for numerical computations on the Mackey-Glass Timeseries dataset in the provided code."</data>
      <data key="d6">4073cafddb73621f26061385c5570659</data>
    </edge>
    <edge source="&quot;API&quot;" target="&quot;VERBOSITY&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Verbosity is mentioned in the context of using an API, referring to the level of detail provided in the output."</data>
      <data key="d6">14bccd672d2f8dd2cd7300581c8844fb</data>
    </edge>
    <edge source="&quot;VERBOSITY&quot;" target="&quot;SOFTWARE APPLICATIONS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Verbosity refers to the level of detail provided in the output of Software Applications."</data>
      <data key="d6">f838f4cbb7060f4409ba2d174a396fb1</data>
    </edge>
    <edge source="&quot;SEED&quot;" target="&quot;SOFTWARE APPLICATIONS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"A seed is used to initialize a pseudorandom number generator in Software Applications, ensuring deterministic and repeatable results."</data>
      <data key="d6">f838f4cbb7060f4409ba2d174a396fb1</data>
    </edge>
    <edge source="&quot;SEED&quot;" target="&quot;REGULARIZATION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"REGULARIZATION and SEED are used in the context of experiments, and their interaction may influence the reproducibility of results."</data>
      <data key="d6">76f47f241e255f9f36646409d2ec30f1</data>
    </edge>
    <edge source="&quot;SEED&quot;" target="&quot;HP_SPACE&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"hp_space is used to explore the seed parameter."</data>
      <data key="d6">80033e741d8e10abdcfe20dd17192152</data>
    </edge>
    <edge source="&quot;SEED&quot;" target="&quot;HYPEROPT-MULTISCROLL&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"hyperopt-multiscroll is associated with the parameter seed, which ensures reproducibility."</data>
      <data key="d6">adfc38e9dc5e6fd0fe67ce83dfa1f154</data>
    </edge>
    <edge source="&quot;SEED&quot;" target="&quot;ESN&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Seed parameter is used to initialize the random number generator in the ESN model, ensuring reproducibility of results."</data>
      <data key="d6">72e6eee633bcb5b1458c4cee3975cee1</data>
    </edge>
    <edge source="&quot;SEED&quot;" target="&quot;HYPEROPT&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Seed is a parameter mentioned in the Hyperopt configuration."</data>
      <data key="d6">0982b8d1eb1e636b19fa2e9d9361e566</data>
    </edge>
    <edge source="&quot;SOFTWARE APPLICATIONS&quot;" target="&quot;APIS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Software Applications use APIs to communicate with each other, enabling integration and interaction."</data>
      <data key="d6">f838f4cbb7060f4409ba2d174a396fb1</data>
    </edge>
    <edge source="&quot;SCIPY&quot;" target="&quot;ESN&quot;">
      <data key="d4">3.0</data>
      <data key="d5">"Scipy is used to work with sparse matrices in ESN, allowing for efficient computation and memory usage."
"The ESN model uses Scipy for scientific computing, such as working with sparse matrices."
"Scipy is mentioned in the context of ESNs for working with sparse matrices."</data>
      <data key="d6">1cbfde86d1258f2b267135412e50a590,38b3e8ea0ec280360770513327b0d9d3,cdc64af0dde941250d89b191d0666c9b</data>
    </edge>
    <edge source="&quot;SCIPY&quot;" target="&quot;RESERVOIRS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Scipy is used to store and manipulate parameters in reservoirs."</data>
      <data key="d6">ff860bc63e3d697a6183c0b850689048</data>
    </edge>
    <edge source="&quot;SCIPY&quot;" target="&quot;READOUTS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Scipy is used to store and manipulate parameters in readouts."</data>
      <data key="d6">ff860bc63e3d697a6183c0b850689048</data>
    </edge>
    <edge source="&quot;SCIPY&quot;" target="&quot;BERNOULLI DISTRIBUTION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Scipy is not explicitly mentioned in the context of generating matrices from a Bernoulli Distribution."</data>
      <data key="d6">d5e39e29b61f6ea0ffe0c868ba7a4252</data>
    </edge>
    <edge source="&quot;BACKPROPAGATION OF ERROR&quot;" target="&quot;NEURAL NETWORK MODELS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Backpropagation of Error is a method used to train Neural Network Models."</data>
      <data key="d6">8fdd0220497c9b9d8c2ece14be6a8f25</data>
    </edge>
    <edge source="&quot;BACKPROPAGATION OF ERROR&quot;" target="&quot;GRADIENT DESCENT&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Gradient Descent is often used in conjunction with Backpropagation of Error to update the network parameters."</data>
      <data key="d6">8fdd0220497c9b9d8c2ece14be6a8f25</data>
    </edge>
    <edge source="&quot;BACKPROPAGATION OF ERROR&quot;" target="&quot;STOCHASTIC GRADIENT DESCENT&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Stochastic Gradient Descent is a variant of gradient descent that updates the parameters using random subsets of data, often used in conjunction with backpropagation."</data>
      <data key="d6">8fdd0220497c9b9d8c2ece14be6a8f25</data>
    </edge>
    <edge source="&quot;GRADIENT DESCENT&quot;" target="&quot;BACKPROPAGATION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Backpropagation is commonly used with Gradient Descent to update the network parameters."</data>
      <data key="d6">f60e4bd6b9e356b88d3a008130e8ac4b</data>
    </edge>
    <edge source="&quot;GRADIENT DESCENT&quot;" target="&quot;DEEP LEARNING&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Deep Learning has solved the problems faced by gradient descent-based training of RNNs, making them less unique compared to ESNs."</data>
      <data key="d6">eafe89ad19a57846f953a1dfcf8571f8</data>
    </edge>
    <edge source="&quot;GRADIENT DESCENT&quot;" target="&quot;RECURRENT NEURAL NETWORKS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Gradient Descent is used to minimize the error term in Recurrent Neural Networks."</data>
      <data key="d6">0bb54b1de8d2297293defe94addb8076</data>
    </edge>
    <edge source="&quot;GRADIENT DESCENT&quot;" target="&quot;RNN&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Gradient Descent is used for optimizing parameters in RNN models, facing challenges such as vanishing gradients."</data>
      <data key="d6">1aec5b03f663d1614b2ecbf97981a5c2</data>
    </edge>
    <edge source="&quot;GRADIENT DESCENT&quot;" target="&quot;BPTT&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"BPTT is used in the context of optimizing parameters in RNN models, where it faces challenges with vanishing gradients."</data>
      <data key="d6">1aec5b03f663d1614b2ecbf97981a5c2</data>
    </edge>
    <edge source="&quot;GRADIENT DESCENT&quot;" target="&quot;RTRL&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"RTRL is used in the context of optimizing parameters in RNN models, where it faces challenges with vanishing gradients."</data>
      <data key="d6">1aec5b03f663d1614b2ecbf97981a5c2</data>
    </edge>
    <edge source="&quot;GRADIENT DESCENT&quot;" target="&quot;LSTM&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"LSTM is used in the context of optimizing parameters in RNN models, addressing the vanishing gradients problem."</data>
      <data key="d6">1aec5b03f663d1614b2ecbf97981a5c2</data>
    </edge>
    <edge source="&quot;GRADIENT DESCENT&quot;" target="&quot;INDRNN&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"IndRNN is used in the context of optimizing parameters in RNN models, allowing for the exploration of cross-neuron information."</data>
      <data key="d6">1aec5b03f663d1614b2ecbf97981a5c2</data>
    </edge>
    <edge source="&quot;STOCHASTIC GRADIENT DESCENT&quot;" target="&quot;BACKPROPAGATION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Backpropagation can also be used with Stochastic Gradient Descent, which updates the parameters using random subsets of data."</data>
      <data key="d6">f60e4bd6b9e356b88d3a008130e8ac4b</data>
    </edge>
    <edge source="&quot;LINEAR REGRESSION&quot;" target="&quot;LEAST SQUARES METHOD&quot;">
      <data key="d4">2.0</data>
      <data key="d5">"Linear Regression often uses the Least Squares Method to find the best-fit line for a set of paired data."
"Linear Regression uses the Least Squares Method to find the best-fit line that minimizes the sum of the squares of the differences between the observed values and the values predicted by the line."</data>
      <data key="d6">573ef2ebe6a637a429cdc073a8508ca4,f60e4bd6b9e356b88d3a008130e8ac4b</data>
    </edge>
    <edge source="&quot;LINEAR REGRESSION&quot;" target="&quot;ORGANIZATIONS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Linear Regression helps organizations transform large amounts of raw data into actionable information, uncovering patterns and relationships."</data>
      <data key="d6">573ef2ebe6a637a429cdc073a8508ca4</data>
    </edge>
    <edge source="&quot;LINEAR REGRESSION&quot;" target="&quot;IBM&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"IBM is referenced as a source of detailed information about Linear Regression, providing insights into its application and benefits."</data>
      <data key="d6">573ef2ebe6a637a429cdc073a8508ca4</data>
    </edge>
    <edge source="&quot;LINEAR REGRESSION&quot;" target="&quot;SIMPLE LINEAR REGRESSION CALCULATORS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Simple Linear Regression Calculators are tools that use Linear Regression and the Least Squares Method to find the best-fit line for a set of paired data."</data>
      <data key="d6">573ef2ebe6a637a429cdc073a8508ca4</data>
    </edge>
    <edge source="&quot;LINEAR REGRESSION&quot;" target="&quot;DATA ASSUMPTIONS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Before using Linear Regression, it's important to ensure that the data meets certain assumptions, such as linearity, independence, and normal distribution of errors."</data>
      <data key="d6">573ef2ebe6a637a429cdc073a8508ca4</data>
    </edge>
    <edge source="&quot;LINEAR REGRESSION&quot;" target="&quot;LASSO REGRESSION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"LASSO Regression builds on the advantages of Linear Regression, addressing its shortcomings such as instability of the estimate and unreliability of the forecast in a high-dimensional context."</data>
      <data key="d6">861c28cb739722ddeb0babb7e1427409</data>
    </edge>
    <edge source="&quot;LINEAR REGRESSION&quot;" target="&quot;ESN&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Linear Regression is used for training connections in the Echo State Network."</data>
      <data key="d6">f730c6800099724052a2d061f3cd8c2e</data>
    </edge>
    <edge source="&quot;LINEAR REGRESSION&quot;" target="&quot;DESIRED OUTPUT WEIGHTS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Desired Output Weights are computed using linear regression, which involves finding the relationship between two variables."</data>
      <data key="d6">6a4432cd530b28770e2b903fe242a0d1</data>
    </edge>
    <edge source="&quot;LINEAR REGRESSION&quot;" target="&quot;RIDGE READOUT&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Linear Regression is used by the Ridge Readout to solve a task."</data>
      <data key="d6">5d3baa9818a4e01fe1196c43378a2cea</data>
    </edge>
    <edge source="&quot;IBM&quot;" target="&quot;RIDGE REGRESSION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"IBM provides information about Ridge Regression, including detailed explanations and resources."</data>
      <data key="d6">b5b73413fbe4ab8b61c4a939fe6c6a2b</data>
    </edge>
    <edge source="&quot;IBM&quot;" target="&quot;OVERFITTING&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"IBM provides information about overfitting on their website, which is relevant to the discussion of the Ridge Parameter."</data>
      <data key="d6">173a2da2c7ea80f95b04db8422ced004</data>
    </edge>
    <edge source="&quot;INDEPENDENT VARIABLE&quot;" target="&quot;DEPENDENT VARIABLE&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Linear Regression helps predict a dependent variable based on the independent variable."</data>
      <data key="d6">573ef2ebe6a637a429cdc073a8508ca4</data>
    </edge>
    <edge source="&quot;RIDGE REGRESSION&quot;" target="&quot;MULTICOLLINEARITY&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Ridge Regression is used to address multicollinearity in data, which can lead to unreliable coefficients in traditional linear regression."</data>
      <data key="d6">b5b73413fbe4ab8b61c4a939fe6c6a2b</data>
    </edge>
    <edge source="&quot;RIDGE REGRESSION&quot;" target="&quot;OVERFITTING&quot;">
      <data key="d4">2.0</data>
      <data key="d5">"Ridge Regression is a technique used to prevent overfitting in machine learning models."
"Ridge Regression is used to mitigate overfitting by penalizing large weights, which helps improve the model's generalization and robustness to noise."</data>
      <data key="d6">77c3759b4ed32509aaf1403c6fa8030f,87757855658e1d198ec49a3290760dd5</data>
    </edge>
    <edge source="&quot;RIDGE REGRESSION&quot;" target="&quot;RIDGE READOUT&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"A Ridge Readout utilizes Ridge Regression to learn the connections from the reservoir to the readout neurons, which helps avoid overfitting and improve the model's generalization."</data>
      <data key="d6">87757855658e1d198ec49a3290760dd5</data>
    </edge>
    <edge source="&quot;RIDGE REGRESSION&quot;" target="&quot;ESN&quot;">
      <data key="d4">3.0</data>
      <data key="d5">"Ridge Regression is mentioned as a regularization technique used during the offline training of Echo State Networks."
"Ridge regression is a method used for offline training of an Echo State Network (ESN)."
"ESN can be trained offline using ridge regression, which helps to prevent overfitting by adding a penalty term to the loss function."</data>
      <data key="d6">1db191f05801d40d5a346febd10d3352,593080a95ef7640b3925b07cad1bedd4,fe90abb0dde126fafbf44782aeb6738c</data>
    </edge>
    <edge source="&quot;RIDGE REGRESSION&quot;" target="&quot;ESN OFFLINE TRAINING WITH RIDGE REGRESSION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Ridge Regression is used during the training of ESN for offline tasks."</data>
      <data key="d6">18e4624a6da9e8e6d9b9b2ed260bf9b2</data>
    </edge>
    <edge source="&quot;RIDGE REGRESSION&quot;" target="&quot;RESERVOIR COMPUTING MODEL&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Ridge Regression is used in the provided text as a method for estimating coefficients in a Reservoir Computing Model."</data>
      <data key="d6">71f966d00b6d0eceb580d00b9cb86b1e</data>
    </edge>
    <edge source="&quot;RIDGE REGRESSION&quot;" target="&quot;ECHO STATE NETWORK&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Echo State Network uses Ridge Regression as a regularization technique in its readout layer."</data>
      <data key="d6">688ebc7151bc148ac24dc7e2727d7afe</data>
    </edge>
    <edge source="&quot;OVERFITTING&quot;" target="&quot;RIDGE READOUT&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Overfitting is a problem that Ridge Readout helps mitigate by using a regularization term to prevent the model from fitting the noise in the training data."</data>
      <data key="d6">b09c66bc81fd63720bef0cfa941ee65b</data>
    </edge>
    <edge source="&quot;OVERFITTING&quot;" target="&quot;RIDGE PARAMETER&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Ridge Parameter is used to prevent overfitting, which occurs when a model learns the training data too well and performs poorly on new data."</data>
      <data key="d6">173a2da2c7ea80f95b04db8422ced004</data>
    </edge>
    <edge source="&quot;FEEDBACK CONNECTIONS&quot;" target="&quot;FORCED FEEDBACK&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Forced Feedback and Feedback Connections are two different techniques used in network training. Forced Feedback involves using teacher vectors as feedback, while Feedback Connections are structural links allowing recurrent information flow within the network."</data>
      <data key="d6">3ecffab3c205dece73b47f9a7004fc89</data>
    </edge>
    <edge source="&quot;FEEDBACK CONNECTIONS&quot;" target="&quot;ESN&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Feedback connections are connections from the readout to the input in ESNs, which can be used for generating signals or long term forecasting."</data>
      <data key="d6">ead6383a44acd8ebd17907b85a910455</data>
    </edge>
    <edge source="&quot;FEEDBACK CONNECTIONS&quot;" target="&quot;GENERATION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Feedback connections can be used for generating signals."</data>
      <data key="d6">ead6383a44acd8ebd17907b85a910455</data>
    </edge>
    <edge source="&quot;FEEDBACK CONNECTIONS&quot;" target="&quot;LONG TERM FORECASTING&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Feedback connections can be used for long term forecasting."</data>
      <data key="d6">ead6383a44acd8ebd17907b85a910455</data>
    </edge>
    <edge source="&quot;FEEDBACK CONNECTIONS&quot;" target="&quot;ESN_MODEL&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The ESN model supports feedback connections between nodes, allowing for dynamic data processing."</data>
      <data key="d6">cf15a09e77b695a117e1cca05461aea2</data>
    </edge>
    <edge source="&quot;READOUT LAYER&quot;" target="&quot;RIDGE NODE&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Readout Layer in Echo State Networks is created using a Ridge Node, which is a form of regularized linear regression that helps prevent overfitting and ensures the model generalizes well to new data."</data>
      <data key="d6">0e6f0f7cd882a638ecb571ef36068868</data>
    </edge>
    <edge source="&quot;READOUT LAYER&quot;" target="&quot;INPUT DATA&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Input Data is directly fed to the Readout Layer, bypassing the Reservoir, allowing the model to utilize raw input features."</data>
      <data key="d6">4da651284dbab3f68dc3cae41e6e0311</data>
    </edge>
    <edge source="&quot;READOUT LAYER&quot;" target="&quot;SPECIAL CONCAT NODE&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Special Concat Node combines inputs from different sources and feeds the combined vector to the Readout Layer, enhancing its ability to process complex data."</data>
      <data key="d6">a35f6cae32a3d24b18ee17ec0471a9d4</data>
    </edge>
    <edge source="&quot;RIDGE NODE&quot;" target="&quot;ESN&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Ridge nodes are used in the ESN and are capable of performing regularized linear regression on the reservoir&#8217;s activations."</data>
      <data key="d6">9b360c6a33aafa6827417de5bd4faa82</data>
    </edge>
    <edge source="&quot;ECHO STATE NETWORK (ESN)&quot;" target="&quot;TIME CONSTANT&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Changing the Time Constant in an Echo State Network (ESN) affects how quickly the neurons in the reservoir update their states in response to inputs."</data>
      <data key="d6">77c3759b4ed32509aaf1403c6fa8030f</data>
    </edge>
    <edge source="&quot;ECHO STATE NETWORK (ESN)&quot;" target="&quot;LEAKING RATE&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Leaking Rate parameter in an Echo State Network (ESN) controls the rate at which neurons forget previous states."</data>
      <data key="d6">77c3759b4ed32509aaf1403c6fa8030f</data>
    </edge>
    <edge source="&quot;ECHO STATE NETWORK (ESN)&quot;" target="&quot;SPECTRAL RADIUS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Spectral Radius of the reservoir matrix in an Echo State Network (ESN) determines the stability and memory capacity of the reservoir."</data>
      <data key="d6">77c3759b4ed32509aaf1403c6fa8030f</data>
    </edge>
    <edge source="&quot;ECHO STATE NETWORK (ESN)&quot;" target="&quot;CHAINING&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Chaining is used to sequentially connect nodes in an Echo State Network (ESN), allowing the flow of data through each node and enabling the network to process the input data step-by-step."</data>
      <data key="d6">b641b2be224e677674f7d3523e87ccde</data>
    </edge>
    <edge source="&quot;ECHO STATE NETWORK (ESN)&quot;" target="&quot;FEEDBACK CONNECTION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Echo State Network (ESN) utilizes feedback connections to incorporate past activations into current processing, enhancing its dynamic capabilities and memory abilities."</data>
      <data key="d6">57a27a1504a5ef7d330172c0ac1085c9</data>
    </edge>
    <edge source="&quot;ECHO STATE NETWORK (ESN)&quot;" target="&quot;TEACHER VECTORS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Teacher Vectors are used as feedback during the training phase of an Echo State Network to help the network learn more effectively."</data>
      <data key="d6">3ecffab3c205dece73b47f9a7004fc89</data>
    </edge>
    <edge source="&quot;ECHO STATE NETWORK (ESN)&quot;" target="&quot;RECENTLY&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Echo State Network (ESN) is mentioned in the context of recent optimizations for increased network stability and relevance to real-world applications."</data>
      <data key="d6">a8c0edd2cdddb7d6d899284063b541f5</data>
    </edge>
    <edge source="&quot;ECHO STATE NETWORK (ESN)&quot;" target="&quot;TRAINING DATA&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Echo State Network (ESN) model is trained using Training Data."</data>
      <data key="d6">1365a36c76afc697ac626fd0f784804a</data>
    </edge>
    <edge source="&quot;ECHO STATE NETWORK (ESN)&quot;" target="&quot;TESTING DATA&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Echo State Network (ESN) model is evaluated using Testing Data."</data>
      <data key="d6">1365a36c76afc697ac626fd0f784804a</data>
    </edge>
    <edge source="&quot;ECHO STATE NETWORK (ESN)&quot;" target="&quot;GAUSSIAN PROCESS MODEL&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Echo State Network (ESN) is used to obtain a Gaussian Process Model with an ESN-driven kernel function."</data>
      <data key="d6">a4b801e70cf2ba3a3101d34899450087</data>
    </edge>
    <edge source="&quot;ECHO STATE NETWORK (ESN)&quot;" target="&quot;AURESERVOIR&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"aureservoir is an implementation of the Echo State Network (ESN)."</data>
      <data key="d6">a4b801e70cf2ba3a3101d34899450087</data>
    </edge>
    <edge source="&quot;ECHO STATE NETWORK (ESN)&quot;" target="&quot;MATLAB CODE&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Matlab code is an implementation of the Echo State Network (ESN)."</data>
      <data key="d6">a4b801e70cf2ba3a3101d34899450087</data>
    </edge>
    <edge source="&quot;ECHO STATE NETWORK (ESN)&quot;" target="&quot;RESERVOIRCOMPUTING.JL&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"ReservoirComputing.jl is an implementation of the Echo State Network (ESN)."</data>
      <data key="d6">a4b801e70cf2ba3a3101d34899450087</data>
    </edge>
    <edge source="&quot;ECHO STATE NETWORK (ESN)&quot;" target="&quot;PYESN&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"pyESN is an implementation of the Echo State Network (ESN)."</data>
      <data key="d6">a4b801e70cf2ba3a3101d34899450087</data>
    </edge>
    <edge source="&quot;LEAKING RATE&quot;" target="&quot;SPECTRAL RADIUS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Spectral Radius and Leaking Rate are parameters mentioned in the text, which are log-uniformly distributed within specified ranges."</data>
      <data key="d6">0a9b132ecb1c4b63fdbb0e144295362e</data>
    </edge>
    <edge source="&quot;LEAKING RATE&quot;" target="&quot;HYPEROPT&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Hyperopt is exploring the Leaking Rate parameter."</data>
      <data key="d6">65ba78d1f678e080bd930319c54234ef</data>
    </edge>
    <edge source="&quot;SPECTRAL RADIUS&quot;" target="&quot;RESERVOIR MATRIX&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Spectral Radius is a property of the Reservoir Matrix in an Echo State Network (ESN)."</data>
      <data key="d6">01f8dd8235ba0d4cf0837b5ea958ec95</data>
    </edge>
    <edge source="&quot;SPECTRAL RADIUS&quot;" target="&quot;RESERVOIR DYNAMICS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The behavior of the reservoir neurons, or Reservoir Dynamics, can be influenced by the Spectral Radius."</data>
      <data key="d6">01f8dd8235ba0d4cf0837b5ea958ec95</data>
    </edge>
    <edge source="&quot;SPECTRAL RADIUS&quot;" target="&quot;HYPER-PARAMETER EXPLORATION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Spectral Radius is a hyper-parameter in Reservoir Computing that can be explored during the hyper-parameter exploration process to optimize the stability and dynamics of the reservoir layer."</data>
      <data key="d6">716940af834825642e01a3cb59a7e006</data>
    </edge>
    <edge source="&quot;SPECTRAL RADIUS&quot;" target="&quot;STABLE DYNAMICS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"A spectral radius close to 1 is associated with stable dynamics, indicating predictable and consistent reservoir behavior."</data>
      <data key="d6">1f30b86a46d4819603edc730df816c49</data>
    </edge>
    <edge source="&quot;SPECTRAL RADIUS&quot;" target="&quot;CHAOTIC DYNAMICS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"A spectral radius further from 1 is associated with chaotic dynamics, indicating unpredictable and sensitive reservoir behavior."</data>
      <data key="d6">1f30b86a46d4819603edc730df816c49</data>
    </edge>
    <edge source="&quot;SPECTRAL RADIUS&quot;" target="&quot;ECHO STATE PROPERTY&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Echo State Property is theoretically associated with a spectral radius close to 1, allowing the reservoir states to be less affected by their initial conditions."</data>
      <data key="d6">1f30b86a46d4819603edc730df816c49</data>
    </edge>
    <edge source="&quot;SPECTRAL RADIUS&quot;" target="&quot;ADDITIVE-SIGMOID NEURON RESERVOIRS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Spectral Radius is mentioned in the context of Additive-Sigmoid Neuron Reservoirs and their relationship with the Echo State Property."</data>
      <data key="d6">a9f53979e9dbe6b936ff3374c73006dd</data>
    </edge>
    <edge source="&quot;SPECTRAL RADIUS&quot;" target="&quot;ESP&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The ESP is erroneously identified with a Spectral Radius below 1, but the relationship is more complex and depends on input amplitude.")</data>
      <data key="d6">3b592e5ac113a5c031925f91a182baa6</data>
    </edge>
    <edge source="&quot;SPECTRAL RADIUS&quot;" target="&quot;CUSTOM INITIALIZER FUNCTIONS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Spectral Radius is a property that can be adjusted when creating initializer functions for weight matrices."</data>
      <data key="d6">ff860bc63e3d697a6183c0b850689048</data>
    </edge>
    <edge source="&quot;SPECTRAL RADIUS&quot;" target="&quot;HYPEROPT&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Hyperopt is exploring the Spectral Radius parameter."</data>
      <data key="d6">65ba78d1f678e080bd930319c54234ef</data>
    </edge>
    <edge source="&quot;ECHO STATE NETWORKS (ESNS)&quot;" target="&quot;CANONICAL METHOD&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Canonical Method is a common approach used for creating and training Echo State Networks."</data>
      <data key="d6">fa7c410cf411eb68eb517e23427ec1c8</data>
    </edge>
    <edge source="&quot;ECHO STATE NETWORKS (ESNS)&quot;" target="&quot;NON-CANONICAL METHOD&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Non-Canonical Method is an alternative approach used for creating and training Echo State Networks."</data>
      <data key="d6">fa7c410cf411eb68eb517e23427ec1c8</data>
    </edge>
    <edge source="&quot;ECHO STATE NETWORKS (ESNS)&quot;" target="&quot;FORECASTING&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Echo State Networks are used for time series prediction and analysis, which includes the process of forecasting future data points."</data>
      <data key="d6">fa7c410cf411eb68eb517e23427ec1c8</data>
    </edge>
    <edge source="&quot;ECHO STATE NETWORKS (ESNS)&quot;" target="&quot;WARMUP PARAMETER&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Warmup Parameter is used in the training process of Echo State Networks to discard initial transient states."</data>
      <data key="d6">fa7c410cf411eb68eb517e23427ec1c8</data>
    </edge>
    <edge source="&quot;ECHO STATE NETWORKS (ESNS)&quot;" target="&quot;FORCED FEEDBACK&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Echo State Networks (ESNs) use Forced Feedback as a technique to improve training efficiency."</data>
      <data key="d6">0d922ae20673124fc4588949e3863ed0</data>
    </edge>
    <edge source="&quot;ECHO STATE NETWORKS (ESNS)&quot;" target="&quot;TEACHER FORCING&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Teacher Forcing is also used in training Echo State Networks (ESNs) to help the model learn the mapping between inputs and targets."</data>
      <data key="d6">d0a69d653d08e58959dd8d0f2033e697</data>
    </edge>
    <edge source="&quot;ECHO STATE NETWORKS (ESNS)&quot;" target="&quot;GENERATION&quot;">
      <data key="d4">2.0</data>
      <data key="d5">"Echo State Networks (ESNs) are used for generating timeseries data by predicting the next data point and using this prediction as input."
"ESNs are used for generating future values of a timeseries based on past data."</data>
      <data key="d6">0c3779349544e78c4d650ccf76623127,4b78fdc153f982e64291112395c316c7</data>
    </edge>
    <edge source="&quot;ECHO STATE NETWORKS (ESNS)&quot;" target="&quot;LONG-TERM FORECASTING&quot;">
      <data key="d4">2.0</data>
      <data key="d5">"Echo State Networks (ESNs) are also used for long-term forecasting, predicting future values of a timeseries over an extended period."
"ESNs are used for long-term forecasting, predicting many steps ahead in a timeseries."</data>
      <data key="d6">0c3779349544e78c4d650ccf76623127,4b78fdc153f982e64291112395c316c7</data>
    </edge>
    <edge source="&quot;ECHO STATE NETWORKS (ESNS)&quot;" target="&quot;SHIFT_FB=TRUE&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The shift_fb=True parameter is used in Echo State Networks (ESNs) to ensure the correct temporal alignment between input and feedback timeseries."</data>
      <data key="d6">0c3779349544e78c4d650ccf76623127</data>
    </edge>
    <edge source="&quot;ECHO STATE NETWORKS (ESNS)&quot;" target="&quot;WITH_FEEDBACK() CONTEXT MANAGER&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The with_feedback() context manager is used in Echo State Networks (ESNs) to temporarily change the feedback received by the reservoir for experimentation or manipulation."</data>
      <data key="d6">0c3779349544e78c4d650ccf76623127</data>
    </edge>
    <edge source="&quot;ECHO STATE NETWORKS (ESNS)&quot;" target="&quot;TRAINING DATA&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"ESNs are trained using historical data, allowing them to learn patterns and dynamics."</data>
      <data key="d6">4b78fdc153f982e64291112395c316c7</data>
    </edge>
    <edge source="&quot;ECHO STATE NETWORKS (ESNS)&quot;" target="&quot;ROBOT FALLING&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Echo State Networks (ESNs) are used to demonstrate a use case involving the Robot Falling event."</data>
      <data key="d6">af2db1cc5ab6b16acae2c93d3facb668</data>
    </edge>
    <edge source="&quot;RESERVOIR DYNAMICS&quot;" target="&quot;CHAOTICITY&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Chaoticity is a measure of the complexity and unpredictability in the Reservoir Dynamics, which can be altered by changing the Spectral Radius."</data>
      <data key="d6">01f8dd8235ba0d4cf0837b5ea958ec95</data>
    </edge>
    <edge source="&quot;NP.PI&quot;" target="&quot;NP.LINSPACE&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"np.pi is used as an endpoint in the np.linspace function to generate evenly spaced numbers over the interval [0, 6*np.pi]."</data>
      <data key="d6">475ca77684df5045266ddf079f2e37f1</data>
    </edge>
    <edge source="&quot;NP.SIN&quot;" target="&quot;NP.LINSPACE&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"np.sin is applied to the output of np.linspace to compute the sine of all elements in the array."</data>
      <data key="d6">475ca77684df5045266ddf079f2e37f1</data>
    </edge>
    <edge source="&quot;NP.SIN&quot;" target="&quot;NP.RESHAPE&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"np.reshape is used to reshape the output of np.sin into a column vector with 100 rows and 1 column."</data>
      <data key="d6">475ca77684df5045266ddf079f2e37f1</data>
    </edge>
    <edge source="&quot;NP.LINSPACE&quot;" target="&quot;SINGLE TIMESTEP OF DATA&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The concept of a single timestep of data is mentioned in the context of np.linspace, suggesting that it may be relevant to the usage of np.linspace in time series analysis."</data>
      <data key="d6">475ca77684df5045266ddf079f2e37f1</data>
    </edge>
    <edge source="&quot;TIMESTEP&quot;" target="&quot;TIMESERIES&quot;">
      <data key="d4">2.0</data>
      <data key="d5">"A Timestep is a single point in time within a Timeseries, while a Timeseries is a collection of multiple Timesteps."
"Timesteps are individual data points that collectively form a Timeseries, capturing the evolution of data over time."</data>
      <data key="d6">c41b9b19460dc63e06639ea4bbbd1515,fa082948fa919150e9c06c6f5c1b53b0</data>
    </edge>
    <edge source="&quot;TIMESTEP&quot;" target="&quot;WARMUP PARAMETER&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Warmup Parameter is used to discard initial Timesteps, allowing the Reservoir's internal state to stabilize and accurately reflect the input data."</data>
      <data key="d6">fa082948fa919150e9c06c6f5c1b53b0</data>
    </edge>
    <edge source="&quot;TIMESTEP&quot;" target="&quot;TRAINING DATA&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Timestep is a single point in time used to iterate through Training Data."</data>
      <data key="d6">af2db1cc5ab6b16acae2c93d3facb668</data>
    </edge>
    <edge source="&quot;INPUT DATA&quot;" target="&quot;ESN&quot;">
      <data key="d4">2.0</data>
      <data key="d5">"The ESN uses the Input Data to learn and capture the temporal dynamics of the timeseries."
"The ESN model is trained on input data, in this case, a sine wave."</data>
      <data key="d6">693e4d1e43289f46866236c10207a17e,7b294b788fe5ee385d08c4aabe2ca71d</data>
    </edge>
    <edge source="&quot;INPUT DATA&quot;" target="&quot;INPUT SCALING&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Input Scaling parameter is used to control the magnitude of the input data in the Echo State Network (ESN) model."</data>
      <data key="d6">1365a36c76afc697ac626fd0f784804a</data>
    </edge>
    <edge source="&quot;INPUT DATA&quot;" target="&quot;INPUT CONNECTIVITY&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Input Connectivity parameter is used to control the connection between the input data and the reservoir in the Echo State Network (ESN) model."</data>
      <data key="d6">1365a36c76afc697ac626fd0f784804a</data>
    </edge>
    <edge source="&quot;NULL&quot;" target="&quot;PROGRAMMING&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Null is a special value used to represent the absence of a value or an empty value in programming languages."</data>
      <data key="d6">56cde5dc9d350498c1544cd57733ca8f</data>
    </edge>
    <edge source="&quot;NP.EMPTY&quot;" target="&quot;STATES&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"np.empty is used to create the 'states' array, which is then filled with data representing the activations of neurons in a reservoir computing system."</data>
      <data key="d6">53e61c078c8f43b7a9b0efb347f394a6</data>
    </edge>
    <edge source="&quot;RESERVOIR.OUTPUT_DIM&quot;" target="&quot;STATES&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"reservoir.output_dim specifies the number of output dimensions of the reservoir, defining the second dimension of the 'states' array."</data>
      <data key="d6">53e61c078c8f43b7a9b0efb347f394a6</data>
    </edge>
    <edge source="&quot;STATES&quot;" target="&quot;STATES[:, :20]&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"states[:, :20] is a slice notation used to access and visualize the activations of the first 20 neurons across all timesteps in the timeseries."</data>
      <data key="d6">53e61c078c8f43b7a9b0efb347f394a6</data>
    </edge>
    <edge source="&quot;STATES&quot;" target="&quot;FEATURES&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Features are used as input for machine learning models, while states are variables that store the internal state of a system or model, representing the current condition or configuration of the system."</data>
      <data key="d6">53e61c078c8f43b7a9b0efb347f394a6</data>
    </edge>
    <edge source="&quot;FOR-LOOP&quot;" target="&quot;FEATURES&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"A for-loop can be used to iterate over features in a dataset, such as processing each pixel in an image."</data>
      <data key="d6">54b1174770e13d4a2bc0916db477cc56</data>
    </edge>
    <edge source="&quot;FEATURES&quot;" target="&quot;SUPERVISED LEARNING&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Supervised Learning models use labeled data and features to learn patterns and make predictions."</data>
      <data key="d6">e72d27e122bf954a854a23a367c9c609</data>
    </edge>
    <edge source="&quot;FEATURES&quot;" target="&quot;UNSUPERVISED LEARNING&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Unsupervised Learning models use features to find patterns and group data without the need for labeled data."</data>
      <data key="d6">e72d27e122bf954a854a23a367c9c609</data>
    </edge>
    <edge source="&quot;FEATURES&quot;" target="&quot;IMAGE CLASSIFICATION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Image Classification models use visual features of images, such as pixels, to categorize images into different classes."</data>
      <data key="d6">e72d27e122bf954a854a23a367c9c609</data>
    </edge>
    <edge source="&quot;FEATURES&quot;" target="&quot;MACHINE TRANSLATION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Machine Translation models use linguistic features of sentences or words to translate text from one language to another."</data>
      <data key="d6">e72d27e122bf954a854a23a367c9c609</data>
    </edge>
    <edge source="&quot;FEATURES&quot;" target="&quot;REINFORCEMENT LEARNING&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Reinforcement Learning models use features of states to make decisions and optimize rewards in an environment."</data>
      <data key="d6">e72d27e122bf954a854a23a367c9c609</data>
    </edge>
    <edge source="&quot;MODEL&quot;" target="&quot;TRAINING TASK&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Model learns through the Training Task, which specifies the objective and guides its parameter adjustment."</data>
      <data key="d6">c41b9b19460dc63e06639ea4bbbd1515</data>
    </edge>
    <edge source="&quot;MODEL&quot;" target="&quot;READOUT NODE&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Readout Node is a component of the Model that is trained as a standalone node to perform a specific task."</data>
      <data key="d6">c41b9b19460dc63e06639ea4bbbd1515</data>
    </edge>
    <edge source="&quot;MODEL&quot;" target="&quot;ESN&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"ESN is not designed to be integrated into a Model because it is optimized for standalone use and does not conform to the standard node interface required for Model integration."</data>
      <data key="d6">df811c27ddc46d5b90c5863a52666a4b</data>
    </edge>
    <edge source="&quot;MODEL&quot;" target="&quot;X_TRAIN&quot;">
      <data key="d4">3.0</data>
      <data key="d5">"The machine learning model is trained using the x_train dataset."
"The X_train dataset is used to train the Model, allowing it to learn patterns and make accurate predictions."
"X_train is used for training the Model."</data>
      <data key="d6">3ff318aebcb07ca141d0a40730d96c7c,75e530c1a04e30b373dc7cc68e3ad819,a0feae89e52a4291db0a512a3a102d8e</data>
    </edge>
    <edge source="&quot;MODEL&quot;" target="&quot;LOSS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The loss metric is calculated based on the performance of the machine learning model."</data>
      <data key="d6">75e530c1a04e30b373dc7cc68e3ad819</data>
    </edge>
    <edge source="&quot;MODEL&quot;" target="&quot;R2&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The R-squared (R2) metric is calculated based on the performance of the machine learning model."</data>
      <data key="d6">75e530c1a04e30b373dc7cc68e3ad819</data>
    </edge>
    <edge source="&quot;MODEL&quot;" target="&quot;NODE&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Nodes are connected together inside directed acyclic graphs to form a Model, which allows for complex operations to be represented."</data>
      <data key="d6">dc46bcef51e88747b544f7efb111203a</data>
    </edge>
    <edge source="&quot;MODEL&quot;" target="&quot;FEEDBACK CONNECTION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Some nodes in a Model may be connected through Feedback Connections, which delay the signal, allowing for more complex operations to be represented."</data>
      <data key="d6">dc46bcef51e88747b544f7efb111203a</data>
    </edge>
    <edge source="&quot;MODEL&quot;" target="&quot;X&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The X dataset is used to make predictions using the trained Model, allowing it to generate output based on new input data."</data>
      <data key="d6">3ff318aebcb07ca141d0a40730d96c7c</data>
    </edge>
    <edge source="&quot;MODEL&quot;" target="&quot;TIME SERIES PREDICTION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Model is used for Time Series Prediction, aiming to predict future values based on past data."</data>
      <data key="d6">46dcc47b4358d3895c1eeb1182c6f997</data>
    </edge>
    <edge source="&quot;MODEL&quot;" target="&quot;LASSO&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Model uses Lasso, a type of Linear Model, as the readout function to predict the target variable."</data>
      <data key="d6">eebc9d7d2b66e3898b7d068c38fd200f</data>
    </edge>
    <edge source="&quot;MODEL&quot;" target="&quot;MACKEY-GLASS TIME SERIES&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Model is evaluated using Mackey-Glass Time Series data, which is a chaotic time series used for time series analysis."</data>
      <data key="d6">eebc9d7d2b66e3898b7d068c38fd200f</data>
    </edge>
    <edge source="&quot;SUPERVISED LEARNING&quot;" target="&quot;UNSUPERVISED LEARNING&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Supervised Learning and Unsupervised Learning are two different approaches in machine learning, with Supervised Learning using labeled data and Unsupervised Learning focusing on finding patterns in unlabeled data."</data>
      <data key="d6">58330f62da357197950f63388e4ceaff</data>
    </edge>
    <edge source="&quot;SUPERVISED LEARNING&quot;" target="&quot;ESN METHODS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"ESN methods are mentioned in the context of Supervised Learning."</data>
      <data key="d6">dbca0570761b1698d32f0c0bfb593b1a</data>
    </edge>
    <edge source="&quot;UNSUPERVISED LEARNING&quot;" target="&quot;NEURAL HISTORY COMPRESSOR&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Neural History Compressor is an unsupervised learning model that learns patterns from unlabeled data."</data>
      <data key="d6">7b6ff30ef255db2d2c68326d78cf0115</data>
    </edge>
    <edge source="&quot;ARTIFICIAL NEURAL NETWORK&quot;" target="&quot;RIDGE READOUT&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Artificial Neural Networks can use Ridge Readout as an offline readout, which needs to be fitted with data before use."</data>
      <data key="d6">7e6b5dcab1703bfec57161a4d5543848</data>
    </edge>
    <edge source="&quot;ARTIFICIAL NEURAL NETWORK&quot;" target="&quot;ONLINE READOUTS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Artificial Neural Networks can also use Online Readouts, which can update their weights continuously as new data arrives."</data>
      <data key="d6">7e6b5dcab1703bfec57161a4d5543848</data>
    </edge>
    <edge source="&quot;ARTIFICIAL NEURAL NETWORK&quot;" target="&quot;WIKIPEDIA PAGE ON NEURAL NETWORKS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Wikipedia page on Neural Networks provides additional information about Artificial Neural Networks and their components."</data>
      <data key="d6">7e6b5dcab1703bfec57161a4d5543848</data>
    </edge>
    <edge source="&quot;RESERVOIR NODE&quot;" target="&quot;DATA&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Data is processed by the Reservoir Node in the Echo State Network (ESN) model."</data>
      <data key="d6">32f8cfb6373e6cb4d6daa32e52aa74fc</data>
    </edge>
    <edge source="&quot;RESERVOIR NODE&quot;" target="&quot;READOUT NODE&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The output of the Reservoir Node is used as input to the Readout Node in the Echo State Network (ESN) model."</data>
      <data key="d6">32f8cfb6373e6cb4d6daa32e52aa74fc</data>
    </edge>
    <edge source="&quot;RESERVOIR NODE&quot;" target="&quot;FEEDBACK CONNECTION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Feedback Connection allows the state of one Reservoir Node to influence another Reservoir Node with a one-timestep delay in the Echo State Network (ESN) model."</data>
      <data key="d6">32f8cfb6373e6cb4d6daa32e52aa74fc</data>
    </edge>
    <edge source="&quot;RIDGE READOUT&quot;" target="&quot;RIDGE PARAMETER&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Ridge Parameter is a hyperparameter used in Ridge Readout to control the strength of the regularization term, with a value of 1e-7 used to prevent overfitting."</data>
      <data key="d6">b09c66bc81fd63720bef0cfa941ee65b</data>
    </edge>
    <edge source="&quot;RIDGE READOUT&quot;" target="&quot;RIDGE REGULARIZATION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Ridge Regularization is used in the Ridge Readout to avoid overfitting during training."</data>
      <data key="d6">5d3baa9818a4e01fe1196c43378a2cea</data>
    </edge>
    <edge source="&quot;RIDGE READOUT&quot;" target="&quot;TRAINING TASK&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Ridge Readout is trained to solve a specific Training Task, where it creates a mapping from input to target timeseries."</data>
      <data key="d6">5d3baa9818a4e01fe1196c43378a2cea</data>
    </edge>
    <edge source="&quot;RIDGE READOUT&quot;" target="&quot;SINE WAVE&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Ridge Readout is trained to predict the next value in the Sine Wave sequence."</data>
      <data key="d6">f2d5625f36aa4cb036089ce89ec607eb</data>
    </edge>
    <edge source="&quot;TEACHER VECTORS&quot;" target="&quot;TRAINING TASK&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Teacher Vectors are the target outputs used during the training of a machine learning model, which is a part of defining a Training Task."</data>
      <data key="d6">173a2da2c7ea80f95b04db8422ced004</data>
    </edge>
    <edge source="&quot;TEACHER VECTORS&quot;" target="&quot;FORCED FEEDBACK&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Teacher Vectors are used as feedback in the Forced Feedback technique for Echo State Networks (ESNs)."</data>
      <data key="d6">0d922ae20673124fc4588949e3863ed0</data>
    </edge>
    <edge source="&quot;TRAINING TASK&quot;" target="&quot;X&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"X is used as input data for the Training Task, which involves training the ESN model."</data>
      <data key="d6">09ea760dd2f000c961d1cfd4ea795da5</data>
    </edge>
    <edge source="&quot;TRAINING TASK&quot;" target="&quot;Y&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Y is used as target data for the Training Task, which involves training the ESN model."</data>
      <data key="d6">09ea760dd2f000c961d1cfd4ea795da5</data>
    </edge>
    <edge source="&quot;TIMESERIES&quot;" target="&quot;ESN&quot;">
      <data key="d4">3.0</data>
      <data key="d5">"The ESN is being trained to make one-step-ahead forecasts of a Timeseries data set."
"The Echo State Network is trained on a Timeseries to make one-step-ahead forecasts."
"Timeseries data is used as input for an Echo State Network (ESN) for prediction and generation tasks."</data>
      <data key="d6">7f70879016c133fe58e4838172a69613,f730c6800099724052a2d061f3cd8c2e,f7f7dbc1e69b3b0e801bc5ba9c0cabca</data>
    </edge>
    <edge source="&quot;TIMESERIES&quot;" target="&quot;MACKEY-GLASS EQUATION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Mackey-Glass Equation generates a Timeseries, which is used to visualize its behavior."</data>
      <data key="d6">518f1e492b92054cf2f5c5289444da02</data>
    </edge>
    <edge source="&quot;TIMESERIES&quot;" target="&quot;TUTORIAL&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Timeseries data is used in the tutorial to demonstrate how to train and perform predictions with an Echo State Network (ESN) created using ReservoirPy."</data>
      <data key="d6">74c073137c970e32982756d008532cb8</data>
    </edge>
    <edge source="&quot;TIMESERIES&quot;" target="&quot;GENERATIVE MODE&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Generative Mode is used to generate Timeseries data for comparison."</data>
      <data key="d6">70db98fabc82fc96ecf8cc2c023b586b</data>
    </edge>
    <edge source="&quot;READOUT NODE&quot;" target="&quot;CONCATENATE NODE&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Concatenate Node combines multiple inputs and passes the result to the Readout Node in the Echo State Network (ESN) model."</data>
      <data key="d6">32f8cfb6373e6cb4d6daa32e52aa74fc</data>
    </edge>
    <edge source="&quot;FORECASTING&quot;" target="&quot;TIME SERIES DATA&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Forecasting is used to predict future values in Time Series Data, such as predicting the next values of a sine wave."</data>
      <data key="d6">cc12e22afbf2ef530100516df59d24f2</data>
    </edge>
    <edge source="&quot;FORECASTING&quot;" target="&quot;MANUAL MANAGEMENT&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Manual Management may not leverage the seamless data flow and integrated training provided by the canonical method, potentially leading to less efficient training and suboptimal performance in forecasting."</data>
      <data key="d6">cc12e22afbf2ef530100516df59d24f2</data>
    </edge>
    <edge source="&quot;FORECASTING&quot;" target="&quot;NP.ARANGE() FUNCTION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"np.arange() function generates an array of values used for forecasting future time steps."</data>
      <data key="d6">4ac00cf37a752d89d55a749c01c6f6fd</data>
    </edge>
    <edge source="&quot;FORECASTING&quot;" target="&quot;DOUBLE-SCROLL ATTRACTOR&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Double-Scroll Attractor is used as a complex system of differential equations in the example, and the goal is to forecast its future values 10 steps ahead."</data>
      <data key="d6">2d8ea1123f365fb047b024022ba4fdc4</data>
    </edge>
    <edge source="&quot;FORECASTING&quot;" target="&quot;ONLINE TIME SERIES APPROXIMATION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Online Time Series Approximation is a problem that can contribute to the process of forecasting by providing an approximate representation of data that supports time series queries."</data>
      <data key="d6">9261efcc24379d9c0b2d35a2fde8275d</data>
    </edge>
    <edge source="&quot;FORECASTING&quot;" target="&quot;STATISTICS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Statistics provides a means of transferring knowledge about a sample to other related populations, which is not necessarily the same as forecasting over time."</data>
      <data key="d6">423d3b5ec1acc9a4cb448a15d3b6b595</data>
    </edge>
    <edge source="&quot;FORECASTING&quot;" target="&quot;MACKEY-GLASS TIME SERIES&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Mackey-Glass Time Series dataset is used for forecasting, as demonstrated in the provided code using the ReservoirPy library to convert it into a forecasting format."</data>
      <data key="d6">b2beacacc8c190393e4583a69518378c</data>
    </edge>
    <edge source="&quot;MATRIX&quot;" target="&quot;WEIGHT&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Weights are individual numerical values in a Matrix that define the strength of connections between nodes in a neural network."</data>
      <data key="d6">cc12e22afbf2ef530100516df59d24f2</data>
    </edge>
    <edge source="&quot;PARALLELIZATION&quot;" target="&quot;NEURAL NETWORK&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Parallelization is used to improve performance and efficiency in training neural networks by dividing the task into smaller sub-tasks that can be executed simultaneously on multiple processors or cores."</data>
      <data key="d6">cc12e22afbf2ef530100516df59d24f2</data>
    </edge>
    <edge source="&quot;PARALLELIZATION&quot;" target="&quot;ESN&quot;">
      <data key="d4">2.0</data>
      <data key="d5">"ESN training can be parallelized to speed up computation and reduce overall training time."
"Parallelization is mentioned in the context of training and running Echo State Networks to speed up computation and improve efficiency."</data>
      <data key="d6">1cbfde86d1258f2b267135412e50a590,593080a95ef7640b3925b07cad1bedd4</data>
    </edge>
    <edge source="&quot;PARALLELIZATION&quot;" target="&quot;MULTIPROCESSING&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Multiprocessing is a method of parallel computation that is mentioned in the context of parallelization."</data>
      <data key="d6">593080a95ef7640b3925b07cad1bedd4</data>
    </edge>
    <edge source="&quot;NEURAL NETWORK&quot;" target="&quot;DEEP ARCHITECTURE&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Deep Architecture refers to a neural network with multiple hidden layers, allowing it to learn and represent more complex patterns and features in the data."</data>
      <data key="d6">a16039f06e545c915f8e7668c39c3e5c</data>
    </edge>
    <edge source="&quot;NEURAL NETWORK&quot;" target="&quot;MACHINE LEARNING&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Machine Learning is a field that focuses on developing neural networks and other statistical models to enable computers to learn patterns and make predictions based on data."</data>
      <data key="d6">a16039f06e545c915f8e7668c39c3e5c</data>
    </edge>
    <edge source="&quot;NEURAL NETWORK&quot;" target="&quot;ESN&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"ESN is a type of neural network used for training, which is a machine learning model."</data>
      <data key="d6">894d59d781535ca85389c4226715c007</data>
    </edge>
    <edge source="&quot;TIME SERIES DATA&quot;" target="&quot;AUTOREGRESSIVE (AR) MODELS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Autoregressive (AR) Models are used to model variations in Time Series Data."</data>
      <data key="d6">a000a3fbf1f8fad62e4c25b495858c79</data>
    </edge>
    <edge source="&quot;TIME SERIES DATA&quot;" target="&quot;INTEGRATED (I) MODELS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Integrated (I) Models are used to model variations in the level of Time Series Data."</data>
      <data key="d6">a000a3fbf1f8fad62e4c25b495858c79</data>
    </edge>
    <edge source="&quot;TIME SERIES DATA&quot;" target="&quot;MOVING-AVERAGE (MA) MODELS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Moving-Average (MA) Models are used to model variations in Time Series Data."</data>
      <data key="d6">a000a3fbf1f8fad62e4c25b495858c79</data>
    </edge>
    <edge source="&quot;TIME SERIES DATA&quot;" target="&quot;SINE WAVE&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Sine Wave is an example of Time Series Data, a sequence of data points collected at regular time intervals."</data>
      <data key="d6">2bcc39da2ecef3011cc3da428fca5dd5</data>
    </edge>
    <edge source="&quot;DEEP ARCHITECTURES&quot;" target="&quot;ESN&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Deep Architectures involve combining nodes in various ways to create more complex structures than a simple reservoir and readout, as demonstrated in the ESN model."</data>
      <data key="d6">f0c8d4d322d73f46464e3e9f6914f2ee</data>
    </edge>
    <edge source="&quot;INPUT-TO-READOUT CONNECTIONS&quot;" target="&quot;ESN&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"More advanced ESNs may include direct connections from input to readout."</data>
      <data key="d6">ead6383a44acd8ebd17907b85a910455</data>
    </edge>
    <edge source="&quot;INPUT-TO-READOUT CONNECTIONS&quot;" target="&quot;RESERVOIR COMPUTING MODEL&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Input-to-readout Connections are a key feature of Reservoir Computing Models, as they enable the model to learn and make predictions based on input data."</data>
      <data key="d6">71f966d00b6d0eceb580d00b9cb86b1e</data>
    </edge>
    <edge source="&quot;INPUT NODES&quot;" target="&quot;RESERVOIR NODES&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Input Nodes pass their processed data to Reservoir Nodes, allowing the network to learn and capture patterns."</data>
      <data key="d6">b641b2be224e677674f7d3523e87ccde</data>
    </edge>
    <edge source="&quot;RESERVOIR NODES&quot;" target="&quot;READOUT NODES&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Reservoir Nodes pass their processed data to Readout Nodes, which produce the final output based on the input data."</data>
      <data key="d6">b641b2be224e677674f7d3523e87ccde</data>
    </edge>
    <edge source="&quot;RESERVOIR NODES&quot;" target="&quot;ONE-TO-MANY CONNECTIONS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"One-to-many connections allow the same data to be processed in different ways by different Reservoir Nodes, enhancing the network's ability to capture and learn patterns."</data>
      <data key="d6">b641b2be224e677674f7d3523e87ccde</data>
    </edge>
    <edge source="&quot;READOUT NODES&quot;" target="&quot;MANY-TO-ONE CONNECTIONS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Many-to-one connections allow multiple inputs to be aggregated and fed into a single Readout Node, enhancing the model's ability to process complex data."</data>
      <data key="d6">b641b2be224e677674f7d3523e87ccde</data>
    </edge>
    <edge source="&quot;ONE-TO-MANY CONNECTIONS&quot;" target="&quot;ITERABLES OF NODES&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Iterables of Nodes can be used to create One-to-Many Connections, enabling the same input data to be processed in different ways by different nodes."</data>
      <data key="d6">a35f6cae32a3d24b18ee17ec0471a9d4</data>
    </edge>
    <edge source="&quot;ESN MODEL&quot;" target="&quot;RUNNING&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The ESN Model is used to make predictions during the Running event on unseen data."</data>
      <data key="d6">8ade7819a5f8d1ec26e9bdbd059142e6</data>
    </edge>
    <edge source="&quot;ESN MODEL&quot;" target="&quot;AUTHOR&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The author demonstrates expertise in using the ESN Model to predict future values in a Time Series."</data>
      <data key="d6">973d44d321c7ceee7add295c60b085d2</data>
    </edge>
    <edge source="&quot;ESN MODEL&quot;" target="&quot;MATPLOTLIB&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Matplotlib is used to create visualizations of the ESN Model's output, such as the sine wave plot."</data>
      <data key="d6">8294eed5fc10df1c118f9afa266910e4</data>
    </edge>
    <edge source="&quot;ESN MODEL&quot;" target="&quot;JAEGER&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Jaeger is a developer of the Echo State Network (ESN) model, which is used in the ESN Model."</data>
      <data key="d6">52d001cd1786e3d9f36e0c57538bc21e</data>
    </edge>
    <edge source="&quot;ESN MODEL&quot;" target="&quot;HAAS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Haas is a developer of the Echo State Network (ESN) model, which is used in the ESN Model."</data>
      <data key="d6">52d001cd1786e3d9f36e0c57538bc21e</data>
    </edge>
    <edge source="&quot;DATA&quot;" target="&quot;CONCATENATE&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Multiple data inputs are concatenated by the concatenate node in the ESN model."</data>
      <data key="d6">cf15a09e77b695a117e1cca05461aea2</data>
    </edge>
    <edge source="&quot;DATA&quot;" target="&quot;AUTHOR&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The author uses data as input and output for the reservoir computing model."</data>
      <data key="d6">069ae9388dfd52fec9c184c7168f64dd</data>
    </edge>
    <edge source="&quot;FEEDBACK CONNECTION&quot;" target="&quot;CONTROL SYSTEMS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Feedback connections enable the network to use past control signals to adjust future control actions, which is beneficial for control systems tasks."</data>
      <data key="d6">57a27a1504a5ef7d330172c0ac1085c9</data>
    </edge>
    <edge source="&quot;CONTROL SYSTEMS&quot;" target="&quot;'&lt;&lt;' OPERATOR&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Control systems uses the '&lt;&lt;' operator to incorporate past control signals into current processing."</data>
      <data key="d6">c4b54c2da2dda7e660de7bd6de6f13b4</data>
    </edge>
    <edge source="&quot;'&gt;&gt;' OPERATOR&quot;" target="&quot;'&lt;&lt;' OPERATOR&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The '&gt;&gt;' operator is used to chain connections between nodes in sequence, while the '&lt;&lt;' operator creates a feedback connection with a one-timestep delay."</data>
      <data key="d6">c4b54c2da2dda7e660de7bd6de6f13b4</data>
    </edge>
    <edge source="&quot;'&lt;&lt;' OPERATOR&quot;" target="&quot;'&lt;&lt;=' OPERATOR&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Both the '&lt;&lt;' and '&lt;&lt;=' operators establish a feedback connection, but the '&lt;&lt;=' operator does so without creating a copy of the receiver node."</data>
      <data key="d6">c4b54c2da2dda7e660de7bd6de6f13b4</data>
    </edge>
    <edge source="&quot;FORCED FEEDBACK&quot;" target="&quot;MODEL.FIT()&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Model.fit() method allows for the specification of the forced feedback parameter, enabling the use of teacher vectors as feedback during training."</data>
      <data key="d6">3ecffab3c205dece73b47f9a7004fc89</data>
    </edge>
    <edge source="&quot;FORCED FEEDBACK&quot;" target="&quot;MACHINE LEARNING MODEL&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The machine learning model may use forced feedback to maintain functionality when direct feedback connections are not available."</data>
      <data key="d6">9f1e5883a5f969a6d913beed5a5abd4f</data>
    </edge>
    <edge source="&quot;FORCED FEEDBACK&quot;" target="&quot;SHIFT FEEDBACK&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Shift feedback is used to align past outputs with future inputs in the forced feedback timeseries."</data>
      <data key="d6">9f1e5883a5f969a6d913beed5a5abd4f</data>
    </edge>
    <edge source="&quot;MODEL.FIT()&quot;" target="&quot;X_TRAIN&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Model.fit() is used to train a model on the input data from X_train."</data>
      <data key="d6">b338d2dcc1fe6ccf42407444c02cad7c</data>
    </edge>
    <edge source="&quot;MODEL.FIT()&quot;" target="&quot;ESN&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"ESN is a type of model that can be trained using the Model.fit() method."</data>
      <data key="d6">b338d2dcc1fe6ccf42407444c02cad7c</data>
    </edge>
    <edge source="&quot;TEACHER FORCING&quot;" target="&quot;SEQUENCE MODELING&quot;">
      <data key="d4">2.0</data>
      <data key="d5">"Teacher Forcing is a training technique used in sequence modeling to provide the model with the correct input at each time step during training, allowing it to learn the sequence more accurately."
"Teacher Forcing is a technique used in Sequence Modeling to help the network learn the correct sequence of outputs."</data>
      <data key="d6">3ecffab3c205dece73b47f9a7004fc89,d0a69d653d08e58959dd8d0f2033e697</data>
    </edge>
    <edge source="&quot;TEACHER FORCING&quot;" target="&quot;CONVERGENCE&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Convergence is a result of the training process in Teacher Forcing, indicating that the model has effectively learned the mapping between inputs and targets."</data>
      <data key="d6">d0a69d653d08e58959dd8d0f2033e697</data>
    </edge>
    <edge source="&quot;CONVERGENCE&quot;" target="&quot;MACHINE LEARNING MODEL&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The machine learning model reaches convergence, indicating it has learned patterns in the training data."</data>
      <data key="d6">9f1e5883a5f969a6d913beed5a5abd4f</data>
    </edge>
    <edge source="&quot;MACHINE LEARNING MODEL&quot;" target="&quot;HYPERPARAMETER OPTIMIZATION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Hyperparameter Optimization is used to improve the performance of a Machine Learning Model by finding the best hyperparameters for the model."</data>
      <data key="d6">bd4cf5e35045463b7f0d8da82debc122</data>
    </edge>
    <edge source="&quot;TRAINING DATA&quot;" target="&quot;DATA PREPROCESSING&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Data Preprocessing is applied to the Training Data to clean and prepare it for use in the Echo State Network (ESN) model."</data>
      <data key="d6">1365a36c76afc697ac626fd0f784804a</data>
    </edge>
    <edge source="&quot;ESN&quot;" target="&quot;CUSTOM WEIGHT MATRIX&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"A Custom Weight Matrix is used in the ESN to adjust the input-reservoir connections, potentially improving the model's performance."</data>
      <data key="d6">693e4d1e43289f46866236c10207a17e</data>
    </edge>
    <edge source="&quot;ESN&quot;" target="&quot;ESN OFFLINE TRAINING WITH RIDGE REGRESSION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"ESN is trained using ridge regression for offline tasks."</data>
      <data key="d6">18e4624a6da9e8e6d9b9b2ed260bf9b2</data>
    </edge>
    <edge source="&quot;ESN&quot;" target="&quot;LINSPACE()&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"linspace() is used to generate input and target sequences for training and running the ESN."</data>
      <data key="d6">df811c27ddc46d5b90c5863a52666a4b</data>
    </edge>
    <edge source="&quot;ESN&quot;" target="&quot;CPU CORES&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The number of CPU cores used for parallel computation is managed by the 'workers' parameter in the ESN, which can help manage system resources and ensure that other processes or applications have enough computational power available."</data>
      <data key="d6">df811c27ddc46d5b90c5863a52666a4b</data>
    </edge>
    <edge source="&quot;ESN&quot;" target="&quot;PARALLEL COMPUTATION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"ESN is optimized for parallel computation, which is used to improve efficiency in training and running the network."</data>
      <data key="d6">df811c27ddc46d5b90c5863a52666a4b</data>
    </edge>
    <edge source="&quot;ESN&quot;" target="&quot;WORKERS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The 'workers' parameter specifies the number of parallel processes to use for training and running the ESN."</data>
      <data key="d6">3695f5d218cdda0a91ae6a2f9b296837</data>
    </edge>
    <edge source="&quot;ESN&quot;" target="&quot;BACKEND&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The 'backend' parameter specifies the method of execution for the ESN."</data>
      <data key="d6">3695f5d218cdda0a91ae6a2f9b296837</data>
    </edge>
    <edge source="&quot;ESN&quot;" target="&quot;COMPLEX MODELS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Complex Models are advanced versions of the ESN model that can handle more complex tasks."</data>
      <data key="d6">3695f5d218cdda0a91ae6a2f9b296837</data>
    </edge>
    <edge source="&quot;ESN&quot;" target="&quot;FORCE LEARNING&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"FORCE learning is a method used for online training of an Echo State Network (ESN)."</data>
      <data key="d6">1db191f05801d40d5a346febd10d3352</data>
    </edge>
    <edge source="&quot;ESN&quot;" target="&quot;BACKPROPAGATION-DECORRELATION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Backpropagation-decorrelation is a method used for training an Echo State Network (ESN) to minimize output error while preserving echo state properties."</data>
      <data key="d6">1db191f05801d40d5a346febd10d3352</data>
    </edge>
    <edge source="&quot;ESN&quot;" target="&quot;RESERVOIR ADAPTATION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Reservoir adaptation is a method used for training an Echo State Network (ESN) by modifying internal reservoir parameters based on performance metrics."</data>
      <data key="d6">1db191f05801d40d5a346febd10d3352</data>
    </edge>
    <edge source="&quot;ESN&quot;" target="&quot;RMSE&quot;">
      <data key="d4">3.0</data>
      <data key="d5">"RMSE is used to evaluate the performance of the Echo State Network."
"The Root Mean Squared Error (RMSE) loss function is used to evaluate the quality of parameters in the Echo State Network (ESN) model."
"Root Mean Squared Error is used to evaluate the performance of the Echo State Network."</data>
      <data key="d6">251a50c2ae8ceea4fd7da1127cc5f461,bf4eaad93f89884d02cdad6a50f145a6,f730c6800099724052a2d061f3cd8c2e</data>
    </edge>
    <edge source="&quot;ESN&quot;" target="&quot;R^2 SCORE&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"R^2 Score is used to evaluate the performance of the Echo State Network."</data>
      <data key="d6">f730c6800099724052a2d061f3cd8c2e</data>
    </edge>
    <edge source="&quot;ESN&quot;" target="&quot;TIMESERIES PREDICTION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Echo State Networks (ESNs) are a type of reservoir computing algorithm used for timeseries prediction."</data>
      <data key="d6">0b6c69085074b2cf23267eb149068b9f</data>
    </edge>
    <edge source="&quot;ESN&quot;" target="&quot;ICANN&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The guide on exploring hyper-parameters for Echo State Networks was published by ICANN, which refers to Echo State Networks."</data>
      <data key="d6">088d2280349d652200861994c09d7dd5</data>
    </edge>
    <edge source="&quot;ESN&quot;" target="&quot;STATE COLLECTION MATRIX&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"During the training stage, extended system states are filed row-wise into the State Collection Matrix."</data>
      <data key="d6">f18a060e6d2bb1da70432cbc71378770</data>
    </edge>
    <edge source="&quot;ESN&quot;" target="&quot;INPUT SEQUENCE&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The ESN is driven by an Input Sequence during the state harvesting stage of training."</data>
      <data key="d6">f18a060e6d2bb1da70432cbc71378770</data>
    </edge>
    <edge source="&quot;ESN&quot;" target="&quot;OUTPUT SEQUENCE&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The ESN generates an Output Sequence during the training stage, which may involve teacher forcing."</data>
      <data key="d6">f18a060e6d2bb1da70432cbc71378770</data>
    </edge>
    <edge source="&quot;ESN&quot;" target="&quot;SYSTEM EQUATIONS&quot;">
      <data key="d4">2.0</data>
      <data key="d5">"The ESN is described by the System Equations, which include the reservoir and input states, and the output activation function."
"System Equations are used in the ESN model to describe its behavior."</data>
      <data key="d6">6a4432cd530b28770e2b903fe242a0d1,f18a060e6d2bb1da70432cbc71378770</data>
    </edge>
    <edge source="&quot;ESN&quot;" target="&quot;OUTPUT FEEDBACK&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The ESN model may include output feedback, where correct outputs are written into the output units during the generation of system states."</data>
      <data key="d6">6a4432cd530b28770e2b903fe242a0d1</data>
    </edge>
    <edge source="&quot;ESN&quot;" target="&quot;DESIRED OUTPUTS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The ESN model aims to produce desired outputs, which are the target values it aims to achieve."</data>
      <data key="d6">6a4432cd530b28770e2b903fe242a0d1</data>
    </edge>
    <edge source="&quot;ESN&quot;" target="&quot;MANJUNATH AND JAEGER&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Manjunath and Jaeger are the authors of a study that discusses the properties of Echo State Networks, including memory capacity."</data>
      <data key="d6">d4563a00dc04ebf7bcf01e5062fde46f</data>
    </edge>
    <edge source="&quot;ESN&quot;" target="&quot;INPUT SIGNAL&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Echo State Network processes the Input Signal to produce an Output Signal, and its memory capacity is quantified based on the correlation between delayed input signals and trained output signals."</data>
      <data key="d6">d4563a00dc04ebf7bcf01e5062fde46f</data>
    </edge>
    <edge source="&quot;ESN&quot;" target="&quot;OUTPUT SIGNAL&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Echo State Network produces an Output Signal as a result of processing the Input Signal, and its memory capacity is evaluated by training the network to predict and memorize delayed input signals."</data>
      <data key="d6">d4563a00dc04ebf7bcf01e5062fde46f</data>
    </edge>
    <edge source="&quot;ESN&quot;" target="&quot;MEMORY CAPACITY&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Echo State Network's memory capacity is a measure of its ability to retain and recall information from past input signals, which is quantified in the text."</data>
      <data key="d6">d4563a00dc04ebf7bcf01e5062fde46f</data>
    </edge>
    <edge source="&quot;ESN&quot;" target="&quot;PYRCN&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"PyRCN is mentioned in the context of ELM, which is similar to ESN where recurrence has been removed."</data>
      <data key="d6">a1adb5de4156f0a4a448caf79056e886</data>
    </edge>
    <edge source="&quot;ESN&quot;" target="&quot;RESERVOIRCOMPUTING.JL&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"ReservoirComputing.jl is used to create an Echo State Network (ESN) for training and forecasting."</data>
      <data key="d6">d7ac2f6fb13af389417785f2f3152c52</data>
    </edge>
    <edge source="&quot;ESN&quot;" target="&quot;MACKEY-GLASS TIMESERIES&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Mackey-Glass timeseries is used for training and forecasting with an Echo State Network (ESN)."</data>
      <data key="d6">d7ac2f6fb13af389417785f2f3152c52</data>
    </edge>
    <edge source="&quot;ESN&quot;" target="&quot;X_TRAIN1&quot;">
      <data key="d4">2.0</data>
      <data key="d5">"ESN is trained using the X_train1 dataset."
"ESN is trained using a subset of the input data X_train1."</data>
      <data key="d6">09198e939639c229c2c97555f65b12a7,993a69efae014a8f8d6ec0c235104d46</data>
    </edge>
    <edge source="&quot;ESN&quot;" target="&quot;Y_TRAIN1&quot;">
      <data key="d4">2.0</data>
      <data key="d5">"ESN is trained using the y_train1 dataset as the target output."
"ESN is trained using a subset of the target data y_train1."</data>
      <data key="d6">09198e939639c229c2c97555f65b12a7,993a69efae014a8f8d6ec0c235104d46</data>
    </edge>
    <edge source="&quot;ESN&quot;" target="&quot;TEST&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"ESN is tested on new data to evaluate its performance."</data>
      <data key="d6">cc1fb6ca5695434ad0279c2606e928af</data>
    </edge>
    <edge source="&quot;ESN&quot;" target="&quot;TIME SERIES PREDICTION&quot;">
      <data key="d4">5.0</data>
      <data key="d5">"ESN is used for the task of Time Series Prediction, which involves forecasting future values based on past data."
"ESN is primarily used for Time Series Prediction, which involves forecasting future values based on past observations."
"ESN is used for the task of Time Series Prediction, which involves forecasting future values based on past observations."
"ESN is a type of recurrent neural network commonly used for time series prediction."
"ESN is used for the task of Time Series Prediction in the provided code."</data>
      <data key="d6">36e4df75a46fb977f9516f2d2f1f9bc2,7b9936d57ece8ba985947a7aca12e2c7,cc1fb6ca5695434ad0279c2606e928af,eb7a223eeb120e3fcc45a96a6018707d,f0c8d4d322d73f46464e3e9f6914f2ee</data>
    </edge>
    <edge source="&quot;ESN&quot;" target="&quot;AUTHOR&quot;">
      <data key="d4">3.0</data>
      <data key="d5">"The author uses the ESN model to perform time series prediction and forecasting."
"The author demonstrates expertise in using the ESN model for time series prediction and generative tasks."
"The author creates an ESN model using the ReservoirPy library."</data>
      <data key="d6">069ae9388dfd52fec9c184c7168f64dd,29aad23ce67e778ac31d4fb287fd20c7,76963fa19a9caab847e50167f71c86a2</data>
    </edge>
    <edge source="&quot;ESN&quot;" target="&quot;ONE-TIMESTEP-AHEAD FORECASTING TASK&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"ESN is trained on a one-timestep-ahead forecasting task to make predictions."</data>
      <data key="d6">0ae9f3cf96547c05eff54812cb72ac31</data>
    </edge>
    <edge source="&quot;ESN&quot;" target="&quot;CLOSED LOOP GENERATIVE MODE&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"ESN is run in closed loop generative mode to generate new data based on its own predictions."</data>
      <data key="d6">0ae9f3cf96547c05eff54812cb72ac31</data>
    </edge>
    <edge source="&quot;ESN&quot;" target="&quot;ONE-TIMESTEP-AHEAD FORECAST&quot;">
      <data key="d4">2.0</data>
      <data key="d5">"ESN is used to perform one-timestep-ahead forecasting on the input data."
"The ESN model is used to perform the task of One-timestep-ahead Forecast."</data>
      <data key="d6">29aad23ce67e778ac31d4fb287fd20c7,593306edfb8d4c7ef4b99d24fa009970</data>
    </edge>
    <edge source="&quot;ESN&quot;" target="&quot;GENERATIVE MODE&quot;">
      <data key="d4">3.0</data>
      <data key="d5">"ESN is used to generate new data points in the time series using the generative mode."
"ESN is used to generate new time series data in Generative Mode."
"The ESN model is also used to generate new data points in Generative Mode."</data>
      <data key="d6">29aad23ce67e778ac31d4fb287fd20c7,424bf7c7b82dc966139c25f7c9ccffb7,593306edfb8d4c7ef4b99d24fa009970</data>
    </edge>
    <edge source="&quot;ESN&quot;" target="&quot;NP&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"np is a library used in the code snippet to perform numerical computations for the ESN model."</data>
      <data key="d6">593306edfb8d4c7ef4b99d24fa009970</data>
    </edge>
    <edge source="&quot;ESN&quot;" target="&quot;PLT&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"plt is a library used in the code snippet to create visualizations for the ESN model."</data>
      <data key="d6">593306edfb8d4c7ef4b99d24fa009970</data>
    </edge>
    <edge source="&quot;ESN&quot;" target="&quot;X&quot;">
      <data key="d4">2.0</data>
      <data key="d5">"X is the input data used in the ESN model for time series prediction and generation."
"ESN takes input data X for training and prediction."</data>
      <data key="d6">09198e939639c229c2c97555f65b12a7,593306edfb8d4c7ef4b99d24fa009970</data>
    </edge>
    <edge source="&quot;ESN&quot;" target="&quot;X_T&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"X_t is the true values of the input data used in the ESN model for evaluation."</data>
      <data key="d6">593306edfb8d4c7ef4b99d24fa009970</data>
    </edge>
    <edge source="&quot;ESN&quot;" target="&quot;X_GEN&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"X_gen is the generated values of the input data produced by the ESN model."</data>
      <data key="d6">593306edfb8d4c7ef4b99d24fa009970</data>
    </edge>
    <edge source="&quot;ESN&quot;" target="&quot;FORCE ALGORITHM&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"ESN uses the FORCE Algorithm for online learning, allowing the update of readout parameters at every timestep of input series."</data>
      <data key="d6">424bf7c7b82dc966139c25f7c9ccffb7</data>
    </edge>
    <edge source="&quot;ESN&quot;" target="&quot;SPECIAL NODE E&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"ESN includes a special node E, which plays a significant role in the training process."</data>
      <data key="d6">894d59d781535ca85389c4226715c007</data>
    </edge>
    <edge source="&quot;ESN&quot;" target="&quot;X_TRAIN&quot;">
      <data key="d4">2.0</data>
      <data key="d5">"The Echo State Network (ESN) system is trained using the X_train input data."
"ESN is trained using a subset of the input data, X_train."</data>
      <data key="d6">72e6eee633bcb5b1458c4cee3975cee1,80c9f51870e239404ed671ef0374f191</data>
    </edge>
    <edge source="&quot;ESN&quot;" target="&quot;VOCAB&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The vocabulary (vocab) is used to map the predicted output of the Echo State Network (ESN) system to the corresponding target value."</data>
      <data key="d6">80c9f51870e239404ed671ef0374f191</data>
    </edge>
    <edge source="&quot;ESN&quot;" target="&quot;DIRECT CONNECTIONS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"More advanced ESNs may include direct connections from input to readout."</data>
      <data key="d6">ead6383a44acd8ebd17907b85a910455</data>
    </edge>
    <edge source="&quot;ESN&quot;" target="&quot;CUSTOM WEIGHT MATRICES&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Custom weight matrices can be used to create more complex ESNs."</data>
      <data key="d6">ead6383a44acd8ebd17907b85a910455</data>
    </edge>
    <edge source="&quot;ESN&quot;" target="&quot;'DEEP' ARCHITECTURES&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"'Deep' architectures can be created by stacking multiple ESNs together."</data>
      <data key="d6">ead6383a44acd8ebd17907b85a910455</data>
    </edge>
    <edge source="&quot;ESN&quot;" target="&quot;MODEL.RUN()&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"ESN is a type of model that can be used to make predictions using the Model.run() method."</data>
      <data key="d6">b338d2dcc1fe6ccf42407444c02cad7c</data>
    </edge>
    <edge source="&quot;ESN&quot;" target="&quot;TIMESTEPS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The ESN model is used to predict and generate timesteps in a time series."</data>
      <data key="d6">38b3e8ea0ec280360770513327b0d9d3</data>
    </edge>
    <edge source="&quot;ESN&quot;" target="&quot;READOUTS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The ESN model includes Readouts, which hold parameters and perform output calculations."</data>
      <data key="d6">38b3e8ea0ec280360770513327b0d9d3</data>
    </edge>
    <edge source="&quot;ESN&quot;" target="&quot;RESERVOIRS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The ESN model includes Reservoirs, which hold parameters and perform internal computations."</data>
      <data key="d6">38b3e8ea0ec280360770513327b0d9d3</data>
    </edge>
    <edge source="&quot;ESN&quot;" target="&quot;INITIALIZER FUNCTIONS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The ESN model uses Initializer Functions to initialize parameters in its components."</data>
      <data key="d6">38b3e8ea0ec280360770513327b0d9d3</data>
    </edge>
    <edge source="&quot;ESN&quot;" target="&quot;JOBLIB&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Joblib can be used to parallelize the computation of node states over independent sequences of inputs in ESN training/running, exploiting multiprocessing."</data>
      <data key="d6">fe90abb0dde126fafbf44782aeb6738c</data>
    </edge>
    <edge source="&quot;ESN&quot;" target="&quot;SEQUENCES OF INPUTS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"ESN is used for processing Sequences of Inputs."</data>
      <data key="d6">3bee7b78d0ab9582cc9bffe9e305df2e</data>
    </edge>
    <edge source="&quot;ESN&quot;" target="&quot;SEQUENCES OF TARGETS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"ESN is used for processing Sequences of Targets, which correspond to the Inputs."</data>
      <data key="d6">3bee7b78d0ab9582cc9bffe9e305df2e</data>
    </edge>
    <edge source="&quot;ESN&quot;" target="&quot;STANDARD RESERVOIR&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Standard Reservoir is used as a base for creating ESN."</data>
      <data key="d6">3bee7b78d0ab9582cc9bffe9e305df2e</data>
    </edge>
    <edge source="&quot;ESN&quot;" target="&quot;SEQUENTIAL BACKEND&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"ESN uses the Sequential Backend for processing data in a sequential manner."</data>
      <data key="d6">f0c8d4d322d73f46464e3e9f6914f2ee</data>
    </edge>
    <edge source="&quot;ESN&quot;" target="&quot;MULTIPROCESSING BACKEND&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"ESN uses the Multiprocessing Backend for processing data in parallel using multiple cores."</data>
      <data key="d6">f0c8d4d322d73f46464e3e9f6914f2ee</data>
    </edge>
    <edge source="&quot;ESN&quot;" target="&quot;PREDICTIONS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The ESN model makes predictions, which attempt to forecast the next value in a timeseries."</data>
      <data key="d6">7b294b788fe5ee385d08c4aabe2ca71d</data>
    </edge>
    <edge source="&quot;ESN&quot;" target="&quot;Y&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"ESN predicts target data y based on the input data."</data>
      <data key="d6">09198e939639c229c2c97555f65b12a7</data>
    </edge>
    <edge source="&quot;ESN&quot;" target="&quot;CHAPTER 2&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"ESN (Echo State Network) is mentioned in Chapter 2 as a type of recurrent neural network used in the context of the generative mode."</data>
      <data key="d6">e396354e3a9be76616392af11f56e671</data>
    </edge>
    <edge source="&quot;ESN&quot;" target="&quot;X_TRAIN3&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"X_train3 is used for training the esn model."</data>
      <data key="d6">0c5a253fb2bcebe8674581a5dc12fd96</data>
    </edge>
    <edge source="&quot;ESN&quot;" target="&quot;Y_TRAIN3&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"y_train3 is used for training the esn model."</data>
      <data key="d6">0c5a253fb2bcebe8674581a5dc12fd96</data>
    </edge>
    <edge source="&quot;ESN&quot;" target="&quot;X_TEST3&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"X_test3 is used for testing the esn model."</data>
      <data key="d6">0c5a253fb2bcebe8674581a5dc12fd96</data>
    </edge>
    <edge source="&quot;ESN&quot;" target="&quot;Y_TEST3&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"y_test3 is used for testing the esn model."</data>
      <data key="d6">0c5a253fb2bcebe8674581a5dc12fd96</data>
    </edge>
    <edge source="&quot;ESN&quot;" target="&quot;CHAPTER 3&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The esn model is discussed in Chapter 3."</data>
      <data key="d6">0c5a253fb2bcebe8674581a5dc12fd96</data>
    </edge>
    <edge source="&quot;ESN&quot;" target="&quot;LBR.FEATURE.DELTA&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"ESN uses the lbr.feature.delta function for feature extraction."</data>
      <data key="d6">71366a4c7e791080872ba783d3787bd7</data>
    </edge>
    <edge source="&quot;ESN&quot;" target="&quot;INPUTS SCALING&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The ESN model scales the input data using the Inputs Scaling parameter."</data>
      <data key="d6">72e6eee633bcb5b1458c4cee3975cee1</data>
    </edge>
    <edge source="&quot;ESN&quot;" target="&quot;INPUT CONNECTIVITY&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Input Connectivity parameter determines the density of connections between input nodes and reservoir nodes in the ESN model."</data>
      <data key="d6">72e6eee633bcb5b1458c4cee3975cee1</data>
    </edge>
    <edge source="&quot;ESN&quot;" target="&quot;REGULARIZATION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The ESN model uses Regularization to prevent overfitting and improve generalization."</data>
      <data key="d6">72e6eee633bcb5b1458c4cee3975cee1</data>
    </edge>
    <edge source="&quot;ESN&quot;" target="&quot;MACKEY-GLASS EQUATION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The ESN is used for analyzing and predicting time series data generated by the Mackey-Glass Equation."</data>
      <data key="d6">1db5e6cd356c6066227de5e273de1abe</data>
    </edge>
    <edge source="&quot;NP.RANDOM.NORMAL&quot;" target="&quot;NP.RANDOM.UNIFORM&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Both np.random.normal and np.random.uniform are functions used to generate random numbers, but they use different statistical distributions."</data>
      <data key="d6">4a8a4a7eeebd68a535cf84cfaecebaba</data>
    </edge>
    <edge source="&quot;NP.RANDOM.NORMAL&quot;" target="&quot;KWARGS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"kwargs allows additional keyword arguments to be passed to the np.random.normal function, providing flexibility in its usage."</data>
      <data key="d6">4a8a4a7eeebd68a535cf84cfaecebaba</data>
    </edge>
    <edge source="&quot;RESERVOIRPY.MAT_GEN&quot;" target="&quot;RANDOM_SPARSE&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The reservoirpy.mat_gen submodule provides the random_sparse function for initializing sparse matrices."</data>
      <data key="d6">8f2f2cfd667a304a288723de779c9bee</data>
    </edge>
    <edge source="&quot;RESERVOIRPY.MAT_GEN.RANDOM_SPARSE&quot;" target="&quot;RESERVOIR.W.RAVEL()&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"reservoirpy.mat_gen.random_sparse initializes a weight matrix W, which is then flattened using reservoir.W.ravel()."</data>
      <data key="d6">4a8a4a7eeebd68a535cf84cfaecebaba</data>
    </edge>
    <edge source="&quot;PLT.HIST&quot;" target="&quot;RESERVOIR.W.RAVEL()&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"plt.hist creates a histogram of data, and reservoir.W.ravel() is used to flatten a matrix W into a one-dimensional array for this purpose."</data>
      <data key="d6">4a8a4a7eeebd68a535cf84cfaecebaba</data>
    </edge>
    <edge source="&quot;RANDOM_SPARSE&quot;" target="&quot;UNIFORM DISTRIBUTION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The random_sparse function can use a uniform distribution to generate non-zero elements of the matrix."</data>
      <data key="d6">8f2f2cfd667a304a288723de779c9bee</data>
    </edge>
    <edge source="&quot;UNIFORM DISTRIBUTION&quot;" target="&quot;MATRIX CREATION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"A uniform distribution is used to generate non-zero elements of a matrix during its creation, ensuring values are evenly spread within a specified range."</data>
      <data key="d6">8559ec6650745de27a3f41815fbfde09</data>
    </edge>
    <edge source="&quot;DELAYED MATRIX CREATION&quot;" target="&quot;MATRIX CREATION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Delayed matrix creation differs from matrix creation in that it initializes the parameters only when needed, such as at the first run."</data>
      <data key="d6">8559ec6650745de27a3f41815fbfde09</data>
    </edge>
    <edge source="&quot;GAUSSIAN DISTRIBUTION&quot;" target="&quot;BERNOULLI RANDOM VARIABLE&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"A Gaussian distribution and a Bernoulli random variable are both probability distributions, but they have different characteristics and applications."</data>
      <data key="d6">8559ec6650745de27a3f41815fbfde09</data>
    </edge>
    <edge source="&quot;BERNOULLI RANDOM VARIABLE&quot;" target="&quot;NORMAL DISTRIBUTION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Normal Distribution is not directly mentioned in relation to Bernoulli Random Variable."</data>
      <data key="d6">1cbfde86d1258f2b267135412e50a590</data>
    </edge>
    <edge source="&quot;MULTIPROCESSING&quot;" target="&quot;COMPUTING NODE STATES OVER INDEPENDENT SEQUENCES OF INPUTS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Multiprocessing is used to compute node states over independent sequences of inputs, allowing for parallel processing."</data>
      <data key="d6">18e4624a6da9e8e6d9b9b2ed260bf9b2</data>
    </edge>
    <edge source="&quot;JOBLIB&quot;" target="&quot;COMPUTING NODE STATES OVER INDEPENDENT SEQUENCES OF INPUTS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Joblib is mentioned as a tool that can be used for parallelizing the computation of node states over independent sequences of inputs."</data>
      <data key="d6">18e4624a6da9e8e6d9b9b2ed260bf9b2</data>
    </edge>
    <edge source="&quot;JOBLIB&quot;" target="&quot;COMPUTING NODE STATES&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Joblib is mentioned in the context of computing node states over independent sequences of inputs, indicating its potential use in this process."</data>
      <data key="d6">085c9d7a2af51b93826fc393600682d8</data>
    </edge>
    <edge source="&quot;JOBLIB&quot;" target="&quot;DELAYED()&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Joblib provides the delayed() function, which is used to create a lazy evaluation of the function it wraps."</data>
      <data key="d6">f3b5b178557c4991ab5b81d869a4752e</data>
    </edge>
    <edge source="&quot;JOBLIB&quot;" target="&quot;PARALLEL&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Joblib provides the parallel function, which is used to run tasks concurrently, allowing for faster data loading and processing."</data>
      <data key="d6">f3b5b178557c4991ab5b81d869a4752e</data>
    </edge>
    <edge source="&quot;JOBLIB&quot;" target="&quot;DATA SCIENTIST&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Data Scientist uses the joblib library to enable parallel and efficient computing."</data>
      <data key="d6">9fdaabd6c7e893a275a3848c10007477</data>
    </edge>
    <edge source="&quot;SEQUENCES&quot;" target="&quot;DIFFERENT LENGTHS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Sequences are mentioned as having the potential for different lengths, which is a challenge that is acknowledged and addressed with suggested techniques."</data>
      <data key="d6">085c9d7a2af51b93826fc393600682d8</data>
    </edge>
    <edge source="&quot;SEQUENCES&quot;" target="&quot;DIMENSIONALITY REDUCTION TECHNIQUES&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Dimensionality Reduction Techniques are used to process sequences with varying dimensions to a common size."</data>
      <data key="d6">6f3d0ba82cf3b10b19b64f73ace8c695</data>
    </edge>
    <edge source="&quot;SEQUENCES&quot;" target="&quot;FEATURE ENGINEERING&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Feature Engineering is used to match the required dimensionality of sequences."</data>
      <data key="d6">6f3d0ba82cf3b10b19b64f73ace8c695</data>
    </edge>
    <edge source="&quot;SEQUENCES&quot;" target="&quot;INTERPOLATION OR EXTRAPOLATION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Interpolation or Extrapolation is used to adjust the length of sequences to a common size."</data>
      <data key="d6">6f3d0ba82cf3b10b19b64f73ace8c695</data>
    </edge>
    <edge source="&quot;SEQUENCES&quot;" target="&quot;TRANSFORMATION TECHNIQUES&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Transformation Techniques are used to transform input sequences to a uniform dimensionality before processing."</data>
      <data key="d6">6f3d0ba82cf3b10b19b64f73ace8c695</data>
    </edge>
    <edge source="&quot;PADDING&quot;" target="&quot;TRUNCATION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Padding and Truncation are techniques used to standardize sequence lengths for efficient processing in machine learning models."</data>
      <data key="d6">33a235bffff79a56e3ff5e5a9e86a3de</data>
    </edge>
    <edge source="&quot;DYNAMIC BATCHING&quot;" target="&quot;SEQUENCE MASKING&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Dynamic Batching and Sequence Masking are techniques used to minimize padding and ignore padded values during processing and computation."</data>
      <data key="d6">33a235bffff79a56e3ff5e5a9e86a3de</data>
    </edge>
    <edge source="&quot;DIMENSIONALITY REDUCTION&quot;" target="&quot;FEATURE ENGINEERING&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Dimensionality Reduction and Feature Engineering are techniques used to match the required dimensionality of sequences."</data>
      <data key="d6">33a235bffff79a56e3ff5e5a9e86a3de</data>
    </edge>
    <edge source="&quot;INTERPOLATION&quot;" target="&quot;EXTRAPOLATION&quot;">
      <data key="d4">2.0</data>
      <data key="d5">"Interpolation and Extrapolation are techniques used to adjust the length of sequences to a common length."
"Extrapolation is similar to Interpolation, but it is used to estimate values beyond the range of known data points."</data>
      <data key="d6">33a235bffff79a56e3ff5e5a9e86a3de,472b44b36407c9a89cf5c51459188263</data>
    </edge>
    <edge source="&quot;INTERPOLATION&quot;" target="&quot;CURVE FITTING&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Interpolation is a method used in Curve Fitting to construct an exact fit to the data."</data>
      <data key="d6">630c86e110e2dabbe068f446b619cef3</data>
    </edge>
    <edge source="&quot;INTERPOLATION&quot;" target="&quot;ECONOMIC TIME SERIES&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Interpolation is a method used in the construction of Economic Time Series to estimate unknown quantities between known data points."</data>
      <data key="d6">bde7c826c746ece93a512a0cf167fa3e</data>
    </edge>
    <edge source="&quot;INTERPOLATION&quot;" target="&quot;POLYNOMIAL INTERPOLATION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Polynomial Interpolation is a type of Interpolation that fits piecewise polynomial functions into time intervals."</data>
      <data key="d6">472b44b36407c9a89cf5c51459188263</data>
    </edge>
    <edge source="&quot;INTERPOLATION&quot;" target="&quot;SPLINE INTERPOLATION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Spline Interpolation is a type of Interpolation that uses piecewise continuous functions composed of many polynomials."</data>
      <data key="d6">472b44b36407c9a89cf5c51459188263</data>
    </edge>
    <edge source="&quot;EXTRAPOLATION&quot;" target="&quot;CURVE FITTING&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Extrapolation is the use of a fitted curve beyond the range of the observed data in Curve Fitting."</data>
      <data key="d6">630c86e110e2dabbe068f446b619cef3</data>
    </edge>
    <edge source="&quot;EXTRAPOLATION&quot;" target="&quot;ECONOMIC TIME SERIES&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Extrapolation is a method used to predict values of a function in Economic Time Series beyond the range of the observed data."</data>
      <data key="d6">bde7c826c746ece93a512a0cf167fa3e</data>
    </edge>
    <edge source="&quot;NP.LINSPACE()&quot;" target="&quot;NP.SIN()&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"np.linspace() generates an array of values that is used as input to np.sin() to create a sine wave."</data>
      <data key="d6">6f3d0ba82cf3b10b19b64f73ace8c695</data>
    </edge>
    <edge source="&quot;NP.SIN()&quot;" target="&quot;NP.ARRAY()&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"np.sin() computes the sine of an array of values, which is then converted to a NumPy array using np.array()."</data>
      <data key="d6">6f3d0ba82cf3b10b19b64f73ace8c695</data>
    </edge>
    <edge source="&quot;COMPLEX MODELS&quot;" target="&quot;HIERARCHICAL ESNS&quot;">
      <data key="d4">2.0</data>
      <data key="d5">"Hierarchical ESNs are a type of complex model that utilizes a hierarchical structure."
"Hierarchical ESNs are a type of Complex Model, utilizing a sequential hierarchy of nodes for data processing."</data>
      <data key="d6">22499cd4a0b7216dad5b05eb109fcb73,3695f5d218cdda0a91ae6a2f9b296837</data>
    </edge>
    <edge source="&quot;COMPLEX MODELS&quot;" target="&quot;DEEP ESNS&quot;">
      <data key="d4">2.0</data>
      <data key="d5">"Deep ESNs are a type of complex model that utilize multiple layers of ESNs."
"Deep ESNs are a type of Complex Model, involving multiple layers of reservoirs connected in series and parallel pathways."</data>
      <data key="d6">22499cd4a0b7216dad5b05eb109fcb73,3695f5d218cdda0a91ae6a2f9b296837</data>
    </edge>
    <edge source="&quot;COMPLEX MODELS&quot;" target="&quot;MULTI-INPUTS ESNS&quot;">
      <data key="d4">2.0</data>
      <data key="d5">"Multi-inputs ESNs are a type of complex model that can handle multiple input streams simultaneously."
"Multi-inputs ESNs are a type of Complex Model, capable of handling multiple input sources for data integration."</data>
      <data key="d6">22499cd4a0b7216dad5b05eb109fcb73,3695f5d218cdda0a91ae6a2f9b296837</data>
    </edge>
    <edge source="&quot;COMPLEX MODELS&quot;" target="&quot;DICTIONARY&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Dictionaries can be used in the training of Complex Models to specify target outputs for each readout node."</data>
      <data key="d6">22499cd4a0b7216dad5b05eb109fcb73</data>
    </edge>
    <edge source="&quot;DICTIONARY&quot;" target="&quot;SCIKITLEARNNODE&quot;">
      <data key="d4">2.0</data>
      <data key="d5">"The concept of a dictionary is mentioned in the context of using ScikitLearnNode, but there is no direct relationship between the two."
"A dictionary is used to specify the parameters of a model when using a ScikitLearnNode."</data>
      <data key="d6">84cacfea14ea9ff46a34150e77a0767a,861c28cb739722ddeb0babb7e1427409</data>
    </edge>
    <edge source="&quot;DEEP ESN&quot;" target="&quot;MULTI-INPUTS ESN&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Deep ESNs and Multi-inputs ESNs are both types of models, and they can be combined to create more complex and versatile models that can handle multiple inputs and have multiple layers of reservoirs."</data>
      <data key="d6">c7c2383410ac00bad82831596a2d27a6</data>
    </edge>
    <edge source="&quot;DEEP ESN&quot;" target="&quot;MACKEY-GLASS EQUATION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Mackey-Glass equation is a concept used to describe the temporal behavior of different physiological signals, which can be applied in the context of Deep ESNs for modeling and analysis."</data>
      <data key="d6">c7c2383410ac00bad82831596a2d27a6</data>
    </edge>
    <edge source="&quot;DEEP ESN&quot;" target="&quot;TIME SERIES PREDICTION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Deep ESN models are commonly used for the task of Time Series Prediction."</data>
      <data key="d6">2336a57d055095c6ffa9d156ddee0096</data>
    </edge>
    <edge source="&quot;MULTI-INPUTS ESN&quot;" target="&quot;MACKEY-GLASS EQUATION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Mackey-Glass equation is a concept used to describe the temporal behavior of different physiological signals, which can be applied in the context of Multi-inputs ESNs for modeling and analysis."</data>
      <data key="d6">c7c2383410ac00bad82831596a2d27a6</data>
    </edge>
    <edge source="&quot;MACKEY-GLASS EQUATION&quot;" target="&quot;CHAOTIC SYSTEMS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Mackey-Glass Equation is used to study Chaotic Systems and describe their behavior."</data>
      <data key="d6">9f13e40ee24c7913a62781d708e3b47e</data>
    </edge>
    <edge source="&quot;MACKEY-GLASS EQUATION&quot;" target="&quot;TIME DELAY&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Time Delay is a parameter in the Mackey-Glass Equation that controls the chaotic behavior of the system."</data>
      <data key="d6">9f13e40ee24c7913a62781d708e3b47e</data>
    </edge>
    <edge source="&quot;MACKEY-GLASS EQUATION&quot;" target="&quot;DATA RESCALING&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Data Rescaling is a preprocessing step used in the context of the Mackey-Glass Equation to standardize data."</data>
      <data key="d6">9f13e40ee24c7913a62781d708e3b47e</data>
    </edge>
    <edge source="&quot;MACKEY-GLASS EQUATION&quot;" target="&quot;PHASE DIAGRAM&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Mackey-Glass Equation is used to create a Phase Diagram, which shows how its variables change over time."</data>
      <data key="d6">518f1e492b92054cf2f5c5289444da02</data>
    </edge>
    <edge source="&quot;MACKEY-GLASS EQUATION&quot;" target="&quot;TAU&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Mackey-Glass Equation includes a time delay parameter Tau, which affects its behavior and is used in the Phase Diagram."</data>
      <data key="d6">518f1e492b92054cf2f5c5289444da02</data>
    </edge>
    <edge source="&quot;MACKEY-GLASS EQUATION&quot;" target="&quot;DATA PREPROCESSING&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Data Preprocessing is applied to the Mackey-Glass Equation data to prepare it for analysis."</data>
      <data key="d6">c5c29ba06a5cc70a086c2c2c8858e5aa</data>
    </edge>
    <edge source="&quot;CHAOTIC SYSTEMS&quot;" target="&quot;LORENZ CHAOTIC ATTRACTOR&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Lorenz Chaotic Attractor is a mathematical model used to describe chaotic systems."</data>
      <data key="d6">af2db1cc5ab6b16acae2c93d3facb668</data>
    </edge>
    <edge source="&quot;CHAOTIC SYSTEMS&quot;" target="&quot;H&#201;NON MAP&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"H&#233;non Map is a mathematical model used to describe chaotic systems."</data>
      <data key="d6">af2db1cc5ab6b16acae2c93d3facb668</data>
    </edge>
    <edge source="&quot;CHAOTIC SYSTEMS&quot;" target="&quot;LOGISTIC MAP&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Logistic Map is a mathematical model used to describe chaotic systems."</data>
      <data key="d6">af2db1cc5ab6b16acae2c93d3facb668</data>
    </edge>
    <edge source="&quot;CHAOTIC SYSTEMS&quot;" target="&quot;DOUBLE SCROLL ATTRACTOR&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Double Scroll Attractor is a mathematical model used to describe chaotic systems."</data>
      <data key="d6">af2db1cc5ab6b16acae2c93d3facb668</data>
    </edge>
    <edge source="&quot;MACKEY-GLASS TIMESERIES&quot;" target="&quot;STANDARDIZATION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Standardization is applied to Mackey-Glass timeseries for preprocessing, improving performance and stability."</data>
      <data key="d6">4ac00cf37a752d89d55a749c01c6f6fd</data>
    </edge>
    <edge source="&quot;MACKEY-GLASS TIMESERIES&quot;" target="&quot;MATPLOTLIB.PYPLOT&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"matplotlib.pyplot is used to visualize the Mackey-Glass timeseries."</data>
      <data key="d6">94fd1ebf256db17e4ac2255b89caa473</data>
    </edge>
    <edge source="&quot;MACKEY-GLASS TIMESERIES&quot;" target="&quot;MACKEY-GLASS EQUATIONS&quot;">
      <data key="d4">2.0</data>
      <data key="d5">"Mackey-Glass Timeseries is generated by the Mackey-Glass Equations."
"Mackey-Glass Equations are used to generate Mackey-Glass Timeseries."</data>
      <data key="d6">238049de5f28dca3e857a46a8b1bed03,2f4c992d69812866e6fce6dbb52d8612</data>
    </edge>
    <edge source="&quot;MACKEY-GLASS TIMESERIES&quot;" target="&quot;MATPLOTLIB&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Matplotlib is used to create visualizations of the Mackey-Glass Timeseries dataset in the provided code."</data>
      <data key="d6">4073cafddb73621f26061385c5570659</data>
    </edge>
    <edge source="&quot;MAGMA COLORMAP&quot;" target="&quot;NP.ARANGE() FUNCTION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Magma colormap is applied to the plot generated by np.arange() function to visualize the data."</data>
      <data key="d6">4ac00cf37a752d89d55a749c01c6f6fd</data>
    </edge>
    <edge source="&quot;NP.ARANGE(0, 500)&quot;" target="&quot;X_TRAIN&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"np.arange(0, 500) is used to select a subset of elements from X_train."</data>
      <data key="d6">7d747b0c740e8b5b60726dcf7dcadef5</data>
    </edge>
    <edge source="&quot;X_TRAIN&quot;" target="&quot;PLT.PLOT&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"X_train is used as input data for the plt.plot function to create a plot."</data>
      <data key="d6">7d747b0c740e8b5b60726dcf7dcadef5</data>
    </edge>
    <edge source="&quot;X_TRAIN&quot;" target="&quot;JAPANESE_VOWELS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The japanese_vowels function is used to obtain data for training, which is stored in X_train."</data>
      <data key="d6">b3361508c3e49b5bb3089f10e31d2c81</data>
    </edge>
    <edge source="&quot;X_TRAIN&quot;" target="&quot;ESN_MODEL&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The esn_model is trained using the X_train data input."</data>
      <data key="d6">751b176a8d6149a853e597c65a6fe0cf</data>
    </edge>
    <edge source="&quot;X_TRAIN&quot;" target="&quot;NP.VSTACK&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"np.vstack is used to vertically stack arrays to create the input data for training the ESN."</data>
      <data key="d6">71366a4c7e791080872ba783d3787bd7</data>
    </edge>
    <edge source="&quot;X_TRAIN&quot;" target="&quot;DATASET&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"X_train is a variable used to store the training input data in the dataset."</data>
      <data key="d6">0982b8d1eb1e636b19fa2e9d9361e566</data>
    </edge>
    <edge source="&quot;X_TRAIN&quot;" target="&quot;RESERVOIR MODEL&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Reservoir Model is trained using the X_train dataset."</data>
      <data key="d6">0970cd32ce54f6ee1180ab237fdcefe1</data>
    </edge>
    <edge source="&quot;TO_FORECASTING&quot;" target="&quot;X&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"X is used as input data for the to_forecasting function to prepare data for forecasting."</data>
      <data key="d6">7d747b0c740e8b5b60726dcf7dcadef5</data>
    </edge>
    <edge source="&quot;X&quot;" target="&quot;CHAPTER 2&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The variable X is mentioned in Chapter 2 as input data used in the context of the generative mode."</data>
      <data key="d6">e396354e3a9be76616392af11f56e671</data>
    </edge>
    <edge source="&quot;READOUT.WOUT&quot;" target="&quot;MODEL TRAINING&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"readout.Wout is checked to see if it's equal to 0.0, indicating whether the model has been trained."</data>
      <data key="d6">7d747b0c740e8b5b60726dcf7dcadef5</data>
    </edge>
    <edge source="&quot;OFFLINE TRAINING&quot;" target="&quot;ONLINE TRAINING&quot;">
      <data key="d4">2.0</data>
      <data key="d5">"Offline Training and Online Training are different methods for training a model, with Offline Training using a complete dataset and Online Training updating the model incrementally."
"Offline Training and Online Training are different methods for training a model, with Offline Training requiring significant memory and processing power and Online Training allowing the model to learn and adapt in real-time."</data>
      <data key="d6">7d747b0c740e8b5b60726dcf7dcadef5,c9e71660f79df626c288b3a58eab0f2f</data>
    </edge>
    <edge source="&quot;OFFLINE TRAINING&quot;" target="&quot;NP.RAVEL&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"np.ravel is used in the context of Offline Training to flatten a multi-dimensional array into a one-dimensional array."</data>
      <data key="d6">c9e71660f79df626c288b3a58eab0f2f</data>
    </edge>
    <edge source="&quot;ONLINE TRAINING&quot;" target="&quot;NP.ARANGE&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"np.arange is used in the context of Online Training to return evenly spaced values within a given interval."</data>
      <data key="d6">c9e71660f79df626c288b3a58eab0f2f</data>
    </edge>
    <edge source="&quot;ONLINE TRAINING&quot;" target="&quot;BIAS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Bias is a concept that is mentioned in the context of Online Training, as it is a constant value added to the input of a neuron to help the model make more accurate predictions."</data>
      <data key="d6">c9e71660f79df626c288b3a58eab0f2f</data>
    </edge>
    <edge source="&quot;MODEL TRAINING&quot;" target="&quot;DATA SCIENTIST&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Data Scientist is performing Model Training to train a machine learning model."</data>
      <data key="d6">9fdaabd6c7e893a275a3848c10007477</data>
    </edge>
    <edge source="&quot;NP.R_&quot;" target="&quot;NP.CONCATENATE&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"np.r_ is a shorthand for 'np.concatenate', which is used to concatenate arrays along the first axis."</data>
      <data key="d6">c9e71660f79df626c288b3a58eab0f2f</data>
    </edge>
    <edge source="&quot;NP.R_&quot;" target="&quot;BIAS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"np.r_ is used to concatenate the 'bias' array with another array."</data>
      <data key="d6">9078b0f36522f21a9e8e1aadac48ed9c</data>
    </edge>
    <edge source="&quot;NP.R_&quot;" target="&quot;WOUT&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"np.r_ is used to concatenate the 'Wout' array with another array."</data>
      <data key="d6">9078b0f36522f21a9e8e1aadac48ed9c</data>
    </edge>
    <edge source="&quot;BIAS&quot;" target="&quot;ESN MODELS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Bias refers to the assumptions or preferences that can influence the results of ESN models, and it is a term used in machine learning to describe this effect."</data>
      <data key="d6">e805d3f438bd9c485639f1c69f917ae5</data>
    </edge>
    <edge source="&quot;ABSOLUTE DEVIATION&quot;" target="&quot;ESN PREDICTION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Absolute deviation is a measure of the difference between the True value and the ESN prediction."</data>
      <data key="d6">ee83abbbbc707d8131952b2b01ebc268</data>
    </edge>
    <edge source="&quot;MODEL-0&quot;" target="&quot;X_TEST1&quot;">
      <data key="d4">2.0</data>
      <data key="d5">"Model-0 is processing the 'X_test1' input data to make predictions."
"Model-0 processes data points from the X_test1 dataset."</data>
      <data key="d6">9078b0f36522f21a9e8e1aadac48ed9c,c122738fd421d3d662f759af5a0a23f3</data>
    </edge>
    <edge source="&quot;MODEL-0&quot;" target="&quot;Y_PRED1&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Model-0 generates predicted values (y_pred1) based on the input data."</data>
      <data key="d6">c122738fd421d3d662f759af5a0a23f3</data>
    </edge>
    <edge source="&quot;MODEL-0&quot;" target="&quot;ACCURACY&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Accuracy is a measure of how often the Model-0's predictions are correct."</data>
      <data key="d6">c122738fd421d3d662f759af5a0a23f3</data>
    </edge>
    <edge source="&quot;MODEL-0&quot;" target="&quot;PRECISION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Precision is a measure of how good the Model-0 is at identifying true positives."</data>
      <data key="d6">c122738fd421d3d662f759af5a0a23f3</data>
    </edge>
    <edge source="&quot;MODEL-0&quot;" target="&quot;RECALL&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Recall is a measure of how good the Model-0 is at identifying true positives and true negatives."</data>
      <data key="d6">c122738fd421d3d662f759af5a0a23f3</data>
    </edge>
    <edge source="&quot;MODEL-0&quot;" target="&quot;MEAN SQUARED ERROR&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Mean Squared Error is a measure of how far off the Model-0's predictions are from the actual values."</data>
      <data key="d6">c122738fd421d3d662f759af5a0a23f3</data>
    </edge>
    <edge source="&quot;MODEL-0&quot;" target="&quot;R^2 OR RSQUARE&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"R^2 or rsquare is a statistical measure of how well the Model-0's predicted values match the actual values."</data>
      <data key="d6">c122738fd421d3d662f759af5a0a23f3</data>
    </edge>
    <edge source="&quot;MODEL-0&quot;" target="&quot;NRMSE OR NRMSE&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"NRMSE or nrmse is a measure of the average magnitude of the errors in the Model-0's predictions, normalized by the range of the actual values."</data>
      <data key="d6">c122738fd421d3d662f759af5a0a23f3</data>
    </edge>
    <edge source="&quot;Y_TEST1&quot;" target="&quot;Y_PRED1&quot;">
      <data key="d4">2.0</data>
      <data key="d5">"The actual values (y_test1) are compared against the predicted values (y_pred1) to evaluate the model's performance."
"y_pred1 and y_test1 are used together to evaluate the accuracy of a prediction model."</data>
      <data key="d6">c122738fd421d3d662f759af5a0a23f3,d8022c6a3caf781300e2abc1dfd2ed44</data>
    </edge>
    <edge source="&quot;Y_TEST1&quot;" target="&quot;RSQUARE&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"rsquare measures the proportion of the variance in the actual values (y_test1) that is predictable from the independent variable(s)."</data>
      <data key="d6">d8022c6a3caf781300e2abc1dfd2ed44</data>
    </edge>
    <edge source="&quot;Y_TEST1&quot;" target="&quot;NRMSE&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"NRMSE measures the differences between predicted values (y_pred1) and actual values (y_test1), normalized by the range or mean of the actual values."</data>
      <data key="d6">d8022c6a3caf781300e2abc1dfd2ed44</data>
    </edge>
    <edge source="&quot;RSQUARE&quot;" target="&quot;NRMSE&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"nrmse and rsquare are metrics used to evaluate the performance of a machine learning model, mentioned together in the provided code."</data>
      <data key="d6">0753d4e507badadd900c522ee03ad28d</data>
    </edge>
    <edge source="&quot;CLOSED LOOP GENERATIVE MODE&quot;" target="&quot;NP.ZEROS()&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"np.zeros() is used in Closed Loop Generative Mode to create an initial array of zeros for the prediction process."</data>
      <data key="d6">05ba4f2e1a9472bd286417154cb0c0d4</data>
    </edge>
    <edge source="&quot;NP.ZEROS()&quot;" target="&quot;X_GEN&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"np.zeros() is used to initialize X_gen as a 2D array with nb_generations rows and 1 column, where all the elements are set to zero."</data>
      <data key="d6">d55aca098e1ba2aea26a4bf33cc2d4a2</data>
    </edge>
    <edge source="&quot;ONLINE LEARNING&quot;" target="&quot;OFFLINE LEARNING&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Online Learning updates the parameters of a model incrementally with each new sample of data, while Offline Learning requires the entire dataset to be available before training a model."</data>
      <data key="d6">d55aca098e1ba2aea26a4bf33cc2d4a2</data>
    </edge>
    <edge source="&quot;ONLINE LEARNING&quot;" target="&quot;FORCE ALGORITHM&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"FORCE Algorithm is used for Online Learning, allowing for the continuous updating of the readout parameters at every timestep of input series."</data>
      <data key="d6">1b9bc5f1bd54d2b0c90359b6ed022bb6</data>
    </edge>
    <edge source="&quot;FORCE ALGORITHM&quot;" target="&quot;LEARNING ALGORITHM&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The First Order Reduced and Controlled Error (FORCE) algorithm is a learning algorithm that focuses on reducing the output error and maintaining it small, while minimizing the number of modifications needed to keep the error small."</data>
      <data key="d6">d55aca098e1ba2aea26a4bf33cc2d4a2</data>
    </edge>
    <edge source="&quot;FORCE ALGORITHM&quot;" target="&quot;SUSSILLO AND ABOTT&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Sussillo and Abott are the authors of the FORCE Algorithm, which is used in the ESN model for online learning."</data>
      <data key="d6">424bf7c7b82dc966139c25f7c9ccffb7</data>
    </edge>
    <edge source="&quot;FORCE ALGORITHM&quot;" target="&quot;SUSSILLO&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Sussillo is a contributor to the development of the FORCE Algorithm."</data>
      <data key="d6">1b9bc5f1bd54d2b0c90359b6ed022bb6</data>
    </edge>
    <edge source="&quot;FORCE ALGORITHM&quot;" target="&quot;ABOTT&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Abott is a contributor to the development of the FORCE Algorithm."</data>
      <data key="d6">1b9bc5f1bd54d2b0c90359b6ed022bb6</data>
    </edge>
    <edge source="&quot;ZIP()&quot;" target="&quot;ENUMERATE&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"zip() is used in conjunction with enumerate to combine multiple iterables into a single iterable, allowing elements from each iterable to be accessed together in a loop."</data>
      <data key="d6">d55aca098e1ba2aea26a4bf33cc2d4a2</data>
    </edge>
    <edge source="&quot;FIRST ORDER REDUCED AND CONTROLLED ERROR (FORCE) ALGORITHM&quot;" target="&quot;ZIP() FUNCTION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The zip() function is not explicitly mentioned in the context of the FORCE algorithm, but it could potentially be used in its implementation."</data>
      <data key="d6">4d8b9e762d08c8cdf5189130be11021e</data>
    </edge>
    <edge source="&quot;FIRST ORDER REDUCED AND CONTROLLED ERROR (FORCE) ALGORITHM&quot;" target="&quot;ENUMERATE() FUNCTION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The enumerate() function is not explicitly mentioned in the context of the FORCE algorithm, but it could potentially be used in its implementation."</data>
      <data key="d6">4d8b9e762d08c8cdf5189130be11021e</data>
    </edge>
    <edge source="&quot;LORENZ CHAOTIC ATTRACTOR&quot;" target="&quot;LORENZ SYSTEM&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Lorenz chaotic attractors are solutions to the Lorenz system of differential equations."</data>
      <data key="d6">4d114857b77ff15b495bb6456c9ad30c</data>
    </edge>
    <edge source="&quot;LORENZ CHAOTIC ATTRACTOR&quot;" target="&quot;EDWARD LORENZ&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Edward Lorenz discovered Lorenz chaotic attractors while studying atmospheric convection."</data>
      <data key="d6">4d114857b77ff15b495bb6456c9ad30c</data>
    </edge>
    <edge source="&quot;LORENZ SYSTEM&quot;" target="&quot;LORENZ ATTRACTOR&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Lorenz system is represented by the Lorenz attractor, which highlights its chaotic behavior."</data>
      <data key="d6">d4080e34001a0ebe22f20efdb204240b</data>
    </edge>
    <edge source="&quot;LORENZ SYSTEM&quot;" target="&quot;LORENZ SYSTEM WIKIPEDIA PAGE&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Lorenz system Wikipedia page provides information about the Lorenz system and its mathematical representation."</data>
      <data key="d6">d4080e34001a0ebe22f20efdb204240b</data>
    </edge>
    <edge source="&quot;H&#201;NON MAP&quot;" target="&quot;MICHEL H&#201;NON&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The H&#233;non map was introduced by Michel H&#233;non in 1976."</data>
      <data key="d6">4d114857b77ff15b495bb6456c9ad30c</data>
    </edge>
    <edge source="&quot;H&#201;NON MAP&quot;" target="&quot;H&#201;NON&#8211;POMEAU ATTRACTOR/MAP&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The H&#233;non&#8211;Pomeau attractor/map is an alternative name for the H&#233;non map."</data>
      <data key="d6">4d114857b77ff15b495bb6456c9ad30c</data>
    </edge>
    <edge source="&quot;H&#201;NON MAP&quot;" target="&quot;H&#201;NON STRANGE ATTRACTOR&quot;">
      <data key="d4">2.0</data>
      <data key="d5">"The H&#233;non map exhibits the H&#233;non strange attractor, which is a fractal structure known for its unique shape."
"The H&#233;non strange attractor is the attractor of the H&#233;non map, a mathematical model that exhibits chaotic behavior."</data>
      <data key="d6">9ada201f787cd4e88cd18dae60de346d,d4080e34001a0ebe22f20efdb204240b</data>
    </edge>
    <edge source="&quot;H&#201;NON MAP&quot;" target="&quot;LORENZ MODEL&quot;">
      <data key="d4">2.0</data>
      <data key="d5">"The H&#233;non map models the Poincar&#233; section of the Lorenz model, which is a set of ordinary differential equations describing a flow of fluid in a 3D space."
"The H&#233;non map models the Poincar&#233; section of the Lorenz model, illustrating complex dynamics."</data>
      <data key="d6">9ada201f787cd4e88cd18dae60de346d,d4080e34001a0ebe22f20efdb204240b</data>
    </edge>
    <edge source="&quot;H&#201;NON MAP&quot;" target="&quot;H&#201;NON MAP WIKIPEDIA PAGE&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The H&#233;non map Wikipedia page provides information about the H&#233;non map and its chaotic behavior."</data>
      <data key="d6">d4080e34001a0ebe22f20efdb204240b</data>
    </edge>
    <edge source="&quot;LOGISTIC MAP&quot;" target="&quot;CHAOTIC BEHAVIOR&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The logistic map models population dynamics and shows chaotic behavior for certain values of a parameter."</data>
      <data key="d6">9ada201f787cd4e88cd18dae60de346d</data>
    </edge>
    <edge source="&quot;DOUBLE SCROLL ATTRACTOR&quot;" target="&quot;CHUA'S CIRCUIT&quot;">
      <data key="d4">2.0</data>
      <data key="d5">"Double scroll attractors, also known as Chua's attractors, are strange attractors observed in a chaotic electronic circuit called Chua's circuit."
"Double scroll attractors are observed in Chua's circuit, which exhibits chaotic behavior."</data>
      <data key="d6">538ff8c18495002c85cbc9020b0146f9,9ada201f787cd4e88cd18dae60de346d</data>
    </edge>
    <edge source="&quot;SCIKIT-LEARN&quot;" target="&quot;MODULENOTFOUNDERROR&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"ModuleNotFoundError occurs when scikit-learn, a machine learning library, is not installed on the system."</data>
      <data key="d6">538ff8c18495002c85cbc9020b0146f9</data>
    </edge>
    <edge source="&quot;SCIKIT-LEARN&quot;" target="&quot;INSTANCE&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Scikit-learn models handle data points as instances, which are used for training and prediction."</data>
      <data key="d6">b130d3d59f0d3a2bb4feac9fdb85ed5b</data>
    </edge>
    <edge source="&quot;SCIKIT-LEARN&quot;" target="&quot;OUTPUT FEATURE&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Scikit-learn models are designed to predict output features, which are the target variables that the model aims to forecast."</data>
      <data key="d6">b130d3d59f0d3a2bb4feac9fdb85ed5b</data>
    </edge>
    <edge source="&quot;SCIKIT-LEARN&quot;" target="&quot;MULTIPLE OUTPUT FEATURES&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Scikit-learn models can handle multiple output features by creating multiple instances of the model under the hood, each dispatched to predict a specific output feature."</data>
      <data key="d6">b130d3d59f0d3a2bb4feac9fdb85ed5b</data>
    </edge>
    <edge source="&quot;SCIKIT-LEARN&quot;" target="&quot;REGRESSION METHODS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Scikit-learn provides various regression methods, which are statistical techniques used to model the relationship between a dependent variable and one or more independent variables."</data>
      <data key="d6">b130d3d59f0d3a2bb4feac9fdb85ed5b</data>
    </edge>
    <edge source="&quot;SCIKIT-LEARN&quot;" target="&quot;SCIKITLEARNNODE&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"ScikitLearnNode is a component that allows the use of any model from the scikit-learn library."</data>
      <data key="d6">8c66981c9d2009113219bbf2681f664c</data>
    </edge>
    <edge source="&quot;SCIKIT-LEARN&quot;" target="&quot;LASSO REGRESSION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Lasso Regression is a type of linear regression model available in the scikit-learn library."</data>
      <data key="d6">8c66981c9d2009113219bbf2681f664c</data>
    </edge>
    <edge source="&quot;SCIKIT-LEARN&quot;" target="&quot;API REFERENCE&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The API reference is a documentation section that provides information about the methods and functions available in the scikit-learn library."</data>
      <data key="d6">8c66981c9d2009113219bbf2681f664c</data>
    </edge>
    <edge source="&quot;SCIKIT-LEARN&quot;" target="&quot;RIDGECLASSIFIER&quot;">
      <data key="d4">3.0</data>
      <data key="d5">"scikit-learn implements the RidgeClassifier, which can be used to handle outlier data and make decisions."
"Scikit-learn provides the RidgeClassifier model for classification tasks."
"RidgeClassifier is a machine learning algorithm provided by the Scikit-learn library."</data>
      <data key="d6">0036fb6f489e13c0db0f1c02bf3323be,d58662ee42c14a0787d839ebfd0a6e9b,f5358a50d00a1cac02dd4ad8fcb167ee</data>
    </edge>
    <edge source="&quot;SCIKIT-LEARN&quot;" target="&quot;LOGISTICREGRESSION&quot;">
      <data key="d4">3.0</data>
      <data key="d5">"scikit-learn implements the LogisticRegression classifier, which can be used for making predictions based on input data."
"Scikit-learn provides the LogisticRegression model for classification tasks."
"LogisticRegression is a machine learning algorithm provided by the Scikit-learn library."</data>
      <data key="d6">0036fb6f489e13c0db0f1c02bf3323be,d58662ee42c14a0787d839ebfd0a6e9b,f5358a50d00a1cac02dd4ad8fcb167ee</data>
    </edge>
    <edge source="&quot;SCIKIT-LEARN&quot;" target="&quot;ML TECHNIQUES&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"scikit-learn is a library that offers a simple API to apply ML techniques."</data>
      <data key="d6">295606b4bc5d12929a913a3c79f93734</data>
    </edge>
    <edge source="&quot;SCIKIT-LEARN&quot;" target="&quot;DV BUONOMANO&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"scikit-learn is mentioned in the context of a scientific paper by DV Buonomano and M. M. Merzenich."</data>
      <data key="d6">ce7b58ffc7f43f36bc78154597d01903</data>
    </edge>
    <edge source="&quot;GLOB.GLOB()&quot;" target="&quot;FILE PATHS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"glob.glob() retrieves and returns a list of file paths that match a specified pattern."</data>
      <data key="d6">538ff8c18495002c85cbc9020b0146f9</data>
    </edge>
    <edge source="&quot;GLOB.GLOB()&quot;" target="&quot;R4-DATA/EXPERIMENTS/&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"glob.glob() retrieves all file paths within the r4-data/experiments/ directory."</data>
      <data key="d6">fb40afaf160923869aba1456b3a1ddca</data>
    </edge>
    <edge source="&quot;PARALLEL()&quot;" target="&quot;DELAYED()&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Parallel() is used to enable parallel processing, and delayed() is used to create a lazy evaluation of the function it wraps, allowing for parallel execution of tasks."</data>
      <data key="d6">fb40afaf160923869aba1456b3a1ddca</data>
    </edge>
    <edge source="&quot;DELAYED()&quot;" target="&quot;PD.READ_CSV()&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"delayed() is used to create a lazy evaluation of pd.read_csv(), enabling parallel reading of multiple CSV files."</data>
      <data key="d6">fb40afaf160923869aba1456b3a1ddca</data>
    </edge>
    <edge source="&quot;DELAYED()&quot;" target="&quot;PD.READ_CSV&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The pd.read_csv function is wrapped by the delayed() function, allowing for concurrent execution of data loading tasks."</data>
      <data key="d6">f3b5b178557c4991ab5b81d869a4752e</data>
    </edge>
    <edge source="&quot;NP.ROLL&quot;" target="&quot;ARRAY ELEMENTS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The np.roll function is used to shift the elements of an array by a specified number of positions."</data>
      <data key="d6">f3b5b178557c4991ab5b81d869a4752e</data>
    </edge>
    <edge source="&quot;NP.ROLL&quot;" target="&quot;CIRCULAR SHIFT&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"np.roll is used to perform a circular shift of the elements of an array."</data>
      <data key="d6">584889d2db258e32e7f673d3c0a0e603</data>
    </edge>
    <edge source="&quot;RMSE&quot;" target="&quot;MODEL PERFORMANCE&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The rmse function is used to calculate the Root Mean Square Error, a common metric for evaluating the performance of a model."</data>
      <data key="d6">f3b5b178557c4991ab5b81d869a4752e</data>
    </edge>
    <edge source="&quot;RMSE&quot;" target="&quot;AVERAGED RMSE&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"RMSE is used to calculate Averaged RMSE, which provides an overall measure of prediction accuracy."</data>
      <data key="d6">584889d2db258e32e7f673d3c0a0e603</data>
    </edge>
    <edge source="&quot;RMSE&quot;" target="&quot;HYPEROPT&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Hyperopt uses the Root Mean Squared Error (RMSE) loss function to evaluate the quality of parameters in optimization algorithms."</data>
      <data key="d6">251a50c2ae8ceea4fd7da1127cc5f461</data>
    </edge>
    <edge source="&quot;ROOT MEAN SQUARED ERROR (RMSE)&quot;" target="&quot;OBJECTIVE FUNCTION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Root Mean Squared Error (RMSE) is used as a loss function within the objective function to evaluate the quality of parameters."</data>
      <data key="d6">4f7b43545046f0e6f9b6fb3816da1d79</data>
    </edge>
    <edge source="&quot;AVERAGED RMSE&quot;" target="&quot;AVERAGED RMSE (WITH THRESHOLD)&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Averaged RMSE (with threshold) is a variant of Averaged RMSE that considers only predictions within a specific range."</data>
      <data key="d6">584889d2db258e32e7f673d3c0a0e603</data>
    </edge>
    <edge source="&quot;GLOB.GLOB&quot;" target="&quot;FILE RETRIEVAL&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"glob.glob is used to retrieve files with a specific extension, allowing for their subsequent processing."</data>
      <data key="d6">584889d2db258e32e7f673d3c0a0e603</data>
    </edge>
    <edge source="&quot;SORTED&quot;" target="&quot;ASCENDING ORDER&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"sorted is used to sort the elements of a list in ascending order."</data>
      <data key="d6">584889d2db258e32e7f673d3c0a0e603</data>
    </edge>
    <edge source="&quot;LBR.FEATURE.MFCC&quot;" target="&quot;SPEECH AND AUDIO PROCESSING&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"lbr.feature.mfcc is used to compute the Mel-frequency cepstral coefficients (MFCCs) of a given audio signal, which are commonly used for speech and audio processing tasks."</data>
      <data key="d6">584889d2db258e32e7f673d3c0a0e603</data>
    </edge>
    <edge source="&quot;SORTED() FUNCTION&quot;" target="&quot;GLOB.GLOB() FUNCTION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The sorted() function is used in conjunction with the glob.glob() function to sort the list of audio file paths in ascending order."</data>
      <data key="d6">7bea9e814256104a2d7ede466ddc3364</data>
    </edge>
    <edge source="&quot;MFCCS&quot;" target="&quot;LIBROSA LIBRARY&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"MFCCs are features extracted from audio signals using the librosa library, which provides functions for this purpose."</data>
      <data key="d6">7bea9e814256104a2d7ede466ddc3364</data>
    </edge>
    <edge source="&quot;MFCCS&quot;" target="&quot;LIBROSA&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"librosa provides functions for extracting Mel-Frequency Cepstral Coefficients (MFCCs) from audio signals."</data>
      <data key="d6">e3828ad4e78d575fabb543e0eab86160</data>
    </edge>
    <edge source="&quot;MFCCS&quot;" target="&quot;DELTA COEFFICIENTS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Delta Coefficients are derived from the Mel-Frequency Cepstral Coefficients (MFCCs) to enhance the feature set for tasks like audio and speech processing."</data>
      <data key="d6">e3828ad4e78d575fabb543e0eab86160</data>
    </edge>
    <edge source="&quot;DELTA&quot;" target="&quot;LIBRISPEECH DATASET&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Delta is used to extract features from the audio files in the Librispeech Dataset."</data>
      <data key="d6">adfade0d7bc85c6420e61ecd1ce7095c</data>
    </edge>
    <edge source="&quot;LIBROSA&quot;" target="&quot;DELTA COEFFICIENTS&quot;">
      <data key="d4">3.0</data>
      <data key="d5">"librosa provides a function to compute Delta Coefficients, which are derived from the MFCCs to capture their temporal dynamics."
"librosa provides functions for calculating delta coefficients, which are the first-order differences of the MFCCs, enhancing the feature set for tasks like audio and speech processing."
"librosa is used to calculate delta coefficients, which measure the rate of change of a signal."</data>
      <data key="d6">7c8a0a6b9506a584f1c98495097d48ee,aea362ee35c2a3a01b76020d0b892cbd,e3828ad4e78d575fabb543e0eab86160</data>
    </edge>
    <edge source="&quot;LIBROSA&quot;" target="&quot;MEL-FREQUENCY CEPSTRAL COEFFICIENTS (MFCCS)&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"librosa provides functions for calculating MFCCs, which are a feature extraction technique used in audio and speech processing."</data>
      <data key="d6">7c8a0a6b9506a584f1c98495097d48ee</data>
    </edge>
    <edge source="&quot;LIBROSA&quot;" target="&quot;SECOND-ORDER DIFFERENCES (OR DELTA-DELTAS)&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"librosa provides functions for calculating second-order differences (or delta-deltas) of the MFCCs, which capture the acceleration or the rate of change of the delta coefficients."</data>
      <data key="d6">7c8a0a6b9506a584f1c98495097d48ee</data>
    </edge>
    <edge source="&quot;LIBROSA&quot;" target="&quot;CHAPTER 5&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Librosa is used in Chapter 5 for audio processing and analysis."</data>
      <data key="d6">1e8ee805d22cd143d2372d300997d253</data>
    </edge>
    <edge source="&quot;DELTA COEFFICIENTS&quot;" target="&quot;EDGE EFFECTS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Edge effects can affect the accuracy of delta coefficients, which measure the rate of change of a signal."</data>
      <data key="d6">aea362ee35c2a3a01b76020d0b892cbd</data>
    </edge>
    <edge source="&quot;DATAFRAME&quot;" target="&quot;NAMED TUPLES&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"DataFrame.itertuples() returns each row as a named tuple, allowing for attribute-based access to the data."</data>
      <data key="d6">aea362ee35c2a3a01b76020d0b892cbd</data>
    </edge>
    <edge source="&quot;ONE-HOT ENCODING&quot;" target="&quot;CATEGORICAL DATA&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"One-hot encoding is used to convert categorical data variables into a format that can be used by machine learning algorithms."</data>
      <data key="d6">aea362ee35c2a3a01b76020d0b892cbd</data>
    </edge>
    <edge source="&quot;CATEGORICAL DATA&quot;" target="&quot;ONEHOTENCODER&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The OneHotEncoder function is used to transform categorical data into a binary matrix representation."</data>
      <data key="d6">d5477dbd84525291f2e017ae618de222</data>
    </edge>
    <edge source="&quot;ONEHOTENCODER&quot;" target="&quot;SPARSE_OUTPUT&quot;">
      <data key="d4">2.0</data>
      <data key="d5">"The OneHotEncoder function has a parameter called sparse_output that determines whether the output should be a sparse matrix or a dense array."
"sparse_output is a parameter used in the OneHotEncoder function to specify the format of the resulting one-hot encoded matrix."</data>
      <data key="d6">84a64dd2c683e779d55aaccea16b1032,d5477dbd84525291f2e017ae618de222</data>
    </edge>
    <edge source="&quot;ONEHOTENCODER&quot;" target="&quot;MACHINE LEARNING MODELS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"One-hot encoding is a preprocessing step that can make categorical data more suitable for feeding into machine learning models."</data>
      <data key="d6">d5477dbd84525291f2e017ae618de222</data>
    </edge>
    <edge source="&quot;ONEHOTENCODER&quot;" target="&quot;FLATTEN()&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"flatten() is used to convert the multi-dimensional array resulting from the OneHotEncoder function into a one-dimensional array."</data>
      <data key="d6">84a64dd2c683e779d55aaccea16b1032</data>
    </edge>
    <edge source="&quot;ONEHOTENCODER&quot;" target="&quot;HYPEROPT&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Hyperopt is used for optimizing hyperparameters, which may include the parameters used in the OneHotEncoder function."</data>
      <data key="d6">84a64dd2c683e779d55aaccea16b1032</data>
    </edge>
    <edge source="&quot;ARGMAX()&quot;" target="&quot;HYPEROPT&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"argmax() is used in the context of optimizing hyperparameters with the Hyperopt library."</data>
      <data key="d6">84a64dd2c683e779d55aaccea16b1032</data>
    </edge>
    <edge source="&quot;HYPEROPT&quot;" target="&quot;NP.ARGMAX()&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"np.argmax() is used in the context of Hyperopt to return the indices of the maximum values, which may be relevant in the process of optimizing hyperparameters."</data>
      <data key="d6">3b4d50c051c177770830f7c0a6b3dd69</data>
    </edge>
    <edge source="&quot;HYPEROPT&quot;" target="&quot;PARAMETERS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Hyperopt is used to optimize Parameters."</data>
      <data key="d6">6a6d88a8f9731e1ed05b786e0a9ba6dc</data>
    </edge>
    <edge source="&quot;HYPEROPT&quot;" target="&quot;XAVIER HINAUT&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Xavier Hinaut is an author of the paper that introduces the use of Hyperopt for Echo State Networks hyperparameter optimization."</data>
      <data key="d6">46913f0d73ba0b8cecfdf42bde9862f4</data>
    </edge>
    <edge source="&quot;HYPEROPT&quot;" target="&quot;NICOLAS TROUVAIN&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Nicolas Trouvain is an author of the paper that introduces the use of Hyperopt for Echo State Networks hyperparameter optimization."</data>
      <data key="d6">46913f0d73ba0b8cecfdf42bde9862f4</data>
    </edge>
    <edge source="&quot;HYPEROPT&quot;" target="&quot;PYTHON NOTEBOOKS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Hyperopt is a Python library for hyperparameter optimization that may be used in the Python Notebooks for reservoir computing."</data>
      <data key="d6">0b6c69085074b2cf23267eb149068b9f</data>
    </edge>
    <edge source="&quot;HYPEROPT&quot;" target="&quot;TROUVAIN ET AL.&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Trouvain et al. are authors of a paper that uses Hyperopt for exploring hyperparameters."</data>
      <data key="d6">280cbdf53022bbaed48ccb34ebe142bc</data>
    </edge>
    <edge source="&quot;HYPEROPT&quot;" target="&quot;R&#178;&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Hyperopt also computes the R&#178; metric to measure the proportion of the variance in the dependent variable that is predictable from the independent variable(s)."</data>
      <data key="d6">251a50c2ae8ceea4fd7da1127cc5f461</data>
    </edge>
    <edge source="&quot;HYPEROPT&quot;" target="&quot;AUTHOR&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The author discusses the use of Hyperopt to approximate a function and find a minimum."</data>
      <data key="d6">11749b7d0fdadf05ea29da6025618407</data>
    </edge>
    <edge source="&quot;HYPEROPT&quot;" target="&quot;OBJECTIVE FUNCTION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Hyperopt is used to optimize the objective function, which evaluates the performance of a machine learning model."</data>
      <data key="d6">0753d4e507badadd900c522ee03ad28d</data>
    </edge>
    <edge source="&quot;HYPEROPT&quot;" target="&quot;HYPEROPT_CONFIG&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Hyperopt uses the hyperopt_config file to define the parameters for hyperparameter optimization."</data>
      <data key="d6">75e530c1a04e30b373dc7cc68e3ad819</data>
    </edge>
    <edge source="&quot;HYPEROPT&quot;" target="&quot;RANDOM SEARCH ALGORITHM&quot;">
      <data key="d4">2.0</data>
      <data key="d5">"Hyperopt is mentioned as using the Random Search Algorithm for hyperparameter optimization."
"Random Search Algorithm is mentioned as a method used by Hyperopt to optimize parameters."</data>
      <data key="d6">0a9b132ecb1c4b63fdbb0e144295362e,25743a99f36f3e56551ffafbba8d15c4</data>
    </edge>
    <edge source="&quot;HYPEROPT&quot;" target="&quot;GRID SEARCH&quot;">
      <data key="d4">2.0</data>
      <data key="d5">"Hyperopt is mentioned as not using the Grid Search method for hyperparameter optimization."
"Grid Search is mentioned as a method that could add a bias during optimization when used with Hyperopt."</data>
      <data key="d6">0a9b132ecb1c4b63fdbb0e144295362e,25743a99f36f3e56551ffafbba8d15c4</data>
    </edge>
    <edge source="&quot;HYPEROPT&quot;" target="&quot;RANDOM SEED&quot;">
      <data key="d4">2.0</data>
      <data key="d5">"Hyperopt is mentioned as using a Random Seed for the ESN initialization."
"Hyperopt is using a fixed Random Seed parameter for ESN initialization."</data>
      <data key="d6">0a9b132ecb1c4b63fdbb0e144295362e,65ba78d1f678e080bd930319c54234ef</data>
    </edge>
    <edge source="&quot;HYPEROPT&quot;" target="&quot;PROCEED&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Hyperopt is presented at the Proceed event."</data>
      <data key="d6">a3a74dc4754a8c8b0730f808285893e2</data>
    </edge>
    <edge source="&quot;HYPEROPT&quot;" target="&quot;JAMES BERGSTRA&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"James Bergstra is an author of Hyperopt, a python library for optimizing the hyperparameters of machine learning algorithms."</data>
      <data key="d6">82de30f43839f4985de20a981b524af1</data>
    </edge>
    <edge source="&quot;HYPEROPT&quot;" target="&quot;DAN YAMINS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Dan Yamins is an author of Hyperopt, a python library for optimizing the hyperparameters of machine learning algorithms."</data>
      <data key="d6">82de30f43839f4985de20a981b524af1</data>
    </edge>
    <edge source="&quot;HYPEROPT&quot;" target="&quot;DAVID D COX&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"David D Cox is an author of Hyperopt, a python library for optimizing the hyperparameters of machine learning algorithms."</data>
      <data key="d6">82de30f43839f4985de20a981b524af1</data>
    </edge>
    <edge source="&quot;HYPEROPT&quot;" target="&quot;RANDOM METHOD&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Hyperopt uses the Random Method to choose different sets of parameters."</data>
      <data key="d6">65ba78d1f678e080bd930319c54234ef</data>
    </edge>
    <edge source="&quot;HYPEROPT&quot;" target="&quot;INPUT SCALING&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Hyperopt is using a fixed Input Scaling parameter."</data>
      <data key="d6">65ba78d1f678e080bd930319c54234ef</data>
    </edge>
    <edge source="&quot;HYPEROPT&quot;" target="&quot;RIDGE REGULARIZATION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Hyperopt is using a fixed Ridge Regularization parameter."</data>
      <data key="d6">65ba78d1f678e080bd930319c54234ef</data>
    </edge>
    <edge source="&quot;HYPEROPT&quot;" target="&quot;CHOICE&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Choice is a parameter mentioned in the Hyperopt configuration."</data>
      <data key="d6">0982b8d1eb1e636b19fa2e9d9361e566</data>
    </edge>
    <edge source="&quot;HYPEROPT&quot;" target="&quot;LOGUNIFORM&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Loguniform is a parameter mentioned in the Hyperopt configuration."</data>
      <data key="d6">0982b8d1eb1e636b19fa2e9d9361e566</data>
    </edge>
    <edge source="&quot;HYPEROPT&quot;" target="&quot;RESEARCH PAPER&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Hyperopt is a tool mentioned in the research paper."</data>
      <data key="d6">870f29520f7a1c42eecb0c4ff855f09e</data>
    </edge>
    <edge source="&quot;CORRELATION&quot;" target="&quot;NP.CORRCOEF()&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The concept of Correlation is explained using the np.corrcoef() function to calculate the correlation coefficient matrix."</data>
      <data key="d6">a8df60a94e25d863b436f47f4f8e6a6d</data>
    </edge>
    <edge source="&quot;CORRELATION&quot;" target="&quot;INPUT SCALING&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Input Scaling is mentioned in the context of correlation, indicating its impact on the relationship between variables."</data>
      <data key="d6">b957e1bf5bf175c7630222ca742c7933</data>
    </edge>
    <edge source="&quot;INPUT_SCALING&quot;" target="&quot;PERSON CORRELATION COEFFICIENT&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"INPUT_SCALING affects the calculation of the Person Correlation Coefficient, influencing the correlation between states and inputs."</data>
      <data key="d6">76f47f241e255f9f36646409d2ec30f1</data>
    </edge>
    <edge source="&quot;INPUT_SCALING&quot;" target="&quot;HP_SPACE&quot;">
      <data key="d4">3.0</data>
      <data key="d5">"hp_space is the configuration parameter that explores the input_scaling parameter, which represents the input scaling."
"hp_space is used to explore the input_scaling parameter."
"hp_space is associated with the parameter input_scaling, which specifies the input scaling."</data>
      <data key="d6">5cea9edfd65fcfa25a081554300b28cc,80033e741d8e10abdcfe20dd17192152,adfc38e9dc5e6fd0fe67ce83dfa1f154</data>
    </edge>
    <edge source="&quot;RC_CONNECTIVITY&quot;" target="&quot;DOUBLE-SCROLL ATTRACTOR&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"RC_CONNECTIVITY determines the density of the reservoir's internal matrix, which may have an impact on the observation of Double-Scroll Attractors."</data>
      <data key="d6">76f47f241e255f9f36646409d2ec30f1</data>
    </edge>
    <edge source="&quot;INPUT_CONNECTIVITY&quot;" target="&quot;LEAK_RATE&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Both INPUT_CONNECTIVITY and LEAK_RATE influence the behavior of the reservoir, potentially affecting the correlation between states and inputs."</data>
      <data key="d6">76f47f241e255f9f36646409d2ec30f1</data>
    </edge>
    <edge source="&quot;RK23&quot;" target="&quot;THE OPTIMIZATION ALGORITHM&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"RK23 is used in the context of the Optimization Algorithm to simulate and analyze a double-scroll attractor."</data>
      <data key="d6">7c7818502732457fb71aacdd9a90ee36</data>
    </edge>
    <edge source="&quot;THE OPTIMIZATION ALGORITHM&quot;" target="&quot;THE OBJECTIVE FUNCTION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Optimization Algorithm aims to minimize the Objective Function, which is defined in terms of the Loss Function (RMSE)."</data>
      <data key="d6">7c7818502732457fb71aacdd9a90ee36</data>
    </edge>
    <edge source="&quot;THE OBJECTIVE FUNCTION&quot;" target="&quot;THE LOSS FUNCTION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Objective Function is defined in terms of the Loss Function (RMSE), which measures the quality of the parameters chosen in the Optimization Algorithm."</data>
      <data key="d6">7c7818502732457fb71aacdd9a90ee36</data>
    </edge>
    <edge source="&quot;R-SQUARED (R^2)&quot;" target="&quot;OBJECTIVE FUNCTION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"R-squared (R^2) is an additional metric computed within the objective function to assess the goodness of fit of a model."</data>
      <data key="d6">4f7b43545046f0e6f9b6fb3816da1d79</data>
    </edge>
    <edge source="&quot;OBJECTIVE FUNCTION&quot;" target="&quot;HYPERPARAMETER OPTIMIZATION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Hyperparameter Optimization uses the Objective Function to calculate the loss or error of a machine learning model."</data>
      <data key="d6">d4684af3c445d312afe4d838abc45502</data>
    </edge>
    <edge source="&quot;OBJECTIVE FUNCTION&quot;" target="&quot;DATASET&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Dataset is split into training and testing sets in the Objective Function, which may require additional preprocessing steps based on the type of data."</data>
      <data key="d6">d4684af3c445d312afe4d838abc45502</data>
    </edge>
    <edge source="&quot;OBJECTIVE FUNCTION&quot;" target="&quot;OPTIMIZATION ALGORITHM&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Optimization Algorithm is used to optimize the Objective Function, which measures the performance of the forecasting task."</data>
      <data key="d6">91704ce63f9ba41247fdc452a7a62ba6</data>
    </edge>
    <edge source="&quot;OBJECTIVE FUNCTION&quot;" target="&quot;EXPERIMENTATION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Experimentation is the process of designing and conducting experiments to test the Objective Function, which in this case is the Root Mean Squared Error (RMSE) loss function."</data>
      <data key="d6">251a50c2ae8ceea4fd7da1127cc5f461</data>
    </edge>
    <edge source="&quot;OBJECTIVE FUNCTION&quot;" target="&quot;AUTHOR&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The author discusses the definition and structure of the Objective Function."</data>
      <data key="d6">11749b7d0fdadf05ea29da6025618407</data>
    </edge>
    <edge source="&quot;HYPERPARAMETER OPTIMIZATION&quot;" target="&quot;CONFIG FILE&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Config File defines the hyperparameters and settings for the Hyperparameter Optimization process."</data>
      <data key="d6">d4684af3c445d312afe4d838abc45502</data>
    </edge>
    <edge source="&quot;HYPERPARAMETER OPTIMIZATION&quot;" target="&quot;CONFIGURATION FILE&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Configuration File is used in the Hyperparameter Optimization process to define the settings and hyperparameters for the optimization process."</data>
      <data key="d6">bd4cf5e35045463b7f0d8da82debc122</data>
    </edge>
    <edge source="&quot;HYPERPARAMETER OPTIMIZATION&quot;" target="&quot;RANDOM SEARCH ALGORITHM&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Random Search Algorithm is a technique used in the Hyperparameter Optimization process to randomly choose parameters within a specified range."</data>
      <data key="d6">bd4cf5e35045463b7f0d8da82debc122</data>
    </edge>
    <edge source="&quot;HYPERPARAMETER OPTIMIZATION&quot;" target="&quot;GRID SEARCH&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Grid Search is a technique used in the Hyperparameter Optimization process to systematically search through a manually specified subset of the hyperparameter space."</data>
      <data key="d6">bd4cf5e35045463b7f0d8da82debc122</data>
    </edge>
    <edge source="&quot;HYPERPARAMETER OPTIMIZATION&quot;" target="&quot;OBJECTIVE&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Objective is the function used to evaluate the performance of the machine learning model during Hyperparameter Optimization."</data>
      <data key="d6">f70c7d3d89baaabbeaad57b58e379e08</data>
    </edge>
    <edge source="&quot;HYPERPARAMETER OPTIMIZATION&quot;" target="&quot;HYPEROPT_CONFIG&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Hyperopt_config is the configuration file used for Hyperparameter Optimization."</data>
      <data key="d6">f70c7d3d89baaabbeaad57b58e379e08</data>
    </edge>
    <edge source="&quot;HYPERPARAMETER OPTIMIZATION&quot;" target="&quot;LR&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Lr is a hyperparameter representing the learning rate in the machine learning model, which is optimized during Hyperparameter Optimization."</data>
      <data key="d6">f70c7d3d89baaabbeaad57b58e379e08</data>
    </edge>
    <edge source="&quot;HYPERPARAMETER OPTIMIZATION&quot;" target="&quot;SR&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Sr is a hyperparameter representing the spectral radius in the machine learning model, which is optimized during Hyperparameter Optimization."</data>
      <data key="d6">f70c7d3d89baaabbeaad57b58e379e08</data>
    </edge>
    <edge source="&quot;HYPERPARAMETER OPTIMIZATION&quot;" target="&quot;METRIC&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Metric is a measure used to evaluate the performance of the machine learning model during Hyperparameter Optimization."</data>
      <data key="d6">f70c7d3d89baaabbeaad57b58e379e08</data>
    </edge>
    <edge source="&quot;HYPERPARAMETER OPTIMIZATION&quot;" target="&quot;OBJECTIVE FUNCTIONS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Objective Functions are used to guide the search for optimal parameters during Hyperparameter Optimization."</data>
      <data key="d6">0113164912437e96423379cb9c039f56</data>
    </edge>
    <edge source="&quot;DATASET&quot;" target="&quot;TRAINING SERIES&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The dataset is split into a training series for training an Echo State Network (ESN)."</data>
      <data key="d6">1db191f05801d40d5a346febd10d3352</data>
    </edge>
    <edge source="&quot;DATASET&quot;" target="&quot;TESTING SERIES&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The dataset is split into a testing series for evaluating the performance of an Echo State Network (ESN) after training."</data>
      <data key="d6">1db191f05801d40d5a346febd10d3352</data>
    </edge>
    <edge source="&quot;DATASET&quot;" target="&quot;TRAIN_LEN&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Train_len is a variable used to set the length of the training data in the dataset."</data>
      <data key="d6">0982b8d1eb1e636b19fa2e9d9361e566</data>
    </edge>
    <edge source="&quot;DATASET&quot;" target="&quot;FORECAST&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Forecast is a variable used to set the forecasting horizon in the dataset."</data>
      <data key="d6">0982b8d1eb1e636b19fa2e9d9361e566</data>
    </edge>
    <edge source="&quot;PARAMETERS&quot;" target="&quot;LOSS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Loss is a measure of error that depends on the Parameters of a model."</data>
      <data key="d6">6a6d88a8f9731e1ed05b786e0a9ba6dc</data>
    </edge>
    <edge source="&quot;PARAMETERS&quot;" target="&quot;EXPERIMENTATION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Experimentation involves testing and optimizing Parameters."</data>
      <data key="d6">6a6d88a8f9731e1ed05b786e0a9ba6dc</data>
    </edge>
    <edge source="&quot;LOSS&quot;" target="&quot;HYPER-PARAMETER EXPLORATION&quot;">
      <data key="d4">2.0</data>
      <data key="d5">"Loss is a measure used during hyper-parameter exploration to evaluate the performance of a machine learning model with different hyper-parameters."
"During Hyper-parameter Exploration, the Loss is minimized to optimize the model's performance."</data>
      <data key="d6">136d135c710f6cf78a4c536d43276fe1,716940af834825642e01a3cb59a7e006</data>
    </edge>
    <edge source="&quot;HINAUT, X.&quot;" target="&quot;TROUVAIN, N.&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Hinaut, X. and Trouvain, N. are co-authors of a guide on hyperparameter exploration."</data>
      <data key="d6">6a6d88a8f9731e1ed05b786e0a9ba6dc</data>
    </edge>
    <edge source="&quot;HINAUT, X.&quot;" target="&quot;ICANN 2021&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Hinaut, X. presented a guide on hyperparameter exploration at ICANN 2021."</data>
      <data key="d6">6a6d88a8f9731e1ed05b786e0a9ba6dc</data>
    </edge>
    <edge source="&quot;HINAUT, X.&quot;" target="&quot;ICANN&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Hinaut, X. is an author of a guide on exploring hyper-parameters for Echo State Networks published by ICANN."</data>
      <data key="d6">088d2280349d652200861994c09d7dd5</data>
    </edge>
    <edge source="&quot;TROUVAIN, N.&quot;" target="&quot;ICANN&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Trouvain, N. is an author of a guide on exploring hyper-parameters for Echo State Networks published by ICANN."</data>
      <data key="d6">088d2280349d652200861994c09d7dd5</data>
    </edge>
    <edge source="&quot;ICANN 2021&quot;" target="&quot;TROUVAIN &amp; HINAUT&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Trouvain &amp; Hinaut presented a paper at ICANN 2021 on Canary Song Decoder, Transduction, and Implicit Segmentation with ESNs and LTSMs."</data>
      <data key="d6">20b16c2e1cb8813ade96fea5f9591631</data>
    </edge>
    <edge source="&quot;ICANN 2021&quot;" target="&quot;XAVIER HINAUT&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Xavier Hinaut is an author of a guide presented at ICANN 2021."</data>
      <data key="d6">25743a99f36f3e56551ffafbba8d15c4</data>
    </edge>
    <edge source="&quot;ICANN 2021&quot;" target="&quot;NICOLAS TROUVAIN&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Nicolas Trouvain is an author of a guide presented at ICANN 2021."</data>
      <data key="d6">25743a99f36f3e56551ffafbba8d15c4</data>
    </edge>
    <edge source="&quot;XAVIER HINAUT&quot;" target="&quot;INRIA BORDEAUX SUD-OUEST&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Xavier Hinaut works at Inria Bordeaux Sud-Ouest, contributing to reservoirpy."</data>
      <data key="d6">18910a60b2547ec3133340f42c45bb47</data>
    </edge>
    <edge source="&quot;XAVIER HINAUT&quot;" target="&quot;IMN&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Xavier Hinaut works at IMN, a department at Inria Bordeaux Sud-Ouest, contributing to reservoirpy."</data>
      <data key="d6">18910a60b2547ec3133340f42c45bb47</data>
    </edge>
    <edge source="&quot;XAVIER HINAUT&quot;" target="&quot;LABRI&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Xavier Hinaut works at LaBRI, a research unit at Inria Bordeaux Sud-Ouest, contributing to reservoirpy."</data>
      <data key="d6">18910a60b2547ec3133340f42c45bb47</data>
    </edge>
    <edge source="&quot;XAVIER HINAUT&quot;" target="&quot;CANARY SONG DECODER RESEARCH&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Xavier Hinaut is an author of a research paper on canary song decoder: transduction and implicit segmentation with esns and ltsms."</data>
      <data key="d6">7751d435f46a6d4027a1c96edabb9626</data>
    </edge>
    <edge source="&quot;HP_SPACE&quot;" target="&quot;N&quot;">
      <data key="d4">2.0</data>
      <data key="d5">"hp_space is the configuration parameter that explores the N parameter, which represents the number of neurons."
"hp_space is associated with the parameter N, which specifies the number of neurons."</data>
      <data key="d6">5cea9edfd65fcfa25a081554300b28cc,adfc38e9dc5e6fd0fe67ce83dfa1f154</data>
    </edge>
    <edge source="&quot;HP_SPACE&quot;" target="&quot;SR&quot;">
      <data key="d4">2.0</data>
      <data key="d5">"hp_space is the configuration parameter that explores the sr parameter, which represents the spectral radius."
"hp_space is associated with the parameter sr, which specifies the spectral radius."</data>
      <data key="d6">5cea9edfd65fcfa25a081554300b28cc,adfc38e9dc5e6fd0fe67ce83dfa1f154</data>
    </edge>
    <edge source="&quot;HP_SPACE&quot;" target="&quot;LR&quot;">
      <data key="d4">2.0</data>
      <data key="d5">"hp_space is the configuration parameter that explores the lr parameter, which represents the leaking rate."
"hp_space is associated with the parameter lr, which specifies the leaking rate."</data>
      <data key="d6">5cea9edfd65fcfa25a081554300b28cc,adfc38e9dc5e6fd0fe67ce83dfa1f154</data>
    </edge>
    <edge source="&quot;HP_SPACE&quot;" target="&quot;JSAN.DUMP()&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"jsan.dump() is used to serialize the hyperopt_config object, which includes parameters explored by hp_space."</data>
      <data key="d6">80033e741d8e10abdcfe20dd17192152</data>
    </edge>
    <edge source="&quot;HP_SPACE&quot;" target="&quot;HYPEROPT-MULTISCROLL&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"hyperopt-multiscroll is associated with the parameter hp_space, which specifies the ranges of parameters explored."</data>
      <data key="d6">adfc38e9dc5e6fd0fe67ce83dfa1f154</data>
    </edge>
    <edge source="&quot;SR&quot;" target="&quot;HYPER-PARAMETER EXPLORATION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Support Vector Regression (SR) is one of the models used in Hyper-parameter Exploration."</data>
      <data key="d6">136d135c710f6cf78a4c536d43276fe1</data>
    </edge>
    <edge source="&quot;LR&quot;" target="&quot;HYPER-PARAMETER EXPLORATION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Logistic Regression (LR) is one of the models used in Hyper-parameter Exploration."</data>
      <data key="d6">136d135c710f6cf78a4c536d43276fe1</data>
    </edge>
    <edge source="&quot;TRAINING SERIES&quot;" target="&quot;TESTING SERIES&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The dataset is split into a training series and a testing series for model training and evaluation."</data>
      <data key="d6">80033e741d8e10abdcfe20dd17192152</data>
    </edge>
    <edge source="&quot;TRAINING SERIES&quot;" target="&quot;K-FOLD&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"K-fold cross-validation is a technique used to assess the model's performance by training it multiple times on different subsets of the data."</data>
      <data key="d6">80033e741d8e10abdcfe20dd17192152</data>
    </edge>
    <edge source="&quot;JSON.DUMP&quot;" target="&quot;HYPEROPT_CONFIG&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"json.dump is used to serialize the hyperopt_config object and write it to a file."</data>
      <data key="d6">1db191f05801d40d5a346febd10d3352</data>
    </edge>
    <edge source="&quot;OBJECTIVE&quot;" target="&quot;RESEARCH&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The objective function is used as a parameter in the research function to perform hyperparameter optimization."</data>
      <data key="d6">1db191f05801d40d5a346febd10d3352</data>
    </edge>
    <edge source="&quot;OBJECTIVE&quot;" target="&quot;BEST&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Objective is the objective function used in the hyperparameter optimization process to find the best hyperparameters."</data>
      <data key="d6">0982b8d1eb1e636b19fa2e9d9361e566</data>
    </edge>
    <edge source="&quot;LOSS FUNCTION&quot;" target="&quot;AUTHOR&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The author mentions the use of the Loss Function in the context of the Objective Function."</data>
      <data key="d6">11749b7d0fdadf05ea29da6025618407</data>
    </edge>
    <edge source="&quot;HYPERPARAMETERS&quot;" target="&quot;AUTHOR&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The author presents a basic example of optimizing hyperparameters using Hyperopt and ReservoirPy.hyper tools."</data>
      <data key="d6">73e81fd6509a2ba400a8435793ade3c5</data>
    </edge>
    <edge source="&quot;HYPERPARAMETERS&quot;" target="&quot;OPTIMIZATION TOOLS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Optimization Tools are used to find the best values for hyperparameters, such as the Leaking Rate, to improve the performance of the model."</data>
      <data key="d6">2d8ea1123f365fb047b024022ba4fdc4</data>
    </edge>
    <edge source="&quot;HYPER-PARAMETER EXPLORATION&quot;" target="&quot;R^2 SCORE&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"R^2 Score is a statistical measure used during hyper-parameter exploration to assess the proportion of the variance explained by a machine learning model."</data>
      <data key="d6">716940af834825642e01a3cb59a7e006</data>
    </edge>
    <edge source="&quot;HYPER-PARAMETER EXPLORATION&quot;" target="&quot;LEARNING RATE&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Learning Rate is a hyper-parameter that can be explored during the hyper-parameter exploration process to optimize the learning rate of a machine learning model."</data>
      <data key="d6">716940af834825642e01a3cb59a7e006</data>
    </edge>
    <edge source="&quot;HYPER-PARAMETER EXPLORATION&quot;" target="&quot;RIDGE REGULARIZATION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Ridge Regularization is a technique that can be explored during the hyper-parameter exploration process to prevent overfitting in machine learning models by adding a penalty term to the loss function."</data>
      <data key="d6">716940af834825642e01a3cb59a7e006</data>
    </edge>
    <edge source="&quot;HYPER-PARAMETER EXPLORATION&quot;" target="&quot;R&#178; SCORE&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"During Hyper-parameter Exploration, the R&#178; Score is maximized to improve the model's explanatory power."</data>
      <data key="d6">136d135c710f6cf78a4c536d43276fe1</data>
    </edge>
    <edge source="&quot;REGRESSION&quot;" target="&quot;CLASSIFICATION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Regression and classification are two different tasks with distinct objectives. Regression models predict continuous variables, while classification models assign data points to predefined categories."</data>
      <data key="d6">1c462a6eef00aac37dc1ab33a689b930</data>
    </edge>
    <edge source="&quot;REGRESSION&quot;" target="&quot;STATISTICAL LEARNING THEORY&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Regression is a statistical technique that is viewed as a supervised learning problem within the framework of Statistical Learning Theory."</data>
      <data key="d6">9261efcc24379d9c0b2d35a2fde8275d</data>
    </edge>
    <edge source="&quot;CLASSIFICATION&quot;" target="&quot;SCIKITLEARNNODE&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Classification is a method that can benefit from the integration of Scikit-Learn models through the use of ScikitLearnNode in ReservoirPy."</data>
      <data key="d6">c05906c1f12c4edfc32a04aa9935067e</data>
    </edge>
    <edge source="&quot;CLASSIFICATION&quot;" target="&quot;STATISTICAL LEARNING THEORY&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Classification is a statistical problem that is viewed as a supervised learning problem within the framework of Statistical Learning Theory."</data>
      <data key="d6">9261efcc24379d9c0b2d35a2fde8275d</data>
    </edge>
    <edge source="&quot;CLASSIFICATION&quot;" target="&quot;HAND MOVEMENTS IN SIGN&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Hand Movements in Sign is a technique used for identifying words based on a series of hand movements, which can be viewed as a classification problem."</data>
      <data key="d6">9261efcc24379d9c0b2d35a2fde8275d</data>
    </edge>
    <edge source="&quot;CLASSIFICATION&quot;" target="&quot;SIGNAL ESTIMATION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Classification and Signal Estimation are related concepts, as both involve the analysis and interpretation of data patterns, although in different contexts."</data>
      <data key="d6">423d3b5ec1acc9a4cb448a15d3b6b595</data>
    </edge>
    <edge source="&quot;REGRESSION MODELS&quot;" target="&quot;LOGISTIC REGRESSION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Regression Models include Logistic Regression, which is used to predict probabilities and can be part of a classifier."</data>
      <data key="d6">d1617d5101da7c02e732e53860c49383</data>
    </edge>
    <edge source="&quot;SVM&quot;" target="&quot;CLASSIFICATION ALGORITHMS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"SVM is a type of classification algorithm that does not provide probabilities."</data>
      <data key="d6">d1617d5101da7c02e732e53860c49383</data>
    </edge>
    <edge source="&quot;LINEAR PREDICTION COEFFICIENT (LPC)&quot;" target="&quot;LINEAR PREDICTIVE CODING (LPC)&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Linear Prediction Coefficient (LPC) is a concept used in Linear Predictive Coding (LPC), which is a method for signal representation and analysis."</data>
      <data key="d6">d1617d5101da7c02e732e53860c49383</data>
    </edge>
    <edge source="&quot;LINEAR PREDICTIVE CODING (LPC)&quot;" target="&quot;CEPSTRAL DOMAIN&quot;">
      <data key="d4">2.0</data>
      <data key="d5">"Linear Predictive Coding (LPC) and the Cepstral Domain are both signal processing techniques, but their specific relationship is not explicitly stated in the text."
"The cepstral domain is a representation of a signal that separates the source and filter characteristics, which can be beneficial for tasks such as pitch detection. LPC is a method used to represent the spectral envelope of a signal, making it relevant to the cepstral domain."</data>
      <data key="d6">c1ba6d7a4f4bd16c4fd25baf07c9747c,d1617d5101da7c02e732e53860c49383</data>
    </edge>
    <edge source="&quot;LINEAR PREDICTIVE CODING (LPC)&quot;" target="&quot;LINEAR PREDICTION COEFFICIENTS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"LPC is a process that results in Linear Prediction Coefficients, which are used for signal representation and analysis."</data>
      <data key="d6">c1ba6d7a4f4bd16c4fd25baf07c9747c</data>
    </edge>
    <edge source="&quot;SCIKITLEARNNODE&quot;" target="&quot;LASSO REGRESSION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"ScikitLearnNode allows the integration of Lasso Regression models into ReservoirPy workflows, enabling the combination of reservoir computing with Scikit-Learn&#8217;s machine learning algorithms."</data>
      <data key="d6">84cacfea14ea9ff46a34150e77a0767a</data>
    </edge>
    <edge source="&quot;SCIKITLEARNNODE&quot;" target="&quot;LINEAR_MODEL.LASSO&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"ScikitLearnNode is used to implement the linear_model.Lasso machine learning model."</data>
      <data key="d6">dddc79e4cd04d2d07e35930dd8458168</data>
    </edge>
    <edge source="&quot;SCIKITLEARNNODE&quot;" target="&quot;LINEAR_MODEL.PASSIVEAGGRESSIVEREGRESSOR&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"ScikitLearnNode is used to interface with the linear_model.PassiveAggressiveRegressor machine learning model."</data>
      <data key="d6">ee83abbbbc707d8131952b2b01ebc268</data>
    </edge>
    <edge source="&quot;SCIKITLEARNNODE&quot;" target="&quot;PASSIVEAGGRESSIVEREGRESSOR&quot;">
      <data key="d4">2.0</data>
      <data key="d5">"ScikitLearnNode provides an interface to the PassiveAggressiveRegressor model from scikit-learn."
"ScikitLearnNode is used to initialize a node with the PassiveAggressiveRegressor model."</data>
      <data key="d6">2cba60e2f36479613bb0243a19f3a3b4,35631fbf2ad11c53d75cb9b42e2c39b4</data>
    </edge>
    <edge source="&quot;SCIKITLEARNNODE&quot;" target="&quot;RIDGECLASSIFIER&quot;">
      <data key="d4">2.0</data>
      <data key="d5">"ScikitLearnNode provides an interface to the RidgeClassifier model from scikit-learn."
"ScikitLearnNode is used to initialize a node with the RidgeClassifier model."</data>
      <data key="d6">2cba60e2f36479613bb0243a19f3a3b4,35631fbf2ad11c53d75cb9b42e2c39b4</data>
    </edge>
    <edge source="&quot;SCIKITLEARNNODE&quot;" target="&quot;LOGISTICREGRESSION&quot;">
      <data key="d4">2.0</data>
      <data key="d5">"ScikitLearnNode provides an interface to the LogisticRegression model from scikit-learn."
"ScikitLearnNode is used to initialize a node with the LogisticRegression model."</data>
      <data key="d6">2cba60e2f36479613bb0243a19f3a3b4,35631fbf2ad11c53d75cb9b42e2c39b4</data>
    </edge>
    <edge source="&quot;SCIKITLEARNNODE&quot;" target="&quot;LINEAR MODEL&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"ScikitLearnNode uses the Linear Model component to create a machine learning model."</data>
      <data key="d6">dc3bd3697a140b64d70e0e3ac6db6c7e</data>
    </edge>
    <edge source="&quot;SCIKITLEARNNODE&quot;" target="&quot;LASSO&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"ScikitLearnNode uses the Lasso type of linear model to create a machine learning model."</data>
      <data key="d6">dc3bd3697a140b64d70e0e3ac6db6c7e</data>
    </edge>
    <edge source="&quot;REGRESSION METHODS&quot;" target="&quot;CLASSIFICATION TASKS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Regression Methods are not well-suited for Classification Tasks due to the impact of Outlier Data on the Decision Boundary."</data>
      <data key="d6">dadca3c89b34dc48a60c53367ab55768</data>
    </edge>
    <edge source="&quot;CLASSIFICATION TASKS&quot;" target="&quot;RIDGECLASSIFIER&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"RidgeClassifier is a suitable algorithm for Classification Tasks as it applies regularization to prevent overfitting."</data>
      <data key="d6">dadca3c89b34dc48a60c53367ab55768</data>
    </edge>
    <edge source="&quot;CLASSIFICATION TASKS&quot;" target="&quot;LOGISTICREGRESSION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"LogisticRegression is a suitable algorithm for Classification Tasks as it models the probability of data points belonging to specific classes."</data>
      <data key="d6">dadca3c89b34dc48a60c53367ab55768</data>
    </edge>
    <edge source="&quot;CLASSIFICATION TASKS&quot;" target="&quot;ARGMAX() FUNCTION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The argmax() function is used in Classification Tasks to find the indices of the maximum values along an axis in a given array, which can be used to determine the predicted class."</data>
      <data key="d6">dadca3c89b34dc48a60c53367ab55768</data>
    </edge>
    <edge source="&quot;RIDGECLASSIFIER&quot;" target="&quot;DECISION BOUNDARY&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The RidgeClassifier can be used to significantly shift the Decision Boundary when handling outlier data."</data>
      <data key="d6">d58662ee42c14a0787d839ebfd0a6e9b</data>
    </edge>
    <edge source="&quot;RIDGECLASSIFIER&quot;" target="&quot;JAPANESE_VOWELS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The japanese_vowels dataset is used for training a RidgeClassifier model."</data>
      <data key="d6">2cba60e2f36479613bb0243a19f3a3b4</data>
    </edge>
    <edge source="&quot;LOGISTICREGRESSION&quot;" target="&quot;JAPANESE_VOWELS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The japanese_vowels dataset is used for training a LogisticRegression model."</data>
      <data key="d6">2cba60e2f36479613bb0243a19f3a3b4</data>
    </edge>
    <edge source="&quot;JAPANESE_VOWELS() FUNCTION&quot;" target="&quot;REPEAT_TARGETS PARAMETER&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The repeat_targets parameter in the japanese_vowels() function ensures that one label is obtained per timestep, not one label per utterance."</data>
      <data key="d6">dadca3c89b34dc48a60c53367ab55768</data>
    </edge>
    <edge source="&quot;HYPERPARAMETER EXPLORATION&quot;" target="&quot;MACKEY-GLASS TIME SERIES PREDICTION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Hyperparameter Exploration is used to optimize the performance of Mackey-Glass Time Series Prediction."</data>
      <data key="d6">1315547792fcb5d618913a4c7ac03511</data>
    </edge>
    <edge source="&quot;HYPERPARAMETER EXPLORATION&quot;" target="&quot;LORENZ TIME SERIES PREDICTION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Hyperparameter Exploration is used to optimize the performance of Lorenz Time Series Prediction."</data>
      <data key="d6">1315547792fcb5d618913a4c7ac03511</data>
    </edge>
    <edge source="&quot;HYPERPARAMETER EXPLORATION&quot;" target="&quot;HYPERPARAMETER INTERDEPENDENCY PLOTS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Hyperparameter Interdependency Plots are used as a tool in the Hyperparameter Exploration process to evaluate the interdependencies between hyperparameters."</data>
      <data key="d6">1315547792fcb5d618913a4c7ac03511</data>
    </edge>
    <edge source="&quot;HYPERPARAMETER INTERDEPENDENCY PLOTS&quot;" target="&quot;HYPERPARAMETER SEARCH METHOD&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Hyperparameter Interdependency Plots are used to evaluate the Hyperparameter Search Method and manage the interdependencies between hyperparameters."</data>
      <data key="d6">4ea4de00090795130d7ae12a57a729ec</data>
    </edge>
    <edge source="&quot;HYPERPARAMETER SEARCH METHOD&quot;" target="&quot;MACKEY-GLASS TIME SERIES&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Hyperparameter Search Method is used to optimize the prediction of Mackey-Glass Time Series."</data>
      <data key="d6">4ea4de00090795130d7ae12a57a729ec</data>
    </edge>
    <edge source="&quot;HYPERPARAMETER SEARCH METHOD&quot;" target="&quot;LORENZ TIME SERIES&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Hyperparameter Search Method is used to optimize the prediction of Lorenz Time Series."</data>
      <data key="d6">4ea4de00090795130d7ae12a57a729ec</data>
    </edge>
    <edge source="&quot;HYPERPARAMETER SEARCH METHOD&quot;" target="&quot;TEST DOCUMENT RECEPTION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Test Document Reception is a test used to evaluate the effectiveness of the Hyperparameter Search Method."</data>
      <data key="d6">4ea4de00090795130d7ae12a57a729ec</data>
    </edge>
    <edge source="&quot;MACKEY-GLASS TIME SERIES&quot;" target="&quot;TASK 1: 10 TIMESTEPS AHEAD FORECAST&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Mackey-Glass Time Series is the data set used in Task 1 to predict 10 timesteps ahead."</data>
      <data key="d6">fac681bdc38ae5829173c747ee6240fa</data>
    </edge>
    <edge source="&quot;MACKEY-GLASS TIME SERIES&quot;" target="&quot;DATA PREPROCESSING&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Mackey-Glass Time Series dataset is used for data preprocessing, such as converting it into a forecasting format."</data>
      <data key="d6">b2beacacc8c190393e4583a69518378c</data>
    </edge>
    <edge source="&quot;MACKEY-GLASS TASK&quot;" target="&quot;THE MODEL&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The model is trained on the Mackey-Glass task to predict time series data."</data>
      <data key="d6">b3c8de6f33c2ebb84f0d2797933d0cad</data>
    </edge>
    <edge source="&quot;THE MODEL&quot;" target="&quot;THE AUTHOR&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The author creates the model and evaluates its performance."</data>
      <data key="d6">b3c8de6f33c2ebb84f0d2797933d0cad</data>
    </edge>
    <edge source="&quot;CASTING(MG, FORECAST=10, TEST_SIZE=0.2)&quot;" target="&quot;ESN PREDICTION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The casting(mg, forecast=10, test_size=0.2) process involves generating ESN predictions."</data>
      <data key="d6">ee83abbbbc707d8131952b2b01ebc268</data>
    </edge>
    <edge source="&quot;ESN PREDICTION&quot;" target="&quot;TRUE VALUE&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"ESN predictions are compared to the True value in data analysis or modeling."</data>
      <data key="d6">ee83abbbbc707d8131952b2b01ebc268</data>
    </edge>
    <edge source="&quot;ESN PREDICTION&quot;" target="&quot;RSQUARE(Y_TEST, Y_PRED)&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"rsquare(y_test, y_pred) is used to evaluate the goodness of fit of the ESN prediction model."</data>
      <data key="d6">ee83abbbbc707d8131952b2b01ebc268</data>
    </edge>
    <edge source="&quot;ESN PREDICTION&quot;" target="&quot;NRMSE(Y_TEST, Y_PRED)&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"nrmse(y_test, y_pred) is used to evaluate the accuracy of the ESN prediction model."</data>
      <data key="d6">ee83abbbbc707d8131952b2b01ebc268</data>
    </edge>
    <edge source="&quot;PASSIVEAGGRESSIVEREGRESSOR&quot;" target="&quot;SCIKIT-LEARN NODE&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Scikit-learn Node is a wrapper for using the PassiveAggressiveRegressor model from scikit-learn."</data>
      <data key="d6">52d001cd1786e3d9f36e0c57538bc21e</data>
    </edge>
    <edge source="&quot;MACKEY-GLASS&quot;" target="&quot;TIMESERIES PREDICTION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Mackey-Glass is a chaotic system used as an example for timeseries prediction, demonstrating the capabilities of reservoir computing algorithms."</data>
      <data key="d6">0b6c69085074b2cf23267eb149068b9f</data>
    </edge>
    <edge source="&quot;TROUVAIN ET AL.&quot;" target="&quot;EXPLORING HYPERPARAMETERS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Trouvain et al. are authors of a paper that explores hyperparameters."</data>
      <data key="d6">280cbdf53022bbaed48ccb34ebe142bc</data>
    </edge>
    <edge source="&quot;HINAUT ET AL.&quot;" target="&quot;EXPLORING HYPERPARAMETERS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Hinaut et al. provide advice on exploring hyperparameters."</data>
      <data key="d6">280cbdf53022bbaed48ccb34ebe142bc</data>
    </edge>
    <edge source="&quot;LEGER ET AL.&quot;" target="&quot;EXPLORING HYPERPARAMETERS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Leger et al. use ReservoirPy for exploring hyperparameters in the context of meta reinforcement learning."</data>
      <data key="d6">280cbdf53022bbaed48ccb34ebe142bc</data>
    </edge>
    <edge source="&quot;CHAIX-EICHEL ET AL.&quot;" target="&quot;EXPLORING HYPERPARAMETERS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Chaix-Eichel et al. use ReservoirPy for exploring hyperparameters in the context of implicit learning and explicit representations."</data>
      <data key="d6">280cbdf53022bbaed48ccb34ebe142bc</data>
    </edge>
    <edge source="&quot;PAGLIARINI ET AL.&quot;" target="&quot;EXPLORING HYPERPARAMETERS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Pagliarini et al. use ReservoirPy for exploring hyperparameters in the context of vocal sensorimotor modeling and low-dimensional GAN generation."</data>
      <data key="d6">280cbdf53022bbaed48ccb34ebe142bc</data>
    </edge>
    <edge source="&quot;PAGLIARINI ET AL.&quot;" target="&quot;ICDL 2021&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Pagliarini et al. presented a paper at ICDL 2021 on Canary Vocal Sensorimotor Model with RNN Decoder and Low-dimensional GAN Generator."</data>
      <data key="d6">20b16c2e1cb8813ade96fea5f9591631</data>
    </edge>
    <edge source="&quot;PAGLIARINI ET AL.&quot;" target="&quot;HAL PREPRINT&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Pagliarini et al. published a paper as a HAL preprint on What does the Canary Say? Low-Dimensional GAN Applied to Birdsong."</data>
      <data key="d6">20b16c2e1cb8813ade96fea5f9591631</data>
    </edge>
    <edge source="&quot;MNEMOSYNE GROUP&quot;" target="&quot;BORDEAUX&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Mnemosyne group is located at Bordeaux, France."</data>
      <data key="d6">2a197220a94bac0b44fc0b07712e45ba</data>
    </edge>
    <edge source="&quot;NATHAN TROUVAIN&quot;" target="&quot;INRIA BORDEAUX SUD-OUEST&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Nathan Trouvain works at Inria Bordeaux Sud-Ouest, contributing to reservoirpy."</data>
      <data key="d6">18910a60b2547ec3133340f42c45bb47</data>
    </edge>
    <edge source="&quot;NATHAN TROUVAIN&quot;" target="&quot;IMN&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Nathan Trouvain works at IMN, a department at Inria Bordeaux Sud-Ouest, contributing to reservoirpy."</data>
      <data key="d6">18910a60b2547ec3133340f42c45bb47</data>
    </edge>
    <edge source="&quot;NATHAN TROUVAIN&quot;" target="&quot;LABRI&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Nathan Trouvain works at LaBRI, a research unit at Inria Bordeaux Sud-Ouest, contributing to reservoirpy."</data>
      <data key="d6">18910a60b2547ec3133340f42c45bb47</data>
    </edge>
    <edge source="&quot;NATHAN TROUVAIN&quot;" target="&quot;CANARY SONG DECODER RESEARCH&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Nathan Trouvain is an author of a research paper on canary song decoder: transduction and implicit segmentation with esns and ltsms."</data>
      <data key="d6">7751d435f46a6d4027a1c96edabb9626</data>
    </edge>
    <edge source="&quot;AUTHOR&quot;" target="&quot;R&#178;&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The author mentions the computation of the R&#178; metric in addition to the Loss Function."</data>
      <data key="d6">11749b7d0fdadf05ea29da6025618407</data>
    </edge>
    <edge source="&quot;AUTHOR&quot;" target="&quot;ROBOT PERFORMANCE EVALUATION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The author discusses the process of evaluating Robot Performance in the text."</data>
      <data key="d6">e7d249cdab85dc69b631d43ac6b62915</data>
    </edge>
    <edge source="&quot;AUTHOR&quot;" target="&quot;CANARY SONG DECODING&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The author mentions the use case of Canary Song Decoding in the text."</data>
      <data key="d6">e7d249cdab85dc69b631d43ac6b62915</data>
    </edge>
    <edge source="&quot;ECHO STATE PROPERTY&quot;" target="&quot;ADDITIVE-SIGMOID NEURON RESERVOIRS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Echo State Property is a property that applies to Additive-Sigmoid Neuron Reservoirs."</data>
      <data key="d6">a9f53979e9dbe6b936ff3374c73006dd</data>
    </edge>
    <edge source="&quot;INPUT SCALING&quot;" target="&quot;REGULARIZATION PARAMETER&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Input Scaling and Regularization Parameter are parameters mentioned in the text, which are fixed."</data>
      <data key="d6">0a9b132ecb1c4b63fdbb0e144295362e</data>
    </edge>
    <edge source="&quot;HYPEROPT-MULTISCROLL&quot;" target="&quot;HP_MAX_EVALS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"hyperopt-multiscroll is associated with the parameter hp_max_evals, which specifies the number of different sets of parameters to try."</data>
      <data key="d6">adfc38e9dc5e6fd0fe67ce83dfa1f154</data>
    </edge>
    <edge source="&quot;HYPEROPT-MULTISCROLL&quot;" target="&quot;HP_METHOD&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"hyperopt-multiscroll is associated with the parameter hp_method, which specifies the method used to choose sets of parameters."</data>
      <data key="d6">adfc38e9dc5e6fd0fe67ce83dfa1f154</data>
    </edge>
    <edge source="&quot;HYPEROPT-MULTISCROLL&quot;" target="&quot;INSTANCES_PER_TRIAL&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"hyperopt-multiscroll is associated with the parameter instances_per_trial, which specifies how many random ESN will be tried with each set of parameters."</data>
      <data key="d6">adfc38e9dc5e6fd0fe67ce83dfa1f154</data>
    </edge>
    <edge source="&quot;Y&quot;" target="&quot;CHAPTER 2&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The variable Y is mentioned in Chapter 2 as output or target data used in the context of the generative mode."</data>
      <data key="d6">e396354e3a9be76616392af11f56e671</data>
    </edge>
    <edge source="&quot;UNITED STATES&quot;" target="&quot;TUBERCULOSIS&quot;">
      <data key="d4">2.0</data>
      <data key="d5">"Tuberculosis incidence rates are mentioned in the context of the United States."
"Tuberculosis incidence data is mentioned in the context of the United States."</data>
      <data key="d6">4b75a8a7637b05307e62f309c682d43b,a2b394d556da06b8c14dd2f5e106343b</data>
    </edge>
    <edge source="&quot;SERIES ANALYSIS&quot;" target="&quot;HEAT MAP MATRICES&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Heat Map Matrices are a visual tool used in Series Analysis to represent time series data."</data>
      <data key="d6">630c86e110e2dabbe068f446b619cef3</data>
    </edge>
    <edge source="&quot;SERIES ANALYSIS&quot;" target="&quot;CURVE FITTING&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Curve Fitting is a technique used in Series Analysis to discover patterns in data over time."</data>
      <data key="d6">630c86e110e2dabbe068f446b619cef3</data>
    </edge>
    <edge source="&quot;SERIES ANALYSIS&quot;" target="&quot;PROCESSES&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Processes are the subject of analysis in Series Analysis, where patterns are discovered over time."</data>
      <data key="d6">630c86e110e2dabbe068f446b619cef3</data>
    </edge>
    <edge source="&quot;CURVE FITTING&quot;" target="&quot;SMOOTHING&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Smoothing is a method used in Curve Fitting to construct a 'smooth' function that approximately fits the data."</data>
      <data key="d6">630c86e110e2dabbe068f446b619cef3</data>
    </edge>
    <edge source="&quot;FUNCTION APPROXIMATION&quot;" target="&quot;POLYNOMIAL REGRESSION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Polynomial Regression is a method used in Function Approximation to model an entire data set with a single polynomial."</data>
      <data key="d6">472b44b36407c9a89cf5c51459188263</data>
    </edge>
    <edge source="&quot;FUNCTION APPROXIMATION&quot;" target="&quot;SPLINE INTERPOLATION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Spline Interpolation is a method used in Function Approximation to model a data set with piecewise continuous functions composed of many polynomials."</data>
      <data key="d6">472b44b36407c9a89cf5c51459188263</data>
    </edge>
    <edge source="&quot;WORLD WAR II&quot;" target="&quot;SIGNAL ESTIMATION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"World War II significantly accelerated the development of mathematical techniques and technologies for signal processing and estimation."</data>
      <data key="d6">423d3b5ec1acc9a4cb448a15d3b6b595</data>
    </edge>
    <edge source="&quot;NORBERT WIENER&quot;" target="&quot;SIGNAL ESTIMATION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Norbert Wiener made significant contributions to signal processing and filtering during World War II, significantly accelerating the development of these techniques."</data>
      <data key="d6">423d3b5ec1acc9a4cb448a15d3b6b595</data>
    </edge>
    <edge source="&quot;RUDOLF E. K&#193;LM&#193;N&quot;" target="&quot;SIGNAL ESTIMATION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Rudolf E. K&#225;lm&#225;n developed the Kalman filter, a mathematical tool for signal estimation and prediction, which was accelerated during World War II."</data>
      <data key="d6">423d3b5ec1acc9a4cb448a15d3b6b595</data>
    </edge>
    <edge source="&quot;DENNIS GABOR&quot;" target="&quot;SIGNAL ESTIMATION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Dennis Gabor contributed to the development of signal processing and spectral density estimation during World War II, accelerating these techniques."</data>
      <data key="d6">423d3b5ec1acc9a4cb448a15d3b6b595</data>
    </edge>
    <edge source="&quot;SIGNAL ESTIMATION&quot;" target="&quot;SEGMENTATION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Segmentation and Signal Estimation are related concepts, as both involve the analysis and processing of time-series data, although in different ways."</data>
      <data key="d6">423d3b5ec1acc9a4cb448a15d3b6b595</data>
    </edge>
    <edge source="&quot;DIGITAL SIGNAL PROCESSING&quot;" target="&quot;TIME-SERIES SEGMENTATION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Time-Series Segmentation is a process mentioned in the context of Digital Signal Processing."</data>
      <data key="d6">5d6a266e9d567f013be17768c04cbc09</data>
    </edge>
    <edge source="&quot;DIGITAL SIGNAL PROCESSING&quot;" target="&quot;TIME-SERIES CLUSTERING&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Time-Series Clustering is a process mentioned in the context of Digital Signal Processing."</data>
      <data key="d6">5d6a266e9d567f013be17768c04cbc09</data>
    </edge>
    <edge source="&quot;TIME-SERIES SEGMENTATION&quot;" target="&quot;CHANGE-POINT DETECTION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Change-Point Detection is a method used in Time-Series Segmentation to identify segment boundary points."</data>
      <data key="d6">5d6a266e9d567f013be17768c04cbc09</data>
    </edge>
    <edge source="&quot;TIME-SERIES SEGMENTATION&quot;" target="&quot;MARKOV JUMP LINEAR SYSTEM&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Markov Jump Linear System is a more sophisticated modeling approach that may be used in Time-Series Segmentation."</data>
      <data key="d6">5d6a266e9d567f013be17768c04cbc09</data>
    </edge>
    <edge source="&quot;TIME-SERIES CLUSTERING&quot;" target="&quot;SUBSEQUENCE TIME-SERIES CLUSTERING&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Time-Series Clustering may involve subsequence clustering, as mentioned in the text."</data>
      <data key="d6">5d6a266e9d567f013be17768c04cbc09</data>
    </edge>
    <edge source="&quot;AUTOREGRESSIVE (AR) MODELS&quot;" target="&quot;AUTOREGRESSIVE MOVING-AVERAGE (ARMA) MODELS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Autoregressive Moving-Average (ARMA) Models combine Autoregressive and Moving-Average concepts."</data>
      <data key="d6">a000a3fbf1f8fad62e4c25b495858c79</data>
    </edge>
    <edge source="&quot;AUTOREGRESSIVE (AR) MODELS&quot;" target="&quot;AUTOREGRESSIVE FRACTIONALLY INTEGRATED MOVING-AVERAGE (ARFIMA) MODELS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Autoregressive Fractionally Integrated Moving-Average (ARFIMA) Models generalize Autoregressive, Integrated, and Moving-Average concepts."</data>
      <data key="d6">a000a3fbf1f8fad62e4c25b495858c79</data>
    </edge>
    <edge source="&quot;INTEGRATED (I) MODELS&quot;" target="&quot;AUTOREGRESSIVE INTEGRATED MOVING-AVERAGE (ARIMA) MODELS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Autoregressive Integrated Moving-Average (ARIMA) Models combine Autoregressive and Integrated concepts with Moving-Average."</data>
      <data key="d6">a000a3fbf1f8fad62e4c25b495858c79</data>
    </edge>
    <edge source="&quot;INTEGRATED (I) MODELS&quot;" target="&quot;AUTOREGRESSIVE FRACTIONALLY INTEGRATED MOVING-AVERAGE (ARFIMA) MODELS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Autoregressive Fractionally Integrated Moving-Average (ARFIMA) Models generalize Autoregressive, Integrated, and Moving-Average concepts."</data>
      <data key="d6">a000a3fbf1f8fad62e4c25b495858c79</data>
    </edge>
    <edge source="&quot;MOVING-AVERAGE (MA) MODELS&quot;" target="&quot;AUTOREGRESSIVE MOVING-AVERAGE (ARMA) MODELS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Autoregressive Moving-Average (ARMA) Models combine Autoregressive and Moving-Average concepts."</data>
      <data key="d6">a000a3fbf1f8fad62e4c25b495858c79</data>
    </edge>
    <edge source="&quot;MOVING-AVERAGE (MA) MODELS&quot;" target="&quot;AUTOREGRESSIVE FRACTIONALLY INTEGRATED MOVING-AVERAGE (ARFIMA) MODELS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Autoregressive Fractionally Integrated Moving-Average (ARFIMA) Models generalize Autoregressive, Integrated, and Moving-Average concepts."</data>
      <data key="d6">a000a3fbf1f8fad62e4c25b495858c79</data>
    </edge>
    <edge source="&quot;VECTOR-VALUED DATA&quot;" target="&quot;MULTIVARIATE TIME-SERIES MODELS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Multivariate Time-Series Models are extensions of univariate models to deal with Vector-Valued Data."</data>
      <data key="d6">a000a3fbf1f8fad62e4c25b495858c79</data>
    </edge>
    <edge source="&quot;MULTIVARIATE TIME-SERIES MODELS&quot;" target="&quot;ARIMA MODELS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Multivariate Time-Series Models are extensions of ARIMA Models that can handle vector-valued data."</data>
      <data key="d6">e5e350429a2ca41c6bfd4aa812e4c391</data>
    </edge>
    <edge source="&quot;MULTIVARIATE TIME-SERIES MODELS&quot;" target="&quot;VAR MODELS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"VAR Models are a type of Multivariate Time-Series Model that stands for Vector Autoregression."</data>
      <data key="d6">e5e350429a2ca41c6bfd4aa812e4c391</data>
    </edge>
    <edge source="&quot;ARIMA MODELS&quot;" target="&quot;ARFIMA MODELS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"ARFIMA Models are an extension of ARIMA Models, generalizing them to include fractionally integrated components."</data>
      <data key="d6">e5e350429a2ca41c6bfd4aa812e4c391</data>
    </edge>
    <edge source="&quot;ARIMA MODELS&quot;" target="&quot;EXOGENOUS TIME-SERIES MODELS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Exogenous Time-Series Models are extensions of ARIMA Models that account for the influence of a 'forcing' time-series."</data>
      <data key="d6">e5e350429a2ca41c6bfd4aa812e4c391</data>
    </edge>
    <edge source="&quot;KANTZ AND SCHREIBER&quot;" target="&quot;NONLINEAR TIME SERIES ANALYSIS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Nonlinear Time Series Analysis is mentioned in the context of references by Kantz and Schreiber."</data>
      <data key="d6">e5e350429a2ca41c6bfd4aa812e4c391</data>
    </edge>
    <edge source="&quot;ABARBANEL&quot;" target="&quot;NONLINEAR TIME SERIES ANALYSIS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Nonlinear Time Series Analysis is mentioned in the context of references by Abarbanel."</data>
      <data key="d6">e5e350429a2ca41c6bfd4aa812e4c391</data>
    </edge>
    <edge source="&quot;NON-LINEAR TIME SERIES MODELS&quot;" target="&quot;AUTOREGRESSIVE CONDITIONAL HETEROSKEDASTICITY (ARCH)&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Non-linear Time Series Models include Autoregressive Conditional Heteroskedasticity (ARCH) as a subcategory for modeling changes in variability over time."</data>
      <data key="d6">7b54e70c4e190dec8a2da85292b3e4af</data>
    </edge>
    <edge source="&quot;AUTOREGRESSIVE CONDITIONAL HETEROSKEDASTICITY (ARCH)&quot;" target="&quot;GARCH&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"GARCH is a specific model within Autoregressive Conditional Heteroskedasticity (ARCH) that predicts variability based on recent past values of the observed series."</data>
      <data key="d6">7b54e70c4e190dec8a2da85292b3e4af</data>
    </edge>
    <edge source="&quot;AUTOREGRESSIVE CONDITIONAL HETEROSKEDASTICITY (ARCH)&quot;" target="&quot;TARCH&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"TARCH is a variant of GARCH that incorporates a threshold to model asymmetric volatility patterns."</data>
      <data key="d6">7b54e70c4e190dec8a2da85292b3e4af</data>
    </edge>
    <edge source="&quot;AUTOREGRESSIVE CONDITIONAL HETEROSKEDASTICITY (ARCH)&quot;" target="&quot;EGARCH&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"EGARCH is a modification of GARCH that allows for the modeling of long-term memory effects in time series data."</data>
      <data key="d6">7b54e70c4e190dec8a2da85292b3e4af</data>
    </edge>
    <edge source="&quot;AUTOREGRESSIVE CONDITIONAL HETEROSKEDASTICITY (ARCH)&quot;" target="&quot;FIGARCH&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"FIGARCH is an extension of GARCH that incorporates fractional integration to handle non-stationary data."</data>
      <data key="d6">7b54e70c4e190dec8a2da85292b3e4af</data>
    </edge>
    <edge source="&quot;AUTOREGRESSIVE CONDITIONAL HETEROSKEDASTICITY (ARCH)&quot;" target="&quot;CGARCH&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"CGARCH is a generalization of GARCH that allows for the modeling of conditional correlations and volatilities in multivariate time series data."</data>
      <data key="d6">7b54e70c4e190dec8a2da85292b3e4af</data>
    </edge>
    <edge source="&quot;WAVELET TRANSFORM BASED METHODS&quot;" target="&quot;LOCALLY STATIONARY WAVELETS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Locally Stationary Wavelets are a subcategory of Wavelet Transform Based Methods that allow for the modeling of non-stationary data by adapting the wavelet basis to local characteristics."</data>
      <data key="d6">7b54e70c4e190dec8a2da85292b3e4af</data>
    </edge>
    <edge source="&quot;WAVELET TRANSFORM BASED METHODS&quot;" target="&quot;WAVELET DECOMPOSED NEURAL NETWORKS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Wavelet Decomposed Neural Networks are a combination of Wavelet Transform Based Methods and Neural Networks that decompose time series data at multiple scales and use neural networks for modeling and prediction."</data>
      <data key="d6">7b54e70c4e190dec8a2da85292b3e4af</data>
    </edge>
    <edge source="&quot;MARKOV SWITCHING MULTIFRACTAL (MSMF)&quot;" target="&quot;VOLATILITY MODELING&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Markov Switching Multifractal (MSMF) techniques are a category of models used to model volatility in financial time series data."</data>
      <data key="d6">7b54e70c4e190dec8a2da85292b3e4af</data>
    </edge>
    <edge source="&quot;WAVELET TRANSFORM&quot;" target="&quot;MULTISCALE TECHNIQUES&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Wavelet Transform is a type of Multiscale Technique used for time-frequency analysis."</data>
      <data key="d6">f5ca4e75341eb9da478381a489ae6058</data>
    </edge>
    <edge source="&quot;HIDDEN MARKOV MODEL&quot;" target="&quot;SKTIME&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Hidden Markov Model is a time series model collected in the Sktime Python package."</data>
      <data key="d6">f5ca4e75341eb9da478381a489ae6058</data>
    </edge>
    <edge source="&quot;ERGODICITY&quot;" target="&quot;STATIONARITY&quot;">
      <data key="d4">2.0</data>
      <data key="d5">"Ergodicity implies Stationarity, but the converse is not necessarily the case."
"Ergodicity implies stationarity, but the converse is not necessarily the case."</data>
      <data key="d6">cd814464801a2b4d72fc06b10de5e865,f5ca4e75341eb9da478381a489ae6058</data>
    </edge>
    <edge source="&quot;TIME-SERIES ANALYSIS&quot;" target="&quot;TOOLS FOR TIME-SERIES ANALYSIS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Time-series Analysis makes use of various tools for investigating time-series data."</data>
      <data key="d6">cd814464801a2b4d72fc06b10de5e865</data>
    </edge>
    <edge source="&quot;TIME-SERIES ANALYSIS&quot;" target="&quot;TIME-FREQUENCY ANALYSIS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Time-series Analysis can be applied where the series are seasonally stationary or non-stationary, and situations where the amplitudes of frequency components change with time can be dealt with in time-frequency analysis."</data>
      <data key="d6">cd814464801a2b4d72fc06b10de5e865</data>
    </edge>
    <edge source="&quot;TIME-SERIES ANALYSIS&quot;" target="&quot;TIME-SERIES METRICS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Time-series Metrics are used for time series classification or regression analysis in the field of time-series analysis."</data>
      <data key="d6">cd814464801a2b4d72fc06b10de5e865</data>
    </edge>
    <edge source="&quot;TIME-SERIES ANALYSIS&quot;" target="&quot;VISUALIZATION TECHNIQUES&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Visualization Techniques are used to present and compare time series data in the field of time-series analysis."</data>
      <data key="d6">cd814464801a2b4d72fc06b10de5e865</data>
    </edge>
    <edge source="&quot;TIME-SERIES METRICS&quot;" target="&quot;MEASURES&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Measures is a category that includes Time-series Metrics, which are used for time series classification or regression analysis."</data>
      <data key="d6">a9c0a1c4d1c08c2c79806dc970186e79</data>
    </edge>
    <edge source="&quot;VISUALIZATION&quot;" target="&quot;PYTHON CODE&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Python Code is used to create visualizations to represent data and results."</data>
      <data key="d6">d15f6d075c072f0335b5332f11c00299</data>
    </edge>
    <edge source="&quot;OVERLAPPING CHARTS&quot;" target="&quot;BRAIDED GRAPHS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Braided Graphs is a type of Overlapping Chart used for visualizing time series data."</data>
      <data key="d6">a9c0a1c4d1c08c2c79806dc970186e79</data>
    </edge>
    <edge source="&quot;OVERLAPPING CHARTS&quot;" target="&quot;LINE CHARTS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Line Charts is a type of Overlapping Chart used for visualizing time series data."</data>
      <data key="d6">a9c0a1c4d1c08c2c79806dc970186e79</data>
    </edge>
    <edge source="&quot;OVERLAPPING CHARTS&quot;" target="&quot;SLOPE GRAPHS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Slope Graphs is a type of Overlapping Chart used for visualizing time series data."</data>
      <data key="d6">a9c0a1c4d1c08c2c79806dc970186e79</data>
    </edge>
    <edge source="&quot;OVERLAPPING CHARTS&quot;" target="&quot;GAPCHART&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"GapChart is a type of Overlapping Chart used for visualizing time series data."</data>
      <data key="d6">a9c0a1c4d1c08c2c79806dc970186e79</data>
    </edge>
    <edge source="&quot;SEPARATED CHARTS&quot;" target="&quot;HORIZON GRAPHS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Horizon Graphs is a type of Separated Chart used for visualizing time series data."</data>
      <data key="d6">a9c0a1c4d1c08c2c79806dc970186e79</data>
    </edge>
    <edge source="&quot;SEPARATED CHARTS&quot;" target="&quot;REDUCED LINE CHART&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Reduced Line Chart, also known as Small Multiples, is a type of Separated Chart used for visualizing time series data."</data>
      <data key="d6">a9c0a1c4d1c08c2c79806dc970186e79</data>
    </edge>
    <edge source="&quot;SEPARATED CHARTS&quot;" target="&quot;SILHOUETTE GRAPH&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Silhouette Graph is a type of Separated Chart used for visualizing time series data."</data>
      <data key="d6">a9c0a1c4d1c08c2c79806dc970186e79</data>
    </edge>
    <edge source="&quot;SEPARATED CHARTS&quot;" target="&quot;CIRCULAR SILHOUETTE GRAPH&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Circular Silhouette Graph is a type of Separated Chart used for visualizing time series data, which is a variation of the Silhouette Graph."</data>
      <data key="d6">a9c0a1c4d1c08c2c79806dc970186e79</data>
    </edge>
    <edge source="&quot;ECHO STATE NETWORK&quot;" target="&quot;HERBERT JAEGER&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Herbert Jaeger is a key figure in the development of Echo State Networks."</data>
      <data key="d6">804bd76fa6f4950ef9a5cf8f0025fc1c</data>
    </edge>
    <edge source="&quot;ECHO STATE NETWORK&quot;" target="&quot;LIQUID STATE MACHINES&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Liquid State Machines and Echo State Networks share similarities in their architecture and development."</data>
      <data key="d6">804bd76fa6f4950ef9a5cf8f0025fc1c</data>
    </edge>
    <edge source="&quot;ECHO STATE NETWORK&quot;" target="&quot;SIGMOID FUNCTION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Echo State Network uses a sigmoid function to map input values to a specific range."</data>
      <data key="d6">cc7c60d8e36838743d509a97c9ac3a4b</data>
    </edge>
    <edge source="&quot;ECHO STATE NETWORK&quot;" target="&quot;RESERVOIR WEIGHT MATRIX&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Echo State Network uses the Reservoir Weight Matrix to update the reservoir state."</data>
      <data key="d6">cc7c60d8e36838743d509a97c9ac3a4b</data>
    </edge>
    <edge source="&quot;ECHO STATE NETWORK&quot;" target="&quot;INPUT WEIGHT MATRIX&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Echo State Network uses the Input Weight Matrix to map input signals to the reservoir state."</data>
      <data key="d6">cc7c60d8e36838743d509a97c9ac3a4b</data>
    </edge>
    <edge source="&quot;ECHO STATE NETWORK&quot;" target="&quot;OUTPUT FEEDBACK MATRIX&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Echo State Network uses the Output Feedback Matrix to provide feedback from the output signal to the reservoir state."</data>
      <data key="d6">cc7c60d8e36838743d509a97c9ac3a4b</data>
    </edge>
    <edge source="&quot;ECHO STATE NETWORK&quot;" target="&quot;JAEGER&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Jaeger is mentioned in the text as a contributor to the development of Echo State Networks."</data>
      <data key="d6">2dca9849c50a439b0637cf370afde7dd</data>
    </edge>
    <edge source="&quot;ECHO STATE NETWORK&quot;" target="&quot;LUKO&#352;EVI&#268;IUS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Luko&#353;evi&#269;ius is mentioned in the text as a writer about practical techniques for optimizing Echo State Networks."</data>
      <data key="d6">2dca9849c50a439b0637cf370afde7dd</data>
    </edge>
    <edge source="&quot;ECHO STATE NETWORK&quot;" target="&quot;REAL-TIME RECURRENT LEARNING ALGORITHM&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Echo State Network is mentioned in the text in the context of the Real-time Recurrent Learning Algorithm."</data>
      <data key="d6">2dca9849c50a439b0637cf370afde7dd</data>
    </edge>
    <edge source="&quot;ECHO STATE NETWORK&quot;" target="&quot;TIME SERIES PREDICTION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Echo State Networks are commonly used for the task of Time Series Prediction."</data>
      <data key="d6">29f9b2e5fa311519b18e7aef31c68d0a</data>
    </edge>
    <edge source="&quot;ECHO STATE NETWORK&quot;" target="&quot;RESERVOIR COMPUTER&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Echo State Network is a type of Reservoir Computer."</data>
      <data key="d6">dcd6355fc1ed8a61a1b70c50ce60fd36</data>
    </edge>
    <edge source="&quot;ECHO STATE NETWORK&quot;" target="&quot;SPARSELY CONNECTED HIDDEN LAYER&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Echo State Network has a Sparsely Connected Hidden Layer."</data>
      <data key="d6">dcd6355fc1ed8a61a1b70c50ce60fd36</data>
    </edge>
    <edge source="&quot;ECHO STATE NETWORK&quot;" target="&quot;AURESERVOIR&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Echo State Network is implemented using the aureservoir library."</data>
      <data key="d6">dcd6355fc1ed8a61a1b70c50ce60fd36</data>
    </edge>
    <edge source="&quot;HERBERT JAEGER&quot;" target="&quot;JACOBS UNIVERSITY BREMEN&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Herbert Jaeger is affiliated with Jacobs University Bremen."</data>
      <data key="d6">804bd76fa6f4950ef9a5cf8f0025fc1c</data>
    </edge>
    <edge source="&quot;HERBERT JAEGER&quot;" target="&quot;CORR&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Herbert Jaeger is an author of a research paper published in CoRR."</data>
      <data key="d6">c8b7bd13cf99920ecce56cb563910cb3</data>
    </edge>
    <edge source="&quot;HERBERT JAEGER&quot;" target="&quot;CORR, ABS/1403.3369, 2014&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Herbert Jaeger published a paper on controlling recurrent neural networks by conceptors."</data>
      <data key="d6">546551fd625e354e9afe1245e060bed3</data>
    </edge>
    <edge source="&quot;JACOBS UNIVERSITY BREMEN&quot;" target="&quot;BREMEN&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Jacobs University Bremen is located in Bremen."</data>
      <data key="d6">804bd76fa6f4950ef9a5cf8f0025fc1c</data>
    </edge>
    <edge source="&quot;BREMEN&quot;" target="&quot;GERMANY&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Bremen is a city located in Germany."</data>
      <data key="d6">804bd76fa6f4950ef9a5cf8f0025fc1c</data>
    </edge>
    <edge source="&quot;LIQUID STATE MACHINES&quot;" target="&quot;WOLFGANG MAASS&quot;">
      <data key="d4">3.0</data>
      <data key="d5">"Wolfgang Maass is a key figure in the development of Liquid State Machines."
"Wolfgang Maass is the developer of Liquid State Machines, which are related to Echo State Networks and Reservoir Computing."
"Wolfgang Maass independently developed Liquid State Machines."</data>
      <data key="d6">158f53cd85edbb4f2e4c77b78c5e7acc,804bd76fa6f4950ef9a5cf8f0025fc1c,b32958d42199d47252887dc7be40ab5a</data>
    </edge>
    <edge source="&quot;WOLFGANG MAASS&quot;" target="&quot;GREGOR M. HOERZER&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Gregor M. Hoerzer and Wolfgang Maass co-authored a scientific paper on a specific topic, but the relationship description is not explicitly stated in the text."</data>
      <data key="d6">ce7b58ffc7f43f36bc78154597d01903</data>
    </edge>
    <edge source="&quot;WOLFGANG MAASS&quot;" target="&quot;NEURAL COMPUTATION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Wolfgang Maass is an author of a research paper mentioned in the text, but no specific publication is mentioned."</data>
      <data key="d6">c8b7bd13cf99920ecce56cb563910cb3</data>
    </edge>
    <edge source="&quot;BACKPROPAGATION DECORRELATION LEARNING RULE&quot;" target="&quot;SCHILLER AND STEIL&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Schiller and Steil demonstrated the use of the Backpropagation Decorrelation learning rule for RNNs, which is related to Reservoir Computing."</data>
      <data key="d6">158f53cd85edbb4f2e4c77b78c5e7acc</data>
    </edge>
    <edge source="&quot;PETER F. DOMINEY&quot;" target="&quot;SEQUENCE PROCESSING&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Peter F. Dominey analyzed a process related to the modeling of sequence processing in the mammalian brain."</data>
      <data key="d6">b32958d42199d47252887dc7be40ab5a</data>
    </edge>
    <edge source="&quot;L. SCHOMAKER&quot;" target="&quot;RESERVOIR COMPUTING IDEA&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"L. Schomaker contributed to the development of the reservoir computing idea."</data>
      <data key="d6">a621b44739e0cb4379645a4a58f16697</data>
    </edge>
    <edge source="&quot;RNN&quot;" target="&quot;TRAINING INPUT-OUTPUT SEQUENCE&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The RNN is trained using the Training Input-Output Sequence to behave as a tunable frequency generator."</data>
      <data key="d6">a621b44739e0cb4379645a4a58f16697</data>
    </edge>
    <edge source="&quot;RNN&quot;" target="&quot;LINEAR CHAIN&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"RNNs have a structure that corresponds to a linear chain."</data>
      <data key="d6">7b6ff30ef255db2d2c68326d78cf0115</data>
    </edge>
    <edge source="&quot;RNN&quot;" target="&quot;SECOND-ORDER RNNS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Recurrent Neural Networks (RNN) are used in the development of Second-order RNNs."</data>
      <data key="d6">4470a7f7ad60a2866b31907a2a3ca96e</data>
    </edge>
    <edge source="&quot;RNN&quot;" target="&quot;LONG SHORT-TERM MEMORY (LSTM)&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Recurrent Neural Networks (RNN) are used in the development of Long short-term memory (LSTM)."</data>
      <data key="d6">4470a7f7ad60a2866b31907a2a3ca96e</data>
    </edge>
    <edge source="&quot;RNN&quot;" target="&quot;BPTT&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"BPTT is a method for training RNNs that uses backpropagation through time."</data>
      <data key="d6">1aec5b03f663d1614b2ecbf97981a5c2</data>
    </edge>
    <edge source="&quot;RNN&quot;" target="&quot;RTRL&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"RTRL is a method for training RNNs that uses real-time recursive learning."</data>
      <data key="d6">1aec5b03f663d1614b2ecbf97981a5c2</data>
    </edge>
    <edge source="&quot;RNN&quot;" target="&quot;LSTM&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"LSTM is a variant of RNN that addresses the vanishing gradients problem."</data>
      <data key="d6">1aec5b03f663d1614b2ecbf97981a5c2</data>
    </edge>
    <edge source="&quot;RNN&quot;" target="&quot;INDRNN&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"IndRNN is a variant of RNN that reduces the context of a neuron to its own past state."</data>
      <data key="d6">1aec5b03f663d1614b2ecbf97981a5c2</data>
    </edge>
    <edge source="&quot;SIGMOID FUNCTION&quot;" target="&quot;LOGISTIC SIGMOID&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Logistic Sigmoid is a type of sigmoid function."</data>
      <data key="d6">cc7c60d8e36838743d509a97c9ac3a4b</data>
    </edge>
    <edge source="&quot;SIGMOID FUNCTION&quot;" target="&quot;TANH FUNCTION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Tanh Function is a type of sigmoid function."</data>
      <data key="d6">cc7c60d8e36838743d509a97c9ac3a4b</data>
    </edge>
    <edge source="&quot;DESIRED OUTPUTS&quot;" target="&quot;DESIRED OUTPUT WEIGHTS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Desired Output Weights are the linear regression weights of the desired outputs on the harvested extended states."</data>
      <data key="d6">6a4432cd530b28770e2b903fe242a0d1</data>
    </edge>
    <edge source="&quot;DESIRED OUTPUT WEIGHTS&quot;" target="&quot;PSEUDOINVERSE&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Desired Output Weights can be computed using the pseudoinverse, which is a mathematical operation."</data>
      <data key="d6">6a4432cd530b28770e2b903fe242a0d1</data>
    </edge>
    <edge source="&quot;PSEUDOINVERSE&quot;" target="&quot;OUTPUT WEIGHTS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Pseudoinverse is used in the computation of Output Weights."</data>
      <data key="d6">a9f53979e9dbe6b936ff3374c73006dd</data>
    </edge>
    <edge source="&quot;LINEAR SIGNAL PROCESSING&quot;" target="&quot;OUTPUT WEIGHTS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Linear Signal Processing is mentioned as a method for computing Output Weights."</data>
      <data key="d6">a9f53979e9dbe6b936ff3374c73006dd</data>
    </edge>
    <edge source="&quot;JAEGER 2003&quot;" target="&quot;OUTPUT WEIGHTS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Jaeger 2003 is a reference mentioned as a source for online adaptive methods used to compute Output Weights."</data>
      <data key="d6">a9f53979e9dbe6b936ff3374c73006dd</data>
    </edge>
    <edge source="&quot;ESP&quot;" target="&quot;JAEGER&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Jaeger contributes to the understanding of Echo State Properties, including providing abstract characterizations and algebraic conditions.")</data>
      <data key="d6">3b592e5ac113a5c031925f91a182baa6</data>
    </edge>
    <edge source="&quot;ESP&quot;" target="&quot;BUEHNER&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Buehner contributes to the algebraic conditions for additive-sigmoid neuron reservoirs, which may be relevant to the ESP.")</data>
      <data key="d6">3b592e5ac113a5c031925f91a182baa6</data>
    </edge>
    <edge source="&quot;ESP&quot;" target="&quot;YILDIZ&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Yildiz contributes to the algebraic conditions for a specific subclass of reservoirs, which may be relevant to the ESP.")</data>
      <data key="d6">3b592e5ac113a5c031925f91a182baa6</data>
    </edge>
    <edge source="&quot;ESP&quot;" target="&quot;MANJUNATH&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Manjunath explores the relationship between input signal characteristics and the ESP, providing a fundamental 0-1-law.")</data>
      <data key="d6">3b592e5ac113a5c031925f91a182baa6</data>
    </edge>
    <edge source="&quot;JAEGER&quot;" target="&quot;LEAKY INTEGRATOR NEURONS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Jaeger et al. spell out the algebraic conditions for Leaky Integrator Neurons, which are mentioned in the text.")</data>
      <data key="d6">3b592e5ac113a5c031925f91a182baa6</data>
    </edge>
    <edge source="&quot;JAEGER&quot;" target="&quot;RC NETWORKS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Jaeger is a person who firstly formulated the concept of RC networks."</data>
      <data key="d6">418f92b0dd08e03a20637ffec8193bfc</data>
    </edge>
    <edge source="&quot;SCHMIDHUBER&quot;" target="&quot;LONG SHORT TERM MEMORY&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Schmidhuber is a researcher who made significant contributions to the development of Long Short Term Memory (LSTM) cells for training Recurrent Neural Networks."</data>
      <data key="d6">6de297d888d10db4c987b5eafc6398b2</data>
    </edge>
    <edge source="&quot;SCHMIDHUBER&quot;" target="&quot;BACKPROPAGATION THROUGH TIME&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Schmidhuber developed methods for training recurrent neural networks, including Backpropagation Through Time."</data>
      <data key="d6">0bb54b1de8d2297293defe94addb8076</data>
    </edge>
    <edge source="&quot;SCHMIDHUBER&quot;" target="&quot;REAL-TIME RECURRENT LEARNING&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Schmidhuber contributed to the development of Real-Time Recurrent Learning."</data>
      <data key="d6">6bbaf3df0fa2fac979f6d6a64abb2e91</data>
    </edge>
    <edge source="&quot;TEST ERROR&quot;" target="&quot;VALIDATION SET&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Test Error is a performance metric that is monitored using a Validation Set during model training."</data>
      <data key="d6">e805d3f438bd9c485639f1c69f917ae5</data>
    </edge>
    <edge source="&quot;REAL-TIME RECURRENT LEARNING&quot;" target="&quot;HOCHREITER&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Hochreiter contributed to the development of Real-Time Recurrent Learning."</data>
      <data key="d6">6bbaf3df0fa2fac979f6d6a64abb2e91</data>
    </edge>
    <edge source="&quot;REAL-TIME RECURRENT LEARNING&quot;" target="&quot;PEARLMUTTER&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Pearlmutter contributed to the development of Real-Time Recurrent Learning."</data>
      <data key="d6">6bbaf3df0fa2fac979f6d6a64abb2e91</data>
    </edge>
    <edge source="&quot;BACKPROPAGATION THROUGH TIME&quot;" target="&quot;RECURRENT NEURAL NETWORKS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Backpropagation Through Time is a method used in training Recurrent Neural Networks to calculate gradients."</data>
      <data key="d6">0bb54b1de8d2297293defe94addb8076</data>
    </edge>
    <edge source="&quot;BACKPROPAGATION THROUGH TIME&quot;" target="&quot;WERBOS&quot;">
      <data key="d4">2.0</data>
      <data key="d5">"Werbos developed methods for training recurrent neural networks, including Backpropagation Through Time."
"Werbos contributed to the development of Backpropagation through Time."</data>
      <data key="d6">0bb54b1de8d2297293defe94addb8076,6bbaf3df0fa2fac979f6d6a64abb2e91</data>
    </edge>
    <edge source="&quot;BACKPROPAGATION THROUGH TIME&quot;" target="&quot;WILLIAMS&quot;">
      <data key="d4">2.0</data>
      <data key="d5">"Williams developed methods for training recurrent neural networks, including Backpropagation Through Time."
"Williams contributed to the development of Backpropagation through Time."</data>
      <data key="d6">0bb54b1de8d2297293defe94addb8076,6bbaf3df0fa2fac979f6d6a64abb2e91</data>
    </edge>
    <edge source="&quot;BACKPROPAGATION THROUGH TIME&quot;" target="&quot;ROBINSON&quot;">
      <data key="d4">2.0</data>
      <data key="d5">"Robinson developed methods for training recurrent neural networks, including Backpropagation Through Time."
"Robinson contributed to the development of Backpropagation through Time."</data>
      <data key="d6">0bb54b1de8d2297293defe94addb8076,6bbaf3df0fa2fac979f6d6a64abb2e91</data>
    </edge>
    <edge source="&quot;BACKPROPAGATION THROUGH TIME&quot;" target="&quot;HOCHREITER&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Hochreiter developed methods for training recurrent neural networks, including Backpropagation Through Time."</data>
      <data key="d6">0bb54b1de8d2297293defe94addb8076</data>
    </edge>
    <edge source="&quot;BACKPROPAGATION THROUGH TIME&quot;" target="&quot;PEARLMUTTER&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Pearlmutter developed methods for training recurrent neural networks, including Backpropagation Through Time."</data>
      <data key="d6">0bb54b1de8d2297293defe94addb8076</data>
    </edge>
    <edge source="&quot;OPTICAL MICROCHIPS&quot;" target="&quot;NONLINEAR RESERVOIR&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Optical Microchips are used as a nonlinear reservoir."</data>
      <data key="d6">7767d42e08c8eab856e8e3025c692309</data>
    </edge>
    <edge source="&quot;ARTIFICIAL SOFT LIMBS&quot;" target="&quot;NONLINEAR RESERVOIR&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Artificial Soft Limbs are used as a nonlinear reservoir."</data>
      <data key="d6">7767d42e08c8eab856e8e3025c692309</data>
    </edge>
    <edge source="&quot;B&#220;RGER ET AL.&quot;" target="&quot;ESN METHODS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"B&#252;rger et al. is mentioned in the context of using ESN methods."</data>
      <data key="d6">dbca0570761b1698d32f0c0bfb593b1a</data>
    </edge>
    <edge source="&quot;DALE ET AL.&quot;" target="&quot;ESN METHODS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Dale et al. is mentioned in the context of using ESN methods."</data>
      <data key="d6">dbca0570761b1698d32f0c0bfb593b1a</data>
    </edge>
    <edge source="&quot;NAKAJIMA, HAUSER AND PFEIFER&quot;" target="&quot;ESN METHODS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Nakajima, Hauser and Pfeifer is mentioned in the context of using ESN methods."</data>
      <data key="d6">dbca0570761b1698d32f0c0bfb593b1a</data>
    </edge>
    <edge source="&quot;ESN METHODS&quot;" target="&quot;LIQUID STATE MACHINE&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"ESN methods are mentioned in the same context as Liquid State Machine."</data>
      <data key="d6">dbca0570761b1698d32f0c0bfb593b1a</data>
    </edge>
    <edge source="&quot;ESN METHODS&quot;" target="&quot;RECURRENT NEURAL NETWORKS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"ESN methods are mentioned in the same context as Recurrent Neural Networks."</data>
      <data key="d6">dbca0570761b1698d32f0c0bfb593b1a</data>
    </edge>
    <edge source="&quot;RECURRENT NEURAL NETWORKS&quot;" target="&quot;DAVID RUMELHART&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"David Rumelhart made significant contributions to the development of recurrent neural networks in 1986."</data>
      <data key="d6">f59839daadfb1f3832bb9f8d201a7126</data>
    </edge>
    <edge source="&quot;RECURRENT NEURAL NETWORKS&quot;" target="&quot;NEURAL HISTORY COMPRESSOR SYSTEM&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Neural History Compressor System used a recurrent neural network to solve a 'Very Deep Learning' task in 1993."</data>
      <data key="d6">f59839daadfb1f3832bb9f8d201a7126</data>
    </edge>
    <edge source="&quot;RECURRENT NEURAL NETWORKS&quot;" target="&quot;LONG SHORT-TERM MEMORY&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Long Short-Term Memory is a type of Recurrent Neural Network that uses a mechanism to retain information over long sequences."</data>
      <data key="d6">2bdd28d9e151597072c8490db69b9941</data>
    </edge>
    <edge source="&quot;RECURRENT NEURAL NETWORKS&quot;" target="&quot;BI-DIRECTIONAL RNNS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Bi-directional RNNs are a type of Recurrent Neural Network that use a finite sequence to predict or label each element of the sequence based on the element&#8217;s past and future contexts."</data>
      <data key="d6">2bdd28d9e151597072c8490db69b9941</data>
    </edge>
    <edge source="&quot;RECURRENT NEURAL NETWORKS&quot;" target="&quot;CONTINUOUS-TIME RECURRENT NEURAL NETWORK&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"A Continuous-time Recurrent Neural Network is a type of neural network that uses a system of ordinary differential equations to model the effects on a neuron of the incoming inputs."</data>
      <data key="d6">2bdd28d9e151597072c8490db69b9941</data>
    </edge>
    <edge source="&quot;RECURRENT NEURAL NETWORKS&quot;" target="&quot;HIERARCHICAL RECURRENT NEURAL NETWORK&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Hierarchical Recurrent Neural Network is a type of Recurrent Neural Network that uses multiple layers to process data at different levels of abstraction."</data>
      <data key="d6">2bdd28d9e151597072c8490db69b9941</data>
    </edge>
    <edge source="&quot;RECURRENT NEURAL NETWORKS&quot;" target="&quot;SHANNON SAMPLING THEOREM&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Shannon sampling theorem is mentioned in the context of recurrent neural networks, suggesting a connection between the principles of signal processing and the structure of artificial neural networks."</data>
      <data key="d6">9e61c22432d6984a19da5840f64d417d</data>
    </edge>
    <edge source="&quot;RECURRENT NEURAL NETWORKS&quot;" target="&quot;RECURRENT MULTILAYER PERCEPTRON NETWORK&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"A recurrent multilayer perceptron network is a type of recurrent neural network that consists of cascaded subnetworks, each containing multiple layers of nodes, with feedback connections in the last layer."</data>
      <data key="d6">9e61c22432d6984a19da5840f64d417d</data>
    </edge>
    <edge source="&quot;RECURRENT NEURAL NETWORKS&quot;" target="&quot;NEURAL TURING MACHINES&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Neural Turing machines are a method for extending recurrent neural networks."</data>
      <data key="d6">0f59288ce2aaf33e468cdc3877cefd85</data>
    </edge>
    <edge source="&quot;RECURRENT NEURAL NETWORKS&quot;" target="&quot;RECURSIVE NEURAL NETWORKS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Recursive Neural Networks and Recurrent Neural Networks are both types of neural networks, and their similarities are mentioned in the text."</data>
      <data key="d6">2f1161d1f711d264529aa7bddf81959b</data>
    </edge>
    <edge source="&quot;RECURRENT NEURAL NETWORKS&quot;" target="&quot;FINITE IMPULSE RESPONSE FILTERS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Recurrent Neural Networks are mentioned as a nonlinear version of Finite Impulse Response Filters."</data>
      <data key="d6">2f1161d1f711d264529aa7bddf81959b</data>
    </edge>
    <edge source="&quot;RECURRENT NEURAL NETWORKS&quot;" target="&quot;INFINITE IMPULSE RESPONSE FILTERS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Recurrent Neural Networks are mentioned as a nonlinear version of Infinite Impulse Response Filters."</data>
      <data key="d6">2f1161d1f711d264529aa7bddf81959b</data>
    </edge>
    <edge source="&quot;RECURRENT NEURAL NETWORKS&quot;" target="&quot;NONLINEAR AUTOREGRESSIVE EXOGENOUS MODEL (NARX)&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Recurrent Neural Networks are mentioned as a nonlinear version of Nonlinear Autoregressive Exogenous Model (NARX)."</data>
      <data key="d6">2f1161d1f711d264529aa7bddf81959b</data>
    </edge>
    <edge source="&quot;DOMINEY&quot;" target="&quot;RC NETWORKS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Dominey is a person who contributed to the concept of RC networks in the Neuroscience field."</data>
      <data key="d6">418f92b0dd08e03a20637ffec8193bfc</data>
    </edge>
    <edge source="&quot;HOCHREITER&quot;" target="&quot;LONG SHORT TERM MEMORY&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Hochreiter is a researcher who made significant contributions to the development of Long Short Term Memory (LSTM) cells for training Recurrent Neural Networks."</data>
      <data key="d6">6de297d888d10db4c987b5eafc6398b2</data>
    </edge>
    <edge source="&quot;RC NETWORKS&quot;" target="&quot;MAASS ET AL.&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Maass et al. is an organization that contributed to the formulation of RC networks."</data>
      <data key="d6">418f92b0dd08e03a20637ffec8193bfc</data>
    </edge>
    <edge source="&quot;RC NETWORKS&quot;" target="&quot;BUONOMANO AND MERZENICH&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Buonomano and Merzenich is an organization that contributed to the concept of RC networks in the Neuroscience field."</data>
      <data key="d6">418f92b0dd08e03a20637ffec8193bfc</data>
    </edge>
    <edge source="&quot;DEEP LEARNING FRAMEWORKS&quot;" target="&quot;RNN TECHNIQUES&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"RNN techniques can be easily replicated using popular Deep Learning frameworks."</data>
      <data key="d6">295606b4bc5d12929a913a3c79f93734</data>
    </edge>
    <edge source="&quot;DEEP LEARNING FRAMEWORKS&quot;" target="&quot;RC MODELS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"RC models are often implemented from scratch due to a lack of common libraries, and they do not benefit from the automatic differentiation features of Deep Learning tools."</data>
      <data key="d6">295606b4bc5d12929a913a3c79f93734</data>
    </edge>
    <edge source="&quot;TROUVAIN AND HINAUT&quot;" target="&quot;RNN TECHNIQUES&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Trouvain and Hinaut mention RNN techniques like LSTMs in their comparison of methods with RC models."</data>
      <data key="d6">295606b4bc5d12929a913a3c79f93734</data>
    </edge>
    <edge source="&quot;TROUVAIN AND HINAUT&quot;" target="&quot;RC MODELS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Trouvain and Hinaut mention RC models in their comparison of methods with RNN techniques."</data>
      <data key="d6">295606b4bc5d12929a913a3c79f93734</data>
    </edge>
    <edge source="&quot;RECURRENT OPERATOR&quot;" target="&quot;NODE&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"A Recurrent Operator is a type of Node that maps its internal state and input vector to the next state."</data>
      <data key="d6">dc46bcef51e88747b544f7efb111203a</data>
    </edge>
    <edge source="&quot;LMS&quot;" target="&quot;HOERZER ET AL. (2014)&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"LMS is used in the study referenced by Hoerzer et al. (2014) for online learning."</data>
      <data key="d6">b03e2cc6fe2648e792c1d5f1ec5773a3</data>
    </edge>
    <edge source="&quot;RLS&quot;" target="&quot;SUSSILLO AND ABBOTT (2009)&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"RLS is used in the study referenced by Sussillo and Abbott (2009) for online learning."</data>
      <data key="d6">b03e2cc6fe2648e792c1d5f1ec5773a3</data>
    </edge>
    <edge source="&quot;INTRINSIC PLASTICITY&quot;" target="&quot;STEIL (2007)&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Intrinsic Plasticity mechanism is introduced in the study referenced by Steil (2007)."</data>
      <data key="d6">b03e2cc6fe2648e792c1d5f1ec5773a3</data>
    </edge>
    <edge source="&quot;INTRINSIC PLASTICITY&quot;" target="&quot;SCHRAUWEN ET AL. (2008)&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Intrinsic Plasticity mechanism is further explored in the study referenced by Schrauwen et al. (2008)."</data>
      <data key="d6">b03e2cc6fe2648e792c1d5f1ec5773a3</data>
    </edge>
    <edge source="&quot;NON-LINEAR VECTOR AUTOREGRESSIVE MACHINE&quot;" target="&quot;GAUTHIER ET AL. (202&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Non-Linear Vector Autoregressive machine is introduced in the study referenced by Gauthier et al. (202)."</data>
      <data key="d6">b03e2cc6fe2648e792c1d5f1ec5773a3</data>
    </edge>
    <edge source="&quot;PYRCN&quot;" target="&quot;ELM&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"PyRCN is a software that allows the training of Extreme Learning Machine (ELM), which is similar to ESN where recurrence has been removed."</data>
      <data key="d6">a1adb5de4156f0a4a448caf79056e886</data>
    </edge>
    <edge source="&quot;PYRCN&quot;" target="&quot;LSM&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"PyRCN and LSM are mentioned together, suggesting a relationship or comparison between the two software solutions."</data>
      <data key="d6">a1adb5de4156f0a4a448caf79056e886</data>
    </edge>
    <edge source="&quot;PYRCN&quot;" target="&quot;RESERVOIRCOMPUTING.JL&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Both ReservoirComputing.jl and PyRCN are mentioned in the context of software for Reservoir Computing, suggesting a relationship or comparison between the two."</data>
      <data key="d6">a1adb5de4156f0a4a448caf79056e886</data>
    </edge>
    <edge source="&quot;OGER&quot;" target="&quot;MODULAR LEARNING ARCHITECTURES FOR LARGE-SCALE SEQUENTIAL PROCESSING&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Oger is the publication source for the research paper on modular learning architectures for large-scale sequential processing."</data>
      <data key="d6">b8d8b71875a9ccc508b40fe4aad8d796</data>
    </edge>
    <edge source="&quot;LARS BUITINCK&quot;" target="&quot;API DESIGN FOR MACHINE LEARNING SOFTWARE&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Lars Buitinck is an author of a paper on API design for machine learning software, highlighting experiences from the scikit-learn project."</data>
      <data key="d6">82de30f43839f4985de20a981b524af1</data>
    </edge>
    <edge source="&quot;DV BUONOMANO&quot;" target="&quot;TEMPORAL INFORMATION TRANSFORMATION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"DV Buonomano is an author of a scientific paper on temporal information transformation into a spatial code by a neural network."</data>
      <data key="d6">82de30f43839f4985de20a981b524af1</data>
    </edge>
    <edge source="&quot;DV BUONOMANO&quot;" target="&quot;M. M. MERZENICH&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"DV Buonomano and M. M. Merzenich co-authored a scientific paper on transforming temporal information into a spatial code using a neural network."</data>
      <data key="d6">ce7b58ffc7f43f36bc78154597d01903</data>
    </edge>
    <edge source="&quot;M. M. MERZENICH&quot;" target="&quot;TEMPORAL INFORMATION TRANSFORMATION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"M. M. Merzenich is an author of a scientific paper on temporal information transformation into a spatial code by a neural network."</data>
      <data key="d6">82de30f43839f4985de20a981b524af1</data>
    </edge>
    <edge source="&quot;P. DOMINEY&quot;" target="&quot;COMPLEX SENSORY-MOTOR SYSTEMS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"P. Dominey is an author of a scientific paper on complex sensory-motor systems."</data>
      <data key="d6">82de30f43839f4985de20a981b524af1</data>
    </edge>
    <edge source="&quot;P. DOMINEY&quot;" target="&quot;C. GALLICCHIO&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"P. Dominey and C. Gallicchio are authors of different scientific papers, but their relationship in the context of the text is not explicitly stated."</data>
      <data key="d6">ce7b58ffc7f43f36bc78154597d01903</data>
    </edge>
    <edge source="&quot;C. GALLICCHIO&quot;" target="&quot;A. MICHELI&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"C. Gallicchio and A. Micheli co-authored a scientific paper on designing deep echo state networks."</data>
      <data key="d6">ce7b58ffc7f43f36bc78154597d01903</data>
    </edge>
    <edge source="&quot;C. GALLICCHIO&quot;" target="&quot;L. PEDRELLI&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"C. Gallicchio and L. Pedrelli co-authored a scientific paper on designing deep echo state networks."</data>
      <data key="d6">ce7b58ffc7f43f36bc78154597d01903</data>
    </edge>
    <edge source="&quot;SEPP HOCHREITER&quot;" target="&quot;J&#220;RGEN SCHMIDHUBER&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Sepp Hochreiter and J&#252;rgen Schmidhuber co-authored a scientific paper on long short-term memory."</data>
      <data key="d6">ce7b58ffc7f43f36bc78154597d01903</data>
    </edge>
    <edge source="&quot;SEPP HOCHREITER&quot;" target="&quot;NEURAL COMPUTATION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Sepp Hochreiter is an author of a research paper published in Neural Computation."</data>
      <data key="d6">c8b7bd13cf99920ecce56cb563910cb3</data>
    </edge>
    <edge source="&quot;J&#220;RGEN SCHMIDHUBER&quot;" target="&quot;NEURAL COMPUTATION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"J&#252;rgen Schmidhuber is an author of a research paper published in Neural Computation."</data>
      <data key="d6">c8b7bd13cf99920ecce56cb563910cb3</data>
    </edge>
    <edge source="&quot;DANIEL J. GAUTHIER&quot;" target="&quot;ERIK BOLLT&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Daniel J. Gauthier and Erik Bollt co-authored a scientific paper on next generation reservoir computing."</data>
      <data key="d6">ce7b58ffc7f43f36bc78154597d01903</data>
    </edge>
    <edge source="&quot;DANIEL J. GAUTHIER&quot;" target="&quot;AARON GRIFFITH&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Daniel J. Gauthier and Aaron Griffith co-authored a scientific paper on next generation reservoir computing."</data>
      <data key="d6">ce7b58ffc7f43f36bc78154597d01903</data>
    </edge>
    <edge source="&quot;DANIEL J. GAUTHIER&quot;" target="&quot;WENDSON A. S. BARBOSA&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Daniel J. Gauthier and Wendson A. S. Barbosa co-authored a scientific paper on next generation reservoir computing."</data>
      <data key="d6">ce7b58ffc7f43f36bc78154597d01903</data>
    </edge>
    <edge source="&quot;GREGOR M. HOERZER&quot;" target="&quot;ROBERT LEGENSTEIN&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Gregor M. Hoerzer and Robert Legenstein co-authored a scientific paper on a specific topic, but the relationship description is not explicitly stated in the text."</data>
      <data key="d6">ce7b58ffc7f43f36bc78154597d01903</data>
    </edge>
    <edge source="&quot;GREGOR M. HOERZER&quot;" target="&quot;NEURAL COMPUTATION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Gregor M. Hoerzer is an author of a research paper mentioned in the text, but no specific publication is mentioned."</data>
      <data key="d6">c8b7bd13cf99920ecce56cb563910cb3</data>
    </edge>
    <edge source="&quot;ROBERT LEGENSTEIN&quot;" target="&quot;NEURAL COMPUTATION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Robert Legenstein is an author of a research paper mentioned in the text, but no specific publication is mentioned."</data>
      <data key="d6">c8b7bd13cf99920ecce56cb563910cb3</data>
    </edge>
    <edge source="&quot;S. BARBOSA&quot;" target="&quot;NEURAL COMPUTATION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"S. Barbosa is an author of a research paper published in Neural Computation."</data>
      <data key="d6">c8b7bd13cf99920ecce56cb563910cb3</data>
    </edge>
    <edge source="&quot;GUANG-BIN HUANG&quot;" target="&quot;INT. J. MACH. LEARN. &amp; CYBER.&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Guang-Bin Huang is an author of a research paper published in Int. J. Mach. Learn. &amp; Cyber."</data>
      <data key="d6">c8b7bd13cf99920ecce56cb563910cb3</data>
    </edge>
    <edge source="&quot;DIAN HUI WANG&quot;" target="&quot;INT. J. MACH. LEARN. &amp; CYBER.&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Dian Hui Wang is an author of a research paper published in Int. J. Mach. Learn. &amp; Cyber."</data>
      <data key="d6">c8b7bd13cf99920ecce56cb563910cb3</data>
    </edge>
    <edge source="&quot;YUAN LAN&quot;" target="&quot;INT. J. MACH. LEARN. &amp; CYBER.&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Yuan Lan is an author of a research paper published in Int. J. Mach. Learn. &amp; Cyber."</data>
      <data key="d6">c8b7bd13cf99920ecce56cb563910cb3</data>
    </edge>
    <edge source="&quot;HINAUT H. TROUVAIN&quot;" target="&quot;GMD TECH. REPORT&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Hinaut H. Trouvain is an author of a research paper published in GMD Tech. Report."</data>
      <data key="d6">c8b7bd13cf99920ecce56cb563910cb3</data>
    </edge>
    <edge source="&quot;JACQUES KAISER&quot;" target="&quot;BIOINSPIRATION &amp; BIOMIMETICS, 12(5):055001, SEP 2017&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Jacques Kaiser published a paper on scaling up liquid state machines to predict over address events from dynamic vision sensors."</data>
      <data key="d6">546551fd625e354e9afe1245e060bed3</data>
    </edge>
    <edge source="&quot;GERMAN NATIONAL RESEARCH CENTER FOR INFORMATION TECHNOLOGY GMD&quot;" target="&quot;GMD TECH. REPORT, 148:34, 2001&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"GMD published a report on the 'echo state' approach for training recurrent neural networks."</data>
      <data key="d6">546551fd625e354e9afe1245e060bed3</data>
    </edge>
    <edge source="&quot;GERMAN NATIONAL RESEARCH CENTER FOR INFORMATION TECHNOLOGY GMD&quot;" target="&quot;BONN, GERMANY&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"German National Research Center for Information Technology GMD is based in Bonn, Germany."</data>
      <data key="d6">546551fd625e354e9afe1245e060bed3</data>
    </edge>
    <edge source="&quot;W. MAASS&quot;" target="&quot;NEURAL COMPUTATION, 14(11):2531&#8211;2560, 2002&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"W. Maass published a paper on real-time computing without stable states: A new framework for neural computation based on perturbations."</data>
      <data key="d6">546551fd625e354e9afe1245e060bed3</data>
    </edge>
    <edge source="&quot;W. MAASS, T. NATSCHL&#168;AGER, AND H. MARKRAM&quot;" target="&quot;REAL-TIME COMPUTING WITHOUT STABLE STATES PAPER&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The entity is associated with the research paper on real-time computing without stable states."</data>
      <data key="d6">ea62f994886333282704a19ebf0469ea</data>
    </edge>
    <edge source="&quot;FRANCESCO MARTINUZZI, CHRIS RACKAUCKAS, ANAS ABDELREHIM, MIGUEL D. MAHECHA, AND KARIN MORA&quot;" target="&quot;RESERVOIRCOMPUTING.JL LIBRARY&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The entity is associated with the development of the Reservoircomputing.jl library."</data>
      <data key="d6">ea62f994886333282704a19ebf0469ea</data>
    </edge>
    <edge source="&quot;NILS SCHAETTI&quot;" target="&quot;ECHOTORCH LIBRARY&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Nils Schaetti is the developer of the Echotorch library."</data>
      <data key="d6">ea62f994886333282704a19ebf0469ea</data>
    </edge>
    <edge source="&quot;BENJAMIN SCHRAUWEN, MARION WARDERMANN, DAVID VERSTRAETEN, JOCHEN J. STEIL, AND DIRK STROOBANDT&quot;" target="&quot;IMPROVING RESERVOIRS PAPER&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The entity is associated with the research paper on improving reservoirs using intrinsic plasticity."</data>
      <data key="d6">ea62f994886333282704a19ebf0469ea</data>
    </edge>
    <edge source="&quot;JOCHEN J STEIL&quot;" target="&quot;ONLINE RESERVOIR ADAPTATION PAPER&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Jochen J Steil is an author of the research paper on online reservoir adaptation."</data>
      <data key="d6">ea62f994886333282704a19ebf0469ea</data>
    </edge>
    <edge source="&quot;JOCHEN J STEIL&quot;" target="&quot;PYRCN TOOLBOX&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Jochen J Steil is an author of a research paper related to the Pyrcn Toolbox."</data>
      <data key="d6">7751d435f46a6d4027a1c96edabb9626</data>
    </edge>
    <edge source="&quot;PETER STEINER, AZARAKHSH JALALVAND, SIMON STONE, AND PETER BIRKHOLZ&quot;" target="&quot;PYRCN TOOLBOX&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The entity is associated with the development of the Pyrcn toolbox."</data>
      <data key="d6">ea62f994886333282704a19ebf0469ea</data>
    </edge>
    <edge source="&quot;PYRCN TOOLBOX&quot;" target="&quot;PETER STEINER&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Peter Steiner is an author of the Pyrcn Toolbox."</data>
      <data key="d6">7751d435f46a6d4027a1c96edabb9626</data>
    </edge>
    <edge source="&quot;PYRCN TOOLBOX&quot;" target="&quot;AZARAKHSH JALALVAND&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Azarakhsh Jalalvand is an author of the Pyrcn Toolbox."</data>
      <data key="d6">7751d435f46a6d4027a1c96edabb9626</data>
    </edge>
    <edge source="&quot;PYRCN TOOLBOX&quot;" target="&quot;SIMON STONE&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Simon Stone is an author of the Pyrcn Toolbox."</data>
      <data key="d6">7751d435f46a6d4027a1c96edabb9626</data>
    </edge>
    <edge source="&quot;PYRCN TOOLBOX&quot;" target="&quot;PETER BIRKHOLZ&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Peter Birkholz is an author of the Pyrcn Toolbox."</data>
      <data key="d6">7751d435f46a6d4027a1c96edabb9626</data>
    </edge>
    <edge source="&quot;DAVID SUSSILLO&quot;" target="&quot;COHERENT PATTERNS RESEARCH&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"David Sussillo is an author of a research paper on generating coherent patterns of activity from chaotic neural networks."</data>
      <data key="d6">7751d435f46a6d4027a1c96edabb9626</data>
    </edge>
    <edge source="&quot;L. F. ABBOTT&quot;" target="&quot;COHERENT PATTERNS RESEARCH&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"L. F. Abbott is an author of a research paper on generating coherent patterns of activity from chaotic neural networks."</data>
      <data key="d6">7751d435f46a6d4027a1c96edabb9626</data>
    </edge>
    <edge source="&quot;DAVID VERSTRAETEN&quot;" target="&quot;OGER RESEARCH&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"David Verstraeten is an author of a research paper on oger: modular learning architectures for large-scale sequential processing."</data>
      <data key="d6">7751d435f46a6d4027a1c96edabb9626</data>
    </edge>
    <edge source="&quot;BENJAMIN SCHRAUWEN&quot;" target="&quot;OGER RESEARCH&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Benjamin Schrauwen is an author of a research paper on oger: modular learning architectures for large-scale sequential processing."</data>
      <data key="d6">7751d435f46a6d4027a1c96edabb9626</data>
    </edge>
    <edge source="&quot;SANDER DIELEMAN&quot;" target="&quot;OGER RESEARCH&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Sander Dieleman is an author of a research paper on oger: modular learning architectures for large-scale sequential processing."</data>
      <data key="d6">7751d435f46a6d4027a1c96edabb9626</data>
    </edge>
    <edge source="&quot;PHILEMON BRAKEL&quot;" target="&quot;OGER RESEARCH&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Philemon Brakel is an author of a research paper on oger: modular learning architectures for large-scale sequential processing."</data>
      <data key="d6">7751d435f46a6d4027a1c96edabb9626</data>
    </edge>
    <edge source="&quot;PIETER BUTENEERS&quot;" target="&quot;OGER RESEARCH&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Pieter Buteneers is an author of a research paper on oger: modular learning architectures for large-scale sequential processing."</data>
      <data key="d6">7751d435f46a6d4027a1c96edabb9626</data>
    </edge>
    <edge source="&quot;DEJAN PECEVSKI&quot;" target="&quot;OGER RESEARCH&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Dejan Pecevski is an author of a research paper on oger: modular learning architectures for large-scale sequential processing."</data>
      <data key="d6">7751d435f46a6d4027a1c96edabb9626</data>
    </edge>
    <edge source="&quot;VERSTRAETEN, BENJAMIN&quot;" target="&quot;MODULAR LEARNING ARCHITECTURES FOR LARGE-SCALE SEQUENTIAL PROCESSING&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Verstraeten, Benjamin is an author of the research paper on modular learning architectures for large-scale sequential processing."</data>
      <data key="d6">b8d8b71875a9ccc508b40fe4aad8d796</data>
    </edge>
    <edge source="&quot;SCHRAUWEN, SANDER&quot;" target="&quot;MODULAR LEARNING ARCHITECTURES FOR LARGE-SCALE SEQUENTIAL PROCESSING&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Schrauwen, Sander is an author of the research paper on modular learning architectures for large-scale sequential processing."</data>
      <data key="d6">b8d8b71875a9ccc508b40fe4aad8d796</data>
    </edge>
    <edge source="&quot;DIELEMAN, PHILEMON&quot;" target="&quot;MODULAR LEARNING ARCHITECTURES FOR LARGE-SCALE SEQUENTIAL PROCESSING&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Dieleman, Philemon is an author of the research paper on modular learning architectures for large-scale sequential processing."</data>
      <data key="d6">b8d8b71875a9ccc508b40fe4aad8d796</data>
    </edge>
    <edge source="&quot;BRAKEL, PIETER&quot;" target="&quot;MODULAR LEARNING ARCHITECTURES FOR LARGE-SCALE SEQUENTIAL PROCESSING&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Brakel, Pieter is an author of the research paper on modular learning architectures for large-scale sequential processing."</data>
      <data key="d6">b8d8b71875a9ccc508b40fe4aad8d796</data>
    </edge>
    <edge source="&quot;BUTE-NEERS, AND DEJAN PECEVSKI&quot;" target="&quot;MODULAR LEARNING ARCHITECTURES FOR LARGE-SCALE SEQUENTIAL PROCESSING&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Bute-neers, and Dejan Pecevski are additional authors of the research paper on modular learning architectures for large-scale sequential processing."</data>
      <data key="d6">b8d8b71875a9ccc508b40fe4aad8d796</data>
    </edge>
    <edge source="&quot;THE JOURNAL OF MACHINE LEARNING RESEARCH&quot;" target="&quot;MODULAR LEARNING ARCHITECTURES FOR LARGE-SCALE SEQUENTIAL PROCESSING&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Journal of Machine Learning Research is the publication source for the research paper on modular learning architectures for large-scale sequential processing."</data>
      <data key="d6">b8d8b71875a9ccc508b40fe4aad8d796</data>
    </edge>
    <edge source="&quot;DIRECTED ACYCLIC GRAPH&quot;" target="&quot;STRICTLY FEEDFORWARD NEURAL NETWORK&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Directed Acyclic Graph can be unrolled and replaced with a Strictly Feedforward Neural Network."</data>
      <data key="d6">f59839daadfb1f3832bb9f8d201a7126</data>
    </edge>
    <edge source="&quot;INFINITE IMPULSE RECURRENT NETWORK&quot;" target="&quot;FINITE IMPULSE NETWORK&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Additional stored states and the storage under direct control by the network can be added to both Infinite-Impulse and Finite-Impulse Networks."</data>
      <data key="d6">f59839daadfb1f3832bb9f8d201a7126</data>
    </edge>
    <edge source="&quot;FEEDBACK NEURAL NETWORK&quot;" target="&quot;LONG SHORT-TERM MEMORY&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Feedback Neural Network is also called Feedback Neural Network (FNN), and Long Short-Term Memory networks are a type of FNN."</data>
      <data key="d6">f59839daadfb1f3832bb9f8d201a7126</data>
    </edge>
    <edge source="&quot;FEEDBACK NEURAL NETWORK&quot;" target="&quot;GATED RECURRENT UNITS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Gated Recurrent Units use gated states, which are also referred to as gated memory and are part of Feedback Neural Networks."</data>
      <data key="d6">f59839daadfb1f3832bb9f8d201a7126</data>
    </edge>
    <edge source="&quot;LONG SHORT-TERM MEMORY&quot;" target="&quot;GATED RECURRENT UNITS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Long Short-Term Memory networks and Gated Recurrent Units are similar in that they use gated states to control the flow of information."</data>
      <data key="d6">f59839daadfb1f3832bb9f8d201a7126</data>
    </edge>
    <edge source="&quot;LONG SHORT-TERM MEMORY&quot;" target="&quot;SECOND-ORDER RNNS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Long Short-Term Memory is an example of second-order RNNs, which use higher order weights and states for direct mapping to a finite-state machine."</data>
      <data key="d6">b888c4ebe914c1dfa26682de69de9de9</data>
    </edge>
    <edge source="&quot;LONG SHORT-TERM MEMORY&quot;" target="&quot;LSTM&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"LSTM is an abbreviation for Long Short-Term Memory, a type of Recurrent Neural Network that uses a mechanism to retain information over long sequences."</data>
      <data key="d6">2bdd28d9e151597072c8490db69b9941</data>
    </edge>
    <edge source="&quot;HOCHREITER AND SCHMIDHUBER&quot;" target="&quot;LSTM&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Hochreiter and Schmidhuber invented Long Short-Term Memory (LSTM) networks in 1997."</data>
      <data key="d6">b31ca51b419f7270ee5f4910c90ea331</data>
    </edge>
    <edge source="&quot;LSTM&quot;" target="&quot;GOOGLE&quot;">
      <data key="d4">2.0</data>
      <data key="d5">"Google used LSTM networks in its speech recognition and Android systems."
"Google used LSTM for speech recognition and improved machine translation, language modeling, and multilingual language processing."</data>
      <data key="d6">486e4b71bf02f756450ab727db88f821,b31ca51b419f7270ee5f4910c90ea331</data>
    </edge>
    <edge source="&quot;LSTM&quot;" target="&quot;CNN&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"LSTM was used in combination with CNNs for automatic image captioning."</data>
      <data key="d6">486e4b71bf02f756450ab727db88f821</data>
    </edge>
    <edge source="&quot;LSTM&quot;" target="&quot;CTC&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"LSTM is trained using the Connectionist Temporal Classification (CTC) method to find an RNN weight matrix that maximizes the probability of label sequences in a training set, given the corresponding input sequences."</data>
      <data key="d6">b48d5212c060453a846e21cdb98dbd7d</data>
    </edge>
    <edge source="&quot;LSTM&quot;" target="&quot;HMM&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"LSTM can learn to recognize context-sensitive languages unlike previous models based on Hidden Markov Models (HMM) and similar concepts."</data>
      <data key="d6">b48d5212c060453a846e21cdb98dbd7d</data>
    </edge>
    <edge source="&quot;LSTM&quot;" target="&quot;GRUS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"GRUs are a type of gating mechanism in recurrent neural networks (RNNs) similar to LSTM but with fewer parameters."</data>
      <data key="d6">b48d5212c060453a846e21cdb98dbd7d</data>
    </edge>
    <edge source="&quot;LSTM&quot;" target="&quot;BI-DIRECTIONAL RNNS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Bi-directional RNNs can be used in conjunction with LSTM to improve performance in certain applications."</data>
      <data key="d6">b48d5212c060453a846e21cdb98dbd7d</data>
    </edge>
    <edge source="&quot;LSTM&quot;" target="&quot;BPTT&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"LSTM combines with a BPTT/RTRL hybrid learning method to overcome problems in recurrent neural networks."</data>
      <data key="d6">88405de18768775d8bce062ea467bd7f</data>
    </edge>
    <edge source="&quot;LSTM&quot;" target="&quot;RTRL&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"LSTM combines with a BPTT/RTRL hybrid learning method to overcome problems in recurrent neural networks."</data>
      <data key="d6">88405de18768775d8bce062ea467bd7f</data>
    </edge>
    <edge source="&quot;LSTM&quot;" target="&quot;INDRNN&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"IndRNN reduces the context of a neuron to its own past state, which is a concept similar to the approach taken by LSTM."</data>
      <data key="d6">88405de18768775d8bce062ea467bd7f</data>
    </edge>
    <edge source="&quot;BAIDU&quot;" target="&quot;CTC-TRAINED RNNS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Baidu used CTC-trained RNNs to break the 2S09 Switchboard Hub5&#8217;00 speech recognition dataset in 2014."</data>
      <data key="d6">b31ca51b419f7270ee5f4910c90ea331</data>
    </edge>
    <edge source="&quot;BAIDU&quot;" target="&quot;2S09 SWITCHBOARD HUB5&#8217;00&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Baidu used the 2S09 Switchboard Hub5&#8217;00 dataset to break a speech recognition benchmark."</data>
      <data key="d6">486e4b71bf02f756450ab727db88f821</data>
    </edge>
    <edge source="&quot;BAIDU&quot;" target="&quot;CTC&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Baidu used CTC-trained RNNs in their machine learning models."</data>
      <data key="d6">486e4b71bf02f756450ab727db88f821</data>
    </edge>
    <edge source="&quot;GOOGLE&quot;" target="&quot;CTC&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Google used CTC-trained LSTM in their machine learning models."</data>
      <data key="d6">486e4b71bf02f756450ab727db88f821</data>
    </edge>
    <edge source="&quot;CTC&quot;" target="&quot;LONG SHORT-TERM MEMORY (LSTM)&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Long short-term memory (LSTM) is often used in applications that train stacks of LSTM RNNs using Connectionist Temporal Classification (CTC)."</data>
      <data key="d6">4470a7f7ad60a2866b31907a2a3ca96e</data>
    </edge>
    <edge source="&quot;ELMAN NETWORKS&quot;" target="&quot;CONTEXT UNITS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Elman Networks have additional context units that save a copy of the previous values of the hidden units, allowing them to maintain a sort of state."</data>
      <data key="d6">bf4dccb5096a917a6a71f0cc224e4d7c</data>
    </edge>
    <edge source="&quot;ELMAN NETWORKS&quot;" target="&quot;SEQUENCE PREDICTION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Elman Networks can perform tasks such as sequence prediction by maintaining a sort of state through their context units."</data>
      <data key="d6">bf4dccb5096a917a6a71f0cc224e4d7c</data>
    </edge>
    <edge source="&quot;ELMAN NETWORK&quot;" target="&quot;JEFF ELMAN&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Elman Networks were invented by Jeff Elman."</data>
      <data key="d6">fb7999a4b39733c28630293d3659d7eb</data>
    </edge>
    <edge source="&quot;ELMAN NETWORK&quot;" target="&quot;SIMPLE RECURRENT NETWORKS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Elman Networks are a type of Simple Recurrent Network."</data>
      <data key="d6">fb7999a4b39733c28630293d3659d7eb</data>
    </edge>
    <edge source="&quot;JORDAN NETWORK&quot;" target="&quot;GEOFFREY HINTON&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Jordan Networks are also known as Simple Recurrent Networks, which are a field of study associated with Geoffrey Hinton."</data>
      <data key="d6">fb7999a4b39733c28630293d3659d7eb</data>
    </edge>
    <edge source="&quot;JORDAN NETWORK&quot;" target="&quot;SIMPLE RECURRENT NETWORKS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Jordan Networks are a type of Simple Recurrent Network."</data>
      <data key="d6">fb7999a4b39733c28630293d3659d7eb</data>
    </edge>
    <edge source="&quot;BIDIRECTIONAL ASSOCIATIVE MEMORY (BAM) NETWORK&quot;" target="&quot;BART KOSKO&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Bart Kosko is the author of the Bidirectional Associative Memory (BAM) Network."</data>
      <data key="d6">a8c0edd2cdddb7d6d899284063b541f5</data>
    </edge>
    <edge source="&quot;BIDIRECTIONAL ASSOCIATIVE MEMORY (BAM) NETWORK&quot;" target="&quot;RECENTLY&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Bidirectional Associative Memory (BAM) Network has recently been optimized for increased network stability and relevance to real-world applications."</data>
      <data key="d6">a8c0edd2cdddb7d6d899284063b541f5</data>
    </edge>
    <edge source="&quot;INDEPENDENTLY RECURRENT NEURAL NETWORK&quot;" target="&quot;RECURSIVE NEURAL NETWORK&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Both Independently Recurrent Neural Network and Recursive Neural Network are types of neural networks that address the gradient vanishing and exploding problems in the traditional fully connected RNN, but they differ in their structure and application."</data>
      <data key="d6">423cdb622c47fa8cec25f22eb9f9f01f</data>
    </edge>
    <edge source="&quot;RECURSIVE NEURAL NETWORK&quot;" target="&quot;AUTOMATIC DIFFERENTIATION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Recursive Neural Networks are typically trained using the reverse mode of automatic differentiation."</data>
      <data key="d6">7b6ff30ef255db2d2c68326d78cf0115</data>
    </edge>
    <edge source="&quot;RECURSIVE NEURAL NETWORK&quot;" target="&quot;DISTRIBUTED REPRESENTATIONS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Recursive Neural Networks can process distributed representations of structure, such as logical terms."</data>
      <data key="d6">7b6ff30ef255db2d2c68326d78cf0115</data>
    </edge>
    <edge source="&quot;CHUNKER&quot;" target="&quot;AUTOMATIZER&quot;">
      <data key="d4">2.0</data>
      <data key="d5">"The Automatizer learns to predict or imitate inputs based on the hidden units of the Chunker.""The Chunker learns to predict and compress inputs that are unpredictable by the Automatizer."</data>
      <data key="d6">b888c4ebe914c1dfa26682de69de9de9</data>
    </edge>
    <edge source="&quot;GENERATIVE MODEL&quot;" target="&quot;VANISHING GRADIENT PROBLEM&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Generative Model partially overcame the vanishing gradient problem in neural networks."</data>
      <data key="d6">b888c4ebe914c1dfa26682de69de9de9</data>
    </edge>
    <edge source="&quot;SECOND-ORDER RNNS&quot;" target="&quot;FINITE-STATE MACHINE&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Second-order RNNs can be directly mapped to a finite-state machine, allowing both training and representation."</data>
      <data key="d6">4470a7f7ad60a2866b31907a2a3ca96e</data>
    </edge>
    <edge source="&quot;CONTINUOUS-TIME RECURRENT NEURAL NETWORK&quot;" target="&quot;CTRNN&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"CTRNN is an abbreviation for Continuous-time Recurrent Neural Network, a type of neural network that uses a system of ordinary differential equations to model the effects on a neuron of the incoming inputs."</data>
      <data key="d6">2bdd28d9e151597072c8490db69b9941</data>
    </edge>
    <edge source="&quot;CTRNN&quot;" target="&quot;EVOLUTIONARY ROBOTICS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"CTRNNs have been applied to Evolutionary Robotics where they have been used to address vision, co-operation, and minimal cognitive behaviour."</data>
      <data key="d6">2bdd28d9e151597072c8490db69b9941</data>
    </edge>
    <edge source="&quot;HIERARCHICAL RECURRENT NEURAL NETWORK&quot;" target="&quot;HRNN&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"HRNN is an abbreviation for Hierarchical Recurrent Neural Network, a type of Recurrent Neural Network that uses multiple layers to process data at different levels of abstraction."</data>
      <data key="d6">2bdd28d9e151597072c8490db69b9941</data>
    </edge>
    <edge source="&quot;HIERARCHICAL RECURRENT NEURAL NETWORKS&quot;" target="&quot;CONSUMER PRICE INDEX&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Hierarchical recurrent neural networks are used in forecasting disaggregated inflation components of the consumer price index (CPI), demonstrating their application in predicting economic data."</data>
      <data key="d6">9e61c22432d6984a19da5840f64d417d</data>
    </edge>
    <edge source="&quot;US CPI-U INDEX&quot;" target="&quot;HRNN MODEL&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The HRNN model is evaluated using the US CPI-U index dataset."</data>
      <data key="d6">c7ca22e82a3823afda793ad30077348e</data>
    </edge>
    <edge source="&quot;HAWKINS&quot;" target="&quot;MEMORY-PREDICTION THEORY&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Hawkins is known for his work on the memory-prediction theory of brain function."</data>
      <data key="d6">0f59288ce2aaf33e468cdc3877cefd85</data>
    </edge>
    <edge source="&quot;NEURAL TURING MACHINES&quot;" target="&quot;DIFFERENTIABLE NEURAL COMPUTERS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Differentiable neural computers are an extension of Neural Turing machines."</data>
      <data key="d6">0f59288ce2aaf33e468cdc3877cefd85</data>
    </edge>
    <edge source="&quot;NEURAL TURING MACHINES&quot;" target="&quot;NEURAL NETWORK PUSHDOWN AUTOMATA&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Neural network pushdown automata are similar to Neural Turing machines."</data>
      <data key="d6">0f59288ce2aaf33e468cdc3877cefd85</data>
    </edge>
    <edge source="&quot;MEMRISTIVE NETWORKS&quot;" target="&quot;GREG SNIDER&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Greg Snider describes a system of cortical neural networks that use memristive devices for memory storage and processing."</data>
      <data key="d6">0f59288ce2aaf33e468cdc3877cefd85</data>
    </edge>
    <edge source="&quot;MEMRISTIVE NETWORKS&quot;" target="&quot;HP LABS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"HP Labs is mentioned in the context of developing cortical computing systems with memristive nanodevices, which are a type of memristive network."</data>
      <data key="d6">671755b49cf8893c9fcf9c9c05777ea6</data>
    </edge>
    <edge source="&quot;MEMRISTIVE NETWORKS&quot;" target="&quot;DARPA'S SYNAPSE PROJECT&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Memristive Networks are a type of neural network being developed in DARPA's SyNAPSE Project."</data>
      <data key="d6">671755b49cf8893c9fcf9c9c05777ea6</data>
    </edge>
    <edge source="&quot;MEMRISTIVE NETWORKS&quot;" target="&quot;LITTLE-HOPFIELD NETWORKS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Memristive Networks are compared to Little-Hopfield Networks, sharing similar properties such as continuous dynamics and limited memory capacity."</data>
      <data key="d6">5445391448d4ac43471e2bce5eb41a70</data>
    </edge>
    <edge source="&quot;MEMRISTIVE NETWORKS&quot;" target="&quot;RESISTOR-CAPACITOR NETWORK&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Memristive Networks are mentioned to have a more interesting non-linear behavior compared to Resistor-Capacitor Networks."</data>
      <data key="d6">5445391448d4ac43471e2bce5eb41a70</data>
    </edge>
    <edge source="&quot;MEMRISTIVE NETWORKS&quot;" target="&quot;NEUROMORPHIC ENGINEERING&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Memristive Networks are mentioned in the context of Neuromorphic Engineering, where the device behavior depends on the circuit wiring or topology."</data>
      <data key="d6">5445391448d4ac43471e2bce5eb41a70</data>
    </edge>
    <edge source="&quot;MEMRISTIVE NETWORKS&quot;" target="&quot;CARAVELLI-TRAVERSA-DI VENTRA EQUATION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Caravelli-Traversa-Di Ventra Equation is mentioned as a method used to study the evolution of memristive networks analytically."</data>
      <data key="d6">5445391448d4ac43471e2bce5eb41a70</data>
    </edge>
    <edge source="&quot;GREG SNIDER&quot;" target="&quot;HP LABS&quot;">
      <data key="d4">2.0</data>
      <data key="d5">"Greg Snider works at HP Labs."
"Greg Snider is a researcher at HP Labs."</data>
      <data key="d6">0f59288ce2aaf33e468cdc3877cefd85,671755b49cf8893c9fcf9c9c05777ea6</data>
    </edge>
    <edge source="&quot;HP LABS&quot;" target="&quot;DARPA'S SYNAPSE PROJECT&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"HP Labs is a collaborating organization in DARPA's SyNAPSE Project."</data>
      <data key="d6">671755b49cf8893c9fcf9c9c05777ea6</data>
    </edge>
    <edge source="&quot;DARPA'S SYNAPSE PROJECT&quot;" target="&quot;IBM RESEARCH&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"IBM Research is a collaborating organization in DARPA's SyNAPSE Project."</data>
      <data key="d6">671755b49cf8893c9fcf9c9c05777ea6</data>
    </edge>
    <edge source="&quot;DARPA'S SYNAPSE PROJECT&quot;" target="&quot;BOSTON UNIVERSITY DEPARTMENT OF COGNITIVE AND NEURAL SYSTEMS (CNS)&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Boston University Department of Cognitive and Neural Systems (CNS) is a collaborating organization in DARPA's SyNAPSE Project."</data>
      <data key="d6">671755b49cf8893c9fcf9c9c05777ea6</data>
    </edge>
    <edge source="&quot;BPTT&quot;" target="&quot;CRBP&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"CRBP implements and combines BPTT and RTRL paradigms for locally recurrent networks."</data>
      <data key="d6">88405de18768775d8bce062ea467bd7f</data>
    </edge>
    <edge source="&quot;RTRL&quot;" target="&quot;CRBP&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"CRBP implements and combines BPTT and RTRL paradigms for locally recurrent networks."</data>
      <data key="d6">88405de18768775d8bce062ea467bd7f</data>
    </edge>
    <edge source="&quot;SIGNAL-FLOW GRAPHS&quot;" target="&quot;LEE&#8217;S THEOREM&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Signal-Flow Graphs is based on Lee&#8217;s Theorem for network sensitivity calculations."</data>
      <data key="d6">88405de18768775d8bce062ea467bd7f</data>
    </edge>
    <edge source="&quot;DYNAMICAL SYSTEMS THEORY&quot;" target="&quot;APPLICATIONS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Dynamical Systems Theory is mentioned in the context of analyzing chaotic behavior in systems, which could be considered an application."</data>
      <data key="d6">2f1161d1f711d264529aa7bddf81959b</data>
    </edge>
    <edge source="&quot;SILENCING MECHANISM&quot;" target="&quot;APPLICATIONS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Silencing Mechanism is mentioned in the context of a more biological-based model for memory-based learning, which could be considered an application."</data>
      <data key="d6">2f1161d1f711d264529aa7bddf81959b</data>
    </edge>
    <edge source="&quot;MACKEY-GLASS EQUATIONS&quot;" target="&quot;PHYSIOLOGICAL SIGNALS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Mackey-Glass Equations are used to describe the temporal behavior of physiological signals."</data>
      <data key="d6">2f4c992d69812866e6fce6dbb52d8612</data>
    </edge>
    <edge source="&quot;MACKEY-GLASS EQUATIONS&quot;" target="&quot;TAU&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Tau is a parameter in the Mackey-Glass Equations that influences their chaotic behavior."</data>
      <data key="d6">238049de5f28dca3e857a46a8b1bed03</data>
    </edge>
    <edge source="&quot;MATPLOTLIB&quot;" target="&quot;SINE WAVE&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Matplotlib is used to visualize the Sine Wave, which is generated using Numpy."</data>
      <data key="d6">71f966d00b6d0eceb580d00b9cb86b1e</data>
    </edge>
    <edge source="&quot;MATPLOTLIB&quot;" target="&quot;PLOTTING FUNCTION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Plotting Function utilizes Matplotlib to create visualizations of data."</data>
      <data key="d6">c5c29ba06a5cc70a086c2c2c8858e5aa</data>
    </edge>
    <edge source="&quot;MATPLOTLIB&quot;" target="&quot;CHAPTER 2&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Matplotlib is mentioned in Chapter 2 as a library used for data visualization in the context of the generative mode."</data>
      <data key="d6">e396354e3a9be76616392af11f56e671</data>
    </edge>
    <edge source="&quot;TASK 1: 10 TIMESTEPS AHEAD FORECAST&quot;" target="&quot;DATA PREPROCESSING&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Data Preprocessing is a necessary step in Task 1 to prepare the Mackey-Glass Time Series data for prediction."</data>
      <data key="d6">fac681bdc38ae5829173c747ee6240fa</data>
    </edge>
    <edge source="&quot;DATA PREPROCESSING&quot;" target="&quot;THE DATA&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Data Preprocessing is the step of loading and processing the data found on Zenodo."</data>
      <data key="d6">8677349b328abac82fa1cfc91c856a6c</data>
    </edge>
    <edge source="&quot;DATA PREPROCESSING&quot;" target="&quot;TESTING DATA&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Data Preprocessing is applied to the Testing Data to clean and prepare it for use in the Echo State Network (ESN) model."</data>
      <data key="d6">1365a36c76afc697ac626fd0f784804a</data>
    </edge>
    <edge source="&quot;TIME SERIES PREDICTION&quot;" target="&quot;TRAINING THE ESN&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Training the ESN is a step in the process of Time Series Prediction, allowing the model to learn patterns and make predictions."</data>
      <data key="d6">eb7a223eeb120e3fcc45a96a6018707d</data>
    </edge>
    <edge source="&quot;GENERATIVE MODE&quot;" target="&quot;CHAPTER 2&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Generative Mode is the main concept discussed in Chapter 2, which involves generating new data based on learned patterns."</data>
      <data key="d6">e396354e3a9be76616392af11f56e671</data>
    </edge>
    <edge source="&quot;GENERATIVE MODE&quot;" target="&quot;REAL TIMESERIES DATA&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Generative Mode is compared to Real Timeseries Data in the text."</data>
      <data key="d6">70db98fabc82fc96ecf8cc2c023b586b</data>
    </edge>
    <edge source="&quot;ROBOT FALLING&quot;" target="&quot;ZENODO&quot;">
      <data key="d4">2.0</data>
      <data key="d5">"Data for the Robot Falling use case can be found on Zenodo."
"Data for the robot falling use case can be found on Zenodo."</data>
      <data key="d6">af2db1cc5ab6b16acae2c93d3facb668,b483c6bbce54156c724905b340aa2e85</data>
    </edge>
    <edge source="&quot;ZENODO&quot;" target="&quot;CANARY SONG DECODING&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Zenodo hosts data for the canary song decoding use case, making it accessible for analysis."</data>
      <data key="d6">d15f6d075c072f0335b5332f11c00299</data>
    </edge>
    <edge source="&quot;ZENODO&quot;" target="&quot;THE DATA&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Data is found on the Zenodo platform."</data>
      <data key="d6">8677349b328abac82fa1cfc91c856a6c</data>
    </edge>
    <edge source="&quot;ROBOT&quot;" target="&quot;FALL INDICATOR&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The robot's data is being analyzed to predict and monitor the fall indicator, with the goal of preventing falls."</data>
      <data key="d6">90fa1052aec4e6374867e9a2951fb3c4</data>
    </edge>
    <edge source="&quot;ROBOT&quot;" target="&quot;FORCE MAGNITUDE&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The robot's data includes measurements of force magnitude, which is being analyzed in the context of the data."</data>
      <data key="d6">90fa1052aec4e6374867e9a2951fb3c4</data>
    </edge>
    <edge source="&quot;CANARY SONG DECODING&quot;" target="&quot;CANARY SONG&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Canary Song Decoding is a process that involves analyzing Canary Song to extract information."</data>
      <data key="d6">e7d249cdab85dc69b631d43ac6b62915</data>
    </edge>
    <edge source="&quot;CANARY SONG DECODING&quot;" target="&quot;CHAPTER 5&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Chapter 5 discusses a use case in the wild involving Canary Song Decoding."</data>
      <data key="d6">1e8ee805d22cd143d2372d300997d253</data>
    </edge>
    <edge source="&quot;LIBRISPEECH DATASET&quot;" target="&quot;MFCC&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"MFCC is used to extract features from the audio files in the Librispeech Dataset."</data>
      <data key="d6">adfade0d7bc85c6420e61ecd1ce7095c</data>
    </edge>
    <edge source="&quot;LIBRISPEECH DATASET&quot;" target="&quot;DELTA-DELTA&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Delta-Delta is used to extract features from the audio files in the Librispeech Dataset."</data>
      <data key="d6">adfade0d7bc85c6420e61ecd1ce7095c</data>
    </edge>
    <edge source="&quot;LIBRISPEECH DATASET&quot;" target="&quot;LOAD_DATA&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The load_data function is used to process data from the Librispeech Dataset."</data>
      <data key="d6">adfade0d7bc85c6420e61ecd1ce7095c</data>
    </edge>
    <edge source="&quot;SKLEARN&quot;" target="&quot;DATA SCIENTIST&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Data Scientist uses the sklearn library to perform data analysis and model training."</data>
      <data key="d6">9fdaabd6c7e893a275a3848c10007477</data>
    </edge>
    <edge source="&quot;SKLEARN&quot;" target="&quot;CHAPTER 5&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Sklearn is used in Chapter 5 for data preprocessing and label encoding."</data>
      <data key="d6">1e8ee805d22cd143d2372d300997d253</data>
    </edge>
    <edge source="&quot;SKLEARN&quot;" target="&quot;RESEARCH PAPER&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Sklearn is a tool mentioned in the research paper."</data>
      <data key="d6">870f29520f7a1c42eecb0c4ff855f09e</data>
    </edge>
    <edge source="&quot;ONE_HOT&quot;" target="&quot;NP.VSTACK&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"np.vstack is used in conjunction with one_hot encoding for inverse transformations and comparisons."</data>
      <data key="d6">1db5e6cd356c6066227de5e273de1abe</data>
    </edge>
    <edge source="&quot;VOCAB&quot;" target="&quot;OUTPUTS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"vocab is used for mapping between numerical and categorical representations of data in the context of comparing predicted outputs to actual targets."</data>
      <data key="d6">1db5e6cd356c6066227de5e273de1abe</data>
    </edge>
    <edge source="&quot;AVERAGE ACCURACY&quot;" target="&quot;STANDARD DEVIATION&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Average Accuracy and Standard Deviation are used together to provide a more comprehensive understanding of a model's performance, with the Standard Deviation indicating the variability in the accuracy scores."</data>
      <data key="d6">eb4cbfc924325a7ec01e566ffac75ac3</data>
    </edge>
    <edge source="&quot;MODEL CREATION&quot;" target="&quot;CONNECTION CHAINING&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Connection chaining is a technique used in model creation to connect nodes in a sequential manner."</data>
      <data key="d6">f1fc6fbc8158d3da070d55544041a2ca</data>
    </edge>
    <edge source="&quot;MODEL CREATION&quot;" target="&quot;CONNECTION MERGE&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Connection merge is a technique used in model creation to combine connections from multiple nodes to a single node."</data>
      <data key="d6">f1fc6fbc8158d3da070d55544041a2ca</data>
    </edge>
    <edge source="&quot;ESN_MODEL&quot;" target="&quot;RESERVOIRPY.NODES.RESERVOIR&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The reservoirpy.nodes.Reservoir organization is used to construct the esn_model."</data>
      <data key="d6">751b176a8d6149a853e597c65a6fe0cf</data>
    </edge>
    <edge source="&quot;ESN_MODEL&quot;" target="&quot;RESERVOIRPY.MAT&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The reservoirpy.mat module is likely used in the construction of the esn_model."</data>
      <data key="d6">751b176a8d6149a853e597c65a6fe0cf</data>
    </edge>
    <edge source="&quot;MODEL.RUN()&quot;" target="&quot;FEEDBACK TIMESERIES&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Model.run() can take a feedback timeseries as input to influence the behavior of a model during the prediction phase."</data>
      <data key="d6">b338d2dcc1fe6ccf42407444c02cad7c</data>
    </edge>
    <edge source="&quot;MODEL.RUN()&quot;" target="&quot;FEEDBACK&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Feedback is a concept that can be applied during the prediction phase using the Model.run() method."</data>
      <data key="d6">b338d2dcc1fe6ccf42407444c02cad7c</data>
    </edge>
    <edge source="&quot;CUSTOM INITIALIZER FUNCTIONS&quot;" target="&quot;SCIPY.STATS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Scipy.stats is used to create initializer functions that can generate weights from any distribution."</data>
      <data key="d6">ff860bc63e3d697a6183c0b850689048</data>
    </edge>
    <edge source="&quot;CUSTOM INITIALIZER FUNCTIONS&quot;" target="&quot;CONNECTIVITY&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Connectivity is a property that can be adjusted when creating initializer functions for weight matrices."</data>
      <data key="d6">ff860bc63e3d697a6183c0b850689048</data>
    </edge>
    <edge source="&quot;SINE WAVE&quot;" target="&quot;INPUT TIMESERIES&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Sine Wave is used as an example of Input Timeseries in the text."</data>
      <data key="d6">5366a81a025c098744b5d6f1432c2fbc</data>
    </edge>
    <edge source="&quot;SINE WAVE&quot;" target="&quot;TARGET TIMESERIES&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Sine Wave is used as an example of Target Timeseries in the text."</data>
      <data key="d6">5366a81a025c098744b5d6f1432c2fbc</data>
    </edge>
    <edge source="&quot;INPUT TIMESERIES&quot;" target="&quot;TARGET TIMESERIES&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Input Timeseries and Target Timeseries are used together to train Ridge to solve a prediction task."</data>
      <data key="d6">5366a81a025c098744b5d6f1432c2fbc</data>
    </edge>
    <edge source="&quot;NORMAL_W&quot;" target="&quot;RESERVOIRPY.NODES.RESERVOIR&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The normal_w function is used to generate weights for the reservoirpy.nodes.Reservoir organization."</data>
      <data key="d6">751b176a8d6149a853e597c65a6fe0cf</data>
    </edge>
    <edge source="&quot;TQDM&quot;" target="&quot;DATA SCIENTIST&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Data Scientist uses the tqdm library to monitor the progress of data loading."</data>
      <data key="d6">9fdaabd6c7e893a275a3848c10007477</data>
    </edge>
    <edge source="&quot;ROBOT PERFORMANCE EVALUATION&quot;" target="&quot;ROBOT PERFORMANCE&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Robot Performance Evaluation is a process used to assess Robot Performance."</data>
      <data key="d6">e7d249cdab85dc69b631d43ac6b62915</data>
    </edge>
    <edge source="&quot;CHAPTER 5&quot;" target="&quot;IPYTHON&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"IPython is used in Chapter 5 for displaying audio and visualizing data."</data>
      <data key="d6">1e8ee805d22cd143d2372d300997d253</data>
    </edge>
    <edge source="&quot;CHAPTER 5&quot;" target="&quot;PANDAS&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Pandas is used in Chapter 5 for data manipulation and analysis."</data>
      <data key="d6">1e8ee805d22cd143d2372d300997d253</data>
    </edge>
    <edge source="&quot;LPC (CEPSTRA)&quot;" target="&quot;SPEAKER DATA&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"LPC (cepstra) is used to analyze and extract features from Speaker Data."</data>
      <data key="d6">688ebc7151bc148ac24dc7e2727d7afe</data>
    </edge>
    <edge source="&quot;LINEAR MODEL&quot;" target="&quot;LASSO&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Lasso is a type of Linear Model that uses shrinkage to reduce complexity and prevent overfitting."</data>
      <data key="d6">eebc9d7d2b66e3898b7d068c38fd200f</data>
    </edge>
    <edge source="&quot;RESERVOIR MODEL&quot;" target="&quot;SK RIDGE&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Reservoir Model uses SK Ridge as one of its components."</data>
      <data key="d6">0970cd32ce54f6ee1180ab237fdcefe1</data>
    </edge>
    <edge source="&quot;RESERVOIR MODEL&quot;" target="&quot;SK LOGISTIC&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Reservoir Model uses SK Logistic as one of its components."</data>
      <data key="d6">0970cd32ce54f6ee1180ab237fdcefe1</data>
    </edge>
    <edge source="&quot;RESERVOIR MODEL&quot;" target="&quot;SK PERCEPTRON&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Reservoir Model uses SK Perceptron as one of its components."</data>
      <data key="d6">0970cd32ce54f6ee1180ab237fdcefe1</data>
    </edge>
    <edge source="&quot;RESERVOIR MODEL&quot;" target="&quot;SPEAKER&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"The Reservoir Model is used to predict or classify the Speaker."</data>
      <data key="d6">0970cd32ce54f6ee1180ab237fdcefe1</data>
    </edge>
    <edge source="&quot;MECHANICAL NANOOSCILLATORS&quot;" target="&quot;NONLINEAR RESERVOIR&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Mechanical Nanooscillators are used as a nonlinear reservoir."</data>
      <data key="d6">7767d42e08c8eab856e8e3025c692309</data>
    </edge>
    <edge source="&quot;POLYMER MIXTURES&quot;" target="&quot;NONLINEAR RESERVOIR&quot;">
      <data key="d4">1.0</data>
      <data key="d5">"Polymer Mixtures are used as a nonlinear reservoir."</data>
      <data key="d6">7767d42e08c8eab856e8e3025c692309</data>
    </edge>
  </graph>
</graphml>