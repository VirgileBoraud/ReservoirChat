# Jax performances comparison

```python
# Imports

import time



import numpy as np

import matplotlib.pyplot as plt

import jax



import reservoirpy as rpy

import esn_jax



rpy.verbosity(0)
```

```python
#jax.config.update("jax_platform_name", "cpu")

print(jax.numpy.ones(3).devices()) # Check if jax will run on gpu or cpu
```

```python
# Dataset

TIMESTEPS = 3_000

UNITS = 1000

CONNECTIVITY = 0.01

INPUT_CONNECTIVITY = 0.01



rng = np.random.default_rng(seed=2504)



x = rng.normal(size=(TIMESTEPS, 1))

y = rng.normal(size=(TIMESTEPS, 1))

```

## En fonction de $N$

```python
# En fonction de N, pourcentage de connectivité



unit_trials = np.logspace(2, 4.2, 8).astype(int)

fit_times = np.zeros((8, 2))

run_times = np.zeros((8, 2))



for i, units in enumerate(unit_trials):

    print(units)



    rpy_model = rpy.nodes.ESN(

        units=units,

        connectivity=CONNECTIVITY,

        input_connectivity=INPUT_CONNECTIVITY,

        ridge=1,

    )

    jax_model = esn_jax.ESN(

        units=units,

        connectivity=CONNECTIVITY,

        input_connectivity=INPUT_CONNECTIVITY,

        ridge=1,

    )



    start = time.time()

    rpy_model.fit(x, y)

    fit_time = time.time()

    rpy_model.run(x)

    stop = time.time()

    print(stop - start)



    fit_times[i, 0] = fit_time - start

    run_times[i, 0] = stop - fit_time



    start = time.time()

    jax_model.fit(x, y)

    fit_time = time.time()

    jax_model.run(x)

    stop = time.time()

    print(stop - start)



    fit_times[i, 1] = fit_time - start

    run_times[i, 1] = stop - fit_time
```

```python
np.save("fit_times_N_0,01_cpu", fit_times)

np.save("run_times_N_0,01_cpu", run_times)
```

```python
plt.figure(figsize=(16, 8))

plt.suptitle(

    f"timesteps={TIMESTEPS}, connectivity={CONNECTIVITY}, input_connectivity={INPUT_CONNECTIVITY}"

)

plt.subplot(1, 2, 1)

plt.title("Fit time")

plt.plot(unit_trials, fit_times[:, 0], color="red", label="ReservoirPy")

plt.plot(unit_trials, fit_times[:, 1], color="gold", label="Jax")

plt.legend()

plt.grid()

plt.subplot(1, 2, 2)

plt.title("Run time")

plt.plot(unit_trials, run_times[:, 0], color="red", label="ReservoirPy")

plt.plot(unit_trials, run_times[:, 1], color="gold", label="Jax")

plt.legend()

plt.grid()



plt.show()
```

```python
fit_cpu = np.load("fit_times_N_0,01_cpu.npy")[:, 1]

fit_gpu = np.load("fit_times_N.npy")[:, 1]

fit_rpy1 = np.load("fit_times_N.npy")[:, 0]

fit_rpy2 = np.load("fit_times_N_0,01_cpu.npy")[:, 0]



run_cpu = np.load("run_times_N_0,01_cpu.npy")[:, 1]

run_gpu = np.load("run_times_N.npy")[:, 1]

run_rpy1 = np.load("run_times_N.npy")[:, 0]

run_rpy2 = np.load("run_times_N_0,01_cpu.npy")[:, 0]



plt.figure(figsize=(16, 8))

plt.suptitle(

    f"timesteps={TIMESTEPS}, connectivity={CONNECTIVITY}, input_connectivity={INPUT_CONNECTIVITY}"

)

plt.subplot(1, 2, 1)

plt.title("Fit time")

plt.plot(unit_trials, fit_rpy1, color="red", label="ReservoirPy1")

plt.plot(unit_trials, fit_gpu, color="orange", label="Jax GPU")

plt.plot(unit_trials, fit_rpy2, color="#880000", label="ReservoirPy2")

plt.plot(unit_trials, fit_cpu, "--", color="orange", label="Jax CPU")

plt.legend()

plt.grid()

plt.subplot(1, 2, 2)

plt.title("Run time")

plt.plot(unit_trials, run_rpy1, color="red", label="ReservoirPy1")

plt.plot(unit_trials, run_gpu, color="orange", label="Jax GPU")

plt.plot(unit_trials, run_rpy2, color="#880000", label="ReservoirPy2")

plt.plot(unit_trials, run_cpu, "--", color="orange", label="Jax CPU")

plt.legend()

plt.grid()



plt.show()
```

### Avec compilation de la régression linéaire

```python
# En fonction de N

unit_trials = np.logspace(2, 4.2, 8).astype(int)

times = np.zeros((8, 3))



for i, units in enumerate(unit_trials):

    print(units)



    X = np.random.normal(size=(TIMESTEPS, units))

    Y = np.random.normal(size=(TIMESTEPS, 1))

    

    ridge_node = rpy.nodes.Ridge(ridge=1,input_bias=False)



    start = time.time()

    ridge_node.fit(X, Y)

    stop = time.time()

    print(stop - start)

    times[i, 0] = stop - start



    start = time.time()

    esn_jax.ESN._ridge_regression(1, X, Y)

    stop = time.time()

    times[i, 1] = stop - start

    print(stop - start)



    start = time.time()

    jax.jit(esn_jax.ESN._ridge_regression)(1, X, Y).block_until_ready()

    stop = time.time()

    times[i, 2] = stop - start

    print(stop - start)



plt.figure(figsize=(16, 8))

plt.title("Fit time, RPY vs uncompiled Jax vs JIT Jax")

plt.plot(unit_trials, times[:, 0], color="red", label="ReservoirPy")

plt.plot(unit_trials, times[:, 1], color="orange", label="uncompiled Jax")

plt.plot(unit_trials, times[:, 2], color="gold", label="JIT Jax")

plt.legend()

plt.grid()



plt.show()
```

```python


plt.figure()

plt.title("Fit time, RPY vs uncompiled Jax vs JIT Jax")

plt.plot(unit_trials, times[:, 0], color="red", label="ReservoirPy")

plt.plot(unit_trials, times[:, 1], color="orange", label="uncompiled Jax")

plt.plot(unit_trials, times[:, 2], color="gold", label="JIT Jax")

plt.legend()



plt.grid(alpha=0.5)



plt.show()
```

#### Degré de connectivité

```python
# En fonction de N



unit_trials = np.logspace(2, 4.2, 8).astype(int)

fit_times = np.zeros((8, 2))

run_times = np.zeros((8, 2))



for i, units in enumerate(unit_trials):

    print(units)



    rpy_model = rpy.nodes.ESN(

        units=units,

        connectivity=5/units,

        input_connectivity=5/units,

        ridge=1,

    )

    jax_model = esn_jax.ESN(

        units=units,

        connectivity=5/units,

        input_connectivity=5/units,

        ridge=1,

    )



    start = time.time()

    rpy_model.fit(x, y)

    fit_time = time.time()

    rpy_model.run(x)

    stop = time.time()

    print(stop - start)



    fit_times[i, 0] = fit_time - start

    run_times[i, 0] = stop - fit_time



    start = time.time()

    jax_model.fit(x, y)

    fit_time = time.time()

    jax_model.run(x)

    stop = time.time()

    print(stop - start)



    fit_times[i, 1] = fit_time - start

    run_times[i, 1] = stop - fit_time



np.save("fit_times_N_d3_cpu", fit_times)

np.save("run_times_N_d3_cpu", run_times)
```

```python


plt.figure(figsize=(16, 8))

plt.suptitle(

    f"timesteps={TIMESTEPS}, connectivity={CONNECTIVITY}, degree={5}"

)

plt.subplot(1, 2, 1)

plt.title("Fit time")

plt.plot(unit_trials, fit_times[:, 0], color="red", label="ReservoirPy")

plt.plot(unit_trials, fit_times[:, 1], color="gold", label="Jax")

plt.grid()

plt.legend()

plt.subplot(1, 2, 2)

plt.title("Run time")

plt.plot(unit_trials, run_times[:, 0], color="red", label="ReservoirPy")

plt.plot(unit_trials, run_times[:, 1], color="gold", label="Jax")

plt.grid()

plt.legend()



plt.show()
```

# TRÈS GROS RESERVOIRS SPARTI

```python
np.logspace(4, 5.5, 4).astype(int)
```

```python
# En fonction de N



unit_trials = np.logspace(4, 5.5, 4).astype(int)

times = np.zeros((4, ))



for i, units in enumerate(unit_trials):

    print(units)



    jax_model = esn_jax.ESN(

        units=units,

        connectivity=5/units,

        input_connectivity=5/units,

        ridge=1,

    )



    start = time.time()

    jax_model.fit(x, y)

    stop = time.time()

    print(stop - start)



    times[i] = stop - start



np.save("large_reservoirs", times)
```

```python


import math

import operator



from jax import dtypes

from jax import vmap

from jax import random

from jax.util import split_list

import jax.numpy as jnp

from jax.experimental import sparse



import numpy as np

import jax



def random_bcoo(

  key,

  shape,

  *,

  dtype=jnp.float_,

  indices_dtype=None,

  nse=0.2,

  n_batch=0,

  n_dense=0,

  unique_indices=True,

  sorted_indices=False,

  generator=random.uniform,

  **kwds,

):

  shape = tuple(map(operator.index, shape))

  n_batch = operator.index(n_batch)

  n_dense = operator.index(n_dense)

  if n_batch < 0 or n_dense < 0 or n_batch + n_dense > len(shape):

    raise ValueError(f"Invalid {n_batch=}, {n_dense=} for {shape=}")

  n_sparse = len(shape) - n_batch - n_dense

  batch_shape, sparse_shape, dense_shape = map(

    tuple, split_list(shape, [n_batch, n_sparse])

  )

  print(f"{shape=}, {n_batch=}, {n_sparse=}, batch_shape, sparse_shape, dense_shape: {batch_shape, sparse_shape, dense_shape}")



  batch_size = math.prod(batch_shape)

  sparse_size = math.prod(sparse_shape)

  if not 0 <= nse < sparse_size:

    raise ValueError(f"got {nse=}, expected to be between 0 and {sparse_size}")

  if 0 < nse < 1:

    nse = int(math.ceil(nse * sparse_size))

  nse = operator.index(nse)



  data_shape = batch_shape + (nse,) + dense_shape

  indices_shape = batch_shape + (nse, n_sparse)

  if indices_dtype is None:

    indices_dtype = dtypes.canonicalize_dtype(jnp.int_)

  if sparse_size > jnp.iinfo(indices_dtype).max:

    raise ValueError(

      f"{indices_dtype=} does not have enough range to generate "

      f"sparse indices of size {sparse_size}."

    )

  print(3)



  @vmap

  def _indices(key):

    if not sparse_shape:

      return jnp.empty((nse, n_sparse), dtype=indices_dtype)

    flat_ind = random.choice(

      key, sparse_size, shape=(nse,), replace=not unique_indices

    ).astype(indices_dtype)

    return jnp.column_stack(jnp.unravel_index(flat_ind, sparse_shape))



  keys = random.split(key, batch_size + 1)

  print(4)

  data_key, index_keys = keys[0], keys[1:]

  print(5, data_key, data_shape, dtype, kwds)

  data = generator(data_key, shape=data_shape, dtype=dtype, **kwds)

  print(6)

  indices = _indices(index_keys).reshape(indices_shape)

  print(7)

  mat = sparse.BCOO((data, indices), shape=shape)

  return mat.sort_indices() if sorted_indices else mat
```

```python
sparse_shape = (31622, 31622)

sparse_size = np.prod(sparse_shape)

nse=100

n_sparse = 2

unique_indices = False



key=jax.random.PRNGKey(seed=1)

keys = random.split(key, 2)



@vmap

def _indices(key):

    if not sparse_shape:

        return jnp.empty((nse, n_sparse), dtype=jnp.float32)

    print("XDDDDDDD")

    flat_ind = random.choice(

        key, sparse_size, shape=(nse,), replace=not unique_indices

    ).astype(dtypes.canonicalize_dtype(jnp.int_))

    print("AAAAAAAA")

    unraveled = jnp.unravel_index(flat_ind, sparse_shape)

    print("EEEEEEEE")

    return jnp.column_stack(unraveled)



_indices(keys)
```

```python
import os



os.environ["XLA_PYTHON_CLIENT_PREALLOCATE"]="false"
```

```python
import jax

import os

from jax.experimental import sparse

import numpy as np



W = random_bcoo(

    key=jax.random.PRNGKey(seed=1),

    shape=(31622, 31622),

    dtype=np.float32,

    indices_dtype=int,

    nse=100,

    n_batch=0,

    n_dense=0,

    unique_indices=False,

    generator=jax.random.normal,

)
```

```python
import jax

import os

from jax.experimental import sparse

import numpy as np



os.environ["XLA_PYTHON_CLIENT_PREALLOCATE"]="false"

os.environ["XLA_PYTHON_CLIENT_MEM_FRACTION"]=".25"

os.environ["XLA_PYTHON_CLIENT_ALLOCATOR"]="platform"





@jax.jit

def test(a):

    W = a*sparse.random_bcoo(

        key=jax.random.PRNGKey(seed=1),

        shape=(31622, 31622),

        dtype=np.float32,

        indices_dtype=int,

        nse=0.001,

        generator=jax.random.normal,

    )

    Win = sparse.random_bcoo(

        key=jax.random.PRNGKey(seed=1),

        shape=(1, 31622),

        dtype=np.float32,

        indices_dtype=int,

        nse=0.001,

        generator=jax.random.normal,

    )

    return 1. * Win * W * Win.T



test(2.)
```

```python

```

