Neuromorphic hardware as a self-organizing computing
system
Lyes Khacef, Bernard Girau, Nicolas P. Rougier, Andres Upegui, Benoit

Miramond

To cite this version:

Lyes Khacef, Bernard Girau, Nicolas P. Rougier, Andres Upegui, Benoit Miramond. Neuromorphic
hardware as a self-organizing computing system. WCCI 2018 - IEEE World Congress on Computa-
tional Intelligence, Workshop NHPU : Neuromorphic Hardware In Practice and Use, Jul 2018, Rio de
Janeiro, Brazil. pp.1-4. ￿hal-01790776￿

HAL Id: hal-01790776

https://hal.science/hal-01790776

Submitted on 18 May 2018

HAL is a multi-disciplinary open access
archive for the deposit and dissemination of sci-
entific research documents, whether they are pub-
lished or not. The documents may come from
teaching and research institutions in France or
abroad, or from public or private research centers.

L’archive ouverte pluridisciplinaire HAL, est
destinée au dépôt et à la diffusion de documents
scientifiques de niveau recherche, publiés ou non,
émanant des établissements d’enseignement et de
recherche français ou étrangers, des laboratoires
publics ou privés.

Neuromorphic hardware as a self-organizing
computing system

Lyes Khacef1, Bernard Girau2, Nicolas Rougier3, Andres Upegui4, Benoˆıt Miramond1,∗
1 University Cˆote d’Azur - LEAT / CNRS UMR 7248 2 University of Lorraine - Loria
3 Inria Bordeaux Sud-Ouest - LaBRI / University of Bordeaux / CNRS UMR 5800
4 University of Applied Sciences of Western Switzerland InIT - hepia - HES-SO
∗ Corresponding author: benoit.miramond@unice.fr

Abstract—This paper presents the self-organized neuromor-
phic architecture named SOMA. The objective is to study neural-
based self-organization in computing systems and to prove the
feasibility of a self-organizing hardware structure. Considering
that these properties emerge from large scale and fully connected
neural maps, we will focus on the deﬁnition of a self-organizing
hardware architecture based on digital spiking neurons that
offer hardware efﬁciency. From a biological point of view, this
corresponds to a combination of the so-called synaptic and
structural plasticities. We intend to deﬁne computational models
able to simultaneously self-organize at both computation and
communication levels, and we want these models to be hardware-
compliant, fault tolerant and scalable by means of a neuro-
cellular structure.

I. INTRODUCTION

Several current issues such as analysis and classiﬁcation of
major data sources (sensor fusion, Internet of Things, etc.), and
the need for adaptability in many application areas (automotive
systems, autonomous drones, space exploration, etc.), lead us
to study a desirable property from the brain that encompasses
all others: the cortical plasticity. This term refers to one of the
main developmental properties of the brain where the organi-
zation of its structure (structural plasticity) and the learning of
the environment (synaptic plasticity) develop simultaneously
toward an optimal computing efﬁciency. Such developmental
process is only made possible by some key features: focus on
relevant information, representation of information in a sparse
manner, distributed data processing and organization ﬁtting the
nature of data, leading to a better efﬁciency and robustness.
Our goal is to understand and design the ﬁrst artiﬁcial blocks
that are involved in these principles of plasticity. Hence,
transposing plasticity, and its underlying blocks, into hardware
will contribute to deﬁne a substrate of computation endowed
with self-organization properties stemming from the learning
of incoming data.

to
Neural principles of plasticity may not be sufﬁcient
ensure that such a substrate of computation is scalable enough
in the perspective of future massively parallel an distributed
devices. Our claim is that the expected properties of such
alternative computing devices could emerge from a close inter-
action between cellular computing (decentralization and hard-
ware compliant massive parallelism) and neural computation
(self-organization and adaptation). We also claim that neuro-
cellular algorithmics and hardware design are so tightly related

that these two aspects should be studied together. Therefore we
propose to combine neural adaptativity and cellular computing
efﬁciency through a neuro-cellular approach of synaptic and
structural self-organization that deﬁnes a fully decentralized
control layer for neuromorphic reconﬁgurable hardware.

For this aim, the project gathers neuroscientists, computer
science researchers, hardware architects and micro-electronics
designers to explore the concepts of a Self-Organizing Ma-
chine Architecture: SOMA. This Self-Organization property
already studied in various ﬁelds of computer science (artiﬁcial
neural networks, multi-agents and swarm systems, cellular au-
tomata, etc.), is studied for the very ﬁrst time in a new context
with a transverse look from the computational neuroscience
discipline to the design of reconﬁgurable microelectronic cir-
cuits. The project focuses on the blocks that will pave the way
in the long term for smart computing substrates, exceeding
the limits of current technology. The SOMA architecture will
practically deﬁne an original brain-inspired computing system
that will be prototyped onto FPGA devices.

II. SELF-ORGANIZING NEURAL MODELS

The gap between existing ﬁxed computing systems and
dynamic self-organized substrates may be ﬁlled with the help
of computational neuroscience through the deﬁnition of neural
models that exhibit properties like unsupervised learning, self-
adaptation, self-organization, and fault tolerance which are of
particular interest for efﬁcient computing in embedded and
autonomous systems. However, these properties only emerge
from large fully connected neural maps that result in intensive
synaptic communications. Previous works have for example
already showed the possibility of using neural self-organizing
models to control task allocation in manycore substrates [1].
Other works have also proposed adaptation of neural com-
putational paradigms to cellular (neighborhood) constraints
(DMAD-SOM [2], RSDNF [3], CASAS [4]). Previous works
have also studied different approaches to deﬁne cellular self-
reconﬁguration [5] and self-organization [6] onto FPGA-based
hardware. This paper addresses the challenge of deﬁning a
neural model supporting hardware self-organization by lying at
the intersection of four main research ﬁelds, namely adaptive
reconﬁgurable computing, cellular computing, computational
neuroscience, and hardware neurocomputing. We thus propose
a dynamically laterally connected neural model (map) that

permits us to think about modifying the network topology in
order to better ﬁt the probability density function of incom-
ing data. Synaptic pruning and sprouting are two biological
mechanisms permitting structural plasticity. In the case of the
model presented here, we are only using pruning by deﬁning
a probability for a lateral synaptic connection to be removed.
A useless synapse connects two neurons whose activities are
poorly correlated. Such poor correlation is expressed as a high
distance between the weight vectors representing both neurons,
and a very low activity (winning) of neurons which reﬂects
a poor capability of the prototype vector to represent the
probability density function. All these factors are modulated
by a pruning rate w and determine the probability of a given
synapse to be removed as illustrated in Figure 1.

Fig. 1. (Left) Cellular architecture connections after training with w = 3e −
07. (Right) Weights and probability density after training with w = 3e − 07.

III. SELF-ORGANIZING MACHINE ARCHITECTURE

The neural-based mechanism responsible of

the self-
organization is integrated into a cellular processing archi-
tecture. It is decomposed in four distinct layers intended to
provide the hardware plasticity targeted by the SOMA project.
These layers are: (1) data acquisition, (2) pre-processing,
which can be in the form of feature extraction, (3) self-
organization of computation and communications, and (4)
computation in the form of a reconﬁgurable computation unit
(FPGA or processor). These four architecture layers have been
presented in [2] and we already designed preliminary versions
of the three ﬁrst layers in [1], [7].

The ﬁrst results obtained with this architecture showed that
the system was able to solve a task allocation problem in a
distributed way. Yet, the means to achieve it are not completely
satisfactory for several reasons. First, the system architecture,
although adaptive, relies on a neural model whose structure
is ﬁxed a priori and often results in expensive communica-
tion times. Secondly, the architecture does not implement a
distributed clustering algorithm, which makes it difﬁcult to
classify a node into a computing area once the neural network
has learned the data from the environment.

Finally, the adaptation is based on the temporal correlations
between the modalities in the input space, which leads to a
considerable increase in the number of clusters (areas) in the
computation architecture. The aim of this paper is to avoid
the issues mentioned above by proposing an evolution of the
existing adaptive methods. This method takes advantage of
synaptic pruning and will lighten the cost of communication
over the learning process to isolate the neurons belonging

to the same cluster. The third problem could be raised by
hierarchically constructing a single neural map per data type
and a upper map for the merge of the different modalities.

The proposed self-organizing mechanisms will be exploited
by user-deﬁned applications running on a multicore array
in the form of a NoC-based manycore system. The NoC
architecture we currently use is based on the HERMES
routing architecture [8] for inter-node communication, for
which we previously proposed an adapted version of the
NoC architecture to support dynamic reconﬁguration [7]. The
main novelty concerns the coupling with the self-organizing
mechanism. The routing layer implements the neural model
brieﬂy presented in section II. The model has been adapted
for cellular architectures and integrates pruning capabilities.
We applied the model to a quantization problem where we
the organization of the hardware to a den-
try to adapt
sity function representing the environment as illustrated in
Figure 1. Preliminary results have shown that the method
removes useless lateral connections in order to better ﬁt the
target probability density functions. The results showed that
the proposed pruning mechanisms may improve the network
performance by reducing the average quantization error of
the incoming stimuli as illustrated in Figure 2. In our future

Fig. 2. AQE vs. time for different pruning rates w. w (cid:54)= 0 corresponds to a
dynamic neural map with pruning enabled.

works, the self-organizing layer will be responsible for the
coordination of nodes in order to decide which node must deal
with new incoming data in a completely decentralized manner.
It will also be able to reconﬁgure the computing layer in order
to better ﬁt the hardware to the nature of incoming data.

IV. CONCLUSION

Hence, this paper proposed a convergence point between
past research approaches toward new computation paradigms
based on adaptive reconﬁgurable architecture and neuromor-
phic hardware. The presented SOMA architecture is based
on cellular computing and targets a massively parallel, dis-
tributed and decentralized neuromorphic architecture. The self-
organizing mechanism integrated into the architecture is based
on neural models inspired from brain plasticity where the
hardware organization emerges from the interactions between
neural maps transposed into hardware. The ﬁrst results pre-
sented in this paper have shown how such dynamical structure
can adapt to random data representing a dynamic and evolving
environment.

05000100001500020000iterations0.050.060.070.080.090.10AQEω=1e-07ω=3e-07ω=1e-06ω=3e-06ω=1e-05ω=0ω=3e-08ω=3e-05REFERENCES

[1] L. Rodriguez, L. Fiack, and B. Miramond, “A neural model for hardware
plasticity in artiﬁcial vision systems,” in Proceedings of the Conference
on Design and Architectures for Signal and Image Processing (DASIP),
2013.

[2] L. Rodriguez, B. Miramond, and B. Granado, “Toward a sparse self-
organizing map for neuromorphic architectures,” ACM Journal on Emerg-
ing Technologies in Computing Systems, vol. 11, no. 4, p. 33, Apr. 2015.
[3] B. Chappet De Vangel, C. Torres-Huitzil, and B. Girau, “Randomly
spiking dynamic neural ﬁelds,” Journal of Emerging Technologies in
Computing Systems, 2014.

[4] B. Chappet De Vangel and B. Girau, “Stochastic and asynchronous
spiking dynamic neural ﬁelds,” in International Joint Conference on
Neural Networks, ser. 2015 International Joint Conference on Neural
Networks, IJCNN 2015, Killarney, Ireland, Jul. 2015.

[5] A. Stauffer, D. Mange, J. Rossier, and F. Vannel, “Bio-inspired self-
organizing cellular systems,” Biosystems, vol. 94, no. 1-2, pp. 164–169,
2008.

[6] B. Girau, C. Torres-Huitzil, N. Vlassopoulos, and J. H. Barron-Zambrano,
“Reaction diffusion and chemotaxis for decentralized gathering on fpgas,”
Int. J. Reconﬁg. Comp., vol. 2009, pp. 639 249:1–639 249:15, 2009.
[7] L. Fiack, B. Miramond, A. Upegui, and F. Vannel, “Dynamic parallel
reconﬁguration for self-adaptive hardware architectures,” in NASA/ESA
Conference on Adaptive Hardware and Systems (AHS-2014), 2014.
[8] F. Moraes, N. Calazans, A. Mello, L. M¨oller, and L. Ost, “Hermes: an
infrastructure for low area overhead packet-switching networks on chip,”
INTEGRATION, the VLSI journal, vol. 38, no. 1, pp. 69–93, 2004.

