Modeling non-standard retinal in/out function using computer vision
variational methods Elaa Teftef, Maria-Jose Escobar, Aland Astudillo,
Carlos Carvajal, Bruno

Cessac, Adrian Palacios, Thierry Viéville, Frédéric Alexandre

To cite this version:

Elaa Teftef, Maria-Jose Escobar, Aland Astudillo, Carlos Carvajal, Bruno
Cessac, et al.. Modeling non-standard retinal in/out function using
computer vision variational methods. [Research Report] RR-8217, INRIA.
2013, pp.28. ￿hal-00783091v2￿

HAL Id: hal-00783091

https://inria.hal.science/hal-00783091v2

Submitted on 1 Feb 2013

HAL is a multi-disciplinary open access archive for the deposit and
dissemination of sci- entific research documents, whether they are pub-
lished or not. The documents may come from teaching and research
institutions in France or abroad, or from public or private research
centers.

L’archive ouverte pluridisciplinaire HAL, est destinée au dépôt et à la
diffusion de documents scientifiques de niveau recherche, publiés ou
non, émanant des établissements d’enseignement et de recherche français
ou étrangers, des laboratoires publics ou privés.

Modeling non-standard retinal in/out function using computer vision
variational methods

E. Teftef1, M.-J. Escobar2, A. Astudillo2, C. Carvajal1, B. Cessac4,
A.G. Palacios3, T. Viéville1, F. Alexandre1. (1) Inria Mnemosyne/Cortex
http://team.inria.fr/mnemosyne, France. (2) Universidad Técnica Federico
Santa María, Electronics Engineering Department, Chile. (3) Universidad
de Valparaíso, Centro Interdisciplinario de Neurociencia de Valparaiso,
Chile. (4) Inria Neuromathcomp, France.

G N E + R F - - 7 1 2 8 - -

RESEARCH REPORT N° 8217 Janvier 2013

Project-Teams Mnemosyne

I

N R S

I

9 9 3 6 - 9 4 2 0 N S S

I

/

R R A R N

I

Modeling non-standard retinal in/out function using computer vision
variational methods

E. Teftef1, M.-J. Escobar2, A. Astudillo2, C. Carvajal1, B. Cessac4,
A.G. Palacios3, T. ViØville1, F. Alexandre1. ∗

(1) Inria Mnemosyne/Cortex http://team.inria.fr/mnemosyne, France.
(2) Universidad TØcnica Federico Santa Mar(cid:237)a, Electronics
    Engineering Department, Chile.
(3) Universidad de Valpara(cid:237)so, Centro Interdisciplinario de
    Neurociencia de Valparaiso, Chile.
(4) Inria Neuromathcomp, France.

Project-Teams Mnemosyne

Research Report n

(cid:176)

8217 (cid:22) Janvier 2013 (cid:22) 27 pages

Abstract: We propose a computational approach using a variational
speci(cid:28)cation of the visual front-end, where ganglion cells with
properties of retinal Konio cells (K-cells), are considered as a
network, yielding a mesoscopic view of the retinal process. The
variational framework is imple- mented as a simple mechanism of
di(cid:27)usion in a two-layered non-linear (cid:28)ltering mechanism
with feedback, as observed in synaptic layers of the retina, while its
biological plausibility, and capture functionalities as (i) stimulus
adapted response; (ii) non-local noise reduction (i.e. segmentation);
(iii) visual event detection, taking several visual cues into account:
contrast and local texture, color or edge channels, and motion base in
natural images. Those functionalities could be implemented in the
biological tissues We use computer vision methods to propose an
e(cid:27)ective link between the observed functions and their possible
implementation in the retinal network base on a two-layers network with
non- separable local spatio-temporal convolution as input, and recurrent
connections performing non- linear di(cid:27)usion before prototype
based visual event detection. The numerical robustness of the proposed
model has been experimentally checked on real natu- ral images. Finally,
we discuss in base of experimental biological and computational results
the generality of our description.

Key-words: No keywords

∗ Supported by the CONICYT/ANR KEOpS project and CORTINA associated
team.

RESEARCH CENTRE BORDEAUX – SUD-OUEST

351, Cours de la Libération Bâtiment A 29 33405 Talence Cedex

ModØlisation de la fonction d’entrØe/sortie non-standard de la rØtine
(cid:224) partir de mØthodes variationnelles de vision par ordinateur

RØsumØ : Nous proposons ici une approche fonctionnelle de la description
des propriØtØs des cellules rØtiniennes dites Konio, ceci au niveau du
rØseau, en utilisant une spØci(cid:28)cation variation- nelle, ce qui
donne une vue mØsoscopique du processus de calcul de la rØtine. Le cadre
variationnel est implØmentØ comme un simple mØcanisme de di(cid:27)usion
non-linØaire, mØ- canisme de (cid:28)ltrage avec rØtroaction, suivi
d’une couche d’unitØs ajustØes (cid:224) un ØlØment statistique de la
scŁne, comme on l’observe dans les couches synaptiques de la rØtine pour
ces cellules. On se propose de capturer les fonctionnalitØs suivantes:
(i) adaptation de la rØponse aux statis- tiques des stimuli naturels,
(ii) rØduction non-locale du bruit (en lien avec la segmentation de
l’image), et (iii) dØtection d’ØvØnements visuels, en tenant compte de
plusieurs indices visuels: contraste local, texture ou couleur, ces
amers Øtant gØnØralisables (cid:224) des canaux de calcul de mouvement.
Ces fonctionnalitØs peuvent Œtre mises en (cid:247)uvre dans les tissus
biologiques, comme on le discute ici. Nous utilisons des mØthodes de
vision par ordinateur pour proposer une description fonctionnelle du
calcul e(cid:27)ectuØ au niveau de la rØtine. La robustesse numØrique du
modŁle proposØ a ØtØ vØri(cid:28)Ø expØrimentalement au niveau numØrique
sur de vØritables images naturelles. Nous discutons, sur la base de
rØsultats expØrimentaux bi- ologiques et informatiques, la gØnØralitØ de
notre description.

Mots-clØs : Pas de motclef

Modeling non-standard retinal in/out function using computer vision
variational methods

3

1 Introduction

Recently it has been proposed that the retina, a accessible part of the
brain, sustain more complex behaviors than expected before (Masland &
Martin, 2007), including spatial, temporal and motion recognition
(Schwartz & Michael, 2008) (Olveczky, Baccus, & Meister, 2003). The
retina correspond to a multi-stream device including from
phototransduction to early visual processing and neural coding, at
di(cid:27)erent spatial and temporal scales. At the application level, a
computing parallel information streams system for (e.g.) visual
prosthesis is likely to need an important post-processing level before
visual signals feed the nervous system (Barriga-Rivera & Suaning, 2011).
For the later, an adequate computational architecture should have at
least two-layers network with non-separable local spatio-temporal
convolution as input, and recurrent connections performing non-linear
di(cid:27)usion before prototype based visual event detection.

The present article is organized as follow: In the section 2, we review
key biological facts at the early dorsal and ventral K-cells visual
streams, computing sophisticated spatial and temporal pattern
recognition as review in the next section, 3, base on (Gollisch &
Meister, 2010; Litke et al., 2004; Schwartz & Michael, 2008; Olveczky et
al., 2003; Sterling, 2004). In the subsequent section 4, we implement
the computational principles raised by the study on the retinal K- cells
(Hendry & Reid, 2000; Yoonessi & Yoonessi, 2011) using a variational
speci(cid:28)cation of the visual front-end, base on a network of
retinal ganglion cells. In the section 5, we implemented a numerical
model to study real image sequences and (cid:28)nally model predictions
are presented to veri(cid:28)ed biological validity.

2 From standard to non-standard early-vision front-end

Standard front-end retinal streams

The retinal output correspond to several di(cid:27)erent spatio-temporal
processing, base on a diversity of ganglion cells (Gc) types, the output
of the retina to the nervous system, of the incoming image sequence.
Such streams are embodied as separate strata that span the retina at the
Gc surface.

It is generaly accepted, that the (i) parvo (P-cells) and (ii) magno
(M-cells) streams, compute respectively (i) color image details and
contrast in central vision and (ii) monochrome intensity temporal
variation, including at very low contrast, in peripheral vision and
(iii) konio streams (K-cells) projecting to the LGN (middle layer)
receive information from blue cones, sending information to the V1 color
blobs (Hendry & Reid, 2000) and from small bistrati(cid:28)ed Gc having
a surround which is sensitive to yellow (G. Field et al., 2007). Here,
we are going to focus on a subset of K-cells, beyond their color
property, as detailed in the sequel. For other types of Gc see, e.g.,
(Callaway, 1998).

At the modeling level, information streams (i) and (ii) are well
represented by LN models, i.e., a one layer spatio-temporal
(cid:28)ltering followed by a static non-linearity, as represented in
the right part of Fig. 2, this unit being tuned by a gain control
mechanism, as reviewed e.g., in (Wohrer, 2008). Qualitatively, such
non-linear (cid:28)ltering tends to remove spatial correlations in the
visual world, producing a less redundant output, as required to transmit
information in the optic nerve (cid:28)bers of limited spatial capacity
(see (Pitkow & Meister, 2012) for a discussion), resulting in a sparse
coding for retinal spike trains in response to the statistics of natural
images (Simoncelli, 2003).

(cid:176) RR n

8217

4

E. Teftef & others

Figure 1: Schematic representation of projections of the K-cells from
(Masland & Martin, 2007) and (Nassi & Callaway, 2009).

Considering retinal output K-streams

While standard magno/parvo Gc downstream correspond to the standard
visual dorsal/ventral streams (leftward drawing) after a relay in the
ventral/dorsal LNG layers (rightward drawing); K-cells projections are
more miscellaneous (leftward drawing) and interact with the parvo/magno
streams in the LGN and via the V1 2/3 (rightward drawing). Connections
from the retina are feed-forward, while all other brain connections
include feed-backs. In a purposive view of visual perception, the
parietal cortex performs from such input an unconscious, e(cid:30)cient,
specialized and rapid processing of the whole visual (cid:28)eld, and
prepares actions adapted to the characteristics of the environment. In
addition K-cells connect via the LGN to important multi-sensorial areas
like the amygdala lateral nucleus (ALN) involved in the control of
emotion (Ciocchi et al., 2010), thus in direct link with survival
actions.

Importance of the K-streams

Quantitatively, 80% of the Gc are midget towards the P-cells in the
thalamus, because of the need of (cid:28)ne spatial resolution to
perceive visual details. Only 10% are parasol Gc towards the M-cells in
the thalamus, and 10% are bistrati(cid:28)ed Gc (K-cells) towards the
superior colliculus and the LGN layers (G. D. Field et al., 2007).
Though such non-standard retinal cells are in proportion few in primates
(whereas up to 75% in phylogenetically earlier mammalians) they
constitute robust and well-identi(cid:28)ed cell mapping of the visual
(cid:28)eld (Gauthier et al., 2009). This lower proportion is easily
explained: Having large receptive (cid:28)eld (RF) about 10 deg, the
cover of the whole retinal (cid:28)eld required less units.

In the human eye, about 130 millions of photoreceptors, where 120
millions are rods and 10

Inria

Modeling non-standard retinal in/out function using computer vision
variational methods

5

millions are cones, concentrate onto about 1.5 millions of Gc, including
the 105 K-cells considered here.

The key computational aspect of K-streams

The current computational assumption here consider that K-cells streams
provide rough but fast event or object -detection of visual events
(Hendry & Reid, 2000)(Masland & Martin, 2007) in order to induce
survival goal-directed actions on time (V. Lamme & Roelfsema, 2000), and
to drive higher-level iterative processes with prior information
(Callaway, 1998; Koivisto, Railo, Revonsuo, Vanni, & Salminen-Vaparanta,
2011). Given natural image sequences, we interpret these two
functionalities as image segmentation for visual objects detection and
natural statistical recognition, including temporal pattern recognition.
In the other hand, K-cells participate to blind-sight (V. A. Lamme,
2001; Cowey, 2010), i.e., or not consciously seen, including, slowly
moving targets detection, rough localization of stimulus. This is
typically information not for (cid:16)seeing(cid:17) but for visually
guided behavior. There are some evidences, that such computation starts
in the retina:

(i) Some retinal Gc are able to produce sophisticated spatial and
    temporal pattern recogni- tion on their own (Gollisch & Meister,
    2010; Werblin, 2011), including motion detection, directional
    selectivity, local edge detection, object motion and looming
    detection.

(ii) During phylogenetical evolution, the eye was not a simple
     feed-forward system: Feed-backs from the remainder of the nervous
     system had been able to produce adaptive learning of sophisticated
     visual functions (cid:16)optimizing the transfer of
     information(cid:17) (Sterling, 2004).

(iii) Fast stimulus categorization develops roughly 150 ms after
      stimulus onset (Thorpe, Fize, & Marlot, 1996). In that respect the
      visual processing need to perform this using only few computation
      steps (ViØville & Crahay, 2004).

(iv) From an information processing point of view, regarding downstream
     computation, it is op- timal to take into-account the whole spatial
     and temporal resolution of the photo-receptors before the necessary
     compression occurring in the optical nerve to implement such
     complex non-linear (cid:28)ltering (Simoncelli, 2003).

These are the key elements that di(cid:27)erentiate the K-cells from
parvo/magno streams. In nutschell, the K-stream provides fast, a-priori
event detection assumptions, to the remainder of the visual system (V.
Lamme & Roelfsema, 2000).

3 Retinal architecture and biological constraints

What are the biological constraints regarding what can be computed in
the retina (i.e., the computational characteristics)?.

In order to derive a mesoscopic model of K-cells input/output function
let us collect known

facts about the computational properties of the retina, as schematized
in Fig. 2.

Here are the three major features we propose to take into account:

1.  Not one but two layers: It is clear that, by no means, a simple
    feed-forward (cid:28)ltering layer, even non-linear, can compute
    complex visual cues such as those reviewed above. On the other hand,
    it is known that a two layers non-linear feed-forward network, i.e.,
    with a (cid:16)hidden(cid:17) layer, is a universal approximator of
    any function. For a static input/output relationship, i.e., a unique
    image as input with a unique related output, a neural network

(cid:176) RR n

8217

6

E. Teftef & others

left: Schematic representation of the retinal architecture, after
(Wohrer, 2008) and Figure 2: (Gollisch & Meister, 2010). Excitatory
connections are in red, inhibitory in blue. Gap junc- tions are in red
with a black contour, neighboring cells of the same type being generally
linked through gap junctions. The direct pathway from light receptors to
Gc is a two-layers process de(cid:28)ning two successive non-linear
(cid:28)ltering stages with di(cid:27)erent excitatory-inhibitory
patterns. The present mesoscopic model is compatible with such an
architecture, but requires a subset of this architecture (highlighted in
yellow). This pathway is modulated by the interstitial cells in each
layer. Here, we have emphasized that non-linearities are present on each
link. right: The basic view of cell unit processing: (i) spatial
(cid:28)ltering (gray arrow) speci(cid:28)ed by the wired connectivity,
combined by a (ii) band-pass temporal (cid:28)lter, thus including
delays, (blue rectangle) and (iii) followed by a thresholding operation.

Inria

Modeling non-standard retinal in/out function using computer vision
variational methods

7

(e.g. retina) with two layers is a su(cid:30)cient architecture for
generic computations (Hornik, Stinchcombe, & White, 1989). For a dynamic
input, i.e., an image sequence, this basic idea has to be generalized,
and we propose the following.

2.  Non separable spatio-temporal (cid:28)ltering: At a given time, we
    consider that the retina input state is a function of the short-term
    visual information and that the output is a causal function of this
    2D+T image volume.

Quantitatively, we may consider the last 150 ms interval as temporal
depth (Li, 1992), with a visual minimal event-time of about 10 ms: This
thus correspond to a dozen of (cid:16)frames(cid:17) when time is
discretized.

-   This means that the spatio-temporal (cid:28)ltering is local, i.e.,
    only spatial connections from neighborhood cells are taken into
    account, while in the temporal domain the (cid:28)ltering is only
    due to delays in the biological substrate and connections. This
    seems to be fairly true for the outerplexiform layer (OPL) (i.e. for
    horizontal cells) which corresponds to the (cid:28)ltering mechanism
    considered here. This is less obvious for amacrine cells in the IPL
    (Werblin, 2011), likely involved in mechanisms not addressed here.

-   This means that the spatio-temporal (cid:28)lters are constrained:
    not all (cid:16)weight(cid:17) values can be used, but only values
    with signs compatible with the excitatory/inhibitory connections,
    and value ranges taking into account the nature of the connection
    (e.g., gap junction versus synaptic junctions). All synapses have a
    delay, increasing as a function of the connection length.

-   This means that the output at a given time is a static function a
    2D+T volume, thus computing local motion in the image sequence, but
    no long-term motion cue. Therefore the previous argument of a
    two-layers architecture is su(cid:30)cient for complex function ap-
    proximation still stands for dynamic stimuli in this restrained
    framework.

-   This also means that the spatio-temporal (cid:28)ltering is
    non-separable: In other words, we do not consider a sequence of 2D
    image (thus spatial (cid:28)ltering each image and then temporal
    (cid:28)ltering the result) but the (cid:28)ltering of the 2D+T
    volume.

In fact, as made explicit before (Gollisch & Meister, 2010; Dong, 2001),
the retinal structure induces a separable spatio-temporal
(cid:28)ltering if we consider a cell (cid:16)alone(cid:17) in a
standard parvo-stream, but di(cid:27)erent if we consider interactions
between cells, and also consider that the retina is adapted to natural
image stimuli, as suggested by (Dong, 2001).

3.  Recurrent connections: The general architecture de(cid:28)nitely
    shows that the hard-wiring pro- vides feed-forward connections and
    recurrent (horizontal and feed-back) connections, as made explicit
    in Fig. 2.

-   Recurrent connections as local di(cid:27)usion. These connections
    are local, continuous and with tiny delays (i.e. based on
    gap-junctions on local non-spiking very short dendrite/axon
    connections) (Sterling, 2004). Qualitatively, this corresponds to
    local di(cid:27)usion of the state value, here mainly corresponding
    to the membrane voltage value.
-   Static non-linearities everywhere. Another key aspect is the fact
    that each connection is subject to a static non-linearity with a
    main characteristic: Threshold corresponding to a
    recti(cid:28)cation of the signal. The recti(cid:28)cation is not
    related to action potential spiking (except for the Gc output), but
    to bio-chemical membrane mechanisms.

(cid:176) RR n

8217

8

E. Teftef & others

3.1 Functional characteristics of the retinal network

The retina is able to compute local isotropic contrast and intensity
temporal variation detection, but requires speci(cid:28)c
functionalities.

-A- stimulus adapted response

From raw light intensity event detection (including dim light
(cid:29)ashes), to RF responses corre- sponding to the basis element of
natural images decomposition (Hyv(cid:228)rinen, 2009), the primary
aspect of the retinal input-output function is to be adapted not only to
the general statistics of natural images, as observed in the LGN
projections (Dan, Atick, & Reid, 1996), but also to dynamic changes in
the statistics of a given environment (Hosoya, Baccus, & Meister, 2005).
Such stimulus adaptation is implemented by a suitable choice of the
local 2D+T convolution kernel induced by the local network connectivity
(Wohrer, 2008). Such (cid:28)lter elements span the space of possible
relevant local input (Hyv(cid:228)rinen, 2009).

However, beyond the hard-wiring of such connections, a local adaptation
must occur to optimize the response. This also means that the retinal
(cid:28)ltering is not only adapted to (cid:16)any(cid:17) natural image
sequence, but likely also adapted to a (cid:16)the(cid:17) present
visual environment, as observed at the LGN level (Truccolo, 2001).

A way to interpret this, is to generalize the contrast adaptation
mechanism proposed in, e.g. (Wohrer, 2008), to second-order local
statistics adaptation. This means to assume that the retinal processing
is able to tune not only the (cid:16)gain(cid:17) but also the local
spatio-temporal correlations to a given environment and to react (i.e.,
to detect) a speci(cid:28)c second-order spatio-temporal statistics in
the signal.

This is the (cid:28)rst main computational assumption of our work, with
two consequences:

1.  On one hand, as illustrated in Fig. 3, second-order statistics is in
    one to one correspon- dence with the magnitude of the (here: 2D+T)
    spectrum1. Detecting second-order spatio- temporal statistics means
    detecting a given spectrum magnitude signature. On the reverse, the
    spectrum phase is a function of the higher-order and second-order
    statistics, so that as- suming second-order processing means that
    the retinal adaptation and detection capability is only related to
    the spectrum magnitude signature. This is due to the
    Wiener-Khintchine theorem that relates the signal auto-correlation,
    thus the second-order moments, the power spectral density. It has
    been shown that, in fact, this is a relevant cue to characterize
    nat- ural image categories (Torralba & Oliva, 2003), e.g.,
    discriminate between human-made environment or not, categorize a
    given landscape, etc. We would like to hypothesize that what is true
    for (cid:16)large scale(cid:17) natural image categories is also
    true for (cid:16)small scale(cid:17) image categories, e.g., detect
    stone vs vegetation, etc. This is plausible since the natural image
    statistics power spectra is 1/f , meaning that the second order
    statistics is scale invariant, which suggests (but it is not
    established) that the same cue may be relevant at a local scale.
    This is going to be veri(cid:28)ed numerically in section 5. This is
    not obvious and this does not means that the whole statistics is
    scale invariant. It is true, in average, for natural images
    (Simoncelli & Olshausen, 2001). It is not the case for a given
    subset of images and there are evidence at least in V1 that even if
    the statistic is preserved our visual system treats images
    di(cid:27)erently (Simoncini, Perrinet, Montagnini, Mamassian, &
    Masson, 2012).

2.  On the other hand, tuning the second-order but not the higher-order
    statistics has a very precise meaning with respect to stimulus
    decomposition. It means that the retinal pro- cessing is related
    rather to a (cid:16)Principal Component Analysis(cid:17) (PCA) which
    decomposes

1 see the Wiener-Khintchine theorem for a formal equivalence

Inria

Modeling non-standard retinal in/out function using computer vision
variational methods

9

Figure 3: Top view : Relevant representation of natural image categories
from the spectrum magnitude signature (here the 60, 80 (in blue) and 90%
(in red) level curves), from (Torralba & Oliva, 2003): Each environment
class has a relatively speci(cid:28)c signature. In a bio-plausible
framework such signature correlation can be computed by a
linear/non-linear network subset, since the distance to a given spectral
signature is equivalent to the energy response of a (cid:28)lter with
spectral property corresponds the given signature, as made explicit in
the sequel. Bottom view: The (cid:16)semantic(cid:17) of the spatial
spectrum magnitude versus the spectrum phase: When (on the left, from
(Hyv(cid:228)rinen, 2009)) corrupting the magnitude while preserving the
phase, the image (here of a bull and an insect) is still recognizable,
whereas (on the right, for the well-known (cid:16)Lena image(cid:17))
when canceling the phase and preserving the magnitude the image has
still (cid:16)natural image statistics(cid:17) but the shape has
vanished. Here, we propose as a minimal model, to consider that K-cells
processing is based on second-order information, thus on spectrum
amplitude, since in one-to-one correspondence1.

(cid:176) RR n

8217

10

E. Teftef & others

a signal with respect to its correlations, thus second-order statistics,
than an (cid:16)indepen- dent component analysis(cid:17) (ICA) which
decomposes the signal with respect to higher-order moments.

The fact that early vision optimized for either only a second-order
statistics or for higher- order statistical dependencies is an open
question and recent results tends to show that V1 RF function not only
make their outputs as independent as possible, but also facilitate the
processing of higher-order statistical regularities (Karklin & Lewicki,
2006). Similarly, it is assumed that high-order statistics are taken
into account in redundancy reduction (Barlow, 2001).

However, results suggest that adaptation in the retina system is not
sensitive to changes in commonly measured higher-order statistics,
retinal cells exhibit remarkably invariant behavior to changes in
higher-order statistics (Tka£ik, Ghosh, Schneidman, & Segev, 2012).

This invariance is coherent with what has been observed in V1 with
pink-noise, i.e., the fact it is su(cid:30)cient to
(cid:16)imitate(cid:17) second-order statistics of natural images to
obtain responses similar to natural image statistics (Kayser, Salazar, &
Konig, 2003). To this debate, we bring the following argument: If
natural images categories are essentially characterized by their
spectrum magnitude (Torralba & Oliva, 2003), thus second-order momenta,
it is su(cid:30)cient to detect visual events related to such
second-order cues.

No mistake, this statement only concerns the K-cell processing
considered here, whereas analyzing natural images using ICA at the
retina level is another important issue considered elsewhere (Keskes,
2011). And we are going to numerically verify that it is su(cid:30)cient
to use such cues to perform the complex early-vision processing that is
attributed to K-cells. We also wonder, if, since the eye is expected to
produce visual input from natural images anyway, it is relevant not to
transmit the obvious information that the image is natural, but the
information remainder. How could it be, in that case, that though
invariant with respect to higher-order momenta (such as kurtosis) the
retina still (cid:16)computes(cid:17) higher-order momenta? In our
framework, this is due to another processing step : Non-local
(cid:28)ltering, now described and which is a non-linear transformation
of the image, so that second-order and higher-order momenta are mixed,
thus higher-order momenta indirectly taken into account, even if the
basic detection mechanism is only due to second-order cues.

-B- non-local noise reduction

Since the main biological constraint of the retina in terms of
information transmission is the 102 compression factor for P-cells up to
103 for other Gc cells in the optical nerve, reducing the noise with
respect to the signal is a major issue (Simoncelli & Olshausen, 2001).
The noise added by the photo-transduction mechanism is obviously to be
(cid:28)ltered (Wohrer, 2008). However, what is to be considered as
pertinent signal vs distracting information or noise in the incoming
visual (cid:29)ow is task dependent. For instance, the background motion
induced by ego-motion is a (cid:16)noise(cid:17) with respect to object
motion recognition but a relevant signal with respect to gaze
stabilization (the opto-kinetic re(cid:29)ex for instance has the
background motion as main input cue).

Furthermore, there is a (cid:16)local(cid:17) notion of noise (i.e., a
random spurious additive signal, locally correlated in space and time,
or not), but regarding the visual perception, there are other notions: A
notion of (cid:16)outliers(cid:17) (i.e., spurious piece of signal not
to be taken into account to avoid bias, e.g., a spurious light
re(cid:29)ection) and a notion of (cid:16)inliers(cid:17) (i.e., piece
of signal coherent with the ground base data but inducing a
mis-perception, e.g., a shadow.

The concept of noise reduction is no more related to a local
(cid:28)lter, but to non-local operators, since the context matters. In
other words, (cid:28)ltering means estimating a given zone in the image,

Inria

Modeling non-standard retinal in/out function using computer vision
variational methods

11

thus to perform image segmentation. This non-local idea of
(cid:28)ltering corresponds to the grouping of homogeneous information,
reducing small or spurious non-signi(cid:28)cant variations, and then
pro- duce a reduced representation in which outliers are eliminated
because they’re not homogeneous with respect to the information
neighborhood, while inliers are grouped in another region to be further
treated as signal or noise depending on the perceptual task. Such
mechanism of synchro- nization is well-known in the retina (Gollisch &
Meister, 2008; Shlens, Rieke, & Chichilnisky, 2008) where the shared
noise from photoreceptors is a major cause of correlated (cid:28)ring
(Greschner et al., n.d.), so that synchronized Gc outputs correspond to
activity with the same stochastic signal characteristics.

Furthermore, it is important to point out that we do not group regions
of homogeneous (cid:16)intensity(cid:17) but regions of homogeneous
response to the 2D+T (cid:28)ltering discussed above, e.g., of the
intensity, intensity variation, contrast, local edge or motion pattern,
etc. It is important to remark that time, here, is considered only as a
local feature. As a consequence, such mechanism should be able to
segment on complex local spatio-temporal patterns. In particular, as
explained in (Gollisch & Meister, 2010) after (Hochstein & Shapley,
1976), texture motion, even if the average local intensity remains
constant, is locally detected: During texture motion, di(cid:27)erent
intensity- variation cells respond at di(cid:27)erent time to
di(cid:27)erent spatial patterns at their RF locations, showing the same
activity pro(cid:28)le, inducing a cumulative e(cid:27)ect related to
strong recti(cid:28)cation (summing only positive responses in the
neighborhood with both excitatory and inhibitory responses). It is a
perspective of this work to numerically verify that texture motion is
also compatible with such variational approach (Olveczky et al., 2003)
(Aubert & Kornprobst, 2009).

To further understand this aspect of retinal processing, we are going to
formalize in details to which extents the retinal architecture is able
to not only smooth but also segment the visual signal in order to
provide a multi-scale representation of the input in terms of regions of
homogeneous signal values (upper-scale), with a coding at
(cid:28)ner-scale of the region indexing for a given unit. In this
framework we thus only consider the spiking rate and phase, and are
going to code them by two analog signals, the former being a positive
value, the latter being a relative (i.e., only de(cid:28)ned by the
di(cid:27)erence with another value). Since phases synchronize, we
obtain only a discrete set of distinguishable values and this is
equivalent to an indexing.

-C- visual event detection

The retina is able to detect sophisticated visual events such as:

(i) Fine spatial information, as observed qualitatively with natural
    image sequences, a Gc being often either silent or sparsely by
    deterministic (cid:28)ring for a given image category (Soo,
    Schwartz, Sadeghi, & Berry, 2011);

(ii) local approaching motion, which is known as being computable by a
     local divergence (cid:28)lter

(Subbarao, 1990), i.e., the weighted sum of dedicated local masks.

Such functionality includes anticipation, either motion extrapolation or
omitted stimulus response (Schwartz & Michael, 2008), these complex
computations coming about through the interplay of rather generic
features of retinal circuitry (Gollisch & Meister, 2010). In both cases,
as expected, spatio-temporal pattern yields adaptation (delay reduction
in the former case, response habituation in the later) and an unexpected
event induces a strong reaction. The time window order of magnitude is
the second. This is thus not directly derived from a 2D+T
(cid:28)ltering mechanism (its temporal window being too short) but by a
local fading memory of previous input, thus using regressive feed-backs,
and the simpler model we propose here is a simple auto-regressive
mechanism. The key point is that this induces a switching mechanism, the
detection of a visual event modifying the local parameters on the
retina. With (Gollisch

(cid:176) RR n

8217

12

E. Teftef & others

& Meister, 2010) we assume that the switching (cid:16)may be initiated
by much more subtle image features(cid:17), precisely by the detection
of a given visual event.

Regarding the detection of such fast visual event, it has already been
investigated in detail how Gc and subsequent layers can produce early
responses to a visual event (Rullen & Thorpe, 2001; Thorpe &
Fabre-Thorpe, 2001). We assume here, that if such a mechanism is able to
produce a detection at early stages in the visual system, it is likely
produced by a large con- tribution of the retinal processing. This is
plausible because the corresponding bio-plausible most e(cid:30)cient
computational method is a one layer method implementable a simple
non-linear (cid:28)lter with threshold e(cid:27)ect (ViØville & Crahay,
2004). This is related to the so-called Support Vector Machine (SVM)
algorithm, and the bio-plausible implementation is a simple competition
between units coding similarities with respect to prototypes. This may
be implemented as a two steps process: correlation with prototyping
responses and competition between the outputs, as implemented in a
standard one-layer architecture with lateral inhibitory connections,
which is the case of the OPL.

The statistical learning theory and the related SVM algorithm (ViØville
& Crahay, 2004) allows us to assume that only a little set of prototypes
(the support vectors) has to be recruited for the detection of an event.
Moreover, (cid:16)approximate(cid:17) prototypes are su(cid:30)cient,
since the prototype of a category can be wrong as far as it is less
wrong than a prototype of another category. It is thus reasonable to
assume that this is a biologically plausible functional model of the
retina, since it is able to detect rather complex spatio-temporal visual
events. As already pointed-out, the major argument is that it is a
pertinent to use the full retinal resolution to perform it before the
optical nerve spatial compression.

This view is also coherent with the observation that in the presence of
natural stimulus Gc have a sparse and deterministic behavior. Sparse
because they react in terms of detection of not a given visual event.
Deterministic in the sense that they (cid:28)re a spike response at
reproducible times. This is also coherent with observations already
reviewed here, that the response is not limited to a (cid:16)local
visual (cid:28)eld(cid:17), since there is no signi(cid:28)cant visual
events at such small case, but at higher sizes of the visual
(cid:28)eld. When considering the objects size in a standard natural
scene (?, ?), the fact that the K-cells response corresponds to events
in a 10deg of the visual (cid:28)eld seems properly tuned to natural
visual events (Hendry & Reid, 2000).

4 Variational speci(cid:28)cation of the visual front-end

Let us now (cid:16)translate into equations(cid:17) the previous
elements, as developed elsewhere (ViØville & Crahay, 2004; ViØville,
Chemla, & Kornprobst, 2007) and adapted to the retinal processing.

4.1 Non-local IPL (cid:28)ltering

The main mechanism is illustrated in Fig. 4, where non-local
(cid:28)ltering is precisely de(cid:28)ned from the well-known work of
(Mumford & Shah, 1985), and following here the presentation of (Aubert &
Kornprobst, 2009). A step further, following (GØrard, Kornprobst, &
ViØville, 2007), we consider the well-de(cid:28)ned discrete
approximation of the Mumford-Shah criterion proposed by (Chambolle,
1995; Chambolle & Dal Maso, 1999). This allows us to implement this
mechanism, taking the retinal IPL architecture into account, as follows.
Over a 2D array of (cid:16)pixels(cid:17), at a resolution h,

Inria

Modeling non-standard retinal in/out function using computer vision
variational methods

13

it writes:

minO

¯W ∗ I(ωij) − O(ωij)|2

-   

Xij

Input (cid:28)ltering {z

}

,

Xij,dω∈{(0,1),(1,0)}

min

α |O(ωij) − O(ωij + dω)|2, β h (cid:1)

(cid:0)

Region & border optimization {z

R

ω∈P ixelij

with I(ωij) = I(ω)/h2 being the integrated value of a pixel. It has been
shown by (Chambolle, 1995) that this discrete criterion is a
well-de(cid:28)ned discretization of such a function. Contrary to other
numerical schemes (Aubert & Kornprobst, 2009), its distributed implemen-
tation corresponds to a simple-layer network computation with
feed-backs. Another technical aspect is the fact that here we consider
not a scalar but a vectorial image, and in, e.g., (ViØville et al.,
2007), it has been derived how such mechanisms trivially generalize to
the multi-channel case. More precisely, the minimization is implemented
by the following non-linear iterative (cid:28)lter:

}

O(ωij)t+1 ← O(ωij)t + δ ∇O(ωij)

with:

∇O(ωij) ≡ ¯W ∗ I(ωij) − O(ωij) 0 α (O(ω + dω) − O(ω))

dω∈{(0,1),(1,0)} (cid:26)

-   

P

if |O(ω) − O(ω + dω)|2 > β h α otherwise

.

Making explicit this recurrent equations allows us to relate it to the
IPL retinal architecture discussed previously. It is thus an iterative
(cid:28)lter, implemented as a local feed-back with recurrent
connections and is based on local di(cid:27)usion, as made explicit in
Fig. 2 and discussed in section ??, regarding recurrent connections. The
input gain is positive ((cid:16)excitatory connections(cid:17)) and the
local di(cid:27)usion (in(cid:29)uence of the neighborhood activity) is
positive too. On the reverse, the local feedback is negative, again as
predicted by our knowledge of the IPL architecture. The proposed
iterative (cid:28)lter is based on a piece-wise linear feedback, with a
very precise static non-linearity: if the local contrast magnitude
|∇O(ω)|2 is higher than a threshold, di(cid:27)usion is canceled. This
is easily implemented by local inhibition, triggered by a contrast
threshold, again compatible with elements of Fig. 2. This is the reason
why we propose that the IPL (cid:28)ltering stage may be considered as
implementing such non-local (cid:28)ltering.

4.2 Visual event detection in the OPL

As far as the choice of the non separable 2D+T convolution kernels are
concerned, beyond usual contrast and image intensity variation kernels,
we thus assume in this modeling that natural image local categories can
be related to a spectral magnitude signature, i.e., normalized spectral
magnitude pro(cid:28)le. We thus hypothesize that retinal computational
units are tuned to a given spatio-temporal spectral response ¯Wn(f ).
This means that a given input I corresponds to the pattern ¯Wn, if its
spectrum I(f ) is closed to ¯Wn(f ), up to a scale factor. Let us write
|I|2 = ω |In(ω)|2 and assume without loss of generality that the
spatio-temporal spectral response is | ¯W| = 1. Let us also consider the
(cid:16)orthogonal(cid:17) pattern, i.e. the normalized normalized, i.e.
R pro(cid:28)le ¯W⊥ n (f ) ¯Wn(f ) = 0, this pro(cid:28)le being
well-de(cid:28)ned up to

n , with | ¯W⊥

n | = 1 and

¯W⊥

f

(cid:176) RR n

8217

R

14

E. Teftef & others

min O,K Zω∈Ω−K

¯W ∗ I(ω) − O(ω)|2

-   α

|∇O(ω)|2

-   β

Zω∈Ω−K

1

Zω∈K

Input (cid:28)ltering {z

Region homogeneity } {z |

}

Border parsimony | {z }

Figure 4: The computational principle of the Mumford-Shah image
segmentation variational approach for a multi-channel image, after
(Aubert & Kornprobst, 2009). Given an area of pixels Ω and an input
image I : Ω → R3 which associate to each pixel its color (here a
red-green-blue (RGB) value), the goal is to compute an output image O :
Ω → RC, segmented in regions, writing K the border between regions. The
speci(cid:28)cation is three-fold. (i) Input (cid:28)ltering. The output
image is closed to the local (cid:28)ltering of the incoming image by
2D+T convolution kernels parameterized by the weights ¯W and computing C
channels such as contrast, intensity variation, or local spectral
property. (ii) Region homogeneity. Inside a region we want the output
value variations to be minimal (here ∇ stand for the gradient operator,
thus the value variation), yielding homogeneous regions. (iii) Border
parsimony. Between regions, we want the border length to be as small as
possible to draw smooth and minimal edges between regions. Minimizing
the weighted sum of these three criterion allows us to specify an image
segmentation, tuning the (cid:28)ne/coarse grained segmentation with β
and tuning the region scale with α. The success of the method comes from
the fact that, under realistic conditions, the optimization converges
towards a piece-wise a constant intensity pro(cid:28)le, i.e., perfect
homogeneous regions. Implementing this minimization, from the derivation
of the criterion gradient using the related Euler-Lagrange equation,
leads to a distributed algorithm with precise local weights adaptation
rules (ViØville et al., 2007). Region indexing (pixels of the same
region have similar output values) and edge detection (edge pixels have
non negligible local contrast) is also obviously provided by such
process.

Inria

Modeling non-standard retinal in/out function using computer vision
variational methods

15

a negligible measure for the given dot-product. Applying usual
equalities we can relate this mechanism to a simple convolution with
normalization and static non-linearity as follows:

¯Wn(f ) ≃ λ I(f ) ⇔ ǫ ≃

⇔  

I(f ) |¯I| |2 = ≃

f

¯Wn(f ) | ¯W| −

f | ¯Wn(ω)∗I(ω)|ω=0 R |¯I| n (ω)∗I(ω)|ω=0 |¯I|

¯W⊥

ω |

¯Wn(ω))

I(ω) |¯I| |2 | ¯W| − R ¯Wn(f ) ¯Wn(f ) = 1 n (f ) ¯W(f ) = 0 ¯W⊥

R

=

f

R



This obvious textbook derivations make explicit two facts: if spectral
magnitude signatures are similar, this simply means that the two
normalized signals are similar, while using the reference signal as a
normalized convolution (convolution after normalization of the input
signal) yields a unitary response.

Local spectral signature detectors are thus easily implementable in the
biological substrate as a convolution with a normalized input signal, as
it is the case for a simple neural cell with gain control, a static
non-linearity providing the thresholding mechanism after the
convolution, to cancel negative or negligible parts of the signal. A
step further, if two coupled convolution kernels are coupled with their
(cid:16)negation(cid:17), i.e. with kernel representing the orthogonal
response, the visual event detection can be based on more robust
mechanisms of (cid:16)margin(cid:17) comparison, detecting the event if
the (cid:16)positive(cid:17) channel response is signi(cid:28)cantly
higher than the (cid:16)negative(cid:17) one.

5 An e(cid:27)ective implementation of visual events detection

In order to address the question (cid:16)How is it possible for the
retina ‘alone’ to e(cid:30)ciently compute, on natural image sequences,
such sophisticated visual responses(cid:17), we have developed a
software (Teftef, 2012; Teftef & ViØville, 2012) that implements the
previous described functionalities. This piece of code is based on the
CImg2 image processing open-source library, and is itself a piece of
open-source code available under the K-mrs3 nick-name. For the generic
segmentation routine, we reuse the LØonard GØrard implementation (GØrard
et al., 2007) of the related Chambolle algorithm (Chambolle & Dal Maso,
1999), and have contributed to CImg on this aspect. The event detection
SVM mechanism has been implemented using the open-source libsvm4 of
Chih- Chung Chang and Chih-Jen Lin.

As far as software engineering is concerned, the key point is that we
work on vectorial data volumes, i.e. an (cid:16)image(cid:17) is a data
structure with pixels indexed by their 2D location (x, y) and temporal
depth t, each pixel being a vector c of channels, starting with the red,
green, blue channels, as input, extended with computed channels (e.g.,
spectrum signature). As a consequence, all functions developed here are
usable for both static and dynamic event detection, and all related
processes.

While the numerical veri(cid:28)cations proposed here only consider
static images, spatio-temporal convolutions and other operators are
available for the software to process 2D+T images sequence slices.

The SVM learning of the spatial event detection prototype was a complete
standard process: We have selected images of variable sizes of each
category, and run the calculation of the intensity channels and spectral
channel, as shown and explained in Fig. 7. Given the red (R), green (G)
and blue (B), original channels we have chosen the redundant coding :
G-R, G-B, G in addition to the intensity R+G+B. The only reason was to
obtain numbers rather stable, given the data

2http://cimg.sourceforge.net 3M-mrs, for KEOpS mesoscopic retina
simulator http://project.inria.fr/keops/K-mr
4http://www.csie.ntu.edu.tw/∼cjlin/libsvm

(cid:176) RR n

8217

16

E. Teftef & others

Figure 5: Schematic representation of middle-scale visual events as a
support-vector-machine (SVM) implemented in terms of a competitive
winner-takes-all connectivity. Here, areas of 3 to 10 deg of the visual
(cid:28)eld are considered with, as examples,
(cid:16)(cid:29)owers(cid:17) (upper-left),
(cid:16)gravel-(cid:29)oor(cid:17) (middle) and
(cid:16)vegetation(cid:17) (upper-right). The discrimination between
such regions is based on the trivial competitive response of the
di(cid:27)erent detectors. Such winner-takes-all mechanism is obviously
implemented with spike-coding (Rullen & Thorpe, 2001) since the higher
the response, the sooner the spike generation, which can inhibit other
responses and thus (cid:16)win(cid:17) the competition. The key point,
for the present process, is the choice of the
(cid:16)prototypes(cid:17). As pointed out in (ViØville & Crahay, 2004),
the very powerful statistical learning theory, leading to the SVM
algorithm, can be revisited as a competitive comparison between
prototypes. These prototypes, are the support vectors, close to the
hyper-surface that separates two categories. The key parameter is the
(cid:16)margin(cid:17) between these prototypes and the frontier between
two categories: The higher the margin, the more robust the detection on
the subsequent data set (generalization property). In the present
numerical experimentation, a standard SVM supervised mechanism have been
used.

Inria

Modeling non-standard retinal in/out function using computer vision
variational methods

17

set intensity distribution, with for instance, a predominance of green,
while red or blue coloration of the image is often relative to green
zones. We recall that the (cid:28)ltering is not linear, so that even if
the SVM algorithm is invariant by an a(cid:30)ne transformation of the
features space, the segmentation step depends on such coding choice.

Obviously, the representation is easily adaptable, for instance to
dichromate visual systems, like in rodents, using B+G or UV+G, so
somehow di(cid:27)erent from trichromats vision (Peichl et al., 2005).
As soon as these two colors allow to discriminate the natural scene
objects, the previous framework applies. This is in coherence withj the
fact that the retinal visual system is adapted to the natural
environment of the animal (Sterling, 2004).

This event detection is performed on the non-local (cid:28)ltered images
(in fact it has been quali-

tatively experimented that event detection does not work on the raw
images in this context).

The choice of considering the sum of the spectrum amplitude responses at
50% of the max- imal spectrum response is a pure experimental choice, as
detailed in Fig. 7, but guided by two considerations. On one hand, this
can be implemented by a simple linear / non-linear (cid:28)lter, as
follows: each point of the spatial spectrum corresponds to the
correlation of the signal by the corresponding trigonometric functions.
The maximal spectrum response always corresponds to the continuous (or
DC) component of the spectrum, i.e., the average intensity value.
Tuning, in a given 2D direction, the spatial frequency in order the
response to correspond to 50% of the DC component, is a simple gain
control feedback. Finally, computing the signature reduces to a simple
summation. By no means we assume here that this is what happens in the
retina, nor that this is the only solution. In fact, as developed in the
previous section, the biological sub- strate o(cid:27)ers a much more
generic mechanism, computing the correlation between the observed and
expected spectrum amplitude.

Though, as discussed previously, all functions can be implemented as
distributed compu- tations on a biologically plausible neural network,
for obvious computation time performances issues, we have used optimized
code in this numerical implementation. Previous studies on these aspects
(ViØville & Crahay, 2004; ViØville et al., 2007) have extensively
addressed the issue of both the segmentation and detection
implementation in a biological network.

The originality of the numerical experimentation is the fact that we
have considered a rather speci(cid:28)c set of visual stimuli, as made
explicit in Fig. 6, and involving studying a speci(cid:28)c animal model
(see (Delgado, Vielma, K(cid:228)hne, Palacios, & Schmachtenberg, 2009;
Ardiles et al., 2012) for more details on these aspects) 5. Restraining
the issue to computer vision process only, it means that we have
considered (cid:16)degraded visual conditions(cid:17) (with respect to
state of the art image sequence data base), the issue being to check
whether and to which extents such processes (cid:16)still work(cid:17)
in such restrained conditions.

In order to experiment in a rather tricky context, we have applied the
proposed framework to the ability to recognize shapes in the image
(Masland & Martin, 2007), i.e. restraining to 2D+T volumes with a
thickness of one. We thus have implemented the fact that we consider
that the retina is able to compute sophisticated second-order visual
cues, including spectrum amplitude signature, since this is
implementable as a linear/non-linear (cid:28)lter, see Fig. 7. We have
implemented the non-local (cid:28)ltering of the di(cid:27)erent visual
streams as a mechanism of image segmentation, see Fig. 8 for results.
Finally, considering that the retina is able to detect static or
time-varying visual events, we propose after (ViØville & Crahay, 2004) a
suitable mechanism for such biological computation, evaluated on a
realistic data set, see Fig 9. More technical details are available in
(Teftef, 2012). In particuler, this report includes comparisons with
di(cid:27)erent types of (cid:28)ltering mechanisms in order to
illustrate the bene(cid:28)ts of the non-local (cid:28)ltering proposed
in

5As an example, an interesting issue regarding the will to work with
such (cid:16)rodent speci(cid:28)c visual data(cid:17), is to wonder
whether the rodent visual system is (cid:16)optimized(cid:17) for such
visual environment, or if on the contrary such rodent visual system is
phylogenetically conserve with respect to such ecological variation.

(cid:176) RR n

8217

18

E. Teftef & others

RGB histogram

Spectrum pro(cid:28)le

Spectrum magnitude

Figure 6: The (cid:16)La Campana database: a natural habitat of Octodon
degus rodent(cid:17) (40 sequences of 102 images of about 800 × 800
pixels). In order to be able to perform both biological and numerical
experiments on degus visual system, image sequences of about 102 images
each have been taken, in the natural environment of the animal, at the
height, lighting conditions, image resolution and with displacements
roughly corresponding to the rodent usual displacements. It is important
to note that this species use to live in a speci(cid:28)c visual
environment: In the bottom- left view, the red-green-glue (RGB)
intensity histogram is not Gaussian as it is usually the case
(Simoncelli & Olshausen, 2001), but biased, especially in the green
channel (oscillation in the distribution), due to the statistics of the
vegetation colors. In the bottom-central view, two spectrum magnitude
pro(cid:28)les in log coordinates, taken over hundred of frames, show
that the 1/f d, d ≃ 1 expected pro(cid:28)le (thus a line with a
negative slope in the (cid:28)gure) does not occur here, whereas the
spectrum is a function of such visual context.

Inria

Modeling non-standard retinal in/out function using computer vision
variational methods

19

Figure 7: Considering a multi-stream computational framework, including
spectrum amplitude signature. For (cid:28)ve di(cid:27)erent zones of
natural images labeled on the left picture, the spectrum amplitude and
the 50% level curves are drawn, from the non-local (cid:28)ltered
images. From left to right : 1. a (cid:29)ower, 2. a piece of sky with
an artifact, 3. a tree zone, 4. a dark zone, and 5. a third tree zone
perturbed by a piece of sky. Interesting enough is the fact that zones
3. and 5., despite their very di(cid:27)erent visual aspect have a
rather similar spectrum signature, di(cid:27)erent from 1. Though zones
2. and 4. have spurious spectral responses (for 2. this is the artifact
in the sky that yields the spectrum and for 4. the spectrum is not
relevant in such a dark zone), since the system is also using the local
color as a cue, this yields no mistake. We numerically observed that not
only the whole image second-order statistics (Torralba & Oliva, 2003),
but also very local second-order statistics seem to be relevant for
natural image categorization. More precisely, in the present numerical
implementation limited to static images, the color and the sum of the
spectrum amplitude responses at 50% of the maximal amplitude are taken
as cues to characterize the local texture, in order to perform region
detection. The fact that such very simple scalar parameter calculated on
the spectrum magnitude leads to relevant results (see Fig. 9) is a good
argument in favor of the proposed choice. The generalization to
spatio-temporal volumes, thus 2D+T spectra, is straightforward and is a
direct perspective of this work.

(cid:176) RR n

8217

20

E. Teftef & others

Figure 8: Qualitative examples of non-local (cid:28)ltering using
di(cid:27)usion mechanisms as discussed in (ViØville et al., 2007)
regarding their biological implementation. Lower images are the
non-local (cid:28)ltering output of one channel (here intensity)
computed on the corresponding upper image. Interesting enough, several
key points can be observed here : The output is morally an
(cid:16)arti(cid:28)cial image(cid:17) corresponding to the
(cid:16)natural(cid:17) input, where the forms in the image have been
preserved. More precisely, the edges (e.g., the (cid:29)owers
boundaries) are preserved even when the image is
(cid:16)smoothed(cid:17) : The fact the mechanism (cid:28)lters the
noise and not the edges, is simply due to the non-linearity of the
di(cid:27)usion operator, since small variations di(cid:27)use and are
thus (cid:28)ltered, whereas higher intensity variations related to
edges do not. Furthermore, di(cid:27)usion is anisotropic, more
precisely performed along the edge, but not across it (in a more
mathematical language : Tangential to the local edge orientation, but
not orthogonal to it), thus preserving it. In the present computer
implementation, region synchronization is implemented by the propagation
of a (cid:16)phase index(cid:17) as expected in a biological neural
network. In the sky, the artifact (likely a tree limb) has disappeared,
because one non-local e(cid:27)ect of this process is small enough so
such regions are absorbed though the non-linear di(cid:27)usion. In a
nutshell, we have here a (cid:16)full resolution(cid:17), but
simpli(cid:28)ed image.

Inria

Modeling non-standard retinal in/out function using computer vision
variational methods

21

Figure 9: Two examples of detection of visual events (here, spatial
events only). Top views correspond to the input image, bottom views to
the detection output. The most salience regions are shown in both cases,
i.e. those with maximal size and/or channel average values (here, for
the present (cid:28)gures, size only is considered). Left view A
(cid:16)sky(cid:17) zone and four dark/light (cid:16)tree(cid:17) zone
have been detected. Right view The main (cid:16)tree(cid:17) zone have
been detected, while the ground is less salient since not structured in
terms of (cid:16)regions(cid:17). Clearly this kind of information is
relevant to directly detect zones with potential pray/predators
(cid:16)hidden in the green(cid:17). The categorization algorithm has
been trained with a very small learning set (a few dozen of samples) and
the recognition test is no more than a comparison of the region
synchronized parameters (color, spectral signature) with respect to
prototypes in competition. Such functionality is easy to generalize to
another visual events (e.g. snake crawling, predator approaching motion,
etc..) and thus provides an e(cid:27)ective early-vision generation of
a-priory information. We have numerically veri(cid:28)ed that such
detection is robust along the image sequence. However, we also
experimented that the non-linear (cid:28)ltering (i.e., segmentation)
step is mandatory: Without this sophisticated early-vision step, the
present categorization has very poor performances. This output
represents sparse responses of the retina in the presence of
speci(cid:28)c visual events.

(cid:176) RR n

8217

22

this article.

E. Teftef & others

6 Discussion: What is predicted by such a modeling ?

With respect to usual models regarding the retina processing, the
present work simply proposes to instantiate usual ideas about the
so-called non-standard Gc behaviors, but with a compu- tational
framework that make them compatible with realistic image processing.
Furthermore, this framework raises some new predictions about retinal
processing that are not yet tested, but could be worth tested to better
understand the biological behavior of the retina.

Here are experimental some facts that will falsify the present
framework, regarding the K-cells

behavior considered here.

About adaptation

We consider K-cells stream and speculate that the related processing
mainly involve second-order statistics, because this is su(cid:30)cient
to characterize (cid:16)natural image categories(cid:17). It may thus be
a second-order issue (Simoncelli & Olshausen, 2001) (Torralba & Oliva,
2003). A simple way to falsify the present statement would be to study
to which kind of stimulus statistics a K-cell in the LGN is sensitive
to. We expect such cell to be invariant to global pink noise whitening
(e.g., to response to an arti(cid:28)cial image with the same features a
natural one except its spatial spectra magnitude).

About segmentation

We claim that the IPL (cid:28)ltering not only (cid:16)reduces local
noise(cid:17) but performs an implicit clustering of visual zones,
likely based on non-linear di(cid:27)usion mechanisms yielding
synchronization between cell responses of the same class. As a
consequence, the compression process is not only based on very local
spectral or statistical properties, but tuned to non-local cues. This
means that the context must strongly in(cid:29)uence the local response.
More precisely, a Gc response must be averaged and synchronized with
respect to Gc with similar responses (i.e., cells of the same
(cid:16)region(cid:17)) but not with cells of another one. If we can
observe, for instance, un-synchronized cells corresponding clearly to
the same value of the corresponding visual cue in the same image area,
the present model is lapsed.

A key falsi(cid:28)able consequence of the present assumption is the
fact that the Gc channels output (cid:16)image(cid:17) (i.e., 2D map)
must not correspond anymore to the statistics of natural images with a
scale invariance of a spectrum in 1/f . This is simply incompatible with
the non-local region segmentation mechanism. If such statistics are
preserved, the proposal is defeated. In other words, the decoding of the
LGN transmitted image to the brain must have the look of an
(cid:16)arti(cid:28)cial image(cid:17) more than a natural one.

A less falsi(cid:28)able consequence on this topic is the fact that high
spatial frequencies are (cid:28)ltered, but not in a homogeneous way:
inside a region high-frequency are expected to be canceled, information
di(cid:27)usion leading to a uniform responses of cells averaging the
response value, whereas on the border between regions, no
(cid:28)ltering occur. This is a weaker argument because, anyway, as the
spatial frequencies are higher on edges than between edges. Here the
inhomogeneity in terms of spatial high-frequency (cid:28)ltering must
have been ampli(cid:28)ed by the IPL.

Inria

Modeling non-standard retinal in/out function using computer vision
variational methods

23

About detection

We (cid:28)nally have considered the visual event detection to be based
on a (cid:16)prototype competition(cid:17). This means that a given
visual event must be represented by a few spatio-temporal patterns and
if the input is close to one of these patterns, the Gc detection must
(cid:28)re. If, on the contrary, the representation of a given visual
event (e.g. a crawling motion) is fully distributed, as when repre-
sented by additive information or dynamic attraction, the proposal is to
be deprecated. Another key aspect is that such prototype must represent
event and no-event cases, since the underlying algorithm compares two
alternatives to trigger an event. In other words, the mechanism is a
comparison with respect to a ground state, not a threshold. Furthermore,
we expect border-line prototypes rather than (cid:16)typical(cid:17)
prototypes, to be coded for the detection. This means that we expect the
local spatio-temporal activity to be correlated with responses that, for
di(cid:27)erent categories, are close together. This is again due to the
fact that the system does not have to detect an event in absolute way
but relatively to an alternative. Therefore, it is more important to be
able to characterize the data with respect to prototypes close to the
border of such alterna- tives (notion of (cid:16)support
prototypes(cid:17)), than to con(cid:28)rm that the similarity with a
(cid:16)caricaturistic(cid:17) prototype. If such characteristic is
detected at the experimental level, the proposed framework becomes
plausible, otherwise it remains questionable.

At the mesoscopic level, i.e. considering the response of a given
retinal stream at the network level, it implies that a single cell type
may serve quite di(cid:27)erent roles (e.g., approaching motion and
structure motion), because it is recruited for a di(cid:27)erent event
detection mechanism, depending on the current state of the network. This
has already been partially observed, but if this observation is
marginal, whereas the majority of cells are dedicated to a unique
function, the model fails.

A less falsi(cid:28)able consequence is that we have to assume that the
observed switching between local scale functions must be initiated by
much more subtle image features, i.e., the visual event context. If such
switching is coherent with the related event detection (i.e., switch
does not occur when stimuli correspond to detecting similar events, but
does otherwise), the proposed modeling is not a fake.

Conclusion

We propose here the use a variational framework to model and simulate,
given natural image sequences, the mesoscopic collective non-standard
behavior of some retinal input/output func- tions that correspond to the
output of a subclass of the so-called K-cells. We hypothesize that from
sophisticated temporal pattern recognition, to image segmentation, or
speci(cid:28)c natural sta- tistical recognition, a unique generic
two-layers non-linear (cid:28)ltering mechanism with feedback is
implemented in the biological tissues, while not the individual but the
collective behavior of the retinal cells answer for such input/output
functions. Taking the retinal architecture and related biological
constraints into account and considering the wider class of early-vision
non-standard sensory-motor functionality known as non-standard
behaviors, we use computer vision methods to propose an e(cid:27)ective
link between the observed functions and their possible implementation in
the retinal network.

At the application level, we simply propose a generic visual front-end
to be used for either the simulation of the sensory input of a larger
simulator of the brain behavior (e.g., considering sensory-motor loops,
embedded vision, ..) or for industrial applications considering such
similar visual input, which concretely means degraded visual input.

Such framework raises falsi(cid:28)able predictions to be veri(cid:28)ed
at the biological level and points out how the retina can
computationally deliver visual event candidates driving subsequent vi-
sual processes. With such framework, it is not possible to assume that
the brain visual system stands on the reception of an homogeneous visual
pipe of (cid:28)ltered images coming from the retina,

(cid:176) RR n

8217

24

E. Teftef & others

whereas it is connected to several heterogeneous sources of information
at di(cid:27)erent spatial and visual scales, and di(cid:27)erent
integration levels, while tuned to the natural image statistics. At the
application level, on one hand, this completely changes the way
arti(cid:28)cial systems could be in- spired by the biological retina.
Roughly speaking, this encourages to compute in parallel several
information streams depending on the sensory-motor task, instead of
thinking of a large informa- tion pipe. On the other hand, this makes
very questionable the idea of designing relevant visual prostheses by
simply (cid:16)connecting(cid:17) a visual sensor array to the brain, as
it is. In a nutshell, visual prostheses are likely to be though as a
plural of sensors with a non-negligible data processing, before feeding
the nervous system.

Acknowledgment A big thank you to StØphane Deny for recent discussions
and Pierre Kornprobst for older discussions, both at the origin of some
important aspects of this work. We also acknowledge FONDECYT Nro.1120570
(Chile), CONICYT PIA Nro. 79100014 (Chile), ANR-47 CONICYT (Chile) and
DGIP USM 231117.

References

Ardiles, A. O., Tapia-Rojas, C. C., Mandal, M., Alexandre, F., Kirkwood,
A., Inestrosa, N. C., et al. (2012, August 06). Postsynaptic dysfunction
is associated with spatial and object recognition memory loss in a
natural model of Alzheimer’s disease. Proceedings of the National
Academy of Sciences.

Aubert, G., & Kornprobst, P. (2009, February). Can the nonlocal
characterization of sobolev spaces by bourgain etal. be useful to solve
variational problems? SIAM Journal on Nu- merical Analysis, 47 (2),
844(cid:21)860.

Barlow, H. (2001, August). Redundancy reduction revisited. Network , 12
(3), 241(cid:21)253. Barriga-Rivera, A., & Suaning, G. J. (2011).
Digital image processing for visual prosthesis: (cid:28)ltering
implications. Conference proceedings : … Annual International Conference
of the IEEE Engineering in Medicine and Biology Society. IEEE
Engineering in Medicine and Biology Society. Conference, 2011 ,
4860(cid:21)4863.

Callaway, E. M. (1998). Local circuits in primary visual cortex of the
macaque monkey. Annual

Review of Neuroscience, 21 , 47(cid:21)74.

Chambolle, A. (1995). Image segmentation by variational methods: Mumford
and Shah func- tional and the discrete approximation. SIAM Journal of
Applied Mathematics, 55 (3), 827(cid:21)863.

Chambolle, A., & Dal Maso, G. (1999). Discrete approximations of the
Mumford(cid:21)Shah functional ((also available as Technical report 9820
from

in dimension two. M2AN , 33 (4), 651(cid:21)672. UniversitØ Paris
Dauphine, Ceremade))

Ciocchi, S., Herry, C., Grenier, F., Wol(cid:27), S. B., Letzkus, J. J.,
Vlachos, I., et al. (2010, Novem- ber 11). Encoding of conditioned fear
in central amygdala inhibitory circuits. Nature, 468 (7321),
277(cid:21)282.

Cowey, A. (2010, September 14). Visual System: How Does Blindsight
Arise? Curr Biol , 20 (17),

R702(cid:21)R704.

Dan, Y., Atick, J. J., & Reid, R. C. (1996, May 15). E(cid:30)cient
coding of natural scenes in the lateral geniculate nucleus: experimental
test of a computational theory. The Journal of neuroscience : the
o(cid:30)cial journal of the Society for Neuroscience, 16 (10),
3351(cid:21)3362. Delgado, L. M., Vielma, A. H., K(cid:228)hne, T.,
Palacios, A. G., & Schmachtenberg, O. (2009, June 10). The GABAergic
system in the retina of neonate and adult Octodon degus, studied by
immunohistochemistry and electroretinography. The Journal of comparative
neurology, 514 (5), 459(cid:21)472.

Dong, D. W. (2001). Spatiotemporal Inseparability of Natural Images and
Visual Sensitivities

Inria

Modeling non-standard retinal in/out function using computer vision
variational methods

25

Motion Vision. In J. M. Zanker & J. Zeil (Eds.), Motion vision
(pp. 371(cid:21)380). Berlin, Heidelberg: Springer Berlin Heidelberg.

Field, G., Sher, A., Gauthier, J., Greschner, M., Shlens, J., Litke, A.,
et al. (2007, November).

The Journal of Neuroscience, 27 (48), 13261-13272.

Field, G. D., Sher, A., Gauthier, J. L., Greschner, M., Shlens, J.,
Litke, A. M., et al. (2007, November 28). Spatial properties and
functional organization of small bistrati(cid:28)ed ganglion cells in
primate retina. The Journal of neuroscience : the o(cid:30)cial journal
of the Society for Neuroscience, 27 (48), 13261(cid:21)13272.

Gauthier, J. L., Field, G. D., Sher, A., Greschner, M., Shlens, J.,
Litke, A. M., et al. (2009, April 7). Receptive (cid:28)elds in primate
retina are coordinated to sample visual space more uniformly. PLoS
biology, 7 (4), e63+.

GØrard, L., Kornprobst, P., & ViØville, T. (2007). From variational to
spiking network image-

segmentation techniques. In Perception 36 ecvp abstract supplement.

Gollisch, T., & Meister, M. (2008). Rapid neural coding in the retina
with relative spike latencies.

Science, 319 , 1108(cid:21)1111. (DOI: 10.1126/science.1149639)

Gollisch, T., & Meister, M. (2010, January 28). Eye Smarter than
Scientists Believed: Neural

Computations in Circuits of the Retina. Neuron, 65 (2), 150(cid:21)164.

Greschner, M., Shlens, J., Bakolitsa, C., Field, G. D., Gauthier, J. L.,
Jepson, L. H., et al. (n.d.).

Correlated (cid:28)ring among major ganglion cell types in primate
retina.

Hendry, S. H., & Reid, R. C. (2000). The Koniocellular Pathway in
Primate Vision. Annual

Review of Neuroscience, 23 (1), 127(cid:21)153.

Hochstein, S., & Shapley, R. M. (1976). Linear and nonlinear spatial
subunits in Y cat retinal

ganglion cells. J Physiol , 262 , 265(cid:21)284.

Hornik, K., Stinchcombe, M., & White, H. (1989). Multilayer feedforward
networks are universal

approximators. Neural Networks, 2 , 359(cid:21)366.

Hosoya, T., Baccus, S. A., & Meister, M. (2005, July 7). Dynamic
predictive coding by the

retina. Nature, 436 (7047), 71(cid:21)77.

Hyv(cid:228)rinen. (2009). Natural Image Statistics. Springer-Verlag.
Karklin, Y., & Lewicki, M. S. (2006). Is Early Vision Optimized for
Extracting Higher-order Dependencies? In Y. Weiss, B. Sch(cid:246)lkopf,
& J. Platt (Eds.), Advances in neural information processing systems 18.
Cambridge, MA: MIT Press.

Kayser, C., Salazar, R. F., & Konig, P. (2003, September). Responses to
natural scenes in cat

V1. Journal of neurophysiology, 90 (3), 1910(cid:21)1920.

Keskes, M. (2011). ModØlisation des premiŁres Øtapes de la vision avec
des rØseaux de neurones.

Unpublished master’s thesis.

Koivisto, M., Railo, H., Revonsuo, A., Vanni, S., & Salminen-Vaparanta,
N. (2011, February 16). Recurrent Processing in V1/V2 Contributes to
Categorization of Natural Scenes. The Journal of Neuroscience, 31 (7),
2488(cid:21)2492.

Lamme, V., & Roelfsema, P. R. (2000, November 1). The distinct modes of
vision o(cid:27)ered by

feedforward and recurrent processing. Trends in Neurosciences, 23 (11),
571(cid:21)579.

Lamme, V. A. (2001, April). Blindsight: the role of feedforward and
feedback corticocortical

connections. Acta psychologica, 107 (1-3), 209(cid:21)228.

Li, Z. (1992). Di(cid:27)erent retinal ganglion cells have
di(cid:27)erent functional goals. International Journal

of Neural Systems, 3 , 237(cid:21)248.

Litke, A. M., Bezayi(cid:27), N., Chichilnisky, E. J., Cunningham, W.,
Dabrowski, W., Grillo, A. A., et al. (2004, August). What Does the Eye
Tell the Brain?: Development of a System for the Large-Scale Recording
of Retinal Output Activity. Nuclear Science, IEEE Transactions on, 51 ,
1434(cid:21)1440.

(cid:176) RR n

8217

26

E. Teftef & others

Masland, R. H., & Martin, P. R. (2007, August 07). The unsolved mystery
of vision. Current

Biology, 17 (15), R577(cid:21)R582.

Mumford, D., & Shah, J.

In Proceedings of the international conference on computer vision and
pattern recognition (pp. 22(cid:21)26). San Francisco, CA: IEEE.

(1985, June). Boundary detection by minimizing functionals.

Nassi, J. J., & Callaway, E. M. (2009). Parallel processing strategies
of the primate visual system.

Nat. Rev. Neurosci., 10 (5), 360(cid:21)372. Olveczky, B. P., Baccus, S.
A., & Meister, M.

(2003, May 22). Segregation of object and

background motion in the retina. Nature, 423 (6938), 401(cid:21)408.

Peichl, L., Chavez, A. E., Ocampo, A., Mena, W., Bozinovic, F., &
Palacios, A. G. (2005, June 6). Eye and vision in the subterranean
rodent cururo (Spalacopus cyanus, Octodontidae). The Journal of
comparative neurology, 486 (3), 197(cid:21)208.

Pitkow, X., & Meister, M. (2012, April 11). Decorrelation and
e(cid:30)cient coding by retinal ganglion

cells. Nat Neurosci , 15 (4), 628(cid:21)635.

Rullen, R. V., & Thorpe, S. (2001). Rate coding versus temporal order
coding: What the retina

ganglion cells tell the visual cortex. Neural Computing, 13 (6),
1255-1283.

Schwartz, G., & Michael.

(2008, April 01). Sophisticated Temporal Pattern Recognition in

Retinal Ganglion Cells. Journal of Neurophysiology, 99 (4),
1787(cid:21)1798.

Shlens, J., Rieke, F., & Chichilnisky, E. (2008, October 27).
Synchronized (cid:28)ring in the retina.

Current Opinion in Neurobiology.

Simoncelli, E. P. (2003, April). Vision and the statistics of the visual
environment. Current

Opinion in Neurobiology, 13 (2), 144(cid:21)149.

Simoncelli, E. P., & Olshausen, B. A. (2001). Natural Image Statistics
and Neural Representation.

Annual Review of Neuroscience, 24 (1), 1193(cid:21)1216.

Simoncini, C., Perrinet, L., Montagnini, A., Mamassian, P., & Masson, G.
(2012).

Nature Neuroscience, Epub ahead of print.

Soo, F. S., Schwartz, G. W., Sadeghi, K., & Berry, M. J. (2011, February
9). Fine Spatial Information Represented in a Population of Retinal
Ganglion Cells. The Journal of Neu- roscience, 31 (6), 2145(cid:21)2155.

Sterling, P.

(2004). How retinal circuits optimize the transfer of visual
information.

In L. M. Chalupa & J. S. Werner (Eds.), The visual neurosciences
(pp. 234(cid:21)259). MIT Press, Cambridge MA.

Subbarao, M. (1990, June). Bounds on time-to-collision and rotational
component from (cid:28)rst- order derivatives of image (cid:29)ow.
Computer Vision, Graphics, And Image Processing, 52 (3), 329(cid:21)341.

Teftef, E. (2012). Formalisation de la transformation analogique /
ØvØnementielle des mØcan- ismes non-standards des cellules
ganglionnaires de la rØtine. Unpublished master’s thesis, UniversitØ de
Paris 6 et UniversitØ El Manar de Tunis.

Teftef, E., & ViØville, T.

(2012). Formalization of the input/output retinal transformation
regarding non-standard ganglion cells behavior. In The neuromp’12 keops
workshop. (sub- mitted)

Thorpe, S., & Fabre-Thorpe, M. (2001). Seeking categories in the brain.
Science, 291 , 260(cid:21)263. Thorpe, S., Fize, D., & Marlot, C. (1996,
June 06). Speed of processing in the human visual

system. Nature, 381 (6582), 520(cid:21)522.

Tka£ik, G., Ghosh, A., Schneidman, E., & Segev, R. (2012, January 17).
Retinal adaptation

and invariance to changes in higher-order stimulus statistics.

Torralba, A., & Oliva, A. (2003). Statistics of natural image
categories. In Network: Computation

in neural systems (Vol. 14, pp. 391(cid:21)412).

Truccolo, W.

(2001, June). Dynamic temporal decorrelation: An information-theoretic
and

Inria

Modeling non-standard retinal in/out function using computer vision
variational methods

27

biophysical model of the functional role of the lateral geniculate
nucleus. Neurocomputing, 38-40 (1-4), 993(cid:21)1001.

ViØville, T., Chemla, S., & Kornprobst, P. (2007). How do high-level
speci(cid:28)cations of the brain

relate to variational approaches? J. Physiol. Paris, 101 .

ViØville, T., & Crahay, S. (2004). Using an hebbian learning rule for
multi-class svm classi(cid:28)ers.

Journal of Computational Neuroscience, 17 (3), 271(cid:21)287.

Werblin, F. S. (2011, August 1). The retinal hypercircuit: a repeating
synaptic interactive motif

underlying visual function. The Journal of physiology, 589 (Pt 15),
3691(cid:21)3702.

Wohrer, A. (2008). Model and large-scale simulator of a biological
retina with contrast gain

control. Unpublished doctoral dissertation, University of Nice
Sophia-Antipolis.

Yoonessi, A., & Yoonessi, A. (2011, April). Functional assessment of
magno, parvo and konio- cellular pathways; current state and future
clinical applications. Journal of ophthalmic & vision research, 6 (2),
119(cid:21)126.

(cid:176) RR n

8217

RESEARCH CENTRE BORDEAUX – SUD-OUEST

351, Cours de la Libération Bâtiment A 29 33405 Talence Cedex

Publisher Inria Domaine de Voluceau - Rocquencourt BP 105 - 78153 Le
Chesnay Cedex inria.fr

ISSN 0249-6399


