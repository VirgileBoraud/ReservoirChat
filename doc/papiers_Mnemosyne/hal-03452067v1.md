Intelligence artificielle et singularité
Nicolas P. Rougier

To cite this version:

Nicolas P. Rougier. Intelligence artificielle et singularité. Hypermondes #01 Robots, , 2021, 978-2-
36183-749-5. ￿hal-03452067￿

HAL Id: hal-03452067

https://inria.hal.science/hal-03452067

Submitted on 26 Nov 2021

HAL is a multi-disciplinary open access
archive for the deposit and dissemination of sci-
entific research documents, whether they are pub-
lished or not. The documents may come from
teaching and research institutions in France or
abroad, or from public or private research centers.

L’archive ouverte pluridisciplinaire HAL, est
destinée au dépôt et à la diffusion de documents
scientifiques de niveau recherche, publiés ou non,
émanant des établissements d’enseignement et de
recherche français ou étrangers, des laboratoires
publics ou privés.

Intelligence ar,ﬁcielle et singularité 
Nicolas P. Rougier 
Cet ar2cle est une version étendue de textes ini2alement parus sur les sites Inters2ces et The Conversa2on. 

Les origines. L’intelligence ar2ﬁcielle, ou IA, est oﬃciellement née en 1956 lors d’une conférence à 
Dartmouth (USA). Même si les recherches ont de fait commencé dès l’après-guerre (par exemple le 
« Test de Turing » en 1950), ceUe conférence est historique en ce qu’elle a rassemblé en un même lieu 
presque toutes les ﬁgures embléma2ques de l’IA, notamment John McCarthy, mathéma2cien, 
Herbert Simon, théoricien des organisa2ons, Allen Newell, mathéma2cien, Claude Shannon, père de 
la théorie de l’informa2on et Marvin Minsky, mathéma2cien. Ces pionniers rêvaient alors de 
construire des machines pouvant égaler voire surpasser l’intelligence humaine, sur la base des 
nouveaux moyens de l’informa2que naissante. C’était un projet d’une ambi2on folle, puisque, à ceUe 
époque, tout restait à faire. Or, malgré les immenses diﬃcultés qui se trouvaient devant eux, ces 
chercheurs, aidés d’autres scien2ﬁques, vont rapidement obtenir des résultats qui ﬁrent date dans 
l’histoire de l’informa2que. 

Ainsi, dès 1955, Newell et Simon conçoivent un programme (Logic theorist ou logicien théoriste en 
français) qui permet de démontrer automa2quement 38 des 52 théorèmes du traité Principia 
Mathema2ca d’Alfred North Whitehead et Bertrand Russell (1913). C’est un résultat majeur et 
extrêmement impressionnant pour l’époque, puisque pour la première fois, une machine est capable 
de raisonnement. On considère légi2mement ce programme comme la toute première intelligence 
ar2ﬁcielle de l’histoire. Quelques années plus tard, Newell et Simon généralisent ceUe approche et 
concevoir le GPS — General Problem Solver (solveur universel) — qui permet de résoudre n’importe 
quel type de problème, pour peu que l’on puisse le spéciﬁer formellement à la machine. À ceUe 
même époque, d’autres chercheurs défrichent les domaines de la traduc2on automa2que, de la 
robo2que, de la théorie des jeux, de la vision, etc. Jusqu’au milieu des années 1970, l’intelligence 
ar2ﬁcielle est extrêmement proliﬁque et engendre un nombre considérable de résultats. Mais elle va 
bientôt être vic2me de ses folles promesses originelles. En eﬀet, si des avancées extraordinaires ont 

 
été réalisées, les chercheurs sont encore très loin d’avoir résolu le problème général de l’intelligence. 
Ils se rendent compte qu’ils ont été un peu trop op2mistes, à l’exemple de Marvin Minsky qui aﬃrmait 
en 1970 que « Dans trois à huit ans nous aurons une machine avec l’intelligence générale d’un être 
humain ordinaire » (cita2on rapportée par Brad Darrach dans le magazine Life en 1970,). On parle de 
ce coup d’arrêt comme du premier hiver de l’IA. Mais avec l’arrivée des systèmes experts et la 
résolu2on du problème de l’appren2ssage dans les réseaux de neurones ar2ﬁciels, l’IA connaît un 
second souﬄe jusqu’à la ﬁn des années 1990 où, de nouveau, tout s’arrête ou presque pour à peu 
près les mêmes raisons. Le lecteur intéressé pourra se référer au très joli texte de Dominique Cardon, 
Jean-Philippe Cointet et Antoine Mazières « La revanche des neurones » pour un historique un plus 
complet. 

Deep Blue vs. Kasparov. Il aura fallu aUendre 1997, pour enﬁn lire ces quelques lignes dans le journal 
« L’Humanité » du 13 mai 1997 : 

Kasparov mis en échec par Deep Blue. […] le super-ordinateur d’IBM a vaincu le champion du 
monde […] en gagnant dimanche soir la sixième et dernière par2e de leur choc. […] Le grand 
maître électronique s’impose 3-1/2 à 2-1/2 face au meilleur des humains et devient surtout le 
premier ordinateur à l’emporter sur un champion du monde dans une rencontre classique. 

Avec presque trente ans de retard, la prophé2e de Newell et Simon s’est réalisée (« d’ici dix ans un 
ordinateur sera le champion du monde des échecs »), l’automate joueur d’échec d’Ambrose Bierce (Le 
maître de Moxon, 1899) était devenu réel. Les objec2fs de l’intelligence ar2ﬁcielle auraient-ils été 
ﬁnalement aUeints ? Serions-nous capables de concevoir des machines 
intelligentes et 
omnipotentes ? 

La réponse est non. S’il est eﬀec2vement possible aujourd’hui de baUre n’importe quel humain aux 
échecs, au Go ou au Poker, il reste impossible, par exemple, de faire jouer un robot au football contre 
un quelconque adversaire humain, quand bien même les scien2ﬁques y travaillent en organisant des 
compé22ons des matches de football entre robots (la Robocup) dont le but à terme est de faire jouer 
les robots contre des humains. Le football ne peut pourtant prétendre rivaliser en ﬁnesse et en 
intelligence avec le jeu des échecs. Mais comment peut-on baUre le champion du monde des échecs 
et se trouver en même temps incapable de jouer au football ? CeUe situa2on paradoxale s’explique 
par la diversité d’interpréta2on de la no2on d’intelligence. En eﬀet, l’intelligence que l’on veut prêter à 
Deep Blue est ici fondée sur le calcul, l’analyse et le raisonnement (courant symbolique de l’IA). Depuis 
le Discours de la méthode de Descartes, le courant de pensée des ra2onalistes, mené par Descartes, 
Spinoza et Leibniz, a voulu croire à ceUe intelligence, une intelligence fondée sur l’esprit et la raison, 
équivalente à l’intelligence humaine. À l’opposé, le courant de pensée des empiristes (courant 
connexioniste de l’IA), parmi lesquels Bacon, Locke, Berkeley et Hume, prôna la prise en compte de 
l’expérience sensible du monde et rejeta l’idée de la connaissance réduite à l’esprit et à la raison. 

la naissance de 

Ainsi, dès 
l’IA, deux courants de pensée vont coexister plus ou moins 
paciﬁquement. Un premier courant, symbolique, considère la machine comme un système de 
manipula2on de symboles qui peut être u2lisé pour manipuler des représenta2ons formelles du 
monde. Il est fondé sur la logique, se faisant ainsi l’héri2er des ra2onalistes. Sa philosophie peut se 
résumer à la volonté de construire un esprit (« making a mind »). Mené par Allen Newell et Herbert 
Simon, ce courant symbolique s2pule que l’intelligence repose sur la no2on de symbole. Le deuxième 
courant, connexionniste, considère en revanche la machine comme un support de la modélisa2on du 
cerveau, oﬀrant les capacités nécessaires pour simuler les interac2ons entre les neurones. Il s’appuie 
sur le domaine des sta2s2ques et sa philosophie peut se résumer à la volonté de modéliser le cerveau 
(« modelling the brain »). Ce courant connexionniste, mené entre autres par Frank RosenblaU, 
propose une vision numérique du traitement de l’informa2on et s’oppose en cela à l’hypothèse 
symboliste. 

La victoire de Deep Blue sur Kasparov représente le paroxysme de l’approche symbolique. En eﬀet, le 
jeu d’échecs est un très beau problème de nature symbolique, où il faut en substance déplacer des 
pièces sur des cases pour aUeindre un but précis (échec et mat). La plus grande diﬃculté est 
l’explosion combinatoire, lorsque le programme souhaite prédire des séquences de coups. Cependant, 

grâce à des algorithmes très ingénieux, à la force brute, à la rapidité de calcul et une bibliothèque 
d’ouvertures bien fournie, Deep Blue a pu prédire plus de coups à l’avance que ce qu’il est 
humainement possible de faire. Deep Blue est-il intelligent au sens commun du terme ? A priori non, 
c’est simplement un logiciel qui joue aux échecs et ne fait que cela. 

Certains n’ont pas été réellement surpris par ce résultat. Ainsi Rodney Brooks écrivait dès 1990 un 
ar2cle au 2tre un peu curieux, « Les éléphants ne jouent pas aux échecs ». Ce qu’il voulait expliquer 
alors, c’était que les éléphants ont une certaine intelligence — ils doivent se nourrir, trouver des 
points d’eau, se reproduire, fuir les prédateurs, etc. — mais n’ont a priori pas besoin de manipuler des 
symboles abstraits pour le faire. C’est de fait une cri2que assez sévère du courant symbolique de l’IA, 
que l’on désigne aussi par le terme GOFAI (« Good Old Fashion Ar2ﬁcial Intelligence », la bonne vieille 
intelligence ar2ﬁcielle). Or, nous savons aujourd’hui que ce courant de l’IA ne pourra pas résoudre le 
problème de l’intelligence générale à cause du problème de l’ancrage du symbole notamment. En 
eﬀet, comment meUre en rela2on les symboles avec les objets qu’ils désignent ? Comment faire le 
lien entre un verre, le mot, et un verre, l’objet physique que je vois posé sur la table ? Autant cela est 
évident pour nous humains, autant cela reste un déﬁ pour une machine qui n’a jamais soif et qui n’a 
pas de corps pour manipuler l’objet. C’est pourquoi ceUe théorie de la cogni2on incarnée a émergé 
dès les années 1990, en meUant en avant le rôle du corps dans la cogni2on et son intelligence propre. 

Un cerveau + un corps. Si vous possédez un animal domes2que, par exemple un chien ou un chat, 
regardez-le aUen2vement et vous aurez alors un bon aperçu de tout ce qu’on ne sait pas faire en 
intelligence ar2ﬁcielle… « Mais mon chat ne fait rien de la journée à part dormir, manger et se laver », 
pourriez-vous me répondre. Et pourtant votre chat sait marcher, courir, sauter (et retomber sur ses 
paUes), entendre, voir, gueUer, apprendre, se cacher, être heureux, être triste, avoir peur, rêver, 
chasser, se nourrir, se baUre, s’enfuir, se reproduire, éduquer ses chatons, et la liste est encore très 
longue. Chacune de ces ac2ons met en œuvre des processus qui ne sont pas directement de 
l’intelligence au sens le plus commun mais relève de la cogni2on et de l’intelligence animale. Tous les 
animaux ont une cogni2on qui leur est propre, de l’araignée qui 2sse sa toile jusqu’aux chiens guides 
qui viennent en aide aux personnes. Pour certains, ils peuvent même communiquer avec nous. Pas 
par la parole, bien entendu, mais en u2lisant le langage du corps ainsi que la vocalisa2on (par exemple 
des miaulements ou des aboiements). En ce qui concerne votre chat, lorsqu’il vient négligemment se 
froUer contre vous ou bien qu’il reste assis devant sa gamelle ou devant une porte, le message est 
assez clair. Il ou elle veut une caresse, a faim ou veut sor2r, puis rentrer, puis sor2r, puis rentrer… Il a 
appris à interagir avec vous pour arriver à ses ﬁns. Parmi toutes ces ap2tudes cogni2ves, il n’y en a 
aujourd’hui qu’une toute pe2te poignée que 
l’on commence un peu à savoir reproduire 
ar2ﬁciellement. Par exemple la marche bipède. Ça n’a l’air rien de rien et c’est pourtant quelque chose 
d’extrêmement compliqué à réaliser pour la robo2que et il aura fallu de nombreuses décennies de 
recherche avant de savoir construire et programmer un robot qui marche convenablement sur deux 
jambes. C’est-à-dire sans tomber à cause d’un pe2t caillou sous son pied ou lorsqu’une personne l’a 
simplement eﬄeuré d’un peu trop près. Mais ceUe complexité existe aussi chez l’homme puisque si 
vous vous rappelez bien, il nous faut en moyenne une année pour apprendre à marcher. C’est dire la 
complexité du problème. 

 Qu’en est-il de la reconnaissance des objets ? S’il est vrai que l’on a vu apparaître ces dernières 
années des algorithmes capables de nommer le contenu de pra2quement n’importe quelle image, on 
ne parle pas pour autant d’intelligence ou de cogni2on. Pour le comprendre, il faut regarder comment 
ces algorithmes fonc2onnent. L’appren2ssage supervisé, qui reste aujourd’hui la méthode la plus 
populaire, consiste à présenter au programme des images ainsi qu’un mot décrivant le contenu de 
l’image. Le nombre total d’images est généralement bien supérieur au nombre de mots u2lisés car 
pour un même mot, on va associer un très grand nombre d’images représentant l’objet dans 
diﬀérentes situa2ons, sous diﬀérents angles de vues, sous diﬀérentes lumières, etc. Par exemple, pour 
reconnaître les chats, on peut présenter jusqu’à un million d’images. En faisant cela, le programme va 
se cons2tuer une représenta2on visuelle interne de ce qu’est cet objet, en calculant une sorte de 
moyenne de l’ensemble des images. Mais ceUe représenta2on n’est in ﬁne qu’une simple descrip2on 
qui n’est pas ancrée dans la réalité du monde. 

En a<endant Terminator. Aujourd’hui, en 2020, l’Intelligence Ar2ﬁcielle connaît un second souﬄe, 
notamment avec l’avènement du big data et une puissance de calcul inégalée jusqu’alors. Ainsi, la 
redécouverte récente de l’appren2ssage profond (deep learning), qui date des années 1980, a permis 
de nouvelles avancées en traitement de données et reconnaissance d’images. Cet algorithme 
d’appren2ssage est un réseau de neurones ar2ﬁciel qui permet d’apprendre à par2r d’exemples. De 
fait, la diﬀérence fondamentale entre les années 1980 et les années 2010 se situe au niveau de la 
puissance de calcul mise en jeu et de la masse de données qui a aUeint des propor2ons 
gigantesques. Imaginez un peu que plus d’un milliard de personnes postent leur photo sur 
Facebook alors qu’il y a trente ans, les chercheurs se démenaient pour cons2tuer des échan2llons de 
quelques dizaines de portraits. De nos jours, ils peuvent donc avoir accès à des centaines de millions 
de visages. C’est ainsi que Facebook possède un algorithme de reconnaissance faciale qui égale 
sta2s2quement les performances humaines. Est-il besoin de préciser qu’on ne parle pas ici 
d’intelligence, mais bien d’algorithmes et d’appren2ssage machine sur des gros volumes de données ? 

Diverses interven2ons dans les médias soulignent les avancées extraordinaires en intelligence 
ar2ﬁcielle et ses dangers poten2els. S’il existe certainement des dangers liés à ce domaine comme à 
tout progrès scien2ﬁque, les vrais risques de l’IA sont peut-être masqués par la crainte que des 
machines prennent le pouvoir. Faut-il s’eﬀrayer de l’avènement futur d’une super IA issue de la 
singularité ? Si ceUe idée est assez populaire en liUérature et au cinéma (« Terminator », « 2001 A 
Space Odyssey », « Ex-Machina »), elle l’est beaucoup moins dans le domaine scien2ﬁque. Ce concept 
de singularité a été de fait introduit par Vernon Vinge (professeur de mathéma2ques et auteur de 
science-ﬁc2on) lors du symposium « Vision 21: Interdisciplinary Science and Engineering in the Era of 
Cyberspace » organisé par la NASA en 1993 : 

Within thirty years, we will have the technological means to create superhuman intelligence. 
Shortly a^er, the human era will be ended. 

Dans trente ans, nous aurons les moyens de créer une intelligence sur-humaine. Peu de 
temps après, l’ère de l’humanité prendra ﬁn. 

Si l’on s’en 2ent à ceUe prédic2on, nous pouvons en déduire que nous allons bientôt disparaître 
puisqu’une super IA doit d’ores et déjà exister dans quelques labos secrets. Or, force est de constater 
que nous sommes encore très loin de ces conclusions drama2ques car il n’y a pas aujourd’hui de 
machine « super-intelligente ». Pourtant, ce concept de singularité peut séduire car il repose sur une 
idée somme toute assez simple : si l’on construisait des ordinateurs de plus en plus « intelligents », 
alors ceux-ci deviendraient plus intelligents que leurs concepteurs et pourraient à leur tour concevoir 
de nouveaux ordinateurs plus intelligents qu’eux-mêmes. Le moment précis où l’Homme construirait 
cet ordinateur plus intelligent que lui-même est précisément ce que Vernor Vinge désigne par 
singularité : puisque les ordinateurs sont beaucoup plus rapides que nous, l’accroissement de 
l’intelligence se ferait alors de façon exponen2elle. Avec les nouveaux résultats époustouﬂants de ces 
dernières années, ce concept a été remis au goût du jour, bien qu’il soit bancal (lire à ce sujet le livre 
de Jean-Gabriel Ganascia «Le Mythe de la singularité »). Pour interpréter les prédic2ons de Vernor 
Vinge sur la singularité, il conviendrait de lui faire préciser sa pensée, aﬁn de savoir ce qu’il considère 
être une intelligence surpra-humaine. Par exemple, ceUe intelligence devrait-elle parler ? avoir des 
buts propres ? avoir un corps ? avoir des opinions ? des amis ? des émo2ons ? des rêves ? etc. Et 
d’ailleurs, comment pourrions-nous reconnaître la singularité, c’est-à-dire, comment pourrions-nous 
savoir que la machine que nous venons de créer est intelligente ? 

Au ﬁnal, l’intelligence ar2ﬁcielle est un champ de recherche extrêmement fécond, qui a enfanté à son 
tour de très nombreux champs de recherche, que ce soit en reconnaissance de la parole, en 
algorithmes pour la géné2que, en fouille de données, en vision par ordinateur, en réseaux de 
neurones ar2ﬁciels, en appren2ssage machine, etc. L’IA « canal historique » a permis de concevoir de 
très nombreux algorithmes que l’on retrouve aujourd’hui dans un très grand nombre d’applica2ons 
grand public. Et si aujourd’hui on ne les appelle plus IA, ils en sont pourtant les héri2ers directs. C’est 

d’ailleurs là une des malédic2ons de l’IA, car dès qu’un algorithme fonc2onne, on a tendance à lui 
re2rer sa ﬁlia2on. En eﬀet, si une machine sait le faire, c’est qu’il ne s’agit plus d’intelligence !

