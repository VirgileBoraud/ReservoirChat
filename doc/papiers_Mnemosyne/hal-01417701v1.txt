Semantic Role Labelling for Robot Instructions using Echo State Networks
Johannes Twiefel, Xavier Hinaut, Stefan Wermter

To cite this version:

Johannes Twiefel, Xavier Hinaut, Stefan Wermter. Semantic Role Labelling
for Robot Instructions using Echo State Networks. European Symposium on
Artificial Neural Networks, Computational Intelligence and Machine
Learning (ESANN), Apr 2016, Bruges, Belgium. ￿hal-01417701￿

HAL Id: hal-01417701

https://inria.hal.science/hal-01417701

Submitted on 15 Dec 2016

HAL is a multi-disciplinary open access archive for the deposit and
dissemination of sci- entific research documents, whether they are pub-
lished or not. The documents may come from teaching and research
institutions in France or abroad, or from public or private research
centers.

L’archive ouverte pluridisciplinaire HAL, est destinée au dépôt et à la
diffusion de documents scientifiques de niveau recherche, publiés ou
non, émanant des établissements d’enseignement et de recherche français
ou étrangers, des laboratoires publics ou privés.

Semantic Role Labelling for Robot Instructions using Echo State
Networks

Johannes Twiefel and Xavier Hinaut and Stefan Wermter ∗

Universit¨at Hamburg - Department Informatik Vogt-K¨olln-Straße 30,
D-22527 Hamburg - Germany https://www.informatik.uni-hamburg.de/wtm/

Abstract. To control a robot in a real-world robot scenario, a real-time
parser is needed to create semantic representations from natural
language which can be interpreted. The parser should be able to create
the hi- erarchical tree-like representations without consulting external
systems to show its learning capabilities. We propose an eﬃcient Echo
State Network- based parser for robotic commands and only relies on the
training data. The system generates a single semantic tree structure in
real-time which can be executed by a robot arm manipulating objects.
Four of six other approaches, which in most cases generate multiple
trees and select one of them as the solution, were outperformed with
64.2% tree accuracy on dif- ﬁcult unseen natural language (74.1% under
best conditions) on the same dataset.

1 Background and Related Work

1.1 Method: Echo State Networks

ESNs belong to the domain of reservoir computing and were e.g. described
by Jaeger [1]. The main part of an ESN is called a reservoir, which is a
recurrent neural network consisting of randomly and sparsely or (in our
case) fully con- nected neurons. A special property of ESNs compared to
other recurrent neural networks is the learning principle which leaves
the input layer and the reservoir untrained. Only the output layer
(readout), which is connected to the reservoir, is trained on reservoir
states usually by Linear or Ridge Regression but it can also be trained
online using Least Mean Square [2]. To be able to balance the inﬂuence
of new inputs and past states of the network, we used leaky integrator
neurons in the reservoir update equation [3]:

x(n + 1) = (1 − α)x(n) + αf (W x(n) + W inu(n + 1)

(1) 

with x(n) the current state; W the weights inside the reservoir; W in
the weights of the input layer; u(n + 1) the next input; f the
activation function (tanh); α the leak rate. The outputs of an ESN are
given by y(n), the output weights W out are calculated using Linear
Regression

y(n) = W outz(n); W out = (X T X)∗X T Y

(2) 

∗This research was partially supported by a Marie Curie Intra European
Fellowship within the 7th European Community Framework Programme:
EchoRob project (PIEF-GA-2013- 627156).

with W out the weights of the output layer; z(n) given by [x(n); 1]; X
the states of the reservoir concatenated with a bias ([x(n); 1]); Y the
desired output of the system; (X T X)∗ the Moore-Penrose-Pseudoinverse
of (X T X).

1.2 Task: Supervised Semantic Parsing of Robotic Spatial Com-

mands

The SemEval-2014 Task 6 [4] was a contest in 2014 to provide parsing
systems for a robotic spatial command dataset to extract semantic
information in predeﬁned structures. It was based on the Train Robots
[5] dataset which consists of robot instructions and their corresponding
semantic representation. Instructions were produced by internet users
and are often grammatically incorrect. Whereas the whole treebank
consists of around 10,000 sentences, for SemEval-2014 Task 6, a subset
of 3,409 sentences from the treebank was chosen taking the ﬁrst 2,500
sentences as training data, and the remaining 909 sentences as testing
data. The dataset contains linguistically rich sentences, including
ellipses, anaphoric references, multi-word spatial expressions and
lexical disambiguation. The com- mands are related to a simulated
environment containing an 8 x 8 board, on which diﬀerently colored
objects like boxes and pyramids are placed (see Fig. 1). A robot arm is
able to grasp objects from the board and move them to diﬀerent
positions. The sentences of the dataset contain a visual description of
the scene before (left) and after (right) performing the desired action.
For each sentence a semantic annotation exists which is described by the
Robot Control Language (RCL). One challenging example sentence would be
”Pick up the blue block from the top of the green block and put it down
on the blue block which lies next to another green block.”

event

action

entity

destination

color

type

spatial-relation

relation

entity

color

type

move the

red

brick

on

top

of the

blue

brick

Fig. 1: An example for a board scene before (left board) and after
(right board) the command Move the red brick on top of the blue brick
and the corresponding parse tree.

1.3 Related Reference Systems

UW-MRS: Packard [6] developed a parser that uses the English Resource
Grammar (ERG) as ﬁrst-phase processing and employs a modiﬁed Berkeley

Parser as a second-phase backup. The ERG produces Minimal Recursion Se-
mantics (MRS) as output and converts these to RCL statements. If the
produced RCL statement is invalid, the Berkeley Parser creates
hypothetical trees. RoBox: The parser introduced by Evang and Bos [7]
employs Combinatory Categorial Grammar (CCG) as a representation instead
of RCL trees for train- ing. To choose the best hypothetic tree, a
structured perceptron is performing a post-processing step. Tag&Parse:
The Tag&Parse approach [8] consists of an independent tagger creating
part-of-speech tags and performs chunking and chunk labelling. Then a
constituency parser is used to generate RCL trees. To resolve anaphors,
a maximum entropy model is used to generate tree hypotheses. Finally,
the most probable tree is selected by the system. KUL-Eval: Mattelaer et
al. λ-expressions together with a probabilistic CCG. Shrdlite: Shrdlite,
a model of Ljungl¨of [10] consists of a hand-written ambigu- ous grammar
to generate multiple trees. The system selects the tree containing the
minimum number of nodes as the best hypothetic tree. UWM: The system
developed by Kate [11] consists of the KRISP parser which uses a Support
Vector Machine and a handwritten context-free grammar.

[9] developed a system using RCL statements as

2 Approach

The aim of the developed approach is to provide a neural model for
processing commands directed to a robot and create semantic
representations that can be interpreted by that robot to perform the
action contained in a given command. The developed model is inspired by
the model of Hinaut and Dominey [12, 13], which is able to learn
predicates from sentence structures consisting of closed class word
(like the, and, …) and place-holder open-class words. As input, our
model receives tagged and labelled chunks (TLCs) (e.g. action: take).
The TLCs are fed as a sequence to the network. At each timestep, only
two neurons are active, one specifying the current tag (e.g. action),
the other one setting the current label (e.g. take). For training, the
reservoir state at the end of the sequence is collected for each input
sequence and a Linear Regression is used to calculate the weights for
the readout. The output nodes are used to generate RCL trees. Each word
can have multiple outputs active. The possible outputs are
spatial-relation (4), sequence (1), destination (1), entity (6), measure
(1), event (2), type-reference (2*6) which are in total 27 for each word
and at maximum 1080 for the longest assumable sentence (40 words). An
output will be considered as active if its response is greater than 0.5.
There are multiple outputs for several RCL elements to be able to
distinguish elements of the same type. The inputs are generated by a
second order Hidden Markov Model (HMM) [14], which takes words as input
and generates Inside Outside Beginning 2 (IOB2) representations [15].
The same model is used to generate chunk labels from words. Fig. 2 shows
an example of processing a very simple sentence.

Fig. 2: Processing of a simple example sentence. First, IOB2 tags
(cid:173) are gen- erated (e.g. move → B-action) from the input sequence
(cid:172). Then the HMM creates chunk labels (cid:174) for words
(cid:172) (e.g. on → above). Afterwards the identiﬁed chunks (cid:173)
are merged (e.g. B-rel I-rel I-rel → relation) and are paired with the
corresponding chunk tags (cid:174) to a TLC sequence (cid:175). The TLC
sequence is fed to our ESN-based model which generates outputs for each
words (cid:176). The active outputs (cid:177) are merged (e.g. ent ˙0 …
ent ˙0 → entity) and ordered in a hierarchy derived from the training
data (e.g. event over entity). From this hierarchy, a tree
representation can be derived (event as root, entity as child of event…;
see Fig. 1).

3 Experiments and Results

The training dataset [5] consists of 2,500 sentences and 2,500 RCL trees
repre- senting their semantic content, while the test set contains 909
sentences and 909 RCL representations. To measure the performance of our
system, we consider the metric deﬁned in SemEval-2014 Task 6 [4], which
takes a string representa- tion of the generated RCL tree and compares
it directly to the reference tree. This way, even trees containing small
errors are considered as classiﬁed wrongly which makes it a hard metric.
In SemEval-2014 Task 6, the performance of the diﬀerent systems (see
Sec. 1.3) is measured for performing the task with and without the
assistance of a planner, which is able to validate if a tree is correct
for a given scene. As our system works without consulting a planner, we
com- pare to the performance of the other methods measured without the
planner. The results are shown in Table 1. To ﬁnd out the best
hyper-parameters for our system, we performed a 10-fold cross-validation
on the training dataset explor- ing the parameters leak rate (from 0.1
to 0.9 with step size 0.1), spectral radius (from 0.25 to 10 with step
size 0.25) for 10 diﬀerent reservoir instance with a size of 500. The
grid-search led to the best choice of hyper-parameters (leak rate = 0.3,
spectral radius = 6) and was performed relatively fast (18 hours) using
GPU processing to parallelize the computations. We ﬁxed the reservoir
size to 500 to increase the computation time, as Lukoˇseviˇcius et
al. [16] claimed that hyper-parameters scale for diﬀerent reservoir
sizes on the same task. To show the behaviour of the system with a
reservoir network size, we measured the test

Move the red brick on top of the blue
brickB-actB-colB-typeB-relI-relI-relB-colB-typeOOmoveaboveredcubebluecubeactionmovecolorredtypecuberelationabovecolorbluetypecubeev_0ev_0ev_0ev_0ev_0ev_0ent_0ent_0sp_0ent_1ent_1HMM123465OOaboveaboveevententityspatial-relationentitygreenredmovetakeindcolactrelcar
Outputs: Word 1 Word 2 Word 3 …ESNerror for diﬀerent reservoir sizes up
to 20,000 neurons (see Fig. 3). To train the 2,500 sentences, the system
just needs several seconds for reservoir sizes up to 5,000 neurons, for
20,000 it already takes 5 minutes, while testing a single sentence is
possible in real-time even with a reservoir of 20,000 neurons.

Approach UW-MRS RoBox Tag& Parse KUL-Eval Shrdlite UWM Our Approach Our
Approach (perfect TLCs)

Accuracy (90.50) 79.21 60.84 57.76 51.50 45.98 64.2 74.1

Table 1: Performance on SemEval-2014 Task 6 [4] data.

Fig. 3: Performance for diﬀerent reservoir sizes.

4 Discussion

Compared to the other systems (see Sec. 1.3), which usually generate
multiple possible trees and select one using a post-processor, our
system only generates one tree as output, which leads to a constant
computation time (O(1)) for a sentence with a given size, compared to
O(n3) [17] for the CKY-based RoBox parser. Our ESN-based model is
trainable in an eﬃcient and fast way, as only the output weights have to
be calculated only at the last time-step. Even scaling up the reservoir
size up to 20,000 neurons (which leads to an increased performance (see
Fig. 3)) does not prevent the system to work in real-time. A larger
reservoir would be possible but is computationally too expensive, as
with modern GPUs (approx. 5,000 cores) not all computations can be
parallelized and a lot of data shifting has to be performed, which slows
down the training process. The results in Table 1 show that the system
outperforms four of the six reference systems. The best system (UW-MRS)
is based on the English Resource Grammar which is an external expert,
while our system only uses the training data as input. The system would
be even better if the TLCs generated by the HMM were correct (64.2% →
74.1% accuracy). Because of this fact, we plan to develop an improved
chunker based on ESNs. After inspecting the neural outputs of the
system, we identiﬁed that often only one or few labels are incorrect,
and that there are low activities for diﬀerent concurrent outputs
(e.g. spatial-relation and entity), which leads to the hypothesis that
the system was trained with ambiguous data and provides weak responses
to the diﬀerent possible outputs at the same time. We plan to introduce
a post-processing step which disambiguates these outputs. By solving
this systematic error, the system could outperform the other methods
which do not use an external expert. Due to the fact that the system is
running in real-time, we are also planning to bring the system to a
real-world scenario by

1002005001000200050001000020000ReservoirSize4045505560657075RCLTreeAccuracyperfectchunkschunksfromHMMconnecting
it to an existing speech recognition environment [18] and to employ the
outputs of the system to control a real-world robot like in [13].

References

[1] H. Jaeger. The “echo state” approach to analysing and training
recurrent neural networks- with an erratum note. Bonn, Germany: German
National Research Center for Informa- tion Technology GMD Technical
Report, 148:34, 2001.

[2] X. Hinaut and S. Wermter. An incremental approach to language
acquisition: Thematic role assignment with echo state networks. In ICANN
2014, pages 33–40. Springer, 2014.

[3] H. Jaeger, M. Lukoˇseviˇcius, D. Popovici, and U. Siewert.
Optimization and applications of echo state networks with
leaky-integrator neurons. Neural Networks, 20(3):335–352, 2007.

[4] K. Dukes. Semeval-2014 task 6: Supervised semantic parsing of
robotic spatial commands.

SemEval 2014, page 45, 2014.

[5] K. Dukes. Train robots: A dataset for natural language human-robot
spatial interaction through verbal commands. In ICSR. Embodied
Communication of Goals and Intentions Workshop, Bristol, United Kingdom,
2013.

[6] W. Packard. UW-MRS: leveraging a deep grammar for robotic spatial
commands. Se-

mEval 2014, page 812, 2014.

[7] K. Evang and J. Bos. Robox: CCG with structured perceptron for
supervised semantic

parsing of robotic spatial commands. SemEval 2014, page 482, 2014.

[8] S. Stoyanchev, H. Jung, J. Chen, and S. Bangalore. AT&T: The
tag&parse approach to

semantic parsing of robot spatial commands. SemEval 2014, page 109,
2014.

[9] W. Mattelaer, M. Verbeke, and D. Nitti. Kul-eval: A combinatory
categorial grammar ap- proach for improving semantic parsing of robot
commands using spatial context. SemEval 2014, page 385, 2014.

[10] P. Ljungl¨of. Shrdlite: Semantic parsing using a handmade grammar.
SemEval 2014, page

556, 2014.

[11] R. J. Kate. UWM: Applying an existing trainable semantic parser to
parse robotic spatial

commands. SemEval 2014, page 823, 2014.

[12] X. Hinaut and P. F. Dominey. Real-time parallel processing of
grammatical structure in the fronto-striatal system: a recurrent network
simulation study using reservoir comput- ing. PloS one, 8(2):e52946,
2013.

[13] X. Hinaut, M. Petit, G. Pointeau, and P. F. Dominey. Exploring the
acquisition and production of grammatical constructions through
human-robot interaction with echo state networks. Frontiers in
Neurorobotics, 8, 2014.

[14] K. Dukes. Contextual Semantic Parsing using Crowdsourced Spatial
Descriptions.

arXiv:1405.0145 [cs], May 2014. arXiv: 1405.0145.

[15] E. F. Tjong Kim Sang and S. Buchholz.

Introduction to the conll-2000 shared task: Chunking. In Proceedings of
the 2nd workshop on Learning language in logic and the 4th CoNLL-Volume
7, pages 127–132. Association for Computational Linguistics, 2000.

[16] M. Lukoˇseviˇcius. A practical guide to applying echo state
networks. In Neural Networks:

Tricks of the Trade, pages 659–686. Springer, 2012.

[17] X. Song, S. Ding, and C. Lin. Better binarization for the cky
parsing. In EMNLP 2008.

Hawaii, USA, pages 167–176. Association for Computational Linguistics,
2008.

[18] J. Twiefel, T. Baumann, S. Heinrich, and S. Wermter. Improving
domain-independent cloud-based speech recognition with domain-dependent
phonetic post-processing. In Twenty-Eighth AAAI. Qu´ebec City, Canada,
pages 1529–1535, 2014.


