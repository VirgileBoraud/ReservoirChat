Jouez avec les neurones de la machine
Thalita F Drumond, Laurent Viennot, Thierry Viéville, Valérie François

To cite this version:

Thalita F Drumond, Laurent Viennot, Thierry Viéville, Valérie François. Jouez avec les neurones de
la machine. 2017, pp.1-3. ￿hal-01620451￿

HAL Id: hal-01620451

https://inria.hal.science/hal-01620451

Submitted on 23 Oct 2017

HAL is a multi-disciplinary open access
archive for the deposit and dissemination of sci-
entific research documents, whether they are pub-
lished or not. The documents may come from
teaching and research institutions in France or
abroad, or from public or private research centers.

L’archive ouverte pluridisciplinaire HAL, est
destinée au dépôt et à la diffusion de documents
scientifiques de niveau recherche, publiés ou non,
émanant des établissements d’enseignement et de
recherche français ou étrangers, des laboratoires
publics ou privés.

about:blank

20 octobre 2017

Jouez avec les neurones de la machine

Le canard artiﬁciel de
Vaucanson (1738), qui «
boit, mange, cancane,
barbote et digère comme
un vrai canard »

« L’intelligence artiﬁcielle est la science de faire faire à des machines des choses qui demanderaient de l’intelligence si elles étaient
faites par des humains». Tout est dit par le fondateur de l’intelligence artiﬁcielle,  Marvin Minsky. Exit les fantasmes du genre\* de
celui d’une «servante-robot, qui sert [le] café [au lit] le matin ».  Et comme le mentionne Cédric Villani au lancement de sa mission de
réﬂexion sur ces sujets, notre meilleure arme est «une grande qualité de formation» sur ce sujet qui est «l’aﬀaire de [toutes et] tous».
Soit. Et si on commençait, là, maintenant ? Ça vous dirait de soulever le capot de l’intelligence artiﬁcielle ? Thierry Viéville.

Un réseau de neurones est un mécanisme générique composé de petites unités (des pseudo-neurones) connectées les unes aux autres.
Chaque unité fait une opération très simple : elle prend des valeurs en entrée, les combine très simplement (un simple calcul de
moyenne avec des coeﬀicients comme les notes du bac) et applique une transformation sur le résultat (par exemple ne garde que les
valeurs positives). Les coeﬀicients utilisés pour pondérer la moyenne sont les paramètres de cet algorithme. C’est la combinaison d’un
très, très grand nombre de ces unités qui permet de réaliser des opérations très complexes. Un réseau de telles « neurones » s’obtient
en accumulant plusieurs couches de telles unités. En entrée il y a les données que l’on veut traiter. Elles se transforment à travers
toutes les couches et la dernière couche donne en sortie une prédiction sur ces données, par exemple détecter s’il y a un visage dans
une image. Le réseau de neurone constitue ainsi une fonction paramétrée par ces nombreux coeﬀicients (on parle de « poids ») et
c’est le choix de ces poids qui déﬁnit le traitement eﬀectué.

Chaque « neurone » mélange les entrées X
de manière proportionnelle à ses poids W et
rectiﬁe le résultat pour donner la sortie y.
C’est la combinaison de miriades de tels
calculs élémentaires qui genère un système
complexe. Issu de Interstices.

Sur l’interface web de TensorFlow, on constitue facilement un réseau d’une douzaine de neurones possédant chacun entre 3 et 10
paramètres. La sortie calculée dépend donc d’une centaines de paramètres en plus des deux coordonnées (x,y) du point d’entrée. Sur
l’interface, chaque carré représente un neurone et la couleur du pixel de coordonnées (x,y) dans le carré représente la sortie du
neurone quand on met (x,y) en entrée du réseau. Il y a un seul neurone en sortie, il est représenté avec un carré plus grand sur la
droite du réseau. Les paramètres du réseau sont initialisés au départ avec des valeurs aléatoires.

1 of 3

10/20/2017 03:57 PM

about:blank

Mais comment apprendre ces poids ? L’apprentissage supervisé

consiste à fournir des exemples de données accompagnés de la solution à trouver, pour entrainer le réseau à ajuster ces poids comme
il faut. Ici, il s’agit d’une série de points dans un carré avec pour chacun une couleur attendue (bleu ou orange), avec comme but de
prédire la couleur du point à un endroit donné. C’est un algorithme classique d’ajustement progressif des poids (on parle de
« descente de gradient ») qui permet de trouver les paramètres en question. Le bouton « play » en haut à gauche de l’interface
permet de lancer cet algorithme, on voit alors la sortie du réseau de neurones évoluer au cours de l’ « apprentissage » : la couleur du
fond du neurone de sortie tend à prendre la couleur des points d’entrainement qui sont dessinés par-dessus. Une autre partie du jeu
de données est ensuite utilisée pour tester la qualité de la fonction obtenue par le réseau. Une courbe en haut à droite aﬀiche le taux
d’erreurs liées aux données utilisées pour apprendre (pour vériﬁer que les poids se sont bien ajustés) et le taux d’erreurs liées aux
autres données de test (pour vériﬁer que ce qui a été appris se généralise bien à de nouvelles données). Des boutons sur la gauche
permettent de régler la répartition des données entre le jeu d’apprentissage et celui de test et aussi  d’ajouter des erreurs aux
données (les bruiter) pour voir si le mécanisme est robuste face à ces erreurs.

© Casterman

En pratique, on arrive à trouver des paramètres satisfaisants, mais il n’y a pas vraiment de cadre théorique pour formaliser tout cela,
c’est aﬀaire d’expérience : choisir le bon nombre de neurones, le bon nombre de couches de neurones, quels calculs préliminaires
ajouter en entrée (par exemple multiplier les entrées pour augmenter les degrés de liberté permettant de faire le calcul). Ce genre de
techniques permet d’obtenir des résultats impressionnants en pratique, comme en reconnaissance de la voix ou d’objets dans une
image (voir les vidéos du cours de Yann Le Cun au Collège de France). Cependant, comprendre pourquoi (et comment) on obtient de
si bons résultats reste une question scientiﬁque encore assez ouverte. En attendant voulez-vous essayer une application réelle sur des
données réelles ? C’est par ici https://www.clarifai.com/demo (il suﬀit de jouer avec les options).

A vous de tester votre petite cuisine neuronale ! Arriverez-vous à mettre les bonnes couleurs sur le jeu de données en spirale ?

Quelques exemples

Si on choisit de simplement classer deux populations, ici orange et bleue, qui sont déjà groupées en deux blocs facilement séparés par
un ligne, alors c’est très facile : il suﬀit de trois neurones. En cliquant sur l’image on peut lancer la solution et observer l’ajustement
des paramètres de chaque unités de calcul, ces pseudo neurones.
Les deux premiers neurones de la couche d’entrée calculent pour la position horizontale et verticale et le neurone de sortie combine
ses informations pour faire une sortie oblique.
On parle de problème linéaire pour décrire un tel problème de classiﬁcation dont la solution est une simple séparation par une

2 of 3

10/20/2017 03:57 PM

surface plate.

about:blank

Mais si les données sont complètement intermélées comme dans le cas de ces données en spirale

alors il faut beaucoup plus de couches de calcul avec plus de neurones.
On voit alors comment au ﬁl du calcul dans les couches de l’architecture, chaque neurone code pour un aspect de la forme à trouver,
basique dans les couches basses, plus sophistiqué dans les couches plus hautes. Beaucoup de calculs pour une simple paire de
spirales ! Mais ce qui est remarquable c’est que cette foule de calculs élémentaires a pu coder approximativement un objet non trivial,
en s’adaptant aux données, sans avoir eu à donner des informations à priori sur ces formes spiralées.

Faut-il tous ces neurones pour résoudre ce problème de classiﬁcation de données ? Pas forcément : lors d’un atelier lycéen où des
jeunes expérimentaient ce logiciel à travers l’interface Web, en expérimentant numériquement les solution possibles, deux d’entre eux
Akmal et Amandine ont obtenu une solution plus longue à obtenir et moins stable qu’une solution gourmande en nombre de neurones,
mais qui marche plutôt bien.
Et vous avez vous une solution encore plus astucieuse à proposer ?

Thalita Firmo-Drumond à partir d’une proposition de Laurent Viennot éditée par Valérie François et publiée
conjointement sur pixees.fr.

(\*) On trouve hélas cette métaphore sexiste et anti-pédagogique au possible (sans aucune explicitation du propos qui serait au
deuxième degré), en introduction du livre blanc sur l’intelligence artiﬁcielle produit par un institut de recherche de référence sur ces
sujets.

3 of 3

10/20/2017 03:57 PM

