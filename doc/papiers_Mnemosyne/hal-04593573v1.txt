Citizenship, Censorship, and Democracy in the Age of Artificial
Intelligence Tetiana Matusevych, Margarida Romero, Oksana Strutynska

To cite this version:

Tetiana Matusevych, Margarida Romero, Oksana Strutynska. Citizenship,
Censorship, and Democ- racy in the Age of Artificial Intelligence.
Creative Applications of Artificial Intelligence in Edu- cation,
Springer Nature Switzerland, pp.57-71, 2024, Palgrave Studies in
Creativity and Culture, ￿10.1007/978-3-031-55272-4_5￿. ￿hal-04593573￿

HAL Id: hal-04593573

https://hal.science/hal-04593573

Submitted on 29 May 2024

HAL is a multi-disciplinary open access archive for the deposit and
dissemination of sci- entific research documents, whether they are pub-
lished or not. The documents may come from teaching and research
institutions in France or abroad, or from public or private research
centers.

L’archive ouverte pluridisciplinaire HAL, est destinée au dépôt et à la
diffusion de documents scientifiques de niveau recherche, publiés ou
non, émanant des établissements d’enseignement et de recherche français
ou étrangers, des laboratoires publics ou privés.

5

Citizenship, Censorship, and Democracy in the Age of Artificial
Intelligence

Tetiana Matusevych, Margarida Romero, and Oksana Strutynska

Abstract This chapter delves into the ethical dilemmas that arise from
the incorporation of artiﬁcial intelligence (AI) into the ﬁeld of
education. It emphasises the importance of media literacy, AI literacy,
and critical use of digital technologies in order to combat information
conﬂicts, political manipulation, and AI inequality, among other issues.
Poten- tial threats to citizenship, such as AI censorship and
disinformation, are examined in this chapter. Discourse is devoted to
the dangers of deep- fake technology as it pertains to the dissemination
of false information and the manipulation of public sentiment; the
signiﬁcance of compre- hending AI fundamentals and enforcing ethical
standards is underscored.

T. Matusevych (B) · O. Strutynska Dragomanov Ukrainian State University,
Kyiv, Ukraine e-mail: t.v.matusevych@udu.edu.ua

O. Strutynska e-mail: o.v.strutynska@udu.edu.ua

M. Romero Université Côte d’Azur, Nice, France e-mail:
margarida.romero@univ-cotedazur.fr; margarida.romero@unice.fr

© The Author(s) 2024 A. Urmeneta and M. Romero (eds.), Creative
Applications of Artiﬁcial Intelligence in Education, Palgrave Studies in
Creativity and Culture, https://doi.org/10.1007/978-3-031-55272-4_5

57

58

T. Matusevych et al.

Notwithstanding the potential hazards, this chapter acknowledges the
prospective advantages of AI in the ﬁeld of education, which encom- pass
gamiﬁcation and adaptive learning paths. The text culminates by
emphasising the signiﬁcance of AI acculturation in enabling individ-
uals to comprehend the ethical intricacies and arrive at well-informed
judgements regarding the impact of AI on democracy, education, and
citizenship.

Keywords AI fundamentals · AI literacy · Digital competence ·
Citizenship · AI ethics · AI algorithms

Introduction

The rapid development of digital technologies and their widespread
adoption make it necessary to develop citizens’ digital competence and
to actively engage people in their responsible use (Alexandre et al.,
2020). Important components of citizens’ digital competence include
artiﬁcial intelligence (AI) literacy, critical use of digital
technologies, and media literacy. These literacies are required due to
the threats of information wars, political manipulation, but also
digital and AI inequality and divi- sions (Calvo et al., 2020). These
issues highlight the need to engage modern youth in responsible digital
citizenship, which is an important component of citizenship education.

One of the conceptual initiatives to overcome these challenges was the
creation of the Digital Citizenship Education program by the Council of
Europe (Committee of Ministers Council Europe, 2019), which aims to
provide young people with innovative opportunities to develop the
values, attitudes, skills, and knowledge necessary for every citizen to
fully participate and fulﬁl their responsibilities in society. Digital
citi- zens are deﬁned by the Council of Europe as people who are able to
use digital tools to create, consume, communicate, and interact
positively and responsibly with others. Digital citizens understand and
respect human rights, embrace diversity, and prioritise lifelong
learning as a way of keeping pace with societal changes.

Digital civic education is a holistic approach that aims to develop the
basic skills and knowledge needed in today’s connected world, as well as

5 Citizenship, Censorship, and Democracy in the Age …

59

to foster values and attitudes that will ensure their wise and
meaningful use. The development, regulation, involvement, and use of AI
in educa- tion are part of this approach. In particular, it states that
AI, like any other tool, offers many opportunities, but also poses
signiﬁcant threats that require the consideration of human rights
principles in the early stages of its application. Educators need to be
aware of the strengths and weaknesses of AI in education in order to
empower their digital civic education practices (Committee of Ministers
Council Europe, 2019). In this regard, Artiﬁcial Intelligence for Social
Good (AI4SG) is also an important concept for civic education, which is
becoming increasingly popular in professional circles (Hager et al.,
2019). Projects aimed at using AI for the social good range from
applications to help the hungry, to combating natural disasters,
game-theoretic models aimed at poaching prevention, online HIV education
for homeless youth, prevention of gender-based violence, and
psychological support for students. (Floridi et al., 2020).

But despite the fact that new

initiatives are emerging every day, researchers note that there is still
only a limited understanding of what constitutes AI ‘for the social
good’. The lack of a clear understanding of what makes AI socially
useful in theory, or what can be described as AI4SG in practice, and how
to replicate its initial successes from a policy perspective creates at
least two major obstacles for developers: avoid- able mistakes and
missed opportunities. AI software is shaped by human values, which, if
not carefully selected, can lead to ‘good AI goes bad’ scenarios
(Floridi et al., 2020). Thus, the issues of the value component and
ethical principles of AI use are becoming increasingly relevant.

In general, the ethical issues of AI development and application are the
focus of many researchers and international institutions, which has led
to the creation of numerous initiatives, committees, and institutes of
AI ethics. The Montreal AI Ethics Institute (MAIEI) published a
guideline including the norms for responsible AI research and use
(Dilhac et al., 2018). The Montreal Declaration for a Responsible
Development of Artiﬁcial Intelligence is founded upon a set of ethical
principles centred on seven fundamental values: well-being, autonomy,
justice, privacy, knowledge, democracy, and responsibility. As a result
of the analysis, researchers identiﬁed 84 published sets of ethical
principles for AI that

60

T. Matusevych et al.

coincide in ﬁve areas: transparency, fairness and honesty, harmlessness,
responsibility, and conﬁdentiality (Jobin et al., 2019).

Current Problems in the Integration of AI into Education

Despite the extensive debate around the ethical use of AI, there are a
number of problems that have not yet been solved. The main ones are as
follows:

1.  The polymorphic nature of the ethics of using AI in education . AI
    ethics raises a number of complex issues centred on data (e.g.,
    consent and data privacy) and how this data is analysed (e.g.,
    transparency and trust). It is clear, however, that the ethics of AI
    in education cannot be reduced to issues of data and computational
    approaches alone. Research into the ethics of data and computing for
    AI in education is necessary but not sufﬁcient. The ethics of AI in
    education should also take into account the ethics of education
    (Holmes et al., 2022).
2.  Potential threats to fundamental rights and democracy. The results
    produced by AI depend on how it is designed and the data it
    utilises. Both the design and the data may be intentionally or
    unintentionally biassed. For example, some important aspects of the
    problem may not be programmed into the algorithm or may be
    programmed to reﬂect and repeat structural biases (Borenstein &
    Howard, 2021). In addition, the use of numbers to represent complex
    social real- ities may carry risks of apparent simplicity (Holmes et
    al., 2022). Another signiﬁcant threat to human rights is data bias,
    which can affect the training of large language models (LLM) and
    result in biassed models For example, if an educational institution
    has student performance data biassed towards a certain ethnic,
    gender, or socioe- conomic group, the AI system can learn to favour
    students from that particular group (Manyika & Silberg, 2019;
    Roselli et al., 2019). A further example of gender bias, this time
    in neural network algo- rithms for image generation, is provided in
    the research by Nikoli´c and Joviˇci´c (2023). When working with the
    visual generative AI

5 Citizenship, Censorship, and Democracy in the Age …

61

services DALL-E 2 and Stable Diffusion, the researchers observed the
types of images the neural networks produced, particularly in rela- tion
to the representation of women in STEM. Speciﬁcally, when using the
prompts ‘IT expert’, between 75 and 100% of the AI-generated images
featured men, reinforcing stereotypes about male-dominated STEM profes-
sions: both as occupations that primarily attract men and as profes-
sions where men are prominent compared to women (Nikoli´c & Joviˇci´c,
2023).

‘mathematician’, or

‘engineer’,

‘scientist’,

3.  AI colonialism in education. AI colonialism can be understood in
    relation to the ‘control, domination, and manipulation of human
    values’ (Faruque, 2022, para. 25). AI colonialism is developed under
    an industrial perspective in which the business applications of AI
    are moved forward mainly for commercial objectives instead of human-
    istic ones. In 2020, in spite of the coronavirus pandemic, venture
    capital investment in AI startups reached US$75 billion for the
    year, of which about US$2 billion was invested in AI in education
    compa- nies, predominantly based in the US. It is these companies
    that sell their interpretations around the world, creating what is
    called the colonialism of AI in education. This problem makes
    addressing cultural diversity one of the most challenging topics in
    AI in educa- tion (Blanchard, 2015). We can also consider the use of
    the English language as a form of colonialism in technology, given
    that it is the default language of consumption as well as the
    academic language in which AI speciﬁcations, frameworks, and ethical
    guidelines are produced and debated. Given that language not only
    conveys a symbolic representation of society, but also a cultural
    perspective of a certain context, we should acknowledge that having
    a default language reduces cultural perspectives and creates an
    accessibility challenge for those lacking the requisite language
    skills.

4.  Lack of a universal approach to regulating the ethical issues of
    using AI in education. Unlike healthcare, where there are
    long-established ethical principles and codes of conduct for the
    treatment of humans, education (outside of university research) does
    not have the same for ethics universal approach or a commonly
    accepted model committees (Holmes et al., 2022). As such, when it
    comes to the

62

T. Matusevych et al.

use of AI in education, most discussions treat students as data subjects
rather than human beings. The learner activity is quanti- ﬁed in a way
that reduces the representation of the learner into a quantitative
model, mostly based on certain learning analytics. As a result,
commercial players and schools may involve children in AI- driven
systems without any ethical or other risk assessment (Holmes et al.,
2022). In Europe, the AI Act (Pagallo et al., 2022) aims to advance the
regulation of AI systems with the goal of making them ‘safe,
transparent, traceable, non-discriminatory, and environ- mentally
friendly’ (EU AI Act, 2023). Meanwhile, other countries are developing
their own initiatives independently, without joint cooperation on a
universal approach to AI regulation.

increasing

their policies. This

5.  Challenges of ‘ethics washing’ . A large number of commercial actors
    in the tech sector publish ethics guidelines to ‘wash away’ concerns
    regarding instrumentalization of ethical guidelines by technology
    companies is called ‘ethics washing’ and refers to a situation where
    ethics is used by companies as an acceptable facade to justify
    deregulation, self-regulation, or market- driven governance, and is
    increasingly identiﬁed with the self-serving use and pretence of
    ethical behaviour (Bietti, 2020; van Maanen, 2022). For AI in
    education, given that children are the primary users of these
    commercial AI technologies, it is important to develop and implement
    robust ethical guidelines and avoid any ‘ethics washing’ (OECD,
    2021).

6.  Lack of systematic application of ethical principles for the use of
    AI . Although universities usually have robust research ethics
    procedures, most university or commercial AI research companies do
    not oversee AI ethics. This may be partly due to the fact that, in
    the early days of AI, research using human data was considered
    minimally risky (Holmes et al., 2022). The way AI is integrated into
    educa- tional academic activities is regulated at different levels,
    including in schools or research labs, university and school
    departments, and government bodies such as the Ministries of
    Education of individual countries, all of whom may have different
    policies related to the ethical principles of AI. We should also
    consider that the end-user may not be able to evaluate the ethical
    principles of AI technologies,

5 Citizenship, Censorship, and Democracy in the Age …

63

meaning that AI creators have a responsibility to design and deploy AI
technologies that recognise the varied ethical principles found in
different national and professional domains.

7.  Threats of excessive and unjustiﬁed use of AI. Overuse of AI can be
    problematic. Examples include investing in AI applications that turn
    out to be ineffective or applying AI to tasks for which it is not
    suited, such as explaining complex societal problems (Holmes et al.,
    2022). Automation of certain human activities related to educa- tion
    necessitates a high degree of sensitivity in determining what is
    appropriate, rather than merely what is possible. For example, it is
    important to continue to learn foreign languages even if auto- matic
    translations are available. Not only because human-to-human
    interaction is more empathetic, but also because there is a poten-
    tial cognitive decline if we are not engaging in effortful cognitive
    activities such as learning, speaking, or writing in foreign
    languages. Finally, when evaluating the applications of AI, it is
    important to consider the energy consumption associated with its use
    versus alter- native information search processes that may be less
    energy-intensive (Yang et al., 2021).

8.  Challenges of accountability and responsibility. For educational
    insti- tutions, the question is not only whether AI can be used in
    children’s education, but also how accountability and responsibility
    should be determined when educators decide to adopt or reject any
    systemic recommendation (Holmes et al., 2022).

‘AI

9.  Challenges of conﬂict of interest or ‘AI loyalty’ . The concept of
    conﬂict of interest, or loyalty’ (Aguirre et al., 2021) in
    educational institutions is largely absent in the current body of
    literature. For whom do AI systems work? Is it the students,
    schools, the educa- tion system, commercial players (e.g., AI edtech
    companies), or politicians? The question is not necessarily about
    the ethics of the technology itself, but rather about the ethics of
    the decision makers leading the companies behind AI’s development,
    implementation, and use (Holmes et al., 2022). Understanding AI
    loyalty means clearly deﬁning ownership and any conﬂicts of
    interest. To increase the transparency and credibility of AI
    applications, system devel- opers and controllers should be required
    to clearly align the loyalty

64

T. Matusevych et al.

of their AI systems and governance structures with the interests of
learners and other stakeholders of their systems (Holmes et al., 2022).
In their daily work, educators should be acculturated to the
fundamentals of AI in order to decide which of its uses are relevant for
the teaching or learning process, but also to be able to decline the use
of certain AI technologies that are not relevant to their teaching
practices.

10. Decreased social connection and overreliance on technology. There is
    a risk that an increase in time spent using AI systems will lead to
    a decrease in the interactions between students, teachers, and
    class- mates. Kids might also begin substituting other human
    interactions (e.g., conversions with families and friends) with
    conversational AI systems amplifying and exacerbating the public
    health crises of loneliness, isolation, and disconnection (Bailey,
    2023).

11. AI threats to citizenship. Widespread threats, such as AI censor-
    ship and AI misinformation, can lead to the manipulation of public
    opinion, contribute to the incitement of conﬂicts on various grounds
    (e.g., racial, religious, etc.), and contribute to the worsening of
    existing inequalities and stereotypes (e.g., gender inequalities).
    Filgueiras (2022) highlights the risks of AI in the context of
    author- itarianism in developing countries, which can amplify
    surveillance mechanisms put in place to control citizens considered
    a threat to the current establishment.

12. AI censorship . Due to the rapid development of AI, the threat of AI

censorship has been added to internet censorship and the deletion of
uncomfortable content practices (i.e., for political elites who want to
inﬂuence public opinion). Censorship of political content on Chinese and
Russian social media (e.g., active deletion of messages posted by
individuals) is already having a corresponding impact on public opinion
in these countries (Bamman et al., 2012; Ermoshina et al., 2022; Yang,
2016). Furthermore, AI censorship can dramati- cally affect the
objectivity of people’s perceptions of information. For example,
motivated groups can adjust the algorithms of AI systems in such a way
that inconvenient facts are hidden from the general public. The research
on setting censorship parameters in neural networks and AI services by
Ermoshina (2023) is an example of this

5 Citizenship, Censorship, and Democracy in the Age …

65

type of manipulation. Another example of this type of manipulation can
be found in the Russian neural network Kandinsky 2.1, which returns
images of ﬂowers when given prompts of ‘war in Ukraine’, ‘Ukrainian
Flag’, or even just the word ‘Ukrainian’ whether entered in Russian or
English. This censorship is also present in the visual generative AI
services of other countries: Chinese ERNIE-ViLG, American DALL-E 2,
Stable Diffusion, Midjourney (Ermoshina, 2023).

13. AI misinformation. One of the biggest AI threats is disinformation
    and the potential of AI systems to generate massive amounts of
    propaganda. Dishonest groups can use these manipulations to incite
    hatred on a variety of grounds (e.g., racial, religious, etc.), to
    hurt people’s feelings, and to arouse anger and other unpleasant
    emotions. An example of such disinformation can be found in the
    recent blog post exposing AI-generated fake images of violence in
    Gaza and Israel (Gault, 2023).

One strategy for inﬂuencing public opinion and spreading misin-
formation or panic among populations is the creation and distri- bution
of fake videos using deepfake technology. Deepfake is an AI-based method
of generating fabricated images and videos by combining and
superimposing images or videos onto other images or videos out of
context (Sharma & Kaur, 2022). Often, this tech- nology is used to
discredit a person or for purposes of revenge. in Ukraine are examples
of Deepfake videos regarding the war attempts to sow panic among the
Ukrainian population with one example showing Ukrainian President
Volodymyr Zelensky issuing a fabricated statement calling for the end of
resistance to Russian aggressions (Rayon, 2022). Another recent example
of such manip- ulations is a deepfake of the Commander-in-Chief of the
Armed Forces of Ukraine, Valeriy Zaluzhny, calling for a coup d’état
against the President of Ukraine (Espreso, 2023). Other examples of
deep- fake manipulations include the creation of nude images of Spanish
schoolgirls highlighting an alarming trend among younger users. In this
particular instance, a group of mothers, refusing to tolerate such
exploitation, targeted not only the company responsible for creating the
images, but also appealed to educational authorities to

66

T. Matusevych et al.

highlight the severe impact such images can have on the affected
teenagers. The use of deepfakes poses a signiﬁcant challenge to the
epistemic trust undermining the reliability and importance of social
communication (Twomey et al., 2023).

Discussion

We have addressed in this chapter the different threats of AI in
relation to citizenship, democracy, and censorship. Part of the
challenges arising in the ethical use of AI in education require a
better understanding of AI fundamentals. The understanding of data
(i.e., collection and manage- ment), but also the way algorithms work,
is important for ensuring that teachers and learners can develop their
work from a critical thinking perspective.

AI, like any other tool, offers many opportunities, but also poses many
threats that require the consideration of human rights principles at the
earliest stages of its implementation. Educators should be aware of the
strengths and weaknesses of AI in education to empower their digital,
civic education practices. In particular, AI services and tools can be
used to design adaptive learning paths, recommend resources, and offer
scaf- folding and other forms of assistance (e.g., to assign different
levels of complexity, interaction, and differentiation). AI can also
support the gamiﬁcation of learning through the creation of engaging and
interac- tive scenarios, challenges, and simulations that promote
problem solving, critical thinking, creativity, collaboration, and
digital literacy or citizen- ship. Furthermore, AI-based ‘chatbots’ can
be developed for teachers and parents to support both the disciplinary
and transversal aspects of education.

While AI can pose risks to citizenship when lacking an accultura- tion
and regulation of its use, AI in education also provides advantages for
both educators and learners by allowing them to avoid routine work and
focus on creative tasks (Romero et al., 2021; Septiani et al., 2023).
AI, through machine and deep learning, can enrich education and
profoundly affect the interactions between teachers, students, and

5 Citizenship, Censorship, and Democracy in the Age …

67

independent and critical thinking through

citizens at large. In this way, AI in education can promote free
expression learning opportuni- and ties (Committee of Ministers Council
Europe, 2019; Richardson & Milovidov, 2019).

According to Fr˛ackiewicz (2023), the main areas of AI that can
contribute to the development of education for responsible citizenship
include: (i) developing the global dimension of responsible citizenship
through the promotion of intercultural understanding; (ii) facilitating
access to information and education; (iii) informed citizenship; (iv)
democratisation of education, making it more accessible to students; and
(v) the development of digital literacy skills. By developing digital
literacy, AI can help students become responsible consumers of informa-
tion and active participants in online discussions (Fr˛ackiewicz, 2023).

The potential of AI for improving or harming citizenship and educa- tion
will depend on the way citizens and governments decide to use and
regulate it. An acculturation to the fundamentals of AI is required for
each citizen to move beyond the role of mere ‘consumer’ of technology
while also developing a critical, yet creative, perspective on its
impact related to citizenship, well-being, education, and democracy.

References

Aguirre, A., Reiner, P. B., Surden, H., & Dempsey, G. (2021). AI loyalty
by design: A framework for governance of AI. In J. B. Bullock & others
(Eds.), The Oxford handbook of AI governance. Available at SSRN
Scholarly Paper 3930338. https://papers.ssrn.com/abstract=3930338

Alexandre, F., de Barretin, R., Becker, J., Comte, M.-H., Courbin, M.,
Cruchon, S., Lagarrigue, A., Masse, B., De Quatrebarbes, S., Stein, J.,
Terosier, C., & Vieville, T. (2020). Understanding intelligently
artiﬁcial intel- ligence: A citizens’ open formation. International
Workshop on Education in Artiﬁcial Intelligence K-12 (EDUAI-20).

Bailey, J. (2023, Серпень 8). AI in education. Education Next, 23(4),
28– 35.
https://www.educationnext.org/a-i-in-education-leap-into-new-era-mac
hine-intelligence-carries-risks-challenges-promises/

68

T. Matusevych et al.

Bamman, D., O’Connor, B., & Smith, N. (2012). Censorship and deletion
practices in Chinese social media. First Monday.
https://doi.org/10.5210/ fm.v17i3.3943

Bietti, E. (2020). From ethics washing to ethics bashing: A view on tech
ethics from within moral philosophy. In Proceedings of the 2020
conference on fairness, accountability, and transparency (pp. 210–219).
Association for Computing Machinery.
https://doi.org/10.1145/3351095.3372860

Blanchard, E. G. (2015). Socio-cultural imbalances in AIED research:
Inves- tigations, implications and opportunities. International Journal
of Artiﬁcial Intelligence in Education, 25 (2), 204–228.
https://doi.org/10.1007/s40593- 014-0027-7

Borenstein, J., & Howard, A. (2021). Emerging challenges in AI and the
need for AI ethics education. AI and Ethics, 1(1), 61–65.
https://doi.org/10.1007/ s43681-020-00002-7

Calvo, D., Cano-Orón, L., & Abengozar, A. E. (2020). Materials and
assessment of literacy level for the recognition of social bots in
political misinformation contexts. ICONO 14, Revista de comunicación y
tecnologías emergentes, 18(2), 111–136.

Committee of Ministers Council Europe.

(2019). Recommendation CM/ Rec(2019)10 of the Committee of Ministers to
member States on developing and promoting digital citizenship education.
https://rm.coe.int/090000168 098de08

Dilhac, M. A., Christophe, A., & Lehoux, P. (2018). La Déclaration de
Montréal IA responsable.
https://declarationmontreal-iaresponsable.com/la- declaration/

Ermoshina, K. (2023, Червень 15). Украина, протесты и сексизм. Ксения
Ермошина—О цензуре в нейросетях (Ukraine, protests and sexism. Ksenia
Yermoshina—On censorship in neural networks). Теплица социальных
технологий. https://te-st.org/2023/06/15/ai-censorship/ Ermoshina, K.,
Loveluck, B., & Musiani, F. (2022). A market of black boxes: The
political economy of Internet surveillance and censorship in Russia.
Journal of Information Technology & Politics, 19 (1), 18–33.
https://doi.org/ 10.1080/19331681.2021.1905972

Espreso. (2023, Листопад 7). Мережею шириться діпфейк із нібито Залужним
і закликом до збройного повстання (Dipfake with allegedly Zaluzhnyi and
a call for armed rebellion spreads online) [News website]. Espreso.
https://espreso.tv/merezheyu-shiritsya-dipfeyk-iz-nibito-zaluzhnim-
i-zaklikom-do-zbroynogo-povstannya

5 Citizenship, Censorship, and Democracy in the Age …

69

European Parliament. (2023, August 6). EU AI Act: First regulation on
artiﬁ- cial intelligence.
https://www.europarl.europa.eu/news/en/headlines/society/
20230601STO93804/eu-ai-act-ﬁrst-regulation-on-artiﬁcial-intelligence

Faruque, M. U. (2022). AI versus human consciousness: A

future with machines as our masters? Renovatio: The Journal of Zaytuna
College. https://
renovatio.zaytuna.edu/article/ai-versus-human-consciousness

Filgueiras, F. (2022). The politics of AI: Democracy and
authoritarianism in developing countries. Journal of Information
Technology & Politics, 19 (4), 449–464.
https://doi.org/10.1080/19331681.2021.2016543

Floridi, L., Cowls, J., King, T. C., & Taddeo, M. (2020). How to design
AI for social good: Seven essential factors. Science and Engineering
Ethics, 26 (3), 1771–1796. https://doi.org/10.1007/s11948-020-00213-5

Fr˛ackiewicz, M. (2023, May 4). The role of AI in fostering global
citizen- ship education. TS2 SPACE.
https://ts2.space/en/the-role-of-ai-in-fostering-
global-citizenship-education/

Gault, M. (2023, November 7). Adobe Is selling AI-generated images of
violence in Gaza and Israel . Vice.
https://www.vice.com/en/article/3akj3k/adobe-is-
selling-fake-ai-generated-images-of-violence-in-gaza-and-israel

Hager, G. D., Drobnis, A., Fang, F., Ghani, R., Greenwald, A., Lyons,
T., Parkes, D. C., Schultz, J., Saria, S., Smith, S. F., & Tambe, M.
(2019). Artiﬁcial intelligence for social good (arXiv:1901.05406).
arXiv. https://doi. org/10.48550/arXiv.1901.05406

Holmes, W., Persson, J., Chounta, I.-A., Wasson, B., & Dimitrova, V.
(2022). Artiﬁcial intelligence and education: A critical view through
the lens of human rights, democracy and the rule of law. Council of
Europe.

Jobin, A., Ienca, M., & Vayena, E. (2019). The global landscape of AI
ethics guidelines. Nature Machine Intelligence, 1(9), 389–399.
https://doi.org/10. 1038/s42256-019-0088-2

Manyika, J., & Silberg, J. (2019, June). Notes from the AI frontier:
Tackling bias in AI (and in humans). Multidisciplinary symposium on
ethics in AI hosted by DeepMind Ethics and Society.
https://www.mckinsey.com/~/media/
McKinsey/Featured%20Insights/Artiﬁcial%20Intelligence/Tackling%20b
ias%20in%20artiﬁcial%20intelligence%20and%20in%20humans/MGI-
Tackling-bias-in-AI-June-2019.pdf

Nikoli´c, K., & Joviˇci´c, J. (2023, April 3). Reproducing inequality:
How AI image generators show biases against women in STEM. UNDP.
https://
www.undp.org/serbia/blog/reproducing-inequality-how-ai-image-genera
tors-show-biases-against-women-stem

70

T. Matusevych et al.

OECD. (2021). OECD digital education outlook 2021: Pushing the frontiers
with artiﬁcial intelligence, blockchain and robots. Organisation for
Economic Co- operation and Development.
https://www.oecd-ilibrary.org/education/oecd-
digital-education-outlook-2021_589b283f-en

Pagallo, U., Ciani Sciolla, J., & Durante, M. (2022). The environmental
chal- lenges of AI in EU law: Lessons learned from the Artiﬁcial
Intelligence Act (AIA) with its drawbacks. Transforming Government:
People, Process and Policy, 16 (3), 359–376.
https://doi.org/10.1108/TG-07-2021-0121

Rayon.

(2022, Березень 17). Компанія Meta видалила діпфейк із Зеленським (Meta
deletes Zelenskyy’s diplomatic account). Rayon. https://
rayon.in.ua/news/498190-kompaniya-meta-vidalila-dipfeyk-iz-zelenskim
Richardson, J., & Milovidov, E. (2019). Digital citizenship education
handbook:

Being online, well-being online, rights online. Council of Europe.

Romero, M., Heiser, L., & Galindo, L. (2021). L’intelligence artiﬁcielle
en éducation, formation/acculturation et modélisation.
https://hal.science/hal-031 95064

Roselli, D., Matthews, J., & Talagala, N. (2019). Managing bias in AI .
Paper Presented at the Companion Proceedings of The 2019 World Wide Web
Conference, 539–544. https://doi.org/10.1145/3308560.3317590

Septiani, D. P., Kostakos, P., & Romero, M. (2023). Analysis of creative
engagement in AI tools in education based on the #PPai6 framework. In В
Z. Kubincová, F. Caruso, T. Kim, M. Ivanova, L. Lancia, & M. A.
Pellegrino (Eds.). Methodologies and intelligent systems for technology
enhanced learning, workshops—13th international conference (Vol. 769,
pp. 48–58). Springer. https://doi.org/10.1007/978-3-031-42134-1_5

Sharma, M., & Kaur, M. (2022). A review of deepfake technology: An
emerging AI threat. In В G. Ranganathan, X. Fernando, F. Shi, & Y. El
Allioui (Eds.), Soft computing for security applications (pp. 605–619).
Springer. https://doi.org/10.1007/978-981-16-5301-8_44

Twomey, J., Ching, D., Aylett, M. P., Quayle, M., Linehan, C., & Murphy,
G. (2023). Do deepfake videos undermine our epistemic trust? A thematic
anal- ysis of tweets that discuss deepfakes in the Russian invasion of
Ukraine. PLoS ONE, 18(10), e0291668.
https://doi.org/10.1371/journal.pone.0291668 van Maanen, G. (2022). AI
ethics, ethics washing, and the need to politicize data ethics. Digital
Society, 1(2). https://go.gale.com/ps/i.do?p=AONE&
sw=w&issn=27314669&v=2.1⁢=r&id=GALE%7CA712345544&sid=
googleScholar&linkaccess=abs

5 Citizenship, Censorship, and Democracy in the Age …

71

Yang, F. (2016). Rethinking China’s Internet censorship: The practice of
recording and the politics of visibility. New Media & Society, 18(7),
1364–1381. https://doi.org/10.1177/1461444814555951

Yang, S. J. H., Ogata, H., Matsui, T., & Chen, N.-S. (2021).
Human-centered artiﬁcial intelligence in education: Seeing the invisible
through the visible. Computers and Education: Artiﬁcial Intelligence, 2,
100008. https://doi.org/ 10.1016/j.caeai.2021.100008

is

licensed under

Open Access This chapter the Creative Commons Attribution 4.0
International License (http://creativecommons.org/ licenses/by/4.0/),
which permits use, sharing, adaptation, distribution and reproduction
long as you give appropriate credit to the original author(s) and the
source, provide a link to the Creative Commons license and indicate if
changes were made.

in any medium or format, as

terms of

the

The images or other third party material in this chapter are included in
the chapter’s Creative Commons license, unless indicated otherwise in a
credit line to the material. If material is not included in the
chapter’s Creative Commons license and your intended use is not
permitted by statutory regulation or exceeds the permitted use, you will
need to obtain permission directly from the copyright holder.


