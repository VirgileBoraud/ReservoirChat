The art of scaling up : a computational account on
action selection in basal ganglia
Bhargav Teja Nallapu, Bapi Raju Surampudi, Nicolas P. Rougier

To cite this version:

Bhargav Teja Nallapu, Bapi Raju Surampudi, Nicolas P. Rougier. The art of scaling up : a computa-
tional account on action selection in basal ganglia: [FULL Version]. IJCNN 2017 - International Joint
Conference on Neural Networks, May 2017, Anchorage, Alaska, United States. ￿hal-01534459￿

HAL Id: hal-01534459

https://inria.hal.science/hal-01534459

Submitted on 7 Jun 2017

HAL is a multi-disciplinary open access
archive for the deposit and dissemination of sci-
entific research documents, whether they are pub-
lished or not. The documents may come from
teaching and research institutions in France or
abroad, or from public or private research centers.

L’archive ouverte pluridisciplinaire HAL, est
destinée au dépôt et à la diffusion de documents
scientifiques de niveau recherche, publiés ou non,
émanant des établissements d’enseignement et de
recherche français ou étrangers, des laboratoires
publics ou privés.

The art of scaling up : a computational account on
action selection in basal ganglia

Bhargav Teja Nallapu∗‡, Bapi Raju Surampudi∗†, Nicolas P. Rougier‡§¶
∗International Institute of Information Technology, Hyderabad
†School of Computer and Information Sciences, University of Hyderabad
‡Inria Bordeaux Sud-Ouest, Talence, France
§LaBRI, UMR 5800, CNRS, Bordeaux INP, Universit de Bordeaux, Talence, France
¶Institut des Maladies Neurodgnratives, UMR 5293, CNRS, Universit de Bordeaux, Bordeaux, France

Email : bhargav.teja-nallapu@inria.fr

Abstract—What makes a computational neuronal model ’large
scale’ ? Is it the number of neurons modeled? Or the number
of brain regions modeled in a network? Most of the higher
cognitive processes span across co-ordinated activity in a network
of different brain areas. However at the same time, the basic
information transfer takes place at a single neuron level, together
with multiple other neurons. We explore modeling a neural
system involving some areas of cortex, the basal ganglia (BG)
and thalamus for the process of decision making, using a large-
scale neural engineering framework, Nengo. Early results tend
to replicate the known neural activity patterns as found in the
previous action selection model by Guthrie et al. 2013, besides
operating with a larger neuronal populations. The power of
converting algorithms to efﬁciently weighed neural networks in
Nengo (Stewart et al. 2009 and Bekolay et al. 2013) is exploited
in this work. Crucial aspects in a computational model, like
parameter tuning and detailed neural implementations, while
moving from a simplistic to large-scale model, are studied.

I. INTRODUCTION

Action selection is one of the most vital processes for the

survival of an organism.

The very importance of the process of action selection (and
learning from it) in the survival of an organism, pushes for
a need of understanding the process from an evolutionary,
biological and physiological point of view.

Brain works by running complex dynamics forming com-
plex connections within itself, speciﬁc to each behavioral
repertoire. It is at the level of few (or many) neurons that
the information transfer takes place, which drives all
the
processes like perception, memory, decision making, language
or any other brain process. Ideally, it is that level of detail
one wants to model any sub-system of brain or the whole
model of brain itself. Because of the practical limitations like
lack of detailed experimental data, computational challenges
in studying the existing data forces major modeling efforts
to employ simplistic neuron models and smaller population
representations.

It is a positive sign that despite these limitations, large scale
models still manage to emerge, if not at a full-human scale,
but at least at a scale of a rodent’s brain. A recent work in [4]
proposes a thalamo-cortical network model of BG to reproduce
Parkinsonian tremor. Quite interestingly, the model consists of

four neuron types in all the subareas, modeled at the full spatial
size and neuron numbers of the rat. However, depending on
the functional dynamics one tries to model like in [5], [1],
often simpler neuron (rate) models are employed to keep
the computations easier and emphasize more on the network
dynamics than on the detail of neuronal implementations.

We considered one of our previous works on a compu-
tational study of decision making and its dynamics using a
thalamo-cortical BG network [6] inspired by [1] and replicated
in [7]. It is a framework on the top of an optimal decision
making model, accommodating representations of varying vi-
sual salience and delayed presentation of the stimuli, studying
their effect on optimal decision making. The framework uses
known network dynamics as in [1] and the model exhibits
similar characteristics as compared to experimental work de-
scribed in [8]. The framework is indeed robust to study the
other factors mentioned, that affect optimal decision making
- such as stimuli properties, presentation delays and different
associations of reward in learning. Aforementioned model is
still quite simplistic with as few as 72 neurons representing
all of the cortico-thalamic basal ganglia network, involved in
decision making. This is where we emphasize on modeling
the same functional networks at a large scale.

The simple model has been successfully expanded to a large
scale, both in terms of neuron populations and extending to
a variety of tasks that the BG are known to be involved
in. For example, we have attempted to build a similar large
scale model of BG also demonstrating an arm reaching a
target1 (based on the model described in [9]), besides the
reward based decision making. Scaling up involved exploring
various large scale neural modeling frameworks like DANA
[10] and NEF2 (Nengo). The model is scaled using DANA to
as many as 66,000 neurons. With the large scale model, the
functional properties and neural activity patterns have been
found to be consistent with the simplistic model. Using the
large scale neural modeling platform, Nengo, also yielded the
same dynamics of the simplistic model but now the model

1https://www.youtube.com/watch?v=oIHfDabVqcg
2Neural Engineering Framework - http://nengo.ca/

is expanded to a massive scale of 300K neurons. The power
of converting existing models to efﬁciently weighed neural
networks in Nengo is exploited in this work. Additionally,
NEF accounts for various biologically realistic properties of
neurons which form the internal neural networks.

A. Task

II. METHODS

The task used in this work is a probabilistic learning task
that was described in [8] and used in [1], [7], [6]. Four target
shapes are associated with different reward probabilities (see
ﬁgure 1). Each trial (an independent task turn), any two of the
four possible shapes are presented at two random positions
(out of the four cardinal positions - up, right, down and left).
By the end of trial period, a choice is made and the reward is
given according to the reward probability associated with the
chosen shape.

In a single independent trial, the cognitive decision (shape
of the cue) and motor decision (direction of position) are in-
dependent of each other. However, ideally, the motor decision
is expected to be in the direction of the cue shape that is
chosen. On subsequent reward association of the cue decision,
one should eventually select the direction in which the most
rewarding cue is present.

B. Model

In [5], authors demonstrated an action selection mechanism
in the cortico-basal ganglia loops based on a competition be-
tween the positive feedback, direct pathway through the stria-
tum and the negative feedback, hyper-direct pathway through
the sub-thalamic nucleus. In [1], authors investigated further
how multiple level action selection could be performed by the
basal ganglia, and the model has been extended in a manner
consistent with known anatomy and electro-physiology of the
basal ganglia in the monkey (see ﬁgure 2). This model allows a
bidirectional information ﬂow between loops such that during
early trials, a direction can be selected randomly, irrespective
of the cue positions. However, after repeated trials, the model
is able to consistently make the motor decision, only after
cognitive decision (indeed biased by the cognitive decision)
towards the position of the more rewarding cue shape.

To begin with, we reproduce the thalamo-cortical basal
ganglia network with similar characteristics as in [1]. On a
different note, this effort also reminds how a model needs to
be reproducible and less constrained on its parametric values.
In the new model, we could successfully demonstrate the
decision in a single trial. With dopamine modulated learning
in the cognitive channels between cortex and striatum, the
model reached a state where it consistently chooses the higher
rewarding stimulus. We also developed the model to serve as
a framework to accommodate several other complex scenarios
that are more likely to happen in real life decision making.

The model in its simplest form is based on few implicit
assumptions, which facilitate the demonstration of optimal
action selection. One of them being the cortico-striatal learning
only in the cognitive channel. That is, attributing reward only

to the shape of the cue chosen but not to the position it is
shown. Secondly, in all the experiment scenarios, both the
stimuli are presented simultaneously. Lastly, both the stimuli
are represented by same visual salience in the experimental
scenarios, which is an unlikely case with real-world choices.
The model has been extended so as to account such assump-
tions, providing a framework to study factors affecting optimal
decision making. However, to expand it to a larger scale, we
chose to base on its basic form so that the larger model would
provide better representations to challenge such assumptions.
One of the major limitations of the simple model, we pro-
pose, is the discrete representation of stimuli in the discussed
brain areas. In every structure (thoughout this paper, we refer
is modelled as structure), a single
each brain region that
neuron (in each of cognitive and motor channels) representing
each cue shape stands too simpliﬁed a representation and limits
us from analyzing cases with complex stimuli. In ﬁgure 3a, an
ambiguous shape is shown, which resembles two of the known
shapes but still uncertain to identify. Figure 3b shows a famil-
iar shape but with added noise that makes it difﬁcult to identify
as a known shape. It is not just difﬁcult, but impossible to
represent such complex stimuli in the simple and basic model.
Thus we begin to expand the model to a scale that is sufﬁcient
to provide more biologically plausible stimuli representations,
thus demonstrating action selection. Subsequently, the large
scale model poses new testable hypothesis in the context of
stimuli representation.

III. LARGE SCALE MODEL

With the idea of scaling up the model and to have a larger
population of neurons representing the stimuli, we decided to
implement the model with discussed dynamics using DANA
and Cython [11] individually and then scaled up the number of
neurons representing the cue shape inputs in important areas
of cortex and striatum. DANA provides very intuitive way of
modeling neural networks by using structures called Groups -
to represent neuron groups and connections - various type of
connectivities between the groups. It internally uses modiﬁed
NumPy [12] structured arrays made suitable for intensive
computations in the group ﬁelds, by making them a contiguous
block of memory.

In the simplistic model, in a regular structure (excluding the
associative structure), there is one neuron representing each
stimulus (stimulus - cue shape in a cognitive channel, cue
position in a motor channel) and an associative structure has a
2D array of neurons where number of rows and columns both
equal to the number of stimuli. Within each structure, each
neuron (in each channel of any loop) represents the average
activity of a small population and is modeled as a single rate
neuron with the equation:

τ

dm
dt

= −m + Is + IExt − T

(1)

decay time constant of the synaptic input τ and threshold
of the neuron T are set to respective constant values. m is the
output of the neuron. Is is the synaptic current. IExt is an

Fig. 1. The two armed bandit task as described in [8], [1].

Fig. 2. Architecture of BG model from [1].

Fig. 4.
(i) A motor structure with 4N neurons, with each N neurons
representing a motor stimulus (cue position). A cognitive channel also has
similar structure. (ii) An associative structure with 4Nx4N (16x16 in this
case) neurons. All the columns of neurons represent 4 motor stimuli equally
and all rows represent the 4 cognitive stimuli.

stimuli affect the dynamics of decision making. This com-
plex and varying representation of stimuli is what we want
to emphasize while beginning to working on a large scale
model. Few examples can be seen in ﬁgure 5, where different
possibilities of stimuli are represented. This kind of encoding
also could address the complex stimuli presented in ﬁgure 3.
Between such structures, the connectivity is based on the
assumption that the neurons in both the structures correspond
to particular stimuli (shape or position) and only those sub-
groups of neurons are connected in the respective structures.
It might be biologically implausible to assume such a distinct
connectivity between the structures but it provides a good
understanding of expanding this kind of model from simplis-
tic implementations to complex highly populated networks.
Using the above described structures and connections, a large
computational model is developed, which exhibits the intrinsic
functional properties of the simpler model mentioned. The type
of connections, few corresponding to those between cortex and
striatum, are listed in table II.

The model is large in terms of signiﬁcantly higher number
of neurons in each structure. Cortex particularly has larger
population than the other structures. The population numbers
of structures are listed in table III. Higher population in cortex

(a)

(b)

Fig. 3. Stimuli with added complexities (a) An ambiguous shape which
resembles two of the known shapes (b) A noisy shape which looks familiar
but not certainly known.

external input representing the sensory visual salience of the
stimulus, is considered as the input to cortex in the model and
it is a ﬁxed magnitude to the single neuron representing that
stimulus. The values of τ and T used are shown in Table I

In the expanded version, a population of neurons together
represents all the stimuli. To begin with, we have a clear
distinction in such population that each stimulus is represented
by a subgroup of neurons and each subgroup with equal
number of neurons. For example, in a cognitive channel of a
structure, a population of 4N neurons (N>1) for 4 cue shapes,
a subgroup of N neighboring neurons represent each cue shape
(see ﬁgure 4). As for the synaptic input (Iext in equation 1),
a Gaussian input at the center of the subgroup for a particular
cue shape is given.

It is also interesting to explore how the changes in such

Trial startCue presentationGo signalDecisionRewardTrial stop0.5s - 1.5s1.0s - 1.5s1.0s - 1.5sTimeP = 1.00P = 0.66P = 0.33P = 0.00Reward probabilitiesExternal currentExternal currentSOURCETARGETEXCITATORYINHIBITORYEXTERNALSTNmotorSTNcognitiveCortexmotorCortexassociativeCortexcognitiveStriatummotorStriatumassociativeStriatumcognitiveGPimotorGPicognitiveThalamusmotorThalamuscognitiveExternal currentStructure
Cortex
Striatum
Globus Pallidus interna (GPi)
Subthalamic Nucleus (STN)
Thalamus

Threshold(T)
-3
0
10
-10
-40

Decay (τ )
10
10
10
10
10

TABLE I
PARAMETERS IN EACH STRUCTURE

Connection
One to One
One to One
Associative to Associative
Cognitive to Associative
Motor to Associative

Source
cognitive cortex
motor cortex
associative cortex
cognitive cortex
motor cortex

Target
cognitive striatum
motor striatum
associative striatum
associative striatum
associative striatum

TABLE II
CONNECTIONS BETWEEN STRUCTURES

expanding. This is one of the key characteristics a model
should have, when scaled up.

The model is also run for a session of 120 trials, with
cortico-striatal
learning. Although the time taken for the
completion of session is long (around 40 minutes, whereas
the simpler models run in few seconds), model reached a
performance over 90%. Owing to this computational expense,
it was not easy to run the model for 250 simulations to
generate a mean performance over each of the 120 trials of all
250 sessions. The key challenge in computation lies with the
structures like associative cortex, which is a 2D representation.
Since the connections involving associative cortex are like the
ones described in ﬁgure 6, the weight matrices between the
structures span up to a scale of over thousands of rows and
columns, which inevitably makes the computation expensive.

allows complex stimulus representations. In the simpler model,
the synaptic input corresponding to a stimulus is represented in
the cortical structures as external current of ﬁxed magnitude
of 7 spike(sp)/s to the neuron representing that stimulus. In
case of larger populations, for each stimulus, a Gaussian input
(of mean magnitude of 14 sp/s and variance spreading over
the subgroup of the cortical structure) is provided.

Fig. 5. Stimulus in the form of a Gaussian input over a subgroup of neurons
and various scenarios of input representations. The inputs shown here are only
to demonstrate the differences in their mean or variance, or in the timing (see
Difference in timing), irrespective of any scale.

For instance, if the cortex has 1024 neurons, 256 neurons
for each stimulus, and to activate a particular stimulus, a
Gaussian input spreading over these 256 neurons, is given at
the beginning of the trial. The mean cortical activity (over each
sub-population), when the model is run for an independent
trial, is found to be similar to that of simple model before

Structure

Cortex
Striatum
GPi
Thalamus
STN

cognitive
256
16
16
16
16

Channel
motor
256
16
16
16
16

associative
65536
256
-
-
-

Total

66048
288
32
32
32
66432 neurons

TABLE III
NO. OF NEURONS IN EACH STRUCTURE

Fig. 6. Neurons corresponding to each stimulus in both the structures are
connected. For a given stimulus (C0 , M0), each neuron in target is connected
to a block of neurons in source. For eg. neuron (0,0) in target is connected to
the block [(0,0,(0,1),(1,0),(1,1)] in source. Similarly all the neurons that are
connected are highlighted in colors.

This leaves an interesting question about the connection
weights between two highly but unequally populated (like cor-
tex and striatum). And to point out, even in this larger model,
each neuron remains to be a mere computational unit, without
accounting for any other of the biological neuron properties
(spiking or population coded etc). Hence, we move further
exploring another large scale neural modeling framework,
Nengo which appears to solve this problem by effectively
computing some local weights within a sub-population of
neurons while providing ready-to-use spiking neurons to build
the structures.

IV. THE NEF, NENGO AND RESULTS

The underlying principles of NEF are: representation, trans-
formation and dynamics. The activity of a group of neurons
is considered to be best represented by encoding of some
underlying variable, e.g., any vector generally of smaller
dimensionality. The transformation of information from one
neural group to the other neural group. i.e., the neural group

Stimulus AStimulus BTheoretical ideal caseStimulus AStimulus BDifference in saliencyStimulus AStimulus BDifference in population codingStimulus AStimulus BDifference in timingrepresenting x can be connected to other group of neurons
representing a variable y, such that y = f (x).

in the model dynamics that the position corresponding to the
chosen shape only will be selected.

Any desired function can be approximated with improved
accuracy by increasing the number of neurons. The dynamics
of NEF allows us to build recurrent neural networks. These
networks can compute the time evolution of a given variable
x of the form dx
dt = f (x, u) for any control variable u. In a
connection between two neurons, as the activity in the pre-
synaptic neuron changes over time, x(t), the value actually
represented in the post-synaptic neuron over time will be
f(x(t)) × h(t), where h(t) represents the post-synaptic activity
(e.g, h(t)=e−t/τ , for t>0 with a time constant τ ).

The structures involved are modeled as neuron ensembles,
collection of several thousands of neurons. The basic pattern
of connectivities are retained as listed in table II. When
neuron ensembles in two different structures are connected,
the individual spiking activity of each neuron is taken into
account and a resultant activity of the ensemble is calculated.
It is this resultant activity which is provided as the synaptic
input to the target structure. This is a striking advantage in
using Nengo. The individual neuron works on the basis of
chosen neural dynamics, while the network dynamics can be
modeled as required.

There is an array of neuron ensembles representing each
stimulus and corresponding arrays are connected between
structures. The effective activity of each of these arrays is
taken as the resultant activity for the stimulus the ensemble
array represents. Figure 8 displays a case where shape 0 is
shown at position 3 and shape 1 is shown at position 2. Since
shape 1 has higher synaptic weight, it should be chosen over
shape 0. It can be seen that shape 1 is selected (label 1 - green
in CTX COG). Subsequently, for the motor decision, position
2 is selected (label 2 - orange in CTX MOT).

For the models claiming to have network-induced dynamics,
the choice of the neuronal dynamics should not make a
signiﬁcant difference. This has been demonstrated clearly
in this work. The model developed is tested under similar
conditions of action selection task, switching between direct
computations and neural implementations like Sigmoidal and
Integrate & Fire (IF). To start with, we used simple neurons
that directly compute a function. Then the neurons are changed
to detailed implementations, but to a lower scale. However,
the switch between neuron implementations involved minimal
tuning of parameters of the network as well as optimization
of few framework parameters, provided there is computational
power to handle the large scale of spiking or IF neurons.

Fig. 7. BG network model implemented in nengo

Fig. 8. For the combinations of cue shape and position, the best rewarding
cue shape is selected (see CTX COG) and the corresponding position (as per
stim cog and stim mot represent shape 0 is shown at position 3 and shape
1 is shown at position 2). It can be seen that, at a point later than choosing
shape, corresponding position is chosen (see CTX MOT). Inset The decision
in the original simplistic model

The following simulations assume cue shapes are repre-
sented by [0, 1, 2, 3] in the cognitive channel of the cortex and
the cardinal directions, where the shapes could be presented,
are also represented by [0, 1, 2, 3] in the motor channel of
the cortex. The cue shapes have a rewarding probability in the
order 1>0>2>3. The synaptic weights that were learned in
the previous model are applied. To ensure the optimal action is
selected in a generic manner, we exchanged the weights of the
ﬁrst (0) and the second (1) stimuli. These weights ensure that
the highest rewarding cue is always selected. It is also implicit

V. DISCUSSION
Although the population numbers in this work are com-
parable to that of experimental numbers of a rat’s BG and
some recent modeling work by Moren et al. 2015 [4] (see
table IV), we are still far away from the scale of that of
humans’ (150K in rats where as 2.2 million neurons, only
the globus pallidus and sub-thalamic nucleus combined [13]).
As for results, the neural activity corresponding to synaptic
weight-driven decision making and the ideal choice as per
high reward, were consistent. We also believe, at a full range

simulations on the model, performance would match that from
the previous simplistic model. In future, such a functional large
scale network could become readily usable in other functional
processes involving motor reaching or motor learning [14],
modeling deﬁcits in neuro-degenerative disorders such as
Parkinsonianism [15] etc.

One pertinent question that arises is about the usefulness
of a larger network, if the same qualitative behavior could be
realized in a simpler, smaller network. In addition to being able
to replicate the basic features of experimental observations as
in the case of simple model, a large scale model is expected to
provide additional advantages. Some of the advantages are: the
ﬂexibility to cope with sophisticated stimulus representations
as opposed to simplistic ones; the degree of match with the
details of known anatomical features, that is, the feasibil-
ity of a more biologically plausible architecture; and more
importantly the ability to cope with insults / injuries to the
system without degradation in performance, that is, graceful
degradation. These additional beneﬁts make it more appealing
to try and scale up a simpler architecture. But when is a model
sufﬁciently large? A model does not need to be as large as it
can get but could be just large enough to answer questions like
how do we conclude from the activity of a group of neurons
that a stimulus is chosen? and how do we compare a weakly
activated stimulus to a strongly activated one?

Model
Simplistic model [1]
Model implemented
Full-scale rat model [4]

Cortical level
24
24000
180K

Total
72
387,200
3 million

TABLE IV
NO. OF NEURONS ACROSS MODELS

VI. CONCLUSION

In a model, when it comes to designing structures with
bigger populations, it is quite challenging to come-up with
appropriate connectivities among these structures. Assuming
that an ideal large scale model takes the realistic neuronal
population ratios between structures (like a rat cortex having
considerably large populations than that in its striatum, as
suggested by experimental data [16]), the connectivity patterns
are difﬁcult to assume and hence compute. In this research, an
attempt was made by using some simple many-to-one connec-
tions in different sparsities. Using a sophisticated framework
like Nengo provides beneﬁt of taking care of internal compu-
tations among such sub-populations to propagate the resultant
population activity through the inter-structural connections.

A general observation is that in neuroscience, there have
been very few general principles governing systems. Also
quite often, computational models are very rigid in terms of
their speciﬁcations like having to specify range of values for
various parameters, etc. Hence one should try to identify some
generic characteristics of the structures involved in a fool-
proof manner, making them independent of the model details
or the range of parameters used. This means model should be
able to represent multiple scenarios over a range of parameters

used. In this work using Nengo, such conﬁgurations have
been explored. Figure 7 displays how certain parameters
can be isolated from the model to better tune them. Many
key parameters involving reward-prediction errors, dopamine
modulation etc, could be observed independently.

The framework provides various types of neuronal imple-
mentations in-built, allowing conﬁguration of different neuron
models in different structures easily. Because of the optimal
weights computation within the neuron ensembles in Nengo,
inter-structural connections carry network level dynamics in a
very reasonable way.

The large scale models described here, could be extended to
model the formation habits, expanding structures like cortex. It
has been suggested that associative striatum plays a crucial role
in goal-directed actions, contrary to sensori-motor that is part
of the habitual system. New evidence suggests that automatic
behaviors, such as habits, are stored in cortex and that the role
of BG is to train cortex. In other words, BG learns quickly
via reinforcement learning to activate the correct postsynaptic
target in cortex, which leads to appropriate cortical Hebbian
learning ([17], [18]). More evidence supporting this idea is
provided by Piron et al. 2016 [19]. The scaled up cortex
could provide different structured representations individually
for stimulus representations, habitual learning etc, so that it
could make decisions independent of BG after the acquisition
of habits.

In most of the common tasks of action selection, identifying
whether a stimulus is the same or different from a previ-
ous one involves coordination between the incoming sensory
information and working memory [20]. Also, in one of the
cases discussed about complex stimuli, when all the choices
are not presented at once and new choices appear in the
middle of decision making, one needs to model a strategy
with which whether value computation of each choice is
re-computed. Thus the role of working memory in decision
making paradigms where the basal ganglia also play a crucial
role, should be studied.

Thus, a comprehensive network with all the structures mod-
eled, demonstrating optimal action selection, motor reaching
(in the lines of demonstration in [9]), habitual learning, could
be referred as true large scale model. Besides the mere high
population of neurons, ’large-scale’ should be with respect
to the number of structures involved, different responsibilities
each structure switches between and number of cognitive or
biological processes simulated. Also, from a uniﬁed research
perspective, when models of certain important pathways are
developed computationally and made available on frameworks
like Nengo, they are often reusable in the development of
higher functional models using those pathways. Our two cents
to reproducible science, brief pieces of code demonstrating
simple as well as discussed large scale models are made
public3. After all, science ought to be reproducible, replicable4
and extendable.

3https://github.com/cervere/basal-ganglia.git
4http://www.labri.fr/perso/nrougier/downloads/ReproducibleScience.pdf

[17] F. G. Ashby and J. M. Ennis, “The role of the basal ganglia in category
learning,” Psychology of Learning and Motivation, vol. 46, pp. 1–36,
2006.

[18] F. G. Ashby, B. O. Turner, and J. C. Horvitz, “Cortical and basal ganglia
contributions to habit learning and automaticity,” Trends in cognitive
sciences, vol. 14, no. 5, pp. 208–215, 2010.

[19] C. Piron, D. Kase, M. Topalidou, M. Goillandeau, H. Orignac, T.-
H. N’Guyen, N. Rougier, and T. Boraud, “The globus pallidus pars
interna in goal-oriented and routine behaviors: Resolving a long-standing
paradox,” Movement Disorders, 2016.

[20] A. Pooresmaeili, D. R. Bach, and R. J. Dolan, “The effect of visual
salience on memory-based choices,” Journal of neurophysiology, vol.
111, no. 3, pp. 481–487, 2014.

VII. ACKNOWLEDGEMENTS

The authors would like to acknowledge the following grants

which have been a major support to this research.

• Indo-French CEFIPRA Grant for the project Basal Gan-
glia at Large (No. DST-INRIA 2013-02/Basal Ganglia
dated 13-09-2014)

• Internships programme at INRIA, 6 month Internship
with Team Mnemosyne at INRIA Bordeaux - Sud-Ouest
• Travel Support by Nengo 3rd annual Summer School on
large-scale brain modeling, University of Waterloo, ON,
Canada, 5th June, 2016 - 17th June, 2016

REFERENCES

[1] M. Guthrie, A. Leblois, A. Garenne, and T. Boraud, “Interaction between
cognitive and motor cortico-basal ganglia loops during decision making:
a computational study,” Journal of neurophysiology, vol. 109, no. 12,
2013.

[2] T. C. Stewart, B. Tripp, and C. Eliasmith, “Python scripting in the nengo

simulator,” 2009.

[3] T. Bekolay, J. Bergstra, E. Hunsberger, T. DeWolf, T. C. Stewart,
D. Rasmussen, X. Choo, A. R. Voelker, and C. Eliasmith, “Nengo: a
python tool for building large-scale functional brain models,” Frontiers
in neuroinformatics, vol. 7, 2013.

[4] J. Moren, J. Igarashi, J. Yoshimoto, and K. Doya, “A full rat-scale
model of the basal ganglia and thalamocortical network to reproduce
parkinsonian tremor,” BMC Neuroscience, vol. 16, no. 1, p. 1, 2015.
[5] A. Leblois, T. Boraud, W. Meissner, H. Bergman, and D. Hansel,
“Competition between feedback loops underlies normal and pathological
dynamics in the basal ganglia,” Journal of Neurosciences, vol. 26, pp.
3567–3583, 2006.

[6] B. T. Nallapu and N. P. Rougier, “Dynamics of reward based decision
making a computational study,” in International Conference on Artiﬁcial
Neural Networks, 2016.

[7] M. Topalidou and N. Rougier, “[re] interaction between cognitive and
motor cortico-basal ganglia loops during decision making: a computa-
tional study,” ReScience, vol. 1, no. 1, 2015.

[8] B. Pasquereau, A. Nadjar, D. Arkadir, E. Bezard, M. Goillandeau,
B. Bioulac, C. E. Gross, and T. Boraud, “Shaping of Motor Responses by
Incentive Values through the Basal Ganglia,” Journal of Neuroscience,
vol. 27, no. 5, 2007.

[9] S. R. C. Vignesh Muralidharan, “A scalable cortico-basal ganglia model
to understand the neural dynamics of targeted reaching,” Computational
Neuro Science, 2016.

[10] N. P. Rougier and J. Fix, “Dana: Distributed numerical and
adaptive modelling framework,” Network: Computation in Neural
Systems, vol. 23, no. 4, pp. 237–253, 2012.
[Online]. Available:
http://www.tandfonline.com/doi/full/10.3109/0954898X.2012.721573

[11] S. Behnel, R. Bradshaw, C. Citro, L. Dalcin, D. S. Seljebotn, and
K. Smith, “Cython: The best of both worlds,” Computing in Science
& Engineering, vol. 13, no. 2, pp. 31–39, 2011.

[12] S. Van Der Walt, S. C. Colbert, and G. Varoquaux, “The numpy array:
a structure for efﬁcient numerical computation,” Computing in Science
& Engineering, vol. 13, no. 2, pp. 22–30, 2011.

[13] C. D. Hardman, J. M. Henderson, D. I. Finkelstein, M. K. Horne,
G. Paxinos, and G. M. Halliday, “Comparison of the basal ganglia in
rats, marmosets, macaques, baboons, and humans: volume and neuronal
number for the output, internal relay, and striatal modulating nuclei,”
Journal of Comparative Neurology, vol. 445, no. 3, pp. 238–255, 2002.
[14] K. Magdoom, D. Subramanian, V. S. Chakravarthy, B. Ravindran, S.-
i. Amari, and N. Meenakshisundaram, “Modeling basal ganglia for
understanding parkinsonian reaching movements,” Neural Computation,
vol. 23, no. 2, pp. 477–516, 2011.

[15] V. Muralidharan, P. P. Balasubramani, V. S. Chakravarthy, S. J. Lewis,
and A. A. Moustafa, “A computational model of altered gait patterns in
parkinsons disease patients negotiating narrow doorways,” Frontiers in
computational neuroscience, vol. 7, 2015.

[16] G. Paxinos, The Rat Nervous System. Gulf Professional Publishing,

2004.

