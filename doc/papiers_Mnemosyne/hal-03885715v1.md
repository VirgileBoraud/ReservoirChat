The Opportunistic PFC: Downstream Modulation of a
Hippocampus-inspired Network is Optimal for
Contextual Memory Recall
Hugo Chateau-Laurent, Frédéric Alexandre

To cite this version:

Hugo Chateau-Laurent, Frédéric Alexandre. The Opportunistic PFC: Downstream Modulation of a
Hippocampus-inspired Network is Optimal for Contextual Memory Recall. 36th Conference on Neural
Information Processing System, Dec 2022, New Orleans, United States. ￿hal-03885715￿

HAL Id: hal-03885715

https://hal.science/hal-03885715

Submitted on 6 Dec 2022

HAL is a multi-disciplinary open access
archive for the deposit and dissemination of sci-
entific research documents, whether they are pub-
lished or not. The documents may come from
teaching and research institutions in France or
abroad, or from public or private research centers.

L’archive ouverte pluridisciplinaire HAL, est
destinée au dépôt et à la diffusion de documents
scientifiques de niveau recherche, publiés ou non,
émanant des établissements d’enseignement et de
recherche français ou étrangers, des laboratoires
publics ou privés.

The Opportunistic PFC: Downstream Modulation of a
Hippocampus-inspired Network is Optimal for
Contextual Memory Recall

Hugo Chateau-Laurent1,2,3

Frédéric Alexandre1,2,3

1Inria centre at the university of Bordeaux, France
2Institute of Neurodegenerative Diseases, Bordeaux, France
3LaBRI, Université de Bordeaux, France
{hugo.chateau-laurent,frederic.alexandre}@inria.fr

Abstract

Episodic memory serves as a store of individual experiences and allows for flexible
adaptation to environment volatility and goal changes. The selection of episodic
memories to recall is often considered to be driven by external sensory cues. Ex-
perimental studies suggest that this process is also influenced by internal cues,
and that projections from the medial prefrontal cortex to the hippocampus play
a role in this contextual modulation. In order to make sense of the biological
configuration of prefrontal-to-hippocampus connectivity, we investigate the effec-
tiveness of modulating various layers of a hippocampus-inspired neural network in
a contextual memory task. Our results reveal that providing context information
to the most downstream regions (i.e.
last layers) of the model leads to better
performance. In addition, the best average performance is obtained when contex-
tual connections target the regions corresponding to the biological subfields that
receive information from the prefrontal cortex, which provides a normative account
of the biological connectivity. We relate this work to the need for augmenting
reinforcement learning with flexible episodic memory. We make the code available
at https://github.com/HugoChateauLaurent/opportunistic-PFC.

1

Introduction

Episodic memory is our ability to store and recall memories along with their spatiotemporal context of
acquisition. Information about what, when and where events happened in the past can be retrieved and
used to make decisions in the present. This cognitive function contrasts with the formation of semantic
memories which are decontextualized and cached for efficient use [6]. While heavy inspiration has
been drawn from semantic memory to develop deep learning algorithms, artificial agents most often
lack episodic memory, and more generally explicit memory, despite their forecasted potential to
improve sample efficiency and flexibility [7, 15, 19]. In order to guide behavior efficiently, recalled
memories should be relevant to the current situation. More precisely, the memory selection process
should be influenced by both contextual and sensory information. In contrast to the information that
is directly accessible to the agent through its perception of the environment, contextual information
encompasses any internal representation that is not directly perceptible, but is susceptible to help the
agent predict future rewards and states. This includes information about the temporal unfolding of
events, spatial integration, but also the goals pursued by the agent. Numerous studies have shown
the influence of temporal (e.g. [13, 31, 17]), spatial (e.g. [11, 21, 22]), semantic (also investigated in
[11]), and goal [1] factors on episodic memory.

36th Conference on Neural Information Processing Systems (NeurIPS 2022).

The most influential theory of stimulus-driven memory recall states that the hippocampus is able to
perform pattern completion on partial and noisy cues by implementing attractor dynamics through
recurrent connections in area CA3 [27] (but see [8] for an alternative account in which CA1 performs
pattern completion and CA3 learns sequences). With this process, memories to be recalled are those
that share similarities with current sensory observations, or in other words, those with the closest
attractor. Interestingly, stimulus-driven episodic recall has been implemented in a Neural Episodic
Control architecture [24] and shown to improve sample efficiency of classical deep reinforcement
learning algorithms. In this study, a Differentiable Neural Dictionary was used to store episodes
while the network was playing Atari games, and similarity with the situation faced by the agent was
used as a criterion for selecting episodes to recall.

While stimulus-driven retrieval has been studied both empirically and theoretically, much less is
known about the contextual modulation of episodic recall. We believe that a better comprehension of
the mechanisms involved is necessary to develop a complete theory of episodic memory, but also to
develop machine learning algorithms that can comprehend a wider variety of spatiotemporal contexts
and direct their behavior towards internal goals. More precisely, synergy between episodic memory
and contextual control could yield significant improvements over algorithms that use context alone
(e.g. [29, 5, 14, 25, 4]) in terms of sample and parameter efficiency. It is worth noting that Neural
Episodic Control [24] was later extended to include a LSTM-based working memory which arguably
represents some sort of contextual information and influences episodic recall [12]. Other related
works include model-based episodic learning [18], episodic meta learning [20, 26], separate retrieval
mechanisms [16], and so on. Yet, this line of machine learning research is largely disconnected from
the biology.

Experiments suggest that the prefrontal cortex (PFC) and prefrontal-hippocampal interactions play
an important role in this function [2, 10, 17, 21, 22]. In comparison with sensory cortices, PFC
is connected to the hippocampus through many pathways (see [10] for a review). Just as sensory
information, information represented in PFC reaches the hippocampus through superficial layers
of the entorhinal cortex (EC). PFC also directly projects to deeper layers of the EC. In addition,
PFC is connected to the dentate gyrus and CA1 through the supramammillary and reuniens nuclei
respectively. Strikingly, there seems to be no pathway connecting PFC and CA3 [3].

In a modeling study similar to ours [23], contextual information was fed to the dentate gyrus to
modulate recall, but other prefrontal-to-hippocampus pathways were not considered. Here, we address
the question of why PFC targets the hippocampus the way it does, by investigating the effectiveness
of potential PFC-hippocampus configurations in a neural network performing a contextual memory
task. First, we evaluate the added benefit of providing context at intermediate layers of the network
over providing it to the input layer along sensory observations. Second, we test the hypothesis that
more downstream modulations (targeting CA1 and the output portion of EC) are more efficient.

2 Methods

2.1 Task

Like the model of [23], our model performed the rodent task described in [21, 22]. Eight object-
discrimination problems presented in two different contexts were used to evaluate context-guided
memory recall. In a given task ti(i = 1, ..., 8) and context c, the network learned to choose a rewarded
object Ri,c over a non-rewarded object ¯Ri,c. In the alternative context c′, it learned to choose between
the same objects as in context c, except that the non-rewarded object in context c was rewarded in c′,
and conversely (i.e. ¯Rc
i ). As in [23], objects were represented in the network
as 6 × 4 matrices with 6 active entries of value 1 placed at random locations, and other entries with
value 0 (fig. 1, table 1).

i and Rc

i = Rc′

i = ¯Rc′

2.2 Model

The hippocampus model is a 6-layered fully-connected neural network which follows the anatomy of
the biological medial temporal lobe. Information flow corresponds to the trisynaptic pathway: Input
−→ ECin −→ DG −→ CA3 −→ CA1 −→ ECout −→ Output. The number of neurons in each region is set
as the number of neurons in the analog rat region, as retrieved from [9], scaled down by a factor N
(see table 2). The network input consists of three pattern slots: two for the objects to choose between

2

Table 2: Network summary.

Table 1: Input summary. The “Objects" input size
corresponds to the product of the number, width
and height of input patterns.

Input

Size

Context
Objects

2
3 × 6 × 4

Layer

ECin
DG
CA3
CA1
ECout
Output

Function

Output size
1.1 × 105N ReLU
12 × 105N ReLU
2.5 × 105N ReLU
3.9 × 105N ReLU
3.3 × 105N ReLU
3 × 6 × 4

sigmoid

and one for the rewarded object (table 1). The assignment of Rc
i to the first or second slot
is random. ReLU was used as the activation function of hidden layers and sigmoid was used in the
output layer to map latent activity back to the pattern space (table 2). An additional input was used to
modulate different layers of the hippocampal network contextually. It represents the two possible
contexts as a 2D one-hot vector. Note that the output layer was never modulated, since it does not
model a medial temporal lobe region. CA3 was recurrently connected to store memories. We used
the following hebbian rule to update its recurrent weights:

i and ¯Rc

Mt = λMt−1 + ηCA3tCA3T
t

(1)

where CA3t is the result of the DG-to-CA3 connection (i.e. before recurrent processing). λ and η
respectively denote the rates of forgetting and remembering. During both training and test phases, a
single iteration of an attractor network similar to that of [4] and [30] was used for memory retrieval.
It yielded a new vector, CA3r

t , to be passed to the next layer CA1:
CA3r

t = ReLU(κCA3t + Mt−1CA3t)

(2)

where κ is a decay term.

2.3 Training and hyperparameterization

All task-context combinations were presented once during each epoch, in random order. Similarly to
the recently proposed autoencoder model of the hippocampus [28], the network learned to output
its input, namely the two input object patterns and the rewarded one. Thus, the loss function to be
minimized was the mean squared error between the input and the output. Learning was online, as
training examples were presented one by one. The rewarded pattern was provided as input to the
network during training, but was masked during test (i.e. values of the third input slot were set to 0).
In the test phases, a trial was considered correct when the pattern stored in the third slot of the output
was closer to the rewarded pattern than the non-rewarded one, as assessed by the mean squared error.
Unless otherwise mentioned, networks were trained during 100 epochs, and hyperparameters were
selected randomly to ensure robustness of the results. These include N , the learning rate, κ, λ and η.
The same hyperparameterization was shared along configurations of modulated layers to allow for
the use of paired difference statistical tests.

3 Results

Performance was evaluated according to which layers were modulated by contextual information
(fig. 2, left panel). The depth of the layer receiving contextual input (ranging from ECin : 1 to
ECout : 5) positively correlated with performance (Spearman’s r(1250) = .34, p < .001). Wilcoxon
Signed-ranks tests indicated that performance was significantly lower when context was provided to
ECin (Median = 66.88%) than when provided to DG (Median = 78.16%, z = −4.28, p < .001),
CA3 (Median = 82.88%, z = −5.98, p < .001), CA1 (Median = 84.97%, z = −8.67, p < .001) or
ECout (Median = 85.66%, z = −9.54, p < .001). Modulating either CA1 (Median = 84.97%) or
ECout (Median = 85.66%) gave the best results, and did not differ significantly (p = .29). We then
tested whether the effects of modulating individual layers would add up when multiple layers received
contextual information. We found that modulating both CA1 and ECout was more efficient (Median
= 89.97%) than modulating CA1 (Median = 84.97%, z = −3.44, p < .001) or ECout (Median
= 85.66%, z = −2.39, p < .01) individually (fig. 2, right). We investigated the relationship between

3

Figure 2: Recall performance when
different layers are contextually modu-
lated.

Figure 1: Example series of eight tasks. Here, the network
was trained during 1000 epochs and parameterized with
N = .001, a learning rate of 10−4.5, and κ = η = λ = .5.
The output shown was taken from the test phase.

Figure 3: Recall performance when a
different number of layers is contextu-
ally modulated.

Figure 4: Recall performance of all possible modulatory
configurations, ordered by their median.

4

Pattern 1Pattern 2Rewarded in cNetwork output in cRewarded in c'Network output in c'ECinDGCA3CA1ECout5060708090100Performance (% correct)CA1 & ECout0.00.20.40.60.81.0Modulated layers0.00.20.40.60.81.012345Number of modulated layers5060708090100Performance (% correct)5060708090100Performance (% correct)Combinations of modulated layersECoutCA1CA3DGECinthe number of modulated layers and performance by generating all possible combinations of targeted
layers. As shown in figure 3, the relationship was weakly positive (Spearman’s r(7750) = .08,
p < .001), and seemed to stagnate when more than 2 layers received contextual information. In
fact, Mann-Whitney U tests revealed that while modulating two layers was significantly more
efficient (Median = 85.13%) than modulating one (Median = 79.88%, U = 1, 365, 367, p < .001),
modulating five (Median = 87.28%) did not yield significantly better results than modulating two
(Median = 85.13%, U = 292, 927, p = .05).

Over all configurations, the best performance was obtained when CA1 and ECout were simultaneously
modulated (fig. 4), and the worst configuration was to modulate ECin alone. Surprisingly, the second
best configuration was to modulate ECin in addition to CA1 and ECout. We also noted that ECin
was more present than CA3 and DG in top configurations, and that CA3 was the least present.

4 Discussion

Our results provide support for a role of prefrontal projections to CA1 and deep layers of the EC in
top-down control of memory retrieval. A general trend was that modulating the last layers was more
efficient than modulating upstream layers, suggesting that PFC is opportunist and biases processing
at the end of the information flow. The fact that PFC generally targets high-level sensory regions of
the brain suggests that these results might extend to non-mnemonic cognitive control. Projections to
superficial layers of the EC were found to be the most inefficient yet not significantly detrimental
when accompanied by downstream modulation. On the contrary, projections to CA3 which seem
to be absent in biology, or even to DG, were not found to be very efficient whether being alone or
with other prefrontal projections. Results also indicate that feeding multiple layers with the same
contextual information is not redundant for the network and can instead improve performance. Yet,
the relationship between the number of modulated layers and performance does not seem to be
straightforward, as adding more modulations did not necessarily improve performance and rather
increased variance (fig. 3).

These preliminary results along with the study of [23] open up a new line of research dedicated to
the understanding of controlled episodic memory using computational tools, with a focus on the
hippocampus and PFC. For example, the model could be extended with a biologically motivated
monosynaptic pathway (i.e. a shortcut connection from ECin to CA1). Other tasks could also be
considered to further disentangle the selective role of each prefrontal-hippocampal pathway. For
example, the need for cognitive control could be increased by generating patterns with more spatial
overlap. Sequence memory tasks could also be investigated. Interestingly, it has been reported
that inactivating either the entorhinal or thalamic afferences from PFC led to qualitatively different
sequence memory impairments [17]. We believe that this research avenue will yield significant
improvements of episodic reinforcement learning algorithms, as simple stimulus-driven recall will be
augmented with contextual cues, goal-directedness, and possibly sequence modeling.

Acknowledgements

The authors would like to thank Fandilla-Marie Furlan, Xavier Hinaut and David Trocellier for their
generous feedback. Experiments presented in this paper were carried out using the PlaFRIM experi-
mental testbed, supported by Inria, CNRS (LABRI and IMB), Université de Bordeaux, Bordeaux
INP and Conseil Régional d’Aquitaine (see https://www.plafrim.fr).

References

[1] M. C. Anderson and C. Green. Suppressing unwanted memories by executive control. Nature,

410(6826):366–369, 2001.

[2] M. C. Anderson, J. G. Bunce, and H. Barbas. Prefrontal–hippocampal pathways underlying

inhibitory control over memory. Neurobiology of learning and memory, 134:145–161, 2016.

[3] L. Andrianova, S. Yanakieva, G. Margetts-Smith, S. Kohli, E. S. Brady, J. P. Aggleton, and
M. T. Craig. No evidence from complementary data sources of a direct projection from the
mouse anterior cingulate cortex to the hippocampal formation. bioRxiv, 2022.

5

[4] J. Ba, G. E. Hinton, V. Mnih, J. Z. Leibo, and C. Ionescu. Using fast weights to attend to the

recent past. Advances in neural information processing systems, 29, 2016.

[5] S. Babu, P. Savarese, and M. Maire. Online meta-learning via learning with layer-distributed

memory. Advances in Neural Information Processing Systems, 34:14795–14808, 2021.

[6] M. Botvinick, S. Ritter, J. X. Wang, Z. Kurth-Nelson, C. Blundell, and D. Hassabis. Reinforce-

ment learning, fast and slow. Trends in cognitive sciences, 23(5):408–422, 2019.

[7] H. Chateau-Laurent and F. Alexandre. Augmenting machine learning with flexible episodic

memory. In 13th International Joint Conference on Computational Intelligence, 2021.

[8] S. Cheng. The crisp theory of hippocampal function in episodic memory. Frontiers in neural

circuits, 7:88, 2013.

[9] V. Cutsuridis, B. P. Graham, S. Cobb, and I. Vida. Hippocampal microcircuits: a computational

modeler’s resource book. Springer, 2019.

[10] H. Eichenbaum. Prefrontal–hippocampal interactions in episodic memory. Nature Reviews

Neuroscience, 18(9):547–558, 2017.

[11] A. Ennaceur, N. Neave, and J. P. Aggleton. Spontaneous object recognition and object location
memory in rats: the effects of lesions in the cingulate cortices, the medial prefrontal cortex, the
cingulum bundle and the fornix. Experimental brain research, 113(3):509–519, 1997.

[12] M. Fortunato, M. Tan, R. Faulkner, S. Hansen, A. Puigdomènech Badia, G. Buttimore, C. Deck,
J. Z. Leibo, and C. Blundell. Generalization of reinforcement learners with working and episodic
memory. Advances in neural information processing systems, 32, 2019.

[13] L. M. Frank, E. N. Brown, and M. Wilson. Trajectory encoding in the hippocampus and

entorhinal cortex. Neuron, 27(1):169–178, 2000.

[14] H. Fu, H. Tang, J. Hao, C. Chen, X. Feng, D. Li, and W. Liu. Towards effective context for
meta-reinforcement learning: an approach based on contrastive learning. In Proceedings of the
AAAI Conference on Artificial Intelligence, volume 35, pages 7457–7465, 2021.

[15] S. J. Gershman and N. D. Daw. Reinforcement learning and episodic memory in humans and

animals: an integrative framework. Annual review of psychology, 68:101, 2017.

[16] A. Goyal, A. Friesen, A. Banino, T. Weber, N. R. Ke, A. P. Badia, A. Guez, M. Mirza, P. C.
Humphreys, K. Konyushova, et al. Retrieval-augmented reinforcement learning. In International
Conference on Machine Learning, pages 7740–7765. PMLR, 2022.

[17] M. Jayachandran, S. B. Linley, M. Schlecht, S. V. Mahler, R. P. Vertes, and T. A. Allen.
Prefrontal pathways provide top-down control of memory for sequences of events. Cell reports,
28(3):640–654, 2019.

[18] H. Le, T. Karimpanal George, M. Abdolshah, T. Tran, and S. Venkatesh. Model-based episodic
memory induces dynamic hybrid controls. Advances in Neural Information Processing Systems,
34:30313–30325, 2021.

[19] M. Lengyel and P. Dayan. Hippocampal contributions to control: the third way. Advances in

neural information processing systems, 20, 2007.

[20] L. C. Melo. Transformers are meta-reinforcement learners. In International Conference on

Machine Learning, pages 15340–15359. PMLR, 2022.

[21] R. Navawongse and H. Eichenbaum. Distinct pathways for rule-based retrieval and spatial
mapping of memory representations in hippocampal neurons. Journal of Neuroscience, 33(3):
1002–1013, 2013.

[22] G. J. Peters, C. N. David, M. D. Marcus, and D. M. Smith. The medial prefrontal cortex is
critical for memory retrieval and resolving interference. Learning & memory, 20(4):201–209,
2013.

[23] P. K. Pilly, M. D. Howard, and R. Bhattacharyya. Modeling contextual modulation of memory

associations in the hippocampus. Frontiers in Human Neuroscience, 12:442, 2018.

[24] A. Pritzel, B. Uria, S. Srinivasan, A. P. Badia, O. Vinyals, D. Hassabis, D. Wierstra, and
C. Blundell. Neural episodic control. In International Conference on Machine Learning, pages
2827–2836. PMLR, 2017.

6

[25] H. Ren, A. Garg, and A. Anandkumar. Contextbased meta-reinforcement learning with struc-

tured latent space. In Skills Workshop NeurIPS, 2019.

[26] S. Ritter, J. Wang, Z. Kurth-Nelson, S. Jayakumar, C. Blundell, R. Pascanu, and M. Botvinick.
Been there, done that: Meta-learning with episodic recall. In International conference on
machine learning, pages 4354–4363. PMLR, 2018.

[27] E. T. Rolls. A theory of hippocampal function in memory. Hippocampus, 6(6):601–620, 1996.
[28] D. Santos-Pata, A. F. Amil, I. G. Raikov, C. Rennó-Costa, A. Mura, I. Soltesz, and P. F.
Verschure. Entorhinal mismatch: A model of self-supervised learning in the hippocampus.
Iscience, 24(4):102364, 2021.

[29] S. Sodhani, A. Zhang, and J. Pineau. Multi-task reinforcement learning with context-based
representations. In International Conference on Machine Learning, pages 9767–9779. PMLR,
2021.

[30] J. C. Whittington, T. H. Muller, S. Mark, G. Chen, C. Barry, N. Burgess, and T. E. Behrens. The
tolman-eichenbaum machine: unifying space and relational memory through generalization in
the hippocampal formation. Cell, 183(5):1249–1263, 2020.

[31] E. R. Wood, P. A. Dudchenko, R. J. Robitsek, and H. Eichenbaum. Hippocampal neurons
encode information about different types of memory episodes occurring in the same location.
Neuron, 27(3):623–633, 2000.

7

