Section focused on machine learning methods for high-level cognitive
capabilities in robotics Tetsunari Inamura, Hiroki Yokoyama, Emre Ugur,
Xavier Hinaut, Michael

Beetze, Tadahiro Taniguchi

To cite this version:

Tetsunari Inamura, Hiroki Yokoyama, Emre Ugur, Xavier Hinaut, Michael
Beetze, et al.. Section focused on machine learning methods for
high-level cognitive capabilities in robotics. Advanced Robotics, 2019,
33 (11), pp.537-538. ￿10.1080/01691864.2019.1625183￿. ￿hal-02432787￿

HAL Id: hal-02432787

https://inria.hal.science/hal-02432787

Submitted on 8 Jan 2020

HAL is a multi-disciplinary open access archive for the deposit and
dissemination of sci- entific research documents, whether they are pub-
lished or not. The documents may come from teaching and research
institutions in France or abroad, or from public or private research
centers.

L’archive ouverte pluridisciplinaire HAL, est destinée au dépôt et à la
diffusion de documents scientifiques de niveau recherche, publiés ou
non, émanant des établissements d’enseignement et de recherche français
ou étrangers, des laboratoires publics ou privés.

1

6

11

16

21

26

31

36

41

46

51

ADVANCED ROBOTICS https://doi.org/10.1080/01691864.2019.1625183

PREFACE

Q1 Q2

Section focused on machine learning methods for high-level cognitive
capabilities in robotics

Integrating high- and low-levelognitive capabilities is essential for
developing robotic systems that can adap- tively act in our daily
environment in active collabora- tion with humans. Recent advances in
machine learn- ing techniques, including deep learning and hierarchical
Bayesian modeling, are providing us with new possibili- ties to
integrate high- and low-level cognitive capabilities in robotics. It
became clear that such learning meth- ods are indispensable to create
robots that can effectively address uncertainties while acting smart in
the real world. We had organized workshops, named ‘Machine Learning
Methods for High-Level Cognitive Capabilities in Robotics,’ in IROS 2016
and 2017. In the workshops, we solicited excellent papers related to the
demand for accelerating the synergies of low- and high-level cogni- tive
capabilities. It would enable us to develop methods that address
real-world problems in a more robust man- ner. Hence, we aim to share
knowledge regarding state- of-the-art machine learning methods that
contribute to modeling sensory-motor and cognitive capabilities in
robotics and to exchange views among cutting-edge robotics researchers
with a special emphasis on adaptive high-level cognition.

Through the workshops, researchers from cogni- tive robotics, speech
processing, artificial intelligence, machine learning, computer vision,
natural language processing, and so on were gathered to discuss the cur-
rent challenges in machine learning methods for high- level cognitive
capabilities in robotics. Typical keywords discussed in the workshop
were as follows: Multimodal communication, learning motor skills and
segmentation of time-series information, concept formation, proba-
bilistic models, language acquisition, human–robot com- munication and
collaboration, deep learning, the theory of mind and model of others,
skill transfer, Bayesian modeling, application in communicable service
robots, and so on. These keywords should be organized using Figure 1,
which was used in the workshop discussion in 2017.

Our daily environment is full of uncertainties, with complex objects and
challenging tasks. A robot is not only required to deal with things
appropriately in a physical

manner, but also perform logical and linguistic tasks in the real world.
Consider a scenario where a human user tells a robot, ‘please move it
into the blue box.’ In addition to solving a manipulation task, the
robot must move the target object to a particular blue box and estimate
what ‘it’ represents. In addition to solving the manipulation task, the
robot should estimate the meaning of ‘into,’ repre- senting the
relationship between ‘it’ and ‘the blue box’ in a real-world
environment. When a robot attempts to communicate and collaborate with
human users in a real- world environment, bridging high- and low-level
cogni- tive capabilities is critical. Low-level cognitive capabilities
include physical control, behavioral motion generation, and sensory
perception (node (i) in Figure 1). In contrast, high-level cognitive
capabilities include logical inference, planning, and language (node
(ii) in Figure 1).

Conventionally,

symbol-based and/or

rule-based approaches have been employed to model high-level cognitive
capabilities in robotics. However, it has been reported that such
conventional methods could not cre- ate a robot that could address
inevitable uncertainties in the physical environment and natural
human–robot communications. In other words, the difficulty of direct
transformation between nodes (i) and (ii) was the major cause of the low
performance of natural human–robot communications. However, recent
advances in machine learning techniques have provided a bridge between
node (i) and the top node, and between node (ii) and the top node, as
shown in Figure 1. It has become increas- ingly clear that machine
learning methods are indis- pensable for creating robots that address
uncertainties. In addition to machine learning techniques, big data in
human–robot interactions through a virtual reality environment can be
applied to accelerate the learning process to connect the high- and
low-level cognitive capabilities.

We organized a new type of submission strategy at the second workshop in
2017. Authors could choose from two submission categories:

(A) Extended abstract (maximum 2 pages in length)
(B) Full paper (maximum 6 pages in length)

© 2019 Informa UK Limited, trading as Taylor & Francis Group and The
Robotics Society of Japan

56

61

66

71

76

81

86

91

96

101

106

2

PREFACE

t n i r p n

i

W / B

, e n

i l

n o r u o o C

l

Figure 1. Bridge between low-level cognitive capabilities, i.e. node
(i), and high-level cognitive capability, i.e. node (ii). Direct
transformation between nodes (i) and (ii) is diﬃcult using con-
ventional methods; however, recent machine learning techniques provide
high-level cognitive models, depicted as the top node that solves the
gap between (i) and (ii).

All the papers submitted to the workshop are reviewed for consideration
as both (A) and (B). The difference between (A) and (B) is that the
reviewer process for the special issue in Advanced Robotics begins at
the submis- sion for the workshop. The review process for the journal is
independent of the review process for this workshop; however, the
authors can receive the review result from the editors of Advanced
Robotics within approximately 90 days (on average). This implies that
the authors might be able to state in the workshop that the paper will
be pub- lished in the journal later. Hence, the paper for category (B)
should not be published in the workshop proceed- ings. We believe that
this new strategy would result in a good opportunity for and encourage
young researchers to join an international discussion community to
improve their ideas through discussions at the workshop and review
processes. Unfortunately, only one paper will be accepted through
category (B); however, we have received many papers using this
submission and review strategy. We plan to adopt this strategy in future
workshops.

The first paper, entitled ‘Navigation Behavior based on Self-organized
Spatial Representation in Hierarchical Recurrent Neural Network’ by
Wataru Noguchi et al. is accepted using the above submission category
(B). This paper proposes a cognitive map representation based on
hierarchical recurrent neural networks. The model acquires the
relationship between a sequence of images and navigation skill through
navigation experiences. This

111

116

121

126

131

136

141

146

151

156

161

relationship is illustrated as a part of Figure 1, i.e. the bidi-
rectional arrow between node (i) (motion skill and image sequence) and
the top node (cognitive map representa- tion).

The second paper is entitled ‘Bidirectional Estima- tion Between Context
and Motion in Motion Sequence in Which Context Changes’ by Takashi Ogura
et al. This paper proposes an architecture for the bidirectional
recognition of motion patterns and background context. Motion
recognition affects context estimation, and con- text estimation affects
motion recognition. This relation- ship is depicted as a part of Figure
1, i.e. between the top node for context and node (i) for motion
patterns.

Our research community organized a workshop named ‘Language and
Robotics’ in IROS in 2018. The name of the workshop was changed;
however, the posi- tioning of the research interest was almost the same
as that of the workshops in 2017. The understanding of the natural
language by social service robots in daily life environment requires
high-level cognitive information and numerous raw sensor information
related to human activity, which is depicted as node (i) in Figure 1. We
believe that the section focusing on this issue should be the starting
point for the development of cognitive intelligent robot systems,
including the use of language ability.

166

171

176

181

186

191

Disclosure statement

No potential conflict of interest was reported by the authors. Q4

Tetsunari Inamura National Institute of Informatics, Tokyo, Japan
inamura@nii.ac.jp

Hiroki Yokoyama University of Tamagawa, Machida, Japan

Emre Ugur Bogazici University, Istanbul, Turkey

196

201

Xavier Hinaut INRIA, France

Q3

206

Michael Beetze University of Bremen, Bremen, Germany

Tadahiro Taniguchi Ritsumeikan University, Kyoto, Japan

211

216


