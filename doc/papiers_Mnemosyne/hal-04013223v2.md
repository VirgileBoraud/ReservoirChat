Enseigner et apprendre à l’ère de l’intelligence artificielle
Margarida Romero, Laurent Heiser, Alexandre Lepage, Anne Gagnebien,

Audrey Bonjour, Aurelie Lagarrigue, Axel Palaude, Caroline Boulord,

Charles-Antoine Gagneur, Chloé Mercier, et al.

To cite this version:

Margarida Romero, Laurent Heiser (Dir.). Enseigner et apprendre à l’ère de l’intelligence artificielle.
Canopé, Livre blanc, 2023. ￿hal-04013223v2￿

HAL Id: hal-04013223

https://hal.science/hal-04013223v2

Submitted on 13 Mar 2023

HAL is a multi-disciplinary open access
archive for the deposit and dissemination of sci-
entific research documents, whether they are pub-
lished or not. The documents may come from
teaching and research institutions in France or
abroad, or from public or private research centers.

L’archive ouverte pluridisciplinaire HAL, est
destinée au dépôt et à la diffusion de documents
scientifiques de niveau recherche, publiés ou non,
émanant des établissements d’enseignement et de
recherche français ou étrangers, des laboratoires
publics ou privés.

Distributed under a Creative Commons Attribution - NonCommercial - ShareAlike 4.0 International
License

THÉMATIQUE 
Renouvellement des pratiques 
numériques et usages créatifs du 
numérique et de l’IA 

Enseigner et 
apprendre à 
l’ère de 
l’intelligence 
artificielle 

GTnum LINE #Scol\_IA 
2020-2022 

Enseigner et apprendre à l’ère de l’intelligence artificielle Sommaire 

1 

 
 
 
ENSEIGNER ET APPRENDRE A L’ERE DE L’IA 
Acculturation, intégration et usages créatifs de l’IA en éducation 
LIVRE BLANC 

Edition 
Margarida Romero, Université Côte d’Azur 
Laurent Heiser, Université Côte d’Azur 
Alexandre Lepage, Université de Montréal 

Auteurs des chapitres 
Alexandre Lepage, Université de Montréal 
Anne Gagnebien, Université de Toulon 
Audrey Bonjour, Université de Toulon 
Aurélie Lagarrigue, INRIA Mnemosyne 
Axel Palaude, INRIA Mnemosyne 
Caroline Boulord, La Scientothèque 
Charles-Antoine Gagneur, Conservatoire national des arts et métiers de Paris 
Chloé Mercier, INRIA Mnemosyne 
Christelle Caucheteux, Life Bloom Academy 
Dominique Guidoni-Stoltz, Institut Agrosup Dijon 
Florence Tressols, Maison de l’intelligence artificielle 
Frédéric Alexandre, INRIA Mnemosyne 
Jean-François Céci, Université de Poitiers 
Jean-François Metral, Institut Agrosup Dijon 
Jérémy Camponovo, DRANE de l’Académie de Nice 
Julie Henry, Université de Namur 
Laurent Fouché, Life Bloom Academy 
Laurent Heiser, Université de Toulon et Université Côte d’Azur 
Lianne-Blue Hodgkins, Life Bloom Academy 
Ludovic Dibiaggio, Skema Business School 
Margarida Romero, Université Côte d’Azur et INRIA Mnemosyne 
Marie-Hélène Comte, INRIA Mnemosyne 
Michel Durampart, Université de Toulon 
Patricia Corieri, La Scientothèque 
Paul Olry, Institut Agrosup Dijon et Conservatoire national des arts et métiers de Paris 
Pauline Reboul, Université de Toulon 
Philippe Bonfils, Université de Toulon 
Sami Ben Amor, Université de Toulon 
Simon Collin, Université du Québec à Montréal 
Solange Ciavaldini-Cartaut, Université Côte d’Azur 
Thierry Viéville, INRIA Mnemosyne et Université Côte d’Azur 
Victoire Batifol, Life Bloom Academy 
Yann-Aël Le Borgne, La Scientothèque et Université Libre de Bruxelles 

Pilotage du GTnum 
Margarida Romero, Laurent Heiser et Maryna Rafalska, Université Côte d’Azur 

Remerciements aux équipes académiques dans le cadre du GTNum, l’équipe du bureau du soutien à l’innovation numérique et 
à la recherche appliquée (DNE-TN2), dont Axel Jean, Elie Allouche, Valérie Marcon, et aux collègues INRIA Gérard Giraudon, 
Didier Roy, et du LINE Maryna Rafalska et Caroline Duret, pour la révision de l’ouvrage. 

Ces travaux sont publiés dans le cadre des groupes thématiques numériques soutenus par la Direction du numérique 
pour l’éducation. 
• Eduscol https://eduscol.education.fr/2174/enseigner-et-apprendre-avec-la-recherche-les-groupes-thematiques-
numeriques-gtnum 
• Carnet Hypothèses « Éducation, numérique et recherche » https://edunumrech.hypotheses.org/ 

Mars 2023 

Conditions d’utilisation : 

 sauf indication contraire, tout le contenu de ce document est disponible 

sous Licence Ouverte 2.0 

Enseigner et apprendre à l’ère de l’intelligence artificielle Sommaire 

2 

 
 
 
 
 
SOMMAIRE 

AVANT-PROPOS ............................................................................................5 

Introduction ......................................................................................................6 

Partie 1 /// Retours d’expérience .....................................................................8 

1 /// Un MOOC pour initier à l’IA : « Intelligence artificielle avec intelligence »
 .........................................................................................................................9 

Introduction....................................................................................................... 9 
Pourquoi une formation citoyenne sur l’IA ...................................................... 10 
Approche pédagogique et activités du MOOC ............................................... 12 
Retombées sur les participants et le milieu scolaire ....................................... 13 

2 /// Comment la Scientothèque à l’Université Libre de Bruxelles initie 
enseignants et élèves à l’IA depuis 2020 ..................................................... 16 

Présentation de la Scientothèque : l’égalité des chances par les sciences .... 16 
L’approche pédagogique de la Scientothèque en matière d’IA ...................... 18 
Retours d’expérience ..................................................................................... 20 
Perspectives ................................................................................................... 21 

3 /// Sensibiliser 75 % des élèves de collège des Alpes-Maritimes à l’IA : le 
projet Arc-en-ciel pilotÉ par la Maison de l’intelligence artificielle ................ 24 

Qu’est-ce que le projet Arc-en-ciel? ............................................................... 24 
Les réalisations du projet Arc-en-ciel ............................................................. 25 
Un exemple de projet : la ruche intelligente ................................................... 29 
Genèse du projet Arc-en-ciel .......................................................................... 30 
Conclusion...................................................................................................... 33 

4 /// Réflexions des élèves du collège Life Bloom Academy sur l’IA ............ 35 
Un projet interdisciplinaire portant sur l’IA ...................................................... 35 
Les récits d’expérience des élèves ................................................................. 37 
Conclusion...................................................................................................... 39 

Partie 2 /// Enjeux de l’IA en éducation ....................................................... 40 

5 /// L’IA en formation professionnelle .......................................................... 41 

Introduction..................................................................................................... 41 

Fiabilité, qualité et tangibilité des données initiales dans la formation 
professionnelle pour concevoir une IA ........................................................... 43 
L’IA en formation professionnelle, un partenaire de l’apprentissage .............. 46 
Enjeux didactiques de l’IA et de la simulation en formation professionnelle ... 48 

Enseigner et apprendre à l’ère de l’intelligence artificielle Sommaire 

3 

L’IA et les tuteurs intelligents pour les apprentissages professionnels et 
l’assistance à l’enseignement ......................................................................... 50 
Conclusion...................................................................................................... 53 

6 /// L’IA pour mieux apprendre et appréhender l’IA .................................... 56 

L’IA comme outil d’apprentissage adaptatif .................................................... 56 
L’IA comme modèle pour comprendre l’apprentissage humain ...................... 58 
L’IA, un enseignement citoyen ....................................................................... 59 
Un bouleversement dans notre façon de penser ............................................ 60 

7 /// Le dispositif 5J5IA, un exemple de régulation critique de l’IA en 
éducation ...................................................................................................... 63 

L’École à l’ère du numérique et de l’IA ........................................................... 63 

Fondements théoriques du concept de régulation critique du numérique et de 
l’IA en éducation ............................................................................................. 65 
Une régulation qui ne va pas de soi ............................................................... 67 
L’exemple du dispositif pédagogique 5J5IA ................................................... 68 
Une responsabilité à hauteur des enjeux ....................................................... 71 

8 /// L’acculturation au numérique ................................................................ 74 
La notion d’acculturation au numérique .......................................................... 74 
Les trois niveaux d’acculturation numérique .................................................. 75 

Que dit le concept d’acculturation numérique sur l’intégration des technologies 
à l’école .......................................................................................................... 77 

Perspectives pour une acculturation face au numérique au regard des 
perspectives de l’IA dans les apprentissages et l’éducation ........................... 78 

9 /// Préserver l’agentivité des enseignants et élèves : des pistes issues 
d’une recension des écrits ............................................................................ 82 

Introduction..................................................................................................... 82 
Méthode : une recension des écrits sur les enjeux éthiques .......................... 85 
Résultats en lien avec l’agentivité des enseignants et des élèves ................. 85 
Discussion : quelques nuances et pistes pour se prémunir des risques ........ 89 
Conclusion...................................................................................................... 91 

Conclusion .................................................................................................... 94 

Enseigner et apprendre à l’ère de l’intelligence artificielle Sommaire 

4 

 
AVANT-PROPOS 

Au cours des deux dernières années, le Groupe de Travail numérique 
(GTnum) « Renouvellement des pratiques numériques et usages créatifs du 
numérique et IA » (Scol\_IA) a rassemblé des dizaines de personnes de tout 
horizon pour étudier le potentiel pédagogique et les limites de l’intelligence 
artificielle (IA) appliquée au domaine de l’éducation. Ce contexte de 
recherche est singulier à deux égards : d’abord, le déploiement de l’IA en 
éducation est déjà entamé et la réflexion pédagogique qui l’accompagne est 
animée par une certaine urgence d’agir. En s’impliquant dans la réflexion sur 
l’IA à l’école, l’équipe cherche à donner des repères pour que l’intégration de 
l’IA à l’école soit réussie et qu’elle profite aux élèves comme aux 
enseignants. Ensuite, ce contexte est marqué par une interdisciplinarité qui 
apporte une perspective multiple à cet ouvrage. En guise d’exemple, nous 
aborderons dans l’ouvrage la modélisation de l’apprenant, un défis des 
neurosciences computationnelles pouvant bénéficier des perspectives 
d’autres disciplines, dont les sciences de l’éducation et de la formation. 
Pendant deux ans, nous nous sommes affairés à faire dialoguer des 
disciplines, et incidemment des personnes, qui s’ancrent dans des univers 
épistémologiques différents, au premier plan desquels se retrouvent les 
sciences informatiques et de celles de l’éducation. À leurs côtés, la 
psychologie, l’économie et la sociologie. Nous avons également engagé des 
acteurs éducatifs de l’écosystème azuréen comme la Maison de l’intelligence 
artificielle ou Terra Numerica, en collaboration avec la Direction régionale 
académique du numérique éducatif (région Provence-Alpes-Côte-d’Azur). 
Les praticiens professeurs de terrain ont permis de renforcer cette démarche 
et facilité la collaboration avec des élèves du primaire et du secondaire au 
cours de ce GTnum. Nous avons mis en œuvre des mécanismes de 
collaboration permettant d’éclairer l’IA en éducation depuis plusieurs 
perspectives. 

Fruit de cette collaboration entre les différents acteurs éducatifs et de 
recherche, ce livre blanc tient compte de l’expérience partagée au cours de 
ces deux ans. Cet ouvrage est à la fois destiné aux praticiens de l’éducation 
et aux chercheurs ; il présente la diversité des formes que peut prendre l’IA 
en éducation parmi lesquelles se trouvent notamment les tuteurs intelligents, 
les tableaux de bord pour la réussite éducative et les aides à la décision pour 
les enseignants. Il aborde aussi la question de l’éducation à l’IA pour tous. 
Des réflexions sont proposées sur le caractère disruptif de l’IA par rapport à 
la forme scolaire actuelle. Nous avons tenté de donner un sens à l’IA en 
éducation malgré les contradictions qu’elle porte, entre la recherche du 
modèle d’apprenant universel et 
la personnalisation des parcours 
d’apprentissage, entre l’agentivité des enseignants et l’automatisation de 
leurs actions, entre l’innovation technologique et la préservation du 
patrimoine scolaire. 

Enseigner et apprendre à l’ère de l’intelligence artificielle Sommaire 

5 

 
 
 
 
INTRODUCTION 

Margarida Romero1 
Ludovic Dibiaggio2 
Laurent Heiser1 
Alexandre Lepage3 

1 Laboratoire d’innovation pour le numérique en éducation, Université Côte d’Azur 
2 Skema Business School 
3 Université de Montréal 

Les défis sociaux auxquels nous faisons face appellent à la l’actualisation 
des modèles pédagogiques. A contrario de certains domaines techniques, 
où l’utilisation de systèmes d’IA peut produire des résultats aux avantages 
consensuels, l’éducation est un contexte particulièrement marqué par la 
richesse des relations humaines. De ce fait, il faut apprendre à distinguer 
deux types de situations : d’une part, celles qui nécessitent une intervention 
humaine pour compléter les résultats proposés par un algorithme (par 
exemple pour des décisions liées à l’orientation, le décrochage, le mentorat 
ou encore l’obtention d’un certificat) et, d’autre part, les situations qui ne 
nécessitent plus aucune intervention humaine (résultats fournis par un 
algorithme adaptatif). 

le 

D’emblée, il convient de présenter quelques définitions pour le lecteur non 
spécialiste. Le terme « intelligence artificielle » (IA) recouvre un ensemble 
de théories et de techniques qui traite de problèmes dont la résolution fait 
normalement appel à l’intelligence humaine. Aujourd’hui, l’IA s’appuie 
principalement – mais pas seulement – sur l’apprentissage automatique, que 
learning. 
certains connaissent sous 
L’apprentissage automatique exploite des méthodes mathématiques pour 
analyser de grands ensembles de données (dites données massives ou big 
data) et identifier des tendances (corrélations, similarités, patterns). De cette 
analyse découlent des modèles permettant de prédire, parfois avec des taux 
d’exactitude impressionnants, certaines variables comme les résultats 
scolaires ou le risque de décrochage. Les modèles d’apprentissage 
automatique peuvent aussi être employés pour des problèmes de 
classification où l’on cherchera à identifier l’appartenance à un profil 
d’apprenant en vue d’adapter des actions. 

terme anglais de machine 

L’IA, une jeune science 

Depuis les années 1950, l’IA est un domaine de recherche foisonnant mélangeant 
mathématiques appliquées et psychologie. Les techniques ont évolué, plusieurs 
définitions ont été proposées, mais l’idée de repousser les limites des actions humaines 
pouvant être automatisées demeure centrale. On parlera tantôt de prise de décisions, 
tantôt d’aide à la décision, mais il demeure que l’IA affiche l’ambition de modéliser 
certaines facultés mentales de l’être humain. De nos jours, avec la multiplication des 
ensembles de données massives, le raffinement des méthodes d’analyse et la visibilité 
de certains projets qui stimulent l’imaginaire collectif comme les voitures autonomes, 
les applications potentielles de l’IA dans différents domaines de connaissances 
connaissent un essor important. 

Ce livre blanc a l’ambition de livrer un éclairage scientifique sur les outils et 
modèles d’apprentissage automatique, à la fois supports pédagogiques et 
outils expérimentaux permettant d’approfondir notre compréhension du 
fonctionnement de l’apprentissage humain. Il présente une science en train 

Enseigner et apprendre à l’ère de l’intelligence artificielle Sommaire 

6 

 
 
 
de se faire, ouverte à la discussion, et non un discours établi et prescriptif. 
Les débats théoriques et les rapports d’expériences réalisés dans des 
environnements scolaires ou dans l’enseignement professionnel nous 
racontent un métier en évolution, celui d’enseignant. 

Les différentes expériences menées dans le cadre du GTnum Scol\_IA 
mettent aussi en évidence les difficultés rencontrées par les acteurs 
éducatifs. Nous devons tenir compte des compétences de ces derniers et de 
l’acculturation sous-jacente à l’intégration de l’IA, tant dans les systèmes 
formels d’éducation que dans les systèmes informels. 

L’ouvrage est structuré en deux parties. La première concerne les pratiques 
émergentes d’enseignement de 
l’IA auprès de différents publics 
principalement scolaires. Ainsi, les chapitres 1 à 4 présentent des 
réalisations issues de l’éducation ou de la médiation scientifique qui peuvent 
inspirer l’actualisation des pratiques enseignantes dans les écoles. La 
seconde partie de l’ouvrage propose un recul réflexif pour aborder une 
question fondamentale : quelle place devrait occuper l’IA en éducation ? Les 
chapitres 5 à 9 présentent des situations portant tant sur des contextes 
d’éducation formelle et informelle, mais également des activités pour 
l’acculturation et la formation à l’IA. 

Les usages de l’IA en éducation sont abordés à partir du modèle #5c21 
(Romero et al., 2017). Selon ce modèle, tout usage du numérique se situe 
sur un spectre en cinq niveaux allant de la consommation passive à la co-
création participative de connaissances. Nous cherchons en particulier à 
mettre en valeur les usages de l’IA comme moyen de conduire des activités 
renforçant la créativité en tenant compte des contextes et niveaux éducatifs 
différents (Heiser et al., 2022). C’est pourquoi nous proposons une échelle 
des usages créatifs de l’IA en éducation. Aux premier et deuxième niveaux 
se situent les usages de l’IA qui n’engagent ni l’apprenant ni l’enseignant de 
manière créative. Aux troisième et quatrième niveaux sont représentés les 
usages de l’IA qui soutiennent la créativité individuelle ou collective. 
Finalement, au cinquième niveau, les usages de l’IA en éducation 
soutiennent la résolution créative de problèmes à visée participative ou 
sociétale. Nous espérons que le livre aidera les enseignants à imaginer des 
activités poursuivant cette ambition. 

Enseigner et apprendre à l’ère de l’intelligence artificielle Sommaire 

7 

 
 
 
PARTIE 1 /// 
RETOURS 
D’EXPERIENCE 

Enseigner et apprendre à l’ère de l’intelligence artificielle Sommaire 

8 

 
 
 
 
 
 
 
1 /// UN MOOC POUR 
INITIER A L’IA : 
« INTELLIGENCE 
ARTIFICIELLE AVEC 
INTELLIGENCE » 

Frédéric Alexandre1 
Marie-Hélène Comte1 
Aurélie Lagarrigue1 
Chloé Mercier1 
Axel Palaude1 
Margarida Romero1 2 
Thierry Viéville1 2 

1 Institut national de recherche en sciences et technologies du numérique, Équipe Mnémosyne 
2 Laboratoire d’innovation pour le numérique en éducation, Université Côte d’Azur 

Pour appréhender l’IA au quotidien, il faut former les citoyens dès la fin du 
primaire et tout au long de la vie à la compréhension de ses fondamentaux. 
Le MOOC « Intelligence artificielle avec intelligence » (IAI) est une formation 
hybride et participative permettant à des citoyens de s’initier à l’IA de manière 
à la fois théorique et expérimentale, par l’essai de différentes technologies 
comme la reconnaissance d’images. La formation permet de mieux 
comprendre, pour mieux appréhender cette IA désormais présente au 
quotidien. 

Introduction 

Tout le monde est concerné par les technologies numériques. Les enjeux de l’acculturation au 
numérique doivent désormais tenir compte de ce qu’on appelle l’intelligence artificielle (IA), 
car les nouvelles technologies s’en réclamant sont de plus en plus nombreuses et accessibles. 
Il est important de permettre à chacun de comprendre le fonctionnement des mécanismes de 
l’IA afin de développer un regard critique et créatif par rapport à ses usages actuels et futurs. 
Dans ce chapitre, nous présentons un cours en ligne ouvert massivement (Massive open 
online course – MOOC) hybride et participatif intitulé Intelligence artificielle avec intelligence 
(IAI) dont l’objectif principal est de permettre à tout le monde, au-delà des publics scolaires, 
de développer une compréhension de la manière dont l’IA est intégrée dans notre vie. À 
l’origine, ce projet s’inspire de l’ambition de la Finlande de former 1 % de sa population à l’IA 
(Roos et Storchan, 2020), mais aussi du succès de projets antérieurs visant, par exemple, 
l’initiation des enseignants à la pensée informatique (Mariais et al. 2019). Début 2022, plus de 
32 000 personnes avaient suivi la formation et ont témoigné d’un taux de satisfaction de 94 % 
(Alexandre et al., 2020). Par cette initiative, nous participons au vaste projet d’université 
citoyenne ubiquitaire en culture numérique et en sciences numériques (Atlan et al. 2019). 

Enseigner et apprendre à l’ère de l’intelligence artificielle Sommaire 

9 

 
 
 
En premier lieu, ce chapitre rapporte la réflexion qui a conduit à la réalisation d’un MOOC. Il 
sera question de l’importance de développer une culture de l’IA pour prendre part aux 
réflexions éthiques qui l’entourent. Il sera aussi question des partenaires et du financement 
qui ont permis de faire de ces idées une réalité. En second lieu, la structure du cours et les 
activités qui le composent seront présentées. Finalement, nous partagerons les retombées du 
MOOC sur les participants et celles sur les milieux scolaires. 

Pourquoi une formation citoyenne sur l’IA 

L’IA concerne tous les citoyens d’abord parce qu’elle est de plus en plus présente dans tous 
les secteurs de la société et ensuite parce qu’il est nécessaire de la comprendre pour participer 
aux débats éthiques qu’elle engendre. Il est normal de se questionner sur la pertinence de 
confier à des algorithmes des tâches qui mènent à des décisions cruciales, par exemple en 
matière de justice, d’embauche, ou d’autres situations à fortes conséquences humaines. 
L’utilisation de l’IA pour ces cas sensibles doit être soutenue par une réflexion éthique, et c’est 
notamment sur cette base que s’est construit le MOOC. Réfléchir à l’acceptabilité ou non de 
l’IA dans certaines situations implique de maîtriser des notions fines comme l’interprétabilité1 
et l’explicabilité 2, ou encore les causes des biais dans les mécanismes d’IA venant des 
données ou des algorithmes. Aucun sujet technique ne peut être abordé sans que ces aspects 
éthiques ou sociétaux le soient aussi, comme c’est le cas de certaines formations en robotique 
pédagogique (p. ex. le projet Robotination où des enfants doivent construire un robot à partir 
de leurs représentations et de matériel électronique). D’un point de vue éthique, la 
responsabilité est toujours humaine, par exemple si on laisse l’algorithme décider, c’est notre 
décision de le faire : déléguer la décision à un algorithme au lieu de la prendre soi-même, c’est 
un choix et c’est un humain qui doit faire ce choix. Si une personne choisit de faire confiance 
à une machine avec un algorithme d’IA, elle fait surtout confiance à son propre jugement quant 
aux performances de ce mécanisme (voir Alexandre et al., 2022). 

INTELLIGENCE HUMAINE ET INTELLIGENCE ARTIFICIELLE 

Ensuite, toutes les personnes sont concernées par l’IA étant donné que des tâches cognitives 
de plus en plus complexes sont réalisées par des programmes. Cela nous amène aussi à 
questionner ce que nous considérons comme étant les caractéristiques que l’on attribue à 
l’intelligence humaine (Houdé, 2019 ; Romero, 2018). On se pose souvent la question 
« symétrique » de savoir si une machine peut être ou devenir intelligente : le débat est 
interminable, car il suffit de changer la définition de ce que l’on appelle intelligence pour 
répondre « oui, pourquoi-pas » ou au contraire « non, jamais ». De façon simplifiée, selon une 
acception communément véhiculée, le but de l’IA est de faire faire à une machine ce qui aurait 
été jugé intelligent si réalisé par un humain. 

En revanche, avec la mécanisation de processus cognitifs, ce qui paraissait intelligent il y a 
des années ne l’est plus nécessairement. Par exemple, le calcul mental est moins associé à 
une faculté humaine extraordinaire depuis l’apparition de calculettes, même si leur usage n’est 

1 L’interprétabilité « consiste à fournir une information représentant à la fois le raisonnement de l’algorithme et la représentation 
interne des données dans un format interprétable par un expert en apprentissage automatique ou en sciences des données » 
(Chraibi-Kaadoud, 2020). 
2 L'applicabilité vise à justifier de la façon la plus précise possible un résultat donné par un modèle, auprès des personnes 
concernées par le résultat, donc au-delà des experts. Par exemple, dans le cas d’un algorithme de reconnaissance de chat, le 
système doit être capable de prédire si effectivement l’animal observé est un chat et doit être en mesure de dire quels ont été les 
critères déterminants dans cette décision » (Talbi, 2022, p.1). 

Enseigner et apprendre à l’ère de l’intelligence artificielle Sommaire 

10 

 
pas toujours un gage d’économie temporelle (Virgo et al., 2017). De même, l’IA a le potentiel 
de soulager les humains de travaux intellectuels que l’on peut désormais automatiser. Cela 
oblige à réfléchir à l’intelligence humaine en fonction et au-delà de ce que nous appelons la 
pensée informatique, cette compétence permettant de résoudre des problèmes complexes en 
mobilisant des solutions informatiques souvent algorithmiques. Par exemple, nous savons que 
plus le problème à résoudre est spécifique, plus une méthode algorithmique sera efficace, 
possiblement plus que la cognition humaine, tandis qu’à l’inverse plus le problème à résoudre 
est général, moins un algorithme pourra intrinsèquement être performant, quel que soit le sujet 
d’application. Il se trouve que les systèmes biologiques eux aussi ont cette restriction, 
l’intelligence humaine n’est donc peut-être pas aussi générale qu’on ne le pense et se 
développe dans des domaines d’applications spécifiques (Alexandre, Viéville et Comte, 2022). 

Un autre aspect de l’IA qui rend pertinente une formation citoyenne et éthique à son sujet est 
l’omniprésence des usages dans tous les domaines de la vie et les transformations qui en 
découlent. Que des robots assistent des personnes âgées pourrait être considéré comme un 
progrès, permettant de les maintenir chez eux, à leur domicile et en toute dignité. Mais si cela 
est vu uniquement comme un levier de réduction des coûts de prise en charge, ou un moyen 
de nous désengager d’une tâche parmi les plus humaines qui soit, à savoir s’occuper des 
autres, alors la machine nous déshumanisera. Cet exemple montre surtout, comme la crise 
sanitaire l’a fait au cours ces dernières années, que des circonstances exceptionnelles nous 
obligent à revoir en profondeur les équilibres que nous pensions acquis pour notre société. 
Quand – et cela est en train d’advenir – la plupart des tâches professionnelles d’aujourd’hui 
auront été mécanisées et automatisées, la société devra être organisée autrement. 

Nous vivons au temps des algorithmes (Abiteboul et Dowek, 2017). Quelle place voulons-nous 
accorder aux algorithmes dans la vie courante ? Est-ce que cela nous conduit à repenser cette 
cité ? Comment mieux nous préparer aux usages de l’IA ? Ce sont les questions pour 
lesquelles le MOOC a voulu préparer les participants. En formant les citoyens, ils auront « les 
moyens de construire un outil qui rend possible la construction d’un monde meilleur, d’un 
monde plus libre, d’un monde plus juste » écrivent Gilles Dowek et Serge Abiteboul en 
conclusion du Temps des algorithmes. 

LE PUBLIC CIBLE 

À l’origine, le public visé par le MOOC est constitué de l’ensemble des personnes œuvrant à 
l’éducation des enfants et des adolescents : enseignants, animateurs et parents. Ces 
personnes doivent comprendre pour, à leur tour, en initier d’autres à ce qu’est l’IA. Par 
exemple, les enseignants de sciences de 1ère et de terminale doivent être en mesure de piloter 
des activités abordant la résolution de problèmes par un ordinateur ou l’apprentissage 
automatique. Les enseignants d’informatique ont la possibilité d’aborder l’IA de façon 
transversale à plusieurs disciplines, en raison de ses nombreuses applications, ou à organiser 
des ateliers extrascolaires sur le sujet. 

Le MOOC s’adresse également à toutes les personnes qui veulent découvrir ce qu’est l’IA et 
se faire une vision claire des défis et enjeux posés, ceci en comprenant comment ça marche. 
Pour atteindre cet idéal d’accès universel par tous, la formation est gratuite et attestée. 

FINANCEMENT ET PARTENAIRES 

Le projet a été soutenu par des fonds publics et des partenaires industriels pour un total de 
80K€. Plus spécifiquement, il est le fruit d’une collaboration entre La Ligue de l’Enseignement, 

Enseigner et apprendre à l’ère de l’intelligence artificielle Sommaire 

11 

Magic Maker, EducAzur, la Direction du numérique pour l’éducation (DNE), l’Institut national 
de recherche en sciences et technologies du numérique et des laboratoires de recherche 
comme le Laboratoire d’innovation avec le numérique en éducation de l’Université Côte 
d’Azur. Cette coopération était essentielle étant donné la nature interdisciplinaire de l’IA. En 
associant des compétences académiques en sciences du numérique, neurosciences 
cognitives et sciences de l’éducation, l’équipe a rassemblé des connaissances pour contribuer 
à illustrer les liens entre l’IA et l’intelligence humaine. 

DIFFUSION 

Faire connaître l’existence de la formation a représenté un défi, car l’appel à prendre du temps 
pour se former est moins sensationnel que d’autres lorsqu’il est question d’IA. La notoriété du 
MOOC a été construite principalement par les retours des personnes qui ont pu en bénéficier. 
L’enjeu d’une telle formation est d’attirer un nouveau public : difficile de faire prendre 
conscience de l’intérêt à des gens peu ou pas intéressés, alors qu’une fois lancés, les 
participants sont facilement convaincus. Le MOOC a donc été principalement connu grâce à 
la collaboration avec la Direction du numérique pour l’éducation et l’Université Numérique 
d’Ingénierie et de Technologie. 

Approche pédagogique et activités du MOOC 

Le MOOC adopte une approche pédagogique ludique et expérientielle. Des capsules vidéo 
ont été produites, parfois avec des comédiens professionnels et parfois avec des experts de 
production de contenus. Une variété de ressources complémentaires y sont proposées pour 
donner le choix à l’apprenant des formats qui lui conviennent. Certaines sont plus théoriques, 
d’autres plus ludiques, certaines plus approfondies et d’autres plus vulgarisées. Dès les 
premiers modules, l’IA est expliquée et des mythes à son sujet sont déconstruits (Lagarrigue 
et Viéville, 2021). Les deux principaux paradigmes en IA sont présentés, soit l’IA symbolique 
et l’IA connexionniste, de même que quelques repères historiques pour comprendre son 
évolution au cours du XXe siècle. Les participants sont mis en action dans des activités 
concrètes : ils manipulent des réseaux de neurones, essaient de faire reconnaître leurs 
dessins par une IA, sont invités à entraîner des modèles d’apprentissage automatique eux-
mêmes. Ils sont invités à réfléchir collectivement, via les forums de discussion, à des questions 
soulevées par le développement de l’IA. Le MOOC IAI a aussi proposé des webinaires, des 
rencontres en ligne ou en présentiel. Ces possibilités d’échanges entre participants ont été un 
point fort de la formation. La Figure 1 montre une des capsules vidéo ludiques et la Figure 2 
illustre un exemple d’activité où les participants sont invités à choisir une image dans une 
banque et à observer si un programme d’IA peut déterminer ce qu’elle représente, ainsi que 
le niveau de confiance envers la prédiction. 

Le MOOC IAI a une approche ludique et expérientielle qui vise à engager le participant dans des activités 
concrètes comme l’expérimentation d’un réseau de neurones pour démystifier son fonctionnement. 

Enseigner et apprendre à l’ère de l’intelligence artificielle Sommaire 

12 

Figure 1. Une capsule vidéo ludique du MOOC IAI 

Figure 2. Exemple d’activité développée par Class’Code où les participants expérimentent un programme de 
reconnaissance d’images 

Retombées sur les participants et le milieu scolaire 

Depuis son lancement, plus de 2 500 attestations de suivi ont été délivrées parmi les 32 000 
participants. Il y a plus de 10 000 personnes sur le forum et près de 14 000 messages 
échangés, soit entre les participants ou avec l’équipe pédagogique. Le taux de satisfaction 
des participants l’égard de la formation atteint 94 %. Les webinaires ont attiré entre 50 et 100 
personnes et ont été revisionnés par plusieurs centaines d’autres. 

Au terme du MOOC, les participants sont invités à suivre la formation Elements Of AI 
(disponible en français), ou encore à se diriger vers lumni.fr afin de renforcer certains concepts. 
Ces ressources visent à accroître la confiance3 dans le développement des innovations liées 
à l’IA et aider au développement d’un esprit critique4 sur ces sujets. 

3 Lors d’une déclaration commune en Août 2018, la France et la Finlande ont affirmé leur volonté partagée de « jouer un rôle actif 
pour promouvoir une vision de l’IA juste, solidaire et centrée sur l’humain, à la fois fondée sur la confiance et facteur de confiance ». 
4 Motivé par la déclaration commune franco-finlandaise de « promouvoir une vision de l’IA juste, solidaire et centrée sur l’humain » 
nous pensons que la première étape est d’instruire et donner les moyens de s’éduquer. 

Enseigner et apprendre à l’ère de l’intelligence artificielle Sommaire 

13 

 
 
 
Les ressources produites dans le cadre du MOOC ont été réinvesties directement en appui du 
programme scolaire en Terminale, notamment dans le cadre du cours NSI. Ces ressources 
ciblent les premiers fondements de l’IA : apprentissage automatique (avec l’exemple des 
réseaux de neurones artificiels, ou des approches bayésiennes5) (Viéville et Salaun 2020). On 
peut considérer ceci comme une base de culture scientifique pour toutes et tous dans le 
domaine. Les vidéos, placées sous licence libre CC-BY 4.0, peuvent être réutilisées par les 
enseignants. 

Ressources complémentaires 

Le MOOC IAI est ouvert à tous pour se former à l’intelligence artificielle avec intelligence de manière ludique 
et pratique. www.fun-mooc.fr/fr/cours/lintelligence-artificielle-avec-intelligence 

ClassCode Pixees. https://pixees.fr/classcode-v2/ 

ChatGPT et les nouveaux enjeux de l’IA. https://pixees.fr/chatgpt-les-nouveaux-enjeux-de-lia/ 

Elements of AI (formation complémentaire suggérée). https://course.elementsofai.com/fr-be 

Ce texte est partiellement repris de Roos et Storchan (2020) pour la partie écrite par un des 
auteurs de ce chapitre avec l’autorisation du journal Le Monde (blogue Binaire). 

Références 

Abiteboul, S. et Viéville, T. (2021). Formation à l’IA – épisode 1 : Elements 
Of 
LeMonde.fr. 
https://www.lemonde.fr/blog/binaire/2021/01/12/formation-a-lia-episode-1-
elements-of-ai/ 

binaire 

Blog 

AI. 

Abiteboul, S. et Dowek, G. (2017). Le temps des algorithmes. Le Pommier. 

Alexandre, F., Becker, J., Comte, M.-H., Lagarrigue, A., Liblau, R., Romero, 
M. et Viéville, T. (2021). Why, What and How to Help Each Citizen to 
Understand Artificial Intelligence? KI - Künstliche Intelligenz, 35(2), 191-199. 

Alexandre, F., De Barretin, R., Becker, J., Comte, M.-H., Courbin-Coulaud, 
M., Cruchon, S., Lagarrigue, A., Masse, B., De Quatrebarbes, S., Stein, J., 
Terosier, C. et Viéville, T. (2020). Understanding Intelligently Artificial 
Intelligence: A citizens’ open formation. International Workshop on Education 
in Artificial Intelligence K-12 (EduAI). 

Alexandre, F., Viéville, T. et Comte, M.-H. (2023). Délibérer avec 
l’intelligence artificielle au Ssrvice de l’intelligence naturelle. Dans P. Pédrot, 
Penser, calculer, délibérer. Mare & Martin. 

Atlan, C., Archambault, J.-P., Banus, O., Bardeau, F., Blandeau, A., Cois, A., 
Courbin-Coulaud, M., Giraudon, G., Lefèvre, S.-C., Letard, V., Masse, B., 
Masseglia, F., Ninassi, B., De Quatrebarbes, S., Romero, M., Roy, D. et 
Viéville, T. (2019). Apprentissage de la pensée informatique : De la formation 
des enseignant·e·s à la formation de tou.te.s les citoyen·ne·s. EIAH 

5 L’inférence bayésienne est une méthode d’inférence statistique « qui a pour objectif de calculer le degré de confiance à accorder 
à une cause hypothétique. Cette technique algorithmique prend comme point de départ le théorème de Bayes, qui présente les 
principes permettant de calculer une probabilité conditionnelle. Le théorème détermine la probabilité qu’un événement se produise 
en considérant la probabilité d’un autre événement qui s’est déjà produit » (Rojas-Vazquez, 2020, p.1). 

Enseigner et apprendre à l’ère de l’intelligence artificielle Sommaire 

14 

 
Wokshop 2019 - Apprentissage de la pensée informatique de la maternelle 
à l’Université : retours d’expériences et passage à l’échelle. 

Barnabé, S., Denet, L., Manrique, M., Menon, D., Pascual, É., Romero, M. 
et Viéville, T. (2020). A low-cost tabletop game to collect learning analytics 
during computational thinking using unplugged or tangible activities (Rapport 
de Recherche No 9379, 9 pages). Inria - Équipe Mnémosyne et Laboratoire 
LINE. 

Chraibi-Kaadoud, I. (2020). Interprétabilité vs explicabilité : comprendre vs 
Intelligence mécanique. 
expliquer 
https://scilogs.fr/intelligence-mecanique/interpretabilite-vs-explicabilite-
comprendre-vs-expliquer-son-reseau-de-neurone-1-3/ 

neurones. 

réseau 

son 

de 

Giraudon, G., Guitton, P., Romero, M., Roy, D. et Viéville, T. (2020). 
Éducation et numérique : Défis et enjeux. INRIA. 

Guitton, P. et Viéville, T. (2020). Le numérique pour apprendre le 
numérique ? 
LeMonde.fr. 
https://www.lemonde.fr/blog/binaire/2020/01/20/savez-vous-que-demain-
on-pigera-tou %C2 %B7te %C2 %B7s-le-numerique 

binaire 

Blog 

- 

Houdé, O. (2019). L’intelligence humaine n’est pas un algorithme. Odile 
Jacob. 

Lagarrigue, A. et Viéville, T. (2021). Qu’est-ce que l’IA et qu’est-ce que ce 
n’est pas ? Lecture Jeune, 180. 

Mariais, C., Roche, D., Farhi, L., Barnabé, S., Cruchon, S., De Quatrebarbes, 
S. et Viéville, T. (2019). Peut-on former les enseignant·e·s en un rien de 
temps ? EIAH’19 Wokshop : Apprentissage de la pensée informatique de la 
maternelle à l’Université : retours d’expériences et passage à l’échelle. 

Rojas-Vazquez, T. (2020). L’inférence bayésienne : l’intelligence artificielle 
par la statistique. AJC. https://www.ajcact.org/2020/12/16/les-techniques-
algorithmiques-de-lia-linference-bayesienne/ 

Romero. M. (2018). Développer la pensée informatique pour démystifier 
l’intelligence artificielle. Bulletin de la société informatique de France, 12, 67-
75. 

Romero, M., Duflot, M. et Viéville, T. (2019). Le jeu du robot : Analyse d’une 
activité d’informatique débranchée sous la perspective de la cognition 
incarnée. Review of science, mathematics and ICT education, 13(1). 

Romero, M., Lefèvre, S.-C. et Viéville, T. (2020). When a Master of Sciences 
International Community. ERCIM News. 
on EdTech becomes an 
https://hal.inria.fr/hal-02418510 

Talbi, I. (2022). Explicabilité des modèles : ne croyez pas aveuglement ce 
que l’IA vous dit !. https://larevueia.fr/explicabilite-des-modeles-ne-croyez-
pas-aveuglement-ce-que-lia-vous-dit/ 

Viéville, T. et Guitton, P. (2020). Quels sont les liens entre IA et Éducation ? 
Le Monde. 

Viéville, T. et Salaun, Y. (2020). L’intelligence artificielle. Dans Enseignement 
scientifique Terminale. Hatier. 

Virgo, J., Pillon, J., Navarro, J., Reynaud, E. et Osiurak, F. (2017). Are you 
sure you’re faster when using a cognitive tool?. The American Journal of 
Psychology, 130(4), p. 493-503. 

Enseigner et apprendre à l’ère de l’intelligence artificielle Sommaire 

15 

 
2 /// COMMENT LA 
SCIENTOTHEQUE A 
L’UNIVERSITE LIBRE DE 
BRUXELLES INITIE 
ENSEIGNANTS ET 
ELEVES A L’IA DEPUIS 
2020 

Caroline Boulord1 
Yann-Aël Le Borgne1 2 
Patricia Corieri1 

1 La Scientothèque, Université Libre de Bruxelles, Belgique 
2 Machine Learning Group, Université Libre de Bruxelles, Belgique 

Un défi majeur du développement de l’intelligence artificielle (IA) est de 
tendre vers une plus grande inclusion des populations vulnérables et une 
distribution équitable de ses bénéfices potentiels. Ce chapitre présente les 
pistes explorées en ce sens par la Scientothèque, association ancrée dans 
la région bruxelloise et œuvrant depuis 20 ans pour l’accessibilité des 
nouvelles technologies aux populations marginalisées. Nous y décrivons, 
d’une part, les dispositifs pédagogiques mis en place depuis 2020 visant 
l’enseignement de l’IA et la formation des enseignants et, d’autre part, les 
retours d’expérience d’ateliers réalisés sur le thème de l’IA avec des jeunes 
issus de milieux précarisés. Au-delà de ces activités de formation et 
d’animation, le chapitre vise à illustrer l’importance du réseau associatif dans 
la création de ressources éducatives innovantes et dans la réduction de la 
fracture numérique. 

Présentation de la Scientothèque : l’égalité des 
chances par les sciences 

La Scientothèque est une association sans but lucratif installée au sein de l’Expérimentarium, 
musée de Physique de l’Université Libre de Bruxelles. Depuis sa fondation en 2001, sa mission 
principale est de contribuer à la diminution des inégalités sociales (voir la Figure 3). Deux 
réalités ont mené à la mise en place de l’association : d’une part, le risque accru de 
décrochage scolaire et la difficulté d’accès aux études supérieures pour les jeunes issus de 
milieux précarisés (Coslin, 2012) et, d’autre part, la désaffection pour les études scientifiques 
de la part du public féminin. Il a d’ailleurs été démontré qu’il était moins évident d’attirer les 
filles vers les projets à caractère scientifique ou technologique (Blanchard, 2021). La stratégie 

Enseigner et apprendre à l’ère de l’intelligence artificielle Sommaire 

16 

 
 
 
consistant à organiser des activités sur le thème de l’IA dans un cadre scolaire a l’avantage 
de permettre d’atteindre autant les filles que les garçons et représente un moyen de 
compenser ce biais lié au genre. 

Figure 3. Vision, mission et valeurs de La Scientothèque 

L’objectif premier de l’association est d’accompagner les jeunes de 4 à 20 ans lors d’ateliers 
scolaires et extrascolaires d’expérimentation où se côtoient sciences, technologies, ingénierie, 
arts et mathématiques (approche pluridisciplinaire STEAM). Dans cette optique, la 
Scientothèque apporte également un soutien aux enseignants et au personnel d’animation en 
charge des devoirs, notamment concernant l’introduction des outils numériques à l’école. Plus 
récemment, la crise sanitaire a eu « un effet loupe » sur les inégalités sociales, et de ce fait 
sur le phénomène de « fracture numérique » (Lucas, 2020 ; Fenoglio, 2021), raison pour 
laquelle les activités autour du numérique ont pris ces dernières années une place 
prépondérante au sein des ateliers et des actions menées par la Scientothèque. 

La devise de la Scientothèque est « l’égalité des chances par les sciences ». La spécificité de 
la mission de l’association est en effet de mener et promouvoir des activités selon la démarche 
STEAM pour lutter contre l’échec scolaire et les discriminations sociales, culturelles, mais 
aussi de genre. 

La démarche de la Scientothèque consiste à lutter contre le décrochage scolaire et les inégalités sociales, 
les deux étant liés, en proposant des activités aux jeunes selon la pédagogie par projet STEAM. 

Au fil du temps, avec le développement de son expertise et la visibilité grandissante donnée à 
ses projets, la Scientothèque a été de plus en plus sollicitée par les professionnels de 
l’éducation, dont les enseignants et les acteurs associatifs bruxellois, pour animer des ateliers 
STEAM6 à destination des jeunes dans leurs classes, pour partager les ressources mises au 
point ou encore pour développer des formations. Le positionnement de l’association est 
d’accompagner pour autonomiser, tout en développant un écosystème d’apprentissage 
collaboratif. 

Les principaux partenaires scolaires en Belgique sont l’école Marguerite Yourcenar à Laeken, 
l’Institut des Ursulines et le centre sportif Victoria à Koekelberg, l’Institut Saint-Charles à 
Molenbeek, l’école Escale à Woluwe Saint-Lambert ainsi que des écoles de devoirs. La 

6 Acronyme anglais signifiant Science, Technologie, Ingénierie, Art et Mathématiques. 

Enseigner et apprendre à l’ère de l’intelligence artificielle Sommaire 

17 

 
 
Scientothèque a également été un des partenaires du projet Fablab Mobile Brussels 7 
rassemblant les principaux Fablabs de Bruxelles, ainsi que d’autres initiatives de formation 
aux technologies et à la création. Un des aboutissements de ce projet a été la création du 
FabULaB’Kid dont l’aménagement a été achevé en mars 2020. L’association s’inscrit dans le 
développement de dispositifs innovants d’accompagnement des enseignants grâce à des 
projets européens multipartenaires : le projet CAI8 visant à rompre la solitude de l’enseignant 
en créant plusieurs possibilités d’échanges (plateformes de co-construction de ressources, 
discussion d’échange de pratique, webinaire), le projet ESERO Belgium9 financé par l’agence 
spatiale européenne et Belspo, dont la Scientothèque est coordinatrice pour la communauté 
francophone et germanophone, au côté de la KU Leuven qui assure la coordination globale et 
pour les communautés flamandes, œuvrant dans la diffusion et la promotion des STEM en lien 
avec les thématiques spatiales en milieu scolaire, et enfin le projet européen Dexterlab10 en 
collaboration avec différentes universités (France, Grèce, Espagne et Belgique) consistant à 
développer des ressources et un catalogue d’activités expérimentales éducatives en sciences 
basées sur la culture du fait maison et du do it yourself. 

L’approche pédagogique de la Scientothèque en 
matière d’IA 

Forte de 20 années d’expérience dans la pédagogie STEAM et, plus spécifiquement de 8 ans 
dans le développement d’activités liées à la programmation et aux Fablabs, la Scientothèque 
a récemment choisi de développer des projets pédagogiques autour du thème de l’IA pour les 
jeunes de 8 à 18 ans. Les deux axes principaux guidant les actions de l’association en matière 
d’éducation à l’IA sont les suivants : fournir aux jeunes des outils pour développer leur pensée 
critique et une réflexion éthique sur le sujet, et soutenir les enseignants dans la découverte et 
la transmission de la culture numérique et son appropriation. 

La méthodologie de la Scientothèque pour aborder le thème de l’IA est basée sur celle de la 
pédagogie par projet. Les activités sont conçues de manière à mettre l’expérimentation au 
centre et favoriser une participation active des jeunes au processus de création et de 
compréhension tout en les amenant à collaborer avec les autres. Les compétences et les 
connaissances développées grâce à cette approche s’inscrivent à plus long terme dans la 
mémoire et concourent à les remettre au cœur des apprentissages (Papert et Harel, 1991). Il 
s’agit d’une méthode de remédiation scolaire innovante pour prévenir le décrochage scolaire. 

UN CATALOGUE DE RESSOURCES PEDAGOGIQUES SUR L’IA 

En 2020, un premier travail de recension des ressources pédagogiques sur l’IA a été réalisé, 
tant celles portant sur des apprentissages éthiques que techniques. Ce catalogue a permis de 
rassembler et structurer, au sein d’une base de données, les ressources déjà mises au point 
par différentes organisations afin de dresser un état de l’art dans ce domaine. Le catalogue, 
recensant plus de 200 sources pédagogiques et sites d’intérêts, a été rendu accessible sous 
licence Creative Commons BY-SA et sous un format d’édition collaborative11. 

7 Les Fablabs sont des laboratoires de fabrication numérique et servent à l’expérimentation de matériel informatique, numérique 
ou électronique, au prototypage. Ce sont des lieux qui soutiennent l’apprentissage créatif par des situations authentiques. 
8 CAI – Communauté d’apprentissage de l’informatique, voir https://cai.community/ 
9 Le projet ESERO Belgique qui propose ressources et formation sur l’aérospatial, voir https://eserobelgium.be 
10 Le projet DexterLab, voir www.thedexterlab.eu 
11 Voir le catalogue de plus de 200 ressources : https://lascientotheque.github.io/ressources-ia 

Enseigner et apprendre à l’ère de l’intelligence artificielle Sommaire 

18 

 
À partir de ce catalogue, un ensemble complet de scénarios pédagogiques a été développé à 
destination des enseignants travaillant auprès d’élèves âgés de 8 à 14 ans. Par exemple, une 
activité vise à découvrir les inventions qui ont marqué l’histoire de l’IA grâce à un jeu de cartes, 
une à identifier les liens avec l’intelligence biologique à travers des expérimentations, une 
autre à comprendre la notion d’algorithme et les mécanismes d’apprentissage par 
renforcement par des activités débranchées. Certaines impliquent la programmation de robots 
Thymio12 ou bien à l’aide du logiciel Scratch, alors que d’autres ciblent des aspects éthiques 
et amènent à débattre des conséquences de l’IA sur la société. Les fiches pédagogiques ont 
été conçues par La Scientothèque ou sont issues et adaptées de ressources libres identifiées 
préalablement, et sont mises à disposition en ligne13. Un des avantages de cet ensemble 
d’activités tient à son caractère modulaire : il est possible de suivre l’ordre suggéré par le 
programme ou de composer un parcours adapté à ses besoins en sélectionnant tout ou partie 
des fiches pédagogiques. 

ACCOMPAGNEMENT DES ENSEIGNANTS 

Suivant les théories de la pédagogie constructiviste s’inscrivant dans la tradition piagétienne 
(Piaget, 1998) et de l’andragogie (Knowles et al., 2015), l’apprentissage des adultes est de 
plus en plus considéré comme autodirigé, voire autodéterminé. De nos jours, les 
développements théoriques dans le domaine de la pédagogie insistent de plus en plus sur le 
rôle proactif de l’adulte apprenant, et ceci est particulièrement illustré par les technologies 
numériques en constante évolution qui nécessitent un mouvement constant de va-et-vient 
entre l’apprentissage des compétences et leur application. Heureusement, ces technologies 
numériques nous donnent un accès individuel à une panoplie d’outils d’apprentissage, 
multipliant les possibilités d’exercer des choix dans son développement professionnel. 

Il a été constaté que l’impact des formations était moins grand lorsqu’elles ne sont pas suivies 
d’un accompagnement sur le terrain. En effet, une fois en classe, la personne enseignante se 
retrouve seule, face à une activité qu’elle n’a pas l’impression de maîtriser. Quant aux 
animations réalisées par des intervenants externes, qui peuvent présenter un intérêt ponctuel, 
elles génèrent rarement une évolution des pratiques de l’enseignant dans sa classe. À l’instar 
de ce que nous mettons en place pour les jeunes, il faut un contexte facilitant la mise en œuvre 
d’un nouveau savoir-faire. De plus, en rejoignant des enseignants et des associations sans 
but lucratif extérieures et en les mettant en relation, nous participons à créer un réseau à 
travers lequel les membres peuvent interagir, s’entraider et continuer à se former. 

Les formations destinées aux enseignants n’ont d’impact significatif et durable que si elles sont suivies d’un 
accompagnement et de possibilités d’échanges au sein de réseaux collaboratifs. La Scientothèque développe 
de tels dispositifs de suivi et de mise en relation : permanences, cocréation de ressources, conférences et 
mise en contact via des groupes de partage. 

Afin d’enrichir le processus traditionnel de formation en cours de carrière et en s’inspirant des 
développements pédagogiques mentionnés ci-dessus, la Scientothèque développe un 
ensemble de dispositifs pour la formation à l’IA des personnes enseignantes. Elle a notamment 
créé des permanences pour accompagner la mise en œuvre des ressources STEAM dans les 
classes et organisé des conférences scientifiques sur des thématiques de l’IA. Des 
enseignants ont aussi été mis en contact avec des doctorants ou des scientifiques du domaine 

12 Le robot Thymio est un petit appareil pourvu de deux roues indépendantes, de capteurs et de lumières. Il peut être programmé 
pour la détection d’objets et la détection de lignes au sol. 
13 L’ensemble de l’offre de services de la Scientothèque en lien avec l’IA : www.lascientotheque.be/pour-les-pros/nos-
ressources-steam/intelligence-artificielle/ 

Enseigner et apprendre à l’ère de l’intelligence artificielle Sommaire 

19 

 
de l’IA. Finalement, la Scientothèque pilote des réseaux de collaboration inter enseignants 
(p. ex. tous les mercredis en visioconférence ou via les réseaux sociaux) en plus de donner 
accès à des plateformes de partage de pratiques comme la plateforme CAI et des groupes 
Facebook. 

Retours d’expérience 

Une sélection d’activités a été proposée à deux groupes de jeunes de 10-12 ans durant l’année 
scolaire 2020-2021 lors d’ateliers extrascolaires hebdomadaires à l’Institut des Ursulines à 
Koekelberg. Ce projet, financé par la région de Bruxelles-Capitale, visait à diminuer le 
décrochage scolaire pour des élèves vivant dans des quartiers précarisés. Tout au long des 
séances, les jeunes ont pu, grâce à une approche ludique et collaborative, découvrir l’histoire 
des machines, établir des liens avec l’intelligence biologique, comprendre ce qui se cache 
derrière le mot « algorithme », observer et programmer des robots Thymio, s’initier à la 
programmation sur la plateforme Scratch, et débattre des conséquences de l’IA sur la société. 
Au fil des semaines, ils ont eu l’occasion d’aborder différentes disciplines scientifiques, 
renforçant ainsi certaines compétences déjà mises en place par l’école et se sont approprié la 
démarche scientifique : formulation de questionnements, confrontation d’hypothèses en 
collaboration avec les autres, mises à l’essai et retour sur la démarche. Ils ont dû mobiliser 
des compétences scientifiques et mathématiques (logique algorithmique, biologie du cerveau 
et du système nerveux, logiciels de programmation, robotique, principe d’apprentissage par 
renforcement, éthique). 

Figure 4. Activités à la Scientothèque pour la démystification de la programmation 

Aborder de manière concrète et ludique les concepts de base de l’IA, pourtant abstraits et complexes, permet 
aux jeunes d’acquérir des compétences techniques et des outils de réflexion critique sur le sujet dès l’âge de 
8 ans. 

La dimension expérimentale des activités a permis aux jeunes de comprendre les concepts, 
pourtant abstraits et complexes à aborder pour leur âge. En démystifiant par la programmation 
ou le jeu ce qu’est l’IA, les jeunes ont acquis des outils qui leur permettront d’entamer une 
réflexion critique sur les technologies. Ils savent désormais s’informer pour mieux comprendre 
et s’exprimer sur leurs propres usages, et sont sensibilisés à la présence, parfois invisible, 
mais pourtant réelle, de l’IA dans leur quotidien numérique. Les activités avaient aussi un 
caractère collaboratif. La nécessité de collaborer au sein des sous-groupes a amené les 
jeunes à prendre en compte l’avis de l’autre, que ce soit pour résoudre collectivement un 
problème donné ou via des jeux de groupes ou débats (p. ex. le jeu du labyrinthe pour 

Enseigner et apprendre à l’ère de l’intelligence artificielle Sommaire 

20 

 
appréhender le Q-learning, un modèle d’apprentissage par renforcement). Notons également 
l’apport d’un atelier sur le renforcement de la maîtrise de la langue française, particulièrement 
important pour les jeunes primo-arrivants. Certains élèves ont même émis le souhait de 
s’orienter vers des carrières en sciences ou en informatique à l’avenir. 

Figure 5. Activités débranchées et ludiques à la Scientothèque 

Enfin, les jeunes ont été amenés à réaliser en petits groupes des courtes vidéos, suivant un 
scénario établi par leurs soins, pour rendre compte de ce qu’ils ont retenu des expériences 
réalisées. Plusieurs formes ont été explorées : interview, témoignages, conférences 
scientifiques. Cela a permis aux jeunes de développer leur capacité à mettre des mots sur ce 
qu’ils ont appris et à prendre la parole en public. Les enfants ont apprécié le fait de pouvoir 
conserver une trace des ateliers et étaient enthousiastes et fiers à l’idée de pouvoir montrer la 
vidéo à leurs camarades, enseignants et leurs proches. Les capsules ont été utilisées pour la 
réalisation du montage de la vidéo finale disponible sur la chaîne Youtube de la 
Scientothèque14. 

Une évaluation avec les jeunes à la fin de l’année a confirmé qu’ils avaient pris plaisir à 
participer aux ateliers. Ils ont exprimé à l’unanimité avoir apprécié les activités et appris 
beaucoup. Les élèves ont montré un véritable enthousiasme pour les activités proposées, 
qu’elles soient débranchées ou sur ordinateur. Les témoignages recueillis sont un bon 
indicateur que l’objectif pédagogique visé, à savoir donner du sens et de l’intérêt aux matières 
scientifiques et mathématiques en s’amusant, est atteint : « J’ai beaucoup aimé quand on a 
fait le jeu de domino sur le langage binaire », « J’ai appris qu’on pouvait faire des matières 
qu’on n’aime pas forcément en jouant, c’était cool !», « Je sais maintenant ce qu’est un 
algorithme » ou « L’IA, en fait c’est des maths » nous disent différents élèves. 

Perspectives 

Les initiatives en matière de création de ressources pédagogiques, d’ateliers et de formations 
sur l’IA présentées dans ce chapitre sont nées de deux principaux besoins. Le premier est la 
nécessité croissante d’une éducation à l’IA, en particulier pour les jeunes publics, comme en 
témoignent les récents rapports sur le sujet de l’UNESCO (2021) ou de la Commission 
Européenne (Tuomi, 2018). Cette éducation vise d’une part à permettre aux jeunes d’acquérir 
et de développer une solide compréhension de l’IA – ce qu’elle est, comment elle fonctionne 
et comment elle est susceptible d’influencer leurs vies, et d’autre part à assurer que l’IA ne 
creuse pas les inégalités existantes. 

14 Extraits 
www.youtube.com/watch?v=4PgT3yHWbsE 

ateliers 

vidéo 

des 

2020-2021 

de 

la Scientothèque 

sur 

l’IA 

auprès 

des 

jeunes, 

voir 

Enseigner et apprendre à l’ère de l’intelligence artificielle Sommaire 

21 

 
 
Le second est la nécessité de créer ces ressources et de les intégrer dans les programmes 
éducatifs. En effet, la technologie de l’IA représentant un nouveau sujet pour les écoles, il 
n’existe encore que peu d’initiatives visant à définir les cadres de compétences et programmes 
d’enseignement associés pour les jeunes publics. Un aperçu de ces initiatives à l’international 
a été rendu disponible par l’UNESCO (2022), mettant en particulier en évidence le retard des 
pays francophones ou néerlandophones, comparativement à d’autres régions du monde telles 
que les Etats-Unis, l’Asie, ou le Moyen-Orient, où de tels programmes d’enseignements 
commencent à être rendus disponibles. 

Dans ce contexte, les dispositifs mis en œuvre par La Scientothèque se révèlent être parmi 
les premières initiatives concrètes sur le sujet en Belgique. L’intérêt de notre démarche a ainsi 
été reconnu au niveau fédéral par le ministère Stratégie et Appui, avec le récent soutien d’un 
projet visant une ambition plus large : AI4InclusiveEducation15. Le projet, coordonné par la 
Scientothèque et impliquant un consortium d’acteurs associatifs et universitaires, visera à 
développer des contenus éducatifs pilotes, en français et en néerlandais, pour initier à l’IA, la 
programmation, les données et la robotique. Ce contenu éducatif sera présenté, optimisé et 
enfin validé dans les associations partenaires et dans les réseaux éducatifs, et sera ensuite 
diffusé plus largement en libre accès dans l’optique de servir de référence aux personnels 
enseignants francophones et néerlandophones. 

Ressources complémentaires 

Site Web de la Scientothèque www.lascientotheque.be 

Le catalogue recensant plus de 200 sources pédagogiques et sites d’intérêts sur l’IA, accessible sous licence 
Creative Commons BY-SA. https://lascientotheque.github.io/ressources-ia 

Des fiches pédagogiques d’activités autour de l’IA à destination des enseignants conçues par La 
Scientothèque ou issues et adaptées de ressources libres, sont mises à disposition en ligne. 
www.lascientotheque.be/pour-les-pros/nos-ressources-steam/intelligence-artificielle 

Références 

Blanchard, M. (2021). Genre et cursus scientifiques : un état des lieux. 
Revue française de pédagogie. Recherches en éducation, (212), p. 109-143. 

Coslin, P. G. (2012). Précarité sociale et déscolarisation. L’orientation 
scolaire 
URL : 
http://journals.openedition.org/osp/3882 

professionnelle, 

(41/3). 

et 

Fenoglio, P. (2021). Au cœur des inégalités numériques en éducation, les 
inégalités sociales. Dossier de veille de l’IFÉ, (139). http://veille-et-
analyses.ens-lyon.fr/DA/detailsDossier.php?parent=accueil&dossier=139 

UNESCO. (2021). IA et éducation. Guide pour les décideurs politiques (56 
pages). Organisation des Nations unies pour l’éducation, la science et la 
culture. https://unesdoc.unesco.org/ark:/48223/pf0000380006 

15 Le projet AI4InclusiveEducation visant le développement de ressources en français et en néerlandais auquel participe la 
Scientothèque, voir www.digit-all.be 

Enseigner et apprendre à l’ère de l’intelligence artificielle Sommaire 

22 

 
Knowles, M. S., Holton III, E. F. et Swanson, R. A. (2014). The adult learner: 
The definitive classic in adult education and human resource development. 
Routledge. 

Lucas, J.-F. (2020). La Covid-19, accélératrice et amplificatrice des fractures 
numériques. Chaire « Numérique, gouvernance et souveraineté » de 
Sciences Po. https://hal.science/hal-03004991/document 

Papert, S. et Harel, I. (1991). Situating constructionism. Constructionism, 
36(2), p. 1-11. 

Piaget, J. (1998). De la pédagogie. Odile Jacob. 

Tuomi, I. (2018). The impact of artificial intelligence on learning, teaching, 
and education. Luxembourg: Publications Office of the European Union. 

UNESCO. (2022). K-12 AI curricula: a mapping of government-endorsed AI 
curricula. UNESCO Publishing. 

Enseigner et apprendre à l’ère de l’intelligence artificielle Sommaire 

23 

 
 
3 /// SENSIBILISER 75 % 
DES ELEVES DE 
COLLEGE DES ALPES-
MARITIMES A L’IA : LE 
PROJET ARC-EN-CIEL 
PILOTÉ PAR LA MAISON 
DE L’INTELLIGENCE 
ARTIFICIELLE 

Florence Tressols1 
Jérémy Camponovo2 

1 Maison de l’intelligence artificielle, France 
2 Délégation régionale académique du numérique pour l’éducation, Académie de Nice, France 

Le projet Arc-en-ciel piloté par la Maison de l’intelligence artificielle (MIA) à 
Sophia Antipolis poursuit l’objectif de sensibiliser à l’intelligence artificielle 
(IA) 75 % des collégiens des Alpes-Maritimes d’ici 2023. Il est structuré en 
quatre chantiers : les activités pédagogiques à la MIA, les stages scolaires 
ou périscolaires, la sensibilisation aux biais et stéréotypes de genre en IA, et 
les activités hors les murs sur le territoire départemental. Autant les 
réalisations que l’étendue des partenariats qui les ont rendues possibles sont 
abordées dans le chapitre. 

Qu’est-ce que le projet Arc-en-ciel? 

Le projet Arc-en-ciel est une initiative du SMART Deal des Alpes-Maritimes dont le pilotage a 
été confié à la Maison de l’intelligence artificielle (MIA) située dans la technopole Sophia 
Antipolis dans le département des Alpes-Maritimes en France. La cible principale de ce projet 
est de sensibiliser, entre 2020 et 2023, 75 % des collégiens du département à l’IA. Plus 
spécifiquement, il poursuit trois objectifs : (1) contribuer à l’éducation des collégiens des Alpes-
Maritimes via une approche pratique et thématique, (2) partager des usages concrets de l’IA 
par les industries et entreprises locales, et (3) mettre en lumière les compétences des 
personnes œuvrant dans le domaine de l’IA pour susciter des vocations. 

Enseigner et apprendre à l’ère de l’intelligence artificielle Sommaire 

24 

 
 
 
Figure 6. Un des espaces de la MIA à Sophia Antipolis, la salle de démonstration où les personnes sont invitées à 
découvrir et expérimenter des cas d’usages de l’IA 

Ce chapitre présente d’abord les réalisations du projet Arc-en-ciel depuis son démarrage en 
2020, notamment l’organisation de stages scolaires et périscolaires, des visites de la MIA par 
des groupes scolaires et des activités de médiation scientifique réalisées directement dans les 
collèges. Dans un deuxième temps, le contexte plus général dans lequel le projet a été réalisé 
sera présenté. Il sera question des différents partenariats et ententes qui ont mené à 
l’ouverture de la MIA en 2020, de sa raison d’être et des collaborations qu’elle entretient avec 
le monde de la recherche, principalement sur les questions d’enseignement de l’IA et d’équité 
des genres. 

Les réalisations du projet Arc-en-ciel 

La banque d’activités de médiation scientifique, représentant une cinquantaine d’activités 
considérées comme stables sur différents thèmes de l’IA, est incontestablement l’une des 
réalisations phares du projet. Les activités scientifiques et culturelles sont choisies par l’équipe 
de médiation en fonction de publics cibles et des discussions préalables avec les enseignants 
responsables des groupes scolaires. Le choix des activités repose sur des paramètres variés : 
le message principal à véhiculer, le message secondaire, le public cible, les techniques d’IA, 
le nombre de personnes requis pour l’animation, allant même jusqu’à inclure de l’information 
sur le poids des équipements qui doivent être transportés comme l’éclairage. Actuellement, 
des activités sont en cours dans une phase de mise à l’essai et de perfectionnement, ce qui 
devrait accroître le nombre de médiations. 

À l’issue de la première année (2020-2021), 2 982 élèves du collège (soit 33 % des collèges 
du département des Alpes-Maritimes) ont fait l’expérience d’au moins une activité : visite sur 
place à la MIA, avec démonstration sur des cas d’usages de l’IA, visite dans l’établissement 
scolaire, stage scolaires et/ou périscolaires, ou encore formation dispensée par la Délégation 
régionale académique du numérique éducatif (DRANE) en collaboration avec la MIA. Des 
formations ont aussi été offertes sur place à 30 enseignants (par la DRANE et l’organisme 
Terra Numerica situé à Sophia Antipolis). Dans le contexte de ses Mercredis enseignants, la 
Délégation académique à l’éducation artistique et culturelle a organisé en 2021-2022 trois 
visites à la MIA. Précisons que la MIA a aussi participé à des réunions de professeurs 

Enseigner et apprendre à l’ère de l’intelligence artificielle Sommaire 

25 

 
documentalistes: c’est ainsi que la conception de l’exposition « IA by MIA Arc-en-ciel », à 
destination d’usages pédagogique dans les écoles, a été facilitée. 

Formellement, le projet Arc-en-ciel se décompose en quatre chantiers qui sont présentées 
succinctement ci-après. 

CHANTIER #1 : ATELIERS PÉDAGOGIQUES EN LIGNE ET PARCOURS IN SITU 

Ce chantier vise le développement de la banque d’activités pédagogiques et des scénarios 
pédagogiques de visite des espaces de la MIA. En contexte de médiation scientifique, les 
contraintes de temps sont importantes et les activités doivent être conçues de façon à atteindre 
les objectifs d’apprentissage sans possibilité de prolongation. Pour cette raison, plusieurs 
activités sont destinées à être réalisées en 20 minutes auprès de demi-classes, permettant 
une alternance entre quelques types d’activités auprès d’un groupe-classe à l’intérieur d’une 
période d’environ deux heures, incluant les transitions. 

Ces activités se définissent comme de nouvelles ressources pour les enseignants qui disent 
ne pas se sentir encore suffisamment outillés pour le faire en classe (Lin et Van Brummelen, 
2021). Ainsi la MIA se charge-t-elle de sensibiliser notamment aux enjeux éthiques de l’IA, en 
permettant aux élèves de découvrir, comprendre et expérimenter plusieurs cas d’usage de 
l’IA, comme l’indiquent la liste des activités présentée ci-dessous : 

ACTIVITES 
Une histoire de l’IA de l’Antiquité à nos jours 
Usage de drones 
Apprentissage automatique pour classifier des images 
Jeu d’échecs et algorithme 
Voyage en train pour découvrir l’aide à la décision 
Expérimentation de Machine Learning for Kids 
Reconnaissance de chiffres via réseau de neurones 

ACTIVITES (SUITE) 
Automatisme ou autonomie avec le robot AlphAI 
Le phénomène des hypertrucages (Deep Fakes) 
Je programme mon neurone artificiel en Python 
Je programme mon neurone artificiel en Scratch 
Dilemmes de la Moral Machine du MIT 
Robot d’assistance thérapeutique PARO 
Quiz « Intelligent » vs « Pas intelligent » 

Tableau 1. Exemples d’activités développées et offertes à la MIA 

CHANTIER #2 : ENTREPRENDRE À L’ÈRE DE L’IA 

L’objectif de ce chantier est d’offrir aux élèves des occasions de développer leurs capacités 
entrepreneuriales. Plus spécifiquement, ce chantier cherche à développer l’agentivité des 
personnes dans un environnement de plus en plus marqué par l’IA afin qu’elles puissent 
contribuer elles-mêmes, dans le futur, à transformer cet environnement (Engeström et 
Sannino, 2013). Elles sont ainsi placées dans une posture de création face au numérique et 
non plus seulement dans une posture de consommation d’outils d’IA. Elles doivent « se 
prendre en main » et prendre conscience qu’il est possible de participer activement au 
développement de ce domaine. Ce chantier les incite à se positionner par rapport à l’IA, ne 
serait-ce qu’en prenant conscience de leur niveau d’intérêt, de leurs craintes ou de leurs 
croyances, de leurs appréhensions ou de leur confiance à en apprendre les rudiments. Cette 
approche permet aussi de faire évoluer les représentations des élèves (déconstruire et 
construire) (Ghotbi et Ho, 2021). 

Le chantier « Entreprendre à l’ère de l’IA » a pris la forme de stages scolaires et périscolaires. 
Les stages scolaires, offerts à des élèves de 3e année, étaient des stages d’observation. Les 
participants étaient jumelés à une entreprise pour y observer comment l’IA est exploitée et 
explorer une profession dans le domaine. Les stages périscolaires, d’une durée d’une 
semaine, ont été réalisés principalement pendant les périodes de vacances (p. ex. vacances 
de la Toussaint ou du printemps). Pendant une semaine intensive, les participants sont mis à 

Enseigner et apprendre à l’ère de l’intelligence artificielle Sommaire 

26 

l’œuvre pour la réalisation d’un projet d’envergure impliquant l’IA. Les activités des cinq jours 
sont partagées entre des activités d’expérimentations pratiques de l’IA, des activités 
débranchées pour comprendre la logique algorithmique, et des activités d’idéation qui mettent 
en œuvre des méthodes de Design Thinking. Au début de la semaine, une problématique est 
proposée. Par exemple, une des problématiques était « Comment l’IA peut être utile au 
sport ? », une autre « Comment l’IA peut-elle contribuer à la maîtrise des consommations 
énergétiques ? ». L’équipe de médiation propose alors aux participants de réaliser des cartes 
d’empathie, c’est-à-dire de tenter de se placer dans la peau des acteurs concernés par la 
problématique. Dans le cas de l’utilisation de l’IA dans le sport, les stagiaires étaient invités à 
se placer dans la peau des entraîneurs, des personnes pratiquant des sports ou bien des 
spectateurs). Deux prototypes ont été réalisés, un avec des blocs LEGO© (voir Figure 7) et 
un autre en format numérique. La semaine culmine, le vendredi après-midi, avec la présence 
d’un jury bienveillant qui évalue les résultats et qui remet des prix aux équipes. Ce partage 
permet aux élèves de découvrir, comprendre et expérimenter l’IA, en plus de développer des 
compétences interpersonnelles. Celles qui sont les plus souvent citées par les stagiaires sont 
la persévérance, la coopération et la créativité. 

Figure 7. Exemple de maquette réalisée dans le cadre d’un stage périscolaire 

CHANTIER #3 : SE CONSTRUIRE SANS PREJUGE 

Le domaine des technologies est encore l’objet de stéréotypes portant sur les hommes et les 
femmes. Toutes les activités du projet Arc-en-ciel sont très sensibles à cet enjeu et se veulent 
des vecteurs de changement des mentalités et des pratiques. L’objectif de ce chantier est donc 
de sensibiliser les équipes enseignantes, les équipes de médiation pédagogique et les élèves 
aux biais de genre dans le domaine de l’IA. Par exemple, Norouzi et al. (2020), dans le cadre 
d’un projet d’initiation à l’IA, ont été confrontés au fait que les filles avaient beaucoup moins 
confiance que les garçons en leurs compétences en programmation informatique. À la MIA, 
nous observons aussi des manifestations de stéréotypes persistants. 

Ce chantier, piloté par une membre du Club égalité des Alpes-Maritimes travaillant chez 
l’organisme Alter Egaux, a permis de valoriser trois réalisations : d’abord, le livret « Toustes 
numériques » à destination des élèves et des équipes enseignantes16. Cette mallette prend la 

16 La mallette « Toustes numériques » est disponible gratuitement en 
www.alteregaux.org/mallette-toustes-numeriques 

ligne sur 

le site Web d’Alter Egaux : 

Enseigner et apprendre à l’ère de l’intelligence artificielle Sommaire 

27 

 
 
forme d’un guide d’une trentaine de pages dans lequel les personnes sont invitées à identifier 
des stéréotypes de genre et à se questionner sur leurs propres préjugés. Elle propose des 
activités pédagogiques courtes destinées à sensibiliser une classe à ces stéréotypes. La 
seconde réalisation est composée des études réalisées en partenariat avec le Laboratoire 
d’innovation pour le numérique en éducation de l’Université Côte d’Azur et, à nouveau, Alter 
Egaux. Les élèves de passage à la MIA ont été invités à compléter un court questionnaire 
avant et après leur visite, incluant des questions relatives à leur perception des stéréotypes 
de genre. Des membres d’Alter Egaux ont aussi créé des outils d’observation des activités de 
médiation scientifique et partagé leurs analyses avec l’équipe. Finalement, un jeu interactif 
intitulé « La mixité dans les métiers de l’IA » a été réalisé pendant les stages périscolaires. 

La phase préliminaire des observations d’Alter Egaux a permis d’établir un certain nombre de 
constats. D’abord, au sein des groupes mixtes, en raison de la socialisation sexiste 
différenciée des garçons et des filles, les garçons ont tendance à monopoliser la parole et 
l’attention et les filles à s’effacer. On retrouve ce même phénomène lors des interventions de 
la MIA, accentué par le prisme des exemples donnés (majoritairement des domaines à forte 
prédominance masculine : football, secteur militaire, etc.), l’absence de langage épicène et de 
rôle modèle féminin. De plus, il a été observé que les garçons se placent à l’avant de la salle 
et sont donc davantage dans le champ de vision des animateurs comme une preuve de leur 
intérêt plus important que celui des filles pour ces sujets avant même le début des 
interventions. Les animateurs ont observé que la plupart des garçons souhaitent expérimenter, 
manipuler, tester et se placent donc en premier lors des phases de manipulation. Les garçons 
passent souvent en premier tant dans la prise de parole que dans la manipulation des objets. 
Les animateurs observent un impact plus important sur les garçons que sur les filles, 
indépendamment du sexe de l’animateur. 

Soulignons finalement que, dans le contexte de la journée internationale des droits des 
femmes célébrée le 8 mars 2022, la MIA est intervenue dans des classes avec WHAT06 
(Women Hackers Action Tank – département 06) et Alter Egaux pour échanger avec les 
élèves, filles et garçons, sur la mixité des métiers scientifiques, numériques et intégrant l’IA. 
La rencontre de femmes inspirantes dans le domaine des technologies a contribué à faire 
tomber certaines barrières. Une des animations pédagogiques portait sur les compétences 
interpersonnelles et prenait la forme d’un débat interactif suivant la rencontre de 
professionnels de l’IA. Cette activité montre que les valeurs de coopération, flexibilité, 
persévérance, analyse, organisation, créativité, leadership et précision n’ont pas de genre. En 
2022, dix classes de 3e année de collège ont ainsi été sensibilisées. 

CHANTIER #4 : IA HORS LES MURS 

Initié en juin 2021, ce dernier chantier du projet Arc-en-ciel vise la population du département 
des Alpes-Maritimes éloignée de la MIA (littoral, moyen et haut pays). Concrètement, des 
équipes de la MIA et de ses partenaires sont appelées à se déplacer pour aller à la rencontre 
de différents publics et encourager le dialogue sur des questions relatives à l’IA. Le chantier 
est copiloté par une membre des Petits Débrouillards. 

Les activités réalisées dans le cadre de la première année sont nombreuses et témoignent du 
succès de l’approche collaborative et partenariale de la MIA : d’abord, un projet pilote 
d’intervention en classe a été mené dans les vallées sinistrées par la tempête Alex sous le 
leadership d’Ingénieurs pour l’école de la Délégation régionale académique de la formation 
professionnelle initiale et continue. De même, à partir d’août 2021, des animations ont été 
réalisées sur le littoral, à Cannes, dans le contexte des « bibliothèques de plage ». En mars 

Enseigner et apprendre à l’ère de l’intelligence artificielle Sommaire 

28 

2022, une première activité à grand déploiement est réalisée dans le cadre du Tour Science 
IA, en collaboration avec les Petits Débrouillards au collège Jean Cocteau à Beaulieu-sur-Mer, 
puis au collège Les Mimosas dans le cadre de la Semaine de l’IA. Dans ce collège, ce sont 
tous les élèves de 6e, 4e et 3e qui ont été sensibilisés à l’IA. 

LA MIA : UN TERRAIN DE RECHERCHE ET D’EXPERIMENTATION 

Les activités réalisées dans le cadre des quatre chantiers du projet Arc-en-ciel sont innovantes 
à plusieurs égards. Ainsi est-il apparu pertinent de documenter leur évolution dans une 
perspective d’amélioration continue, mais aussi pour inspirer et orienter des initiatives futures. 
Des activités d’observation des élèves, des équipes enseignantes et des équipes de médiation 
pédagogique ont lieu en collaboration avec des partenaires académiques et communautaires. 

D’abord, à l’issue de chaque activité de médiation in situ ou hors les murs, un questionnaire 
de retour d’expérience est proposé à l’équipe enseignante, à remplir avec la classe. Outre le 
fait que cette action facilite la réalisation d’activités post-visites à l’école, l’objectif est de 
quantifier et qualifier plusieurs dimensions de l’animation. Les élèves sont invités à se 
prononcer sur les aspects qu’ils ont le plus appréciés ou qu’ils ont trouvés les moins 
intéressants, et à suggérer des changements. Ces données sont analysées par l’équipe de la 
MIA et feront l’objet d’une publication. 

Dans le cadre du GTNum Scol\_IA, à chaque début et fin de visite de deux heures, les élèves 
sont invités à répondre à un questionnaire électronique comportant 12 questions sur 
l’intelligence humaine et l’IA. L’objectif est d’évaluer l’évolution des représentations de l’IA 
avant et après les activités de médiation. Cette étude scientifique est conduite par le 
Laboratoire d’innovation pour le numérique en éducation. En outre, lors des stages scolaires 
ou périscolaires, les stagiaires sont invités à s’autoévaluer par rapport à cinq dimensions : leur 
connaissance de l’IA, le métier qu’ils aimeraient exercer plus tard, leurs craintes par rapport à 
l’IA, leur ressenti par rapport à l’IA et leurs attentes par rapport au stage. Cette autoévaluation 
a été conçue par Alter Egaux. 

Un exemple de projet : la ruche intelligente 

À l’occasion de la Fête de la Science 2021, la MIA a proposé la réalisation d’un hackaton, qui 
a évolué en IAckathon17, sur la thématique de la ruche intelligente, un projet ayant impliqué 
des élèves de la 6e à la 3e (soit 85 élèves issus de quatre collèges accompagnés d’une dizaine 
d’enseignants). 

Les réalisations issues de cet événement, auquel participaient les FabLabs des collèges en 
réponse à un appel de la Direction régionale académique du numérique éducatif (DRANE), 
ont été exposées au World AI Cannes Festival. 

Dans le Tableau 2, nous décrivons la contribution de chaque collège au projet et dans la Figure 
8 partageons un extrait de la présentation du prototype réalisé par des élèves et leur 
enseignante, qui ont pu bénéficier de l’animation pédagogique des équipes de la DRANE et 
de la MIA. Grâce à son ancrage local, le projet a pu bénéficier de l’expertise des apiculteurs18 

17 Un hackaton est un événement où des participants doivent inventer des solutions innovantes, notamment informatiques, à des 
problèmes d’intérêt public en un court laps de temps, parfois en une seule journée. Ici, le terme IAckathon est un jeu de mot 
original pour souligner l’usage de l’IA. 
18 Une entrevue avec un apiculteur, réalisée par la DRANE, a été présentée aux élèves en guise d’introduction au IAckathon. 

Enseigner et apprendre à l’ère de l’intelligence artificielle Sommaire 

29 

 
de l’association Bee Riviera, et ainsi s’appuyer sur un cahier des charges pour concevoir la 
« ruche intelligente ». Sans oublier l’expertise et le pilotage de la conception par le SoFAB 
Telecom Valley au bénéfice de la réalisation du dispositif. 

L’objectif du IAckathon était de réaliser un projet interdisciplinaire intégrant l’IA et poursuivant 
une visée de développement durable. La thématique de la ruche intelligente a donc été choisie 
parce qu’elle est suffisamment porteuse pour s’inscrire dans plusieurs disciplines et pas 
uniquement dans les matières scientifiques. Le développement durable peut être abordé via 
l’idée de préservation de la biodiversité, ou encore de l’économie des ressources en utilisant 
l’edge computing19 (Shi et Dustdar, 2016). 

COLLEGE 
Collège Pierre Bertone, Antibes 
Via leur FabLab (classe de 3e) 
Collège du Centre International, Valbonne 
Via leur FabLab (classe de 6e) 

Collège Auguste Blanqui, Puget-Théniers 
Via leur campus connecté (classes de 4e et 3e) 

Collège Les Mimosas, Mandelieu-la-Napoule 
Via leur FabLab (classes de 6e à 3e) 

CONTRIBUTION 
Les élèves ont mis en lumière la problématique interdisciplinaire des 
ruches intelligentes, en collaboration avec l’apiculteur. 
Les élèves ont expérimenté l’acquisition de données avec des capteurs 
utiles à la découverte de la vie d’une colonie d’abeilles avec des 
solutions dites d’Internet des objets. 
Les élèves ont cherché à découvrir et comprendre l’emplacement 
adéquat de capteurs dans une ruche et ont analysé les besoins en 
énergie. 
Les élèves ont expérimenté l’apprentissage automatique pour améliorer 
la connaissance des activités d’une colonie d’abeilles. Une présentation 
du résultat par les élèves, les enseignants et le personnel de la MIA est 
disponible en vidéo20. 

Tableau 2. Contributions des élèves de quatre collèges des Alpes-Maritimes au IAckathon sur la thématique de la 
ruche intelligente lors de la Fête de la Science 2021 

Figure 8. Présentation du prototype de ruche intelligente par des élèves et leur enseignante 

Genèse du projet Arc-en-ciel 

Le projet Arc-en-ciel21 n’aurait pas pu se développer et être déployé sans avoir reçu l’appui de 
nombreux acteurs qui ont su créer les conditions de son succès. Ce projet est une preuve 
tangible qu’il est possible de coordonner plusieurs administrations et partenaires en vue de 
réaliser des projets pédagogiques concrets. En moins de deux ans, le projet est passé d’une 
volonté politique à des activités concrètes sur tout le territoire du département. Cette section 
présente le plan de transition numérique SMART Deal dans lequel dans lequel s’inscrit le projet 

19 L’edge computing est une approche informatique dans laquelle le traitement des données est réalisé au plus près de leur point 
de collecte pour éviter le transit inutile et coûteux de l’information vers des serveurs centralisés. 
20 Pour voir 
https://youtu.be/oaRh8yR4ENU. 
21 Ce chapitre a été rédigé en juin 2022. 

la présentation des élèves du Collège Les Mimosas sur 

intelligente, voir 

le projet de 

ruche 

Enseigner et apprendre à l’ère de l’intelligence artificielle Sommaire 

30 

 
 
Arc-en-ciel (SMART Education), la structure de gouvernance et les collaborations avec des 
organismes aux mandats complémentaires. 

LE PLAN DE TRANSITION NUMÉRIQUE SMART DEAL 

En janvier 2018, le plan de transition numérique SMART Deal du département des Alpes-
Maritimes a été lancé par le président Charles Ange Ginésy. Ce plan poursuit deux objectifs : 
(1) moderniser et améliorer les performances de l’administration départementale afin d’offrir 
un meilleur service aux usagers, et (2) répondre aux enjeux du territoire (p. ex. les risques 
naturels) tout en améliorant la qualité de vie et le quotidien de la population. Le comité 
d’experts du SMART Deal, piloté par Marco Landi, a retenu deux thématiques de travail en 
lien avec les compétences départementales : SMART Territory et SMART Education. 

Moins de trois ans après le lancement du SMART Deal, la MIA a été inaugurée le 10 mars 
2020. Quelques mois plus tard, le projet Arc-en-ciel dont il a été question dans la première 
partie a été lancé. La vision du projet a été élaborée par Jean-Marc Gambaudo, président de 
l’Université Côte d’Azur, Marco Landi, président du comité d’experts du SMART Deal et Paul 
Sgro, directeur de la MIA. La coordination du projet a été assurée par Marie Hering, chargée 
de mission pour le SMART Deal, et l’animation par Florence Tressols, experte SMART 
Education. Mentionnons également le soutien indéfectible de la DRANE, pierre angulaire 
activement représentée depuis les débuts par Jérémy Camponovo. La Figure 9 présente une 
photo prise lors de la signature de l’entente pour le projet Arc-en-ciel. 

Figure 9. Signature de l’engagement multipartite pour le projet Arc-en-ciel le 14 septembre 2020 à la MIA 

De gauche à droite : Charles Ange Ginésy, président du Département des Alpes-Maritimes, Maureen Clerc, directrice 
de l’Inria Sophia Antipolis Méditerranée, Richard Laganier, recteur de l’Académie de Nice, Jeanick Brisswalter, 
président de l’Unviersité Côte d’Azur, Aurélie Philippe, déléguée régionale du CNRS Côte d’Azur. 

STRUCTURE DE GOUVERNANCE 

Deux structures parallèles ont donc été mises en place : un comité de pilotage pour les 
questions stratégiques et politiques, et un groupe projet pour les questions opérationnelles et 
tactiques. Chaque structure est composée de trois collèges : institutionnel, académique, et 
industrie & commerce, dont la composition et le rôle sont présentés dans le Tableau 3. 

Enseigner et apprendre à l’ère de l’intelligence artificielle Sommaire 

31 

 
 
 
STRUCTURE 
Comité de 
pilotage 

COLLEGE 
Institutionnel Coordination et 

ROLE 

financement 
Académique Valider le fil 
conducteur 
pédagogique et 
les contenus 

Industrie & 
commerce 

Proposer des 
ateliers, des 
retours 
d’expériences, 
des 
conférences, 
des MOOC 

Groupe projet 

Institutionnel Suivi et 

MEMBRES OU PARTENAIRES 
Membres issus de la Communauté d’agglomération Sophia Antipolis, 
du Département des Alpes-Maritimes et de la MIA 
Membres issus du CNRS, de la Délégation régionale académique au 
numérique éducatif, de la Délégation artistique et culturelle, de la 
Délégation régionale académique Provence-Alpes-Côte d’Azur à la 
formation professionnelle, initiale et continue, de la Délégation à la 
recherche et à l’innovation, de l’Inria et de l’Université Côte d’Azur. 
Membres issus de la Chambre de commerce et d’industrie Nice Côte 
d’Azur, du Cluster IA (une association ayant pour but de réunir 
l’ensemble des acteurs de l’IA incluant universités, PME et 
collectivités), de l’Industrial council of artificial intelligence research) et 
Women Hackers Action Tank 06 (un collectif qui rend visibles les 
femmes travaillant dans le domaine de la technologie et fait découvrir 
les métiers de l’informatique aux femmes et aux jeunes filles). 
Membres issus de la MIA et de l’Université Côte d’Azur. 

copilotage des 
quatre chantiers 

Académique Suivi et 

copilotage des 
quatre chantiers 
Suivi des quatre 
chantiers 

Industrie & 
commerce 

Membres issus de la Délégation régionale académique Provence-
Alpes-Côte d’Azur à la formation professionnelle, initiale et continue, 
de Terra Numerica et de l’Université Côte d’Azur. 
Membres issus du Club égalité des Alpes-Maritimes22, du Code Club 
de Sophia Antipolis. Le Sophia Club Entreprises, représentant les 
entreprises de la technopole, et le Rectorat des Alpes-Maritimes, 
représentant les collèges, ont signé une convention de partenariat 
dont l’objet est d’encadrer les interventions des ingénieurs volontaires 
au sein des établissements scolaires partenaires. 

Tableau 3. Structure de gouvernance du projet Arc-en-ciel 

COLLABORATIONS AVEC DES ORGANISMES AUX MANDATS COMPLÉMENTAIRES 

La MIA participe à des activités conjointes avec d’autres acteurs du domaine de la culture 
scientifique, technique et industrielle. Dès lors, cela permet aux acteurs de partager leurs 
visions et de sensibiliser de concert les élèves à travers le prisme de diverses initiatives 
locales, nationales et internationales. Avec pour objectif, et non des moindres, que cette mise 
en commun enrichisse les méthodes de médiation pédagogique. 

Dans cette perspective, la MIA s’est investie dans d’autres événements : 

– Lors de la Fête de la Science 2021, en plus du IAckathon sur le thème de la ruche 
intelligente dont il a été question, la MIA a organisé un « village des sciences » et a 
proposé un programme ambitieux avec 15 partenaires (des académiques, des 
entreprises innovantes, des grands groupes membres du Industrial council of artificial 
intelligence research). 

– Lors de la Semaine du cerveau 2022, sur les villages des sciences de Villeneuve-
Loubet et d’Antibes Juan-les-Pins, des ateliers scientifiques ont été offerts aux publics 
scolaires sur la thématique de l’évolution des méthodes d’apprentissage cognitif à l’ère 
numérique. Les ateliers étaient animés par le Laboratoire d’innovation pour le 
numérique en éducation et le programme de MSc SmartEdTech de l’Université Côte 
d’Azur. Une activité #CreaCube était proposée dans laquelle les participants devaient 
résoudre des défis créatifs à l’aide de blocs de robotique assemblables ayant des 
fonctions variées (tels que des capteurs, moteurs, éclairage). Une activité sur l’IA et la 
biologie était aussi proposée. 

22 Le Club égalité des Alpes-Maritimes a été créé en 2015 par Alter Egaux et la Délégation aux droites des femmes de la 
Préfecture des Alpes-Maritimes. Il est sous le patronage d’Élisabeth Moreno, ministre déléguée auprès du Premier ministre, 
chargée de l’égalité entre les femmes et les hommes, de la Diversité et de l’Égalité des chances. Le Club égalité regroupe plus 
de 130 membres qui mettent en commun leurs idées et leurs énergies pour travailler ensemble à la réduction des inégalités à 
toutes les échelles de la société. 

Enseigner et apprendre à l’ère de l’intelligence artificielle Sommaire 

32 

 
– Lors des visites scolaires combinées entre la MIA et Terra Numerica, puisque ces deux 
lieux sont situés à proximité de Sophia Antipolis et permettent aux établissements 
d’optimiser les transports en autorisant le déplacement de deux classes en même 
temps. 

Conclusion 

Depuis plus de deux ans, les activités de médiation pédagogique réalisées par la MIA dans le 
contexte du projet Arc-en-ciel mettent en lumière que la sensibilisation à l’IA est possible 
pourvu que l’on ait réfléchi au matériel nécessaire, aux algorithmes à démystifier et aux cas 
d’usage à discuter. Les activités sont soutenues par des acteurs institutionnels, académiques 
et industriels, ce qui s’inscrit dans la vision holistique de l’IA qu’entretient la MIA. Les 
thématiques de culture, de territoire et de la vie quotidienne concrétisent les cas d’usage avec 
un ancrage dans la réalité. Par ses quatre chantiers, le projet Arc-en-ciel met tout en œuvre 
pour atteindre sa cible : sensibiliser les collégiens du département à l’IA. Les autres projets, 
dont sa participation à plusieurs événements comme la Fête de la Science ou la Semaine du 
cerveau, doivent contribuer à élever le niveau de littératie (numérique) de tous les maralpins. 

Six pensées à emporter sur l’IA issues d’une séance de 
Design Thinking 

1. L’IA n’est pas magique : c’est un cas d’usage, du matériel, des données et un type d’algorithme. 

2. L’ère de l’IA est une nouvelle révolution et c’est un outil scientifique, technique et économique. 

3. L’IA est déjà répandue dans de nombreux domaines d’activité, avec un impact présent et potentiellement 
futur. 

4. Les usages de l’IA peuvent être une chance ou un risque pour l’humanité. 

5. Il est nécessaire de légiférer et d’encadrer pour un usage éthique de l’IA. 

6. Et moi dans tout ça ? L’IA a un fort potentiel pour mon travail futur et je peux être acteur pour des usages 
citoyens éclairés. 

Les activités et services de la MIA sont référencés dans le catalogue Ac’Educ, une initiative du Département 
des Alpes-Maritimes. https://aceduc.departement06.fr/ac-educ-06-14518.html 

Références 

Chauvel, D., Tressols, F. et Despres, C. (2012). The open innovation of 
management & organization. Management in the knowledge economy. New 
success. 
managerial 
https://www.academia.edu/es/1831674/The\_Open\_Innovation\_OF\_manag
ement\_and\_organization 

models 

for 

EPSAA (2018). Interview de Florence Tressols sur la Culture de l’innovation, 
MOOC 
numérique, 
de 
https://moocdigital.paris/cours/culture-linnovation-numerique/culture-
linnovation-numerique 

l’innovation 

Culture 

Enseigner et apprendre à l’ère de l’intelligence artificielle Sommaire 

33 

Lin, P., Van Brummelen, J. (2021). Engaging Teachers to Co-Design 
Integrated AI Curriculum for K-12 Classrooms). Proceedings of the 2021 chi 
conference on human factors in computing systems. 

Ghotbi, N. et Ho, M. (2021). Moral Awareness of College Students Regarding 
Artificial Intelligence. Asian Bioethics Review, 13(4), p. 421-433. 

Norouzi, N., Chaturvedi, S. et Rutledge, M. (2020). Lessons Learned from 
Teaching Machine Learning and Natural Language Processing to High 
School Students (WOS:000668126805119). 34, p. 13454-13460. 

Shi, W., & Dustdar, S. (2016). The Promise of Edge Computing. Computer, 
49(5), p. 78-81. 

Enseigner et apprendre à l’ère de l’intelligence artificielle Sommaire 

34 

 
 
4 /// REFLEXIONS DES 
ELEVES DU COLLEGE 
LIFE BLOOM ACADEMY 
SUR L’IA 

Lianne-Blue Hodgkins, professeure d’anglais1 
Victoire Batifol, professeure de français1 
Christelle Caucheteux, professeure d’histoire, géographie et d’enseignement moral et civique1 
Laurent Fouché, professeur de mathématiques, sciences et technologie1 

1 Life Bloom Academy, France 

Au cours de l’année scolaire 2021-2022, les élèves du collège Life Bloom 
interdisciplinaire d’acculturation à 
Academy ont suivi un parcours 
l’intelligence artificielle (IA). Accompagnés par leurs enseignants dans cette 
aventure, ils ont débuté par des réflexions philosophiques sur la signification 
de l’intelligence humaine. Ils ont visité la Maison de l’intelligence artificielle 
et ont pu profiter de l’animation et de l’expertise du personnel sur place, en 
plus de découvrir une variété de cas d’usages contemporains et futurs de 
l’IA. En continuité, d’autres activités ont été réalisées en classe, dans 
différentes disciplines scolaires. Les données collectées, notamment les 
traces de leurs activités en classe, suggèrent que les collégiens sont 
sensibles aux enjeux de l’IA et que la thématique suscite un intérêt qui peut 
dépasser le contexte scolaire. 

Un projet interdisciplinaire portant sur l’IA 

Ce chapitre présente un projet interdisciplinaire auquel ont collaboré différents professeurs du 
collège Life Bloom Academy situé à Cagnes-sur-Mer, dans 
les Alpes-Maritimes : 
mathématiques, sciences et technologie, histoire, géographie et enseignement moral et 
civique (EMC), anglais et français. Les objectifs pédagogiques étaient de découvrir l’IA et son 
fonctionnement, puis d’amener les élèves à réfléchir aux questions éthiques qui en découlent 
et ainsi développer leur esprit critique à ce sujet. 

Enseigner et apprendre à l’ère de l’intelligence artificielle Sommaire 

35 

 
 
 
Figure 10. Les élèves du collège Life Bloom Academy et l’équipe enseignante 

Le projet a démarré par une séance de préparation en classe d’histoire, géographie et 
enseignement moral et civique, en amont d’une visite à la Maison de l’intelligence artificielle 
(MIA). Pendant la séance, les élèves ont participé à un débat philosophique autour de la 
les 
question « Qu’est-ce que 
représentations initiales des élèves et de les amener à nommer différentes formes 
d’intelligences. Ensuite, les élèves ont visité la MIA et ont pu bénéficier de l’animation 
scientifique de l’équipe sur place, notamment des démonstrations de cas d’usage de l’IA et 
des explications vulgarisées. Les activités scientifiques et culturelles de la MIA ont joué le rôle 
de prérequis avant de réaliser les activités immersives sur l’IA du livret 5J5IA présenté dans 
le chapitre 7. 

l’intelligence ? ». Cette activité a permis de récolter 

Figure 11. Les élèves du collège Life Bloom Academy lors de leur passage à la Maison de l’intelligence artificielle 

Forts de ces nouvelles expériences, et après avoir enrichi leurs connaissances en cours de 
mathématiques, sciences et technologies, les élèves ont participé à un second débat sur les 
enjeux de l’IA en classe d’histoire, géographie et EMC. Ce débat portait sur des questions plus 
précises et visait à leur permettre de mobiliser leurs nouvelles connaissances sur l’IA. Chaque 
élève, seul ou en groupe de deux, a répondu aux questions suivantes : Quels sont les points 
positifs et négatifs ? Quels conseils donneriez-vous aux développeurs d’IA ? Le compte-rendu 
de ces débats a été pris en charge par Louise, élève de troisième. Ce travail d’argumentation 

Enseigner et apprendre à l’ère de l’intelligence artificielle Sommaire 

36 

 
 
devait les conduire à décrire une application pratique de l’IA et ses différentes conséquences 
dans la vie quotidienne. 

Les récits d’expérience des élèves 

La section qui suit présente huit réflexions sur l’IA rédigées par les élèves eux-mêmes, 
accompagnés de leurs professeurs, et représente un des aboutissements du projet 
interdisciplinaire. Ils ont d’abord synthétisé les apports de l’IA dans leur vie, puis évoqué les 
risques et les questions éthiques que l’IA pose. Ils ont bien compris grâce aux modules que 
l’IA n’est pas si intelligente et qu’elle doit être programmée. Ils évoquent surtout les risques 
pour leur liberté, leur libre-arbitre et leur capacité de travail. 

REFLEXION #1 – QU’EST-CE QUE L’IA ? 

« L’IA permet de faciliter et d’automatiser presque tout à l’heure actuelle, de nombreuses 
choses sont possibles. Par exemple, de plus en plus de voitures Tesla sont équipées 
d’autopilotes. Par ailleurs, de plus en plus de métiers sont remplacés par des IA comme les 
caissières dans les supermarchés. » 

REFLEXION #2 – L’IA DOIT ETRE ENTRAINEE 

« L’IA pourrait aider les gens dans leur travail de tous les jours. Cela représente beaucoup de 
travail de les programmer, car oui, l’IA n’est rien sans l’humain. Par exemple, Alexa qui répond 
à nos questions à l’oral et avec qui nous pouvons avoir des conversations est une IA et elle se 
développe. Je lui ai dit "au revoir" quand je partais et elle a dit qu’elle ne comprenait pas. Donc, 
je lui ai demandé de dire "au revoir" aux gens qui le lui disaient. Maintenant, elle me sortira 
des petites expressions gentilles pour me dire "au revoir" ! Elle peut se développer seule, ce 
qui fait d’elle une IA. » 

REFLEXION #3 – L’IA ET LE RESPECT DE LA VIE PRIVEE 

« L’IA peut guider des choix grâce à nos données personnelles. Elle nous propose des objets, 
des services, des biens qui correspondent à nos goûts. Quand on fait des recherches et qu’on 
navigue sur des sites Web, une IA récolte ces données et les revend. C’est grâce à cela que 
les publicités que l’on voit sont souvent personnalisées, mais est-ce que cela respecte 
vraiment notre intimité ? Beaucoup de gens ne sont pas confortables avec le fait que toutes 
leurs données sont revendues et vont même jusqu’à dire que ce sont des complots du 
gouvernement ! Et même si c’est peu probable, ces données peuvent être piratées et utilisées 
pour du chantage. Il y a même eu des hôpitaux piratés pour des rançons, ce qui a mis la vie 
d’autrui en danger ! Tout cela nous permet de voir que les données utilisées par l’IA mettent 
en péril notre sécurité et notre liberté. » 

REFLEXION #4 – LES DERIVES POSSIBLES DE L’IA 

« De nos jours, alors que l’IA s’intègre de plus en plus dans notre vie, de nouveaux risques 
liés à son utilisation apparaissent. Son utilisation nous fait réfléchir aux notions de vie privée 
et de sécurité, c’est-à-dire aux risques accrus de piratage de nos données sur la toile. D’autant 
plus que, si l’IA est utilisée à de mauvaises fins, les risques seraient bien plus importants. Un 
usage malveillant de l’IA est déjà en place dans certains pays comme en Chine par exemple 
où le crédit social est mis en place : c’est une sorte de système de surveillance et de contrôle 

Enseigner et apprendre à l’ère de l’intelligence artificielle Sommaire 

37 

des moindres faits et gestes de chaque habitant avec l’IA. Les nouveaux risques qui sont donc 
à prendre en compte sont les risques de la sécurité de nos données, notre confidentialité et 
des usages malveillants de l’IA comme pour la mise en place d’un régime néo-totalitaire. L’IA 
n’est pas humaine et elle permet de répondre à des besoins. Mais elle peut impacter notre vie 
et notre liberté. Par exemple, les témoins de navigation (cookies) ou les recommandations 
nous suivent dans nos recherches internet. Quand on va sur un site, on accepte des témoins 
et l’ordinateur prend en compte notre goût pour ce site-là et peut nous en proposer des 
similaires. Cela réduit notre liberté parce qu’on se sent observés et cela nous empêche de 
faire nos propres choix. On nous propose des choses, donc on est influencés. Bientôt, dans 
notre vie quotidienne, l’IA nous aidera pour les tâches répétitives et ménagères. Mais nous ne 
devons pas dépendre complètement d’elle. » 

REFLEXION #5 –L’IA AU SERVICE DU DEVELOPPEMENT DURABLE 

« L’IA peut nous sembler une solution pour répondre aux enjeux écologiques et de 
développement durable. Elle peut nous aider à créer des innovations durables, à gérer 
l’énergie, à organiser la dépollution et le recyclage ou à résoudre des situations tendues. Grâce 
à l’IA, il serait possible d’optimiser la gestion des sols et le rendement des terres agricoles en 
anticipant par exemple l’apparition de maladies, en optimisant l’usage d’eau ou encore en 
ajustant la production à la demande. Le robot pourrait ressembler juste à une petite puce qui 
pourrait analyser les terres pour optimiser l’eau, etc. Pour nettoyer les océans, on pourrait faire 
deux types de robots, un qui reste à la surface de l’eau pour ramasser les déchets qui y sont 
présents, il aurait la forme d’un petit bateau et il serait formé d’une grande poche pour 
récupérer les déchets. Pour le deuxième type de robots, celui-là pourrait aller sous l’eau pour 
ramasser les déchets. Il aurait la forme d’un gros poisson et pour qu’il ne fasse pas peur aux 
animaux marins, il aurait une très grande poche pour stocker les déchets. Avec les enjeux du 
changement climatique, les ressources naturelles s’amoindrissent et les risques de famine, de 
pénuries alimentaires s’intensifient. Un changement dans nos habitudes s’impose alors, et l’IA 
peut nous aider dans ce changement et dans le contrôle de notre consommation alimentaire 
afin de préserver nos ressources. Nous pourrions par exemple créer une IA qui permettrait de 
prévenir le gâchis alimentaire avec un réfrigérateur intelligent qui nous empêcherait de 
gaspiller de la nourriture. Nous pourrions automatiser et améliorer la production des serres 
grâce à l’IA qui analyserait la température, l’humidité. Tout ça pour dire que l’IA peut nous 
aider à régler nos problèmes mondiaux ». 

REFLEXION #6 – L’IA AU SERVICE DE LA SANTE 

« Un autre domaine dans lequel l’IA pourrait être utile est celui de la santé et plus précisément 
des soins et traitements. En effet, l’IA pourrait aider, voire remplacer, les professionnels dans 
leur travail en effectuant des tâches ou des analyses dans le domaine médical. L’IA pourrait, 
par exemple, s’occuper d’opérations délicates, sans l’intervention de personnel. On peut 
imaginer qu’elle serait utile en cas d’accident. On pourrait aussi utiliser l’IA pour optimiser le 
traitement de maladies. Si l’IA est capable de les détecter et de les reconnaître, il serait 
possible de faire des diagnostics précis que ce soit pour prévenir dès les premiers symptômes 
ou pour les traiter à un stade plus avancé, tout en suivant l’évolution et donc en adaptant des 
traitements. L’avantage de ce système serait de disposer d’une grande base de données qui 
remplacerait l’expérience limitée des professionnels de santé. » 

Enseigner et apprendre à l’ère de l’intelligence artificielle Sommaire 

38 

REFLEXION #7 – L’IA SOUS L’ANGLE DES RISQUES POUR LA SECURITE 

« Les risques sont multiples et il faut les connaître pour les prévenir et les résoudre, mais déjà 
quels sont ces risques ? Les risques éventuels sont le traçage de nos données et la divulgation 
de nos données sur internet. L’autre risque est l’affaiblissement des capacités humaines : si 
tout est fait par l’IA et qu’elle ne fonctionne plus, alors qu’allons-nous faire, car nous ne saurons 
plus faire les choses de la vie quotidienne ? Si un robot contenant de l’IA est piraté, cela serait 
dangereux. Par exemple si un robot médical est piraté, cela pourrait faire des morts. C’est le 
même problème pour l’usage de l’IA dans l’armée. S’il y a des robots dans une guerre, ils 
n’auront pas peur de mourir et donc ils pourront faire beaucoup plus de dégâts et de morts. » 

REFLEXION #8 – L’IA AU SERVICE DE L’EDUCATION 

« L’IA serait capable d’aider les enseignants pour des tâches administratives. Elle pourra faire 
toutes les choses administratives vis-à-vis du directeur en l’aidant pour la comptabilité ou 
l’envoi de courriels. Elle serait aussi très utile au professeur : pour l’appel des présences, la 
préparation des exercices et des leçons, ou l’évaluation des apprentissages. Cela permettrait 
d’aider les enfants qui ont plus de mal que d’autres à apprendre une leçon ou faire des 
exercices. Une IA peut donner des astuces ou des aides aux enfants ou aux adolescents pour 
avancer dans le programme scolaire. Par exemple, elle pourrait proposer de faire des cartes 
mentales ou pourrait suivre l’évolution de l’enfant pour se mettre à sa hauteur. » 

Conclusion 

Nous observons dans les réflexions des élèves qu’ils ont des attentes élevées par rapport à 
l’IA et ses différents usages. Mais ils envisagent également des risques comme celui de perdre 
des opportunités d’apprentissage s’ils font un usage trop important de l’IA pour réaliser leurs 
activités pédagogiques. Les élèves envisagent également des risques liés à une trop grande 
dépendance vis-à-vis de l’IA ou au piratage des données qui pourrait détourner les usages 
initiaux des technologies. Les propos des élèves permettent d’illustrer leur capacité à identifier 
des enjeux éthiques liés à l’usage de l’IA. Le travail de l’équipe disciplinaire, assis sur cinq 
entrées pédagogiques, rend les élèves autonomes dans leur capacité à s’exprimer, de 
manière objective, sur leur citoyenneté à l’ère de l’IA. Les récits d’expérience démontrent leur 
capacité à appliquer un certain détachement au regard de certaines illusions, tout en percevant 
qu’il serait difficile de se passer de l’IA pour résoudre des problèmes. 

Enseigner et apprendre à l’ère de l’intelligence artificielle Sommaire 

39 

 
 
PARTIE 2 /// 
ENJEUX DE L’IA EN 
EDUCATION 

Enseigner et apprendre à l’ère de l’intelligence artificielle Sommaire 

40 

 
 
 
 
 
 
 
5 /// L’IA EN FORMATION 
PROFESSIONNELLE 

Solange Ciavaldini-Cartaut1 2 
Jean-François Metral3 4 
Paul Olry3 4 
Dominique Guidoni-Stoltz3 
Charles-Antoine Gagneur4 

1 Laboratoire d’anthropologie et de psychologie cliniques, cognitives et sociales, Université Côte d’Azur, France 
2 Laboratoire d’innovation pour le numérique en éducation, Université Côte d’Azur, France 
3 Institut Agrosup Dijon, France 
4 Unité de recherche Formation et apprentissages professionnels, Conservatoire national des arts et métiers de Paris, France 

Créer une IA requiert de disposer de données fiables permettant d’assurer 
une fonction d’aide à l’enseignement et à l’apprentissage. En formation 
professionnelle, ces données sont caractérisées par des savoirs pratiques 
et des processus délibératifs et adaptatifs souvent peu formalisés en milieu 
de travail où priment les enjeux de productivité. 

La seconde difficulté de conception d’une IA et de son usage pour la 
formation professionnelle est de conserver le potentiel d’apprentissage de 
l’expérience vécue dans différentes situations, de cheminements pluriels et 
des erreurs, de pondérer parfois le caractère réaliste des situations de travail 
au bénéfice d’enjeux didactiques. 

La troisième difficulté relative à l’usage de tuteurs intelligents à l’aide de l’IA 
est d’inclure dans les rétroactions fournies à l’apprenant, les processus 
d’enquête qui caractérisent notamment le travail « dans et avec le vivant » 
et qui requièrent une projection d’actions sur du temps long. 

Introduction 

L’usage de l’intelligence artificielle (IA) dans la formation professionnelle soulève de 
nombreuses critiques et questions. Elles sont spécifiques aux contextes de son usage dans 
l’alternance entre éducation formelle et éducation-formation sur la place du travail. Elles 
renvoient aussi à la nature même des traces d’apprentissage ou des traces d’activité qui sont 
susceptibles d’être mobilisées dans une conception continuée dans l’usage, d’environnements 
d’apprentissage intégrant de l’IA à des fins de renforcement du processus d’enseignement ou 
d’apprentissage. 

Les analyses rapportées dans ce chapitre s’inscrivent dans le paradigme culturel et 
anthropocentré, mais aussi sociotechnique (Albero, 2019) de l’usage des technologies. Les 
technologies incluant l’IA y sont, pour les utilisateurs, des instruments (Folcher et Rabardel 
2004) subordonnés aux tâches et aux situations dans lesquelles se déploie l’activité 
professionnelle située. L’IA est considérée comme une aide, en ce qu’elle prend en charge 
une part des opérations, traite ou donne accès à des informations venant étayer les 
raisonnements et le processus d’enseignement-formation-apprentissage. Elle peut, à 
certaines conditions, aider à la coopération entre enseignants-formateurs et apprenants, ou à 
la régulation des apprentissages par l’enseignant-formateur ou l’apprenant lui-même. Elle peut 

Enseigner et apprendre à l’ère de l’intelligence artificielle Sommaire 

41 

 
 
 
 
également soutenir le recueil de traces d’activité dans la réalisation d’une tâche dans un emploi 
visé et contribuer à leur analyse. Toutefois, l’usage de l’IA dans la formation professionnelle 
rencontre des freins et des problèmes liés au fait que l’activité productive, délibérative, 
adaptative, créative, notamment « avec et pour le vivant », ne se réduit pas aux seuls 
comportements observables et normalisés. Par ailleurs, le recours aux learning analytics 
s’avère peu pertinent pour saisir et analyser les processus cognitifs, adaptatifs et créatifs qui 
sont requis dans les activités à enjeux productifs, en situation de travail. 

Ces processus inhérents à l’activité en lien avec d’autres humains ou le vivant en général 
(David et Droyer, 2019) conduisent à interroger les traces permettant de constituer des 
données tangibles pour concevoir des formations professionnelles enrichies des contributions 
d’une IA. En outre, le public de la voie professionnelle, à l’articulation entre les formations 
initiales et continues, n’est pas captif des enjeux formels d’éducation. Se pose ainsi aux 
concepteurs d’instruments et de dispositifs de formation, un second problème qui est de rendre 
l’IA « acceptable » tant du côté de la formation que du côté du monde du travail. 

Dans ce chapitre, nous interrogeons la nature des données initiales et leur qualité (ce qui est 
à faire apprendre) ainsi que la nature des traces d’apprentissage dans une perspective de 
forage de données éducatives (educational data mining). Ce préalable sera indispensable 
pour examiner de façon critique les bénéfices consubstantiels de l’IA à la formation 
professionnelle face aux pressions de la performance organisationnelle. Nous prendrons à 
cette fin plusieurs illustrations empiriques. 

La première est en lien avec la fabrication du fromage de Comté (Chrétien et al., 2020) où le 
raisonnement adaptatif des professionnels en situation est déconsidéré face aux processus 
industriels ou semi-industrialisés ce qui in fine constitue un frein sociotechnique à la création 
d’une IA pour la formation professionnelle du secteur. 

En ce qui concerne l’usage de l’IA comme outil partenaire de l’apprentissage, la seconde 
illustration s’appuiera sur les résultats de la recherche e-Fran « Silva numerica » qui portent 
sur la conception et l’usage expérimental d’un environnement d’apprentissage à la gestion de 
la forêt (Guidoni-Stoltz, 2019, 2020 ; Chiron, 2018). Même si le prototype de cet environnement 
virtuel relève actuellement d’une simulation 3D sans recours à l’IA, s’y pose la question d’une 
modélisation réaliste et authentique du travail du forestier pour l’engagement et le suivi des 
apprenants dans un parcours de formation. Toutefois, un caractère réaliste peut devenir un 
frein didactique à l’apprentissage des raisonnements professionnels projectifs sur l’évolution 
du vivant (la forêt). Dans ce cas, nous nous demanderons comment l’IA en tant que ressource 
didactique et « outil partenaire » pourrait être susceptible de contribuer à des feedbacks de 
l’activité simulée, tout en accordant une place à l’erreur dans le raisonnement projectif des 
formés. 

La troisième illustration concerne la contribution de l’IA au potentiel d’apprentissage en 
situation de travail et au développement des compétences des mécaniciens automobiles. À 
partir des résultats de la recherche menée par Gagneur et Vassout (2019) sur les garages 
connectés, nous traiterons de l’invisibilisation du travail d’enquête pourtant requis pour 
l’analyse diagnostic de pannes complexes. L’enjeu pour la formation professionnelle est alors 
de redonner une visibilité aux processus cognitifs d’inférence opérés par le mécanicien sur 
l’état observé du véhicule et l’utilisation par son propriétaire. Ce processus dépasse le simple 
usage d’une valise connectée et requiert d’apprendre en formation professionnelle initiale à 
dominer l’IA en la replaçant comme un instrument parmi d’autres, à utiliser tant par les tuteurs 
que par les apprentis. 

Enseigner et apprendre à l’ère de l’intelligence artificielle Sommaire 

42 

Nous conclurons ce chapitre autour des enjeux relatifs à la fiabilisation des données 
construites à des fins d’exploitation par un système d’IA entendu comme un système 
d’apprentissage automatique. Des suggestions relatives à l’enseignement-formation sont 
faites dans la perspective du dépassement des problèmes d’usage évoqués précédemment. 

Fiabilité, qualité et tangibilité des données initiales 
dans la formation professionnelle pour concevoir 
une IA 

Dans les univers sociaux productifs comme dans celui de l’éducation nationale, il existe un 
discours à propos des compétences professionnelles et des tâches concrètes à réaliser pour 
les acquérir puis les renforcer. Toutefois, les choses se compliquent quand on prend en 
compte le travail réel dans l’entreprise et cela pour deux raisons. D’abord, l’entreprise est un 
lieu de production confidentiel qui ne laisse pas filtrer des données aisément. Puis l’IA suppose 
de documenter une « matière inflammable » : le travail. En effet, si l’entreprise sait documenter 
les emplois, la « logique compétence » a individualisé la réalisation des tâches et nombre 
d’entreprises (ou d’administrations, d’associations, etc.) connaissent mal le travail tel qu’il se 
fait et ne le souhaitent pas. En effet, documenter le travail dit réel supposerait de collecter les 
informations à son propos, ce qui correspond à l’exact contraire des politiques RH menées 
depuis trente ans. D’autres formes de complication s’ajoutent dès lors qu’il s’agit de travailler 
avec autrui ou bien avec et pour le vivant (Mayen et Lainé, 2014), dans des environnements 
complexes, dynamiques, à long délai de réponses, comme celui de l’écosystème forestier par 
exemple. Ce travail qui s’inscrit dans un genre professionnel porteur d’histoire, mais aussi à la 
croisée de sphères économique, sociale et environnementale est tout à la fois singulier, pris 
dans des conflits de critères et parcouru d’incertitudes, de dilemmes et de questions 
socialement vives. 

Se pose donc la question des données initiales sur lesquelles faire porter les apprentissages 
professionnels notamment lorsque le travail est discrétionnaire ou ne se résume pas aux 
seules prescriptions. Dans l’entreprise, il est assez commun d’évoquer les procédures, mais 
le savoir auquel elles sont associées est souvent hors du sujet qui le mobilise dans une activité 
réelle toujours plus complexe que la tâche avec laquelle elle s’éprouve. Ce constat complique 
le choix des données initiales à implémenter dans les instruments numériques et sur lesquelles 
vont porter les apprentissages professionnels. Certes, on peut apprendre les bases du 
management avec un jeu sérieux par exemple, mais l’exercer dans l’entreprise est plus 
complexe aux niveaux opérationnel et adaptatif. Ce plan adaptatif, voire créatif de l’activité en 
lien avec l’humain ou le vivant (David et Droyer, 2019), questionne les traces d’activité 
professionnelle permettant de constituer des données tangibles pour développer des 
formations enrichies des contributions d’une IA. Or, on ne peut dissocier la question de la 
fiabilité des données de celle de leur tangibilité qui est forcément corrélée à leur réduction. 
Dans le monde de l’éducation scolaire, il apparaît plus facile de disposer de données 
tangibles : les savoirs scientifiques et didactiques sont largement établis (notamment par la 
recherche en didactique des disciplines et les programmes scolaires) et la traçabilité de 
l’apprentissage est requise pour l’évaluation de la performance scolaire. Toutefois, il n’en est 
rien du côté du monde du travail où le curseur de l’efficacité est davantage corrélé au résultat 
immédiat ou à long terme sur le produit, comme en termes de développement des sujets. Les 
mesures et les jugements sur les hommes et la qualité de leur travail sont le plus souvent 

Enseigner et apprendre à l’ère de l’intelligence artificielle Sommaire 

43 

« maladroits à dire » (Dujarier, 2010). La formation professionnelle se trouve donc à la croisée 
d’usage des données tangibles d’apprentissage et des données fidèles aux situations de 
travail (Chiron, 2018). L’usage de la simulation en formation se rapproche des données fidèles 
aux situations de travail. Toutefois, elle peut paradoxalement ne contribuer que faiblement aux 
apprentissages si elle est insuffisamment didactisée, ce que documentent fort bien les travaux 
en didactique professionnelle. En effet, dans toute conception d’activité de simulation se pose 
la question de la fidélité épistémique : quelles données et fonctionnalités faut-il implémenter 
pour obtenir quel apprentissage du travail ? Par ailleurs, dans le cas de la transmission 
professionnelle en situation de travail (mentorat, tutorat, action de formation en situation de 
travail), les données initiales ne sont pas toujours assez précises pour envisager de créer une 
IA ou d’alimenter des algorithmes d’apprentissage automatique centrés sur l’activité 
professionnelle cible afin d’en faciliter l’apprentissage. 

L’EXEMPLE DE LA FABRICATION DES MEULES DE FROMAGE DE COMTE 

Nous prendrons comme illustration une étude récente sur la fabrication des meules de fromage 
de Comté (Chrétien et al., 2020). Cette fabrication en France est de loin la plus documentée 
sur les 165 sortes de fromage. Il existe un centre technique depuis trente ans disposant de 
productions scientifiques et des tests à la pointe du domaine. Toutefois, ces données fiables 
et tangibles demeurent incomplètes pour expliquer comment et pourquoi certains fromages 
sont meilleurs que d’autres alors que les procédures sont standardisées. D’un point de vue 
anthropocentré (Albero, 2019), l’un des organisateurs de cette recherche (Chrétien et al., 
2020) a été d’observer in situ et de questionner l’activité des fromagers pour accéder au réel 
de leur travail de fabrication. 

Cet enjeu d’acquisition de traces tangibles de l’activité productive était de saisir les manières 
de faire et les liens avec les déterminants du goût du fromage et de sa qualité. Autrement dit, 
il existait des données nombreuses, fiables, actualisables sur les processus en jeu incluant les 
types de vaches, la météo, le sol, l’herbe qu’elles mangent jusqu’à la place du fromager et 
l’affinage une fois que le fromage a été fabriqué. Toutes les conditions semblaient donc réunies 
pour créer une IA au service de la formation des enseignants de lycées professionnels et des 
apprentis de la voie professionnelle. 

Enseigner et apprendre à l’ère de l’intelligence artificielle Sommaire 

44 

Figure 12. Fabrication du fromage de Comté et questionnement du choix d’une IA adaptée aux variables d’action des 
fromagers 

Mais toutes ces données ne permettent pas de comprendre l’essentiel : les différentes 
variables que le fromager mobilise en action pour fabriquer le fromage selon sa perception de 
la qualité du lait, la saison, les ferments lactiques dont il a observé depuis quelque temps qu’ils 
agissaient de telle ou telle manière. Ce sont ces variables qui lui permettent de fabriquer un 
fromage de Comté qui a du goût et elles peuvent, grâce aux connaissances issues de la 
recherche menée et à leur formalisation, enrichir les données initiales pour l’apprentissage 
professionnel. Elles pourraient même permettre de concevoir une IA incluant le raisonnement 
adaptatif des professionnels en situation. Mais apparaît alors un autre problème : les 
professionnels, comme les commanditaires de cette recherche, accordent moins de crédits à 
leurs propres raisonnements singuliers, contextuels, qu’aux processus industriels ou semi-
industrialisés. Il s’agit ici précisément du principal frein sociotechnique à la conception d’une 
IA contributive du perfectionnement des formations existantes. Autrement dit, la place de 
l’humain dans l’approche anthropocentrée n’est pas défendue à l’intérieur des univers de 
travail, ce qui est au cœur de la question de la fiabilité des données initiales en contexte 
professionnel. Cela pose aussi la question du choix des données pour concevoir l’IA autrement 
que ce qui est fait dans le domaine de l’éducation scolaire et des apprentissages disciplinaires. 
Le cas de la fabrication du fromage de Comté souligne que l’on apprend aussi au travail et sur 
les lieux du travail. Dans quelle mesure l’IA pourrait-elle agir sur le potentiel d’apprentissage 
des situations de travail ? Selon Littlejohn (2017), la première difficulté est inhérente à la 
modélisation d’un environnement complexe et dynamique avec lequel le professionnel 
interagit et pour lequel on ne dispose pas de capteurs d’information suffisamment performants. 
C’est le cas dans la fabrication du fromage de Comté avec les dimensions perceptives et 
gestuelles mobilisées lorsque le fromager veut savoir où en est le processus de transformation 
du lait : il plonge la main dans la cuve pour toucher le lait. Or, il n’existe pas de capteurs 
capables de retourner des informations interprétables par une IA en lien avec des traces 
d’activité du sujet apprenant en agissant au contact de la matière première en situation de 
production. De façon abrupte, et hors des enseignements des écoles professionnelles initiales, 

Enseigner et apprendre à l’ère de l’intelligence artificielle Sommaire 

45 

 
la question du recueil de traces tangibles est autant une question politique que technique. 
Quelle entreprise est prête à reconnaître les dimensions objectivant le travail tel qu’il se fait 
pour documenter un système d’IA ? Quelles références, normes, composantes d’une activité 
singulière et plurielle, toujours complexe doivent être prises en compte ? Jusqu’à présent, on 
trouve des réponses pour les industries à risque (chimie, santé, aéronautique, transport 
ferroviaire, nucléaire, etc.), car y travailler suppose de respecter étroitement la prescription. 
Mais ce sont précisément ces secteurs qui prêtent la plus forte attention au facteur humain 
dans les diagnostics de situation et de prise de décision pour assurer la fiabilité des processus. 
L’enjeu de l’IA en formation professionnelle est de toucher les autres secteurs de travail. 

L’IA en formation professionnelle, un partenaire de 
l’apprentissage 

Un premier usage possible de l’IA dans la formation professionnelle consisterait à 
l’implémenter et à l’utiliser en tant qu’outil d’aide, partenaire de l’apprentissage. Par exemple, 
l’un des intérêts serait de documenter des données fiables pour concevoir des simulations à 
partir de situations professionnelles totalement ou partiellement inaccessibles aux futurs 
professionnels. Ou encore, ce serait aussi de fiabiliser le traitement de situations critiques, soit 
pour le produit, soit pour le processus de fabrication, soit pour les personnes qui y sont 
engagées. Enfin, ces situations peuvent être dangereuses en elles-mêmes, ou au titre des 
conditions de l’exercice professionnel. Les phases d’atterrissage ou de décollage d’un avion 
avec des passagers réels peuvent illustrer notre propos : ces moments sont par nature 
facteurs de risque, ils le sont encore plus lorsque les créneaux de temps sont saturés sur les 
plateformes aéroportuaires : c’est la complexité de l’apprentissage de ces phases pour un 
pilote que pourrait documenter une IA. Mais la difficulté pour l’IA est de disposer de ces 
données, au regard de processus invisibles ou imperceptibles. De même, les actions 
conduites sur ces processus et ces situations s’étalent parfois dans le temps long, et on ne 
peut en voir les effets dans le délai par nature contraint de la formation, voire carrément dans 
le délai d’une vie. C’est précisément le cas de la gestion d’une forêt, organisme vivant d’un 
écosystème complexe. 

LA GESTION DES FORETS ET LE PROJET SILVA NUMERICA 

Gérer le vivant, lorsqu’on parle de décisions dont l’impact est à horizon de près d’un siècle 
(par ex. abattre ou non un arbre, quand ?), opacifie la nature des données susceptibles de 
documenter une IA. Car simultanément, cette gestion dépend aussi des variables relatives à 
l’évolution de l’écosystème lui-même, des objectifs de gestion d’un propriétaire, des prix du 
marché du bois, des risques sanitaires, des évolutions climatiques, etc. Apprendre à gérer une 
forêt, c’est apprendre à gérer plusieurs processus simultanés qui appellent une expertise à 
penser un système, une expertise d’ailleurs plurielle à partir de laquelle une IA pourrait nourrir 
avec pertinence un environnement d’apprentissage à l’aide de la simulation. 

Le projet Silva numerica23 (Guidoni-Stoltz, 2019, 2020) a rassemblé une masse conséquente 
d’informations pour documenter le travail de gestion forestière et son apprentissage dans le 
but de concevoir un environnement numérique d’apprentissage intégrant cette complexité. 
L’environnement virtuel simulateur s’est appuyé sur une modélisation des processus de 
développement des arbres dans une population d’arbres qui constituent la forêt. Mais cette 

23 Pour de l’information sur le projet Silva numérica, voir https://silvanumerica.net/ 

Enseigner et apprendre à l’ère de l’intelligence artificielle Sommaire 

46 

 
modélisation, dans un but pédagogique24, est confrontée à plusieurs limites. La première est 
que les processus naturels de développement qu’elle vise à reproduire sont tellement 
complexes qu’il n’existe pas de modèle global prêt à l’emploi pour la formation, ni même de 
base de données complètes d’autant qu’ils sont très dépendants du contexte (géologique, 
climatique, etc.) et de la sylviculture pratiquée. Si ces données existaient, une IA pourrait 
alimenter des scénarios de simulation pour l’apprentissage de la gestion de parcelles 
forestières très différentes. Il en va de même pour l’étude de Chrétien et collaborateurs (2020) 
pour la fabrication fromagère, dont le processus de fabrication est très documenté, 
suffisamment précis pour élaborer une IA à partir de ces données riches, fiables et tangibles. 

Figure 13. Variabilité du réalisme de la simulation en fonction d’enjeux didactiques (source : projet Silva numerica) 

À gauche de la Figure 13, on retrouve une simulation de la forêt qui est relativement réaliste 
au regard de la sylviculture sur laquelle elle est basée (futaie régulière de chênes sessiles) et 
à droite une simulation qui symbolise les arbres en « bâtons de sucette ». Cette dernière, bien 
qu’ayant perdu de la fidélité au réel, constitue une ressource sémiotique pour apprendre par 
exemple à sélectionner des arbres que l’on veut conserver ou abattre selon leur position 
sociale dans la forêt. 

La limite de la simulation réside dans la variabilité et la diversité des situations de travail. Cela 
nous conduit à poser les questions suivantes : dans quelle mesure en formation 
professionnelle l’IA pourrait-elle aider les concepteurs à modéliser un processus de formation 
à partir d’un ensemble de bases de données ? Comment l’IA pourrait-elle aider à la 
modélisation et à la simulation du réel si les données existent, alors même qu’un certain 
nombre de phénomènes et de processus sont très mal documentés ? Certains auteurs, dont 
les travaux récents de didacticiens (Vadcard 2013, 2019) soulignent que réussir à simuler 
l’environnement, les situations complexes et dynamiques dans lesquelles les futurs 
professionnels ont à agir en modélisant au plus près le réalisme ou l’authenticité des situations 
n’est pas toujours un garant d’efficacité du point de vue de la formation. Ce réalisme est parfois 
indésirable parce qu’il va justement à l’encontre du fait que pour faire apprendre et pour que 

24 Il existe des logiciels performants de croissance des arbres mais à usage de recherche ou pour l’enseignement supérieur. Voir 
par exemple Capsis Presentation : https://capsis.cirad.fr/capsis/presentation 

Enseigner et apprendre à l’ère de l’intelligence artificielle Sommaire 

47 

 
 
les situations puissent devenir des situations de formation, on a besoin de modifier le réel à 
des fins pédagogiques. 

L’INTERET L’IA AUX ENVIRONNEMENTS SIMULES 

L’intérêt didactique d’une IA est ainsi non seulement de modéliser le réel, mais aussi de 
conserver un potentiel d’apprentissage d’une activité professionnelle dans une perspective de 
didactique professionnelle. Les situations proposées dans les scénarios de simulation, les 
réponses à l’activité simulée devraient être à la fois documentées par l’IA, pour permettre aux 
futurs professionnels de s’y immerger, mais aussi de s’en échapper pour les analyser, y 
réfléchir. Car ce sont les possibles évolutions d’une situation problème, et sa gestion qu’il s’agit 
d’apprendre en développant un raisonnement, une réflexivité à leur propos et cela en 
sélectionnant les données pertinentes pour y agir. C’est de son usage dans les raisonnements 
que les données retenues tirent leur tangibilité. Or, ces raisonnements d’une part, et les 
données sur lesquelles ces derniers s’appuient d’autre part, sont rarement documentés et 
difficilement modélisables. 

Ainsi, documenter une IA, pour concevoir ou optimiser un système formatif suppose de 
comprendre comment ces raisonnements s’apprennent dans les lieux d’apprentissage et quels 
en sont les obstacles. L’enjeu de la conception tient alors dans la formalisation de scénarios 
de formation suffisamment proches des situations de travail et de l’activité professionnelle cible 
et réduisant les contraintes imposées par les environnements informatiques à la conception 
didactique. 

Enjeux didactiques de l’IA et de la simulation en 
formation professionnelle 

Dans quelle mesure l’IA peut-elle aider et apporter une plus-value avec une visée didactique ? 
Quelles sont les contraintes de conception pour un usage créatif de l’IA ? Nous reprenons ici 
des questions complémentaires à celles déjà posées autour de la plus-value potentielle d’un 
recours à IA dans la formation professionnelle. Quelles informations relatives à un 
environnement complexe doivent être données aux formés, sous quelle forme et à quel(s) 
moment(s), pour étayer le processus ? Contrairement aux experts, l’une des difficultés des 
novices consiste à repérer les indicateurs et à élaborer des inférences pertinentes pour 
diagnostiquer la situation. Ainsi, l’environnement numérique à créer doit attirer l’attention des 
apprenants sur les dimensions essentielles qu’ils doivent prendre en considération pour agir 
en tant que professionnels : mais à quel point ? Quelles transpositions numériques et 
didactiques intégrant de l’IA sont requises pour aider, guider, accompagner la bonne décision 
en faisant en sorte qu’en situation l’erreur soit encore possible ? Comment ne pas réduire la 
complexité de l’environnement réel et la richesse d’une activité de travail tout en facilitant sa 
compréhension aux apprenants ? 

Peut-on envisager un guidage sémantique ? Faut-il y préférer un guidage iconique ? Dans 
quelle mesure l’IA couplée à des traces d’apprentissage pourrait-elle non seulement permettre 
d’adapter le type de guidage proposé (en fonction des connaissances, des apprentissages 
des utilisateurs), mais aussi faciliter la rétroaction des enseignants formateurs ? Certains 
chercheurs pensent que l’utilisation de l’IA pour mieux guider les apprentissages est 
intéressante (voir, International Journal of Artificial Intelligence in Education). Dans le projet 
Silva numerica, s’est posée la question de la nature des informations relatives aux 

Enseigner et apprendre à l’ère de l’intelligence artificielle Sommaire 

48 

environnements forestiers simulés à proposer aux apprenants, sous quelle forme et à quel 
moment. Différents types d’informations leur ont été données. Prenons l’exemple des fiches 
descriptives, par exemple d’animaux, d’insectes, d’oiseaux, mais aussi des données sur les 
populations d’arbres et les différentes espèces d’arbres en présence, ou encore la construction 
d’un audit sur la valeur économique et la valeur écologique de la parcelle forestière. 

Figure 14. L’IA et les learning analytics pour adapter les informations, leur forme et le moment où elles sont 
accessibles (source : projet Silva numerica) 

Faut-il donner accès immédiatement à ces informations, à ces ressources comme le ferait un 
enseignant dans un cours magistral ? Une IA pourrait-elle aider à adapter les informations, 
leur forme et le moment où elles sont accessibles pour l’apprenant ? 

lourde pour 

Les deux points précédents mettent en évidence une maturité insuffisante de l’écosystème de 
la formation professionnelle vis-à-vis de l’IA et réciproquement, par la méconnaissance de la 
formation professionnelle par les acteurs de l’IA. Documenter une IA suppose une décision 
politique 
formations 
professionnelles initiales et continues : accepter de donner à voir le travail tel qu’il se fait, tel 
qu’il se pense, tel qu’il peut ou non se dire. Les industries à risque y sont contraintes par la 
réglementation. Les autres secteurs professionnels demeurent en partie « sourds et 
aveugles », non par mauvais esprit, mais par méconnaissance. Il y a beaucoup d’enjeux dans 
le dévoilement du travail et les raisonnements qui le guident. 

les organisations productives, comme pour 

les 

Documenter une IA suppose forcément une réduction des situations professionnelles à des 
segments traitables de l’activité professionnelle à faire apprendre. Mais cette réduction doit se 
maintenir au niveau des variables de l’action mobilisées dans les raisonnements des 
professionnels. Autrement dit, il convient de penser la tangibilité des données non comme une 
information ou un fait, mais comme une information qui soit « traitable », soit exprimée dans 
un format reconnaissable, et qui est susceptible d’être mise à l’épreuve, satisfaisant 
simultanément les conventions de métier, la pluralité des modèles opératoires et les 
ajustements à ce qui convient en situation. 

Enseigner et apprendre à l’ère de l’intelligence artificielle Sommaire 

49 

 
L’IA et les tuteurs intelligents pour les 
apprentissages professionnels et l’assistance à 
l’enseignement 

Une question cruciale à nos yeux porte sur la capacité de l’IA à renvoyer des rétroactions 
pertinentes pour les apprentissages. Dans la littérature, comme le montre l’étude de Hwang 
et collaborateurs (2020), il chemine l’idée d’une IA comme tuteur intelligent. En formation 
professionnelle, l’IA est-elle en capacité d’analyser l’activité de l’apprenant afin de réaliser des 
rétroactions pertinentes pour les apprentissages ? Cette question est redoutable, car cela 
implique une attente envers les technologies basées sur l’IA, qui devraient savoir analyser 
l’activité de l’apprenant sur la base de ses seules actions sur la machine, opérer une 
explicitation de la validité ou de l’invalidité de ce qu’il a réalisé et évaluer la qualité des 
apprentissages liés et cela à partir de l’intégration de différentes informations : celles relatives 
aux actions réalisées par l’apprenant, puis leur interprétation. En effet, dans l’action 
professionnelle, il y a souvent plusieurs résultats possibles qui peuvent être pertinents. Dans 
la gestion forestière, par exemple, chaque forestier en fonction des objectifs (de production, 
environnementaux, sociaux) peut analyser la situation et prendre des décisions d’action 
différentes d’un autre forestier. Pour autant, chaque itinéraire sylvicole établi peut être 
pertinent. Par ailleurs, cette interprétation de l’IA devrait tenir compte du fait qu’une conformité 
du résultat ne garantit pas du tout la compréhension de l’apprenant, des stratégies, modes 
opératoires et savoirs professionnels. Cela ne peut pas non plus être une conformité à une 
bonne pratique ou un raisonnement standard puisque, là encore, dans le domaine 
professionnel, plusieurs raisonnements différents, pour une même classe de situations, 
permettent d’arriver à un résultat similaire ou un résultat acceptable. Et enfin, il resterait à 
préciser quels indicateurs permettent d’inférer que l’apprenant a appris quelque chose ou est 
en difficulté. Par exemple, un apprenant peut tout à fait obtenir une « belle forêt » virtuelle (de 
beaux chênes, au diamètre impressionnant et donc avec une grande valeur marchande) par 
un cheminement intellectuel hasardeux et sans même avoir compris les concepts 
pragmatiques organisateurs d’une bonne gestion forestière. L’IA en tant qu’assistant de 
l’enseignant professionnel doit alors lui fournir des informations pertinentes et utilisables afin 
de pouvoir formaliser, discuter et institutionnaliser des savoirs professionnels. 

La question devient alors : dans quelle mesure l’IA, couplée à des traces d’apprentissage 
permettrait d’adapter le type de guidage proposé en fonction des connaissances, des 
apprentissages des utilisateurs, comme certains chercheurs le pensent possible ? Pourrait-on 
s’appuyer sur la capacité annoncée de l’IA à apprendre et à s’autocorriger (apprentissage 
automatique) et à mimer le comportement humain (apprentissage profond) afin qu’elle détecte 
des erreurs ou des difficultés récurrentes des apprenants, puis transforme le contenu, la forme 
ou le moment des rétroactions produites, comme pourrait le faire un enseignant ? Cela nous 
semble hautement hasardeux, car 1/ la capacité d’autoapprentissage des réseaux de 
neurones artificiels est limitée par la manière dont ils s’indexent sur le réel, car ils cherchent 
des régularités non pas dans le réel, mais dans l’image numérique qu’ils en forment et 2/ le 
moteur du tutorat est une maïeutique des discordances, alors que le principe de construction 
des IA est de rechercher des concordances entre jeux de données pour extraire ces 
régularités. 

Il est tout à fait possible que l’IA arrive prochainement à un niveau de finesse lui permettant 
de détecter des discordances pédagogiquement pertinentes au sein du texte (ou de l’activité 
simulée). Mais les problèmes d’indexation de l’IA sur des éléments contextuels distants 

Enseigner et apprendre à l’ère de l’intelligence artificielle Sommaire 

50 

demeurent prégnants. En effet, en formation professionnelle, quand bien même la recherche 
pourrait aider à déterminer une structure conceptuelle pour chaque classe de situation 
professionnelle et modéliser un mode opératoire expert, l’indexation des apprentissages sur 
les situations de travail réelles, sur leur dynamique et leurs particularités, constitue une part 
très importante de l’activité des formateurs et tuteurs. Elle implique bien souvent la 
connaissance d’implicites professionnels pouvant être très distants des conditions hic et nunc 
de la réalisation de l’action (culture de l’entreprise, style professionnel de tel tuteur en 
particulier, inscrite ou non dans le genre professionnel, etc.). Cela pose des problèmes 
d’acquisition, de sélection et de pertinence que l’avancement de la numérisation du monde ne 
permet pas encore de résoudre par l’automatisation, fût-elle appuyée sur des capacités de 
calcul contemporaines. Les exemples supra de la fabrication du Comté, de la gestion forestière 
ou de l’usage de l’IA dans les garages automobiles nous semblent tout à fait significatifs de 
cette difficulté d’indexation du virtuel numérique sur le réel. Dans ce type de contexte, il nous 
semble encore fantasmatique de confier à une IA seule, sans supervision de l’enseignant, la 
conduite d’une maïeutique apprenante à partir des écarts constatés au sein du discours sur 
l’activité, entre l’activité racontée et l’activité observée, entre l’activité observée et l’activité 
réelle, entre l’activité prévue et réalisée ou souhaitable a posteriori. Si cette maïeutique est 
peut-être accessible à l’IA quand elle s’exerce au sein du texte facilement accessible à la 
numérisation, il nous semble que les activités téléologiques dont la régulation fait appel à des 
prises d’informations aux règles complexes et pouvant se faire très à distance de l’activité 
immédiate vont rester encore hors de portée de ces approches pour un certain temps. On 
l’aura compris, le problème n’est pas tant du côté de l’IA en soi. Les deux exemples suivants 
illustrent ces problématiques pour deux configurations de mobilisation de l’IA dans la 
constitution de la capacité à agir. 

LES SCENARIOS PROJET SILVA NUMERICA 

Nous reprendrons l’exemple du projet Silva numérica : l’outil a été conçu pour enregistrer les 
actions réalisées par les apprenants au fur et à mesure qu’ils avancent dans les scénarios et 
les réponses qu’ils apportent aux activités demandées. Ces traces d’actions individuelles 
étaient accessibles aux enseignants à la fin de l’activité, sous une forme extrêmement 
complexe. Elles se sont révélées difficilement exploitables par elles-mêmes après la formation 
(texte illisible et chargé d’informations) et carrément inexploitables en cours de formation. Il 
était donc impossible pour les enseignants formateurs de pratiquer un débriefing sur la base 
du parcours de chaque apprenant dans les scénarios numériques. Fort de ce constat lors des 
premières expérimentations, la décision a été prise de plutôt suivre l’activité des apprenants 
au fur et à mesure de leur travail dans l’environnement virtuel et d’avoir des traces d’activité 
permettant d’implémenter a posteriori dans les scénarios des questionnaires d’évaluation. Et 
c’est sur la base des réponses à ces tâches d’évaluation qu’ont été prises en compte des 
traces de l’activité, des traces des apprentissages. On est loin du tuteur intelligent qui pourrait 
apporter une assistance pédagogique au professeur. Si l’on veut vraiment savoir si les 
apprenants ont compris quelque chose, cela implique aussi qu’ils puissent avoir des espaces 
dans lesquels ils peuvent développer leur raisonnement et donc qu’il y ait des questions ou 
des activités qui impliquent des réponses ouvertes. Or, les enseignants ont constaté que des 
éléments issus de questions ouvertes étaient trop compliqués à interpréter et à exploiter 
collectivement, en formation. Ils en sont donc venus à proposer des quiz et des textes à trous 
plus faciles à utiliser. Alors est-ce que l’IA serait en mesure d’apporter une plus-value en lien 
avec des données beaucoup plus larges, beaucoup plus hétérogènes, pour proposer un 
certain nombre d’indicateurs qui permettraient de situer l’apprenant dans son apprentissage ? 

Enseigner et apprendre à l’ère de l’intelligence artificielle Sommaire 

51 

LES GARAGES CONNECTES 

Nous prendrons cette fois-ci le cas des garages connectés interrogeant le potentiel 
d’apprentissage des situations de travail et la contribution de l’IA au développement des 
compétences. Gagneur et Vassou (2019) ont mené une recherche sur les garages connectés. 
Du point de vue des constructeurs automobiles, une révolution serait en marche en lien avec 
l’omniprésence du numérique. Du point de vue des auteurs, un problème apparaît lié à une 
focalisation excessive sur les valises diagnostiques utilisées en cas de panne des véhicules. 
Les capteurs servent à remonter de l’information, qui est ensuite comparée à des bases de 
données dans lesquelles ont été implémentées les pannes historiques : cela permet d’identifier 
le type de panne et de fournir aux mécaniciens une procédure pour la résoudre. Le constat 
est que 90 % des mécaniciens utilisent cette valise diagnostique sur un mode basique, 
autrement dit sur des pannes simples, parfaitement référencées et pour lesquelles ils suivent 
ensuite la procédure. Cela marche assez bien. Dans ce cas-là, le processus n’est pas 
compliqué à apprendre en formation professionnelle. Mais dans 30 à 40 % des cas, ça ne 
marche pas. À ce moment-là, il faut beaucoup plus de temps pour résoudre ces pannes et 
pour mener l’enquête. En effet, bien qu’il y ait des capteurs un peu partout dans les voitures, 
certains endroits ne peuvent pas en être pourvus. Et la finalité de ces capteurs est de faire 
fonctionner la voiture, mais pas de permettre l’enquête des mécaniciens en cas de panne. De 
nombreux endroits où il n’y a pas de capteurs échappent donc à l’outil numérique. Et c’est là 
qu’intervient l’expertise des professionnels dans ce qui n’est pas accessible à l’outil numérique 
et donc à la mallette diagnostique. D’abord pour faire « capteur humain » et renseigner la 
machine. Ensuite, pour les pannes plus complexes, les professionnels doivent être capables 
« de prendre la main sur le diagnostic fait par la machine » pour l’utiliser dans un autre mode. 
Ce sont des compétences critiques pour la survie des entreprises : il suffit de quelques pannes 
qui résistent au diagnostic et à l’intervention, et consomment donc du temps de travail sans 
possibilité de facturation, pour mettre en péril la profitabilité d’un atelier de réparation 
automobile. Il s’agit de recueillir des données, mais ensuite de les croiser avec d’autres 
données. Des données d’observation des véhicules tels que les bruits, les traces d’huile, voire 
les données relatives à l’expérience client, son usage du véhicule, etc. Pour les mécaniciens 
experts, l’enjeu est de « dominer l’IA et non pas de se laisser dominer par elle ». Et donc, toute 
la compétence, à ce moment-là sera dans l’enquête et leur intégration des différents points de 
vue, des différents types de données : cela implique d’avoir des connaissances sur ce qui se 
passe physiquement et mécaniquement pour limiter les interprétations erronées. Pour la 
formation professionnelle, le défi est alors de proposer des conditions qui vont permettre 
d’apprendre à dominer la machine pour en faire un instrument de son activité, dans un système 
sociotechnique. 

En conclusion, avec la mallette diagnostic dans le secteur de la maintenance automobile, en 
suivant Casilli (2019), on pourrait dire que l’IA « invisibilise une part du travail humain ». 
N’oublions pas que dans l’organisation du travail, cet usage maîtrisé de la machine est confié 
souvent aux agents plus experts alors que les mécaniciens de base, dont les apprentis, n’ont 
pas souvent accès à ces pannes. Apparaît ici le risque d’une déqualification progressive des 
mécaniciens. Cela signifie aussi que tous les professionnels ne pourront pas être tuteurs en 
mesure d’assurer des actions de formation en situation de travail (AFEST) par exemple. Ce 
cas nous invite à rappeler que pour dominer la machine, il faut aussi dominer son objet de 
travail, c’est-à-dire avoir des connaissances en mécanique, en physique assez pointues, pour 
pouvoir se prémunir des biais de la médiation numérique. Le risque est grand aussi de 
conformer les apprenants à un ou quelques modèles professionnels qui ne tiennent pas 
compte de la richesse du travail réel et de l’intelligence professionnelle (Guidoni-Stoltz, 2019). 

Enseigner et apprendre à l’ère de l’intelligence artificielle Sommaire 

52 

En définitive, dans la formation professionnelle, la présence de l’IA ne fait que renforcer la 
nécessité d’un accompagnement humain des apprentissages par des professionnels tuteurs 
et par des formateurs qui sont capables de rendre visible la part invisible du travail. Ils doivent 
mettre en partage les implicites qui fondent l’activité professionnelle. 

Il nous semble donc que l’affirmation posée par Hwang et al. (2020) demeure tout au plus une 
croyance ou une illusion, au moins dans le domaine de la formation professionnelle : 

Une application d’IA pourrait jouer le rôle d’un tuteur qui observe les processus d’apprentissage des 
élèves, analyse leurs performances d’apprentissage et leur fournit une assistance instantanée en fonction 
de leurs besoins. Sur la base des besoins potentiels des élèves, une équipe interdisciplinaire (composée, 
par exemple, d’informaticiens et de spécialistes de l’apprentissage) peut développer un système de tutorat 
intelligent qui permet aux élèves d’apprendre, de s’exercer et d’interagir avec leurs pairs ou leurs 
enseignants, mais qui fournit également des conseils, des orientations et des aides aux individus en 
fonction de leur statut ou de leurs besoins. (p. 2, traduction libre) 

Conclusion 

Dans ce chapitre, nous avons voulu traiter des intérêts potentiels et des limites actuelles 
concernant l’usage de l’IA pour enseigner et pour apprendre les métiers dans la formation 
professionnelle et sur la place du travail. Nous avons pu expliquer comment l’une des clés 
pour rendre possible une plus-value de tels usages de l’IA réside dans la capacité des 
évolutions technologiques à fiabiliser et à rendre tangibles et exploitables les données du 
travail sur lesquelles vont porter les apprentissages professionnels (gestes, situations, 
circonstances, raisonnements, etc.) ainsi que les données d’apprentissage elles-mêmes. Si la 
vitesse d’évolution des techniques d’apprentissage automatique rend difficiles les pronostics 
de développement de l’IA dans les années à venir, l’indexation de ces processus sur le réel 
nous semble constituer une limite d’ordre logique plus que technique, et donc probablement 
pérenne. Partant de là, rendre tangibles et exploitables les données du travail implique une 
démarche partenariale avec les organisations professionnelles sur différents points : la 
conception des outils d’aide à l’apprentissage fondée sur un accès de telles données auprès 
des professionnels, notamment par la recherche ; le dépassement du frein sociotechnique du 
manque de confiance des professionnels quant à de telles données ; l’accès des enseignants, 
formateurs, apprenants aux outils professionnels embarquant une IA, en mettant en place les 
conditions pour rendre visible le travail réel, apprendre la part de raisonnements mobilisés et 
permettre une domination de la machine par une appropriation en tant qu’instrument (Folcher 
et Rabardel, 2004). Nous avons montré en quoi cela nécessite un travail de conception 
d’usage des outils d’assistance à l’enseignement avec les enseignants et les formateurs eux-
mêmes : c’est une condition de leur intégration de l’IA dans les pratiques et son acceptabilité. 
L’enjeu est aussi que l’usage de l’IA dans l’accompagnement des apprentissages se donne 
les moyens d’une reconfiguration ergonomique des outils proposés aux acteurs. 

La didactique professionnelle peut contribuer à des rapprochements pour que les instruments numériques 
éducatifs intégrant de l’IA soient réellement adaptés à la formation professionnelle. Pour en savoir plus, un 
site internet national existe : https://didactiqueprofessionnelle.ning.com/ 

Enseigner et apprendre à l’ère de l’intelligence artificielle Sommaire 

53 

Références 

Albero, B. (2019). La théorie de l’enquête : relier les pôles épistémè et praxis 
de 
: 
https://doi.org/10.4000/rechercheformation.5651 

l’activité, Recherche et 

ligne], 92. DOI 

formation 

[En 

Casilli, A-A. (2019). En attendant les robots. Enquête sur le travail du clic. 
Seuil. 

Chiron, T. (2018). Explorer les potentialités d’un Environnement Virtuel 
Educatif (Silva Numerica) pour favoriser l’apprentissage de situations 
complexes et dynamiques en lien avec le vivant : le cas d’apprenants 
forestiers. Colloque doctoral international de l’éducation et de la formation. 
Rennes, France. ⟨hal-01767554⟩ 

Chrétien, F., Métral, J.-F. et Olry, P. (2020). Voir ce qui ne se voit pas. 
fromagerie. Revue d’Anthropologie des 
Regarder, voir, savoir en 
connaissances, 14 (3). URL : http://journals.openedition.org/rac/10523 ; 
DOI : https://doi.org/10.4000/rac.10523 

David, M. et Droyer, N. (2019). Evaluation de la co-conception d’un 
environnement virtuel éducatif forestier - Pré-enquête à l’entrée par le critère 
de pertinence, e-JIREF, 5 (3). URL : http://journal.admee.org/index.ph 
p/ejiref/article/view/21 

Dujarier, M. A. (2010). L’automatisation du jugement sur le travail. Mesurer 
n’est pas évaluer. Cahiers internationaux de sociologie, (1), 135-159. 

Folcher, V. et Rabardel, P. (2004). 15. Hommes, artefacts, activités : 
perspective 
(pp. 251-268). Presses 
Universitaires de France. 

In Ergonomie 

instrumentale. 

Gagneur, C-A. et Vassout, D. (2019). Étude garage connecté : usage des 
outils connectés. Rapport de recherche dans le cadre d’un Projet 
d’Investissement d’Avenir (PIA). Association Nationale pour la Formation 
Automobile 
https://www.anfa-auto.fr/observatoire/la-
prospective/competences-numeriques 

(ANFA). URL : 

Guidoni-Stoltz, D. (2019). Concevoir un environnement virtuel éducatif pour 
« capitaliser », former ou développer l’intelligence professionnelle des 
forestiers : intérêts et (dés) illusions de la simulation. Acte du colloque 
international de l’association Recherches et Pratiques en Didactique 
Professionnelle (RPDP). Université de Sherbrooke, Longueuil, Canada. 

Guidoni-Stoltz, D. (2020). L’œil du forestier, instrument et miroir de l’activité 
professionnelle : Une perspective de didactique professionnelle. Revue 
d’Anthropologie des connaissances, 
(3). URL : 
http://journals.openedition.org/rac/8371. 
DOI : 
https://doi.org/10.4000/rac.8371 

ligne], 14 

[En 

Hwang, G.-J., Xie, H., Wah, B. W. et Gašević, D. (2020). Vision, challenges, 
roles and research issues of Artificial Intelligence in Education. Computers 
and 
DOI : 
https://doi.org/10.1016/j.caeai.2020.100001 

Intelligence, 

1(100001). 

Education: 

Artificial 

Knight, S. et Buckingham, S. (2017). Theory and Learning Analytics. Dans 
C. Lang, G. Siemens, A. Wise, & G. Dragan (Eds.) (p. 17-22). SOLAR. URL: 
www.solaresearch.org/publications/hla-17 

Littlejohn, A. (2017). Learning and Work: Professional Learning Analytics. 
Dans C. Lang, G. Siemens, A. Wise et D. Gašević (Eds.), Handbook of 

Enseigner et apprendre à l’ère de l’intelligence artificielle Sommaire 

54 

learning 
analytics 
www.solaresearch.org/publications/hla-17 

(p. 268-276). 

SOLAR. 

URL : 

Mayen, P. et Lainé, A. (Eds.). (2014). Apprendre à travailler avec le vivant ? 
Développement durable et didactique professionnelle. Éditions Raison et 
Passions. 

Vadcard, L. (2019). Vers une didactique des gestes techniques. Enjeux pour 
la formation professionnelle en santé [Habilitation à diriger des recherches]. 
Université de Bourgogne Franche-Comté. 

Vadcard, L. (2013). Étude didactique de la dialectique du travail et de la 
formation au bloc opératoire, Éducation et didactique [En ligne], 7 (1). DOI : 
https://doi.org/10.4000/educationdidactique.1598 

Enseigner et apprendre à l’ère de l’intelligence artificielle Sommaire 

55 

 
 
6 /// L’IA POUR MIEUX 
APPRENDRE ET 
APPREHENDER L’IA 

Frédéric Alexandre1 
Marie-Hélène Comte1 
Aurélie Lagarrigue1 
Thierry Viéville1 2 

1 Institut national de recherche en sciences et technologies du numérique, Équipe Mnémosyne, France 
2 Laboratoire d’innovation pour le numérique en éducation, Université Côte d’Azur, France 

L’IA en éducation peut être abordée depuis trois perspectives parallèles. 
D’abord, elle peut servir à adapter l’expérience d’apprentissage par la 
conception d’outils prenant en compte différentes caractéristiques des 
apprenants ou des traces numériques issues de leur interaction avec des 
systèmes. Bien utilisés, de tels systèmes pourraient décharger les 
enseignants de tâches relatives à la transmission des contenus et leur 
permettre d’intervenir sur des aspects plus complexes de l’apprentissage 
des élèves. Ensuite, l’IA peut être utilisée comme outil scientifique pour 
mieux comprendre les phénomènes d’apprentissage humain, par la 
modélisation de l’apprenant. Finalement, l’IA peut être envisagée depuis la 
perspective de l’éducation critique à l’IA. Ce chapitre présente succinctement 
ces trois perspectives qui ne s’excluent pas les unes des autres, mais qui se 
complètent pour mieux cerner les enjeux de l’IA. Les dernières recherches 
associant les sciences de l’éducation et les sciences du numérique 
permettent de comprendre les liens entre l’intelligence artificielle (IA) et 
l’éducation, y compris leurs limites. Ces recherches nous montrent comment 
l’IA peut être pensée pour mieux apprendre et développer son esprit critique 
(Roux et al. 2020 ; Viéville, 2018), pour comprendre l’apprentissage humain 
lui-même, et enfin comme objet d’enseignement, pour maîtriser de manière 
éclairée ces outils devenus quotidiens (Viéville et Guitton, 2020). 

L’IA comme outil d’apprentissage adaptatif 

Tout d’abord, en utilisant des algorithmes, l’apprentissage peut être adaptatif. En analysant 
les traces d’apprentissage de l’élève, comme des résultats à des questionnaires ou des 
données d’utilisation d’un logiciel, le système peut modifier son fonctionnement pour s’adapter 
à la personne, notamment à travers la sélection de contenus et du niveau de difficulté. Il 
commence à être possible d’analyser son comportement grâce à des capteurs, certains 
externes comme une caméra, et d’autres plus intrusifs comme une interface cerveau-
ordinateur. Ce principe d’adaptation est au cœur de la pédagogie numérique, et se rencontre 
le plus souvent dans un contexte où sont aussi poursuivis des objectifs de ludification ; 
l’apprenant s’inscrivant alors dans un jeu pédagogique avec la machine, parfois en 
collaboration avec d’autres apprenants (Giraudon et al., 2020). 

Enseigner et apprendre à l’ère de l’intelligence artificielle Sommaire 

56 

 
 
 
Le projet KidLearn25, illustré dans la Figure 15, propose une activité d’apprentissage dont les 
multiples variantes impliquant additions ou soustractions de nombres entiers ou décimaux ont 
été conçues et mises en place par des didacticiens. Ces variantes sont organisées sous forme 
d’un graphe de difficultés croissantes, en respectant le concept de zone proximale de 
développement (Vygotsky, 1978). Ce concept est fondé sur l’idée que, entre un exercice trop 
difficile qui décourage et un exercice trop facile qui lasse, il existe une zone optimale qui 
maximise le progrès d’apprentissage, mesuré ici en observant les performances de l’élève au 
fil du jeu. Ce sont ces éléments qui sont intégrés à l’algorithme, qui va s’adapter 
automatiquement à la personne apprenante (Oudeyer et al., 2020). 

Figure 15. Le projet Kidlearn se base sur des scénarios d’achats de 1 à 2 objets ou de rendu de monnaie (source : 
équipe Flowers, Inria) 

Si le développement de ces usages reste encore limité 26, la recherche scientifique étant 
toujours en cours, elle offre une étape de réflexion préalable fondamentale, pour comprendre 
comment fonctionnent l’acquisition et l’appropriation de connaissances. En effet, pour 
systématiser cette approche adaptative, il faut formaliser les savoirs (connaissances) et savoir-
faire (pratiques) à faire apprendre, ce qui oblige à expliciter et structurer les types de tâches 
et techniques de résolution. Par ailleurs, il faut garder à l’esprit la nécessité de ne pas 
surcharger l’apprentissage avec des tâches cognitives annexes liées à l’activité elle-même. 
L’apprentissage adaptatif doit également se faire dans un contexte contraint par les 
disponibilités du matériel, la formation des personnes, ou les limites à l’usage des écrans. 

Les effets positifs de cet apprentissage machine peuvent être nombreux. En tout premier lieu, 
on observe qu’ils génèrent en général un meilleur engagement de la personne apprenante, 
car interagir autrement avec les contenus offre une chance supplémentaire de bien les 
comprendre. En effet, le fait que la difficulté soit adaptée à l’apprenant permet de limiter, voire 
d’éviter le découragement ou la lassitude. De plus, à la différence de l’humain, la machine ne 
« juge pas », ce qui peut contribuer à maintenir cet engagement. Pour autant, ce type 
d’apprentissage peut nécessiter un investissement important pour l’enseignant, si la 
conception ne prend pas en compte la charge cognitive de l’élève. Il peut aussi induire le risque 

25 Des détails et publications relatives au projet KidLearn sont accessibles en ligne, voir https://flowers.inria.fr/research/kidlearn/ 
26 Pour des exemples de projets français permettant de l’apprentissage adaptatif, voir Kwyk (www.kwyk.fr), LeLivreScolaire 
(www.lelivrescolaire.fr), ou bien Pix (https://pix.fr/). Ils utilisent de l’algorithmique de manière intensive, y compris avec quelques 
algorithmes issus de l’apprentissage automatique, mais pas uniquement. 

Enseigner et apprendre à l’ère de l’intelligence artificielle Sommaire 

57 

 
 
que l’élève se disperse au lieu de s’investir dans l’apprentissage escompté si l’aspect ludique 
est prépondérant. 

Les outils adaptatifs intégrant des principes considérés comme étant de l’IA doivent permettre 
aux enseignantes et enseignants de se rendre plus disponibles pour les élèves qui en ont le 
plus besoin, car la classe est investie dans des activités d’apprentissage autonomes. De 
même, cela leur permet de se libérer, comme en pédagogie de la classe inversée, d’une partie 
des transmissions de savoir grâce à ces contenus multimédias autoévalués et à des exercices 
d’entraînement automatisés, pour se concentrer sur d’autres approches pédagogiques, par 
exemple fonctionnant par projets. Par rapport à des outils numériques non adaptatifs, c’est-à-
dire sans apprentissage automatique, le degré d’apprentissage en autonomie peut être bien 
plus élevé et s’applique plus largement, avec des parcours complets de développement de 
compétences. Ces outils répondent par ailleurs à un besoin dans le cadre de situations 
d’enseignement à distance, et viennent questionner l’organisation du temps de travail scolaire. 

Il convient néanmoins de souligner les dérives possibles des usages de ces données : le 
traçage omniprésent et omnipotent des apprenants, leur catégorisation, la tentation de réduire 
les effectifs de personnel scolaire, le renforcement des inégalités en lien avec l’illectronisme 
(Gandon, 2020), d’autant que ces pratiques numériques accroissent le risque d’une intégration 
aux autres facettes du comportement en ligne, comme les achats, la consultation de vidéos 
ou les lectures, bref d’un éventuel changement de finalité des traitements. 

L’IA comme modèle pour comprendre 
l’apprentissage humain 

La possibilité de collecter et interpréter des traces d’apprentissage pourrait permettre 
d’améliorer l’apprentissage, si ces traces sont utilisées par l’apprenant ou l’enseignant pour 
s’autoréguler ou pour la régulation externe par l’enseignant (Romero, 2019). L’usage des 
traces pourrait permettre aussi de mieux comprendre sur le long terme les modes 
d’apprentissage humains. Ces traces peuvent être relevées lors de l’utilisation d’un logiciel par 
la mesure des déplacements de la souris ou des clics réalisés au doigt, des saisies au clavier, 
ou encore par des capteurs employés dans des situations pédagogiques sans ordinateur ou 
avec ordinateur (p. ex. caméra, micro, accéléromètre, GPS). On peut ainsi penser à une 
activité physique dans une cour d’école, observée avec des capteurs visuels ou corporels. 
Exploiter ces mesures impose alors non seulement de formaliser la tâche d’apprentissage elle-
même, mais en plus, de modéliser la tâche et la personne apprenante, non pas dans sa 
globalité, mais dans le contexte d’une tâche en particulier. 

L’usage de traces d’apprentissage dans les environnements numériques d’apprentissage permet de de 
modéliser la tâche d’apprentissage, mais également l’activité de l’apprenant dans la tâche. 

Les algorithmes d’apprentissage automatique reposent sur des modèles assez sophistiqués. 
Ils ne sont pas forcément limités à des mécanismes d’apprentissage supervisés où les 
réponses s’ajustent à partir d’exemples fournis avec la solution, mais fonctionnent aussi par 
« renforcement » : le système va inférer les causes permettant d’expliquer les retours positifs 

Enseigner et apprendre à l’ère de l’intelligence artificielle Sommaire 

58 

(appelés récompenses27) ou négatifs au cours de l’apprentissage, en construisant un modèle 
interne de la tâche à effectuer. Ces modèles sont opérationnels, c’est-à-dire qu’ils permettent 
de créer des algorithmes effectifs qui ajustent leurs paramètres. On peut alors se demander si 
de tels modèles permettent de modéliser des aspects de l’apprentissage humain. En 
les processus 
neurosciences, ces modèles dits computationnels, représentent déjà 
fonctionnels de notre cerveau sous forme de mécanismes de calculs ou de traitement de 
l’information au niveau neuronal pour mieux les expliquer. 

Ce domaine d’utilisation des sciences informatiques et de l’IA comme outils de formalisation 
pour modéliser l’apprentissage humain, qu’on pourrait qualifier de « sciences de l’éducation 
computationnelles » (Romero et al., 2020), n’en est qu’à ses débuts, mais on perçoit déjà le 
potentiel qu’il peut représenter pour les sciences de l’éducation : c’est pourquoi des 
recherches sont menées de manière transdisciplinaire avec les sciences du numérique et les 
neurosciences cognitives afin d’explorer ces potentialités. 

L’IA, un enseignement citoyen 

Afin de « maîtriser le numérique » au sens de Giraudon et al. (2021) et non uniquement le 
consommer, il est important d’être initié au fonctionnement scientifique et technique des objets 
informatiques matériels et logiciels, pour éclairer l’usage de ses applications (Atlan et al., 
2019 ; Romero, 2018). L’intégration des technologies dites d’IA dans notre quotidien appelle 
au développement de l’esprit critique des jeunes (Viéville et Guitton, 2020). 

Il est par exemple important de comprendre que, en IA, le résultat du traitement des données 
par les algorithmes n’est pas lié entièrement à leur programmation. Les fonctions souhaitées 
ne sont pas implémentées seulement à l’aide d’instructions, mais aussi en fournissant des 
données à partir desquelles les paramètres sont ajustés pour obtenir le calcul souhaité. Selon 
le degré d’autonomie des programmes, il peut même y avoir des conséquences imprévues 
comme cela a été le cas dans des systèmes de robots conversationnels qui ont appris, par 
des corpus de mauvaise qualité, à produire des commentaires non éthiques sur les médias 
sociaux. Sur le plan juridique, il importe également de se familiariser avec les implications 
découlant de l’utilisation d’un « cobot », à savoir d’un mécanisme robotique interagissant avec 
notre vie quotidienne. On désigne ici un système artificiel, comme une machine médicale qui 
aurait pour fonction de permettre d’éclairer l’aide à la décision thérapeutique dans des 
situations de différents degrés d’urgence. Ce contexte médical nous montre combien la chaîne 
de responsabilité entre conception, construction, installation, paramétrage et utilisation est ici 
infiniment plus complexe que dans une machine dont le comportement n’est pas partiellement 
autonome. 

La formation à l’IA doit permettre de développer des connaissances et des compétences pour comprendre le 
fonctionnement de l’IA et pouvoir développer un positionnement citoyen et professionnel sur les potentiels et 
limites de l’IA. 

C’est face à ces enjeux qu’a été créée le MOOC Intelligence artificielle avec intelligence, 
présenté dans le chapitre 1, afin d’initier de manière citoyenne les éducateurs à l’informatique 
y compris à propos de comment l’IA peut contribuer à faire développer des compétences 

27 Dans l’apprentissage par renforcement, les « récompenses » peuvent être tant positives que négatives. Ainsi, elles ne se 
limitent pas au positif comme au sens classique du terme d’apprentissage par renforcement en psychologie. 

Enseigner et apprendre à l’ère de l’intelligence artificielle Sommaire 

59 

 
(Alexandre et al., 2022). Des outils pédagogiques existent et continuent de se développer pour 
initier les apprenants progressivement au fonctionnement de l’IA. La Figure 16 montre ainsi 
une « machine » minimaliste, développée par Pixees et construite par Snzzur.fr, permettant 
de stocker des boules bleues, pour les succès, ou rouges, pour les échecs, de chacune des 
parties. Ainsi, la machine « mémorise » la stratégie gagnante à coup sûr. Tous les plans de 
construction sont accessibles en libre accès et le jeu peut être reproduit à faible coût avec des 
outils de base28. 

On a pu établir qu’apprendre l’informatique de manière « débranchée », c’est-à-dire en 
s’extrayant de l’interaction avec la machine pour se concentrer de manière active sur les 
concepts sous-jacents, permet de mieux comprendre un des mécanismes de fonctionnement 
de l’IA (dans cet exemple, l’apprentissage par renforcement en l’occurrence). 

Figure 16. Un exemple d’activité débranchée permettant d’expérimenter un algorithme d’apprentissage par 
renforcement 

Un bouleversement dans notre façon de penser 

Dès le début de l’informatique, nous avons vu évoluer notre manière d’apprendre et 
d’enseigner. Par exemple, faut-il encore apprendre à calculer lorsqu’on peut utiliser une 
calculette ? Cela est sans doute nécessaire pour développer ses capacités cognitives et 
comprendre une opération arithmétique, mais de fait, nous avons moins besoin de devenir de 
« bons calculateurs » qu’à l’époque où le calcul mental était la clé pour s’en sortir au quotidien 
ou dans ses activités professionnelles. Par contre, il nous faudra toujours être entraînés au 
calcul des ordres de grandeur, pour vérifier qu’il n’y a pas d’erreur quand on a posé le calcul 
et obtenu le résultat, ou s’assurer que le calcul lui-même est pertinent. 

Ces mutations de l’activité humaine se retrouvent au fur et à mesure que nous automatisons 
des processus qui relèvent de l’intelligence humaine. Finalement, si nous nous contentons 
d’utiliser des algorithmes d’IA sans chercher à comprendre leurs grands principes de 
fonctionnement et leurs implications sur notre vie, nous risquons de perdre de l’intelligence 
individuelle et collective : nous nous en remettrons à leurs mécanismes en réfléchissant moins 
par nous-mêmes, et en développant moins l’esprit critique indispensable à la formation de 
citoyens autonomes et éclairés. C’est là tout le sens de comprendre comment fonctionne l’IA 
(Roux et al., 2020). Si nous cherchons à comprendre et à maîtriser ces processus, alors la 
possibilité de déléguer ce qui est mécanisable dans ce que traite de l’intelligence humaine 
peut nous offrir la chance de nous libérer consciemment de tâches devenues automatiques 
afin de consacrer notre intelligence humaine à des objectifs de plus haut niveau, et à 
considérer des questions humainement plus importantes. 

28 Pour accéder aux plans de construction, voir https://pixees.fr/jouer-au-jeu-des-allumettes-contre-une-machine. 

Enseigner et apprendre à l’ère de l’intelligence artificielle Sommaire 

60 

 
 
Une version préliminaire de ce texte a été publiée par les auteurs dans Lecture Jeune en 2021. 

Ressources complémentaires 

Trois projets français utilisant l’IA pour l’apprentissage (Kwyk, LeLivreScolaire et Pix). 
www.kwyk.fr 
www.lelivrescolaire.fr 
https://pix.fr 

Le projet KidLearn mené par l’équipe Inria Flowers. 
https://flowers.inria.fr/research/kidlearn/ 

L’outil pédagogique d’informatique débranchée pour apprendre l’apprentissage par renforcement. 
https://pixees.fr/jouer-au-jeu-des-allumettes-contre-une-machine. 

Références 

Alexandre, F., Becker, J., Comte, M. H., Lagarrigue, A., Liblau, R., Romero, 
M. et Viéville, T. (2021). Why, What and How to help each Citizen to 
Understand Artificial Intelligence?. KI-Künstliche Intelligenz, 35(2), p. 191-
199. 

Atlan, C., Archambault, J. P., Banus, O., Bardeau, F., Blandeau, A., Cois, A., 
Courbin, M., Giraudon, G., Lefèvre, S-C., Létard, V., Masse, B., Masseglia, 
F., Ninassi, B., de Quatrebarbes, S., Romero, M., Roy, D. et Viéville, T. 
(2019). Apprentissage de la pensée informatique : de la formation des 
enseignant·e·s à la formation de tou·te·s les citoyen·ne·s. Revue de l’EPI. 

Giraudon, G., Guitton, P., Romero, M., Roy, D. et Viéville, T. (2020). 
Éducation et numérique, Défis et enjeux. Inria. 

Oudeyer, P. Y., Clément, B., Roy, D. et Sauzéon, H. (2020). Projet KidLearn 
: Vers une personnalisation motivante des parcours d’apprentissage. Bulletin 
de l’Association Française pour l’Intelligence Artificielle, p. 51-55. 

Romero, M. (2018). Développer la pensée informatique pour démystifier 
l’intelligence artificielle. 1024 – Bulletin de la société informatique de France, 
12, p. 67-75. 

Romero, M. (2019). Analyser les apprentissages à partir des traces. 
Distances et médiations des savoirs, (26). 

Romero, M., Alexandre, F., Viéville, T. et Giraudon, G. (2020) LINE - 
Mnémosyne : Des neurosciences computationnelles aux sciences de 
l’éducation computationnelles pour 
la modélisation du cerveau de 
l’apprenant et du contexte de l’activité d’apprentissage. Bulletin de 
l’Association Française pour l’Intelligence Artificielle, AFIA. 

Roux, L., Romero, M., Alexandre, F. et Viéville, T. (2020). Les hauts de 
Otesia. Binaire. 

Viéville, T. et Guitton, P. (2020). Quels sont les liens entre IA et Éducation ?. 
Binaire. 

Viéville, T. (2019). Mais comment éduquer les garçons à l’équité des genres 
au niveau informatique et numérique. Éducation à la mixité : Et les garçons ? 
Un rêve pour les filles et les garçons. La Science. 

Enseigner et apprendre à l’ère de l’intelligence artificielle Sommaire 

61 

Vygotsky, L. S. (1978). Mind in society: The development of higher 
psychological processes. Harvard University Press. 

Enseigner et apprendre à l’ère de l’intelligence artificielle Sommaire 

62 

 
7 /// LE DISPOSITIF 5J5IA, 
UN EXEMPLE DE 
REGULATION CRITIQUE 
DE L’IA EN EDUCATION 

Jean-François Céci1 
Laurent Heiser2 
Margarida Romero2 

1 Techné, Université de Poitiers, France 
2 Laboratoire d’innovation pour le numérique en éducation, Université Côte d’Azur, France 

L’IA modifie notre manière d’être au monde et notre rapport à la culture. Une 
éducation à l’IA, avec pour objectif de contribuer au développement des 
compétences chez le citoyen numérique, remet en question la forme scolaire 
traditionnelle de l’enseignement collectif et simultané. Les pédagogies dites 
actives, de la découverte, du débat et de la mise en action cognitive sur le 
savoir à acquérir, seront convoquées. Le concept de régulation pédagogique 
de l’IA renvoie à une réflexion large, autant sur les activités de classe que 
sur la formation des enseignants, mais également la représentation de leur 
rôle au sein de l’institution et de la société à l’ère du numérique. 

Le livret pédagogique 5J5IA (5 jours, 5 IA) présenté dans le chapitre introduit 
cinq activités en libre accès utilisables dès le primaire, avec pour objectif 
principal la démystification de l’IA. Les enseignants sont invités à tester des 
séquences pédagogiques prêtes à l’emploi autour de la reconnaissance 
vocale, la classification des données, l’apprentissage supervisé (ou non), 
l’utilisation d’un agent conversationnel et les enjeux éthiques de l’IA. Enfin, 
en répondant aux questions à même les activités, les élèves participent à 
faire avancer la recherche sur la question de l’IA pour l’éducation. 

L’École à l’ère du numérique et de l’IA 

Dans ce chapitre, nous cherchons à caractériser l’évolution du numérique29 à l’École30 et à 
analyser sa capacité à préparer les futurs citoyens à vivre dans un monde en pleine mutation 
sociale, écologique et technologique. Dès lors, face à l’émergence de l’automatisation et de 
l’intelligence artificielle (IA), nous rencontrons de nouveaux défis éducatifs, tant d’acculturation 
que de compétences numériques. Cela rend nécessaire le développement de la capacité 
d’agir pour permettre aux élèves de devenir des citoyens capables d’un positionnement 
critique, émancipateur et créatif par rapport à ces technologies (Alexandre et al., 2021). De 

29 Le substantif « le numérique » est utilisé en référence aux propos de Louise Merzeau (2017) voulant que « c’est dans sa 
dimension "écologique" qu’il convient aujourd’hui de penser le numérique, c’est-à-dire en tant qu’écosystème ou environnement, 
[et] c’est dans ses effets d’interactions, de continuum et d’enveloppement qu’on mesurera le mieux comment ce qui n’était d’abord 
perçu que comme une "nouvelle technologie" a finalement configuré un milieu de vie » (p. 3). « Le numérique » renvoie donc aux 
concepts de culture numérique et de citoyenneté numérique pour décrire cette vision écosystémique du numérique. Il inclut aussi 
le numérique en tant qu’outil et support. Pour plus de détails, voir Céci (2020, p.25). 
30 Le mot École avec un É majuscule est utilisé pour qualifier l’école de la République dans son sens le plus large, tous niveaux 
confondus (et non pas uniquement les niveaux de la maternelle à CM2). 

Enseigner et apprendre à l’ère de l’intelligence artificielle Sommaire 

63 

 
 
 
 
plus, l’École s’adresse à un public qui représente, sans être une catégorie à part (Cerisier, 
2011), une génération d’individus qui ont un accès accru au numérique. L’usage pervasif et 
intensif des écrans de certains jeunes peut changer leur rapport aux savoirs et leur 
construction identitaire, conduisant à « une nouvelle manière d’être au monde de l’individu 
scolarisé » (Céci, 2020, p. 407). Dans le registre de la vie courante, apprendre avec et au 
travers des écrans est à la fois naturel, habituel et intensif puisque ces jeunes passent environ 
deux fois plus de temps31 sur écrans qu’à l’École. Ces apprentissages informels (Hamadache, 
1993) participent fortement de leur construction identitaire et, pour une part, également aux 
apprentissages scolaires. Pour autant, il incombe à l’École32, en plus de la transmission des 
savoirs savants indispensables, de contribuer à l’émancipation de ces futurs citoyens, en 
tenant compte de l’écosystème numérique dans lequel nous évoluons. 

Dans nos recherches, nous qualifions dorénavant ces jeunes de « citoyens numériques »33 en 
considérant qu’ils ont besoin de développer de nouvelles habiletés pour vivre en harmonie 
dans un monde numérisé et percuté par des enjeux sociétaux. Dès lors, la pédagogie doit 
cibler la capacité des élèves à ne pas subir ce monde et à y participer de manière agentive, 
c’est-à-dire, en développant à l’École une représentation forte (Pellaud et Eastes, 2020) des 
enjeux de développement durable. Il s’agit donc d’offrir des occasions de s’acculturer à l’IA et 
d’en faire un usage créatif en vue de la résolution de problèmes connectés au vécu de 
l’apprenant, et plus tard à la société. 

La formation doit contribuer à l’émancipation, au pouvoir d’action et à la créativité des élèves, en tant que 
futurs citoyens capables d’agir dans un monde numérique où les technologies de l’IA sont omniprésentes. 

Depuis les États généraux du numérique pour l’éducation34, nous assistons à un glissement 
conceptuel du numérique éducatif vers celui du numérique pour l’éducation. Dans le but de 
développer les compétences numériques des élèves, certains référentiels visent à proposer 
des repères pour que les enseignants évaluent ces compétences, comme c’est le cas du 
Cadre de Référence des Compétences Numériques (CRCN) paru en octobre 2019. Des 
actions concrètes d’intégration de la culture numérique, du cycle 2 au lycée, peuvent être 
interprétées comme une volonté ministérielle de former le citoyen numérique dans le cadre 
d’une politique et d’une culture nationale, volontarisme entrant en résonance avec des 
enseignements existants au collège et au lycée (p. ex. numérique et sciences informatiques). 
De plus, l’éducation nationale s’intéresse aux usages personnels du numérique à travers des 
cadrages ou incitations comme le CARMO35 et le Règlement général sur la protection des 
données. Enfin, des programmes de recherche, comme les incubateurs numériques (Heiser 
et al., 2022), rapprochent les enseignants des chercheurs pour former des praticiens à des 
usages réflexifs du numérique en contexte éducatif. De nombreux autres exemples peuvent 
être cités. 

31 La moyenne est de 2 160 heures/an passées sur écrans, tous niveaux confondus, ce qui correspond à 90 jours (le quart de 
leur vie). Une année scolaire moyenne (36 semaines de 32 heures) représente 1 152 heures/an (Céci, 2020, p. 231). 
32 Nous considérons que l’École n’est pas la seule structure capable de travailler à l’émancipation du citoyen numérique de 
demain, mais la seule en capacité d’adresser – en volume – cette nouvelle jeunesse. Rappelons « qu’un quart du pays est à 
l’École de la république » (Céci, 2020, p. 68), ou dit autrement, un quart de la population française étudie ou travaille dans le 
système éducatif français. 
33 Nous adoptons la définition de la citoyenneté numérique du Conseil de l’Europe, voir www.coe.int/fr/web/digital-citizenship-
education/home. 
34 Ces États généraux ont été organisés fin 2020 par le ministère de l’Éducation nationale, de la Jeunesse et des Sports, voir 
/www.education.gouv.fr/les-etats-generaux-du-numerique-pour-l-education-304117. 
35 Il s’agit du Cadre de 
https://eduscol.education.fr/1087/cadre-de-reference-carmo-version-30. 

ressources pédagogiques via un équipement mobile, voir 

référence d’accès aux 

Enseigner et apprendre à l’ère de l’intelligence artificielle Sommaire 

64 

 
Le cadrage de cette éducation au numérique, et donc sa régulation, se développe tant en 
France que dans les autres pays de l’OCDE (2021), mais il n’en demeure pas moins que la 
forme scolaire (Vincent, 2021) et universitaire française demeure peu malléable face aux 
changements potentiels que le numérique peut soutenir en termes d’innovation pédagogique 
(Céci, 2020, p. 412). Cette stabilité nous conduit à envisager une analyse des contradictions 
à travers le concept de régulation critique du numérique en éducation et de l’IA, plus 
particulièrement. 

Fondements théoriques du concept de régulation 
critique du numérique et de l’IA en éducation 

Le Tableau 4 illustre notre vision multiscalaire d’une formation du citoyen numérique, à la 
genèse d’une pédagogie que nous qualifierons dorénavant de « contemporaine », incluant 
autant les médiations nécessaires pour une meilleure régulation des sociotechniques (et de 
l’IA), que les formes pédagogiques supportant ces médiations et menant à une encapacitation 
raisonnée des apprenants. Notre démarche permettant d’amplifier la régulation de l’IA par la 
formation est une vision théorique se déclinant autour des trois niveaux de la pensée complexe 
(Morin, 1994) : macro, méso et micro. 

Au premier niveau, macro, nous empruntons la pensée des philosophes de la technique, 
comme Simondon (1958) ou Ellul (2004). Nous retenons l’idée selon laquelle le progrès 
technique n’a pas forcément comme conséquence le progrès social ou environnemental. 
Comment alors réguler en contexte éducatif, pour que cette dichotomie soit moins forte ? 
Comment concevoir des médiations qui puissent atténuer cette contradiction ? Autant de 
questions que nous cherchons à résoudre en proposant trois étapes pour résoudre des 
problèmes de manière créative : la découverte des dispositifs numériques en classe, leur 
apprentissage et leur appropriation. Cette triade permet de comprendre les enjeux techniques 
et éthiques de l’IA (Romero et al., 2021), ainsi que ses apports et ses potentielles dérives. 

ÉTAPES 

Niveau micro 

Niveau méso 

Découverte des dispositifs 
numériques en classe 
Activités de classe spécifiques (reposant sur l’ingénierie 
technopédagogique et disciplinaire de l’enseignant) 
Pédagogie contemporaine (exemple de la techno-créativité 
pouvant entraîner des tensions avec la forme scolaire actuelle) 

Apprentissage et 
appropriation 

Niveau macro Capacitation citoyenne 

Réflexivité sociétale 

Agentivité des citoyens 

Encapacitation individuelle et culture 
numérique partagée 
État d’esprit entrepreneur (de sa vie), 
ou « état d’esprit de développement » 
(Dweck, 2010, p. 13) 
Formation du citoyen aux 
compétences numérique (Céci, 2019) 

Tableau 4. Vision multiscalaire de la formation du citoyen aux compétences numériques 

Au niveau méso, nous prenons appui sur la pensée de Charlot (2020) selon qui les pédagogies 
cherchent à résoudre une tension entre désirs et normes. Le XIXe siècle a donné lieu à 
l’émergence d’une pédagogie traditionnelle essentialiste, reposant sur la discipline. Au 
XXe siècle, il s’agissait de respecter le statut de l’enfant, orientation donnant lieu à des 
« pédagogies nouvelles ». Le XXIe siècle, quant à lui, met l’homme face à des technologies 
pervasives (ou cybertechniques). Cela nous conduit à déduire que ce rapport à la technique 
doit être enrichi pour accompagner au mieux les jeunes à se construire et à apprendre dans 
une société connectée. Il est urgent selon nous de participer à l’émergence d’une pédagogie 

Enseigner et apprendre à l’ère de l’intelligence artificielle Sommaire 

65 

 
 
contemporaine à l’ère numérique, alors même que cette émergence se heurte à une inertie 
importante de la forme scolaire (Vincent, 2021). 

Au niveau micro, nous nous attardons sur le travail effectif du professeur dans la classe, entre 
injonctions et contradictions. Selon Dubet (2002), les enseignants se sont longtemps engagés 
dans le métier par vocation (appétence pour le travail sur autrui, pour l’accompagnement à 
grandir intellectuellement). La vision d’un « citoyen numérique de demain » (Céci, 2019, p. 80) 
appelle à penser le métier d’enseignant également en termes d’ingénierie technopédagogique, 
pour réfléchir et vivre, à l’Ecole, des situations qui feront sens dans le quotidien du citoyen 
connecté. Il s’agit donc d’anticiper, concevoir, mettre en œuvre et réguler des médiations pour 
augmenter les encapacitations (Bernard, 2018) de ce citoyen numérique au sein des 
dispositifs idoines. Dès lors, il s’agit davantage de scolariser la société selon ses besoins, que 
de socialiser l’École (Céci, 2020, p. 417) et le professeur-ingénieur technopédagogique 
devient alors un élément fondamental du développement des compétences de ce citoyen 
numérique. 

La formation des citoyens aux compétences numériques doit s’envisager tant au niveau micro avec des 
activités spécifiques en classe, au niveau méso sur une pédagogie techno-créative et au niveau macro sur 
une encapacitation citoyenne aux compétences numériques. 

La Figure 17 illustre ces propos. La régulation de l’IA par le travail en classe donne lieu à un 
modèle augmenté qui permet, à gauche de la figure, de réfléchir à son impact (agentivité des 
citoyens) et de mettre en relief les problèmes posés par l’IA. 

Figure 17. Les effets de la régulation pédagogique de l’IA 

De ces trois niveaux d’analyse découle une transition du numérique éducatif de ce début de 
XXIe siècle, essentiellement basée sur une instrumentation de la pédagogie, vers un 
numérique pour l’éducation avec cette finalité d’émancipation et de formation de ce citoyen 
numérique, transition que nous allons approfondir, en prenant appui sur l’histoire des 
pédagogies. 

Enseigner et apprendre à l’ère de l’intelligence artificielle Sommaire 

66 

 
Une régulation qui ne va pas de soi 

Pour comprendre la nécessité de réguler l’IA en contexte éducatif, nous proposons de 
regarder dans le rétroviseur de l’histoire des pédagogies. Il est alors nécessaire de rappeler 
l’existence d’une tension permanente entre désirs et normes au sein de la pédagogie (Charlot, 
2020). Au XIXe siècle, les désirs de l’enfant doivent être refoulés au sein de l’école pour l’élever 
à des normes quasi spirituelles. Ces dernières, en outre, s’imposent par la discipline, ce que 
les normes du citoyen idéal permettent de légitimer. Au XXe siècle, les désirs de l’enfant sont 
appréhendés comme naturels. Les psychologues de l’éducation demandent que l’on protège 
l’enfant et que l’on respecte son évolution. La pédagogie dite transmissive se transforme en 
« pédagogies nouvelles » avec un attrait important pour le constructivisme de Piaget. Les 
enseignants, dans ce contexte, vont se mettre en quête d’une certaine efficacité dans leur 
enseignement, à la faveur du meilleur apprentissage possible des élèves. 

Précisons qu’il ne s’agit donc pas de questionner la pertinence des normes tant que ces 
dernières apparaissent comme compatibles avec la conception de la citoyenneté au cours des 
deux siècles précédents. Ainsi, ces normes devraient être redéfinies, pour tenir compte des 
évolutions historico-technologiques qui sont en cours au XXIe siècle. Cela nécessiterait de 
penser une pédagogie qualifiée de contemporaine, à partir de normes qui définissent 
clairement les compétences numériques que les élèves vont devoir acquérir dans un monde 
où le numérique, et l’IA, ont fait émerger une nouvelle culture (Doueihi, 2011, p. 9). Parmi ces 
compétences, il s’agit d’entraîner les élèves à valider ou encadrer une prédiction formulée par 
une IA, ce qui nécessite de comprendre le fonctionnement de l’apprentissage automatique tout 
en ayant le choix de se soumettre ou non aux résultats qui en découlent. 

Dès lors, une ingénierie pédagogique mettant en lien les référentiels des programmes 
scolaires avec le développement de la pensée algorithmique et plus particulièrement de cette 
culture numérique citoyenne intégrant l’IA, est nécessaire. Cependant, l’émergence de ces 
aptitudes fait apparaître des difficultés ou contradictions. Évoquons, par exemple, la nécessité 
d’accroître les savoirs et les savoir-faire des élèves, pour les préparer à s’approprier l’IA et en 
tirer bénéfice de manière intentionnelle. Or, les usages du numérique de ce type, en contexte 
éducatif, sont peu développés sauf dans des disciplines spécifiques comme les sciences de 
l’ingénieur en lycée. Les autres enseignants reçoivent peu ou pas de formation à cette 
ingénierie technopédagogique qui permettrait de développer une pédagogie contemporaine 
en lien avec les nouveaux enjeux liés à notre rapport à la culture du numérique, depuis leur 
discipline. Il est également probable que certains enseignants ne se retrouvent pas dans ce 
rôle d’ingénieur pédagogique, ayant choisi leur métier par vocation (Dubet, 2002, p. 104). Ceci 
explique, selon Charlot (2020), pourquoi une éducation aux enjeux du numérique, et donc une 
régulation de l’IA dans et par la pédagogie, nécessiterait de redéfinir de manière concomitante 
le projet de l’École. 

Nous venons de préciser plusieurs éléments. D’abord, le concept de numérique pour 
l’éducation est désormais appréhendé, mais fait face à des contradictions opérationnelles et 
structurelles, lesquelles découlent du fait que la pédagogie contemporaine s’appuie 
difficilement sur de nouveaux référents didactiques et anthropologiques. Ensuite, le travail de 
l’enseignant est encore trop centré sur la transmission des savoirs et pas assez sur le 
développement personnel de l’élève dans une visée de développement des compétences pour 
une citoyenneté développant la capacité d’agir. La conception pédagogique, susceptible de 
provoquer une bonne régulation des sociotechniques, doit être moins pensée en termes 
d’efficacité des apprentissages (Charlot, 2020, p. 301), qu’en ceux d’émancipation (versus 

Enseigner et apprendre à l’ère de l’intelligence artificielle Sommaire 

67 

aliénation). Une telle émancipation est nécessaire au citoyen pour assurer pleinement sa 
citoyenneté numérique dans un monde connecté. 

L’enseignant doit mettre en œuvre des dispositifs pédagogiques visant autant des apprentissages 
sociotechniques que l’émancipation citoyenne. 

Pour illustrer comment peut se concrétiser ce rôle d’ingénierie pédagogique par l’enseignant, 
la section suivante présente l’exemple du dispositif pédagogique appelé 5J5IA. 

L’exemple du dispositif pédagogique 5J5IA 

Le dispositif 5J5IA (pour 5 jours, 5 IA)36 est un livret pédagogique prêt à l’emploi, incluant une 
enquête scientifique. Ce dispositif pédagogique vise une régulation de l’IA par la pédagogie 
de la découverte, par l’apprentissage et l’appropriation. La philosophie de 5J5IA repose tout 
d’abord sur ce qui a permis de réunir les chercheurs et auteurs de cet article. Tous 
questionnent l’usage des technologies en éducation pour les rendre sociales, en se basant sur 
l’activité réelle, l’expérience authentique vécue et sur une amplification du dispositif 
pédagogique par usage efficient du numérique en éducation. Nous avons donc élaboré un 
projet basé sur des activités concrètes et réalistes de l’IA. Par ailleurs, le livret pédagogique 
explicite l’articulation voulue, entre notre cadre théorique ci-dessus, la recherche et le projet 
pédagogique support, dont nous allons évoquer, ci-dessous, les grands principes. 

Figure 18. Le livret pédagogique 5J5IA 

36 Les activités et le livret pédagogique sont disponibles en ligne, voir https://scoliablog.wordpress.com/5j5ia/. 

Enseigner et apprendre à l’ère de l’intelligence artificielle Sommaire 

68 

 
 
 
 
DESCRIPTION DES ACTIVITES DE 5J5IA 

Le dispositif a été conçu suivant les sept principes suivants d’ingénierie pédagogique : 

1. Proposer une activité facile à intégrer en classe, de moins d’une heure, mais facilement 

extensible 

2. Proposer un livret prêt à l’emploi pour faciliter l’intégration du module par tout 

enseignant 

3. Ludifier l’apprentissage par une trame narrative dans laquelle les apprenants peuvent 

se reconnaître et se sentir concernés ; 

4. Proposer des activités aussi authentiques que possible, porteuses de sens et non 

stéréotypées 

5. Être facilement réalisables en classe, ou à la maison, seul ou en groupe 
6. Acculturer au numérique en lien avec le CRCN, considérant l’intégration de l’IA au 
niveau du référentiel DigComp à l’échelle européenne (Vuorikari, Kluzer et Punie, 
2022) 

7. Proposer une progression pédagogique permettant de percevoir les représentations 
des jeunes autour de l’IA dans une visée de recherche (modules 1 à 3 basés sur 
l’expérience et la découverte, modules 4 et 5 apportant davantage d’informations et un 
cadre théorique plus solide pour ne pas fausser les représentations avant de les avoir 
collectées) 

Cinq activités qui peuvent se développer sur cinq séances ou plus ont été développées. 
Chacune est structurée de la même manière : elle commence par une mise en situation (via 
la narration d’une histoire) suivie d’une activité authentique et d’une phase de 
questionnements pour alimenter la recherche tout en ancrant les savoirs par l’action réflexive. 
Des ressources et questions à aborder « pour comprendre » sont offertes pour faciliter 
l’accompagnement théorique du groupe par l’enseignant. Le Tableau 5 présente les cinq 
activités de 5J5IA. 

ACTIVITE 
1. Reconnaissance vocale 

2. Reconnaissance 
d’objets 

3. Reconnaissance 
d’images 

4. Interaction humain-
machine 

5. Régulation de l’IA 

DESCRIPTION 
L’activité consiste à dicter une histoire pour comprendre les mécanismes de l’IA à l’œuvre 
pour la reconnaissance de plusieurs voix, sans apprentissage préalable. Cette activité permet 
également d’aborder des éléments d’orthographe, de grammaire, de ponctuation ou de 
prononciation en cours de langues par exemple. 
Cette activité vise à faire apprendre à une machine à reconnaître plusieurs objets et à les 
distinguer entre eux. Elle peut être facilement bonifiée pour pouvoir aborder des éléments 
théoriques – en sciences humaines par exemple – autour des traits caractéristiques des êtres 
humains. 
Cette activité s’appuie sur l’activité précédente de reconnaissance d’objets, mais l’application 
apprend au fur et à mesure à reconnaître de nouveaux objets. L’activité ressemble à une 
chasse au trésor où les élèves sont à la recherche d’objets du quotidien, en un temps limité. 
Ils doivent montrer les objets trouvés devant la webcam de l’appareil numérique. À la fin de 
l’activité, l’apport théorique sur l’IA commence via une vidéo ouvrant à un débat. 
La situation s’inspire du test de Turing. Il s’agit d’avoir une conversation écrite avec un robot 
conversationnel (chatbot), que l’on nomme Eliza (ami virtuel dans notre scénario), pour voir s’il 
parviendra à duper les personnes dans une discussion sur de multiples sujets. L’optique est 
d’aborder l’interaction humain-machine, récupérer des données liées aux représentations des 
élèves sur l’IA et sur les liens qu’on entretient avec les objets techniques numériques. 
Cette dernière activité vise le cadrage théorique de l’IA pour une bonne régulation. Il y a 
apport de connaissances via plusieurs vidéos et activités d’analyse, ainsi qu’un bilan final. 

Tableau 5. Les cinq activités du dispositif 5J5IA 

Enseigner et apprendre à l’ère de l’intelligence artificielle Sommaire 

69 

 
LA RECHERCHE EN COURS A PARTIR DU DISPOSITIF 5J5IA 

Un dispositif connecté 

5J5IA est un dispositif pédagogique conçu pour être réalisé en ligne, autour des activités IA 
disponibles sur le Web. Il s’agit d’une contrainte à envisager en premier lieu avant de se lancer 
dans le dispositif (classe connectée : une tablette connectée pour un à trois élèves). Les 
activités sont réalisées directement dans un questionnaire en ligne (via Limesurvey)37. 

les connaissances et 
Ainsi, nous pouvons collecter 
représentations des élèves autour de l’IA, transformant le dispositif pédagogique en outil de 
recherche. L’analyse des données vise une meilleure régulation de l’IA par la pédagogie, 
objectif mis à l’épreuve de notre première collecte de données. 

les activités-réponses, donc 

Résultats préliminaires de la recherche en cours 

La diffusion de ce dispositif a été réalisée via des réseaux sociaux et auprès d’INSPE 
partenaires, ainsi que par l’entremise de la Direction du numérique pour l’éducation (auprès 
de 36 experts nationaux animant un réseau de 450 enseignants), sur la période allant de juin 
2021 à janvier 2022. Le dispositif a aussi été présenté lors de colloques et ateliers 
pédagogiques, comme le colloque Didapro 2022. 

La collecte de données est en cours depuis l’année scolaire 2021-2022, en trois phases 
successives : (1) déclaration d’intention d’usage par les enseignants, (2) résultats sur 
Limesurvey une fois les activités réalisées, (3) retour d’expériences des enseignants. 

En ce qui concerne la déclaration d’intention d’usage par les enseignants (phase 1), nous 
avons récolté 78 réponses partielles, dont trois intentions d’intégration au second trimestre en 
classes de CM2, 3e et 2d, ainsi que sept intentions d’intégration au 3e trimestre. Huit 
enseignants (5 femmes, 3 hommes) ont accepté de nous donner leurs coordonnées pour un 
témoignage après expérimentation (2xCE2, 1xCM1, 2xCM2, 1x6e, 1x4e, 1x3e). Ces 
témoignages, portant sur l’expérience d’apprentissage d’élèves de 7 à 15 ans, peuvent 
constituer une bonne base de départ. 

En dehors de l’acculturation à l’IA, les déclarations d’intentions évoquent un usage disciplinaire 
prévisionnel essentiellement centré sur les langues : vocabulaire, prononciation, ponctuation, 
intonation, « fluence de lecture » (un enseignant de CM2), et pour « alimenter les débats en 
enseignement moral et civique sur la place de l’IA dans notre quotidien et plus généralement 
sur l’impact des technologies » (un enseignant de CM1). 

Pour l’heure, aucune intégration complète n’a pu être constatée et produire les résultats selon 
le scénario prévu (phase 2), via les questionnaires sur Limesurvey. Enfin, le témoignage d’un 
enseignant (phase 3) portant sur la réalisation complète de l’activité n°1 (de dictée vocale) en 
double classe de CE1-CE2, nous laisse espérer des résultats prometteurs lorsque l’adoption 
du dispositif sera plus franche. Au rang des difficultés rencontrées, la gestion technique des 
tablettes (charge, configuration, emprunt) et des difficultés pédagogiques sont relevées, 
comme la gestion du bruit généré par l’activité et les difficultés d’articulation de certains élèves 
rendant l’activité de dictée difficile (mais intéressante en termes de plus-value). 

L’enseignant mentionne que « l’intérêt des élèves est très fort pour l’activité [de dictée vocale 
sur tablettes], [captivant les élèves] pendant une demi-heure facilement ». L’enseignant 

37 Pour un exemple d’activités, voir https://enquetes.univ-cotedazur.fr/index.php/98944?lang=fr. 

Enseigner et apprendre à l’ère de l’intelligence artificielle Sommaire 

70 

 
évoque une activité agréable et facile à scénariser en toute ou partie (autonomie) de classe. 
L’enrichissement en matière de culture numérique est avéré, les « discussions de début 
d’activité faisaient ressortir le caractère très intelligent et presque sans défaut de 
l’informatique » alors que « la mise en commun après l’activité était plus nuancée et montrait 
une réflexion sur les limites de la technologie ». Pour autant, « la plupart des élèves 
considèrent la tablette et ses fonctions comme un tout, et n’ont pas fait de différence entre l’IA 
et le matériel qu’ils utilisaient ». Nous constatons un début prometteur d’acculturation aux 
cybertechniques, certes insuffisant, mais qui serait normalement étoffé par les quatre autres 
activités, si le dispositif était réalisé dans son entièreté. Finalement, l’enseignant évoque une 
expérience très positive, engageant une suite, potentiellement dans d’autres classes car « on 
peut clairement adapter ces activités pour tous niveaux ! ». 

Quant aux réponses des élèves (n=17) au questionnaire d’activité, elles montrent que la 
régulation de l’IA en contexte éducatif (que nous proposons ci-dessus) est nécessaire, tant les 
représentations sont erronées en matière de TIC et d’IA (à l’âge de 8 ans ici). Les résultats 
précédents laissent à penser que la réalisation intégrale du dispositif permettrait de corriger 
(au moins en partie) cela. 

Une responsabilité à hauteur des enjeux 

l’IA nous 

Une régulation pédagogique de l’IA visant l’émancipation du citoyen numérique doit reposer 
sur un modèle d’intégration raisonnée des usages de l’IA en éducation. Au niveau micro, cette 
régulation ne peut aller de soi, car il faut envisager trois phases chronophages : la découverte, 
l’apprentissage et l’appropriation. Quant aux niveaux méso et macro, la régulation 
invite à penser notre humanisme avec des référents 
pédagogique de 
anthropologiques (Charlot, 2020) qui servent à enrichir notre rapport aux objets (Doueihi, 
2011). Intrinsèquement l’humain qui œuvre par et avec l’IA doit intégrer des dimensions 
éthiques avec le souci de développer des liens sociaux, des communautés, des règles et 
codes sociaux qui assurent son bien-être, l’acquisition de valeurs humaines, sociales, 
solidaires, fraternelles dans un monde en pleine mutation. En ce sens, découvrir, apprendre 
et surtout s’approprier l’IA en contexte éducatif, comporte une dimension émancipatrice qui 
doit favoriser le pouvoir d’agir de chaque personne et non son aliénation numérique. 

La régulation pédagogique de l’IA nécessite donc une vision écosystémique des usages de 
l’IA (et du numérique) en éducation pour tirer le potentiel de la technique sans abandonner le 
pouvoir de décisions aux machines, sans succomber au « poison » du pharmakon numérique. 
L’IA représente un 
l’humanité, mais entraîne de grandes 
responsabilités pour la maîtriser. Là semble être l’enjeu du numérique pour l’éducation à l’ère 
de l’IA. 

immense potentiel pour 

Ressources complémentaires 

Les activités et le livret pédagogique sont disponibles en ligne. https://scoliablog.wordpress.com/5j5ia/. 

Enseigner et apprendre à l’ère de l’intelligence artificielle Sommaire 

71 

Références 

Alexandre, F., Becker, J., Comte, M.H., Lagarrigue, A., Liblau, R. Romero, 
M. et Vieville, T. (2021). Why, What and How to help each Citizen to 
Understand Artificial Intelligence?. KI - Künstliche Intelligenz, Springer 
Nature, 2021, p. 1610-1987. 

Bernard, F. (2018). Penser et vivre « l’expérience » : Apports pragmatistes 
de John Dewey Dans S. Leleu-Merviel, D. Schmitt et P. Useille, De l’UXD au 
LivXD design des expériences de vie (ISTE Editions). Hermes Science 
Publishing Ltd. 

Céci, J.-F. (2019). Apprentissage du et par le numérique : la formation des 
jeunes générations à un juste usage du numérique. Annales des Mines - 
Enjeux Numériques, Conseil général de l’Économie, ministère de l’Économie 
et des Finances, 2019, p.76-81. ⟨hal-02154297⟩ 

Céci, J.-F. (2020). Transition de la forme scolaire au prisme du Numérique : 
Le Numérique comme catalyseur et révélateur [Thèse, Université de Pau et 
des Pays de l’Adour, Pau, FRA.]. ⟨tel-03250689⟩ 

Cerisier, J.-F. (2011). Acculturation numérique et médiation instrumentale. 
Le cas des adolescents français. [HDR, Université de Poitiers, Poitiers, 
FRA.]. https://tel.archives-ouvertes.fr/tel-00922778 

Charlot, B. (2020). Education ou Barbarie - Pour une Anthropologie-
Pedagogie Contemporaine. Paris : Economica. 

Doueihi, M. (2011). Pour un humanisme numérique. Seuil. 

Dubet, F. (2002). Le déclin de l’institution. Paris : Seuil. 

Dweck, C. S. (2010). Changer d’état d’esprit : Une nouvelle psychologie de 
la réussite. Wavre : Mardaga. 

Ellul, J. (2004). Le système technicien. Paris : le Cherche midi. (Ouvrage 
original publié en 1977) 

Hamadache, A. (1993). Articulation de l’éducation formelle et non formelle—
Implications pour la formation des enseignants. Rapport 1993 de l’UNESCO. 
http://unesdoc.unesco.org/images/0010/001001/100125f.pdf 

Heiser, L., Romero, M., Prokofieva, V., Acevedo, A., Lefèvre, S. C. et Isaac, 
G. (2022). Analyse des activités technocréatives au collège en contexte 
d’éducation FabLab. Rapport LINE. 

Merzeau, L. (2017). De la bibliothèque à l’Internet : La matrice réticulaire. 
Dans Du 
l’électeur. Bibliothèque, démocratie et autorité. 
http://merzeau.net/matrice-reticulaire/ 

lecteur à 

Morin, E. (1994). La complexité humaine. Paris : Flammarion. 

Pellaud, F. et Eastes, R.-E. (2020). Éduquer à la condition terrestre. 
Éducation relative à l’environnement. Regards - Recherches - Réflexions, 
Volume 15-2, Article Volume 15-2. 

Romero, M., Aloui, H., Heiser, L., Galindo, L. et Lepage, A. (2021). Un bref 
parcours sur les ressources, pratiques et acteurs en IA et éducation. Rapport 
GTnum Scol\_IA. 

Simondon, G. (1958). Du mode d’existence des objets techniques. Aubier 
Montaigne. 

Vincent, G. (2021). L’école primaire française : étude sociologique. Presses 
universitaires de Lyon. 

Enseigner et apprendre à l’ère de l’intelligence artificielle Sommaire 

72 

Vuorikari, R., R., Kluzer, S. et Punie, Y. (2022). DigComp 2.2: The Digital 
Competence Framework for Citizens-With new examples of knowledge, 
skills and attitudes (No. JRC128415). Joint Research Centre, Sevilla. 

Enseigner et apprendre à l’ère de l’intelligence artificielle Sommaire 

73 

 
8 /// L’ACCULTURATION 
AU NUMERIQUE 

Michel Durampart1 
Philippe Bonfils1 
Anne Gagnebien1 
Audrey Bonjour1 
Pauline Reboul1 
Sami Ben Amor1 
Laurent Heiser1 2 

1 Institut méditerranéen des sciences de l’information et de la communication, Université de Toulon, France 
2 Laboratoire d’innovation pour le numérique en éducation, Université Côte d’Azur, France 

Les usages des technologies éducatives, dont l’intelligence artificielle (IA) 
fait partie, demandent une 
réadaptation et un encadrement 
pédagogique. Les représentations et la culture des acteurs, enseignants et 
élèves, peuvent percuter la forme scolaire et sont des points à prendre en 
compte dans l’intégration de l’IA. 

Ce chapitre poursuit deux objectifs : d’une part, définir l’acculturation à l’IA 
en tant que vaste mouvement d’appropriation des outils numériques et, 
d’autre part, à la lumière des travaux de l’Institut méditerranéen des sciences 
de l’information et de la communication (IMSIC), analyser différents usages 
de l’IA permettant de mettre en perspective l’acculturation à l’IA en 
éducation. 

La notion d’acculturation au numérique 

Les sciences de l’information et de la communication ont contribué à mettre en évidence que 
la relation entre numérique et éducation est complexe (Moeglin, 2005), itérative et traversée 
d’enjeux multiples (Durampart, 2018). Dans ce contexte, les chercheurs du laboratoire IMSIC, 
à travers de nombreux programmes de recherche et publications (Collet et al. 2014 ; 
Barbagelatta et al. 2014 ; Dechamp et al. 2018 ; Bonfils et Peraya, 2016 ; Bonfils, 2015, Bonfils 
et Durampart, 2013), ont observé les pratiques des enseignants et des élèves au sein des 
classes ou encore au sein d’un Incubateur (2016-2018). Ils ont pu constater que les artefacts 
numériques destinés aux activités d’apprentissage (Bernard et al., 2018) tendent à provoquer 
des tensions et des apories au sein de la forme scolaire (Vincent, 1994). 

Au fil de près de douze années de travaux conduits au sein du laboratoire, la notion 
d’acculturation nous a semblé pertinente pour qualifier ce vaste mouvement d’appropriation 
des outils numériques venant percuter la pédagogie et les pratiques éducatives. Cette notion 
est venue se former comme une heuristique féconde afin de qualifier un mouvement instable, 
discontinu et hétérogène qui couvre le champ des pratiques où le numérique agit dans le 
contexte et dans les pratiques éducatives. C’est en ce sens que les chercheurs mobilisés sur 
ces enjeux et questions proposent de réfléchir en termes « d’acculturation au numérique » et 
non de « culture numérique » (Durampart, 2016). L’enjeu principal est d’intégrer cette 
supposée culture numérique dans une perspective de bien-être économique et social, 
l’inclusion numérique désignant plus largement « la capacité de chacun à savoir mobiliser ces 
technologies, compétence fondamentale à l’heure du poids croissant de l’économie de la 

Enseigner et apprendre à l’ère de l’intelligence artificielle Sommaire 

74 

 
 
 
connaissance » (Ministère de l’Économie Numérique, 2013). S’il est impossible de restituer la 
diversité des terrains et projets dans lesquels nous nous sommes impliqués, il est possible de 
retracer quelques étapes et jalons clefs qui nous ont permis de mieux cerner cette notion 
d’acculturation au numérique. 

La notion d’acculturation permet de qualifier le vaste mouvement d’appropriation des outils numériques 
venant percuter la pédagogie et les pratiques éducatives. 

L’élément déclencheur des projets de recherche sur l’acculturation numérique de l’IMSIC 
réside dans une étude réalisée dans le cadre de l’observatoire des TIC de la région PACA 
(programme OBTIC, voir Pélissier et al. 2013). Selon cette étude, malgré un bon niveau de 
connaissances du numérique et un usage intensif des réseaux sociaux dans leurs pratiques 
de communication, seule une minorité d’élèves exploite sa « culture numérique » dans une 
perspective d’insertion et d’orientation professionnelle. Même si un apprentissage formel est 
indispensable pour atténuer la diversité du degré de maîtrise des acteurs sociaux, encore faut-
il qu’ils soient capables de mobiliser ces nouvelles pratiques de communication et 
d’information dans des contextes autres que ceux liés aux loisirs et aux relations 
interpersonnelles. L’enjeu de l’acculturation au numérique renverrait donc à une forme de 
capital économique, social et culturel instable, hétérogène et disséminé. Elle est remise sans 
cesse en jeu et en question, avec de multiples modes différents d’appropriation, dans des 
contextes divers, renvoyant aussi à des formes successives ou alternées d’apprentissage 
empilée, qu’elles soient formelles ou informelles. 

Les trois niveaux d’acculturation numérique 

Le concept d’acculturation au numérique que nous avons développé se décline en trois 
niveaux présentés dans les paragraphes qui suivent : l’acquisition de savoirs, l’interaction 
entre les usages personnels et professionnels, et l’utilisation dans les pratiques pédagogiques. 

PREMIER NIVEAU D’ACCULTURATION NUMERIQUE : L’ACQUISITION DES SAVOIRS 
PAR LES ENSEIGNANTS 

Le premier niveau d’acculturation au numérique concerne l’acquisition de savoirs par la 
formation. Parmi les enseignants âgés entre 31 et 50 ans (ce qui représente 77 % de nos 
répondants38), 82 % ont suivi une formation initiale dans les IUFM, avant les INSPE. Ce sont 
73 % d’entre eux qui disent utiliser souvent le numérique, tout en déplorant dans l’ensemble 
une formation insuffisante (68 %). Ils utilisent plus souvent les TIC comme outil personnel 
plutôt que comme outil d’échange ou de partage. Les apprentissages initiaux (p. ex. essais, 
bricolage et autoapprentissage), ou partagés (en situation de co-apprentissage et de multi-
apprentissage), se déroulant chez soi, dans l’environnement domestique, avec des 
orientations ludiques ou influençant des besoins et attentes diverses en quête de facilitation 
de la vie quotidienne, impactent les usages en situation professionnelle, entre difficultés à les 

38 Les données sont issues du programme de recherche Numécole (2014-2016). Un questionnaire a été adressé aux 
enseignants en novembre 2015 et visait à analyser d’un point de vue quantitatif l’expérimentation d’applications numériques en 
Lorraine et en Provence-Alpes-Côte-d’Azur. Les enseignants des 80 classes participantes (plus de 200) à ce programme y ont 
répondu. Dans la perspective de notre étude d’usage, il s’agissait de confronter les réponses à ce questionnaire aux données 
qualitatives récoltées à travers des observations et entretiens d’un échantillon de 8 enseignants au préalable. 

Enseigner et apprendre à l’ère de l’intelligence artificielle Sommaire 

75 

 
retraduire et certaines formes d’aisance. Le manque de formation dans le contexte 
professionnel rend difficile le développement d’un niveau de maîtrise avancé. 

Au premier niveau d’acculturation numérique, les enseignants utilisent le numérique comme outil personnel 
plutôt que comme outil d’échange ou de partage. 

SECOND NIVEAU D’ACCULTURATION NUMERIQUE : DES LIENS ENTRE LES USAGES 
PERSONNELS ET PROFESSIONNELS 

Au second niveau d’acculturation numérique, l’intégration du numérique par les enseignants 
vise à favoriser la relation entre l’école et la maison et met une diversité de supports au service 
de l’activité pédagogique. Ce niveau se situe dans un lien possible et contrarié entre pratiques 
et utilisations, apprentissages privés, personnels, domestiques et ceux du monde 
professionnel ou scolaire. Les projets dits innovants liés au numérique (Incubateur, 2018-
2019) s’inscrivent bien dans une volonté globale d’exploiter les supports numériques pour 
favoriser la continuité entre l’école et la maison. 

Pour autant, la transposition des usages du numérique de la sphère privée vers la sphère de 
l’établissement scolaire demande une réadaptation et un encadrement pédagogique. « Les 
tablettes rentrent dans l’établissement parce qu’elles sont rentrées dans nos vies », nous dit 
une enseignante. Elle insiste aussi sur le fait qu’il faut adopter une logique de recherche 
d’information pour que la tablette soit pédagogique (par le recours à une intense recherche 
documentaire). C’est ce que nous avons désigné comme un phénomène de porosité, constaté 
à la place prise par le numérique dans le monde scolaire qui met directement en jeu la « forme 
scolaire » (Vincent, 1994). 

TROISIEME NIVEAU D’ACCULTURATION NUMERIQUE : LES DISPOSITIFS 
NUMERIQUES DANS LES PRATIQUES PEDAGOGIQUES 

Finalement, le troisième niveau concerne le recours aux dispositifs numériques dans le cadre 
même des pratiques pédagogiques. Nous avons réalisé un vaste programme d’observations 
centré sur les apprentissages fondamentaux du numérique entre 2014-2016. Ce programme, 
nommé Numécole, a permis de réaliser des observations dans des lycées et collèges dits 
défavorisés de Toulon, des journées d’études avec du personnel enseignant et des projets 
d’incubateurs numériques. Les questionnements qui émergent de ces observations résident 
dans le transfert de l’étude des usages vers un regard sur les interfaces. Les enseignants 
expérimentateurs ayant participé à Numécole déclarent principalement des usages 
professionnels du numérique liés : au traitement de texte (95 % dont 90 % pour le français), 
aux documents audiovisuels (86 % dont environ 46 % pour l’histoire, la géographie, les 
sciences et les arts), aux navigateurs Web (72 % dont 46 % pour la recherche documentaire), 
à des logiciels ou documents créés par l’enseignant (69 % principalement pour le français et 
un peu moins pour les mathématiques), à des sites Web éducatifs (62 %, en français, 
mathématiques, sciences et technologies), à des jeux et applications (autour de 63 %, 
principalement en mathématiques et français). Les usages professionnels liés à la publication 
assistée par ordinateur sont moins développés (49 %), de même que ceux liés aux 
encyclopédies numériques (41 %), aux ressources institutionnelles en ligne (37 %), aux 
tableurs (18 %), logiciels de PAO (Photoshop, Publisher…) (49 %) et aux espaces numériques 
de travail (43 %). 

Enseigner et apprendre à l’ère de l’intelligence artificielle Sommaire 

76 

Le troisième niveau d’acculturation numérique concerne l’utilisation des dispositifs numériques dans le cadre 
des pratiques pédagogiques. 

Ensuite vient la question de l’orientation et des motivations qui fondent la relation entre 
dispositifs numériques et pédagogie. De manière générale, dans l’étude Numécole, au-delà 
de la question du numérique à l’école, les approches pédagogiques des enseignants sont 
plutôt disciplinaires (75 %) bien qu’ils déclarent aborder des compétences transversales 
méthodologiques dès que possible (74 %). L’enjeu principal de leur enseignement est 
l’autonomie des élèves (77 %). Le travail individuel et différencié domine largement (77 % et 
56 %) et l’élève préféré est l’élève autonome (82 %). Ils disposent le plus souvent (53 %) de 
leur classe en alignant les tables face au tableau. Dans ce cadre, les enseignants 
expérimentateurs déclarent avoir pour principaux objectifs de l’utilisation du numérique en 
classe, par ordre de fréquence décroissante : la différenciation pédagogique, l’individualisation 
des apprentissages, la motivation, l’aspect ludique, la variation des supports (couleurs), le la 
préparation au brevet informatique et internet, l’éducation aux médias et à l’information. 

Nous proposons d’aborder un positionnement critique dans l’étude des transformations 
induites par les nouveaux médias éducatifs et les médiations liées aux technologies 
numériques. Sous cet angle, l’acculturation numérique induit notre volonté et capacité à 
analyser les possibles transformations affectives, psychocognitives et pragmatiques (Collet et 
al., 2021) des enseignants et des élèves face à un phénomène de mécanisation (Mœglin, 
1993) et de rationalisation des apprentissages que pourrait relancer l’ère de l’IA. Différentes 
approches ont été mises de l’avant par les enseignants de Numécole quant à la façon 
d’intégrer les technologies de l’information et de la communication en enseignement. Parmi 
celles-ci, nous trouvons : l’approche didactique, la transmission des connaissances, 
l’approche cognitive (80 % des répondants l’ont classée en premier ou deuxième), l’école 
comme développement de l’intelligence, l’approche citoyenne (l’école comme lieu de 
socialisation), l’approche culturelle (l’école comme lieu d’intégration dans une culture) (elles 
arrivent juste après dans le primaire avec au collège l’approche culturelle qui est placée en 
deuxième), l’approche professionnelle (l’école comme lieu de préparation à l’insertion 
professionnelle, largement classée en dernier, au primaire comme au collège). 

Que dit le concept d’acculturation numérique sur 
l’intégration des technologies à l’école 

À la lumière de nos résultats, nous envisageons le concept d’acculturation comme un cadre 
permettant d’étudier l’intégration des technologies numériques dans l’école. Depuis près de 
15 ans, des programmes innovants sont inscrits au sein de démarches éducatives ou 
dynamiques de projets, accompagnées par l’institution mais aussi présentes dans les 
pratiques enseignantes. Les élèves sont pris dans des injonctions et volontés contradictoires 
tissées d’émancipation, d’autonomie, d’individuation, de participation, d’engagement, de 
soutien et d’aide voire de réinsertion et d’accompagnement perçues comme des dynamiques 
innovantes, stimulantes offertes par des outils et technologies numériques. 

Dans le programme Incubateur, nous constatons que, pour les élèves, les activités recourant 
au numérique à l’école sont le prolongement du projet hors du cadre scolaire (ils continuent à 
travailler en groupe en dehors des heures de cours) avec l’idée d’acquérir des compétences 

Enseigner et apprendre à l’ère de l’intelligence artificielle Sommaire 

77 

transversales. Un degré plus important d’autonomie, essentiel pour l’apprentissage de 
connaissances disciplinaires, est le fait de savoir agir en équipe. De façon assez constante 
dans tous les programmes, les enseignants insistent sur l’apport des outils numériques dans 
la pédagogie pour la remise en cause des routines de comportement, des habitudes de travail, 
une aide au décloisonnement en dépit d’une chronophagie technologique. 

In fine, l’acculturation au numérique est aussi une question d’écarts, autant pour les 
enseignants que les apprenants, entre l’utilisation et la maîtrise du numérique. Elle est aussi 
une question d’évolution de la forme scolaire, et plus globalement du monde éducatif, et 
s’inscrit dans des pratiques socioculturelles liées à l’usage de différents systèmes symboliques 
ou numériques (Kabuto et Harmey, 2019). 

Par le biais d’usages créatifs, l’acculturation numérique, c’est aussi la possibilité de trouver de 
nouvelles modalités pédagogiques permettant d’engager les élèves dans des activités de 
collaboration. Il s’agit moins d’utiliser le numérique que de trouver, en commun, comment ce 
dernier peut permettre de développer une représentation forte des objectifs de développement 
durable (comme l’Agenda 2030). En ce sens, les CurriQvidéos, un dispositif inventé par Faller 
et Heiser (2022) à l’INSPÉ de Nice, donne à voir plusieurs cours d’action de primo-enseignants 
qui racontent comment le numérique (des robots pédagogiques, des microcontrôleurs, etc.) et 
aujourd’hui l’IA (à travers, par exemple, Google Teachable Machine, VittaScience ou encore 
5J5IA), permettraient d’engager les élèves dans des activités participatives de préservation du 
patrimoine naturel et culturel (Heiser et al. 2021). En définitive, se situer dans le cours de 
l’acculturation, c’est bien s’intéresser au processus non stabilisé d’évolution de l’éducation 
face, avec et par le numérique, sans espérer que le développement de la citoyenneté 
numérique s’opère sans intervention spécifique, mais en l’accompagnant pédagogiquement. 

Perspectives pour une acculturation face au 
numérique au regard des perspectives de l’IA dans 
les apprentissages et l’éducation 

Le groupe T2 associant des chercheurs de l’IMSIC et d’autres chercheurs du GTnum #Scol\_IA 
se situe dans cette perspective de l’acculturation numérique. Si nous éprouvons un certain 
nombre de programmes où l’IA est présente sous forme d’aboutissement d’un projet ou d’une 
réalisation, nous nous situons dans son antichambre en essayant d’interroger comment des 
recours et des perspectives liées aux enjeux de l’IA vont venir interroger, réorienter ou redéfinir 
le niveau d’acculturation numérique observé. 

À l’origine, un programme Médipath (Collet et al. 2021) hors contexte éducatif nous a permis 
de mesurer des enjeux en termes de réorientations d’une expertise médicale liée à des gains 
de temps et à une facilitation de l’expertise. Un programme au sein de l’enseignement 
supérieur et de l’apprentissage professionnel dans le domaine naval (E-DEAL) envisage les 
modalités de transfert et d’acculturation aux pratiques numériques industrielles rassemblées 
autour des concepts d’industrie 4.0 (Julien et Martin, 2018) et de jumeau numérique (Julien et 
Martin, 2020). La gestion des données et l’intégration de l’IA deviennent des enjeux de 
formation à part entière conséquemment aux transformations des métiers par l’intégration de 
ces technologies. Ce projet de recherche questionne également les représentations et la 
culture des acteurs de l’industrie concernant les potentialités de l’IA et des traces 
d’apprentissage (learning analytics) (Peraya, 2019) en termes de profilage, d’individualisation 

Enseigner et apprendre à l’ère de l’intelligence artificielle Sommaire 

78 

des parcours de 
formation, d’autonomisation et d’accentuation des pratiques 
d’autoapprentissage pour des communautés d’apprenants en formation professionnelle. 
D’autres éclairages émanant de l’éducation spécialisée montrent que, même, si les 
technologies numériques cristallisent des tensions inhérentes au champ du travail social 
(Bonjour, 2011, p. 52) et conduisent, dans les usages, à produire autant d’évidences que de 
paradoxes (Bonjour et Daragon, 2017), elles permettent aussi d’introduire davantage 
d’apprentissages dits scolaires (particulièrement en mathématiques et en lecture) quand de 
nombreux travailleurs sociaux sont démunis pour mener à bien ces objectifs. L’IA offre alors 
des possibilités de soutien à la remédiation cognitive et comportementale pour les personnes 
à besoins spécifiques. En conséquence, l’information, la formation et la mutualisation des 
pratiques nous paraissent être trois défis majeurs pour le travail sur autrui (Dubet, 2002) à l’ère 
du numérique (Bonjour et Daragon, 2018). 

Du côté des ressources dans les plateformes éducatives, les questionnements orientés vers 
l’évolution des formes organisationnelles nous amènent à interroger les perspectives 
éducatives de l’IA. Il s’agit de se focaliser sur le préalable que constitue la question de 
l’acculturation aux données constituées par les traces d’utilisation que les enseignants et les 
élèves laissent dans ces environnements numériques. Les enjeux de l’IA en éducation 
semblent s’orienter vers le repérage des dynamiques et contextes d’apprentissage, le 
profilage, l’identification et la construction stratégique des données, afin d’engager des formes 
d’apprentissage centrées sur l’autonomie, l’autoformation, les communautés d’apprenants en 
lien avec les enseignants. Ces environnements instaurent aussi la vision d’une nouvelle 
performance d’interfaces et de médiations, supposées expérientielles et efficientes, dans une 
démarche qui relie l’exploitation des artefacts, des données et de nouveaux processus. Nous 
partons des enjeux d’une traduction de l’IA dans l’acculturation numérique en cours avec des 
questionnements sur les limites, contraintes et apories dans le système éducatif ou sur des 
formes d’apprentissage. Il est possible alors d’envisager que l’IA soit une rupture dans une 
continuité. Son intégration dans l’école ou la formation reprend encore des discours, débats 
et invocations passées, qui retrouvent une nouvelle vigueur dans les expériences et 
démarches liées à l’IA et, en même temps, stimule de nouveau enjeux ou tensions au cœur 
des mondes et systèmes éducatifs. 

Références 

Argyris, C., & Schön, D. A. (1997). Organizational learning: A theory of action 
perspective. Reis, (77/78), p. 345-348.Barbagelata, P., Inaudi, A. et 
Pelissier, M. (2014). Le numérique vecteur d’un renouveau des pratiques de 
lecture : Leurre ou opportunité ? Études de communication. langages, 
information, médiations, 43, p. 17-38. 

Bélisle, C., Berthaud, C., Le Marec, J., Liautard, D., Paquelin, D., Rosado, 
E., (2002), Méthodes et outils pour l’observation et l’analyse des usages – 
étudier les usages pédagogiques des technologies de l’information et de la 
communication : une pratique de recherche ou/et de légitimation ?, Paris : 
Maison des Sciences de l’Homme/PNER. 

Bernard, F., Beyaert-Geslin, A., Bouchardon, S., Bouillon, J.-L., Cerisier, J.-
F., Chabert, G., Chaudiron, S., Damian-Gaillard, B., Douyère, D., Fleury, B., 
Galibert, O., Garcin-Marrou, I., Gimello-Mesplomb, F., Jacobi, D., Lafon, B., 
Legendre, B., Leleu-Merviel, S., Marchand, P., Marcon, C., … Zacklad, M. 
(2018). Dynamique des recherches en sciences de l’information et de la 
communication. 

Enseigner et apprendre à l’ère de l’intelligence artificielle Sommaire 

79 

Bonfils, P., & Durampart, M. (2013). Environnements immersifs et dispositifs 
distanciées. 
numériques. Etudes 
ESSACHESS – Journal for Communication Studies, 6(1(11)), p. 107-124. 

expérimentales 

approches 

et 

Bonfils, P., Collet, L., Durampart, M., Duvernay, D. et Gaste, D. (2014). 
Étudier les environnements immersifs en milieu industriel : Le cas de la 
formation chez Eurocopter. Les Cahiers de la SFSIC, 10, 156. 

Bonfils, P. (2015). « Immersion et environnements numériques : Une 
approche méthodologique par l’expérience vécue ». Dans Question de 
communication, N°27, Metz. p. 261-277. 

Bonfils, P. et Peraya, D. (2016). Processus décisionnels au sein de groupes 
d’étudiants en contexte de projet pédagogique : Le cas d’étudiants à l’UFR 
Ingémédia de l’Université de Toulon. Communication et organisation. Revue 
scientifique francophone en Communication organisationnelle, 49, Article 49. 

Bonjour, A. (2011). Usages et pratiques socio-(ré)éducommunicationnels 
pour les personnes handicapées mentales. Outils informatiques et média 
Internet. Université Paul Verlaine-Metz. Disponible sur : http://tel.archives-
ouvertes.fr/tel-00738077 

Bonjour A. et Daragon E. (2017). « Les technologies numériques dans les 
ESMS, entre évidences et paradoxes », colloque KEDGE, Marseille 

Bonjour, A. et Daragon, E. (2018). Information, formation et mutualisation : 
Trois défis majeurs pour le travail social à l’ère du numérique. Revue Les 
cahiers de l’Actif. 

Bonjour A. et Daragon E., (2019). Information et données ouvertes : un bien 
commun mis à mal dans les établissements et services sociaux et médico-
sociaux ?, Nancy : Presses Universitaire de Nancy. 

Cerisier, J.-F. (2014). La forme scolaire à l’épreuve du numérique : when the 
digital culture challenges the dominant schooling model Université de 
Poitiers. 

Collet, L., Durampart, M. et Pélissier, M. (2013). Focus sur les terrains de 
recherche CRDP, médiathèques, OBTIC, en région PACA. Les Cahiers de 
la SFSIC, (10), p. 154-155. 

Collet, L., Durampart, M. et Pélissier, M. (2012). Le rôle des bibliothèques 
départementales à l’épreuve des services à distance et de la numérisation. 
Dans XVIIIème congrès de la Société Française des Sciences de 
l’Information et de la Communication. 

Collet L., Durampart M. et Pelissier M. (2014). Culture et acculturation au 
numérique : des enjeux clefs pour les organisations de la connaissance, Les 
cahiers de la sfsic, 2014, p. 148-153. 

Collet, L., Durampart, M., Heiser, L. et Picard, L. (2021). Enjeux expérientiels 
de l’utilisation de l’IA en anatomopathologie. Communiquer. Revue de 
communication sociale et publique, 33, p. 26-44. 

Dubet, F. (2002). Le déclin de l’institution. Paris : Seuil. 

Durampart, M. (2016). La forme scolaire en action traversée par l’école 
numérique. Revue française des sciences de l’information et de la 
communication, (9). 

Heiser, L., Faller, C. et Bonjour, A. (2021). Rendre accessible, valoriser et 
préserver le patrimoine naturel et culturel via des pratiques technocréatives 
en enseignement moral et civique. Retour d’expérience du dispositif de 
formation des professeurs des écoles CurriqVidéo. Axe 2 séminaire IMSIC. 

Enseigner et apprendre à l’ère de l’intelligence artificielle Sommaire 

80 

Faller, C. et Heiser, L. (2022). Croiser l’évaluation de compétences 
didactiques et numériques sur un même support : Un défi à relever dans un 
enregistrement vidéo (CurriQvidéo) en Master Enseignement Éducation et 
Formation du premier degré. Médiations et médiatisations, 9, p. 91-108. 

Kabuto, B. et Harmey, S. (2019). Literacy in a Global Context: Educational 
Policy, Pedagogy, and Teacher Education. Global Education Review, 6(2), 
p. 1-4. 

Julien, N. et Martin, É. (2018). L’usine du futur – Stratégies et déploiement - 
Industrie 4.0, de l’IoT aux jumeaux numériques : Industrie 4.0, de l’IoT aux 
jumeaux numériques. Dunod. 

Julien, N. et Martin, É. (2020). Le jumeau numérique : De l’intelligence 
artificielle à l’industrie agile. Dunod. 

Ministère de l’Économie Numérique. (2013). Citoyens d’une société 
numérique – Accès, Littératie, Médiations, Pouvoir d’agir : pour une nouvelle 
politique 
recherche]. 
https://cnnumerique.fr/files/uploads/2018/CNNum\_rapport\_Inclusion\_oct20
13.pdf 

d’inclusion. 

[Rapport 

de 

Peraya, D. (2019). Les Learning Analytics en question. Distances et 
médiations des savoirs. 25. 

Pelissier M., Perocheau G., Collet L., Boutin E. et Gaste D. (2013), Rapport 
d’étude « la culture numérique chez les 16-24 ans », Observatoire des TIC, 
Région Paca. 

Pélissier, M., Dechamp, G. et Romero, M. (2018). Le tournant créatif à 
l’université : Quelles modalités ? Quels enjeux ? Quelles légitimités ? Repéré 
à https://archivesic.ccsd.cnrs.fr/sic\_01823990 

forme scolaire ? 
Vincent, G. (1994). L’éducation prisonnière de 
Scolarisation et socialisation dans les sociétés industrielles. Presses 
Universitaires de Lyon. 

la 

Enseigner et apprendre à l’ère de l’intelligence artificielle Sommaire 

81 

 
9 /// PRESERVER 
L’AGENTIVITE DES 
ENSEIGNANTS ET 
ELEVES : DES PISTES 
ISSUES D’UNE 
RECENSION DES ECRITS 

Alexandre Lepage1 
Simon Collin2 

1 Université de Montréal, Canada 
2 Université du Québec à Montréal, Canada 

Automatiser des actions qui étaient autrefois réalisées par des humains peut 
poser un certain nombre de risques qu’il est toutefois possible de prévenir 
dès l’étape de conception. En éducation, le travail des enseignants comme 
celui des élèves est appelé à se transformer avec l’apparition des systèmes 
d’IA. 

Si aucune précaution n’est prise, certaines technologies éducatives basées 
sur l’IA risquent de limiter la capacité des enseignants à prendre eux-mêmes 
des décisions pédagogiques, en plus d’introduire des erreurs de 
classification ou de jugement. Néanmoins, des solutions existent. Ce 
chapitre présente les résultats partiels d’une recension systématique des 
écrits sur les enjeux éthiques de l’IA en éducation, en se concentrant sur les 
questions relatives à la préservation de l’agentivité des enseignants et des 
élèves. Il est structuré sous forme de rapport de recherche, avec contexte, 
méthode, résultats et discussion. Des pistes sont proposées pour se 
prémunir contre les risques recensés. 

Introduction 

L’éducation n’échappe pas au développement rapide des techniques d’intelligence artificielle 
(IA) et à leur capacité à réaliser des actions de plus en plus complexes. Dans le Consensus 
de Beijing sur l’IA en éducation, l’UNESCO (2019) entrevoit des bénéfices potentiels de l’IA 
dans plusieurs activités jusqu’à présent réalisées par des élèves, du personnel enseignant ou 
du personnel administratif. Les occasions d’utiliser l’IA en éducation sont nombreuses, que ce 
soit pour le tutorat intelligent, l’évaluation des apprentissages ou bien la prévention de 
l’abandon scolaire (Zawacki-Richter et al., 2019). Ces avancées nous amènent à nous poser 
de nouvelles questions : et si le personnel enseignant pouvait enfin être déchargé des 
fastidieuses heures passées à corriger des copies ? Un élève pourra-t-il obtenir une aide en 
temps réel, à la maison, lorsqu’il stagne sur un difficile problème de mathématique ? Une IA 

Enseigner et apprendre à l’ère de l’intelligence artificielle Sommaire 

82 

 
 
 
peut-elle faire aussi bien qu’un enseignant ? Ou même mieux ? Ces questions alimentent des 
craintes non fondées, mais elles demeurent pertinentes pour faire émerger des enjeux 
éthiques à considérer dans les déploiements futurs de l’IA en éducation. 

Le présent chapitre entend réfléchir à ces questions sous l’angle de la préservation de 
l’agentivité humaine (Engeström et Sannino, 2013), un des grands enjeux de l’IA en éducation 
aux côtés de la justice sociale, de la complexité humaine ou de la gouvernance, par exemple. 
Nous présenterons dans l’ordre quelques éléments contextuels dont certaines définitions de 
l’IA en éducation, deux repères théoriques, soit le système technicien et le concept 
d’agentivité, et finalement les résultats d’une recension des écrits sur les enjeux éthiques 
associés à l’agentivité et l’IA en éducation. 

QU’EST-CE QUE L’IA APPLIQUEE A L’EDUCATION ? 

L’IA peut d’abord être envisagée comme un ensemble de techniques aux contours plus ou 
moins définis. Ses techniques les plus communes relèvent de l’apprentissage automatique 
(machine learning), qui peut être supervisé, semi-supervisé ou non supervisé (Taulli, 2019). 
L’apprentissage profond par réseaux de neurones artificiels peut être utilisé pour traiter les 
données dites massives, c’est-à-dire caractérisées par la rapidité à laquelle elles se multiplient, 
leur volume et leur diversité (Taulli, 2019). Humble et Mozelius (2019) l’abordent en soulignant 
le caractère interdisciplinaire qui dépasse les sciences informatiques : « l’IA en éducation est 
un domaine interdisciplinaire intégrant la psychologie, la linguistique, les neurosciences, 
l’éducation, l’anthropologie et la sociologie dans le but de créer des outils puissants pour 
l’éducation et de mieux comprendre le phénomène d’apprentissage » (p. 1). L’IA peut aussi 
être définie autrement que par ses méthodes informatiques, par exemple par les fonctions 
qu’elle occupe dans un système. Loder et Nicholas (2018) présentent l’IA comme des 
« ordinateurs réalisant des tâches cognitives, généralement associées au raisonnement 
humain, particulièrement pour l’apprentissage et la résolution de problèmes » (p. 11). Pour 
Popenici et Kerr (2017), l’IA en éducation est constituée de « systèmes informatiques capables 
de s’engager dans des processus humains comme l’apprentissage, l’adaptation, la synthèse, 
l’autocorrection et l’utilisation de données pour des tâches complexes » (p. 4). C’est cette 
dernière que nous retiendrons, car elle permet de dépasser l’opposition entre l’intelligence 
humaine et l’IA et d’envisager des interactions complexes entre les deux. 

L’IA est un terme qui peut vouloir dire beaucoup de choses. Appliquée à l’éducation, elle vise à accomplir des 
tâches complexes qui étaient jusqu’à maintenant uniquement réalisées par des êtres humains (comme de la 
rétroaction ou l’adaptation du matériel didactique en fonction du niveau de difficulté optimal pour un groupe 
d’élèves). 

L’IA VIA LE PRISME DU SYSTEME TECHNICIEN 

Nous proposons d’envisager ces techniques sous l’angle de la théorie du système technicien 
de Ellul (1977). Selon cette théorie, les techniques redéfinissent constamment la réalité de 
l’expérience humaine. Ellul donne l’exemple de la télévision, rendue possible par accumulation 
de techniques. En la visionnant, les individus finissent par ne plus voir ces techniques. La 
télévision a rendu possible une nouvelle forme de communication que nous avons fini par 
intégrer, puis banaliser au point de ne même plus nous intéresser à son fonctionnement. En 
somme, les techniques qui l’ont rendue possible, comme l’électricité ou les antennes de 
diffusion, finissent par s’implanter et redéfinir les actions des individus qui utilisent la télévision, 
ainsi que les rapports sociaux auxquels ils participent plus largement, etc. En appliquant cette 

Enseigner et apprendre à l’ère de l’intelligence artificielle Sommaire 

83 

théorie à l’IA, on pourrait en venir à se demander si la complexité des techniques d’IA en 
éducation nous fera oublier la complexité des techniques et des gestes professionnels propres 
à l’enseignement. Comment les enseignants occuperaient le temps passé à concevoir et 
articuler des activités pédagogiques si des systèmes sélectionnaient et adaptaient 
automatiquement des exercices selon le niveau de leurs élèves ? Allons-nous cesser de nous 
intéresser à la docimologie, science de l’évaluation, parce qu’une IA le fait à notre place ? 
Contrairement à d’autres technologies éducatives, l’IA a de particulier qu’elle est développée 
dans le but d’accomplir des tâches de plus en plus complexes, ce qui permettrait à l’enseignant 
de se concentrer sur les tâches pour lesquelles l’IA fait moins bien (p. ex. les tâches de haute 
complexité qui exigent une compréhension fine du contexte, comme les relations avec les 
élèves). 

L’enseignement est composé d’actions complexes que les enseignants connaissent bien. Introduire des outils 
basés sur l’IA pour accomplir ces actions ne devrait pas nous amener à oublier ce que nous savons de cette 
complexité et la façon dont nous la gérons actuellement. 

L’AGENTIVITE POUR COMPRENDRE ET SITUER L’ACTIVITE HUMAINE 

La définition que nous avons retenue de l’IA en éducation plus haut, celle de Popenici et Kerr 
(2017), introduit l’idée que les systèmes informatiques simulant l’intelligence humaine 
prennent place dans des systèmes humains. Nous envisageons chacun de ces systèmes 
comme agents l’un de l’autre. En informatique, le terme agent désigne un système avec une 
certaine part d’autonomie capable de réaliser des actions qui auront un impact sur 
l’environnement dans lequel il se trouve : « l’action, qui est un concept fondamental pour les 
systèmes multi-agents, repose sur le fait que les agents accomplissent des actions qui vont 
modifier l’environnement des agents et donc leurs prises de décision futures » (Ferber, 1995, 
p. 13). C’est là une des particularités des systèmes complexes dits intelligents : ceux-ci ne se 
contentent pas de « raisonner » (Ferber, 1995, p. 13), ils agissent et transforment leur 
environnement. 

En sciences sociales, le concept d’agentivité fait aussi référence à une forme d’autonomie, 
mais cette fois de la part des personnes. Selon Engeström et Sannino (2013), « l’agentivité 
est une recherche volontaire de transformation de la part du sujet » et « se manifeste dans 
une situation problématique polymotivée dans laquelle le sujet évalue et interprète les 
circonstances, prend des décisions selon les interprétations et exécute ces décisions » (p. 7). 
Par exemple, un enseignant pourrait souhaiter offrir une rétroaction très précise à ses élèves, 
mais devoir rendre les notes le plus rapidement possible. Dans une telle situation, deux motifs 
sont en concurrence et c’est en prenant des actions agentives que l’enseignant parviendra à 
résoudre ce conflit de motifs. Pour l’IA en éducation, il pourrait s’agir de permettre à l’élève ou 
à l’enseignant, selon le cas, d’avoir une capacité d’action plus importante par l’utilisation de 
systèmes d’IA. Mais au-delà de ce scénario idéal, à l’heure actuelle, la plupart des usages de 
l’IA appliqués à l’éducation tendent plutôt à modéliser des décisions pédagogiques en vue 
d’une aide à la décision, d’une automatisation de certaines décisions ou d’une analyse des 
décisions prises. 

Les êtres humains sont caractérisés par leur agentivité, c’est-à-dire qu’ils parviennent à prendre des actions 
et des décisions dans des situations où seulement de l’information incomplète est disponible. 

Enseigner et apprendre à l’ère de l’intelligence artificielle Sommaire 

84 

QUESTION DE RECHERCHE 

À première vue, les domaines d’applications actuels de l’IA sont susceptibles d’empiéter sur 
l’agentivité des élèves et du personnel enseignant, notamment lorsqu’il est question 
d’évaluation et de choix des ressources ou activités pédagogiques. Pour dépasser ces 
perceptions initiales, nous poserons la question de recherche suivante : quels types d’usages 
de l’IA en éducation risquent de limiter l’agentivité des enseignants, et des élèves ? 

Méthode : une recension des écrits sur les enjeux 
éthiques 

Ce chapitre s’appuie sur des données rassemblées lors d’un projet de recension systématique 
des écrits autour des termes « éthique, IA et éducation », dans les bases de données Google 
Scholar, Web of Science, Microsoft Academic, EBSCO Education, Dimensions.ai et Scopus, 
et en procédant par sérendipité (Michel et Le Nagard, 2019). Les documents sont des articles 
scientifiques ou actes de colloque révisés par les pairs. Ils sont rédigés en français ou en 
anglais, et publiés entre 2010 et 2021 (N = 58). Les articles ont été lus puis des segments 
codés à l’aide du logiciel nVivo par deux personnes. Alors que la recension fera l’objet d’une 
publication spécifique (en rédaction), ce chapitre propose une analyse spécifique, approfondie 
et inédite, des enjeux relatifs à la préservation de l’agentivité humaine. Aux fins du présent 
chapitre, ce sont 24 documents (n = 24) qui ont été retenus pour l’analyse, lesquels 
comprenaient 62 segments codés. 

Résultats en lien avec l’agentivité des enseignants 
et des élèves 

Cette section présente, dans l’ordre, les résultats relatifs à l’agentivité des enseignants puis 
ceux relatifs à l’agentivité des élèves. Elle vise à rapporter le plus fidèlement possible, de façon 
objective et sans interprétation secondaire, les idées véhiculées dans la littérature. La 
discussion qui suivra permettra d’apporter certaines nuances. 

RESULTATS RELATIFS A L’AGENTIVITE DES ENSEIGNANTS 

Sans préciser le type d’outils d’IA dont il est question, plusieurs des documents consultés 
considèrent que ceux-ci risquent de diminuer l’agentivité des enseignants. Le développement 
de systèmes informatiques complexes fait passer une partie de leur pouvoir décisionnel vers 
des équipes de conception de logiciels : 

Intégrer des systèmes d’IA en éducation pourrait exacerber un déséquilibre des pouvoirs et créer de 
nouvelles inégalités. Les systèmes d’IA peuvent faire pivoter le centre de l’expertise des enseignants et 
gestionnaires scolaires vers les programmeurs ou concepteurs de systèmes qui créent les modèles 
permettant de diagnostiquer les retombées sur l’apprentissage, prédire les accomplissements scolaires et 
déterminer les recommandations qui seront affichées et à qui. (Berendt et al., 2020, p. 317). 

C’est le cas par exemple des tuteurs intelligents qui sélectionnent du matériel didactique à la 
place de l’enseignant, du diagnostic des élèves à risque ou bien de la prédiction de la réussite. 
Prenons l’exemple d’une enseignante de mathématiques qui crée elle-même une série 
d’exercices pour entraîner les élèves à la résolution d’équations du second degré. A priori, on 

Enseigner et apprendre à l’ère de l’intelligence artificielle Sommaire 

85 

pourrait penser qu’il s’agit là d’une tâche pouvant être automatisée, ou à tout le moins que du 
matériel existant pourrait être réutilisé. C’est peut-être le cas, mais on pourrait aussi chercher 
à comprendre pourquoi l’enseignante le fait, et faire des découvertes intéressantes. Elle 
pourrait le faire, par exemple, car elle enseigne auprès d’un groupe multiculturel et qu’elle ne 
trouve pas de problèmes mettant en scène des référents culturels pertinents pour son groupe. 
Elle pourrait aussi choisir d’utiliser volontairement une série d’exercices trop faciles pour ses 
élèves pour des considérations purement pédagogiques, par exemple pour renforcer 
momentanément leur confiance à réussir. Elle pourrait, tout compte fait, exercer son agentivité 
dans des situations polymotivées là où un système basé sur l’IA ne considérerait qu’un motif 
didactique. 

Une enseignante pourrait, tout compte fait, exercer son agentivité dans des situations polymotivées là où un 
système basé sur l’IA ne considérerait qu’un motif didactique. 

Selon Berendt et al. (2020), cela pourrait aussi conduire à un recul de compétences des 
enseignants qui pourraient prendre l’habitude de s’en remettre aux décisions d’un système au 
détriment de leur propre expertise. Tout porte à croire que le biais d’automatisation 
(Parasuraman et Manzey, 2010) pourrait aussi s’appliquer, c’est-à-dire qu’il pourrait y avoir 
une trop grande confiance envers les décisions des systèmes basés sur l’IA. De plus, si ce 
risque n’est pas reconnu par les établissements scolaires, ceux-ci pourraient exiger l’utilisation 
de certains outils par les enseignants sous l’illusion de meilleures prédictions ou résultats 
(Jones et al., 2020). 

L’agentivité inscrit toujours l’action dans un contexte élargi. Knox (2017) rappelle que les 
logiciels, algorithmes et bases de données sont toujours employés dans des contextes plus 
larges qu’il n’y paraît : 

L’utilisation des logiciels, algorithmes et bases de données, à travers plusieurs acteurs humains, est 
souvent envisagée comme trop détachée de l’éducation en tant que telle. Les données des étudiants sont 
soumises, et les enseignants sont encouragés à réagir face à ces données, sans pour autant qu’ils aient 
fait partie du processus responsable de leur production. (p. 737, traduction libre) 

Pour Corrin et al. (2019), l’usage d’outils basés sur l’IA doit toujours impliquer l’intervention 
humaine, par exemple pour la révision des décisions contestées et des erreurs de 
classification. Gras (2019), s’appuyant sur le Règlement général sur la protection des 
données, parle de la « nécessité du maintien du contrôle par l’humain » (p. 4), et Knox (2017) 
souligne que la possibilité de refuser les recommandations d’un système d’IA doit être 
préservée et ce, sans conséquences négatives pour les enseignants. Se basant sur une 
préoccupation similaire, Sjödén (2020) questionne qui devrait avoir préséance en cas de 
divergence (note à une évaluation, action à poser, diagnostic de risque d’échec par exemple) : 
l’enseignant ou l’IA ? 

L’importance de préserver l’agentivité est soulignée par plusieurs documents consultés. 
Adams et al. (2021) parle de laisser le choix aux enseignants de recourir ou non à des outils 
basés sur l’IA. Aiken et Epstein (2000) affirment : « il faut à tout prix préserver la capacité 
humaine de résoudre des problèmes et de réfléchir de façon rationnelle » (p. 166, traduction 
libre). Holmes et al. (2021) invite à ne pas tomber dans une glorification des progrès des 
systèmes informatiques qui diminuerait le rôle de l’humain. Sur la préservation de l’agentivité 
des enseignants, Smuha (2020) détonne parmi les autres documents consultés en affirmant 
que, dans la mesure où le choix d’utiliser ou non l’IA et de se fier ou non à ses 
recommandations demeure possible, l’agentivité peut être accrue : 

Enseigner et apprendre à l’ère de l’intelligence artificielle Sommaire 

86 

Tant que les humains peuvent choisir quand et dans quelles conditions les décisions sont déléguées à un 
système d’IA, l’agentivité humaine n’est pas seulement préservée, elle peut être accrue. (p. 8, traduction 
libre) 

Parmi tous les documents consultés, il y a convergence sur l’importance de préserver 
l’agentivité en laissant les enseignants libres d’utiliser ou non les outils basés sur l’IA. Et dès 
la conception, ces outils devraient être pensés pour augmenter l’agentivité et non la 
restreindre. 

RESULTATS RELATIFS A L’AGENTIVITE DES ELEVES 

l’enseignement supérieur, Roberts et al. (2017) constatent 

Les élèves devraient également pouvoir choisir d’agir conformément ou non aux 
recommandations d’un système d’IA (Roberts et al., 2017). À l’échelle de la situation 
d’enseignement-apprentissage, l’usage de l’IA peut retirer de l’agentivité aux élèves. Selon 
Bulger (2016), c’est le cas lorsqu’un système assigne des tâches scolaires. De façon 
spécifique à 
le risque 
d’infantilisation des personnes si des systèmes cherchent à ludifier lorsque cela n’est pas 
nécessaire ou souhaité par les apprenants. West et al. (2020) évoquent aussi ce risque, en 
insistant sur la pertinence des voix étudiantes dans le processus de régulation des 
apprentissages. Leurs perceptions, commentaires, expériences sont des éléments à 
considérer dans les décisions pédagogiques et ne devraient pas être diminués face à un 
système recourant à l’IA. 

Les élèves devraient également pouvoir choisir d’agir conformément ou non aux recommandations d’un 
système d’IA. 

À l’échelle du parcours scolaire d’un élève, des systèmes prédictifs qui s’appuient sur les 
données peuvent conduire à recommander des choix de programmes ou de cours (Jones et 
al., 2020). Ce problème s’inscrit plus généralement dans la problématique des bulles de filtre, 
où des algorithmes de recommandation parviennent bien à identifier des préférences à partir 
de données antérieures concernant une personne, mais parviennent mal à éveiller de 
nouveaux intérêts. C’est le cas, par exemple, de recommandations sur des plateformes 
musicales ou de visionnement de séries télévisées. Ce faisant, elles limitent l’agentivité (Jones 
et al., 2020) ou, à tout le moins, participent à redéfinir l’environnement dans lequel elle 
s’exerce. Regan et Jesse (2019) rappellent que ces usages, même s’ils peuvent sembler 
banals, ont une incidence sur la capacité des personnes à gérer leur vie librement. 

Regan et Jesse (2019), s’appuyant sur Kerr et Earle (2013), présentent trois types de 
prédictions pouvant affecter l’agentivité : les prédictions qui permettent aux personnes 
d’anticiper les conséquences négatives, les prédictions qui orientent vers des décisions 
spécifiques, et les prédictions prescriptives qui réduisent les choix possibles. Selon Regan et 
Jesse (2019), les prédictions basées sur les conséquences réduisent peu l’agentivité des 
personnes, alors que les prédictions prescriptives la réduisent beaucoup. Prenons pour 
exemple la différence entre un système qui recommande automatiquement une série de 
ressources pour l’apprentissage, sans pour autant masquer d’autres ressources, et un autre 
qui les sélectionne et les intègre dans un parcours dit personnalisé. Le premier maintient une 
certaine agentivité alors que le second retire une forme d’agentivité, car il prend des décisions 
à la place de l’apprenant. 

Au niveau des usages didactiques, Sjödén (2020) note que les systèmes basés sur l’IA 
peuvent intégrer de fausses informations à l’environnement dans lequel agit l’élève. Il présente 

Enseigner et apprendre à l’ère de l’intelligence artificielle Sommaire 

87 

trois types de procédés que pourraient employer des systèmes d’IA et qui pourraient poser 
des problèmes éthiques : les cas où les systèmes mentent, c’est-à-dire présentent une 
information volontairement inexacte, les cas où ils cachent de l’information en sélectionnant 
celle à présenter, les cas où ils entretiennent des croyances erronées chez les élèves. Sjödén 
(2020) pose la question : « Jusqu’à quel point est-il justifiable, d’un point de vue éthique, 
d’entretenir de telles illusions ? » (p. 293). Ici, le lien avec l’agentivité tient à l’authenticité de 
l’environnement dans lequel l’agentivité est exercée. Une agentivité appuyée par des 
informations partielles ou fausses est-elle réellement de l’agentivité ? 

Une agentivité appuyée par des informations partielles ou fausses est-elle réellement de l’agentivité ? 

Reiss (2021), s’appuyant sur Puddifoot et O’Donnell (2018), souligne que des outils qui 
poursuivent une intention de facilitation des apprentissages peuvent entraver l’activité 
intellectuelle nécessaire à la formation des concepts : 

Puddifoot et O’Donnell (2018) défendent l’idée qu’une trop grande dépendance envers les technologies 
pour stocker l’information à notre place - information que nous devions auparavant mémoriser - peut être 
contre-productive et donner lieu à des opportunités ratées pour les élèves de former des abstractions et 
de réaliser des inférences à partir de nouvelles informations. (p. 4, traduction libre) 

intellectuelle précise pour 

Même en présence d’outils visant à faciliter la tâche des apprenants, il peut être 
momentanément pertinent de conserver une activité 
le 
développement de certaines structures logiques de pensée. Par exemple, un outil qui 
préidentifie les passages importants dans un texte, pour éviter à l’élève de devoir le lire au 
complet, pourrait ne pas être souhaitable si l’intention pédagogique est le développement de 
la capacité de synthèse. Un peu comme d’autres l’ont fait avant au sujet de la calculette, 
Smuha (2020) parle du risque de développement d’une paresse intellectuelle à force 
d’interagir avec des machines plus performantes pour la réalisation de certaines tâches. Selon 
des parents d’élèves, certains outils pourraient même être des entraves à l’apprentissage si 
les élèves ne développent pas de recul critique et leur accordent une trop grande confiance 
(Qin et al., 2020). 

Par contre, quelques parents sont inquiets que l’usage de systèmes basés sur l’IA en éducation puisse 
faire en sorte que les élèves en deviennent dépendants et manquent de pensée critique. Cela explique le 
fait que les parents soient réticents à faire confiance à ces systèmes. (p. 1699, traduction libre) 

Certains risques s’ajoutent lorsqu’il est question d’enseignement supérieur. Des systèmes trop 
guidés qui s’immiscent dans l’organisation du travail scolaire pourraient être perçus comme 
infantilisants par les principaux intéressés (Roberts et al., 2017). Ce risque est aussi supporté 
par West et al. (2020) selon qui les apprenants doivent être perçus comme des personnes 
capables de réguler eux-mêmes leurs apprentissages. Roberts et al. (2017) proposent de 
s’assurer que les étudiants ne soient jamais obligés d’agir en concordance avec les 
recommandations d’un système ou sur la base de ses indicateurs de performance. Il faut aussi 
souligner l’importance que les systèmes utilisés soient valides, fiables et capables d’accomplir 
les tâches pour lesquelles ils ont été conçus dans un contexte réel (Smuha, 2020). 

Enseigner et apprendre à l’ère de l’intelligence artificielle Sommaire 

88 

Discussion : quelques nuances et pistes pour se 
prémunir des risques 

À la lumière des résultats, cette section revient de manière systématique sur deux des 
éléments abordés dans le contexte, à savoir le système technicien et le concept d’agentivité. 
Elle présente également quelques pistes pour soutenir le développement de l’IA en éducation 
tout en préservant l’agentivité des élèves et des enseignants. 

PAR RAPPORT AU SYSTEME TECHNICIEN 

Suivant Ellul (1977), l’enseignement, comme à peu près tout, peut être compris comme un 
ensemble de techniques (formules pédagogiques, méthodes d’évaluation, etc.). Au fur et à 
mesure que ces techniques se complexifient, dans ce cas-ci par le recours à l’IA, la complexité 
sous-jacente aux techniques qui prévalaient jusqu’alors est masquée, opaque ou bien 
carrément niée. Les outils basés sur l’IA sont rendus possibles par des techniques, au premier 
plan desquelles se trouve l’apprentissage automatique (machine learning). Plus ils se 
développent, plus ils précisent la réalité dans laquelle les individus évoluent. En ce sens, les 
systèmes informatiques basés sur l’IA appliquant ces techniques en contexte éducatif ne 
peuvent pas être considérés uniquement comme des outils. Ils redéfinissent plusieurs 
paramètres de la situation éducative, par exemple le temps requis pour accomplir une tâche, 
ou bien la nécessité ou non de mémoriser certaines informations, la nécessité ou non de 
demander de l’aide pour accomplir une tâche, ou bien les possibilités d’interactions sociales. 

Les outils basés sur l’IA sont rendus possibles par des techniques, au premier plan desquelles se trouve 
l’apprentissage automatique (machine learning). Plus ils se développent, plus ils précisent la réalité dans 
laquelle les individus évoluent. 

Le recours à l’IA en éducation s’inscrit aussi dans la théorie du système technicien par le 
déplacement de certains pouvoirs. Certains outils représentent « une forme de privatisation et 
de commercialisation en transférant le contrôle des programmes scolaires et de la pédagogie 
des enseignants et des écoles vers les entreprises à but lucratif » (Saltman, 2020, p. 199, 
traduction libre). Si ce déplacement de pouvoirs peut être souhaitable, par moments, pour des 
questions d’efficience ou d’innovation, il doit être fait prudemment en évaluant l’ensemble des 
conséquences qui peuvent en découler. Le développement de l’IA ne peut donc être envisagé 
que comme une façon d’améliorer l’expérience d’enseignement et d’apprentissage. Cette 
conception est insuffisante pour décrire la transformation que ces outils pourraient opérer. 
Insuffisante d’abord car elle ne considère pas l’IA comme un ensemble de techniques qui 
reconfigurent les actions des élèves et enseignants, et insuffisante aussi car elle omet de 
considérer que l’enseignement et l’apprentissage sont eux-mêmes alimentés par des 
techniques. 

PAR RAPPORT A L’AGENTIVITE 

L’agentivité, telle que nous l’avons présentée, implique une initiative d’action dans des 
situations présentant des conflits de motifs. Tout usage de l’IA qui retire de l’espace pour 
prendre de telles initiatives limite l’agentivité. Il serait toutefois possible d’atténuer ce risque en 
orientant les systèmes, dès la conception, pour qu’ils augmentent l’agentivité. Selon Kerr et 
Earle (2013), cela pourrait se faire en concevant des systèmes qui réalisent des prédictions 
de conséquences et rendent ainsi disponible plus d’information pour que les personnes 

Enseigner et apprendre à l’ère de l’intelligence artificielle Sommaire 

89 

prennent elles-mêmes des décisions, plutôt que des systèmes basés sur des prédictions de 
préférence ou prescriptives. Une prédiction prescriptive vise à diminuer les options 
disponibles, alors qu’une prédiction de préférence permet d’orienter ou classer, sans diminuer 
les options disponibles. Comme le suggèrent Roberts et al. (2017), il est important que 
l’étudiant n’ait pas l’obligation d’agir sur certains indicateurs. Dans l’enseignement supérieur, 
s’ajoute le risque d’un guidage trop important des étudiants qui peut avoir un effet infantilisant 
sur ces derniers. C’est pourquoi, dans le domaine des traces d’apprentissages (learning 
analytics), le développement des tableaux de bord appelle à prendre en compte les besoins 
réels des étudiants. 

PISTES POUR LE DEVELOPPEMENT D’OUTILS BASES SUR L’IA PRESERVANT 
L’AGENTIVITE 

Les résultats de notre recension des écrits soulèvent plusieurs risques relatifs au maintien de 
l’agentivité humaine à travers les usages de l’IA en éducation, autant pour le personnel 
enseignant que pour les élèves. Nous proposons ici trois pistes pour concevoir des 
technologies éducatives basées sur l’IA tout en préservant, voire renforçant, l’agentivité 
humaine. 

Premièrement, l’IA devrait d’abord être employée non pas pour prendre des décisions, mais 
plutôt pour améliorer la qualité de l’information pour permettre aux personnes de prendre des 
décisions plus éclairées. Cela peut se faire par exemple en présentant les conséquences 
probables de décisions (Regan et Jesse, 2019) tout en maintenant de la transparence sur ce 
dont tiennent compte les prédictions et ce dont elles ne tiennent pas compte. L’utilisation de 
tels systèmes devrait demeurer facultative pour les enseignants (Knox, 2017). 

En éducation, l’IA devrait d’abord être employée non pas pour prendre des décisions, mais plutôt pour 
améliorer la qualité de l’information pour permettre aux personnes de prendre des décisions plus éclairées. 

Deuxièmement, relativement à l’évaluation des apprentissages, il semble prometteur d’utiliser 
l’IA pour des rétroactions rapides, personnalisées et fréquentes, dans des contextes où la 
rétroaction de l’enseignant ne pas être réalistement attendue. Bien sûr, ces systèmes doivent 
être transparents, même auprès de l’élève, sur la façon dont la rétroaction a été établie. En 
cohérence avec le point précédent, ils doivent contribuer à augmenter l’information disponible 
auprès de l’élève, sans toutefois prendre de décisions relatives à la notation, par exemple. L’IA 
ne devrait pas être utilisée pour remplacer le jugement professionnel des enseignants pour 
des évaluations certificatives. Elle pourrait aussi servir à porter à l’attention de l’enseignant 
certains biais potentiels dans ses évaluations ou certaines incohérences. 

Finalement, en ce qui concerne les aides à la tâche destinées aux élèves, elles pourraient être 
développées éventuellement, mais ce terrain semble incertain pour le moment. Les intentions 
pédagogiques des curricula ne permettent pas toujours, à un niveau micro, de distinguer quelle 
activité intellectuelle est essentielle de celle qui est instrumentale ou déjà acquise. Les usages 
de l’IA visant à engager des élèves dans des projets technocréatifs (Romero et al., 2017) et 
développer eux-mêmes des compétences dans le domaine semblent plus prometteurs à court 
terme et peuvent même être combinés à des usages a priori destinés à l’enseignant. 

Enseigner et apprendre à l’ère de l’intelligence artificielle Sommaire 

90 

Conclusion 

En situation éducative, enseignants comme élèves font preuve d’agentivité au quotidien. 
Malgré tous les efforts pour modéliser des problèmes éducatifs et automatiser des solutions, 
par exemple pour l’évaluation des apprentissages, il faut garder en tête que ces problèmes 
peuvent être abordés depuis plusieurs points de vue et qu’ils font intervenir des dimensions 
humaines parfois intangibles, et des motifs contradictoires. C’est par l’agentivité que sont 
résolues ces situations au quotidien. Il faut donc éviter le piège réductionniste de concevoir 
des outils didactiques détachés du contexte dans lequel ils sont utilisés. 

Les pistes étant certainement nombreuses, nous en avons proposé trois : (1) utiliser l’IA pour 
améliorer l’information décisionnelle plutôt que prendre des décisions éducatives, (2) utiliser 
l’IA pour des rétroactions formatives et non pour l’évaluation certificative, tout en entraînant 
les élèves et les enseignants à un recul critique, et (3) privilégier les usages qui engagent les 
élèves et leur permettent de développer un recul critique sur le fonctionnement de l’IA. 

Références 

Adams, C., Pente, P., Lemermeyer, G. et Rockwell, G. (2021). Artificial 
Intelligence Ethics Guidelines for K-12 Education: A Review of the Global 
Landscape. Dans I. Roll, D. McNamara, S. Sosnovsky, R. Luckin et V. 
Dimitrova (Éds.), Artificial Intelligence in Education (Vol. 12749, p. 24-28). 
Springer International Publishing. 

Aiken, R. M., & Epstein, R. G. (2000). Ethical Guidelines for AI in Education: 
Starting a Conversation. International Journal of Artificial Intelligence in 
Education, 11, p. 163-176. 

Berendt, B., Littlejohn, A. et Blakemore, M. (2020). AI in education: Learner 
choice and fundamental rights. Learning, Media and Technology, 45(3), 
p. 312-324. 

Bulger, M. (2016). Personalized Learning: The Conversations We’re Not 
Having. Data & Society, 29. 

Corrin, L., Kennedy, G., French, S., Shum, S. B., Kitto, K., Pardo, A., West, 
D., Mirriahi, N. et Colvin, C. (2019). The Ethics of Learning Analytics in 
Australian Higher Education. 

Ellul, J. (1977). Le système technicien. Calmann-Levy. 

Engeström, Y. et Sannino, A. 
l’agentivité 
transformatrice : Perspective théorique de l’activité. Revue internationale du 
CRIRES : innover dans la tradition de Vygotsky, 1(1), 4-19. 

(2013). La volition et 

Ferber, J. (1995). Les systèmes multi-agents : Vers une intelligence 
collective. Intereditions. 

Gras, B. (2019). Éthique des Learning Analytics. Distances et médiations 
des savoirs, 26. 

Holmes, W., Porayska-Pomsta, K., Holstein, K., Sutherland, E., Baker, T., 
Shum, S. B., Santos, O. C., Rodrigo, M. T., Cukurova, M., Bittencourt, I. I. et 
Koedinger, K. R. (2021). Ethics of AI in Education: Towards a Community-
Wide Framework. International Journal of Artificial Intelligence in Education. 

Humble, N. et Mozelius, P. (2019). Teacher-supported AI or AI-supported 
teachers? 11. 

Enseigner et apprendre à l’ère de l’intelligence artificielle Sommaire 

91 

Jones, K. M. L., Rubel, A. et LeClere, E. (2020). A matter of trust: Higher 
education institutions as information fiduciaries in an age of educational data 
mining and learning analytics. Journal of the Association for Information 
Science and Technology, 71(10), p. 1227-1241. 

Kerr, I. et Earle, J. (2013). Prediction, preemption, presumption: How big data 
threatens big picture privacy. Stanford Law Review Online, 66, 65-72. 

Knox, J. (2017). Data Power in Education: Exploring Critical Awareness with 
the “Learning Analytics Report Card”. Television & New Media, 18(8), 
p. 734-752. 

Loder, J. et Nicholas, L. (2018). Confronting Dr Robot—Creating a people-
powered future for AI in health (p. 38). Nesta Health Lab. 

Michel, G. et Le Nagard, E. (2019). Favoriser la sérendipité pour des 
recherches plus créatives. Decisions Marketing, (1), p. 5-9. 

Parasuraman, R. et Manzey, D. H. (2010). Complacency and bias in human 
use of automation: An attentional integration. Human Factors, 52(3), 
p. 381-410. 

Popenici, S. A. D. et Kerr, S. (2017). Exploring the impact of artificial 
intelligence on teaching and learning in higher education. Research and 
Practice in Technology Enhanced Learning, 12(22), p. 1-13. 

Puddifoot, K. et O’Donnell, C. (2018). Human Memory and the Limits of 
Technology in Education. Educational Theory, 68(6), p. 643-655. 

Qin, F., Li, K. et Yan, J. (2020). Understanding user trust in artificial 
intelligence‐based educational systems: Evidence from China. British 
Journal of Educational Technology, 51(5), p. 1693-1710. 

Regan, P. M. et Jesse, J. (2019). Ethical challenges of edtech, big data and 
personalized learning: Twenty-first century student sorting and tracking. 
Ethics and Information Technology, 21(3), p. 167-179. 

Reiss, M. J. (2021). The use of AI in education: Practicalities and ethical 
considerations. London Review of Education, 19(1). 

Roberts, L. D., Chang, V. et Gibson, D. (2017). Ethical Considerations in 
Adopting a University- and System-Wide Approach to Data and Learning 
Analytics. Dans B. Kei Daniel (Éd.), Big Data and Learning Analytics in 
Higher Education (p. 89-108). Springer International Publishing. 

Romero, M., Lille, B. et Patiño, A. (2017). Usages créatifs du numérique pour 
l’apprentissage au XXIe siècle. PUQ. 

Saltman, K. J. (2020). Artificial intelligence and the technological turn of 
public education privatization: In defence of democratic education. London 
Review of Education, 18(2). 

Sjödén, B. (2020). When Lying, Hiding and Deceiving Promotes Learning—
A Case for Augmented Intelligence with Augmented Ethics. Dans I. I. 
Bittencourt, M. Cukurova, K. Muldner, R. Luckin, & E. Millán (Éds.), Artificial 
Intelligence in Education (Vol. 12164, p. 291-295). Springer International 
Publishing. 

Smuha, N. A. (2020). Trustworthy Artificial Intelligence in Education: Pitfalls 
and Pathways. SSRN Electronic Journal. 

Taulli, T. (2019). Artificial Intelligence Basics: A Non-Technical Introduction. 
Apress. 

UNESCO. (2019). BEIJING CONSENSUS on artificial intelligence and 
education. https://en.unesco.org/themes/ict-education 

Enseigner et apprendre à l’ère de l’intelligence artificielle Sommaire 

92 

West, D., Luzeckyj, A., Toohey, D., Vanderlelie, J. et Searle, B. (2020). Do 
academics and university administrators really know better? The ethics of 
positioning student perspectives in learning analytics. Australasian Journal 
of Educational Technology. 

Zawacki-Richter, O., Marín, V. I., Bond, M. et Gouverneur, F. (2019). 
Systematic review of research on artificial intelligence applications in higher 
education – where are the educators? International Journal of Educational 
Technology in Higher Education, 16(1), 39. 

Enseigner et apprendre à l’ère de l’intelligence artificielle Sommaire 

93 

 
CONCLUSION 

Julie Henry 
Université de Namur, Belgique 

Ce livre blanc rassemble des textes discutant la place de l’intelligence 
artificielle (IA) en éducation au sens large. Une distinction a été faite entre 
l’IA comme un outil pédagogique ou comme objet d’apprentissage. D’abord, 
comme outil, elle peut servir à améliorer l’apprentissage (le point de vue de 
l’apprenant) ou bien à améliorer notre compréhension du processus 
d’apprentissage (le point de vue de l’enseignant et du formateur). Ensuite, 
comme objet d’apprentissage, l’IA doit être envisagée dans le contexte élargi 
d’une éducation à la citoyenneté numérique telle qu’elle est présentée dans 
le cadre de référence pour les compétences numériques DigComp 2.2. 
Cependant, les deux aspects ne doivent pas être étrangers l’un par rapport 
à l’autre. Il faut privilégier avant tout les usages qui engagent les apprenants 
et leur permettent de développer un recul critique sur le fonctionnement de 
l’IA. C’est l’émancipation de chaque citoyen en termes de pouvoir d’agir et 
d’engagement qui doit être visée, et non son aliénation numérique. 

Il y a donc un enjeu démocratique à amener tous les citoyens à comprendre 
les principes de base de l’IA pour développer des pratiques éclairées, 
autonomes et critiques qui leur permettront d’appréhender les questions que 
cette technologie soulève. En effet, les connaissances que possèdent le 
grand public de l’IA sont assez limitées : nombreux sont ceux qui ne peuvent 
pas reconnaître quand ils interagissent avec une technologie faisant appel à 
l’IA (Siri, Alexa, etc.) et ne savent pas expliquer son fonctionnement (Druga 
et al., 2018 ; Williams et al., 2018 ; Druga et al., 2017). Cette 
méconnaissance, couplée aux discours médiatiques qui oscillent entre 
craintes et fantasmes, alimentent représentations biaisées et mauvaise 
compréhension des enjeux techniques et éthiques de l’IA. Bien souvent, les 
technologies faisant appel à l’IA sont réduites aux robots et sont supposées 
avoir des capacités qui sont loin de leurs capacités réelles. 

Ainsi, en ce qui concerne les usages éducatifs de l’IA, il faut prendre 
conscience des limites tout en travaillant à rendre tangibles et exploitables 
les données collectées durant l’apprentissage. Pour pallier ces limites, il faut 
cocréer les technologies à usages éducatifs en impliquant davantage les 
principaux intéressés, à savoir les enseignants, les formateurs et les 
apprenants. Cela tient aussi pour la conception de dispositifs d’éducation à 
l’IA (Henry et al., 2021 et 2020). 

Enfin, si jusqu’à il y a quelques années, peu de ressources pédagogiques 
existaient pour éduquer à l’IA dès le plus jeune âge, ces ressources 
commencent à exploser comme en témoignent les chapitres de la première 
partie. La littérature scientifique rapporte aussi plusieurs ressources ou 
démarches d’introduction à l’IA (p. ex. Sabuncuoglu, 2020 ; Vartiainen et al., 
2020 ; Ho et al., 2019 ; Touretzky et al., 2019 ; Williams et al., 2019 ; Eaton 
et al., 2018 ; Kandlhofer et al., 2016 ; Heinze et al., 2010). Peu d’entre elles 
sont cependant accessibles sans effort aux enseignants qui ont 
généralement une expérience limitée de l’éducation à l’IA. Une formation 
reste donc à envisager, et pas seulement concernant les aspects techniques 
de l’IA puisque les défis sont également éthiques et sociétaux. L’approche 
pédagogique envisagée pour cette éducation se doit donc d’être 
interdisciplinaire et critique (Henry et al., 2018 ; Saariketo, 2014a et 2014b). 
Malheureusement, si une telle approche fait moins peur aux enseignants 

Enseigner et apprendre à l’ère de l’intelligence artificielle Sommaire 

94 

 
 
parce que moins orientée technique de prime abord, ils n’y sont pas pour 
autant mieux formés. 

Dès lors, si la place de l’IA dans l’éducation se confirme, notamment à travers 
la lecture de ce livre blanc, les efforts à fournir pour s’assurer de sa bonne 
intégration restent encore nombreux et doivent faire l’objet d’une attention 
toute particulière pour garantir le développement personnel et social de 
chaque citoyen. 

Références 

Druga S, Williams R, Breazeal C, Resnick M (2017) Hey Google is it OK if I 
eat you? Initial explorations in child-agent interaction. In: Proceedings of the 
2017 ACM conference on interaction design and children (IDC). ACM, 
p. 595-600. 

Druga, S., Williams, R., Park, H. W., & Breazeal, C. (2018). How smart are 
the smart toys? Children and parents’ agent interaction and intelligence 
attribution. In Proceedings of the 17th ACM Conference on Interaction 
Design and Children (p. 231-240). 

Eaton, E., Koenig, S., Schulz, C., Maurelli, F., Lee, J., Eckroth, J., ... & 
Williams, T. (2018). Blue sky ideas in artificial intelligence education from the 
EAAI 2017 new and future AI educator program. AI Matters, 3(4), p. 23-31. 

Heinze, C. A., Haase, J., & Higgins, H. (2010). An action research report from 
a multi-year approach to teaching artificial intelligence at the k-6 level. In First 
AAAI Symposium on Educational Advances in Artificial Intelligence. 

Henry, J., Hernalesteen, A., Dumas, B., & Collard, A. S. (2018). Que signifie 
éduquer au numérique ? Pour une approche interdisciplinaire. De 0 à, 1, 
p. 61-82. 

Henry, J., Hernalesteen, A., & Collard, A. S. (2020). Designing digital literacy 
activities: an interdisciplinary and collaborative approach. In 2020 IEEE 
Frontiers in Education Conference (FIE) (pp. 1-5). IEEE. 

Henry, J., Hernalesteen, A., & Collard, A. S. (2021). Teaching Artificial 
Intelligence to K-12 Through a Role-Playing Game Questioning the 
Intelligence Concept. KI-Künstliche Intelligenz, 35(2), p. 171-179. 

Ho, J. W., Scadding, M., Kong, S. C., Andone, D., Biswas, G., Hoppe, H. U., 
& Hsu, T. C. (2019, June). Classroom activities for teaching artificial 
intelligence to primary school students. In Proceedings of International 
Conference on Computational Thinking Education (pp. 157-159). 

Kandlhofer, M., Steinbauer, G., Hirschmugl-Gaisch, S., & Huber, P. (2016). 
Artificial intelligence and computer science in education: From kindergarten 
to university. In 2016 IEEE Frontiers in Education Conference (FIE) (p. 1-9). 
IEEE. 

Sabuncuoglu, A. (2020). Designing one year curriculum to teach artificial 
intelligence for middle school. In Proceedings of the 2020 ACM Conference 
on Innovation and Technology in Computer Science Education (p. 96-102). 

Saariketo, M. (2014a). Imagining alternative agency in techno-society: 
outlining the basis of critical technology education (en). Media practice and 
everyday agency in Europe, 129-138. 

Enseigner et apprendre à l’ère de l’intelligence artificielle Sommaire 

95 

Saariketo, M. (2014b). Reflections on the question of technology in media 
literacy education. In Reflections on media education futures: contributions 
to the Conference Media Education Futures in Tampere, Finland (p. 51-61). 

Touretzky, D., Gardner-McCune, C., Martin, F., & Seehorn, D. (2019). 
Envisioning AI for K-12: What should every child know about AI? In 
Proceedings of the AAAI conference on artificial intelligence (Vol. 33, No. 01, 
p. 9795-9799). 

Vartiainen, H., Toivonen, T., Jormanainen, I., Kahila, J., Tedre, M., & 
Valtonen, T. (2020, October). Machine learning for middle-schoolers: 
Children as designers of machine-learning apps. In 2020 IEEE Frontiers in 
Education Conference (FIE) (p. 1-9). IEEE. 

Williams, R., Machado, C. V., Druga, S., Breazeal, C., & Maes, P. (2018). " 
My doll says it’s ok" a study of children’s conformity to a talking doll. In 
Proceedings of the 17th ACM Conference on Interaction Design and Children 
(p. 625-631). 

Williams, R., Park, H. W., Oh, L., & Breazeal, C. (2019). Popbots: Designing 
an artificial intelligence curriculum for early childhood education. In 
Proceedings of the AAAI Conference on Artificial Intelligence (Vol. 33, No. 
01, p. 9729-9736).

Enseigner et apprendre à l’ère de l’intelligence artificielle Sommaire 

96 

Ce document est rédigé par les équipes de recherche 
dans le cadre des GTnum du ministère de l’Éducation nationale, 
de la Jeunesse et des Sports. 

La responsabilité des contenus publiés leur appartient. 

 
 
 
 
 
