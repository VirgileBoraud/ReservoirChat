Formalization of the input/output retinal transformation
regarding non-standard ganglion cells behavior
Elaa Teftef, Thierry Viéville

To cite this version:

Elaa Teftef, Thierry Viéville. Formalization of the input/output retinal transformation regarding
from
non-standard ganglion cells behavior. NeuroComp/KEOpS’12 workshop beyond the retina:
computational models to outcomes in bioengineering. Focus on architecture and dynamics sustaining
information flows in the visuomotor system., Oct 2012, Bordeaux, France. ￿hal-00756453￿

HAL Id: hal-00756453

https://inria.hal.science/hal-00756453

Submitted on 23 Nov 2012

HAL is a multi-disciplinary open access
archive for the deposit and dissemination of sci-
entific research documents, whether they are pub-
lished or not. The documents may come from
teaching and research institutions in France or
abroad, or from public or private research centers.

L’archive ouverte pluridisciplinaire HAL, est
destinée au dépôt et à la diffusion de documents
scientifiques de niveau recherche, publiés ou non,
émanant des établissements d’enseignement et de
recherche français ou étrangers, des laboratoires
publics ou privés.

Formalization of the input/output retinal
transformation regarding non-standard ganglion
cells behavior

E. Teftef, T. Vi´eville∗
Inria Mnemosyne http://team.inria.fr/mnemosyne, France.

September 28, 2012

The aim of the present work is the realization of a simulation software of
mesoscopic biological models of non-standard features of the retina, i.e. K-cells
(results are very diﬀerent for X and Y cells). This builds a link between biological
models and non-trivial image processing algorithms of computer vision. The
software created here simulates some functionality of the retina at the network
scale (not at the cell level), considering real natural images and without being
adjusted on each cell.

The models is based on three major biological assumptions, discussed in
(Teftef et al., 2012; Teftef, 2012), derived from recent contributions regarding
“the evidence that the early steps of mammalian vision are more diverse and
more interesting than is usually imagined, so that our understanding of the later
stages is in trouble right from the start” (Masland & Martin, 2007), i.e. the fact
that “the retina solves a diverse set of speciﬁc tasks and provides the results ex-
plicitly to downstream brain areas”, including “sophisticated spatio and temporal
pattern recognition” (Schwartz & Michael, 2008) or “segregation of object and
background motion” (Olveczky, Baccus, & Meister, 2003).

On one hand, we consider that what the retina is able to compute can be
interpreted in terms of sophisticated second-order visual cues, including spectrum
amplitude signature, since this is equivalent to linear/non-linear ﬁltering, while
it has been observed that it is a relevant parameter to characterize natural image
categories (Torralba & Oliva, 2003), see Fig 2. On the other hand, we interpret

∗Supported by the CONICYT/ANR KEOpS project and CORTINA associated team.

1

the non-local ﬁltering of the diﬀerent visual streams as a mechanism of image
segmentation, allowing the optical nerve to perform a huge data compression
tuned to what is speciﬁc in term of visual data. As a consequence, both ﬁne scale
and large scale visual information is output. The bio-plausible implementation
of such mechanism has been extensively discussed elsewhere (Vi´eville, Chemla,
& Kornprobst, 2007), see Fig 3 for results. Finally, we consider that the retina
is able to detect static or time-varying visual events, and propose after (Vi´eville
& Crahay, 2004) an biologically plausible implementaton of such mechanism,
evaluated on a realistic data set, see Fig 4.

We thus propose here to use a variational framework to model and simulate,
given natural image sequences, the mesoscopic collective non-standard behavior
of some retinal input/output functions that correspond to the output of a sub-
class of the so-called konio-cells, as sketched out in Fig. 1. See (Teftef et al., 2012)
for an extended discussion of the class of retinal cells addressed by such a mod-
eling. We hypothesize that from sophisticated temporal pattern recognition, to
image segmentation, or speciﬁc natural statistical recognition, a unique generic
two-layers non-linear ﬁltering mechanism with feedback is implemented in the
biological tissues, while not the individual but the collective behavior of the reti-
nal cells answer for such input/output functions. Taking the retinal architecture
and related biological constraints into account and considering the wider class
of early-vision non-standard sensory-motor functionality known as non-standard
behaviors, we use computer vision methods to propose an eﬀective link between
the observed functions and their possible implementation in the retinal network.
With such framework, it is not possible to assume that the brain visual system
stands on the reception of an homogeneous visual pipe of ﬁltered images from
the retina, whereas it is connected to several heterogeneous sources of informa-
tion at diﬀerent spatial and visual scales, and diﬀerent integration level, while
tuned to the natural image statistics. Roughly speaking, this encourages bio-
inspired systems to compute in parallel several information streams depending
on the sensory-motor task, instead of thinking of large information pipe. Fur-
thermore, visual prostheses are likely to be though as a plural of sensors with a
non-negligible data processing, before feeding the nervous system.

References

Masland, R. H., & Martin, P. R. (2007, August 07). The unsolved mystery of

vision. Current Biology, 17 (15), R577–R582.

2

Figure 1: Schematic representation of projections of the K-cells considered here,
after (Masland & Martin, 2007) and (Nassi & Callaway, 2009). K-cells represent
10% of the retinal projections, with large (about 10deg) visual ﬁelds and react to
visual events. See (Teftef et al., 2012) for details.

Nassi, J. J., & Callaway, E. M.

(2009). Parallel processing strategies of the

primate visual system. Nat. Rev. Neurosci., 10 (5), 360–372.

Olveczky, B. P., Baccus, S. A., & Meister, M. (2003, May 22). Segregation of

object and background motion in the retina. Nature, 423 (6938), 401–408.

Schwartz, G., & Michael.

(2008, April 01). Sophisticated Temporal Pattern
Recognition in Retinal Ganglion Cells. Journal of Neurophysiology, 99 (4),
1787–1798.

Teftef, E. (2012). Formalisation de la transformation analogique / ´ev´enementielle
des m´ecanismes non-standards des cellules ganglionnaires de la r´etine. Un-
published master’s thesis, Universit´e de Paris 6 et Universit´e El Manar de
Tunis.

Teftef, E., Alexandre, F., Carvajal, C., Cessac, B., Escoba, M.-J., Palacios, A., et
al. (2012). Modeling non-standard retinal in/out function using computer
vision variational methods. J. Physiol. (Paris). (submitted)

Torralba, A., & Oliva, A.

(2003). Statistics of natural image categories.

In

Network: Computation in neural systems (Vol. 14, pp. 391–412).

Vi´eville, T., Chemla, S., & Kornprobst, P. (2007). How do high-level speciﬁcations
of the brain relate to variational approaches? J. Physiol. Paris, 101 .
Vi´eville, T., & Crahay, S. (2004). Using an hebbian learning rule for multi-class

svm classiﬁers. Journal of Computational Neuroscience, 17 (3), 271–287.

3

Figure 2: Considering a multi-stream computational framework, including spec-
trum amplitude signature. For ﬁve diﬀerent zones of natural images labeled on
the left picture, the spectrum amplitude and the 50% level curves are drawn.
From left to right : 1. a ﬂower, 2. a piece of sky with an artifact, 3. a tree zone,
4. a dark zone, and 5. a third tree zone perturbed by a piece of sky. Interesting
enough is the fact that zones 3. and 5., despite their very diﬀerent visual aspect
have a rather similar spectrum signature, diﬀerent from 1. Though zones 2. and
4. have spurious spectral responses (for 2. this is the artifact in the sky that yields
the spectrum and for 4. the spectrum is not relevant in such a dark zone), since
the system is also using the local color as a cue, this yields no mistake. We numer-
ically observed that not only the whole image second-order statistics (Torralba
& Oliva, 2003), but also very local second-order statistics seem to be relevant for
natural image categorization. More precisely, in the present numerical implemen-
tation limited to static images, the color and the sum of the spectrum amplitude
responses at 50% of the maximal amplitude are taken as cues to characterize the
local texture, in order to perform region detection. The fact that such very simple
scalar parameter calculated on the spectrum magnitude leads to relevant results
(see Fig. 4) is a good argument in favor of the proposed choice. The generaliza-
tion to spatio-temporal volumes, thus 2D+T spectra, is straightforward and is a
direct perspective of this work.

4

Figure 3: Qualitative examples of non-local ﬁltering using diﬀusion mechanisms
as discussed in (Vi´eville et al., 2007) regarding their biological implementation.
Lower images are the non-local ﬁltering output of one channel (here intensity)
Interesting enough, several key
computed on the corresponding upper image.
points can be observed here : The output is morally an “artiﬁcial image” corre-
sponding to the “natural” input, where the forms in the image have been pre-
served. More precisely, the edges (e.g., the ﬂowers boundaries) are preserved even
when the image is “smoothed” : The fact the mechanism ﬁlters the noise and not
the edges, is simply due to the non-linearity of the diﬀusion operator, since small
variations diﬀuse and are thus ﬁltered, whereas higher intensity variations related
to edges do not. Furthermore, diﬀusion is anisotropic, more precisely performed
along the edge, but not across it (in a more mathematical language : Tangential
to the local edge orientation, but not orthogonal to it), thus preserving it. In the
present computer implementation, region synchronization is implemented by the
propagation of a “phase index” as expected in a biological neural network. In the
sky, the artifact (likely a tree limb) has disappeared, because one non-local eﬀect
of this process is small enough so such regions are absorbed though the non-linear
diﬀusion. In a nutshell, we have here a “full resolution”, but simpliﬁed image.

5

Figure 4: Two examples of detection of visual events (here, spatial events only).
Top views correspond to the input image, bottom views to the detection output.
The most salience regions are shown in both cases, i.e.
those with maximal
size and/or channel average values (here, for the present ﬁgures, size only is
considered). Left view A “sky” zone and four dark/light “tree” zone have been
detected. Right view The main “tree” zone have been detected, while the ground
is less salient since not structured in terms of “regions”. Clearly this kind of
information is relevant to directly detect zones with potential pray/predators
“hidden in the green”. The categorization algorithm has been trained with a
very small learning set (a few dozen of samples) and the recognition test is no
more than a comparison of the region synchronized parameters (color, spectral
signature) with respect to prototypes in competition. Such functionality is easy
to generalize to another visual events (e.g. snake crawling, predator approaching
motion, etc..) and thus provides an eﬀective early-vision generation of a-priory
information. We have numerically veriﬁed that such detection is robust along the
image sequence. However, we also experimented that the non-linear ﬁltering (i.e.,
segmentation) step is mandatory: Without this sophisticated early-vision step,
the present categorization has very poor performances. This output represents
sparse responses of the retina in the presence of speciﬁc visual events.

6

