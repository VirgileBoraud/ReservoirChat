Creativity explained by Computational Cognitive
Neuroscience
Frédéric Alexandre

To cite this version:

Frédéric Alexandre. Creativity explained by Computational Cognitive Neuroscience. ICCC’20 - In-
ternational Conference on Computational Creativity, Sep 2020, Coimbra, Portugal. ￿hal-02891491￿

HAL Id: hal-02891491

https://inria.hal.science/hal-02891491

Submitted on 6 Jul 2020

HAL is a multi-disciplinary open access
archive for the deposit and dissemination of sci-
entific research documents, whether they are pub-
lished or not. The documents may come from
teaching and research institutions in France or
abroad, or from public or private research centers.

L’archive ouverte pluridisciplinaire HAL, est
destinée au dépôt et à la diffusion de documents
scientifiques de niveau recherche, publiés ou non,
émanant des établissements d’enseignement et de
recherche français ou étrangers, des laboratoires
publics ou privés.

Creativity explained by Computational Cognitive Neuroscience

Frederic Alexandre
Inria Bordeaux Sud-Ouest; Labri UMR 5800; IMN UMR 5293
146 rue Leo Saignat; 33076 Bordeaux, France
Frederic.Alexandre@inria.fr

Abstract

Recently, models in Computational Cognitive Neuro-
science (CCN) have gained a renewed interest because
they could help analyze current limitations in Artiﬁcial
Intelligence (AI) and propose operational ways to ad-
dress them. These limitations are related to difﬁcul-
ties in giving a semantic grounding to manipulated con-
cepts, in coping with high dimensionality and in man-
aging uncertainty. In this paper, we describe the main
principles and mechanisms of these models and explain
that they can be directly transferred to Computational
Creativity (CC), to propose operational mechanisms but
also a better understanding of what creativity is.

Introduction
Artiﬁcial Intelligence (AI) has developed approaches based
on knowledge manipulation and others based on data pro-
cessing. The latter ones have made tremendous progresses
recently, mostly due to technological improvements. Nev-
ertheless, the development of AI remains constrained by a
series of limitations, which are present from the birth of this
domain and still unsolved. This is also the case for CC, seen
as a subﬁeld of AI (Colton and Wiggins 2012).

The three limitations of Artiﬁcial Intelligence

These limitations are mostly methodological, which means
that they do not prevent the design of projects of AI or CC
but they render difﬁcult their development up to a realistic
size and they miss a realistic description of certain charac-
teristics, particularly when targeting their autonomy.

Giving a semantic grounding Probably, one of the most
fundamental limitations of AI is the difﬁculty to make sense
and exploit the meaning of the objects they are manipulat-
ing. This limitation is also important in CC where a novel
point of view can come from such a semantic analysis. This
is often related to the incapacity to ground these objects in
the real world (Harnard 1990) and to propose solutions re-
lated to the intrinsic meaning of the objects in the task. This
problem is generally addressed by developping ontologies of
the task, but these ontologies are often built explicitly from
knowledge, whereas in humans, intrinsic meanings are gen-
erally acquired implicitly and difﬁcult to express explicitly.

Coping with high dimensionality Recently, the increase
of computational resources allowed AI to explore tasks in
high dimensional spaces but this progress remains negligi-
ble as compared to the virtually inﬁnite size of state spaces
in realistic tasks. Similarly, (Colton and Wiggins 2012) un-
derline the growing tendency in CC to exploit web and other
large resources. A strategy is to use heuristics and to explore
a limited part of the state space. A side effect of long lasting
exploration in high dimensional state spaces is that learning
requires many examples and long training times, which is
not realistic, as compared to the ability of animals and espe-
cially of humans to learn quickly with few examples.

Managing uncertainty Tasks in the real world can be
stochastic, marring observations with noise;
they can be
volatile, implying that a relation learned one day can sud-
denly be no longer valid. A related important problem,
when an intelligent system receives an error signal, is to
decide if this is due to stochasticity (in the case, the best
strategy is to insist) or to volatility (requiring to look for a
new response). This is related to the balance between explo-
ration and exploitation, questioned in many models in AI.
Exploration can be purely random, but this is not consistent
with observation of a certain degree of ﬂexibility in chang-
ing environments, where the appropriate behavior is imme-
diately reinstated each time the same context is revisited.
Choosing between exploration and exploitation and going
beyond random processes are also important issues in CC.
All these problems are generally tackled in various prob-
abilistic frameworks (like bayesian techniques). Some of
them propose solid and mathematically grounded methods
but they are computationally prohibitive, thus adding to the
problem of high dimensionality deﬁned in the previous item.

The CCN approach
CCN models are primarily developed as a way to opera-
tionalize proposed cognitive concepts, together with their
brain implementation. They can sometimes give a biolog-
ical basis to classical models in AI as it is the case in Re-
inforcement Learning. They can also help study how the
brain solves some problems that remain difﬁcult with clas-
sical mathematical approaches. This is speciﬁcally the case
with the three limitations mentioned above, as we describe
now in more details.

Giving a semantic grounding It is generally considered
that access to the semantic meaning of objects is due to the
fact that we have a body that we can perceive externally
(sense of exteroception, including proprioception) and inter-
nally (sense of interoception (Craig 2009)). Considering the
consequences of taking these sensations into account onto
cognition is studied in what is called embodied AI (Pfeifer,
Bongard, and Grand 2007).

Internal representation of the body is built in the insular
cortex. On the one hand, rich signals of pain and pleasure al-
low to elaborate reinforcement signals much more complex
than the unique scalar generally used in reinforcement learn-
ing. Learning to anticipate these signals (pavlovian condi-
tioning, see a model in (Carrere and Alexandre 2015)) elic-
its what is called emotions and plays a pivotal role in deci-
sion making by allowing to compare different signals under
a common currency, as summarized by the principle of the
somatic markers (Damasio, Everitt, and Bishop 1996).

On the other hand, other important internal signals form
motivations and can be related to physiological needs (ex-
trinsic motivations) as well as needs for certain kinds of in-
formation (intrinsic motivations). Such signals are partic-
ularly important to generate internal goals and to prevent
from obeying only stimuli in the environment. This is an
important dimension for goal-directed behaviors, see com-
putational frameworks in (Pezzulo and Castelfranchi 2009).

Coping with high dimensionality One important contri-
bution has arisen from CCN about the way humans can learn
in high dimensionality with the Complementary Learning
System (CLS) framework (McClelland, McNaughton, and
O’Reilly 1995). In this framework, it is proposed that hu-
mans can, at the same time, learn slowly concepts in seman-
tic memory, in the cortex, and store quickly episodes in the
hippocampus. Later on, by a phenomenon called consolida-
tion, the hippocampus will send episodes back to the cortex
to train it off-line and ensure good properties to the learn-
ing process, for example to avoid mix-up, also called catas-
trophic forgetting. This kind of principles has been used in
Machine Learning to propose ways of training large archi-
tectures (for example deep networks) with “not so big data”,
cf a model in (Drumond, Vi´eville, and Alexandre 2019).

Recently, progresses in neuroscience about the hippocam-
pus and in the corresponding models led to more precise
explanation about information encoding in the hippocam-
pus, and particularly about place cells and grid cells (model
in (Stachenfeld, Botvinick, and Gershman 2017)) and their
proposed contribution in the goal-oriented exploration of
high-dimensional spaces. It has particularly been proposed
that replays of episodes for consolidation are not random
but obey subtle strategies (implemented in (Mattar and Daw
2018)) and that they can be organized in time to partic-
ipate to the elaboration of knowledge-based strategies in
the frontal cortex (cf computational framework in (Daw
2018)).
It has also been experimentally shown (Derdik-
man and Moser 2010) that the hippocampus not only replays
stored episodes but is also able to create new episodes com-
bining pieces of old episodes, thus promoting an imaginative
training with virtual episodes.

These concepts and models are today transfered to the do-
main of AI to elaborate what is called Episodic Reinforce-
ment Learning (Gershman and Daw 2017) and participate
to the design of more realistic and faster learning in high
dimensional data spaces.

Managing uncertainty Deﬁning the stochastic or volatile
nature of the environment has been related to the role of neu-
romodulation and exploited in models (Alexandre and Car-
rere 2016), adapting a general framework of behavior selec-
tion to the estimated kind and level of uncertainty.

As for the ﬂexible adaptation of behavior to a volatile en-
vironment, the role of the prefrontal cortex has been men-
tioned for a long time in neuroscience, observing that pa-
tients with a frontal lesion demonstrate perseveration and
are unable to adapt to changes (Nauta 1971). Accordingly,
it has been proposed that the prefrontal cortex is the place
where nondominant behaviors are deﬁned (Wise 2008) or,
to tell it differently, the place where top-down modulations
are sent to other regions of the brain to insert internally gen-
erated priorities and to help resist to immediate responses
driven by stimuli (Mesulam 2008), thus deﬁning two impor-
tant mechanisms in the prefrontal cortex: the inhibition of
dominant and occasionally non-adapted behaviors and the
triggering and maintenance by working memory of atten-
tional focus towards characteristics supposedly important to
generate the presently appropriate behavior.

Corresponding models describe the prefrontal cortex as a
region where tasks in speciﬁc contexts are represented, thus
deﬁning the notion of Task Sets (Domenech and Koechlin
2015), learning in certain contexts to inhibit the default be-
havior and to suggest new behaviors by an attentional pro-
cess (cf model in (O’Reilly et al. 2002)) biasing the cur-
rent perception. In order to select the pertinent nondominant
behavior, some interesting mathematical frameworks have
been proposed (Collins and Koechlin 2012) to tame the com-
binatorial exploration and generate a limited number of hy-
potheses. Other interesting and bio-inspired computational
mechanisms have been proposed to control and monitor the
execution of such behaviors, particularly in the case of hier-
archical planning (Pezzulo and Castelfranchi 2009).

These models and concepts are also presently transferred
to AI in so-called Meta Reinforcement Learning (Wang et
al. 2018), considering that, to adapt to the changing world, a
meta learner must quickly learn to select a specialized (and
slowly learning) learner, depending on the context.

Another important limitation in AI: Creativity

It is often mentioned though disputable (Boden 2009) that
creativity remains one of the rare cognitive phenomena that
AI cannot replicate (with other phenomena like sense of hu-
mor, not to say consciouness). Remarkably, studying so-
lutions proposed by CCN to remedy limitations in AI (and
consequently in CC), we argue (and will establish below)
that they massively rely on cognitive characteristics related
to creativity. We consequently propose that CCN could be
pivotal to fuel CC with fresh ideas and particularly add a
global view often missing in AI.

Deﬁning creativity
Whether dealing with creativity in speciﬁc domains (like
musical improvisation or scientiﬁc creativity) or from a gen-
eral point of view (Beaty et al. 2016), authors often men-
tion that creativity has two main steps: creating a novel idea
and verifying that this idea is useful or appropriate to the
task (Dietrich 2004); else the idea is adapted or rejected and
another novel idea is elaborated. These two steps are re-
spectively termed divergent and convergent thinking in hu-
man creativity research (Jung et al. 2013). Corresponding
mechanisms in CC are called “generate and evaluate”. The
ﬁrst step can be associated to insight (Kounios and Beeman
2014) and originate from an emotional or a more cognitive
process (Dietrich 2004). As for the second step, it is gener-
ally proposed that the assessment of the value of what has
been proposed is carried out by brain circuits associated to
executive functions. The brain circuits responsible for these
two steps have been studied in different ways as it will be
discussed in more details below.

The two steps of creativity
Concerning the divergent thinking step, it is reported that
self generated thoughts can be spontaneous or goal directed
(to meet speciﬁc task demands) (Dietrich 2004). This can
correspond to the reinterpretation of a situation to produce
a nondominant interpretation (Kounios and Beeman 2014)
or to using generative models to try to explicitly build a
novel solution, which has been qualiﬁed as a more restricted
but more efﬁcient solution (Dietrich 2004). (Boden 2009)
proposes that novel ideas can be produced by combination,
exploration or by transformation. (Dietrich 2004) proposes
four types of creativity: In the ﬁrst step, novelty can come
from emotional or cognitive structures and the processing
can be deliberate or spontaneous.

Among neuronal mechanisms evoked above, it can be re-
marked that the hippocampus is a good candidate to gener-
ate spontaneous novel ideas and that the mechanisms in the
prefrontal cortex, responsible for selecting a new Task Set,
might participate to the explicit elaboration of new thoughts.
Let us also underline that the model proposed in (Collins and
Koechlin 2012) explicitly mentions that if no existing Task
Set is appropriate to the task, a new Task Set might be cre-
ated by the combination between two existing Task Sets or
by the random generation of a new one.

The convergent thinking step is often related to cogni-
tive control, the role of which is also to ensure appropri-
ateness in the execution of a behavior. Appropriateness
can be syntactic (checking that procedural constraints are
respected, which is easy to do with a generative model)
or semantic (checking that manipulated objects have con-
sistent values, which is probably less easy (Dietrich 2004;
Boden 2009)). In all cases, it is proposed that these veriﬁca-
tions are made by the PFC, with the corresponding informa-
tion set in working memory for their conscious evaluation.

The two steps of creativity in brain circuitry
The functional description of brain circuits is often made
through networks of brain regions (Mesulam 2008), high-
lighting some regions as critical hubs for the spreading and

processing of information. The attentional, semantic, de-
fault, cognitive control and salience networks are the major
ones and play a central role in creativity (Jung et al. 2013).
The default network (activated by default, for sponta-
neous thinking, including parietal cortex, medial prefrontal
cortex and hippocampal regions) is much involved in cre-
ativity and is known for its links to episodic memory in the
hippocampus, spontaneous retrieval, replay activity and sim-
ulations based on personal past experiences (Dietrich 2004).
To evaluate the semantic and syntactic appropriateness of
candidate ideas, a reference is made toward an emotional
system for biological signiﬁcance of events (involving the
semantic network, associated to the insula and other limbic
regions) and an information processing system to perform
detailed feature analysis involving attentional control net-
works (Beaty et al. 2016). As a synthesis, pertinence, adap-
tation or rejection of candidate ideas is made by the cogni-
tive control network, involving the lateral prefrontal cortex
and the anterior cingulate cortex, performing top-down mod-
ulation of self generated information for efﬁcacy evaluation,
selection and adaptation to the task (Beaty et al. 2016).

Dynamics of inhibition and excitation in hubs and net-
works are observed with the analysis of EEG activity in
behavioral and psychological tasks (Kounios and Beeman
2014). It must be remarked that corresponding tests of cre-
ativity are in fact relying on measures of ﬂuency, ﬂexibility,
originality and elaboration, all measures also related to prob-
lem solving. This is also a strong argument to propose that
the same brain circuits and cognitive mechanisms are used
for higher brain functions and for creativity (Dietrich 2004).

Discussion
CCN models presented in this paper insist on the need to
build, inspired from neuroscience, different kinds of repre-
sentations in different regions of the brain (Alexandre, Car-
rere, and Kassab 2014) and to organize the selection of be-
havior through the interactions between different kinds of
memories (Alexandre 2000).

Understanding these mechanisms and corresponding
brain circuitry is particularly important to address current
limitations in AI. As a central claim for this paper, we pro-
pose that these mechanisms and cognitive processes are also
central to understand creativity as it is carried out in the
brain. Perhaps this is not so surprising if we consider that
among the mechanisms the brain has developed to circum-
vent the tedious and systematic analysis of some situtations,
creativity might be a choice mechanism to efﬁciently ex-
plore novel approaches.

The present paper mentions operational models that could
be directly exploited to implement CC. It also proposes
paths of research to implement speciﬁc mechanisms. Spon-
taneous processing could be related to the hippocampus and
its role in the default network, whereas deliberate process-
ing would be more frontal and related to the combination of
Task Sets. The more difﬁcult aspect of combinational cre-
ativity could be linked to the limitation of semantic ground-
ing, thus pleading for a closer look to the semantic network.
Using CCN models to implement CC could be also an eas-
ier way to choose the type of creativity to generate or even

to study fundamental differences between human and non-
human creativity (Colton and Wiggins 2012).

The very nature of creativity itself can be questioned from
the elements reported here. Creativity is often associated to
the generation of completly novel ideas. What is reported
here about convergent but also divergent thinking is that
most of the time, old memories are used to create new ideas.
Here also, it is the old that makes the new. What is also
reported here (in line with (Boden 2009) claiming that cre-
ativity is not magic) is that CC, indeed considered as a sci-
entiﬁc questioning, suffers mainly from fragmentation in AI
research (Colton, de Mantaras, and Stock 2009) and could
highly beneﬁt from the global framework proposed by cog-
nitive neuroscience.

References
Alexandre, F., and Carrere, M. 2016. Modeling Neuromod-
ulation as a Framework to Integrate Uncertainty in General
Cognitive Architectures. In The Ninth Conference on Artiﬁ-
cial General Intelligence.
Alexandre, F.; Carrere, M.; and Kassab, R. 2014. Fea-
ture, Conﬁguration, History : a bio-inspired framework for
information representation in neural networks. In Interna-
tional Conference on Neural Computation Theory and Ap-
plications.
Alexandre, F. 2000. Biological Inspiration for Multiple
Memories Implementation and Cooperation. In In V. Kvas-
nicka P. Sincak, J. Vascak and R. Mesiar, editors, Interna-
tional Conference on Computational Intelligence.
Beaty, R. E.; Benedek, M.; Silvia, P. J.; and Schacter, D. L.
2016. Creative Cognition and Brain Network Dynamics.
Trends in Cognitive Sciences 20(2):87–95.
Boden, M. A. 2009. Computer Models of Creativity. AI
Magazine 30(3):23–23. Number: 3.
Carrere, M., and Alexandre, F. 2015. A pavlovian model of
the amygdala and its inﬂuence within the medial temporal
lobe. Frontiers in Systems Neuroscience 9(41).
Collins, A., and Koechlin, E. 2012. Reasoning, Learning,
and Creativity: Frontal Lobe Function and Human Decision-
Making. PLOS Biology 10(3):e1001293+.
Colton, S., and Wiggins, G. A. 2012. Computational Cre-
ativity: The Final Frontier? In ECAI’12.
Colton, S.; de Mantaras, R. L.; and Stock, O. 2009. Compu-
tational Creativity: Coming of Age. AI Magazine 30(3):4pp.
Craig, A. 2009. How do you feel – now? the anterior insula
and human awareness. Nat. Rev. Neurosci. 10:59–70.
Damasio, A. R.; Everitt, B. J.; and Bishop, D.
1996.
The Somatic Marker Hypothesis and the Possible Func-
tions of the Prefrontal Cortex. Philosophical Transactions of
the Royal Society of London. Series B: Biological Sciences
351(1346):1413–1420.
Daw, N. D. 2018. Are we of two minds? Nature Neuro-
science 21(11):1497–1499.
Derdikman, D., and Moser, M.-B. 2010. A Dual Role for
Hippocampal Replay. Neuron 65(5):582–584. Publisher:
Elsevier.

Dietrich, A. 2004. The cognitive neuroscience of creativity.
Psychonomic Bulletin & Review 11(6):1011–1026.
Domenech, P., and Koechlin, E. 2015. Executive control and
decision-making in the prefrontal cortex. Current Opinion
in Behavioral Sciences 1:101–106.
Drumond, T. F.; Vi´eville, T.; and Alexandre, F. 2019. Bio-
inspired Analysis of Deep Learning on Not-So-Big Data
Using Data-Prototypes. Frontiers in Computational Neuro-
science 12.
Gershman, S. J., and Daw, N. D. 2017. Reinforcement
Learning and Episodic Memory in Humans and Animals:
An Integrative Framework. Annual Review of Psychology
68(1):101–128.
Harnard, S. 1990. The symbol grounding problem. Physica
D: Nonlinear Phenomena 42:335–346.
Jung, R. E.; Mead, B. S.; Carrasco, J.; and Flores, R. A.
2013. The structure of creative cognition in the human brain.
Frontiers in Human Neuroscience 7.
Kounios, J., and Beeman, M. 2014. The cognitive neuro-
science of insight. Annual Review of Psychology 65:71–93.
Mattar, M. G., and Daw, N. D. 2018. Prioritized memory
access explains planning and hippocampal replay. Nature
Neuroscience 21(11):1609–1617.
McClelland, J. L.; McNaughton, B. L.; and O’Reilly, R. C.
1995. Why there are complementary learning systems in
the hippocampus and neocortex: insights from the successes
and failures of connectionist models of learning and mem-
ory. Psychological review 102(3):419–457.
Mesulam, M. 2008. Representation, inference, and tran-
scendent encoding in neurocognitive networks of the human
brain. Annals of Neurology 64(5):367–78.
Nauta, W. J. 1971. The problem of the frontal lobe: A rein-
terpretation. Journal of Psychiatric Research 8(3-4):167–
187.
O’Reilly, R. C.; Noelle, D. C.; Braver, T. S.; and Cohen,
J. D. 2002. Prefrontal cortex and dynamic categorization
representational organization and neuromodulatory
tasks:
control. Cereb Cortex 12(3):246–257.
Pezzulo, G., and Castelfranchi, C. 2009. Thinking as the
control of imagination: a conceptual framework for goal-
directed systems. Psychological Research 73(4):559–577.
Pfeifer, R.; Bongard, J.; and Grand, S. 2007. How the body
shapes the way we think: a new view of intelligence. Brad-
ford Books. MIT Press.
Stachenfeld, K. L.; Botvinick, M. M.; and Gershman, S. J.
2017. The hippocampus as a predictive map. Nature Neuro-
science 20(11):1643–1653.
Wang, J. X.; Kurth-Nelson, Z.; Kumaran, D.; Tirumala, D.;
Soyer, H.; Leibo, J. Z.; Hassabis, D.; and Botvinick, M.
2018. Prefrontal cortex as a meta-reinforcement learning
system. Nature Neuroscience 21(6):860–868. Number: 6
Publisher: Nature Publishing Group.
Wise, S. P.
Forward Frontal Fields: Phy-
logeny and Fundamental Function. Trends in neurosciences
31(12):599–608.

2008.

