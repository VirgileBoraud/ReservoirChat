Interagir sans interpréter Apport d’une IA pour autonomiser un objet
robotique Yann Boniface, Nicolas P. Rougier

To cite this version:

Yann Boniface, Nicolas P. Rougier. Interagir sans interpréter Apport
d’une IA pour autonomiser un objet robotique. WACAI 2020 - Workshop sur
les Affects, Compagnons artificiels et Interactions, Jun 2020, Saint
Pierre d’Oléron, France. ￿hal-02933478￿

HAL Id: hal-02933478

https://inria.hal.science/hal-02933478

Submitted on 8 Sep 2020

HAL is a multi-disciplinary open access archive for the deposit and
dissemination of sci- entific research documents, whether they are pub-
lished or not. The documents may come from teaching and research
institutions in France or abroad, or from public or private research
centers.

L’archive ouverte pluridisciplinaire HAL, est destinée au dépôt et à la
diffusion de documents scientifiques de niveau recherche, publiés ou
non, émanant des établissements d’enseignement et de recherche français
ou étrangers, des laboratoires publics ou privés.

Interagir sans interpréter Apport d’une IA pour autonomiser un objet
robotique

Yann Boniface Yann.Boniface@loria.fr Université de Lorraine, CNRS,
LORIA, UMR 7503 Vandoeuvre-lès-Nancy, F-54506, France

RÉSUMÉ

Nous proposons de présenter dans cet article l’utilisation d’une carte
auto-organisatrice dans le processus de décision de l’action d’un objet
robotisé muni d’un capteur, ici une caméra, interagis- sant avec un ou
plusieurs humains. Cette carte utilise le capteur pour s’adapter à ses
interlocuteur, ici les traits de leur visage, et ainsi ajuster ses
mouvements au comportement des humains, sans toutefois les interpréter.

KEYWORDS

Interaction, Robot, Cartes auto-organisatrices, DSOM ACM Reference
Format: Yann Boniface and Nicolas Rougier. 2020. Interagir sans
interpréter Apport d’une IA pour autonomiser un objet robotique. In
Proceedings of Confe- rence (WACAI). ACM, New York, NY, USA, 5 pages.
https://doi.org/10.1145/ nnnnnnn.nnnnnnn

1 INTRODUCTION

Le groupe Psyphine [7], groupe pluridisciplinaire né en 2011, rassemble
des chercheurs issus de l’université de Lorraine en in- telligence
artificielle, philosophie, psychologie, neurosciences, so-
ciolinguistique et anthropologie. Il s’interroge sur les interactions
homme/robot et plus particulièrement sur l’attribution ou non d’in-
tentions, d’intelligence voire de conscience à un objet robotisé non
humanoïde. Pour mener ses expériences, il dispose d’une lampe (figure 1)
robotisée et munie d’une caméra, au dessus de son am- poule, qui est
utilisée en salle d’expérience comme dans des lieux publics
(médiathèque, marché alimentaire, etc.). Ces expériences mettent en
relation cet objet avec un ou plusieurs humains pour étudier leurs
réactions et tenter de les interpréter [2]. L’une des difficultés de nos
expériences passées réside dans les biais dus aux manipulateurs, qui
contrôlent tout ou partie du comportement de la lampe. Nous avons donc
développé un algorithme permettant à cette lampe d’acquérir une forme
d’autonomie, c’est-à-dire de bouger sans contrôle ni intervention de
notre part, tout en adaptant son comportement à celui de ses
interlocuteurs. C’est ce compor- tement, qui conjugue suivi de visage et
mouvements déclenchés par les attitudes des sujets, que nous proposons
de présenter. Ces

Permission to make digital or hard copies of all or part of this work
for personal or classroom use is granted without fee provided that
copies are not made or distributed for profit or commercial advantage
and that copies bear this notice and the full citation on the first
page. Copyrights for components of this work owned by others than ACM
must be honored. Abstracting with credit is permitted. To copy
otherwise, or republish, to post on servers or to redistribute to lists,
requires prior specific permission and/or a fee. Request permissions
from permissions@acm.org. WACAI, Juin 2020, Île d’Oléron, France © 2020
Association for Computing Machinery. ACM ISBN 978-x-xxxx-xxxx-x/YY/MM. .
.$15.00 https://doi.org/10.1145/nnnnnnn.nnnnnnn

Nicolas Rougier Nicolas.Rougier@inria.fr Inria Bordeaux Sud-Ouest
Talence, F-33405, France

attitudes sont apprises au cours de la passation et donc spécifiques à
chaque expérience.

Figure 1: La lampe robotisée du groupe Psyphine. Elle dis- pose de 5
moteurs (M1 à M5) et d’une caméra dans son abat- jour.

2 VERS DES EXPÉRIENCES AUTONOMES ET

QUALITATIVES

Pour étudier ces éventuelles attributions d’intentions à un objet
robotisé, le groupe Psyphine a effectué différentes expériences au cours
des années que nous décrivons succinctement dans cette section, pour une
description plus précise voir [2].

Figure 2: Un exemple de dispositif d’expérience en labora- toire. Le
sujet est placé devant la lampe et est filmé par une caméra.

WACAI, Juin 2020, Île d’Oléron, France

Yann Boniface and Nicolas Rougier

2.1 Expériences dirigées et analyses

quantitatives

Passation. Pour nos premières expériences, nous avons créé des
comportements pour notre lampe qui sont des séries de commandes motrices
prédéterminées et décrivant un mouvement complet de l’objet afin de
tenter d’exprimer une émotion (surprise, joie, ennui, peur, etc.). Nous
placions, en laboratoire, un sujet devant la lampe (voir figure 2) et un
manipulateur, caché au sujet et qui voyait la passation à travers une
caméra, déclenchait des comportements en fonction des attitudes du
sujet. Une passation alternative permettant une comparaison des
interactions proposait une série déterministe de comportements
s’exécutant donc sans tenir compte des réactions du sujet.

Évaluation quantitative. Nous faisions ensuite remplir un ques-
tionnaire au sujet pour comparer les résultats entre les expériences
avec séquence déterministe et celles avec un opérateur.

Bilan. Ces expériences se sont avérées non satisfaisantes pour

plusieurs raisons :

— Les comportements construits n’étaient pas interprétés de la même
façon par les différents sujets, et jamais, ou très rare- ment, comme
ils avaient été imaginés lors de leurs concep- tions. Une expérience
dédiée à cette question, Qualcom (voir [3]) le confirme.

— Les expériences réalisées en laboratoire influent fortement sur
l’attitude des sujets en raison du caractère trop solennel des lieux, de
l’aspect intimidant du dispositif (caméras, pro- jecteurs, écrans, etc.)
et de la connaissance même qu’il s’agit d’une expérience contrôlée,
mesurée et enregistrée.

— Les expériences sont fortement biaisées par le manipulateur, son
interprétation de l’attitude du sujets, son interprétation des séquences
de mouvements et certains dérapages de jeux avec le sujet (qu’il
faudrait un jour étudier, mais ce n’est pas notre propos ici). Le tout
variant en fonction des manipula- teurs.

— Les questionnaires quantitatifs se sont avérés peu informatifs, en
raison principalement de l’interprétation des question- naires et de son
vocabulaire par les sujets, des interprétations des barèmes qualitatifs
et de l’orientation des réponses in- duites par la formulation des
questionnaires.

2.2 Expériences semi-dirigées et analyses

qualitatives

Pour corriger ces limitations, nous nous sommes orientés vers

une nouvelle série d’expériences, appelée Decide.

Passation. Les passations se font, comme on peut le voir dans la figure
3, dans des lieux publics (marché alimentaire, médiathèque, etc.). Les
sujets sont placés par deux (s’ajoutent des participants spontanés
présents sur le lieu et curieux de l’expérience en cours) devant l’objet
et doivent se mettre d’accord sur une question qui leur est posée au
sujet de la lampe (sur son autonomie, son rôle fonc- tionnel par
exemple). L’expérience s’arrête quand ils s’accordent. Le comportement
de la lampe est contrôlé par un opérateur qui dispose de différentes
fonctionnalités (voir figure 4). Pour permettre une forme d’autonomie de
la lampe, et s’inspirant du projet Pinokio

Figure 3: Les expériences en milieu ouvert (marché alimen- taire)
consistaient à demander à deux personnes de discuter en présence de la
lampe afin de déterminer si celle-ci est au- tonome ou non, sachant que
cette dernière est contrôlée à distance par un opérateur caché.

Figure 4: L’interface de contrôle de l’expérience telle que vue par
l’opérateur, à gauche l’interface de contrôle de la lampe. Il est
possible de la manipuler en mode manuel (au joystick), d’utiliser la
fonctionnalité de suivi de visage ou de déclencher, par les boutons de
couleur, ce que nous appelons un comportement (joie, peur, ennui, etc.),
c’est-à-dire une sé- rie de mouvements pré-construits. A noter que la
seule en- trée vidéo est celle de la caméra de la lampe et il n’y a donc
pas de vue globale pour l’opérateur.

[1] nous l’avons dotée d’un comportement de suivi de visages. Il s’agit
de détecter et d’isoler un visage dans le champs visuel de sa caméra
(située dans l’abat-jour) et d’utiliser ses moteurs afin de centrer ce
visage dans l’image. Ce comportement est toutefois insuffisant, notre
objet ne bouge pas en l’absence de visage et le perd fréquemment en
cours d’expérience. Pour retrouver les sujets et relancer le suivi,
l’opérateur, qui ne voit l’expérience que par la caméra de l’objet,
dispose des comportement définis précédemment et d’un contrôle au
joystick.

Évaluation qualitative. L’évaluation de nos passations se fait en

deux étapes.

— Les passations sont filmées et sont ensuite analysées par nos soins.
Nous cherchons à comprendre les perceptions et inter- rogations des
participants par l’analyse de leur dialogue.

Interagir sans interpréter

WACAI, Juin 2020, Île d’Oléron, France

— Les sujets sont interrogés par l’un d’entre nous pour décrire leur
sensations et interprétations. Ces interviews sont enre- gistrées et
ensuite analysées par nos soins.

de la donnée. Ces classes sont apprises à l’aide des données, per-
mettant ainsi une classification propre à chaque jeu de données, ou à
chaque expérience produisant des données.

Bilan. Ces séries d’expériences se sont avérées plus satisfaisantes,
notamment grâce aux lieux ouverts, le dialogue entre les partici- pants
et les interviews mais comportent encore des biais, les princi- paux
étant :

— Pour l’analyse des expériences, les sujets sont encore trop influencés
par la personne effectuant l’entretien. Nous nous sommes tournés ensuite
vers des méthodes d’autoconfron- tation, méthode qui fait l’objet d’une
seconde soumission à Wacai.

— Le comportement de suivi de visage, trop simple, est rapide-

ment identifié par les sujets.

— Les comportements de ’recentrages’, au joystick ou à l’aide des
comportements construits, qui permettent de relancer le suivi de visage,
restent trop dépendant de l’opérateur, avec tous les biais énoncés plus
haut.

2.3 Limitations

Au delà du suivi de visage, qui autonomise en partie notre lampe au
cours des passations, nous restons donc très dépendants de l’opérateur
et des biais induits : interprétations des comportements construits de
la lampe, interprétation des attitudes des sujets, sou- hait de créer sa
propre interaction avec les sujets, de répondre à certaines de leur
-supposées- demandes d’interaction, etc. Nous souhaitons donc enrichir
notre suivi de visage en évitant à la fois des mouvements stéréotypés ou
systématiques et des interventions humaines (commandes manuelles) trop
sujettes à biais. Nous sou- haitons toutefois que les mouvements de la
lampe soient spécifiques aux sujets et cohérents par rapport à leurs
attitudes, par exemple une attitude identique du sujet devra déclencher
une même réaction, un même mouvement, de la lampe.

3 LES SOM, CLASSIFIEURS NEURONAUX

Pour obtenir cette adaptation dépendante du sujet, nous utilisons
l’algorithme DSOM [8], variation des classiques classifieurs cartes
auto-organisatrices (SOM) [6], permettant d’apprendre des données
dynamiques, c’est-à-dire changeantes au cours du temps. Ici ce sont les
sujets, et leurs attitudes, qui changent au cours du temps (au cours
d’une expérience ou d’une expérience à une autre) et le comportement de
la lampe doit s’y adapter. Plus exactement, ce sont les traits des
visages, les coordonnées des points des yeux, bouches, etc. dans le
visage des sujets qui sont les données prises en compte pour notre
classification.

3.1 Carte auto-organisatrice

L’algorithme des cartes auto-organisatrices est un algorithme de
classification des données permettant de les représenter avec une
cohérence topologique : deux classes proches dans l’espace de re-
présentation de la carte représenteront des données proches. Cette
classification permet de représenter les données dans un espace fini (la
taille de la carte), chacune des données (un vecteur) étant représentée
par une classe, celle qui a le vecteur le plus proche (au sens d’une
mesure numérique, la distance euclidienne par exemple)

3.2 Carte auto-organisatrice dynamique

Nous avons modifié l’algorithme original de SOM afin de rendre sa règle
d’apprentissage et son voisinage indépendants du temps. Il en résulte un
couplage étroit entre l’environnement et le modèle qui assure à la fois
stabilité et plasticité. Plus précisément, La carte DSOM est une carte
neurale dotée d’une structure (un hypercube ou un réseau hexagonal) où
chaque neurone 𝑖 se voit attribuer une position fixe pq avec 𝑞 la
dimension de la carte (généralement 1 ou 2). Le processus
d’apprentissage est un processus itératif dans lequel les vecteurs 𝑠 ∈ Ω
sont présentés séquentiellement sur la carte par rapport à la fonction
de densité de probabilité 𝑓 . Pour chaque vecteur 𝑣 présenté, un gagnant
𝑠 ∈ 𝑁 est déterminé selon l’équation. Tous les codes wi du codebook 𝑊
sont alors décalés vers 𝑣 selon l’équation :

Δw𝑖 = 𝜀 ∥v − w𝑖 ∥Ω ℎ𝜂 (𝑖, 𝑠, v)(v − w𝑖 ) (1) avec 𝜀 le pas
d’apprentissage (constant), et ℎ𝜂 (𝑖, 𝑠, v)(v − w𝑖 ) la fonction de
voisinage de la forme :

ℎ𝜂 (𝑖, 𝑠, v)(v − w𝑖 ) = exp −

1 𝜂2

∥p𝑖 − p𝑠 ∥2 ∥v − w𝑠 ∥2 Ω

(2) 

avec 𝜂 le paramètre d’élasticité. A noter que lorsque v = w𝑠 , on a ℎ𝜂
(𝑖, 𝑠, v) = 0.

L’algorithme DSOM est donc essentiellement une variante de l’algorithme
SOM dont la dépendance temporelle a été supprimée. La fonction
d’apprentissage régulier et la fonction de voisinage ont été
respectivement remplacées par les équations (1) et (2) qui reflètent
deux idées principales :

— Si un neurone est suffisamment proche des données, il n’est pas
nécessaire que les autres apprennent quoi que ce soit : le gagnant peut
représenter les données.

— S’il n’y a pas de neurone suffisamment proche des données, tout
neurone apprend les données en fonction de sa propre distance par
rapport aux données.

Cela entraîne plusieurs conséquences sur la notion de voisinage qui est
désormais dynamique et conduit à une auto-organisation qualitativement
différente qui peut être contrôlée à l’aide d’un paramètre d’élasticité
libre 𝜂.

4 CLASSIFIER POUR INTERAGIR

Nous décrivons dans cette section l’utilisation de notre classifieur
dans le cadre de nos expérience avec la lampe du groupe Psyphine.

4.1 Extraire d’une image les traits du visage

Comme nous pouvons le voir sur la figure 5, à partir de l’image reçue de
la caméra, nous isolons un visage (le carré rouge) à l’aide de la
librairie opencv ([4]). Nous extrayons ensuite de chaque image un
vecteur de points (les points bleus dans le carré gris en haut à gauche
de la figure) représentant certains traits 1 de ce visage à

1.  Ici sourcils et lèvres, mais tous les points visibles dans le carré
    rouge sont

disponibles.

WACAI, Juin 2020, Île d’Oléron, France

Yann Boniface and Nicolas Rougier

sur d’autres, et même à des changements de personnes, l’élasti- cité de
DSOM permet l’apprentissage en temps réel de nouveaux prototypes.

Figure 5: La localisation des visages et la capture des traits
principaux à partir de l’image de la caméra de la lampe est effectué en
temps réel via la librairie Open-CV. Seules les informations relatives
aux sourcils et à la bouche sont ici utilisées par la carte
auto-organisatrice.

l’aide de l’algorithme de [5]. C’est ce vecteur de points qui constitue
la donnée numérique apprise par notre classifieur.

4.2 Classifier les attitudes des sujets

La figure 6 montre les vecteurs qui sont appris en temps réel par notre
le classifieur DSOM. Pour décrire rapidement l’apprentis- sage d’une
carte, il faut noter qu’une classe est considérée comme gagnante, pour
un visage, quand les points extraits sont les plus proches des points
appris par cette classe. Cette classe se modifie alors en fonction de
cette nouvelle donnée pour s’en approcher, et entraîne ses voisins (dans
la topologie de la carte) pour qu’ils s’en approchent aussi, mais de
moins en moins en fonction de la distance dans la carte.

Chaque image capturée par la caméra est traitée par l’algorithme
d’extraction de traits et apporte ainsi un nouvel exemple pour
l’apprentissage de la carte, c’est-à-dire pour la spécialisation de la
classe gagnante et de ses voisines. Chaque classe représente ainsi une
posture caractéristique, une attitude, (représentée par les points) de
visage, et nous disposons ainsi en temps réel d’une information sur les
postures de visage les plus fréquentes du ou des sujets placés dans le
champs de la caméra.

Cette classification est unique et totalement dépendante des traits et
des postures du sujet au cours de l’expérience, une personne très
expressive aura une distance entre les classes la représentant plus
importante qu’une autre moins expressive, néanmoins, le nombre de
classes cartographiant ses expressions sera le même. Cette clas-
sification se fait ainsi de manière totalement autonome et sans aucune
interprétation d’éventuelles émotions portées par ces pos- tures. Notre
question est d’isoler des postures de visage, pas d’en comprendre la
signification.

Pour finir, DSOM permettant l’apprentissage de données dyna- miques,
cette classification s’adaptera à plusieurs sujets, c’est-à-dire que
certaines classes se spécialiseront sur l’un des sujets, les autres

Figure 6: Une carte DSOM avec 64 (8×8) neurones. Chaque neurone est
représenté par son prototype (points bleus) dans l’espace des images.
L’auto-organisation permet de s’assurer que deux neurones proches (au
sens de la topologie de la carte) possèdent des prototypes proches (au
sens de la dis- tance entre prototypes). Dans l’exemple montré
ci-dessus, les neurones dans les coins supérieur gauche et inférieur
droit sont opposés, mais il existe un chemin continu dans la carte
permettant de passer de l’un à l’autre). Le paramètre d’élasticité
permet de contrôler la similitude entre les proto- types de deux
neurones voisins.

4.3 Associer des comportements aux classes

Figure 7: Distribution des comportements sur les classes. Nous pouvons
voir au dessus la répartition des classes ga- gnantes, c’est-à-dire le
nombre d’images pour lesquelles chaque classe fut la plus proche.

Interagir sans interpréter

WACAI, Juin 2020, Île d’Oléron, France

Au cours de la mise en place de nos différentes expériences, nous nous
sommes construit un catalogue assez varié de comporte- ments de la
lampe, c’est-à-dire de mouvements préprogrammés [3], certains ayant été
conçus pour -tenter d’- exprimer une émotion (peur, etc.) d’autres non
(vers la droite, vers le haut, etc.). Comme le montre la figure 7, en
utilisant toujours notre classificateur DSOM, nous distribuons nos
comportements sur une carte de même taille que celle des traits. Ce sont
les vecteurs de commandes motrices qui sont cette fois appris, de la
même manière que précédemment les points extraits des images de la
caméra. Les deux cartes étant de la même taille, nous pouvons lier un
comportement de la lampe à chaque expression des sujets apprise. Ainsi
la classe gagnante (en rouge sur la figure 6) sera associée au
comportement PEUR. Cette distribution des comportements de la lampe se
fait au début de l’expérience et reste donc, dans l’état actuel de
l’algorithme, la même tout au long de l’expérience. Elle peut aussi être
gardée d’une passation à une autre.

5 UNE EXPÉRIENCE AUTONOME

Avec ces cartographies, nous disposons maintenant d’un algo- rithme
permettant de déclencher un mouvement de notre objet ro- botisé en
fonction des attitudes du ou des sujets ayant été présents dans le
champs de sa caméra. Il reste à construire une expérience à l’aide des
fonctions dont dispose notre lampe, une expérience qui, en plus d’être
autonome, est spécifique aux sujets présents et à leurs attitudes au
cours de l’expérience. L’expérience s’articule donc principalement sur
le suivi de visage, puis, quand ce suivi échoue, sur l’apprentissage
décrit ci-dessus. Le suivi de visage peut échouer pour de nombreuses
raisons, la lampe ne peut physiquement plus suivre le mouvement (les
articulations sont aux limites de leurs possibilités), le sujet suivi a
été perdu (déplacement trop rapide par exemple), le visage est masqué,
etc. L’expérience proposée est décrite par l’algorithme suivant :

Apprendre la carte des comportements (DSOM) RÉPÉTER

Capturer une image depuis la caméra de la lampe SI un visage peut être
extrait de l’image

. Apprendre ce nouveau visage dans la carte des expressions

à l’aide de DSOM

. Incrémenter le nombre de victoires de la classe gagnante . TI = 0; .
Déplacer la lampe pour centrer le visage dans

l’image de la caméra

SINON

SI Le temps d’impatience (TI) est dépassé

.Déclencher le comportement associé à la classe des expressions qui a le
plus gagné. .TI=0 .Mise à zéro des victoires de la carte des expressions

A noter que les paramètres de cet algorithme sont : — La taille des
cartes auto-organisatrices. — Le nombre de comportements de la lampe.

Il n’est pas souhaitable d’avoir plus de comportements que de classes,
il est même conseillé d’en avoir beaucoup moins, pour distribuer un même
comportement sur plusieurs classes.

— Les temps d’impatience.

Temps au terme duquel une action autre que le suivi de visage sera
déclenchée. Il est généralement de 1500 milli-secondes.

— Les traits pris en compte.

Nous disposons de différentes catégories de traits (nez, sourcils,
lèvres, yeux, chacun pouvant être décomposé : droite/gauche, haut/bas).
Il n’est pas toujours utile de considérer tous les points dans
l’apprentis- sage, d’autant que certains traits (lèvres par exemple, par
leur nombre de points, écrasent les autres). Dans l’expérience qui
illustre cet article nous n’utilisons que les sourcils et les lèvres.

6 DISCUSSION

Le modèle présenté dans cet article permet de rendre le comportement de
la lampe autonome et interactif. Autonome en ce qu’il ne requiert plus
l’intervention d’un opérateur et interactif en ce qu’il réagit aux
informa- tions captées par sa caméra (les visages en particulier) sans
pour autant chercher à interpréter ces informations. C’est là une
propriété importante puisqu’elle garantit l’absence de biais de la part
de l’opérateur et autorisera à terme des interactions plus neutres, du
moins du côté de la lampe. C’est dans ce contexte que nous travaillons
actuellement sur une version plus robuste permettant de laisser notre
objet dans un lieu ouvert et de le laisser interagir au grès du passage
aléatoire des personnes et des visages entrant dans le champ de sa
caméra. Cela requiert cependant de régler quelques paramètres comme le
temps d’impatience (pas de visage détecté) au-delà duquel la lampe
déclenche des comportements moteurs qui sont alors sus- ceptibles
d’attirer des personnes à elle. Cependant, toute la difficulté de ces
expériences réside dans la nature du milieu, à la fois ouvert et non
contrôlé. Comme nous l’avons expliqué auparavant, la nature solennelle
des expériences en laboratoire semble perturber l’interaction entre les
parti- cipants et la lampe, ce qu’il ne semble pas être le cas lorsque
les sujets sont libres d’interagir (ou non) avec la lampe. Nous devrons
donc à terme dé- finir une méthode de mesure objective afin de rendre
compte de l’expérience.

Note aux relecteurs : Cet article présente une solution pour construire
des expériences avec un objet totalement autonome au cours de la
passation. Nous hésitons à proposer cette expérience comme démonstration
pour cause de fragilité de la lampe. Mais s’il vous semble plus
pertinent de la mettre dans cette rubrique… Par ailleurs, cet article a
été rédigé quelque peu dans l’urgence, ses auteurs étant fort impliqués
dans le mouvement d’opposition aux contre réformes en cours pour les
universités et les retraites, il pourra donc être largement remanié pour
une version définitive le cas échéant.

RÉFÉRENCES [1] Ben-Dror Adam and Zhou Shanshan. 2012. Projet Pinokio.
http://www.ben-

dror.com/pinokio.

[2] Virginie André and Yann Boniface. 2018. Quelques considérations
interactionnelles autour d’une expérience robotique. In WACAI 2018 -
Workshop sur les ”Affects, Compagnons Artificiels et Interactions”. Ile
de Porquerolles, France. https://hal. archives-ouvertes.fr/hal-01862725

[3] Joffrey Becker, Virginie Andre, and Alain Dutech. 2019. QUALCOM :
une ex- périence sur la qualification des comportements d’une lampe
robotique. Tech- niques & culture : Revue semestrielle d’anthropologie
des techniques (2019). https: //hal.archives-ouvertes.fr/hal-02075467

[4] Itseez. 2015. Open Source Computer Vision Library.
https://github.com/itseez/

opencv.

[5] Vahid Kazemi and Josephine Sullivan. 2014. One Millisecond Face
Alignment with an Ensemble of Regression Trees. In Proceedings of the
2014 IEEE Conference on Computer Vision and Pattern Recognition (CVPR
’14). IEEE Computer Society, Washington, DC, USA, 1867–1874.
https://doi.org/10.1109/CVPR.2014.241 [6] T. Kohonen, M. R. Schroeder,
and T. S. Huang (Eds.). 2001. Self-Organizing Maps

(3rd ed.). Springer-Verlag, Berlin, Heidelberg.

[7] Psyphine. 2011. https://psyphine.hypotheses.org. MSH, Université de
Lorraine. [8] Nicolas P. Rougier and Yann Boniface. 2011. Dynamic
Self-Organising Map. Neurocomputing 74, 11 (2011), 1840–1847.
https://doi.org/10.1016/j.neucom.2010. 06.034


