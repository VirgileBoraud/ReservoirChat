PRANAS: A new platform for retinal analysis and
simulation
Bruno Cessac, Pierre Kornprobst, Selim Kraria, Hassan Nasser, Daniela

Pamplona, Geoffrey Portelli, Thierry Viéville

To cite this version:

Bruno Cessac, Pierre Kornprobst, Selim Kraria, Hassan Nasser, Daniela Pamplona, et al.. PRANAS:
A new platform for retinal analysis and simulation. [Research Report] RR-8958, Inria Sophia Antipolis;
Inria Bordeaux Sud-Ouest. 2017, pp.27. ￿hal-01377307v2￿

HAL Id: hal-01377307

https://inria.hal.science/hal-01377307v2

Submitted on 24 Aug 2017

HAL is a multi-disciplinary open access
archive for the deposit and dissemination of sci-
entific research documents, whether they are pub-
lished or not. The documents may come from
teaching and research institutions in France or
abroad, or from public or private research centers.

L’archive ouverte pluridisciplinaire HAL, est
destinée au dépôt et à la diffusion de documents
scientifiques de niveau recherche, publiés ou non,
émanant des établissements d’enseignement et de
recherche français ou étrangers, des laboratoires
publics ou privés.

PRANAS: A new
platform for retinal
analysis and simulation

B. Cessac, P. Kornprobst, S. Kraria, H. Nasser, D. Pamplona, G.
Portelli, T. Viéville

The authors are listed in alphabetical order

G
N
E
+
R
F
-
-
8
5
9
8
-
-

/

R
R
A
R
N

I

I

RESEARCH
REPORT
N° 8958
August 2017

Project-Teams Biovision and
Mnemosyne

N
R
S

I

9
9
3
6
-
9
4
2
0
N
S
S

I

PRANAS: A new platform for retinal analysis
and simulation

B. Cessac∗, P. Kornprobst∗, S. Kraria∗, H. Nasser∗, D.
Pamplona∗, G. Portelli∗, T. Viéville†
The authors are listed in alphabetical order

Project-Teams Biovision and Mnemosyne

Research Report n° 8958 — August 2017 — 24 pages

Abstract: The retina encodes visual scenes by trains of action potentials that are sent to the
brain via the optic nerve. In this paper we describe a new free access user-end software allowing
to better understand this coding.
It is called PRANAS (https://pranas.inria.fr), standing for
Platform for Retinal ANalysis And Simulation. PRANAS targets neuroscientists and modelers
by providing a unique set of retina-related tools. PRANAS integrates a retina simulator allowing
large scale simulations while keeping a strong biological plausibility and a toolbox for the analysis of
spike train population statistics. The statistical method (entropy maximization under constraints)
takes into account both spatial and temporal correlations as constraints, allowing to analyze the
eﬀects of memory on statistics. PRANAS also integrates a tool computing and representing in
3D (time-space) receptive ﬁelds. All these tools are accessible through a friendly graphical user
interface. The most CPU-costly of them have been implemented to run in parallel.

Key-words: Retina simulator, spike train statistics, population coding, maximum entropy, Gibbs
distributions, large scale spiking activity, spike train generation, multi-electrode array recordings

∗ Université Côte d’Azur, Inria, Biovision team, France
† Inria, Mnemosyne project team, Bordeaux, France

RESEARCH CENTRE
SOPHIA ANTIPOLIS – MÉDITERRANÉE

2004 route des Lucioles - BP 93
06902 Sophia Antipolis Cedex

PRANAS: Une nouvelle plateforme pour l’analyse et la
simulation de rétines

Résumé : La rétine encode les scènes visuelles par des trains de potentiels d’action qui sont
envoyés au cerveau via le nerf optique. Dans cet article, nous décrivons un nouveau logiciel libre
d’accés qui permet de mieux comprendre ce codage. Il s’appelle PRANAS (https://pranas.inria.fr),
ayant pour signiﬁcation Platform for Retinal ANalysis And Simulation. PRANAS cible les neu-
roscientiﬁques et les modélisateurs en fournissant un ensemble unique d’outils liés à la rétine.
PRANAS intègre un simulateur de rétine permettant des simulations à grande échelle tout
en conservant une forte plausibilité biologique et une boîte à outils pour l’analyse statistique
des trains d’impulsion dans une population de neurones. La méthode statistique (maximisation
de l’entropie sous contraintes) prend en compte les corrélations spatio-temporelles comme con-
traintes, permettant d’analyser les eﬀets de la mémoire sur les statistiques. PRANAS intègre
également un outil de calcul et de représentation en 3D (temps-espace) des champs récepteurs.
Tous ces outils sont accessibles grâce à une interface utilisateur conviviale. Les plus coûteux
d’entre eux en terme de temps de calculs ont été implémentés pour fonctionner en parallèle.

Mots-clés : Retina simulator, spike train statistics, population coding, maximum entropy,
Gibbs distributions, large scale spiking activity, spike train generation, multi-electrode array
recordings

PRANAS: retinal analysis and simulation

3

1

Introduction

The retina is one of the most developed sensing devices [21, 34, 35]. It transforms the incoming
light into a set of electrical impulses, called spikes, which are sent asynchronously to higher
level structures in the visual cortex through the optic nerve. Although Cajal’s neuron doctrine
was postulated more than one century ago, how information is encoded and transmitted by
neurons is still not entirely understood today. Especially, the role of spatio-temporal correlations
in population coding raises up deep theoretical and practical questions that are far from being
answered [49, 6], particularly for the visual information transmitted from the retina to the visual
cortex. To address these questions and make progress in their understanding, one needs to
develop joint modeling and experimental studies with eﬃcient software to analyse data.
In
this paper we present a new Platform for Retinal ANalysis And Simulation called PRANAS
(https://pranas.inria.fr).
It was designed as a user-friendly tool dedicated to neuroscientist
It has
community in a large sense, i.e., not only experienced computational neuroscientists.
two main goals, analyse retina data, especially spatio-temporal correlations, and simulate the
spike response of the retina to a visual ﬂow. This makes this tool a unique platform to better
understand how the retina works.

The ﬁrst goal of PRANAS is to provide methods to analyse retinal recordings at single cell
and population levels. With the advent of new techniques, the recording of the simultaneous
activity of groups of neurons provides a critical database to unravel the role of speciﬁc neural
assemblies in spike coding. The acquisition capacity of Multi-Electrode Arrays (MEA) has been
exponentially increasing over years [57]. Systems like the 256–MEA has become a standard
although new high-density MEA are now available such as the APS CMOS 4096–electrodes [15].
Using these systems, one can record from hundreds to thousands of neurons simultaneously in
the retina (and more generally in vivo or in vitro, from cultures of neurons, and from other
brain areas). As one gains more intuitions and results on the importance of concerted activity
in spike trains, models are developed to extract, from animal recordings, possible canonical
principles underlying spike coding. This is a major challenge with many potential outcomes.
Beyond the dream that population coding is ruled by a few ﬁrst principles, several applications
could emerge such as the development of artiﬁcial systems having similar levels of performance
as biological systems. To this end, accurate tools are required to analyse and compare spike
trains, experimental or computer generated ones. Progress has been made recently to analyse
spike trains [53, 54, 32, 62, 61, 52, 51, 50]. Especially, the spatio-temporal aspects (memory)
and causality have been shown to be relevant for exploring neural activity [6]. For instance, [68]
and [60] demonstrated the importance of temporal statistics and [42, 40] developed new tools to
analyse spatio-temporal activity for large scale spiking networks. These methods shed a new light
on spike train analysis. However, they require time and expertise to be implemented eﬃciently,
making them hard to use. The idea of developing a new software came from our motivation to
share these recent developments with the neuroscience community in a broad sense. PRANAS
integrates all our expertise in terms of spike trains statistical analysis. Note that other methods
analyzing correlations in massively parallel data using completely diﬀerent approaches have also
been proposed [26, 59, 65, 47].

The second goal of PRANAS is to provide a customizable retina simulator which could evolve
in synergy with experimental data analysis. Currently, there is a large and expanding body of
literature concerning models of retinal processing. There are three main classes of models. The
ﬁrst class regroups the linear-nonlinear-poisson (LNP) models [43]. LNP models can simulate
the spiking activity of ganglion cells (and of cortical cells) in response to synthetic or natural
images [3] but they voluntarily ignore the neuronal mechanisms and the details of the inner
retinal layers that transform the image into a continuous input to the ganglion cell (or any

RR n° 8958

4

Cessac & others

type of cell) stages. The second class of models has been developed to serve as a front-end
for subsequent computer vision task. They provide bio-inspired modules for low level image
processing. One interesting example is given by [2, 23], where the model includes parvocellular
and magnocellular pathways using diﬀerent non-separable spatio-temporal ﬁlter that are optimal
for form- or motion-detection. The third class is based on detailed retinal models reproducing
its circuitry, in order to predict the individual or collective responses measured at the ganglion
cells level [44, 69, 31, 33]. In PRANAS, we are interested in this third class of models because
they allow to explore several aspects of retinal image processing such as (i) understanding how
to reproduce accurately the statistics of the spiking activity at the population level [41], (ii)
reconciling connectomics and simple computational rules for visual motion detection [29] and
(iii) investigating how such canonical microcircuits can implement the diﬀerent retinal processing
modules cited in, e.g., [21]. More precisely, the PRANAS platform has integrated and extended
the VIRTUAL RETINA simulator [69]1 initially developed in our team to do large scale retina
simulations. VIRTUAL RETINA has been used in several theoretical studies [37, 39, 1, 11, 12,
66].

This paper, aiming at presenting this new platform PRANAS, is organized as follows. In
Sec. 2, we give an overview of PRANAS and compare it with a selection of other tools currently
available focusing on spike train analysis methods. In Sec. 3, we present the main features of the
software. Illustrations and step by step procedures are given in several cases allowing readers to
reproduce them. In Sec. 4, we discuss future developments.

2 General presentation

PRANAS targets a broad community of scientists interested in exploring spike coding, in par-
ticular at retina level. It provides new tools for analyzing spike trains at the population level and
several methods to generate them, either with a prescribed statistics (including spatio-temporal
correlations) or by emulating the retinal response to a visual scene. This is done through a user-
friendly Graphical User Interface (GUI). PRANAS runs on multiple platforms (Linux, Mac
OS, Windows) and it supports parallel architectures. The software is provided as binary code
or as source code on request upon acceptance on the terms of the license given on the website
(http://pranas.inria.fr). Documentation, tutorials, and samples of spike trains are also available.

The GUI of PRANAS (version 1.0.0) has three main panels, as shown in Fig. 1:

• Function panel ( FP ) is the main panel containing Input/Output interfaces and functions.
It is organized in three sections: Data, Analysis and Simulation. (see Sec. 3 for more
details).

• The parameter panel ( PP ) allows one to set parameters related to the chosen function

from the function panel.

• The results panel ( RP ) contains the results. Several results can be displayed simultaneously
in diﬀerent subpanels, and each result can be exported as a ﬁgure in a variety of formats
(e.g., PDF, PNG, JPG). The user can change the Number of views and which result
should be displayed in each subpanel. In most subpanels, there are icons on the left-hand
side to open, save, export or change plot settings (see Fig. 1(c)). Another example is shown
in Fig. 4(a) (Stimulus view) where the user can export, show/hide grid and spikes and
select neurons graphically.

1VIRTUAL RETINA website: http://virtualretina.inria.fr

Inria

PRANAS: retinal analysis and simulation

5

Figure 1: Presentation of PRANAS GUI panels. (a) Function panel ( FP ) is the main panel con-
taining Input/Output interfaces and functions. It is organized in three sections: Data, Analysis
and Simulation. Note that in the Help option from the menu bar users can select Show bubble
help which will trigger tooltips giving information for each function.
(b) Depending on the
function selected, the parameter panel ( PP ) gives the opportunity to set the corresponding pa-
rameters. (c) Results panel ( RP ) can show all results the user want. The number of sub-panels
and the windows to show can be changed. Note that for each result shown in a sub-panel, the
user can customize the display or export it in diﬀerent formats.

Finally, another convenient feature of the software is that user can save what he has done in
term of analysis in a HDF5 ﬁle [70] (File>Save) and load it later to continue the work.

PRANAS is implemented in C++.

It also uses other
libraries for storage (HDF5), analysis (GSL, SFMT), display and GUI (Qt4, Qwt, VTK, CImg).
Some parts of the software, especially the statistical estimations, run on multiple processors
thanks to OpenMP framework. The software takes all the available processors in the machine
automatically, without any interaction with the user. Parallelization allows to boost heavy
computations and save processing time and memory.

It has its own dedicated libraries.

To our best knowledge there is no other platform integrating together the functionalities pro-
posed by PRANAS, to both analyse and stimulate retinal activities. There are however several
platforms performing eﬃcient spike train analysis. Table 1 provides a qualitative comparison
between PRANAS and a selection of such tools for spike train analysis. We note that the im-
plementation of PRANAS as a stand-alone application in C++/Qt4 rather than a library (such
as, e.g., the FIND toolbox) makes this tool readily available without the need of an external in-

RR n° 8958

Figure 1: GUI overview and basic visualisationsPPFPRP(a)(b)(c)Function panelParameter panelResult panel(b)Menu barExample of Tooltip associated to Population analysis Customize the display or export it in different formatsAbout this moduleFit parameters considering a speciﬁc probability distribution (potential).Show bubble helpTutorialsSupportAbout PRANASFile Help6

Cessac & others

terpreter, such as Python or the commercially available Matlab suite (MathWorks, Natick, VA).
Thus, access to PRANAS functions from a scripted analysis is performed via command line calls
(see Sec. 4).

Version

Language

GUI
Scripting
Free binary
File formats (Nex)
File formats (HDF5)
Rate histogram PSTH
Population PSTH
ISI
Cross-correlograms
Joint spike and stimulus
visu.
STA
PCA
Spectral analysis
MaxtEnt (x / x-t)
Raster generation
... with Poisson / Non
Poisson
... with VIRTUAL
RETINA

CX
2.12
Mat-
lab

FD
2.0
Mat-
lab

(cid:32)
(cid:32)
(cid:32)
(cid:32)
(cid:32)

(cid:32)
(cid:32)
(cid:32)

(cid:32)
(cid:32)
(cid:32)

(cid:32)
(cid:32)
(cid:32)

(cid:32)

SL
1.00
Mat-
lab

(cid:32)
(cid:32)
(cid:32)
(cid:32)

(cid:32)
(cid:32)
(cid:32)
(cid:32)

NT
2.0
Mat-
lab

(cid:32)
(cid:32)

GLM

NY
0.1

OY
0.3.5

ET
0.3.0

SR
0.3-2

R

(cid:32)
(cid:32)

(cid:32)
(cid:32)

Python Python Python

(cid:32)
(cid:32)
(cid:32)
(cid:32)
(cid:32)

(cid:32)

(cid:32)

(cid:32)
(cid:32)
(cid:32)

(cid:32)
(cid:32)
(cid:32)
(cid:32)

(cid:32)

(cid:32)

(cid:32)

(cid:32)

(cid:32)
(cid:32)
(cid:32)
(cid:32)
(cid:32)
(cid:32)
(cid:32)
(cid:32)

(cid:32)

(cid:32)

(cid:32)

(cid:32)

NE
5.037

VB

SV
0.4.2

PS
1.0.0

Python

C++

(cid:32)
(cid:32)

(cid:32)

(cid:32)
(cid:32)
(cid:32)
(cid:32)

(cid:32)
(cid:32)
(cid:32)

(cid:32)
(cid:32)
(cid:32)
(cid:32)
(cid:32)
(cid:32)
(cid:32)
(cid:32)
(cid:32)

(cid:32)

(cid:32)

(cid:32)
(cid:32)
(cid:32)
(cid:32)
(cid:32)
(cid:32)
(cid:32)

(cid:32)

(cid:32)

(cid:32)
(cid:32)

(cid:32)

(cid:32)

Table 1: Comparison between a selection of existing software for spike train analysis. Ab-
breviations for software names (ﬁrst and last initials) have been chosen for the presentation.
Following software is discussed: CX: Chronux [27], FD: FIND [38], NT: nSTAT [20],
SL: sigTOOL [30], NY: NeuroPy [56], OY: OpenElectrophy [18], ET: Elephant, SR:
STAR [45], NE: NeuroExplorer, SV: SpykeViewer [46], and PS: PRANAS. Note that
features selected in this table have essentially been chosen according to what PRANAS does.
It is not an exhaustive list and information applies to the time of writing. Software we mention
can have additional features not commented herein.

3 PRANAS main functions

3.1 Data

In section Data, user can load spike trains ﬁles. Spikes may come either from real cells recordings
or from a simulated spiking neural network. They can be imported from diﬀerent formats such
as simple text ﬁle (.txt), DAT ﬁle for Windows (.dat), NEXUS ﬁle (.nex) or HDF5 ﬁle format
(.hdf5, see [70]) allowing to store not only the spikes but also other information related to
experimental protocole (e.g., time stamps, MEA characteristics).

Depending on how the spikes were generated, the user can also load other information such

as:

• The MEA conﬁguration for animal cell recordings, allowing the spiking activity to be

displayed relative to the grid of electrode.

Inria

PRANAS: retinal analysis and simulation

7

• The sequence of images in case of a visual experiment, allowing the spiking activity to be
displayed together with the stimulus but also to emulate a retinal response (see Sec. 3.3.2).

• The image time stamps, i.e., the precise time at which each image was shown, allowing to

perform Spike-Triggered-Average (STA) [8].

3.2 Analysis

3.2.1 Classical analysis

Once the spikes are available (simulated or imported), diﬀerent analysis can be performed start-
ing with basic visualizations and classical analysis such as peri-stimulus histogram, interspike
interval, and cross-correlation (see Fig. 2 and Example 1). The number of neurons used for the
analysis can be of several thousands, although the user can select subsets of neurons according to
diﬀerent criteria, e.g., individual activity or receptive ﬁeld localization (if applicable, i.e., if data
allows to compute receptive ﬁelds). Even for a large population of neurons (about 4000 neu-
rons), on any modern computer, the computational time of most of the functions in the classical
analysis is neglectable.

Example 1 How to obtain the peri-stimulus time histogram (PSTH) on a selection
of neurons having the highest spike rates?

1. FP Data>Spikes>Open

2. PP Browse and select the ﬁle of spikes.

3. RP (Optional) In the sub-panel showing the list of neurons, click on Spike rate to
sort neurons with respect to their averaged spike rate, select the set of neurons with
higher spike rate and click on Keep selected.

4. FP Analysis>Peri-stimulus time histogram.

5. PP Choose the bin size (time step) in milliseconds and click on Compute.

3.2.2 Population analysis

With the current evolution of Multi-Electrode Array (MEA) recordings devices, it is possible to
record simultaneously thousands of neurons [15]. This opens up the possibility of analysing the
collective neuronal population activity, namely its spatio-temporal correlations. Characterizing
spatio-temporal statistics is a fundamental step toward extracting general population coding
principles in neuronal networks. For example, it has been observed in several vertebrate species
that, even if the pairwise correlations of retinal ganglion cell are weak, they are necessary to
explain the statistics of spikes [19, 22, 53, 54, 62].

Analysing spatio-temporal correlations is, however, a notoriously hard problem from a sta-
tistical perspective. The point is not only to measure pairwise or higher order correlations
but also to address adequately the question of their signiﬁcance in neuronal coding taking into
account constraints such as limited statistical sample, the reliability of statistical tests, the hy-
potheses underlying mathematical models and risks of overﬁtting [51, 52]. One possible way
of solving this problem is to use Gibbs distributions. Initially introduced in statistical physics
by Boltzmann and Gibbs [28] but currently used in a broader context, this general class of
probability distributions, constitutes a canonical paradigm to explain the spike statistics repro-
ducing as close as possible empirical correlations, without adding additional unnecessary assump-
tions [53, 54, 32, 61, 16, 17, 62, 61]. This method has been used to study pairwise correlations
(see [68, 42, 40] as well as more general spatio-temporal correlations [7, 67, 9, 42, 10, 24, 48, 25].

RR n° 8958

8

Cessac & others

Figure 2: Example of classical analysis for a spike train shown in sub-panel (a). The following
estimations are shown: (b) Inter-spike interval (ISI), (c) Peri-stimulus time histogram (PSTH)
and (d) cross-correlogram. Data from electrode array recording of a mouse retina in response to
a moving pattern.

PRANAS provides a toolbox to compute a Gibbs distribution from the neuronal data i.e., to
estimate a probability distribution, reproducing as close as possible empirical space- and time-
statistics of a raster, without adding additional unnecessary assumptions (maximizing entropy)2.
In the current version, the population analysis toolbox of PRANAS focuses on stationary distri-
butions, i.e., the statistics are invariant under time-translation. We give ﬁrst a brief explanation
of Gibbs distribution before explaining how to use PRANAS (see [67, 42, 40] for more details).
Below, rasters are denoted by ω. We assume that time has been discretized with some time
bin.The state of neuron i at time t is denoted by ωi(t) ∈ {0, 1}. We note by ω(t) the vector
ωi(t) (it tells us the spiking state of neurons at time t). Therefore, a raster ω is mathematically
a matrix with N lines (number of neurons) and T columns (time bins in the raster). Obviously,
it is not stored this way in memory (we do not store 0s). A Gibbs distribution is a probability
measure µ deﬁned by a function E (also called "energy"). The probability of observing a raster ω
of time length T , µ [ ω ] is proportional to eE(ω) where E(ω) = (cid:80)T
t=1 φ(ω(t)). In the following φ is
called "potential". A paradigmatic example of Gibbs distribution appears in the Ising 3 model.
Here φ(ω(t)) = (cid:80)
i,j Jijωi(t)ωj(t) where the sums hold on neurons indices. The
terms bi, Jij are parameters tuning the probability whereas the terms ωi(t), ωi(t)ωj(t) depend
on the spike conﬁguration and are called "interactions" (self-interaction for the term ωi(t), and

i biωi(t) + (cid:80)

2Note that this toolbox ﬁrst motivated the creation of the GUI to manipulate these complex notions. In former
publications, software was named ENAS standing for Event Neural Assembly Simulations. After fusing of ENAS
and the retina simulator VIRTUAL RETINA (see Sec. 3.3.2) into the same platform, we decided to choose a
better suited name (PRANAS) to describe the functional scope of this unique platform allowing to (i) analyse
spike trains coming from simulations or MEA recordings, at single cells or population levels, (ii) simulate retinal
spike trains from a bio-plausible model, (iii) use additional dedicated tools for retinal recordings.

3The model initially proposed by Ising and Lenz in 1920 had only nearest neighbours interactions and constant
couplings. The potential form we use corresponds in fact to a spin-glass but we use here the terminology found
in computational neuroscience papers.

Inria

Figure 2: Classical analysis(c)(b)(d)(a)PRANAS: retinal analysis and simulation

9

pairwise interactions ωi(t)ωj(t)). Here parameters bi, Jij are independent on time (stationarity
assumption) so it is suﬃcient to deﬁne the potential φ at time t = 0.

In the Ising model, there is no coupling of spikes at diﬀerent times so that the probability of
observing a raster of length T factorizes into probabilities of spike states ω(t): consecutive time
events are therefore independent. We say the statistical model has "no memory" in contrast
to the Markovian model presented now. A natural generalization of the Ising form is indeed to
deﬁne the potential φ as:

L
(cid:88)

φ(ω) =

hlml(ω)

(1)

l=0
The terms hl are parameters tuning the probability. They correspond to bi, Jij in Ising model
but they tune more general spike interactions. Again, these parameters are independent of time
(stationarity) so that we can deﬁne the potential φ starting from an initial time 0. The main
diﬀerence with Ising model is that now interactions involve spikes at diﬀerent times t1, . . . , tn.
These interactions correspond to the terms ml(ω), with the general form ωi1(t1) . . . ωin(tn), i.e.
it involves spike events occurring at diﬀerent times. As an immediate consequence, consecutive
time events are not independent anymore. One can show the Gibbs distribution is, in this case,
the invariant probability of a Markov chain. Thus, statistics involves memory and has nonvan-
ishing time correlations. For historical reasons, related to the development of our research work,
we call from now the mls "monomials" instead of "interactions". The monomials correspond
thus to the conjunction of events in the raster, varying the space and time. For instance, the
condition “neuron zero is ﬁring at time one, neuron two is ﬁring at time zero and neuron three is
ﬁring at time two” corresponds to m(ω) = ω0(1)ω2(0)ω3(2). More generally, the times tk deﬁn-
ing a monomial are chosen in the interval [0, D] where D is a positive integer characterizing the
memory depth of the Markov chain associated with the Gibbs distribution. The model range is
given by R = D + 1. The potential range is directly connected to the complexity of the algorithm
analyzing data, as the higher the range the higher the computational time and memory load.
Gibbs distributions satisfy a variational principle: maximizing the statistical entropy under the
constraints that the average value of each monomial, µ [ ml ] has a ﬁxed value. Gibbs distribu-
tions are thus also called Maximum Entropy (MaxEnt) distributions. In our case, this value is
equal to average empirical value π [ ml ] computed from an experimental raster. In other words,
here is what our algorithm does: given an initial form of the potential φ, ﬁxed by the user (see
below), one seeks the parameters hl maximizing the statistical entropy under the constraints
µ [ ml ] = π [ ml ]. In general, it is not possible to have the strict equality µ [ ml ] = π [ ml ] so one
tries to approach it at best. Equivalently, we minimize the Kullback-Leibler divergence between
µ, the "model" and π the empirical measure ("data").
In the ideal case of a raster inﬁnite
in time, this is a convex problem, and therefore there is a unique solution. For the realistic
case, the input raster is ﬁnite, and several solutions can solve the problem [6]. The algorithm
starts from an initial guess of the hls and computes the corresponding averages µ(ml) using a
Monte Carlo method. From this, it computes a variation of the hls giving, if possible, a lower
Kullback-Leibler divergence (see [40] for details). We proceed this way until no improvement in
the Kullback-Leibler divergence is observed any more. At this point, modifying some parameters
(see next paragraph) can nevertheless still improve the minimization.

Let us now describe how to compute Gibbs distributions with PRANAS. There are many
(an exponential number) a priori possible potentials. In PRANAS we propose four predeﬁned
potentials although the user can also deﬁne his own one. The options are the following. Here we
characterize the potential by the list of monomials M which compose it.

• Bernoulli model:

It takes into account individual neurons activity where all neurons

RR n° 8958

10

Cessac & others

are independent. The potential reads φ(ω) = (cid:80)N
l=1 hlωl(0) where N is the number of
neurons. Hence, monomials are of type “neuron i is ﬁring at time t” (Example: M =
{ω1(0), ω2(0), ω3(0)} for 3 neurons). This model has range 1 .

• Ising model: This paradigmatic model from statistical physics has been used in neuro-
science in several papers such as [53, 54, 63, 64]. The corresponding potential has been
introduced above. The monomials are of type “neuron i is ﬁring at time t” and “neu-
ron i and neuron j are simultaneously ﬁring at time t”. Thus events are instantaneous,
and this model does not involve memory and causality (consecutive times are indepen-
dent under µ, the Gibbs distribution). This model has range 1 (Example for 3 neurons:
M = {ω1(0), ω2(0), ω3(0), ω1(0)ω2(0), ω1(0)ω3(0), ω2(0)ω3(0)}).

• Pairwise + Triplets model: This model has been introduced by [16, 17]. In addition to
Ising terms, there are triplets of interactions (e.g. ω1(0)ω2(0)ω3(0)). This model too has
range 1.

• Pairwise model. This is an extension of Ising model where monomials are of type “neuron
i is ﬁring at time t” (single events) and “neuron i is ﬁring at time t and neuron j is
ﬁring at time t + k”, 0 ≤ k ≤ D (pairwise events). This model integrates memory and
causality via time dependent pairwise interactions. (Example with range 2 and 2 neurons:
M = {ω1(0), ω2(0), ω1(0)ω2(0), ω1(0)ω1(1), ω2(0)ω2(1), ω1(0)ω2(1), ω1(1)ω2(0)}).

• User. Here the user deﬁnes his own potential (Example M = {ω1(0), ω2(0), ω3(0)

ω1(0)ω2(1)ω3(2), . . . }).

Example 2 How to calculate the Gibbs distribution of a spike train?

1. FP Data>Spikes>Open
2. PP Browse and select the ﬁle of spikes.
3. RP (Optional) In the sub-panel showing the list of neurons, select a subset of

neurons and click on Keep selected.
4. FP Analysis>Population analysis.
5. PP Deﬁne the Potential, either from a ﬁle or by setting the type (e.g., pairwise)
and the range4 (e.g., R=3). Set the Maximal pattern length. For example, if
you select 2, the program will seek in the data all spike events occurring within
2 successive time steps, and compare the probability of these events, predicted
by the model, to the empirical probabilities. In Simulation, choose what you
want to compute. Possible choices are:

(i) Potential: Fits the coeﬃcients of the potential.
(ii) Kullback-Leibler divergence: an estimation of Kullback-Leibler diver-
gence derived from the entropy estimation in [58] and the classical relations
between K-L divergence, µ average of φ and entropy [6].

(iii) Pattern probabilities: The conﬁdence plot.

6. FP Analysis>Population analysis>Parametric potential

4The product N ×R somewhat deﬁnes the complexity of the model. The larger N ×R the longer the simulation
and the memory load. We have been able to run up to N = 100, R = 2 in reasonable times. Note however that the
statistical estimation of a so-huge number of neurons raises the classical problems (not inherent to our method)
of statistical estimation on a sample, which, e.g. for the retina rarely exceeds a few millions of spikes.

Inria

PRANAS: retinal analysis and simulation

11

7. PP Choose Initial coefficients: possible choices are Current (in the case
when you have made a run before and you want to keep hls) or 0. For the
ﬁrst run you can choose both as the initial parameters are anyway set to 0 (this
corresponds to start from a Bernoulli models where spikes are independent with
). Set parameters of the Monte Carlo method to
probability of occurrence 1
2
speed up the process (see text for the role of each parameter).

8. FP Population analysis
9. RP Compute to do the estimation. The red bar at the bottom indicates that

computation is in progress.

Note that in PRANAS the user can ﬁne-tune the probability estimation and speed up the
computation in the ﬁrst steps of the Monte Carlo method by acting on the following parameters
(in FP Analysis>Population analysis>Parametric potential):

• Convergence bound: The lower bound of error you require. Simulations stops when the

code reaches this value.

• Tolerance Coefficient: Allows to ﬁlter monomials to compute hls. For example, if
the event ml appears only, say 3 times in the raster you may consider that it is not
signiﬁcant and must be eliminated from the potential (1). In this case you set Tolerance
Coefficient to 3.

• Raster length: The length of the Monte Carlo raster used to compute the average of
monomials for the current values of hls. This number must increase as you get closer to
the solution (typically when you do not get any improvement in the error).

• Spike flips coefficients: This deﬁnes the number of ﬂips per neuron and per iteration

in Monte Carlo methods [40].

• Delta: If the distance between predicted and empirical distribution is smaller than Delta
the Monte Carlo raster is not recomputed.
Instead, the average value of monomials is
computed via linear response [40]. The number must be decreased as you get closer to the
solution (typically when you do not get any improvement in the error).

• Number of parallel iterations: We use two kinds of updating, based upon [14]: paral-
lel or sequential. Parallel update sets all hls in one step. Number of parallel iterations
tells how many parallel updating of hls are done before the program stops (and e.g. plots
the conﬁdence plot, when selected).

• Number of sequential iterations: Sequential update. It computes only one hl at each

step. It is better to use it at the end of the computation, to ﬁne-tune coeﬃcients.

Figure 3 shows diﬀerent visualizations of the results. In (a), we show a graphical view of the
potential’s coeﬃcients. In (b), we show the literal form of the potential φ(ω). In this example,
it is

φ(ω) = − 0.860273 w1(2) − 0.715493 w2(2) + · · · − 0.280176 w0(2)w2(2)

(2)

+ · · · − 0.120281 w0(2)w3(2)w5(3) + . . . ,

where, e.g., w0(2)w2(2) corresponds to the event "neuron zero and neuron two are ﬁring at time
two whereas −0.280176 is the corresponding coeﬃcient hl of this term in the potential. In (c), we
show a plot of monomials average value, with empirical average on the abscissa and theoretical

RR n° 8958

12

Cessac & others

average (predicted by µ) on the ordinate. In (d), we show the evolution of the Hellinger5 distance
between the model predictions and empirical data, versus the number of iterations. Hellinger
distance is natural here as it relies directly on the estimation of the average value of monomials.
It provides a quantitative measure of the goodness of ﬁt. Finally, in (e) we show a conﬁdence plot.
This ﬁgure consists of plotting, in log scale, on the abscissa the empirical probability of observed
spike blocks and on the ordinate the expected probability of those blocks for the model µ. If the
matching were perfect one would have all points aligning on the diagonal. This perfect matching
is only possible, however, if the input spike train were inﬁnite. For ﬁnite spike trains ﬂuctuations
about the exact probability are observed, ruled by Central Limit Theorem. Namely, ﬂuctuations
, T
are Gaussian with a variance σl, depending on the monomial l and proportional to
being the raster length (number of time bins). Around the diagonal are drawn error bounds
corresponding to 3σl, where σ is an estimated empirically. These bounds deﬁne a conﬁdence
region:
if the Gibbs distribution is a perfect estimation of the input raster then points in the
conﬁdence plot are distributed inside the conﬁdence region with a probability of 99.7% of the
expected averages. The conﬁdence plot provides a qualitative measure of the goodness of the ﬁt.
Reducing the computation time has been a primary concern for us during the development
phase. In fact, the most time-consuming routine of PRANAS is for inferring the Gibbs Potential.
To face this problem, we introduced a new algorithm based on Monte Carlo sampling [42]. For a
large number of neurons, the Monte Carlo-based algorithm oﬀers better computation time than
the algorithm proposed in [67]. With a cluster of 64 cores of 2.4GHz speed, PRANAS needs the
following amount of time to compute a target distribution (1 iteration): 5 min. for 20 neurons
with a pairwise model R = 2, 10 minutes for 40 neurons with an Ising model. To infer the
Gibbs Distribution, one needs 100-200 iterations on the hl estimation. For more details on the
scalability of this method see [42].

1√
T

3.2.3 Receptive ﬁelds estimation

Beyond tools to analyse spike trains at the single cell and population levels, PRANAS provides
speciﬁc instruments in the case when spike trains come from evoked activity of neurons from the
retina. The user can upload MEA characteristics, the sequences of images of the stimulus and
the time stamps. Given this information, PRANAS provides a method to estimate the neuron’s
receptive ﬁelds. The method available in version 1.0.0 is Spike Triggered Average (STA) [8].
The STA can be computed for a single neuron, a subset of neurons or the entire population.
Example 3 describes the general procedure.

Example 3 How to estimate receptive ﬁelds with STA method?6

1. FP Data>Spikes>Open
2. PP Browse and select the ﬁle of spikes. Note that the user can select a subset

of neurons as in Example 1.

3. FP Data>Multi-Electrode Array>Settings
4. PP Deﬁne the MEA conﬁguration, so that, if neurons have a position relative

to the array, the spike activity can be displayed at the correct location.

5The Hellinger distance between the empirical probability π and the Gibbs probability µ is d(π, µ) =
(cid:114)

1√
2

(cid:80)L

l=1

(cid:16) (cid:112)π(ml) − (cid:112)µ(ml)

(cid:17)2

.

6To test this example, one can use sample data available on PRANAS website: recording called mouse-
P39\_17\_06\_14 (We are indebted to Evelyne Sernagor and Gerrit Hilgen, Newcastle University, who provided us
these data and authorized us to use them as a basis for examples.)

Inria

PRANAS: retinal analysis and simulation

13

Figure 3: Population analysis view with N = 10, R = 2. (a) Graphic view of the potential’s
coeﬃcients values; the abscissa corresponds to an index associated to a prescribed order on
monomials: the N ﬁrst coeﬃcients corresponds to single events (hence are related to ﬁring rate);
by clicking on the histogram bar one makes appear the coeﬃcient value and the corresponding
monomial. Ordinate give the value of the coeﬃcient attached to the corresponding monomial.
(b) Literal form of the potential. (c) Theoretical average value of monomials versus their empir-
ical average value. To which extents the model predicts the empirical data is drawn with this
representation. This allows checking that constraints on empirical averages are respected by the
model. (d) Decay of estimation errors versus the number of iterations allowing us to graphically
check the convergence of the estimation algorithm (red curve). In the ﬁgure several successive
runs have been performed. The blue curve shows the evolution of error after each of these trials.
(e) Conﬁdence plot. Cp, Cm corresponds respectively to the upper and lower 3σ bound associated
with Central Limit Theorem (see text).

5. RP Stimulus view shows the activity of individual neurons w.r.t. MEA array.
The user may choose a region of interest to select a subset of neurons. Note
that if you have a TEXT ﬁle for spikes, no position is available, and we chose
to arrange neurons following their order, by rows and columns.

6. FP Data>Stimulus>Open
7. PP Browse to choose the directory containing the sequence of white noise im-
ages. Note that all images should be in this directory and ordered by name. All
standard formats are accepted (e.g., PNG, JPG, TIFF).

8. FP Data>Stimulus>Time stamps: Time stamps of the exact oﬀset of each

image during the experiment.

9. PP Browse and select the ﬁle. Time stamps can be imported from a .txt (row

n contains the starting time of image n) or HDF5 [70].
10. FP Analysis>Receptive fields>Compute via STA

RR n° 8958

Figure 3: Population(a)(e)(b)(d)(c)CpCm14

Cessac & others

Figure 4: Receptive ﬁeld estimation using the STA approach. (a) White noise image sequence
with spiking activity superimposed as red dots. (b) 3D volume visualization of the receptive ﬁeld
of one neuron. (c) Temporal slices of the receptive ﬁeld (RF (·, ·, z)). Slices are in increasing time
order from top to bottom and left to right. Time period between two slices is 33ms. (d) Temporal
proﬁle passing through the peak activity location of the spatio-temporal volume (RF (xM , yM , ·)
where (xM , yM , zM ) = argmaxx,y,zRF (x, y, z).

11. RP Output directory: Choose the directory where the receptive ﬁelds will
be saved, as a sequence of PNG ﬁles and in HDF5 format. Choose the num-
ber of images to be averaged before each spike with Time depth (number of
slices). Then click on Compute.

12. FP Analysis>Receptive fields>Display allows four types of visualization.

13. RP The user can display the receptive ﬁeld of interest by selecting the neuron

in Receptive Fields subpanel and Update views.

A receptive ﬁeld is stored in a regular grid in a three-dimensional space. Each voxel in
that grid, denoted by RF (x, y, z), stores the value of the receptive ﬁeld at each spatial position
(x × sd, y × sd) and temporal depth z × td, where sd and td denote respectively the spatial
and temporal resolutions. The temporal resolution is estimated from the time stamps ﬁle as
the average diﬀerence between two successive time stamps. The number of time slices of the
receptive ﬁeld, nf , is a user-deﬁned parameter. The ﬁrst spatial slice (x, y, z = 0) corresponds
to the average spike triggered stimuli at time −(nf − 1)td before the spike, the second slice
(x, y, z = 1) corresponds to the average spike triggered stimuli at time −(nf − 2) × td before
the spikes and so on. In PRANAS we propose several displays of that volume (2D and 3D), as
illustrated in Fig. 4.

The time spent on the estimation of receptive ﬁelds depends on the parameters. For example,
on a computer equipped with a Intel Core i7@2.8GHz and 32 GB of memory it takes about two
minutes to estimate the receptive ﬁelds of 4000 neurons with 64x64x12 voxels each.

Inria

Figure 4: RF(a)(c)(b)(d)PRANAS: retinal analysis and simulation

15

3.3 Simulation of spike trains

3.3.1 Simulation of spike trains from statistics

PRANAS gives the possibility to generate spike trains from Gibbs distributions. This can
be useful if, for example, one wants to generate spike trains with prescribed spatio-temporal
correlations so as to test a statistical method of analysis. There are two diﬀerent ways:

1. FP Simulation>ComputeSpikes>GibbsRaster>current:

population analysis (see Sec. 3.2.2).

if distribution comes from a

2. FP Simulation>ComputeSpikes>GibbsRaster>File: if distribution has been deﬁned by

the user and stored in a ﬁle containing the Gibbs potential form.

A Gibbs probability distribution (deﬁned by Gibbs potential of the form (1)) is naturally
associated with a Markov chain, with memory D = R − 1, whose transition probabilities can
be computed from the potential φ [68, 6, 10]. The invariant distribution µ of this chain is the
Gibbs distribution associated to φ. Therefore, given a potential of the form (1) it is easy to
generate a sample raster distributed according to µ using Monte Carlo method [42]. PRANAS
aﬀords this functionality allowing to generate rasters with spatio-temporal correlations tuned by
the parameters hl in φ.

3.3.2 Simulation of spike trains from a retina simulator

Another strength of PRANAS is to provide a way to generate spike trains that mimic retina’s
outputs. To do so, PRANAS has integrated and extended the VIRTUAL RETINA simulator
[69] formerly developed in our team.7

In a nutshell, VIRTUAL RETINA is a software to perform large-scale simulations of
biologically-plausible retinas. Given a retina conﬁguration which can be fully customized and an
input video as visual stimulus, VIRTUAL RETINA simulates the spiking output for diﬀerent
cell types. VIRTUAL RETINA has been shown to reproduce a broad range of experimental
data at single cell level, from salamander, cat and primate retinas, and has been used in several
theoretical studies [36, 37, 39, 1, 11, 12, 66]. The underlying model includes a non-separable
spatio-temporal linear model of ﬁltering in the Outer Plexiform Layer, a shunting feedback at
the level of bipolar cells, and a spike generation process using a network generalization of the
noisy leaky integrate-and-ﬁre neurons to model Ganglion Cells (GCells). Note that VIRTUAL
RETINA was designed to be used via a command line (there was no GUI available).

By integrating VIRTUAL RETINA software into PRANAS platform, we allowed this
simulation software to be used through a GUI. We also extended VIRTUAL RETINA with the
aim to reproduce statistically coherent responses at a population level. Indeed, outputs of the
initial VIRTUAL RETINA version were successfully compared to experimental data at single
cell level but could not reproduce collective statistics at a population level. This is because GCells
in the early version were not connected. They were modelled by independent leaky-integrate and
ﬁre neurons receiving their input from bipolar cells, but with no lateral connectivity (due to
amacrine cells - ACells - in the retina). As a consequence correlations in GCells spikes were only
due to statistics of the stimulus and overlapping receptive ﬁelds.

In the new version of the retina simulator embedded in PRANAS, GCells are connected
laterally so as to explore the eﬀects of connectivity on retinal responses to stimuli. More precisely,
the IPL is now composed of discrete time leaky-integrate and ﬁre neurons introduced in [55] and

7VIRTUAL RETINA website: http://virtualretina.inria.fr. VIRTUAL RETINA is under Inria CeCILL-C

license, IDDN.FR.001.210034.000.S.P.2007.000.31235.

RR n° 8958

16

Cessac & others

studied mathematically in [4, 5]. We have chosen this model because of its simplicity, fast
response, and the fact that its collective dynamics are well known.
In a nutshell, the model
comes from the time discretization of the leaky-integrate and ﬁre model whose sub-threshold
dynamics reads:

C

dV
dt

= −gL(V − VL) + I(t) + σBB(t),

(3)

for V < θ, where θ is the ﬁring threshold. Here C is the membrane capacity, gL the leak
conductance, VL is the leak reversal potential, B(t) is a Gaussian noise (mean zero and variance
1) and σB controls the amplitude of this noise. Finally, I(t) is an external current. In our case,
this is the bipolar current coming from the OPL (see [69] for details).

Let τL = C
gL

be the leak characteristic time. We consider now a time discretization with a
(cid:16)

time step dt (here it is ﬁxed, dt = 1ms) and we set γ =
. Note that dt has to be quite
smaller than τL to have a reasonable description of the biophysics. Therefore γ ∈ [0, 1[. Then,
the full dynamics (below and above threshold) of the membrane potential Vi of neuron i is given
by:

1 − dt
τL

(cid:17)

where Z is the binary spike label:

Vi(t + 1) = γVi(t)(1 − Zi) +

Ii(t)
C

+

σB
C

B(t),

Zi =

(cid:40)

if Vi ≥ θ;
1,
0, otherwise.

Thus Zi is 1 whenever neuron i spikes. Here 1 − Zi models the reset. In this equation, neurons
are not coupled. We add then a connectivity through synaptic weights Wij where neuron j (pre
synaptic) acts on neuron i (post synaptic) upon spiking. We have now:

Vi(t + 1) = γVi(t)(1 − Zi) +

Ii(t)
C

+

1
C

N
(cid:88)

j=1

WijZj +

σB
C

B(t).

(4)

For a complete description see [4, 5]. Clearly, this modelling of lateral connectivity, although usual
in the ﬁeld of neural networks models, is rough when compared to the real lateral connectivity in
the IPL involving amacrine cells having a complex dynamics. Elaborating more realistic coupling
is under current investigations.

The simulator allows to tune the parameters leak (γ ∈ [0, 1]); neuronal noise (σB > 0);
membrane capacity (C); threshold (θ) and the connectivity matrix (W ). The connectivity be-
tween neurons is set through the connectivity matrix. One can simulate independent neurons
by choosing none or connected neurons using sparse or dense schemes. One can also upload a
predeﬁned connectivity matrix oﬀering the possibility to explore its impact on spike statistics.
For example, we provide on the website an example of ACells-like connectivity pattern.

Example 4 shows how to generate spikes using PRANAS and Fig. 5 illustrates an example
of simulation. Note that user can ﬁnd online retina conﬁguration ﬁles and videos sequences to
test the simulator.

Example 4 Running the retina simulator.8

1. FP Data>Stimulus>Open

8To run this example one can use data available on PRANAS website, for example the martin-walk image
sequence and the cat\_X\_cell\_DLIF.xml retina conﬁguration ﬁle which corresponds to the result shown in Fig. 5.

Inria

PRANAS: retinal analysis and simulation

17

Figure 5: Spike generation from our retina simulator. (a) Input image sequence with spiking
activity super-imposed (white blobs). (b) Connectivity matrix chosen for the simulation, here
random. (c) Simulated spike train.

2. PP Browse to choose the directory containing the sequence.

3. RP Stimulus sequences subpanel: The sequence of images is loaded with a
default display duration of 100ms per image (Display time column). This value
can be manually set or deﬁned from time stamps ﬁle (see Example 3).

4. FP Simulation>Virtual Retina>Retinal configuration>Open9

5. PP Browse and select the XML ﬁles containing the parameters of the retina.

6. FP Simulation>Virtual Retina>Retinal configuration>Customize: Once

loaded, the user can still change parameters of the retina.

7. FP Simulation>Virtual Retina>Compute spike.

8. PP Compute to get the spikes.

The time spent in the generation of spikes with the retina simulator depends on the param-
eters. For example it takes about six minutes to generate the spikes corresponding to Fig. 5
on a laptop equipped with a Intel Core i7-6820HK CPU@2.70GHz. This was obtained with the
image sequence martin-walk (200×200 pixels, 41 frames) and the cat\_X\_cell\_DLIF.xml retina
conﬁguration ﬁle (100 neurons, sparse connectivity with 1000 connections out of 10000 possible
connections).

9Note that steps 4–6 can be skipped and one can directly generate spikes in step 7 using a proposed default

conﬁguration.

RR n° 8958

Figure 5:(a)(c)(b)18

4 Conclusion

Cessac & others

In this paper we have introduced PRANAS, a new free10 platform for retinal analysis and
simulation. PRANAS provides a retina simulator allowing to transform any video into spike
trains, together with sophisticated methods to analyse spike trains, coming from simulations but
also experiments. As explained, PRANAS (version 1.0.0) includes a range of original methods
from the state-of-the-art [6, 69] which are now available to the neuroscience community. More
precisely, PRANAS intends to be useful for the neuroscience community in a large sense, i.e.,
not only experienced computational neuroscientists. To do so, we decided to make all methods
implemented therein accessible through a friendly GUI. No scripting is needed to run analysis and
simulation methods. This represents a major advantage to promote interdisciplinary neuroscience
and we believe that PRANAS helps in this direction.

However, we are certainly aware that this advantage could also be seen as a limitation of
the software. Indeed, inability to script analyses could be a limitation that can make systematic
analysis of large datasets tedious and error prone. It makes also diﬃcult to link the functionalities
of this toolbox to more extensive data analysis workﬂow. For thoses reasons, we also oﬀer some
functionalities that run on the command line. A non-exhaustive list of tools that can be used
from the command line is SimulateRetina (simulate retinal response), Correlations (compute
the average cross-correlations of a given raster), SpikeTriggerAverage (compute the average
spike triggered stimuli.11 We expect to have the platform fully available with scripting in a
forthcoming version.

In this ﬁrst release of PRANAS, we have focused on the following aspects:

• The user experience: We optimized the ergonomics of interactions between the user and

the interface. No scripting is needed to analyse or generate the spike trains.

• The richness of toolboxes: We developed a variety of methods ranging from classical tools
to population analysis, including a method for receptive ﬁelds estimation. In addition, we
provide two simulators, one inspired in the retina, the other from rasters statistics analysis.

• The computational performance: We parallelized a selection of functions to make possible

to handle faster large populations of neurons12.

By putting together functions related to retina simulation and analysis, PRANAS intends
to be an original platform that will encourage joint modeling and experimental studies. The
synergy between these two areas of functionality will be in particular useful to deﬁne better
retina simulators by confronting simulated output w.r.t. real cell recordings. A typical use case
is to start from a real cell recording of a retina, to analyse its receptive ﬁeld structure, and use
that information to deﬁne the XML retina conﬁguration ﬁle so to deﬁne a virtual retina having
similar characteristics as the real one. Another use case that we target is to start again from
a real cell recording of a retina, analyse spike train statistics and compare them with the ones
given by the simulator. Such a comparison is very informative and will suggest improvements of
the retina simulator to increase its biological plausibility.

10PRANAS is under Inria CeCILL-C license, IDDN.FR.OO1.190004.000.S.P.2014.000.31235. Binaries can be

freely downloaded.

11These commands can be found in the directory pranas/bin. Help of each tool is given with the command

line: toolName -h.

12Parallelization concerns every loop in our C++ code where iterations can be computed independently. To do
so, we used OpenMP so that PRANAS parallel processes can run on a personal computer equipped with multi-
core processors. More precisely, four functions were parallelized: (i) the loading of rasters for all ﬁle formats, (ii)
the statistical analysis functions to generate potentials, compute divergence and estimate patterns probabilities,
(iii) the estimation of receptive ﬁelds and (iv) the retina simulator.

Inria

PRANAS: retinal analysis and simulation

19

Here, we presented its main features, and we refer the interested reader to its website13 for
downloads and more information (see, e.g., tutorials to get started). We hope that PRANAS
becomes a useful tool for neuroscientists to analyse spike trains and we expect to improve it thanks
to the users’ feedback. Our goal is to progressively enrich PRANAS with the latest research
results, to facilitate the transfer of new methods to the community. Future work will focus
on improving several existing functions regarding eﬃciency in time and memory consumptions.
We will include methods for population analysis in the non-stationary case as well as other
statistical analysis models. We are working on better methods for receptive ﬁelds estimation [13].
We are also developing extensions of the retina simulator model so that it could serve as a
satisfactory model at a population level. Finally, as a general objective, we also plan to improve
the computational power of PRANAS in order to handle even larger networks.

Funding

This work was supported by KEOPS ANR-CONICYT, the EC IP project FP7-ICT-2011-9 no.
600847 (RENVISION) and FP7-IDEAS-ERC no. 227747 (NERVI), the French ministry of Re-
search and University of Nice (EDSTIC), INRIA ADT and by the ECOS-Sud program (grant
C13E06).

Acknowledgements

We warmly acknowledge Michael J. Berry, Maria-Jose Escobar, Matthias Hennig, Ruben Herzog,
Gerrit Hilgen, Evgenia Kartsaki, Gaia Lombardi, Olivier Marre, Thierry Mora, Adrian Palacios,
Cesar Ravello, Horacio Rostro, Vivien Robinet, Selma Souihel, Evelyne Sernagor, Gasper Tkacik,
Juan-Carlos Vasquez for their help in designing PRANAS. The authors also thank the reviewers
for their constructive criticisms and valuable comments which helped us improve the manuscript.

References

[1] G. Basalyga, M. A. Montemurro, and T. Wennekers.

Information coding in a laminar
computational model of cat primary visual cortex. J. Comput. Neurosci., 34:273–83, 2013.

[2] A. Benoit, A. Caplier, B. Durette, and J. Herault. Using human visual system modeling
for bio-inspired low level image processing. Computer Vision and Image Understanding,
114(7):758–773, 2010.

[3] M. Carandini, J. B. Demb, V. Mante, D. J. Tollhurst, Y. Dan, B. A. Olshausen, J. L.
Journal of

Gallant, and N. C. Rust. Do we know what the early visual system does?
Neuroscience, 25(46):10577–10597, Nov. 2005.

[4] B. Cessac. A discrete time neural network model with spiking neurons. rigorous results on

the spontaneous dynamics. J. Math. Biol., 56:311–345, 2008.

[5] B. Cessac. A discrete time neural network model with spiking neurons II. dynamics with

noise. J. Math. Biol., 62:863–900, 2011.

13PRANAS website: http://pranas.inria.fr

RR n° 8958

20

Cessac & others

[6] B. Cessac and A. Palacios. Spike train statistics from empirical facts to theory: the case
of the retina. In F. Cazals and P. Kornprobst, editors, Modeling in Computational Biology
and Biomedicine: A Multidisciplinary Endeavor, Lectures Notes in Mathematical and Com-
putational Biology (LNMCB), pages 261–302. Springer-Verlag, Berlin, Heidelberg, 2012.

[7] B. Cessac, H. Rostro-Gonzalez, J.-C. Vasquez, and T. Viéville. How gibbs distribution may
naturally arise from synaptic adaptation mechanisms: a model based argumentation. J.
Stat. Phys, 136(3):565–602, August 2009.

[8] E. J. Chichilnisky. A simple white noise analysis of neuronal light responses. Network

(Bristol, England), 12:199–213, 2001.

[9] R. Cofré and B. Cessac. Dynamics and spike trains statistics in conductance-based integrate-
and-ﬁre neural networks with chemical and electric synapses. Chaos, Solitons & Fractals,
2013.

[10] R. Cofre and B. Cessac. Exact computation of the maximum-entropy potential of spiking

neural-network models. Phys. Rev. E, 89(052117), 2014.

[11] E. Doutsi, L. Fillatre, M. Antonini, and J. Gaulmin. Retinal-inspired ﬁltering for dynamic
image coding. In IEEE International Conference on Image Processing (ICIP), pages 3505–
3509, Quebec city, Canada, 2015.

[12] E. Doutsi, L. Fillatre, M. Antonini, and J. Gaulmin. Video analysis and synthesis based
on a retinal-inspired frame. In 23rd European Signal Processing Conference (EUSIPCO),
pages 2226–2230, Nice, France, 2015. IEEE.

[13] A. Drogoul, G. Aubert, B. Cessac, and P. Kornprobst. A new nonconvex variational ap-
In 6th International Workshop on

proach for sensory neurons receptive ﬁeld estimation.
New Computational Methods for Inverse Problems (NCMIP), Cachan, France, 2016.

[14] M. Dudík, S. J. Phillips, and R. E. Schapire. Performance Guarantees for Regularized
Maximum Entropy Density Estimation, page 472–486. Springer Berlin Heidelberg, Berlin,
Heidelberg, 2004.

[15] E. Ferrea, A. Maccione, L. Medrihan, T. Nieus, D. Ghezzi, P. Baldelli, F. Benfenati, and
L. Berdondini. Large-scale, high-resolution electrophysiological imaging of ﬁeld potentials
in brain slices with microelectronic multielectrode arrays. Front. Neural Circuits, 6(Novem-
ber):80, 2012.

[16] E. Ganmor, R. Segev, and E. Schneidman. The architecture of functional interaction net-

works in the retina. The journal of neuroscience, 31(8):3044–3054, 2011.

[17] E. Ganmor, R. Segev, and E. Schneidman. Sparse low-order interaction network underlies
a highly correlated and learnable neural population code. PNAS, 108(23):9679–9684, 2011.

[18] S. Garcia and N. Fourcaud-Trocmé. Openelectrophy: an electrophysiological data-and

analysis-sharing framework. Frontiers in neuroinformatics, 3, 2009.

[19] K. S. Ginsburg, J. A. Johnsen, and L. Michael W. Common noise in the ﬁring of neighbouring

ganglion cells in goldﬁsh retina. J. Physiol., 351:433–450, 1984.

[20] D. H. Goldberg, J. D. Victor, E. P. Gardner, and D. Gardner. Spike train analysis
toolkit: enabling wider application of information-theoretic techniques to neurophysiology.
Neuroinformatics, 7(3):165–178, 2009.

Inria

PRANAS: retinal analysis and simulation

21

[21] T. Gollisch and M. Meister. Eye smarter than scientists believed: neural computations in

circuits of the retina. Neuron, 65(2):150–164, Jan. 2010.

[22] M. Greschner, J. Shlens, C. Bakolitsa, G. D. Field, J. L. Gauthier, L. H. Jepson, A. Sher,
A. M. Litke, and E. J. Chichilnisky. Correlated ﬁring among major ganglion cell types in
primate retina. J. Physiol., 589(Pt 1):75–86, Jan. 2011.

[23] J. Hérault. Vision: Images, Signals and Neural Networks Models of Neural Processing in
Visual Perception. World Scientiﬁc Publishing Co., Inc., River Edge, NJ, USA, 2010.

[24] R. Herzog, J. Araya, M. Pizarro, B. Cessac, C. Ravello, M.-J. Escobar, and A. Palacios. From
Habitat to Retina: Neural Population Coding using Natural Movies. Bernstein Conference,
Sept. 2015.

[25] R. Herzog, M. J. Escobar, B. Cessac, and A. Palacios. Dimensionality reduction on maximum

entropy models on spiking networks. Plos. Comp. Bio. (submitted), 2017.

[26] C. Hillar and F. Eﬀenberger. Robust discovery of temporal structure in multi-neuron record-

ings using hopﬁeld networks. Procedia Computer Science, 53(L50):365–374, 2015.

[27] R. A. Ince, A. Mazzoni, R. S. Petersen, and S. Panzeri. Open source tools for the information

theoretic analysis of neural data. Frontiers in neuroscience, 4, 2010.

[28] E. Jaynes. Information theory and statistical mechanics. Phys. Rev., 106:620, 1957.

[29] J. S. Kim, M. J. Greene, A. Zlateski, K. Lee, M. Richardson, S. C. Turaga, M. Purcaro,
M. Balkam, A. Robinson, B. F. Behabadi, M. Campos, W. Denk, H. S. Seung, and Eye-
Wirers. Space-time wiring speciﬁcity supports direction selectivity in the retina. Nature,
509(331-336), 2014.

[30] M. Lidierth. sigtool: a matlab-based environment for sharing laboratory-developed software
to analyze biological signals. Journal of neuroscience methods, 178(1):188–196, 2009.

[31] H. Lorach, R. Benosman, O. Marre, S.-H. Ieng, J. A. Sahel, and S. Picaud. Artiﬁcial
retina: the multichannel processing of the mammalian retina achieved with a neuromorphic
asynchronous light acquisition device. Journal of Neural Engineering, 9(6):066004, Oct.
2012.

[32] O. Marre, S. El Boustani, Y. Frégnac, and A. Destexhe. Prediction of spatiotemporal pat-
terns of neural activity from pairwise correlations. Physical review letters, 102(13):138101–
138105, Apr. 2009.

[33] A. Martinez-Alvarez, A. Olmedo-Payá, S. Cuenca-Asensi, J. M. Ferrandez, and E. Fernan-
dez. RetinaStudio: A bioinspired framework to encode visual information. Neurocomputing,
114:45–53, Aug. 2013.

[34] R. H. Masland. Cell populations of the retina: The proctor lecture.

Investigative

Ophthalmology and Visual Science, 52(7):4581–4591, June 2011.

[35] R. H. Masland. The Neuronal Organization of the Retina. Neuron, 76(2):266–280, Oct.

2012.

[36] K. Masmoudi, M. Antonini, and P. Kornprobst. Another look at the retina as an image
scalar quantizer. In Proceedings of the International Symposium on Circuits and Systems
(ISCAS), pages 3076–3079, Paris, France, 2010.

RR n° 8958

22

Cessac & others

[37] T. Masquelier. Relative spike time coding and stdp-based orientation selectivity in the early
visual system in natural continuous and saccadic vision: a computational model. Journal of
Computational Neuroscience, 32(3):425–441, 2012.

[38] R. Meier, U. Egert, A. Aertsen, and M. P. Nawrot. {FIND}: A uniﬁed framework for neural
data analysis. Neural Networks, 21(8):1085 – 1093, 2008. Neuroinformatics Neuroinformat-
ics.

[39] A. Mohemmed, G. Lu, and N. Kasabov. Evaluating SPAN Incremental Learning for Hand-
written Digit Recognition. In International Conference on Neural Information Processing,
pages 670–677, Doha, Qatar, 2012. Springer Berlin Heidelberg.

[40] H. Nasser and B. Cessac. Parameters estimation for spatio-temporal maximum entropy

distributions: application to neural spike trains. Entropy, 16(4):2244–2277, 2014.

[41] H. Nasser, S. Kraria, and B. Cessac. Enas: a new software for neural population analysis
in large scale spiking networks.
In Twenty Second Annual Computational Neuroscience
Meeting, page 57, Paris, France, July 2013. Organization for Computational Neurosciences.

[42] H. Nasser, O. Marre, and B. Cessac. Spatio-temporal spike train analysis for large scale net-
works using the maximum entropy principle and montecarlo method. Journal of Statistical
Mechanics: Theory and Experiment, 2013(03):P03006, 2013.

[43] B. Odermatt, A. Nikolaev, and L. Lagnado. Encoding of luminance and contrast by linear

and nonlinear synapses in the retina. Neuron, 73(4):758 – 773, 2012.

[44] F. J. Pelayo, S. Romero, C. A. Morillas, A. Martinez, E. Ros, and E. Fernandez. Translating
image sequences into spike patterns for cortical neuro-stimulation. Neurocomputing, 58–
60:885–892, 2004.

[45] C. Pouzat and A. Chaﬃol. Automatic spike train analysis and report generation. an im-
plementation with r, r2html and star. Journal of neuroscience methods, 181(1):119–144,
2009.

[46] R. Pröpper and K. Obermayer. Spyke viewer: a ﬂexible and extensible platform for electro-

physiological data analysis. Frontiers in neuroinformatics, 7:26, 2013.

[47] P. Quaglio, A. Yegenoglu, E. Torre, D. M. Endres, and S. Gruen. Detection and evaluation
of spatio-temporal spike patterns in massively parallel spike train data with spade. Frontiers
in Computational Neuroscience, 11:41, 2017.

[48] C. Ravello, R. Herzog, B. Cessac, M.-J. Escobar, and A. Palacios. Spectral dimension
reduction on parametric models for spike train statistics. 12e Colloque de la Société des
Neurosciences , May 2015. Poster.

[49] F. Rieke, D. Warland, R. de Ruyter van Steveninck, and W. Bialek. Spikes, Exploring the

Neural Code. The M.I.T. Press, Cambridge, Massachusetts, USA, 1996.

[50] Y. Roudi and J. Hertz. Mean ﬁeld theory for non-equilibrium network reconstruction. Phys.

Rev. Lett., 106(048702), 2011.

[51] Y. Roudi, S. Nirenberg, and P. Latham. Pairwise maximum entropy models for studying
large biological systems: when they can work and when they can’t. PLOS Computational
Biology, 5(5), 2009.

Inria

PRANAS: retinal analysis and simulation

23

[52] Y. Roudi, J. Tyrcha, and J. A. Hertz. Ising model for neural data: Model quality and ap-
proximate methods for extracting functional connectivity. Physical Review E, page 051915,
2009.

[53] E. Schneidman, M. Berry, R. Segev, and W. Bialek. Weak pairwise correlations imply
strongly correlated network states in a neural population. Nature, 440(7087):1007–1012,
2006.

[54] J. Shlens, G. Field, J. Gauthier, M. Grivich, D. Petrusca, A. Sher, A. Litke, and
E. Chichilnisky. The structure of multi-neuron ﬁring patterns in primate retina. Journal of
Neuroscience, 26(32):8254, 2006.

[55] H. Soula, G. Beslon, and O. Mazet. Spontaneous dynamics of asymmetric random recurrent

spiking neural networks. Neural Computation, 18(1), 2006.

[56] M. Spacek, T. Blanche, and N. Swindale. Python for large-scale electrophysiology. Frontiers

in neuroinformatics, 2, 2008.

[57] I. H. Stevenson and K. P. Kording. How advances in neural recording aﬀect data analysis.

Nature Neuroscience, 14(2):139–142, Jan. 2011.

[58] S. Strong, R. Koberle, R. de Ruyter van Steveninck, and W. Bialek. Entropy and information

in neural spike trains. Phys. Rev. Let, 80(1):197–200, 1998.

[59] K. Takahashi, S. Kim, T. Coleman, K. Brown, A. Suminski, M. Best, and N. Hatsopou-
los. Large-scale spatiotemporal spike patterning consistent with wave propagation in motor
cortex. Nature Communications, 6:7169, 2015.

[60] A. Tang, D. Jackson, J. Hobbs, W. Chen, J. L. Smith, H. Patel, A. Prieto, D. Petrusca, M. I.
Grivich, A. Sher, P. Hottowy, W. Dabrowski, A. M. Litke, and J. M. Beggs. A maximum
entropy model applied to spatial and temporal correlations from cortical networks In Vitro.
The Journal of Neuroscience, 28(2):505–518, January 2008.

[61] G. Tkačik, O. Marre, T. Mora, D. Amodei, M. B. 2nd, and W. Bialek. The simplest
maximum entropy model for collective behavior in a neural network. J. Stat. Mech., 2013,
March 2013.

[62] G. Tkačik, J. S. Prentice, V. Balasubramanian, and E. Schneidman. Optimal population

coding by noisy spiking neurons. PNAS, 107(32):14419–14424, August 2010.

[63] G. Tkačik, E. Schneidman, M. Berry II, and W. Bialek. Ising models for networks of real

neurons. arXiv q-bio/0611072, 2006.

[64] G. Tkačik, E. Schneidman, M. J. Berry II, and W. Bialek. Spin glass models for a network

of real neurons. arXiv preprint arXiv:0912.5409, 2009.

[65] E. Torre, P. Quaglio, M. Denker, T. Brochier, A. Riehle, and S. Grun. Synchronous spike
patterns in macaque motor cortex during an instructed-delay reach-to-grasp task. Journal
of Neuroscience, 36:8329–8340, 2016.

[66] P. Vance, S. A. Coleman, D. Kerr, G. Das, and T. McGinnity. Modelling of a retinal ganglion
cell with simple spiking models. In IEEE International Joint Conference Neural Networks,
pages 1–8, Killarney, Ireland, 2015.

RR n° 8958

24

Cessac & others

[67] J.-C. Vasquez, B. Cessac, and T. Viéville. Entropy-based parametric estimation of spike
train statistics. In Statistical Mechanics of Learning and Inference, Mariehanm, Finland,
May 2010.

[68] J. C. Vasquez, O. Marre, A. G. Palacios, M. J. Berry, and B. Cessac. Gibbs distribution
analysis of temporal correlation structure on multicell spike trains from retina ganglion cells.
J. Physiol. Paris, 106(3–4):120–127, May 2012.

[69] A. Wohrer and P. Kornprobst. Virtual retina: a biological retina model and simulator, with

contrast gain control. Journal of Computational Neuroscience, 26(2):219–249, 2009.

[70] S. Zordan, M. Zanotto, T. Niels, S. Di Marco, H. Amin, A. Maccione, and L. Berdondini. A
scalable high performance client/server framework to manage and analyze high dimensional
datasets recorded by 4096 CMOS-MEAs. In 7th International IEEE/EMBS Conference on
Neural Engineering (NER), Montpellier, France, 2015.

Contents

1 Introduction

2 General presentation

3 PRANAS main functions

3.1 Data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3.2 Analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3.2.1 Classical analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3.2.2 Population analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3.2.3 Receptive ﬁelds estimation . . . . . . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Simulation of spike trains from statistics . . . . . . . . . . . . . . . . . . .
Simulation of spike trains from a retina simulator . . . . . . . . . . . . . .

3.3 Simulation of spike trains

3.3.1
3.3.2

4 Conclusion

3

4

6
6
7
7
7
12
15
15
15

18

Inria

RESEARCH CENTRE
SOPHIA ANTIPOLIS – MÉDITERRANÉE

2004 route des Lucioles - BP 93
06902 Sophia Antipolis Cedex

Publisher
Inria
Domaine de Voluceau - Rocquencourt
BP 105 - 78153 Le Chesnay Cedex
inria.fr

ISSN 0249-6399

