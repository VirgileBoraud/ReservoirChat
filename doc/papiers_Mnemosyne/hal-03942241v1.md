How distinct are Syntactic and Semantic
Representations in the Brain During Sentence
Comprehension?
Subba Reddy Oota, Frédéric Alexandre, Xavier Hinaut

To cite this version:

Subba Reddy Oota, Frédéric Alexandre, Xavier Hinaut. How distinct are Syntactic and Semantic
Representations in the Brain During Sentence Comprehension?. SNL 2022 - 14th Annual Meeting of
the Society for Neurobiology of Language, Oct 2022, Philadelphia, United States. 2022. ￿hal-03942241￿

HAL Id: hal-03942241

https://inria.hal.science/hal-03942241

Submitted on 16 Jan 2023

HAL is a multi-disciplinary open access
archive for the deposit and dissemination of sci-
entific research documents, whether they are pub-
lished or not. The documents may come from
teaching and research institutions in France or
abroad, or from public or private research centers.

L’archive ouverte pluridisciplinaire HAL, est
destinée au dépôt et à la diffusion de documents
scientifiques de niveau recherche, publiés ou non,
émanant des établissements d’enseignement et de
recherche français ou étrangers, des laboratoires
publics ou privés.

How distinct are Syntactic and Semantic Representations in
the Brain During Sentence Comprehension?

Subba Reddy Oota1,2,3

Frédéric Alexandre1,2,3, Xavier Hinaut1,2,3

1INRIA Bordeaux

2LaBRI, UMR 5800

3IMN, UMR 5293, Universite de Bordeaux, France

Introduction

Brain Encoding

Brain Maps (Pearson Correlation)

1 Syntactic parsing is the task of assigning a syntactic structure

to a sentence.

2 Recent works have used syntactic embeddings from

constituency trees and other word syntactic features to
understand how syntax structure is represented in the brain’s
language network.

3 However, the effectiveness of dependency parse trees or the
relative predictive power of the three syntax parsers is yet
unexplored.

Figure 1:Example of syntactic parsing for three parsers

Questions

1 Do syntactic parser representations predict similar fMRI areas?
2 Which syntactic parsing method better predicts fMRI activity?

Main Contributions

1 We explore syntactic structure embeddings obtained from three
parsers and use them in an encoding model to predict brain
responses.

2 We use a GCN model (SynGCN embeddings) for the

dependency parser that accurately encodes the global syntactic
information.

Feature Representations

1 Constituency Tree-based Embeddings
2 Dependency Tree-based Embeddings using GCN (SynGCN)
3 Incremental Top-Down Parser Embeddings
4 Basic Syntactic Features
5 BERT Features

Evaluation Metrics

1 R2 Score
2 Pearson Correlation (R)

Narrative Listening (Pieman dataset from Nastase et al. 2021)

Figure 2:Whole Brain

Cognitive Insights

1 PTL and ATL have high overlap for both syntactic (CC, CI,

SynGCN, INC), and semantic (BERT) features.

2 ROIs such as IFG, IFGOrb and MFG have higher overlap with
syntactic features like CM, PU, SynGCN and INC, and with
semantic feature BERT.

3 Basic syntactic features are much less associated with voxels in

angular gyrus region.

Conclusion

1 Constituency trees explain additional variance better than

other syntactic parsing methods.

2 Future Directions: This work was done on data related to
English stories only. As we do other kinds of models of
language processing in various languages, we want to make
similar studies for multi-lingual languages [1].

Encoding Performance of Various Feature Sets

References

[1] Bhattasali Li Jixing et al. 2022.

Le petit prince multilingual naturalistic fmri corpus.

[2] Aniketh Janardhan Reddy et al. 2021.

Can fmri reveal the representation of syntactic structure in the
brain?

[3] Samuel A Nastase et al. 2021.

The “narratives” fmri dataset for evaluating models of
naturalistic language comprehension.

Acknowledgements

1 We thank Gaël Jobard for his very helpful comments and

discussions.

2 We thank Inria for the PhD funding and ANR DeepPool

project.

(a) Constituency parse tree(b) Dependency parse treeSNPDTNPPPVPNNDTNNVBDINThecatsatonthemat(c) Incremental top-down parse treeROOTVP..SNPDTNNThecatVBDPPsatINNPonDTNNthematStimulusRidge RegressionPresentInputOutputXYWPearson Correlation (R) = Corr(Y, W(X))StimulusPresentPTLATLAGIFGMFGIFGorb0246{PU}{CM, PU}-{PU}{PD, CM, PU}-{CM, PU}{CC, PD, CM, PU}-{PD, CM, PU}{CI, PD, CM, PU}-{PD, CM, PU}{INC, PD, CM, PU}-{PD, CM, PU}{SynGCN, PD, CM, PU}-{PD, CM, PU}{BERT, CC, PD, CM, PU}-{CC, PD, CM, PU}{BERT, CI, PD, CM, PU}-{CI, PD, CM, PU}{BERT, INC, PD, CM, PU}-{INC, PD, CM, PU}{BERT, SynGCN, PD, CM, PU}-{SynGCN, PD, CM, PU}% of ROI voxels with significant R 2 increasesConstituentSynGCN