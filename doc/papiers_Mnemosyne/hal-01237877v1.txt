Modeling pavlovian conditioning with multiple neuronal populations
Maxime Carrere, Frédéric Alexandre

To cite this version:

Maxime Carrere, Frédéric Alexandre. Modeling pavlovian conditioning with
multiple neuronal pop- IEEE International Joint Conference on Neural
Networks, Jul 2015, Killarney, Ireland. ulations.
￿10.1109/IJCNN.2015.7280716￿. ￿hal-01237877￿

HAL Id: hal-01237877

https://inria.hal.science/hal-01237877

Submitted on 3 Dec 2015

HAL is a multi-disciplinary open access archive for the deposit and
dissemination of sci- entific research documents, whether they are pub-
lished or not. The documents may come from teaching and research
institutions in France or abroad, or from public or private research
centers.

L’archive ouverte pluridisciplinaire HAL, est destinée au dépôt et à la
diffusion de documents scientifiques de niveau recherche, publiés ou
non, émanant des établissements d’enseignement et de recherche français
ou étrangers, des laboratoires publics ou privés.

Modeling pavlovian conditioning with multiple neuronal populations

Maxime Carrere and Fr´ed´eric Alexandre LaBRI, Universit´e de Bordeaux,
Institut Polytechnique de Bordeaux, CNRS, UMR 5800, Talence, France
Inria Bordeaux Sud-Ouest, Talence, France Institut des Maladies
Neurod´eg´en´eratives, Universit´e de Bordeaux, CNRS, UMR 5293,
Bordeaux, France

Abstract—Artiﬁcial Neural Networks are often used as black boxes to
implement behavioral functions, developed by trials and errors, fed with
sensory inputs and controlled by some criteria of performance. This is
the case for pavlovian conditioning where important sensory information
is non ambiguous and where the error of prediction is to be minimized.
These past years, taking into account critical conditioning behaviors
entailed complexifying the neuronal functioning and learning rules. This
resulted in networks still simple at the architectural level but with a
dynamics difﬁcult to master. Instead, we propose a new neuronal model
using uniform and classical neuronal dynamics, with a more complex
architecture based on recent ﬁndings in neuroscience. Results reported
in this paper conﬁrm the good behavior of the model and justify the
complex architecture by the greater robustness and ﬂexibility of the
model.

I.  

INTRODUCTION TO PAVLOVIAN CONDITIONING

Many models of Artiﬁcial Neural Networks have been proposed to implement
pavlovian conditioning. One reason is that this topic is attractive
because pavlovian conditioning is a learning process easily observable
at the behavioral level in most species, from the simplest to the most
complex, and that it involves stimuli easy to observe and to control in
the environment. Another reason is that pavlovian conditioning is a
gateway to fundamental concepts like prediction error, attention and
information representation, as it has been shown by the variety of
topics addressed by these models. Conse- quently most of the models that
have been presented to date have the double characteristic of ﬁrstly
proposing a simple implementation to capture the essential features of
pavlovian conditioning and secondly complexifying the model to stick to
a more realistic view of this process [1], [2], [3], [4], [5], [6], [7],
[8].

Pavlovian conditioning is the adaptive process by which a biologically
signiﬁcant stimulus, also known as unconditional stimulus (US), can be
anticipated by learning by a neutral stimulus, also known as conditioned
stimulus (CS). US can correspond to a reward (some food) or to a
punishment (an electric shock) and automatically triggers a response,
not only at the motor level (e.g. orientation, avoidance) but also at
more internal hormonal and autonomic levels to prepare the body
(e.g. release of stress hormones, acceleration of heart rate). After
some pairings between CS and US, the association CS- US is learnt and
the CS presented alone will trigger a pavlovian response.

From a modeling point of view, this simple description

might evoke a simple associative rule between CS and US, except if other
phenomena like blocking are considered. In the blocking protocol, also
described as a principle of parsimony, a stimulus CS1 is paired with a
US until acquisition of the association. Then, the conjunction of two
stimuli CS1 and CS2 is paired with the same US. After this process, it
appears that CS1 but not CS2 predicts the US. This can be interpreted as
a parsimonious learning, since in the learnt cases, CS1 is sufﬁcient to
predict US and there is no need to learn on CS2. In the early 70’s,
Rescorla and Wagner [9] brought a decise answer to this problem,
proposing that the associative strength between CS and US was in fact
proportional to the degree of surprise or of impredictibility of what
happens. [10] proposed a simple implementation of their rule in a
perceptron-like neural network. In this network, each possible CSj
activates a neuron in an input layer, which is directly connected
through a weighted link Wij to an output unit predicting U Si. The
Rescorla-Wagner learning rule is implemented as:

∆Wij = α ∗ β ∗ (U Si − ΣjWij ∗ CSj) ∗ CSij

where α is a parameter standing for the associability (saliency) of the
CS, β for the effectiveness (behavioral impor- tance) of the US and ΣWij
∗ CSj) is the prediction of U Si by the network. Consequently, the term
(U Si − ΣWij ∗ CSj) can be seen as the error of prediction of the
network, which is a major ingredient in most approaches of reinforcement
learning. Sutton and Barto [6] have introduced a temporal dimension to
this rule (the CS must begin before the US), using temporal traces
yielding residual neuronal activities when the stimulus has disappeared.

Even if the Rescorla-Wagner (RW) rule remains of central interest for
modeling pavlovian conditioning, most models that were published
subsequently consisted in considering some the observed protocols where
that rule cannot explain all phenomena and in proposing a modiﬁcation of
the rule accord- ingly. This has been the case for several kinds of
problems. The ﬁrst kind of problem is about the way stimuli are
represented. Learning can become complex when a conﬁguration of stimuli
requires a speciﬁc answer by the network. This is the case for example
for compound stimuli (each of CS1 and CS2 in isolation predicts the US
but not CS1&CS2 together: this is the classical problem of the XOR).
This is also the case when all the surrounding stimuli must be
aggregated in a global

pattern called context and when the response of the network is context
dependent (it has for example been observed that the spatial context of
conditioning, the box in which the rat receives electric shocks, can
become a strong predictor of the US [11]). In all these cases, where the
RW rule cannot learn to predict the US from an input layer made of
elemental CSs, several extensions have been proposed [8], adding new
units in the input layer, corresponding to conﬁgural stimuli or to the
context.

Other kinds of problems are related to the mechanics of the learning
process. The RW rule states that the modiﬁcation of the weights depends
only on the presence of CS and US. This might be modulated by parameters
α and β, but they are supposed to be constant in the rule. In other
words, according to the RW rule, learning to predict the US does not
depend on the history of conditioning, which is not what is observed
experimentally. Two modeling paths have been developed to take this
problem into account. The Pearce-Hall model [7] measures the rate with
which each stimulus is learned. This is called salience associability
and corresponds to rendering parameter α variable and dependent on the
history of each CS. A simple implementation is to multiply the RW rule
by abs(U Si − ΣWij), where abs is the absolute value function. In this
case, and as it is observed experimentally, weights from CSs that
already predict US a lot are modiﬁed more slowly. The Mackintosh model
[4] gives a report on attentional associability which explains which
stimuli have access to the learning process. In this model, good
predictors of US maintain a high associability, to explain for example
the fact that assigning a CS to a new US is quicker after an overtaining
of the CS with previous US.

Both models underline the need to take into account the recent history
of conditioning (it can be mentioned that conﬁguration of stimuli can
develop their own associability [12]) but they also result in a
complexiﬁcation of the learning rules. The best illustration is probably
with so-called hybrid models [13] which propose to incorporate in one
rule all the elements mentioned above.

Another important problem with the RW rule is the fact that it
corresponds to acquiring a static and deterministic view of the world,
whereas it can be stochastic (a CS can predict a US with a certain
probability) and changing (a CS- US rule can be valid one day and
disappear the day after), both concepts referred to, respectively, as
known and unknown uncertainty [14]. The RW rule or the Pearce-Hall model
can compute the probability of known uncertainty as the value of
convergence of the weight, but the unknown uncertainty can only
correspond to an estimation subject to changes at any moment.
Consequently, a special care must be taken for unknown uncertainty,
which is well represented in the case of extinction. In this protocol
[15], a CS-US association is learned until the CS faithfully predicts
the US; then the US in no longer given (extinction of the association).
It is then observed that the prediction will disappear but this takes a
rather long time (for example in fear conditioning, a CS-US association
can be learned after three pairing but more than ten are necessary for
extinction). More important is the related phenomenon of renewal: if
after the extinction, the US is given again, the CS-US association is
re-established immediately. This experiment is a strong argument against
models based on

the RW rule where the level of CS-US association is ﬂuctuating with the
level of association and is ultimately removed after extinction.
Instead, it proposes that the CS-US association is not forgotten but
only inhibited during extinction and that renewal consists in releasing
that inhibition [16]. Consequently, whereas some ﬂuctuation, as proposed
in the RW rule, can be used to precisely deﬁne the level (the
probability) of CS-US association, another mechanism must be deﬁned in
the case of unknown uncertainty, when the rule changes.

In summary, this overview underlines the two main char- acteristics of
modeling pavlovian conditioning with ANNs. On the one hand, the RW rule
has had a deep impact on the models and conﬁrms the preeminence of the
error of prediction of the US in pavlovian conditioning. On the other
hand, adapting the RW rule to a more precise modeling of the behavioral
characteristics reveals difﬁcult in the too simple framework of a
two-layered network, directly predicting the US from the CS. A key issue
in this regard is to take a more insightful view of the biological
substrate of this learning process, which is not limited to a two
layered structure, and to develop more biologically inspired neuronal
networks.

II. CEREBRAL IMPLEMENTATION OF PAVLOVIAN CONDITIONING

Except for the case of simple somatomotor associations where the
cerebellum is mainly involved [17], another cerebral structure, the
amygdala, is reported to be the key region where pavlovian conditioning
takes place [18]. In this regard, two main regions have been
traditionally described: the basolateral nuclei (BLA) receiving the
sensory input and the central nuclei CeA for the motor output. More
precisely, it has been shown that the CS and the US activates neurons in
BLA and that the CS-US association is learned herein [19]. Similarly,
strong experimental evidences have shown that CeA receives infor- mation
from BLA and projects to structures responsible for the motor, hormonal
and autonomic expression of pavlovian responses [20].

Concerning phenomena evoked above and indicating that pavlovian
conditioning is more complex than a simple asso- ciative rule between
elemental CS and US, effects related to conﬁgural or contextual
representations are generally attributed to the hippocampus [21], known
to build arbitrary relations among separate features of a behavioral
episode and projecting to BLA. On this basis, bio-inspired models of
pavlovian conditioning able to process conﬁgural and contextual stimuli
have been proposed, including a model of the hippocampus dedicated to
the formation of complex patterns acting as CSs [1], [2], [22], [23].

The prefrontal cortex is undoubtly considered as a ma- jor cerebral
structure involved in temporal representations, including storage of
past activities in working memory and behavioral sequence representation
[24]. Concerning temporal aspects evoked above for pavlovian
conditioning, the infral- imbic cortex or the homologous structure in
primates, the orbitofrontal cortex, ventral parts of the medial
prefrontal cortex, have been reported to act as a working memory,
keeping track of the recent reward history [25]. It has been speciﬁcally
reported that projections from this structure toward BLA are necessary
for the acquisition of extinction and for ex- tinction memory [26].
Accordingly, bio-inspired neural models

of extinction have been proposed [27], [28], implementing an inhibitory
role of the medial prefrontal cortex toward CS-US associations in the
amygdala in case of extinction, measured as a frequency of prediction of
the US not followed by its occurrence.

In their paper describing the role of uncertainty in decision making
[14], Yu and Dayan underline the prominent role of neuromodulation,
speciﬁcally proposing the inﬂuence of acethylcholine and norepinephrine
on the neural substrate to modulate its activity, respectively as a
function of known and unknown uncertainty. As far as pavlovian
conditioning is concerned, mainly the effect of acetylcholine has been
considered in bio-inspired models [29], underlying that its release from
the basal forebrain is partly due to hormonal responses emitted from CeA
in case of errors of prediction and modeling its role in changing
attentional and learning effects in the cortex and the hippocampus.

Whereas these bio-inspired neuronal models bring valuable insights about
mechanisms underlying some complex aspects of pavlovian conditioning,
they say few about how all these mechanisms coexist and interact in
amygdalar neural popu- lations. Particularly, contradictory information
might be sent to BLA from its afferent structures and it might be
questioned how they are incorporated at the neuronal level to elaborate
the more adapted response. Solutions like complex rules proposed by
hybrid models [13] do not seem transposable here for at least two
reasons. They are too complex to be implemented as a neuronal activation
or learning rule and they are not ﬂexible enough to change autonomously,
depending on the changes in the statistics of external events.

The model that we present in this paper addresses this problem by
incorporating recent ﬁndings from neuroscience in a novel bio-inspired
model of the amygdala. In short, the main characteristics that we
extract from these recent ﬁndings is that distinct populations of
amygdalar neurons receive distinct afferences from the neuronal
structures providing key informa- tion and underlie distinct
evaluations, which are combined and confronted internally in the
amygdala to prepare the pavlovian response.

More precisely, the distributed neuronal implementation that we propose
in our model relies on the following biological hints. The basolateral
nuclei of the amygdala can in fact be differenciated as a lateral
nucleus, receiving elemental sensory information from the thalamus and
the cortex and a basal nucleus, receiving more elaborated information
from the hippocampus and the prefrontal cortex [30]. Besides, within the
basal nucleus, it has been shown recently [15] that two distinct
populations of neurons, called high-fear and low-fear neurons are
respectively connected with the hippocampus and the infralimbic cortex
and are respectively engaged in context- dependent acquisition and
renewal (high-fear neurons) and in extinction (low-fear neurons),
whereas fear neurons in the lateral nucleus can detect simple CS from
elemental sensory information from the thalamus and the cortex. In
addition, inhibitory connections are also reported between these pop-
ulations [31]. Another key difference between the basal and lateral
nucleus exploited by our model is that the activity of the basal nucleus
is particularly modulated by acetylcholine. For example, in [32] a
higher activation in the basal nucleus is associated to a high level of
acetylcholine.

A functional differentiation has also been recently reported in the
lateral part of the central nucleus, concerning the preparation of the
pavlovian response [33]. It is reported in this paper that in this
region in mice, 30% of the neurons (called CeLon) acquire an excitatory
response and 25% a strong inhibitory response and are together in mutual
inhibition. It can be consequently hypothetized that fear and low-fear
neurons from the lateral and basal nuclei respectively project on these
populations, whose interaction results in the level of pavlovian
response emitted from the central nucleus.

In summary, whereas most models of the amygdala pos- tulate a simple
network, directly connecting a sensory layer to a motor layer and
managing the complex features of pavlovian conditioning by the design of
a complex learning rules, biological evidences rather propose to
consider that several populations coexist in the amygdala to process
different classes of sensory and motor patterns, in close relation to
the different classes of afferences received by the amygdala. Several
consequences can be drawn from this global picture. Within such a
distributed network, local learning and func- tioning rules can remain
simple. The global behavior of the network can be more ﬂexible, since
several scenarios can be evaluated in parallel, before the decision
emerges from their competition and coordination. This is more precisely
described in the model that we present now.

III. MODEL DESCRIPTION

Our model aims at illustrating how connections in a neural network can
explain and reproduce behavioral results observed in pavlovian
conditioning. Thus, it describes the amygdala by modeling its differents
parts using different neural populations. Each population has mainly the
same neuronal equations and parameters, but differs one from the other
by its connectivity, ie. differences in inputs from other populations or
from neuro- modulation, and differences in output projections toward
other populations.

Fig. 1. Main features of our amygdalar network. LA and BAf are two fear
neurons populations, which differ by their afferent connections. LA
learns to predict fear, based on sensory input from cortex and thalamus
and projects to BAf and CeLOn. BAf receives contextual inputs from
Hippocampus and sensory-based prediction from LA, resulting in a
prediction based on both sensory or contextual information. BAe is a
population of extinction neurons receiving contextual inputs from medial
Prefrontal Cortex (Infralimbic cortex, IL) during extinction. BAe and
BAf are in mutual inhibition and respectively project to CeLOn and
CeLOff populations in CeA. CeLOn and CeLOff are also in mutual
inhibition. CeLOn activity is considered as the level of US prediction
of the model.

As described in ﬁgure 1, the amygdala is represented by ﬁve different
populations, and encompasses three main infor- mation ﬂows. First, a
population of fear neurons representing the Lateral Nucleus (LA)
receives sensory information from the cortex (this term in the model
will refer to both thalamus and sensory cortex), and learns to predict
fear, based on these sensory inputs. These neurons project to a
population in the Central Nucleus of the Amygdala (CeLOn) whose level of
activation is considered the main output of the model, representing the
fear response. In cases of pavlovian learning using sensory cues, this
Cortex-LA-CeLOn pathway will learn to predict US arrival based on
sensory information.

In the basal nucleus of the amygdala, another population of fear neurons
(BAf) receives contextual inputs from the hippocampus, sensory
prediction from LA, and projects to CeLOn. This Hippocampus-BAf-CeLOn
pathway allows the network to make predictions based on contextual
information. Finally, a population of extinction neurons in the basal
nucleus of the amygdala (BAe) receives contextual information in
situation of extinction from the Infralimbic cortex (IL), and learns to
predict extinction conditioning, ie when predicted US do not arrive. BAe
and BAf neurons are in mutual inhibition, so that in an extinction
situation, neurons in BAe can inhibit BAf fear prediction, thus
inhibiting the prediction of the second pathway.

BAe neurons project to a population in the central nucleus of the
amygdala, CelOff, which in turn can inhibit CelON prediction in an
extinction situation, inhibiting the sensory prediction of the ﬁrst
pathway. Consequently, the IL-BAf- CelOff pathway can inhibit both
sensory and context-based predictions in a case of extinction.

Another mechanism taken into account in this model is the effect of
acetylcholine (ach) concentration on the differ- ent pathways. BAf and
BAe activities are enhanced by ach concentration. A higher level of
acetylcholine will increase BAf and BAe activities, which will favor the
second or third pathway over the ﬁrst one in respectively contextual
learning or extinction learning. At the opposite, a lower ach
concentration can allow sensory-based predictions in LA to win over BA
contextual learning or extinction.

This model is implemented in Python, and is using the DANA library for
neuronal computation [?]. Since we are focusing on modeling the role of
the amygdalar network in pavlovian conditioning, we did not implement
neuronal dynamics for the other parts of the brain providing inputs to
the network, ie cortex and thalamus for LA, hippocampus for BAf and
infralimbic cortex for BAe. Each of these external populations is a
vector of neurons whose activities are set according to the studied
paradigm.

Each amygdalar neuron is described using the mean ﬁeld formalism, which
consists of two variables: the membrane potential V and the ﬁring rate U
. As we aim at modeling pavlovian conditioning by using connectivity to
induce pavlo- vian behaviors rather than behavior-speciﬁc equations, all
of our neurons are using the same equation for V and for U :

dV Amyg i dt

= (−V Amyg i

-   F (ΣjW Amyg−Input ij

∗ U Input j

))/τ

Parameter input size la size baf size bae size CeLOn size CeLOff size

τ α il tau noise level θ ach min ach max ach strength ach uncertainty
strength wmin wmax Cel input W LA to BAf W LA inhib W Cel inhib W BA
inhib W

Architectural parameters

Meaning size of input vectors from cortex, hippo, IL number of neurons
in la number of neurons in baf number of neurons in bae number of
neurons in CeLOn number of neurons in CeLOff

Equation parameters Amygdala neurons time constant Modulates learning
speed in LA, BAf and BAe time constant for ach equation % of neurons
intrinsic noise neurons input threshold minimum of ach level maximum of
ach level modulates effect of ach concentration on BA modulates effect
of uncertainty on ach concentration minimum for modiﬁable weights
initialisation maximum for modiﬁable weights initialisation constant
weights from BLA to Cel constant weights from LA to BAf constant weights
inside LA constant weights between CelOn and CelOff constant weights
between BAf and BAe

Value 10 10 10 10 1 1

0.05 1 5 1 0.3 1 2.5 0.5 5 0.01 0.05 0.2 0.1 0.1 0.25 0.05

Fig. 2. activation and learning rules.

Parameters describing network architecture and parameters used in

U Amyg

i

= noise(sigmoid(V Amyg

i

))−ΣkW Amyg−Inhib ik

∗U Inhib k

Parameters are identical for each neuron. τ is a time constant deﬁning
the dynamics of activity evolution and set to 0.05 throughout all the
experiments. F is a non linear threshold function:

F (U ) = max(min value, U − θ)

with min value a tiny constant set to 10−3, and θ the value of the
threshold, set to 0.3. noise() is a function which represents intrinsic
neuronal noise, by using a uniform distribution centred on the value
sigmoid(V ). Results reported here are robustly obtained with an
interval length of 1% of sigmoid(V ). Yet raising noise up to 20% does
not alter network performance on the different paradigms.

Fear and extinction learning rules are implemented using hebbian
learning, with a prediction error ERR = (U S − UCeLOn) as in the
Rescorla-Wagner rule.

ij

dW P ost−P re dt

= ERR ∗ U S ∗ α ∗ U P re

j

∗ U P ost i

Since extinction neurons need to increase their responsiveness when the
level of prediction of the US is too high, learning rule is the opposite
for extinction neurons and writes:

ij

dW BAe−IL dt is the BAe postsynaptic activity, and U IL

= −ERR ∗ α ∗ U BAe

where U BAe the presynaptic activity from IL. α is a learning coefﬁcient
set to 1.0 for all fear and extinction neurons.

∗ U IL j

j

i

i

CeLOn and CelOff neurons do not require plasticity, since their role in
our model is only to integrate LA, BAf and BAe predictions, which does
not need learning, at least for the paradigms tested here.

Both UBAf and UBAe are multiplicatively enhanced by ach

concentration, computed as follows :

ACh = ach strength ∗ (baseline+ ach uncertainty strength ∗
noise(sigmoid(V ACh)))

dV ACh/dt = (−V ACh + F (|ERR|))/τACh where V ACh is used to compute
recent uncertainty which is reﬂected in ach concentration [14]. baseline
is the baseline to 1.0, τACh is the time level of tonic acetylcholine,
set constant, set to 5, F is the threshold function and ERR the
prediction error deﬁned above. ach uncertainty strength modulates the
effect of the recent uncertainty V ACh on each concentration, and is set
to 5. ach strength modulates the overall effect of ach concentration on
BA activities, and is set to 0.5.

IV. EVALUATION OF THE MODEL

All our experiments were organized according to the pro-

tocol described in ﬁgure 3.

Fig. 3. Each trial is composed of three phases of identical duration. In
the ﬁrst phase, only the sensory CS and/or the context is shown to the
network. The second phase is the learning phase, and begins with US
arrival. Prediction error is computed based of the network output at the
end of phase 1. During phase 3, no input is presented and amygdalar
neurons return to their baseline level of activation.

One trial is a single CS-US presentation, and consists in three phases.
In the ﬁrst phase, the cue (CS and/or context) is presented alone to the
network and enough time is given for its activities to stabilize. In the
seconde phase, CS and/or context is maintained, and the US is presented.
In the third phase, no inputs are presented and neuronal activities go
down to their baseline level.

Fig. 4. Trial 1 (not shown here) was a trial without any stimulus
presentation for network stabilization to baseline values. Fear
conditioning takes place from trial 2 to trial 13. Fear extinction from
trial 14 to trial 21. Renewal is tested in trial 22. Graphs A,B,C,D are
showing average activities at the moment of US arrival. (A) Both LA and
BAf activities increase during conditioning. BAe activity decreases due
to BAf inhibition. (B) Due to LA and BAf increase, CeLOn activity
increases, and correctly predicts US arrival after conditioning. CeLOff
activity is inhibited by CeLOn (C) After a few trials, BAe activity
starts to overcome BAf inhibition, and BAe strongly increases, which
provokes BAf inhibition. LA ﬁring rates remain steady. In the renewal
context, IL does not provide any longer extinction information to BAe,
which stops BAe ﬁring and releases its inhibition on BAf. (D) During
extinction, CeLOff activity increases with BAe increase and overcome
CeLOn inhibition, still powered by LA ﬁring. In the renewal trial,
CeLOff is no longer sustained by BAe, and CeLOn activity is restored to
conditioning value.

Using this procedure, our network manages to reproduce classical
pavlovian acquisition, contextual extinction and re- newal results as
observed in [15] (cf Fig.5). We also report in ﬁgure 5 results
indicating that our network nicely reproduces the blocking paradigm.

Fig. 5. Acquisition takes place from trial 2 to 13. During acquisition,
a single sensory CS is presented to the network followed by US arrival
(without context). Blocking takes place starting from trial 14. A new CS
is presented simultaneously to the previous one, followed by US arrival.
(A,B) Acquisition similar to ﬁgure 4. (C) Weights evolution during
acquisition. LA weights are increasing during acquisition while the
others remain steady. (D,E,F) Blocking occurs: since the ﬁrst stimulus
is already a good US predictor, no learning occurs based on the new
stimulus presentation.

In all these experiments, each neuronal population shows different
behavior, depending on its connections and inputs. During acquisition,
both LA and BAf learn to predict US arrival, so that learning is
distributed between these two populations. During extinction, the
IL-BAe-CelOff pathway extinguishes the other two pathways thanks to BAe
learning. Whereas BAf is inhibited by BAe, LA is still ﬁring and
predicting US arrival, but this prediction is inhibited in CeLOn by
CelOff inhibition. In the last trial, we restore the acquisition context
back and we can observe that renewal is immedi- ate. Moreover, this
network is performing fear conditioning, extinction and renewal with
temporal characteristics similar to those observed in animals by [15].
Neuronal dynamics is also consistent with other experimental ﬁndings
(learning distributed between BAf and LA, still fear prediction in LA
when in an extinction process).

Advantages with our distributed US-prediction network include the facts
that it is both able to make prediction of the US if one pathway is
disturbed and that it can use the more adequate pathway to predict US in
normal conditions. The following experiments were aimed at studying
theses two advantages. In each experiment, after fear acquisition, we
test independantly sensory-based prediction and context-based prediction
of the US, in order to see which neural pathway has undergone the more
learning (Fig.6).

In Fig.6.A, both CS and context are presented to the network for fear
prediction (pairing experiment). Yet after learning, the network is
predicting mostly based on sensory characteristics of the CS. This
phenomenon emerges from the connections from LA to BAf. While only BAf
can perform context-based learning, LA (by receiving sensory information

process and tries to learn to predict the US based on sensory inputs
under normal circumstances. We have explained above that by default,
there is a bias favoring LA, simply due to the network connectivity. If
this pathway is not performing well, either because the elemental
sensory cues are not sufﬁcient to predict US or because LA pathway is
somewhat impaired, errors will accumulate, and ach level will raise,
which will favor the IL-BAe-CeLOff pathway for extinction, or the Hippo-
BAf-CeLOn pathway for contextual conditioning. The choice between the
latter two processes is performed on a simple competitive process,
depending on their levels of prediction. Thus ach concentration plays a
critic role by monitoring recent uncertainty and enables the other two
processes to predominate over the otherwise naturally chosen sensory
pathway.

Moreover, as seen in the last experiment, this network structure remains
ﬂexible: if the second process (BAf pathway) is impaired, the ﬁrst
process through LA is still able to learn and allows the network to make
sensory-based predictions. These characteristics of adaptivity and
ﬂexibility emerge from a multiple layer system, also found in animals
and could not have been obtained by using a single-layer system, even
with complex rules.

V. CONCLUSION

The main ﬁndings of this paper can be ﬁrst discussed on a behavioral and
evolutionary perspective. The initial goal of pavlovian mechanisms in
phylogeny is to increase probability of survival by triggering rapid and
automatic reﬂexes when the animal faces biologically signiﬁcant stimuli.
Along evolution, these mechanisms have evolved to incorporate more
complex cases. This can be the complexiﬁcation of stimuli in space and
time, including attentional mechanisms in mammals. This can also be the
evolution under voluntary control where CS can be seen as conditioned
reinforcers or goals toward which the behavior has to be organized.

Concerning brain structure, this can also be summarized by the recent
expansion of the basal nuclei [18], incorporating new inputs from the
hippocampus and the prefrontal cortex and sending information about
conditioned reinforcers towards the main structures of instrumental
conditionning, the basal ganglia and the prefrontal cortex. But of
course these new capabilities do not replace older ones (survival
reﬂexes are still important in mammals) but just increase the size of
the behavioral repertoire.

These principles are very consistent with what we observe from the
characteristics of our model. In the more simple cases, the network is
tuned in such a way that responses originating from LA will have a
stronger effect and will trigger a fear response from basic sensory
cues. Then, only in the case of error of prediction of the US, this will
trigger acetylcholine, increasing the inﬂuence of BA, and the network is
going to try to build more complex association from more complex sensory
patterns or a longer history in time.

More generally,

this bio-inspired design of a neuronal architecture is a plea for
getting inspired by the modular architecture of the brain: Most of our
complex cognitive func- tions result from the competition and
collaboration of simple functional pathways. Such an architecture is
more simple to build during the evolution of species but also of
individuals.

Fig. 6. CeLOn activity after learning, when only the CS (blue bar) or
only the context (green bar) is presented. Similar results are observed
in animals in [32].(A) During pairing experiment, both CS and context
are presented as cues for US prediction. After conditioning, prediction
is higher for the CS, while context-based prediction does not differ
much from baseline level. (B) Pairing with increased ach level. CeLOn
activity is higher for context-based prediction. ach increase causes US
to be associated with context instead of CS. (C) During the unpairing
experiment, both CS and context are presented to the network as cues for
US prediction. Yet CS intensity is randomly varying from one trial to
another, so that context, whose activity remains the same from one trial
to another, is a better predictor of the US. Consequently, after
learning, the sensory CS alone does not elicit a strong US prediction,
while context does. (D) Unpairing experiment with ach depletion, which
impairs contextual pathway learning. As a result, the sensory pathway is
learning US arrival.

from cortex) and BAf (by receiving LA activations) can per- form
sensory-based learning. Yet, if we set ach constant to 3.0, ie. around
two times the observed ach level in this paradigm, we observe the
opposite phenomenon. Higher ach level means higher activities in BA,
which induces a faster hebbian learning in BAf. The LA pathway does not
have enough time to stabilize, so that the network is making predictions
mostly based on the context (Fig.6.B), as also reported in [32].

In ﬁgure 6.C, we are also presenting both CS and con- text to the
network before US arrival during the learning phase. Yet CS intensity is
randomly varied from one trial to another, by multiplying it with a
number randomly drawn in a uniform distribution between 0 (no CS) and 1
(normal intensity) (unpairing experiment). Thus, the context becomes a
better predictor of the US than CS, since its intensity is always the
same before US arrival. Figure 6.C shows that in this experiment, our
network is indeed making context-based predictions. Learning takes
longer, around 16 trials, which allows the measure of uncertainty to
rise higher, which in turn raises ach value and allows the
Hippo-BAf-CeLOn pathway to predominate in learning. Yet if we impair the
BAf pathway in this experiment, by setting ach concentration to 0.5,
half of its baseline level (Fig.6.D), the network is still able to
predict US arrival, by learning it with its LA pathway. If for some
reason the contextual pathway is impaired, the neural network will learn
to predict US arrival based on the sensory pathway, even in a paradigm
in which it would normally favour the contextual one. All of these
results have also been observed experimentally in animals as reported in
[32].

In summary,

the architecture of the neuronal network model of the amygdala that we
propose can be viewed as three parallel processes and the elaboration of
a criterium for arbitration. The sensory pathway including LA is the
ﬁrst

[19] S. K. Barot, Y. Kyono, E. W. Clark, and I. L. Bernstein,
“Visualizing stimulus convergence in amygdala neurons during associative
learning,” Proceedings of the National Academy of Sciences, vol. 105,
no. 52, pp. 20 959–20 963, Dec. 2008.

[20] M. D. Cassell, L. J. Freedman, and C. Shi, “The Intrinsic
Organization of the Central Extended Amygdala,” Annals of the New York
Academy of Sciences, vol. 877, no. 1, pp. 217–241, Jun. 1999.

[21] H. Eichenbaum, M. Sauvage, N. Fortin, R. Komorowski, and P. Lipton,
“Towards a functional organization of episodic memory in the medial
temporal lobe,” Neurosci Biobehav Rev., vol. 36, no. 7, pp. 1597–1608,
2012.

[22] M. Meeter, C. E. Myers, and M. A. Gluck, “Integrating Incremental
Learning and Episodic Memory Models of the Hippocampal Region,”
Psychological Review, vol. 112, no. 3, pp. 560–585, Jul. 2005. [23] R.
C. O’Reilly and J. W. Rudy, “Conjunctive Representations in Learn- ing
and Memory: Principles of Cortical and Hippocampal Function,”
Psychological Review, vol. 108, no. 2, pp. 311–345, 2001. J. M. Fuster,
“The Prefrontal Cortex - An Update: Time Is of the Essence,” Neuron,
vol. 30, no. 2, pp. 319–333, 2001. J. D. Wallis, “Orbitofrontal cortex
and its contribution to decision- making.” Annual review of
neuroscience, vol. 30, no. 1, pp. 31–56, Apr. 2007.

[24]

[25]

[26] D. Sierra-Mercado, N. Padilla-Coreano, and G. J. Quirk,
“Dissociable roles of prelimbic and infralimbic cortices, ventral
hippocampus, and basolateral amygdala in the expression and extinction
of conditioned fear.” Neuropsychopharmacology, vol. 36, no. 2,
pp. 529–538, Jan. 2011.

[27] W. M. Pauli, T. E. Hazy, and R. C. O’Reilly, “Expectancy,
Ambiguity, and Behavioral Flexibility: Separable and Complementary Roles
in Processing Reward Expectancies,” Journal of Cognitive Neuroscience,
vol. [Online]. Available: 351–366, 2, http://dx.doi.org/10.1162/jocn a
00155

and Amygdala

Frontal Cortex

the Orbital

2011. 

no.

pp.

24,

of

[28] M. Jan, “Emotion and learning : a computational model of the amyg-

dala,” Ph.D. dissertation, Lund University Cognitive Studies, 2002.

[29] W. M. Pauli and R. C. O’Reilly, “Attentional control of associative
learning–a possible role of the central cholinergic system,” Brain
Research, vol. 1202, pp. 43–53, Apr. 2008. J. LeDoux, “The amygdala,”
Current Biology, vol. 17, no. 20, pp. R868– R874, Oct. 2007.

[30]

[31] S. Lee, S.-J. Kim, O.-B. Kwon,

J. H. Lee, and J.-H. Kim, “Inhibitory networks of the amygdala for
emotional memory,” Frontiers in Neural Circuits, vol. 7, no. 129, 2013.
[Online]. Available: http://www.frontiersin.org/neural
circuits/10.3389/fncir.2013.00129/abstract

[32] L. Calandreau, P. Triﬁlieff, N. Mons, L. Costes, M. Marien, A.
Marighetto, J. Micheau, R. Jaffard, and A. Desmedt, “Extracellu- lar
hippocampal acetylcholine level controls amygdala function and promotes
adaptive conditioned emotional response.” The Journal of neuroscience :
the ofﬁcial journal of the Society for Neuroscience, vol. 26, no. 52,
pp. 13 556–13 566, Dec. 2006.

[33] S. Ciocchi, C. Herry, F. Grenier, S. B. E. Wolff, J. J. Letzkus, I.
Vlachos, I. Ehrlich, R. Sprengel, K. Deisseroth, M. B. Stadler, C.
Muller, and A. Luthi, “Encoding of conditioned fear in central amygdala
inhibitory circuits,” Nature, vol. 468, no. 7321, pp. 277–282,
Nov. 2010. [Online]. Available: http://dx.doi.org/10.1038/nature09559

It is more resilient to damages and will integrate more easily changes
by modifying local pathways instead of a unique cost function. It is
certainly of highest interest for designers of Artiﬁcial Neural Networks
to integrate this principle in their daily practice.

REFERENCES

[1] N. A. Schmajuk and J. J. DiCarlo, “Stimulus conﬁguration, classical
conditioning, and hippocampal function,” Psychol Rev., vol. 99, no. 2,
pp. 268–305, 1992.

[2] A. A. Moustafa, C. E. Myers, and M. A. Gluck, “A neurocomputational
model of classical conditioning phenomena: A putative role for the
hippocampal region in associative learning,” Brain Res., vol. 1276, pp.
180–95, 2009. J. L. Armony, D. Servan-Schreiber, J. D. Cohen, and J. E.
LeDoux, “Computational modeling of emotion: explorations through the
anatomy and physiology of fear conditioning,” Trends Cogn Sci, vol. 1,
no. 1, pp. 28–34, Apr. 1997.

[3]

[4] N. J. Mackintosh, “A theory of attention: Variations in the
associability of stimuli with reinforcement,” Psychological Review,
vol. 82, no. 4, pp. 276–298, 1975. J. K. Kruschke, “Toward a uniﬁed
model of attention in associative learning,” Journal of Mathematical
Psychology, vol. 45, pp. 812–863, 2001.

[5]

[6] R. S. Sutton and A. G. Barto, “Toward a modern theory of adaptive
networks: expectation and prediction.” Psychological review, vol. 88,
no. 2, pp. 135–170, Mar. 1981. J. M. Pearce and G. Hall, “A model for
Pavlovian learning: variations in the effectiveness of conditioned but
not of unconditioned stimuli,” Psychological review, vol. 87, no. 6,
1980. [Online]. Available: http://view.ncbi.nlm.nih.gov/pubmed/7443916

[7]

[8] L. G. Allan, “Human Contingency Judgments: Rule Based or Associa-
tive?” Psychological Bulletin, vol. 114, no. 3, pp. 435–448, 1993. [9]
R. Rescorla and A. Wagner, “A theory of pavlovian conditioning:
Variations in the effectiveness of reinforcement and nonreinforcement,”
in Classical Conditioning II: Current Research and Theory. Appleton
Century Crofts, 1972, pp. 64–99.

[10] M. A. Gluck and G. H. Bower, “From conditioning to category
learning: an adaptive network model.” Journal of experimental
psychology. General, vol. 117, no. 3, pp. 227–247, Sep. 1988.

[11] M. Fanselow, “Contextual fear, gestalt memories, and the hippocam-
pus,” Behavioural Brain Research, vol. 110, no. 1-2, pp. 73–81, Jun.
2000.

[12] C. V. Buhusi and N. A. Schmajuk, “Attention, conﬁguration, and
hippocampal function,” Hippocampus, vol. 6, no. 6, pp. 621–642, Jan.
1996.

[13] M. E. Le Pelley, “The role of associative history in models of
associative learning: a selective review and a hybrid model.” The
Quarterly Journal of Experimental Psychology, vol. 57, no. 3,
pp. 193–243, Jul. 2004. [Online]. Available:
http://dx.doi.org/10.1080/02724990344000141 [14] A. J. Yu and P. Dayan,
“Uncertainty, neuromodulation, and attention.” [Online]. Available:

Neuron, vol. 46, no. 4, pp. 681–692, 2005.
http://dx.doi.org/10.1016/j.neuron.2005.04.026

[15] C. Herry, S. Ciocchi, V. Senn, L. Demmou, C. Muller, and A. Luthi,
“Switching on and off fear by distinct neuronal circuits,” Nature,
vol. 454, no. 7204, pp. 600–606, Jul. 2008. [Online]. Available:
http://dx.doi.org/10.1038/nature07166

[16] S. Maren, “Building and Burying Fear Memories in the Brain,” The

Neuroscientist, vol. 11, no. 1, pp. 89–99, Feb. 2005.

[17] R. F. Thompson and J. E. Steinmetz, “The role of the cerebellum in
classical conditioning of discrete behavioral responses.” Neuroscience,
vol. 162, no. 3, pp. 732–755, Sep. 2009.

[18] R. N. Cardinal, J. A. Parkinson, J. Hall, and B. J. Everitt,
“Emotion and motivation: the role of the amygdala, ventral striatum, and
prefrontal cortex,” Neuroscience & Biobehavioral Reviews, vol. 26, no.
3, pp. 321–352, 2002. [Online]. Available:
http://dx.doi.org/10.1016/s0149- 7634(02)00007-6


