Ten Simple Rules for Scientific Fraud & Misconduct
Nicolas P. Rougier, John Timmer

To cite this version:

Nicolas P. Rougier, John Timmer. Ten Simple Rules for Scientific Fraud & Misconduct. 2017. ￿hal-
01562601￿

HAL Id: hal-01562601

https://inria.hal.science/hal-01562601

Preprint submitted on 16 Jul 2017

HAL is a multi-disciplinary open access
archive for the deposit and dissemination of sci-
entific research documents, whether they are pub-
lished or not. The documents may come from
teaching and research institutions in France or
abroad, or from public or private research centers.

L’archive ouverte pluridisciplinaire HAL, est
destinée au dépôt et à la diffusion de documents
scientifiques de niveau recherche, publiés ou non,
émanant des établissements d’enseignement et de
recherche français ou étrangers, des laboratoires
publics ou privés.

Distributed under a Creative Commons Attribution 4.0 International License

Rougier & Timmer • Ten Simple Rules for Scientific Fraud & Misconduct

July 14, 2017

Ten Simple Rules for Scientific Fraud & Misconduct

Nicolas P. Rougier1,2,3,∗ and John Timmer4
1INRIA Bordeaux Sud-Ouest Talence, France 2Institut des Maladies Neurod´eg´en´eratives, Universit´e de Bordeaux, CNRS UMR 5293,
Bordeaux, France 3LaBRI, Universit´e de Bordeaux, Institut Polytechnique de Bordeaux, CNRS, UMR 5800, Talence, France 4Ars Technica,
Cond´e Nast, New York, NY, USA
∗Corresponding author: Nicolas.Rougier@inria.fr

Disclaimer. We obviously do not encourage scientific fraud nor misconduct. The goal of this article is to alert the
reader to problems that have arisen in part due to the Publish or Perish imperative, which has driven a number of
researchers to cross the Rubicon without the full appreciation of the consequences. Choosing fraud will hurt science,
end careers, and could have impacts on life outside of the lab. If you’re tempted (even slightly) to beautify your
results, keep in mind that the benefits are probably not worth the risks.

Introduction

So, here we are! You’ve decided to join the dark side of Science. That’s great! You’ll soon discover a brand new
world of surprising results, non-replicable experiments, fabricated data, and funny statistics. But it’s not without
risks: fame and shame, retractions and lost grants, and… possibly jail. But you’ve made your choice, so now you
need to know how to manage these risks. Only a few years ago, fraud and misconduct was a piece of cake (See the
Mechanical Turk, Perpetual motion machine, Life on Moon, Piltdown man, Water memory). But there are lots of
new players in town (PubPeer, RetractionWatch, For Better Science, Neuroskeptic to name just a few) who have
gotten pretty good at spotting and reporting fraudsters. Furthermore, publishers have started to arm themselves
with high-tech tools, and your fellow scientists are willing to name and shame you on social media. To commit
fraud or misconduct without getting caught in 2017 is a real challenge and requires serious dedication to your
task. While you’ll never be smarter than an entire community of scientists, we’re generously giving you some
simple rules to follow in your brand new career in fraud (see also (Timmer, 2012) for a set of complementary
rules). Of course, neither results or (lack of) consequences are guaranteed.

Rule 1: Misrepresent, falsify, or fabricate your data

In order to start your life as a scientific fraudster, the first thing you need to do is learn how to convincingly
misrepresent, falsify, or fabricate data. If you’re still hesitant about embracing the dark side of science, you can
start with a slight misrepresentation to support your hypothesis — a hypothesis you’re sure is right anyway.
Some classic techniques are described in more detail below (see the seventh rule of (Rougier, Droettboom, &
Bourne, 2014)) but there are a number of others. If your data include numbers, there are many techniques for
making a graph misleading (Wainer, 1984; Raschke & Steinbart, 2008). If you have images, you can change your
results using software such as Photoshop or GIMP, which allow you to change pretty much anything in a figure
(Cromey, 2012; Hendricks, 2011). But be careful, as an ever-growing number of journals are now using forensic
software to spot image manipulation (White, 2007; Rossner & Yamada, 2004; Hsu, Lee, & Chen, 2015) (see also
PLoS image manipulation recommendation and Rockefeller University Press’ discussion of the issue). You can
even test your whether your image has issues that could tip off an editor using the online tool Forensically by
Jonas Wagner. This might dissuade you from manipulating your image, but don’t worry — there are plenty of
other options available to you.

None of the previous techniques will change the statistics of your data, so it might be good to consider your
options here. Starting with real data, you only need to change a few points in order to take a non-significant result
and turn it into something with an astoundingly highly significance. Just see what’s possible using the p-hacker
application (Sch¨onbrodt, 2015) or the interactive applet from (Aschwanden, 2015). The advantage of tweaking
real data is that the results look both good and not very suspicious. The disadvantage is that it requires some
real data in the first place, which means carrying out some actual experiments. Who wants that? Instead, you
can fabricate an entire data set using software. With just a little programming skill, you can choose a correlation
coefficient and X and Y mean/SD, and generate a data set with these precise statistics (Matejka & Fitzmaurice,
2017). (Do not pick one of the datasaurus sets because if you plot it, it might attract the attention of an alert
reader.) Whatever option you choose, make sure to have a backup story in case people start asking about the

1

Rougier & Timmer • Ten Simple Rules for Scientific Fraud & Misconduct

July 14, 2017

details of the experiments. A number of misconduct cases have been detected with just a few questions (Vastag,
2006).

Rule 2: Hack your results

If you are reluctant to manipulate your data, you still have the option of searching through your results to find
anything that reaches significance (a.k.a. p-hacking). This can provide an appealing alternative to scientific mis-
conduct. What is the p value of your NHST (Null Hypothesis Significance Test)? If it’s close to your field’s
standard, one of the many qualification proposed by Matthew Hankins might just do the trick. Can’t you use
expression such as nearly acceptable level of significance (p=0.06), very closely brushed the limit of statistical sig-
nificance (p=0.051) or weakly statistically significant (p=0.0557)? While these statements don’t make much sense,
they might be sufficient to convince a naive reviewer or reader.

If you’re suffering from a bi-polar p-value disorder (a term coined by Daniel Lakens), you’ll want to reach the
magical 0.05 threshold. It might be much easier than you think to portray your data as significant! The correct
method for calculating the infamous p-value is barely understood by many students, teachers, and researchers
(Haller & Krauss, 2002; Lecoutre, Poitevineau, & Lecoutre, 2003). The current situation is so bad that the American
Statistical Association had to release a statement to explain p’s correct usage (Wasserstein & Lazar, 2016); Nature
has issued a warning as well (Baker, 2016). Consequently, before hacking your results, it might be wise to re-
read your classics (Simmons, Nelson, & Simonsohn, 2011; Cumming, 2012b, 2012a; Colquhoun, 2014). A warning
for those of you in psychology: you have to take extra-precaution because this field has drawn attention for
the unusual distribution of p-values smaller than 0.05 (Hartgerink, van Aert, Nuijten, Wicherts, & van Assen,
2016; Bakker, van Dijk, & Wicherts, 2012). There’s now software called statcheck that can be used to recalculate
the p values in your paper (Nuijten, Hartgerink, van Assen, Epskamp, & Wicherts, 2015; Epskamp & Nuijten,
2016), making it difficult to get away with misleading statistics. Although some have called checking the results
of others methodological terrorism (Finske, 2016), it might be enough to scare some away from the dark side of
Science.

Rule 3: Copy/paste from others

It’s not enough to have (fake) results; you still need to publish them if you want to gain fame (and tenure, and
grants). Writing is a tedious task and can be a fair amount of work. Summarizing the state of the art in your
field will force you to actually read about what your colleagues have been doing over the past few years. It is
a very time consuming task. But in doing that reading, you may find that one of these colleagues wrote a nice
introduction to the field or a wonderful summary of its current state. If so, why bother writing a new one? It’s
much simpler to copy/paste what he/she has written. Plagiarism is the nuts and bolts of scientific misconduct
(Neuroskeptic, 2017), be it literal copying, substantial copying or paraphrasing (see definitions from Elsevier and
the committee on publication ethics’ (COPE) procedure for handle plagiarism in a submitted or published article).
Of course, you cannot literally take an excerpt from an article to insert it in yours. You’d run the risk of creat-
ing a situation where the reviewer found his own text in yours. Consequently, if you really intend to plagiarize,
you’ll need to transform the text drastically to avoid detection by humans (Dorigo, 2015) and more importantly,
to avoid detection by dedicated software (e.g. iThenticate). This software is used by universities and journals for
tracking people just like you. As the databases behind these services grow, plagiarism is becoming harder and
harder. Even self-plagiarism is not allowed by a vast majority of scientific journals. All of this means that you
have to be really innovative in your plagiarism techniques (Long, Errami, George, Sun, & Garner, 2009). We’ve
reached the point where writing your own text might be an easier option.

Rule 4: Write your own peer-review

Even if you avoid all the pitfalls discussed above, you’re not in the clear yet. Depending on the journal you
target, you may still encounter problems with the review process. If reviewers are picky, they may ask annoying
questions, request more information or experiments, ask for a major revision and/or reject your submission
entirely. Can you imagine how this would make you feel after all your hard work fabricating the data and
plagiarized the article? There’s even the risk that they’ll notice your malpractice. Fortunately, there is a simple
solution: write your own review!

It is surprisingly easy to do. As you submit, you will often be asked to give name of possible reviewers. Just
provide phony names, along with email addresses that will be redirected to your mailbox. You will soon receive
an invitation to review your own work, and you’re then free to state how brilliant your own work is. Of course,

2

Rougier & Timmer • Ten Simple Rules for Scientific Fraud & Misconduct

July 14, 2017

you’ll have to write a review that looks like an actual review. If you’re Machiavellian, you can introduce some
factual errors in your manuscript, then report them in your review, making it look thorough. Make sure not
to send you review before the deadline because as reported by Elizabeth Wager (Stigbrand, 2017), editors have
spotted fake reviews in part because reviewers responded promptly. Unfortunately, editors and publishers are
now aware of the scam (Ferguson, Marcus, & Oransky, 2014) and have taken counter-measures (Haug, 2015).
For example, some of them no longer offer authors the option of recommending reviewers or if they do, the
recommendation is restricted to a list of certified reviewers. If you insist on writing your own peer-review, you’ll
have to be creative and find new ways to game the system.

Rule 5: Take advantage of predatory publishers

If you’re worried that peer review will reveal your misconduct, you still have opportunities for publishing your
results. There are many predatory publishers on the internet (Shen & Bj¨ork, 2015). These predators will publish
just anything (see “Get Me Off Your Fucking Mailing List” in the International Journal of Advanced Computer
Technology (2005, 2014)) and you have a 100% chance of publication with a lighting fast review - less than
24h for some journals. Finding a predatory publisher used to be easy thanks to a list created and maintained
by Jeffrey Beal. Although not all researchers (and publishers) agreed with his categorization, this list provided
an incredibly useful resource. Unfortunately, Beal’s list was shut down just a few months ago (Straumsheim,
2017) and the soon-to-be released replacement one will not be free (Silver, 2017). Still, you can take advantage
of the Think/Check/Submit website, which provides a easy-to-use checklist that researchers can refer to when
they are investigating whether a journal is trustworthy. You’ll obviously just want take the opposite of their
sage recommendations — like making sure not to pick a journal from the list of the Open Access Scholarly
Publishers Association since these journals have been thoroughly reviewed and can be trusted. Other anti-tips
include finding a journal that none of your colleagues know about, looking for an editorial board that’s made
of unknown or non-existent people (Sorokowski, Kulczycki, Sorokowska, & Pisanski, 2017) or dogs (Kennedy,
2017), and finding a publisher without any address / email / telephone number. Of course, you will have to pay
exorbitant fees to have your work published, but this is the price to pay to have an expedited and complacent
review, assuming there’s any review at all. Before making you decision where to publish, make sure to check for
the retraction fees, which may be much higher than the initial publishing fees in some cases. But who wants to
retract anyway?

Rule 6: Don’t give access to your code and data

You managed to have your article published, congratulations! You’ll probably feel a bit of a buzz, and your
astonishing conclusion may draw some newspaper headlines if your research is sexy enough. Don’t get too
excited about this, though. Attention means an increased chance that other researchers will start asking to
access your material, assuming the publisher has not already requested it prior to publication. Of course, that’s
very bad news for you if your data has been fabricated or if your statistical analysis is not really academic. You
definitely cannot give others access to your raw if it doesn’t exist! Fortunately, researchers have been avoiding
sharing their data for decades, and the same old reasons still apply (Roche et al., 2014): “Oh you know, my
data cannot be anonymized”; “You would not understand the structure of my data”; “A lot of money has been
invested, I cannot give it for free”; etc. You can even tell anyone asking for your data that they are a research
parasite (Longo & Drazen, 2016) although that approach seems to have drawn some unwanted attention (http:
//researchparasite.com). Technological excuses might also be worth a try. When (Collberg et al., 2014; Collberg,
Proebsting, & Warren, 2015) tried to access the code used in several publications, they get some really great
answers: “Too busy to help”; “Code will be available soon”; “Bad backup practice”; etc. Just pick one you like.
With the increasing pressure by funding bodies (NIH, NSF, Europe, etc) to share data, it might be good to pretend
(and only pretend) to be a supporter of Open Data by inserting a simple “data available upon request” or “data
is available from my website”. This does not come close to meeting the FAIR principles (findable, accessible,
inter-operable, re-usable, Wilkinson et al., 2016), but who cares if you can give the illusion you’re not afraid of
sharing your data? Don’t get us wrong, though - you will never answer a request, and the data will never appear
on your website.

Rule 7: Do not allow for replication outside your lab

Here comes the tricky part: replication. It may surprise you, but some researchers may want to replicate your
results using the methods explained in your article. (Open Science Collaboration, 2015) replicated 100 experi-

3

Rougier & Timmer • Ten Simple Rules for Scientific Fraud & Misconduct

July 14, 2017

ments reported in three high-ranking psychology journal. Or tried, at least; they concluded that some experi-
ments were not replicable at all. There are even scientific journals that are now dedicated to replications (e.g.
http://rescience.github.io).

If people try to replicate your work and do not get the same results, you have a problem. They may insist on
seeing your actual data and, if you refuse, you might be suspected of fraud or misconduct. You can try rule 6, but
if there are several failed replications, it will be much harder to deny access to your data. One easy way to avoid
this sort of disaster is to claim in your article that the experiment/study has been already replicated in your lab.
The subliminal message to the reader is “Don’t bother to replicate this, we’ve already taken care of that and it
works, believe us. Don’t waste your time, you will thank us later”. If this doesn’t work, you can also try issuing a
Do Not Replicate order as proposed by Matthew Hankins (who is kind enough as to provide a template). It is not
yet widely used , but with the replication crisis we’re facing, we’re confident it will soon become popular.

Rule 8: Never, ever, retract your results

If you’ve made a genuine (and big) mistake in your work, there is no problem in asking for the retraction of
your paper (Miller, 2006). It’s a behavior that is actually rewarded according to (Lu, Jin, Uzzi, & Jones, 2013)
(positive citation benefits for prior work), even though in some cases, it can take several years (Trivers, Palestis,
& Zaatari, 2009). However, if you’ve been engaged in fraud, having your paper retracted is like an admission of
guilt. It’s something to be avoided. Retraction could start with a simple comment to the editor saying there may
be a problem with you paper. If you’re lucky, the comment will never be published (Trebino, 2009). Otherwise,
you’ll have to give a convincing answer, or the editor could decide to retract your paper without your consent.
So it’s critical to act quickly, defusing the crisis with a simple corrigendum admitting a bad - but not fatal - error
during preparation of the publication. Don’t hesitate to publish as many corrigendum as necessary to make
critics happy. You can drag this out for several years, which is hopefully enough time for people to forget about
the issues.

Rule 9: Don’t get caught. Deny if caught.

If you intend to persist in a rogue scientific career, you have to be aware that you’re likely to get caught sooner or
later. The number of researcher to have never been caught is probably low; only the best can hope to be caught
only after their death (De Groote et al., 2016). But being caught while you’re still breathing does not mean you
career will come to an end. There is a set of simple rules to follow if you need to deny scientific misconduct:

• If you’re first author, explain you were supervised by the last author and had no choice.

• If you’re last author, explain you were not aware of the misconduct of the first author.

• If your name is not first nor last, claim that you didn’t even know your name appeared in the publication.

• If your name appears because of gift authorship, just admit it. It might be considered misconduct, but fraud

is much worse.

• The intern, who cannot be contacted because he/she left academia, is responsible for everything

• Send threatening letters to those who have spotted your misconduct

• Follow through on those threats and sue’em all

If you’re lucky enough, one of the above will work and things should be back to normal. All of this is easier, of
course, if you’re supported by you employer because you’ve been labeled a rising star.

Rule 10: Be creative (for once)

If you look at the annual list of top ten retractions compiled by Adam Marcus and Ivan Oransky (co-founders
of the RetractionWatch), you’ll realize that all the tactics mentioned above are already quite well known by the
research community. If you want to stay off the radar while committing fraud and misconduct, you’ll want to be
creative and invent your own rules.

4

Rougier & Timmer • Ten Simple Rules for Scientific Fraud & Misconduct

July 14, 2017

Conclusion

By following the simple rules above, you should get scientific glory if only temporarily. The downside is that
it could be followed by jail time (Grant, 2015). A former researcher has been sentenced to 57 months jail and
to pay-back 7.2 millions dollars. Science has been and is still poisoned by fraud and misconduct, but it is now
fighting back with increasingly high-tech tools (Buranyi, 2017). Today, the risks that come when you engage in
fraud and misconduct are really high, and the chances of being caught have gone up. So you’d better think twice
before committing misconduct, or your name will soon appear in Wikipedia’s hall of shame.

References

Aschwanden, C. (2015). Science Isn’t Broken. It’s just a hell of a lot harder than we give it credit for. FiveThirthyEight. Retrieved

from https://fivethirtyeight.com/features/science-isnt-broken/

Baker, M. (2016). Statisticians issue warning over misuse of p values. Nature, 531(7593), 151–151. doi:10.1038/nature.2016.19503
Bakker, M., van Dijk, A., & Wicherts, J. M. (2012). The rules of the game called psychological science. Perspectives on Psycho-

logical Science, 7(6), 543–554. doi:10.1177/1745691612459060

Buranyi, S. (2017). The hi-tech war on science fraud. The Guardian. Retrieved from https://www.theguardian.com/science/

2017/feb/01/high-tech-war-on-science

Collberg, C., Proebsting, T., Moraila, G., Shankaran, A., Shi, Z., & Warren, A. M. (2014). Measuring reproducibility in computer

systems research.

Collberg, C., Proebsting, T., & Warren, A. M. (2015). Repeatability and benefaction in computer systems research — a study

and a modest proposal.

Colquhoun, D. (2014). An investigation of the false discovery rate and the misinterpretation of p-values. Royal Society Open

Cromey, D. W. (2012). Digital images are data: And should be treated as such. In Methods in molecular biology (pp. 1–27).

Science, 1(3), 140216–140216. doi:10.1098/rsos.140216

Humana Press. doi:10.1007/978-1-62703-056-4 1

Cumming, G. (2012a). Mind your confidence interval: How statistics skew research results. The Conversation. Retrieved from

https://theconversation.com/mind-your-confidence-interval-how-statistics-skew-research-results-3186

Cumming, G. (2012b). Understanding the new statistics: Effect sizes, confidence intervals, and meta-analysis. New York: Rout-

ledge.

De Groote, I., Flink, L. G., Abbas, R., Bello, S. M., Burgia, L., Buck, L. T., Dean, C., Freyne, A., Higham, T., Jones, C. G., Kruszynski,
R., Lister, A., Parfitt, S. A., Skinner, M. M., Shindler, K., & Stringer, C. B. (2016). New genetic and morphological evidence
suggests a single hoaxer created ‘piltdown man’. Royal Society Open Science, 3(8), 160328. doi:10.1098/rsos.160328

Dorigo, T. (2015). Fighting plagiarism in scientific papers. Retrieved from http://www.science20.com/a quantum diaries

survivor/fighting plagiarism in scientific papers-154460

Epskamp, S. & Nuijten, M. B. [Michele B.]. (2016). Statcheck: Extract statistics from articles and recompute p values. R Package.

Retrieved from http://CRAN.R-project.org/package=statcheck

Ferguson, C., Marcus, A., & Oransky, I. (2014). Publishing: The peer-review scam. Nature, 515(7528), 480–482. doi:10.1038/

515480a

Finske, S. T. (2016). A call to change science’s culture of shaming. Association for Psychological Science. Retrieved from

http://www.psychologicalscience.org/observer/a-call-to-change-sciences-culture-of-shaming

Grant, B. (2015). Vaccine fraudster gets jail time. The Scientist. Retrieved from http://www.the-scientist.com/?articles.view/

articleNo/43456/title/Vaccine-Fraudster-Gets-Jail-Time/

Haller, H. & Krauss, S. (2002). Misinterpretations of significance: A problem students share with their teachers? MPR-online,

7(1). Retrieved from https://www.dgps.de/fachgruppen/methoden/mpr-online/issue16/art1/article.html

Hartgerink, C. H., van Aert, R. C., Nuijten, M. B., Wicherts, J. M., & van Assen, M. A. (2016). Distributions of p-values smaller

than .05 in psychology: What is going on? PeerJ, 4, e1935. doi:10.7717/peerj.1935

Haug, C. J. (2015). Peer-review fraud — hacking the scientific publication process. New England Journal of Medicine, 373(25),

2393–2395. doi:10.1056/nejmp1512330

Hendricks, M. (2011). Scientific integrity in the age of photoshop. Retrieved from http://www.hopkinsmedicine.org/institute

basic biomedical sciences/news events/articles and stories/employment/2011 01 scientific integrity.html

Hsu, C.-M., Lee, J.-C., & Chen, W.-K. (2015). An efficient detection algorithm for copy-move forgery. In 10th Asia Joint Con-

ference on Information Security. IEEE. doi:10.1109/asiajcis.2015.16

Kennedy, K. (2017). This dog sits on seven editorial boards. Atlas Obscura. Retrieved from http://www.atlasobscura.com/

articles/olivia-doll-predatory-journals

Lecoutre, M.-P., Poitevineau, J., & Lecoutre, B. (2003). Even statisticians are not immune to misinterpretations of null hypoth-

esis significance tests. International Journal of Psychology, 38(1), 37–45. doi:10.1080/00207590244000250

Long, T. C., Errami, M., George, A. C., Sun, Z., & Garner, H. R. (2009). Responding to possible plagiarism. Science, 323(5919),

1293–1294. doi:10.1126/science.1167408

Longo, D. L. & Drazen, J. M. (2016). Data sharing. New England Journal of Medicine, 374(3), 276–277. doi:10.1056/nejme1516564
Lu, S. F., Jin, G. Z., Uzzi, B., & Jones, B. (2013). The retraction penalty: Evidence from the web of science. Scientific Reports,

3(1). doi:10.1038/srep03146

5

Rougier & Timmer • Ten Simple Rules for Scientific Fraud & Misconduct

July 14, 2017

Matejka, J. & Fitzmaurice, G. (2017). Same stats, different graphs. In Proceedings of the 2017 CHI conference on human factors

in computing systems - CHI ’17. ACM Press. doi:10.1145/3025453.3025912

Miller, G. (2006). A scientist’s nightmare: Software problem leads to five retractions. Science, 314(5807), 1856–1857. doi:10 .

1126/science.314.5807.1856

Neuroskeptic. (2017). Science has a plagiarism problem. Retrieved from http://blogs.discovermagazine.com/neuroskeptic/

2017/02/03/science-plagiarism-problem/

Nuijten, M. B. [Mich`ele B.], Hartgerink, C. H. J., van Assen, M. A. L. M., Epskamp, S., & Wicherts, J. M. (2015). The prevalence of
statistical reporting errors in psychology (1985–2013). Behavior Research Methods, 48(4), 1205–1226. doi:10.3758/s13428-
015-0664-2

Open Science Collaboration. (2015). Estimating the reproducibility of psychological science. Science, 349(6251). doi:10.1126/

science.aac4716

Raschke, R. L. & Steinbart, P. J. (2008). Mitigating the effects of misleading graphs on decisions by educating users about the

principles of graph design. Journal of Information Systems, 22(2), 23–52. doi:10.2308/jis.2008.22.2.23

Roche, D. G., Lanfear, R., Binning, S. A., Haff, T. M., Schwanz, L. E., Cain, K. E., Kokko, H., Jennions, M. D., & Kruuk, L. E. B.
(2014). Troubleshooting public data archiving: Suggestions to increase participation. PLoS Biology, 12(1), e1001779.
doi:10.1371/journal.pbio.1001779

Rossner, M. & Yamada, K. M. (2004). What’s in a picture? the temptation of image manipulation. The Journal of Cell Biology,

Rougier, N. P., Droettboom, M., & Bourne, P. E. (2014). Ten simple rules for better figures. PLoS Computational Biology, 10(9),

166(1), 11–15. doi:10.1083/jcb.200406019

e1003833. doi:10.1371/journal.pcbi.1003833

Sch¨onbrodt, F. D. (2015). Train your p-hacking skills! Retrieved from http://shinyapps.org/apps/p-hacker/
Shen, C. & Bj¨ork, B.-C. (2015). ‘Predatory’ open access: a longitudinal study of article volumes and market characteristics.

BMC Medicine, 13(1). doi:10.1186/s12916-015-0469-2

Silver, A. (2017). Pay-to-view blacklist of predatory journals set to launch. Nature. doi:10.1038/nature.2017.22090
Simmons, J. P., Nelson, L. D., & Simonsohn, U. (2011). False-positive psychology. Psychological Science, 22(11), 1359–1366.

doi:10.1177/0956797611417632

Sorokowski, P., Kulczycki, E., Sorokowska, A., & Pisanski, K. (2017). Predatory journals recruit fake editor. Nature, 543(7646),

481–483. doi:10.1038/543481a

Stigbrand, T. (2017). Retraction note to multiple articles in tumor biology. Tumor Biology. doi:10.1007/s13277-017-5487-6
Straumsheim, C. (2017). No more ’beall’s list’. Inside Higher Ed. Retrieved from https://www.insidehighered.com/news/2017/

01/18/librarians-list-predatory-journals-reportedly-removed-due-threats-and-politics

Timmer, J. (2012). Epic fraud: How to succeed in science (without doing any). Ars Technica. Retrieved from https://arstechnica.

com/science/2012/07/epic-fraud-how-to-succeed-in-science-without-doing-any/

Trebino, R. (2009). How to publish a scientific comment in 123 easy steps. Retrieved from http://frog.gatech.edu/Pubs/How-

to-Publish-a-Scientific-Comment-in-123-Easy-Steps.pdf

Trivers, R., Palestis, B. G., & Zaatari, D. (2009). The Anatomy of a Fraud: Symmetry and Dance. TPZ Publishers.
Vastag, B. (2006). Cancer fraud case stuns research community, prompts reflection on peer review process. JNCI Journal of

the National Cancer Institute, 98(6), 374–376. doi:10.1093/jnci/djj118

Wainer, H. (1984). How to display data badly. The American Statistician, 38(2), 137–147. doi:10.1080/00031305.1984.10483186
Wasserstein, R. L. & Lazar, N. A. (2016). The ASA’s Statement on p-Values: Context, Process, and Purpose. The American

Statistician, 70(2), 129–133. doi:10.1080/00031305.2016.1154108

White, C. (2007). Software makes it easier for journals to spot image manipulation. BMJ, 334(7594), 607–607. doi:10.1136/bmj.

39160.666204.bd

Wilkinson, M. D., Dumontier, M., Aalbersberg, I. J., Appleton, G., Axton, M., Baak, A., Blomberg, N., Boiten, J.-W., da Silva
Santos, L. B., Bourne, P. E., Bouwman, J., Brookes, A. J., Clark, T., Crosas, M., Dillo, I., Dumon, O., Edmunds, S., Evelo,
C. T., Finkers, R., Gonzalez-Beltran, A., Gray, A. J., Groth, P., Goble, C., Grethe, J. S., Heringa, J., Hoen, P. A. ’., Hooft, R.,
Kuhn, T., Kok, R., Kok, J., Lusher, S. J., Martone, M. E., Mons, A., Packer, A. L., Persson, B., Rocca-Serra, P., Roos, M.,
van Schaik, R., Sansone, S.-A., Schultes, E., Sengstag, T., Slater, T., Strawn, G., Swertz, M. A., Thompson, M., van der Lei,
J., van Mulligen, E., Velterop, J., Waagmeester, A., Wittenburg, P., Wolstencroft, K., Zhao, J., & Mons, B. (2016). The FAIR
guiding principles for scientific data management and stewardship. Scientific Data, 3, 160018. doi:10.1038/sdata.2016.18

6

