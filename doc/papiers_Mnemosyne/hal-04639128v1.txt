Contextual Control of Hopfield Networks in a Hippocampal Model Hugo
Chateau-Laurent, Frédéric Alexandre

To cite this version:

Hugo Chateau-Laurent, Frédéric Alexandre. Contextual Control of Hopfield
Networks in a Hip- pocampal Model. COGSCI 2024 - 46th Annual Conference
of the Cognitive Science Society, Jul 2024, Rotterdam, Netherlands.
￿hal-04639128￿

HAL Id: hal-04639128

https://hal.science/hal-04639128

Submitted on 8 Jul 2024

HAL is a multi-disciplinary open access archive for the deposit and
dissemination of sci- entific research documents, whether they are pub-
lished or not. The documents may come from teaching and research
institutions in France or abroad, or from public or private research
centers.

L’archive ouverte pluridisciplinaire HAL, est destinée au dépôt et à la
diffusion de documents scientifiques de niveau recherche, publiés ou
non, émanant des établissements d’enseignement et de recherche français
ou étrangers, des laboratoires publics ou privés.

Distributed under a Creative Commons Attribution 4.0 International
License

Contextual Control of Hopfield Networks in a Hippocampal Model

Hugo Chateau-Laurent (hugo.chateaulaurent@gmail.com) Inria centre at the
university of Bordeaux, Neurodegenerative Diseases Institute

Fr´ed´eric Alexandre (frederic.alexandre@inria.fr) Inria centre at the
university of Bordeaux, Neurodegenerative Diseases Institute

Abstract

Executive functions guide episodic memory to retrieve infor- mation
essential for adaptive behavior. The prefrontal cortex achieves this by
influencing hippocampal processing through anatomical projections
targeting the entorhinal cortex and area CA1. However, most
computational models of the hippocam- pus overlook this cognitive
control, either neglecting it or im- plementing implausible direct
connections to the hippocam- pus. This paper explores the contextual
control of associative memory implemented by modern Hopfield networks,
within a hippocampus-inspired autoencoder. Our experiments under- score
the importance of proximity between prefrontal affer- ences and the
locus of memory storage for efficient contex- tual modulation of
episodic memory, challenging the standard model of hippocampal
processing. These findings not only advance our understanding of
higher-level cognition but also provide design principles for more
adaptive machine learning algorithms. Keywords: Episodic memory;
cognitive control; hippocam- pus; prefrontal cortex; modern Hopfield
networks; computa- tional neuroscience

Introduction Efficient behavioral guidance relies on the selective
recall of memories pertinent to the current context. This process is in-
tricately shaped by the dynamic interplay between contextual and sensory
information. Contextual information, encom- passing internal
representations beyond immediate percep- tion, is instrumental in
predicting future rewards and states. It includes temporal event
sequences, spatial integration, and overarching goals. While substantial
research has focused on stimulus-driven memory retrieval, the modulation
of episodic memory recall by contextual factors remains less explored.
Understanding these mechanisms is crucial not only for ad- vancing
episodic memory theory but also for developing ma- chine learning
algorithms capable of navigating diverse spa- tiotemporal contexts
flexibly.

The prefrontal cortex is known to guide the recall of rel- evant
memories in the hippocampus (Eichenbaum, 2017). However, in what has
been termed the standard model (Nadel & Moscovitch, 1997) or standard
framework (Cheng, 2013), episodic memories in the hippocampus are stored
in a re- gion called CA3, which lacks a direct connection from the
prefrontal cortex (Andrianova et al., 2023). This raises a fundamental
question about how the prefrontal cortex in- fluences memory retrieval
in CA3. In a modeling study (Pilly, Howard, & Bhattacharyya, 2018),
contextual informa- tion was fed to the dentate gyrus to modulate
recall. This

is at odds with prefrontal projections which are thought to terminate in
the entorhinal cortex (Eichenbaum, 2017) and potentially reach
downstream layer CA1 through the tha- lamus (Anderson, Bunce, & Barbas,
2016). The aim of this paper is to study how prefrontal signals can
modulate memory through the entorhinal cortex or CA1. An autoen- coder
artificial neural network is used to model the entorhi- nal–hippocampal
circuit. A layer representing the prefrontal cortex sends context to one
of the autoencoder layers (tar- get of prefrontal afferences). A modern
Hopfield network (Ramsauer et al., 2020) is placed in one of the
hippocampal layers and used to recall the closest state of that layer,
mim- icking the storage of episodic memory, by taking into account
sensory and context information. Performance and contextual
representations are studied based on the position of the Hop- field
memory relative to the target. As the results challenge the current view
of episodic storage, the implications for the standard model are
discussed in the last section.

Methods

Task Like the model of Pilly et al. (2018), our model performs the tasks
described in Peters, David, Marcus, and Smith (2013). In these tasks,
object-discrimination problems are presented in two different contexts
and used to evaluate context-guided memory recall. In a given task ti
and context c, the network learns to choose a rewarded object Ri,c over
a non-rewarded object ¯Ri,c. In the alternative context c′, it learns to
choose between the same objects as in context c, except that the non-
rewarded object in context c is rewarded in c′, and conversely i ).
Objects are represented in the (i.e. network as 6 × 4 matrices with 6
active entries of value 1 placed at random locations, and other entries
with value 0 (Figure 1).

i = Rc′ ¯Rc

i and Rc

i = ¯Rc′

Model The model is composed of an autoencoder, a modern Hopfield
associative memory, and a prefrontal layer (Figure 2).

The autoencoder is a multi-layered fully-connected neural network which
follows the anatomy of the medial temporal lobe. The input is first sent
to the entorhinal cortex, then flows to CA1 through a trisynaptic
pathway (ECII −→ DG −→ CA3 −→ CA1) and a monosynaptic pathway (ECIII −→
CA1). In- formation is sent from CA1 to ECV, then flows to the output

Table 1: Layers (sizes and activation functions) of the autoen- coder.
The “Objects” input and output size corresponds to the product of the
number, width and height of input patterns.

Layer Context Input Objects Input ECII ECIII DG CA3 CA1 ECV Objects
Output Context Output

Function

Output size 2 3 × 6 × 4 110, 000α ReLU 250, 000α ReLU 1, 200, 000α ReLU
250, 000α ReLU 390, 000α ReLU 330, 000α ReLU 3 × 6 × 4 2

sigmoid sigmoid

Simulation Details

Pretraining Phase All task-context combinations are pre- sented once
during each epoch, in random order. Learning is online, as training
examples are presented one by one. Simi- larly to the recently proposed
autoencoder model of the hip- pocampus (Santos-Pata et al., 2021), the
network learns to output its input, namely the two input object patterns
and the rewarded one, as well as the context vector (unless otherwise
mentioned). This is done by updating feedforward autoen- coder weights
using backpropagation, in a pretraining phase. The loss function to be
minimized is the mean squared error between the input and the output.
Acquisition Phase Subsequently, in the acquisition phase, the weights of
the autoencoder are fixed and memories are stored in the associative
memory. Two training regimes are used to assess the need for the fast
associative memory: one- shot and many-shot. In the many-shot regime,
pretraining lasts 20 epochs with 50 tasks. The same 50 tasks are then
acquired in the memory and used to test performance. Con- trastingly, in
the one-shot regime akin to episodic memory, pretraining lasts a single
epoch with 1000 tasks, such that net- works are updated as many times as
in the many-shot regime. In the acquisition phase of the one-shot
regime, 50 novel tasks are presented to the network for memory
acquisition, then used to test performance. Hence, in the one-shot
regime, the autoencoder weights are not trained with the
acquisition/test tasks. Test Phase While the rewarded pattern is
provided as input to the network during the pretraining and training
phases, it is masked during test (i.e. values of the third input slot
are set to 0). In the test phases, a trial is considered correct when
the pattern stored in the third slot of the output is closer to the
rewarded pattern than the non-rewarded one, as assessed by the mean
squared error (Figure 1). Thus, the expected per- formance of a random
network, or a network with no contex- tual target, is 50% and serves as
baseline. The learning rate

Figure 1: Example tasks in which the model succeeds (first two rows) and
fails (last two rows) to recall the correct mem- ory during the test
phase. The two choice patterns that are placed in the first slots of the
input are shown on the left. The rewarded patterns of contexts c and c′
are shown in the middle. On the right, the choice of the network (i.e.
third slot of the output) is shown for both contexts. In the first two
tasks, the output of the network successfully corresponds to the
rewarded pattern in both contexts. In the third task, how- ever, the
network chooses the same pattern in both contexts In the fourth task,
the and thus fails to complete the task. network outputs the correct
pattern in context c but outputs a pattern that is not in the choice set
for that task in c′. The trial is incorrect as the output is closer to
¯Rc′ i . For these i examples, the network was pretrained on 10000 tasks
with a learning rate of 10−4.5.

than Rc′

layer. ReLU is used as the activation function of hidden layers and
sigmoid is used in the output layer (Table 1). The number of neurons in
each region is set as the number of neurons in the analog rat region, as
retrieved from Cutsuridis, Graham, Cobb, and Vida (2019), scaled down by
a factor α = 0.003. The network input is the concatenation of the two
patterns of the choice objects and the pattern of the rewarded object
(hidden during test). The assignment of objects Rc i to the first or
second slot is random to prevent the network from learning to always
output the same slot. An additional input, corresponding to the
prefrontal cortex, is used to modulate recall contextually (Figure 2).
It represents the two possible contexts as a two-dimensional one-hot
vector. When a layer is targeted by this contextual layer, this simply
means that it receives it as an additional input.

i and ¯Rc

One of the hippocampal layers can be paired with a mod- ern Hopfield
network. During the acquisition phase described in the next section, the
activity vectors of that layer are ap- pended to an autoassociative
memory matrix X. During the test phase, the activity of the layer, say
a, is replaced by the output of the Hopfield network a∗:

a∗ = Xsoftmax(βX⊤a),

(1) 

where β is set to 1,000 to strongly separate memories. The
memory-augmented activity a∗ is then sent to the next layers of the
autoencoder.

Pattern 1Pattern 2Inputcc’RewardedTaskscc’OutputFigure 2: Architecture
of the model consisting of an autoencoder (green), an associative memory
(blue) and a prefrontal cortex layer targeting the autoencoder with
context information (red). The autoencoder is trained to output its
input and the context when indicated. The associative memory is modified
during the acquisition phase, and used to recall memories during the
test phase. In the standard model of the hippocampus, memory is in CA3
(strong blue), but other locations are also tested here (transparent
blue). Similarly, context information can target various layers
(transparent red), but the current view is that the prefrontal sends
context to the entorhinal cortex (Eichenbaum, 2017) or to CA1 (Anderson
et al., 2016), as shown in strong red.

is a sensitive parameter, as its optimal value varies among the
conditions tested in this work. Therefore, for each tested condition,
the learning rate is set as the average of the five learning rates that
best performed during a random search. This purely stochastic
optimization process evaluated the per- formance of the model in each
condition, with 300 random learning rate values. After this process, 50
different simula- tions were performed with the optimal learning rate of
each condition.

Results

Behavioral Performance The need for associative memory is first assessed
to ensure that the tasks require episodic processing. With the many-
shot regime, a one-tailed t-test comparing the performance with Hopfield
memory in CA3 (M = 65.06% correct, SD = 7.85) and without modern
Hopfield network (M = 70.64%, SD = 4.05) indicates that the models can
perform the tasks overall, but that associative memory slightly impairs
perfor- mance with this training regime (t(49) = −4.97, p < .001). On
the other hand, with the one-shot regime akin to episodic memory,
results with CA3 memory (M = 75.06%, SD = 4.64) and without modern
Hopfield network (M = 49.54%, SD = 3.19) indicate that memory is
necessary when test tasks are not used to pretrain the autoencoder
(one-tailed t(49) = 34.89, p < .001). This demonstrates that the
encoding and recall operations of modern Hopfield networks can take con-
text into account. In these conditions, CA3 is directly tar- geted by
context information. To test whether the model can perform the task in
accordance with the anatomical review of (Eichenbaum, 2017), context
information is then provided to entorhinal layers which receive
prefrontal projections in the biological brain. The performance with
entorhinal tar- get (M = 51.06%, SD = 3.05) and CA3 target (M = 75.06%,

SD = 4.64) indicate that the model is much less performant when context
information is given to the entorhinal cortex (one-tailed t(49) = 28.2,
p < .001), and performs almost no better than chance (Figure 3).

When the dentate gyrus is the memory-augmented layer, the performance
when the entorhinal cortex is targeted (M = 70.68%, SD = 4.49) and when
the dentate gyrus is directly targeted (M = 71.44%, SD = 4.7) indicate
that performance is not significantly impaired when targeting entorhinal
lay- ers (one-tailed t(49) = 1.12, p = .13), as shown in Figure 3.
Similarly, when the associative memory is in CA1, the model performs
well when context is provided to upstream layers (Figure 3). When
superficial layers of the entorhinal cortex are targeted and memory is
in CA1, the performance of the model with the monosynaptic pathway (M =
70.14%, SD = 4.71) and without it (M = 56.28%, SD = 4.05) indicate that
this pathway is necessary to convey context information to the memory
(one-tailed t(49) = 17.55, p < .001), as shown in Figure 3. By combining
results of when the dentate gyrus, CA3 or CA1 (no monosynaptic pathway
for simplicity) is memory-augmented, it is possible to evaluate
performance according to the position of the targeted layer relative to
the position of the memory layer. This analysis reveals that tar- geting
regions downstream memory has no effect (Figure 4). Spearman’s rank
correlation was computed to assess the rela- tionship between the
relative position of the target (restricted to relative positions less
than or equal to 0) and performance. There was a positive correlation
between the two variables, r(898) = 0.78, p < .001. Furthermore, a
two-way ANOVA was performed to evaluate the interaction effects of
relative position (less than or equal to 0) and context reconstruction
on performance. Without context reconstruction, only the sensory
(objects) input is taken into consideration in the au- toencoder loss.
The results indicated a significant main effect

ContextDGECIIContextContextContextContextMemoryCA3CA1ECVOutputInputECIIIXTXMemoryXTXMemoryXTXContexttrisynaptic
pathwaymonosynapticpathwayfor relative position (F(3, 899) = 545.59, p
< .001), main ef- fect for context reconstruction (F(1, 899) = 24.29, p
< .001), and interaction between relative position and context recon-
struction (F(3, 899) = 9.06, p < .001). Figure 4 indeed shows that the
steepness of performance decline, as target is located more and more
upstream memory, is greater when the model only tries to reconstruct
sensory input than when it also tries to reconstruct context information
in the pretraining phase.

The presence of context-modulated cells is very likely to help the model
performing the tasks. In order to ensure that context cells indeed have
causal influence on behavioral per- formance and the contextual
separation of activity, inactiva- tion experiments are performed. Since
prefrontal information can hardly reach CA3 when the the entorhinal
cortex is tar- geted, the associative memory is placed in DG. After the
test phase, 1664 context cells were identified in DG (46%). This might
not seem a lot compared to the proportion in CA3, but since DG is bigger
than CA3, this represents many more neu- rons and is enough to separate
contexts much better than CA3 in the principal component space (not
shown). After identifi- cation, the DG context cells were inactivated
during an addi- tional test phase by clamping their activity to 0 in all
50 test tasks. With this protocol, the contexts are no longer separated
in the principal component space (Figure 7), as compared to when 1664
neurons are randomly selected for inactivation instead (Figure 8).
Furthermore, while random inactivation yielded 72% correct answers
(similar to results of Figure 3), performance dropped to 52% when
context cells were inacti- vated.

Figure 4: Performance as a function of the location of the target
relative to the associative memory, using sensory only and full
reconstruction losses. No monosynaptic pathway was used with CA1 memory
for clarity. Relative positions P and -P indicate that the target and
the memory are P layers apart. The target is located before the memory
with -P, and after with P. The gray dashed line indicates the baseline
perfor- mance of 50%.

Neural Coding of Context

In order to understand how the model either succeeds or fails at
performing the task, the representations employed in the different
layers can be analyzed. First, a model with CA3 memory and entorhinal
target is used. After pretraining and acquisition, principal component
projections reveal that con- texts are well separated at the targeted
ECII population (Fig- ure 5), but this separation diminishes in
downstream layer CA3 (Figure 6), to such an extent that the associative
mem- ory in CA3 is not able to separate memories contextually (not
shown). Downstream layers thus cannot know the context to answer
correctly.

One possibility is that some neurons are specifically mod- ulated by
context identity and underlie the separation in the principal component
space. In order to find such context cells, paired t-tests are used to
assess whether the activity of each cell is dependent on the context
(either stronger or weaker), treating the 50 test tasks as samples.
Neurons with p < .001 are considered context cells. This analysis
reveals that 68% of ECII neurons in this model are context cells (Fig-
ure 5), and that this number decreases in the next populations (e.g. 45%
of CA3 cells in Figure 6).

Figure 5: Principal component analysis of ECII activity and proportion
of context cells. Here, ECII is the target and CA3 is the memory.

-3-2-10123Position of Target relative to
Memory2030405060708090100Performance (%
correct)ObjectiveSensorySensory+Context1050510PC1864202468PC2Context
cells: 68%Context 1Context 2Figure 3: Performance of the model with
different memory loci (blue) and targets. The performance with CA1
memory and no monosynaptic pathway is also shown on the right. The gray
dashed line indicates the baseline performance of 50%.

Figure 6: Principal component analysis of CA3 activity and proportion of
context cells. Here, ECII is the target and CA3 is the memory.

Figure 8: Principal component analysis of DG with ECII as a target, DG
as a memory, and 1664 random DG cells inacti- vated.

Discussion A task requiring one-shot episodic memory was introduced by
Peters et al. (2013) and used in the present work to study
context-guided retrieval. Although rewards were encoded ar- tificially
using a third stimulus slot to match the encoding scheme of Pilly et
al. (2018), this task enabled us to evalu- ate the performance of
diverse anatomical configurations in a simple hippocampus-inspired
network. The behavioral re- sults presented here reveal that modern
Hopfield networks can encode and retrieve contextual memories. The fast
as- sociative memory is especially necessary to perform the task when
stimuli are only presented once. In the many-shot regime, however,
pairing a memory with CA3 impairs per- formance. Perhaps when training
examples are shown multi- ple times like in the many-shot regime, the
network learns to generalize and ignore contextual information. An
alternative explanation is that this training regime develops networks
that associate object representations more downstream than in the
one-shot regime, such that the CA3 memory is less able to recall the
rewarded pattern when masked during test.

Figure 7: Principal component analysis of DG with ECII as a target, DG
as a memory, and 1664 DG context cells inacti- vated.

ECinECinECinECinDGDGDGDGCA3CA3CA3CA3CA1CA1CA1CA1ECoutECoutECoutECoutNoneNoneNoneNone30405060708090Performance
(% correct)DGCA3CA1CA1 (no MSP)Target:Memory
locus:1001020PC1105051015PC2Context cells:
45%3020100102030PC120100102030PC2Context 1Context
2201001020PC120100102030PC2Furthermore, it is found that the position
of the target of contextual information is a key factor in correctly
performing the task. The locus of the associative memory is also impor-
tant. In fact, performance seems to be governed by the dis- tance
between these two elements, such that the target must be close to, but
not downstream of, the associative memory layer. Thus, the model that
follows the standard model of hip- pocampal processing and the
anatomical review of prefrontal- hippocampal interactions of Eichenbaum
(2017) does not per- form well. This is due to the associative memory in
CA3 be- ing too far from prefrontal projections to superficial layers of
the entorhinal cortex. While there is a direct connection from the
entorhinal cortex to CA3 in the anatomy, which could po- tentially
improve performance, it is not active during encod- ing in the standard
model. These results, along with the ev- idence put forward by Cheng
(2013), challenge the standard claim that memories are stored in the
recurrent collaterals of CA3.

Some alternative models are much better at performing the task. This is
for example the case of models whose associa- tive memory is located in
a layer directly targeted by the pre- frontal context. Alternatively,
models with associative mem- ory in DG and CA1 work well with the
entorhinal cortex as the target. This is due to DG and CA1 being
connected to the entorhinal cortex through the trisynaptic and monosy-
naptic pathways respectively. It is unlikely that CA1 is the only locus
of memory because information sent by ECII lacks the temporal nature
necessary for sequence learning (Hafting, Fyhn, Bonnevie, Moser, &
Moser, 2008), and the trisynaptic pathway is known to participate in
memory. The alternative hypothesis is that the role of DG in memory
storage is under- estimated, and that a new model could employ it to
store and retrieve contextual memories (Chateau-Laurent, 2024).

Another factor influencing performance is whether the net- works learn
to reconstruct context during the pretraining phase. Models that take
context into account in the recon- struction error perform better. This
is not surprising, as back- propagation then favors the transmission of
context informa- tion across more layers to reconstruct it in the output
layer. Since the hippocampus has been hypothesized to learn to au-
toencode its entorhinal input (Santos-Pata et al., 2021; Ketz, Morkonda,
& O’Reilly, 2013), and since the entorhinal cortex both receives input
from and projects back to the prefrontal cortex, it is reasonable to
assume that context reconstruction is a training objective. Machine
learning models aiming to leverage associative memory in a
context-dependent manner should harness these results. More precisely,
the architectural distance between contextual cues and memory module
should be small and objective functions should include a cue recon-
struction term whenever possible.

Beyond behavioral performance, intermediate representa- tions have been
analyzed. The model has been found to encode context explicitly, as
suggested by the separation of contexts in the principal component space
and the discovery of context-modulated cells. Most importantly, these
context

cells have been found to be necessary to separate contexts and perform
the task correctly. Context information must indeed be encoded in the
input of the modern Hopfield net- work for it to encode and recall
memories contextually. Con- text neurons are reminiscent of splitter
cells discovered in the hippocampus (Wood, Dudchenko, Robitsek, &
Eichenbaum, 2000; Frank, Brown, & Wilson, 2000; Duvelle, Grieves, & Van
der Meer, 2023), which split place representation accord- ing to the
past or future trajectory. The context cells found in this work can be
considered splitter cells without explicit temporal and spatial
components. Future work could explore controlled episodic memory in more
details with more elab- orate contextual modulation and navigation
tasks, in order to provide a more extensive account of splitter cells.
The poten- tial role of DG in memory storage should also be explored in
more depth.

For simplicity and epistemological parsimony,

the net- works employed here were unconstrained feedforward net- works
and modern Hopfield networks. However, biological plausibility elements
such as sparsity constraints and more detailed associative memory
mechanisms could be incorpo- rated to assess whether the same results
hold in networks closer to the biological hippocampus.

Acknowledgements Experiments presented in this paper were carried out
us- ing the PlaFRIM experimental testbed, supported by In- ria, CNRS
(LABRI and IMB), Universit´e de Bordeaux, Bordeaux INP and Conseil
R´egional d’Aquitaine (see https://www.plafrim.fr).

References

Anderson, M. C., Bunce, J. G., & Barbas, H.

(2016). Prefrontal–hippocampal pathways underlying inhibitory control
over memory. Neurobiology of learning and mem- ory, 134, 145–161.

Andrianova, L., Yanakieva, S., Margetts-Smith, G., Kohli, S., Brady, E.
S., Aggleton, J. P., & Craig, M. T. (2023). No ev- idence from
complementary data sources of a direct gluta- matergic projection from
the mouse anterior cingulate area to the hippocampal formation. Elife,
12, e77364.

Chateau-Laurent, H. (2024). Computational modeling of the interactions
between episodic memory and cognitive con- trol. Unpublished doctoral
dissertation, University of Bor- deaux.

Cheng, S. (2013). The crisp theory of hippocampal function in episodic
memory. Frontiers in neural circuits, 7, 88. Cutsuridis, V., Graham, B.
P., Cobb, S., & Vida, I. (2019). Hippocampal microcircuits: a
computational modeler’s re- source book. Springer.

Duvelle, ´E., Grieves, R. M., & Van der Meer, M. A. (2023). Temporal
context and latent state inference in the hip- pocampal splitter signal.
ELife, 12, e82357.

Eichenbaum, H. (2017). Prefrontal–hippocampal interactions in episodic
memory. Nature Reviews Neuroscience, 18(9), 547–558.

Frank, L. M., Brown, E. N., & Wilson, M. (2000). Trajectory encoding in
the hippocampus and entorhinal cortex. Neu- ron, 27(1), 169–178.

Hafting, T., Fyhn, M., Bonnevie, T., Moser, M.-B., & Moser, E. I.
(2008). Hippocampus-independent phase precession in entorhinal grid
cells. Nature, 453(7199), 1248–1252.

Ketz, N., Morkonda, S. G., & O’Reilly, R. C.

(2013). Theta coordinated error-driven learning in the hippocam- pus.
PLoS computational biology, 9(6), e1003067.

Nadel, L., & Moscovitch, M. (1997). Memory consolidation, retrograde
amnesia and the hippocampal complex. Current opinion in neurobiology,
7(2), 217–227.

Peters, G. J., David, C. N., Marcus, M. D., & Smith, D. M. (2013). The
medial prefrontal cortex is critical for memory retrieval and resolving
interference. Learning & memory, 20(4), 201–209.

Pilly, P., Howard, M., & Bhattacharyya, R.

(2018). Mod- eling contextual modulation of memory associations in the
hippocampus. Frontiers in Human Neuroscience, 12, 442. Ramsauer, H.,
Sch¨afl, B., Lehner, J., Seidl, P., Widrich, M., Adler, T., . . . others
(2020). Hopfield networks is all you need. arXiv preprint
arXiv:2008.02217.

Santos-Pata, D., Amil, A. F., Raikov, I. G., Renn´o-Costa, C., Mura, A.,
Soltesz, I., & Verschure, P. F. (2021). Entorhi- nal mismatch: A model
of self-supervised learning in the hippocampus. Iscience, 24(4).

Wood, E. R., Dudchenko, P. A., Robitsek, R. J., & Eichen- baum, H.
(2000). Hippocampal neurons encode informa- tion about different types
of memory episodes occurring in the same location. Neuron, 27(3),
623–633.


