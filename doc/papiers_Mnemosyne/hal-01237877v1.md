Modeling pavlovian conditioning with multiple neuronal
populations
Maxime Carrere, Frédéric Alexandre

To cite this version:

Maxime Carrere, Frédéric Alexandre. Modeling pavlovian conditioning with multiple neuronal pop-
IEEE International Joint Conference on Neural Networks, Jul 2015, Killarney, Ireland.
ulations.
￿10.1109/IJCNN.2015.7280716￿. ￿hal-01237877￿

HAL Id: hal-01237877

https://inria.hal.science/hal-01237877

Submitted on 3 Dec 2015

HAL is a multi-disciplinary open access
archive for the deposit and dissemination of sci-
entific research documents, whether they are pub-
lished or not. The documents may come from
teaching and research institutions in France or
abroad, or from public or private research centers.

L’archive ouverte pluridisciplinaire HAL, est
destinée au dépôt et à la diffusion de documents
scientifiques de niveau recherche, publiés ou non,
émanant des établissements d’enseignement et de
recherche français ou étrangers, des laboratoires
publics ou privés.

Modeling pavlovian conditioning with multiple
neuronal populations

Maxime Carrere and Fr´ed´eric Alexandre
LaBRI, Universit´e de Bordeaux, Institut Polytechnique de Bordeaux,
CNRS, UMR 5800, Talence, France
Inria Bordeaux Sud-Ouest, Talence, France
Institut des Maladies Neurod´eg´en´eratives, Universit´e de Bordeaux,
CNRS, UMR 5293, Bordeaux, France

Abstract—Artiﬁcial Neural Networks are often used as black
boxes to implement behavioral functions, developed by trials and
errors, fed with sensory inputs and controlled by some criteria
of performance. This is the case for pavlovian conditioning
where important sensory information is non ambiguous and
where the error of prediction is to be minimized. These past
years, taking into account critical conditioning behaviors entailed
complexifying the neuronal functioning and learning rules. This
resulted in networks still simple at the architectural level but
with a dynamics difﬁcult to master. Instead, we propose a new
neuronal model using uniform and classical neuronal dynamics,
with a more complex architecture based on recent ﬁndings in
neuroscience. Results reported in this paper conﬁrm the good
behavior of the model and justify the complex architecture by
the greater robustness and ﬂexibility of the model.

I.

INTRODUCTION TO PAVLOVIAN CONDITIONING

Many models of Artiﬁcial Neural Networks have been
proposed to implement pavlovian conditioning. One reason is
that this topic is attractive because pavlovian conditioning is
a learning process easily observable at the behavioral level
in most species, from the simplest to the most complex, and
that it involves stimuli easy to observe and to control in the
environment. Another reason is that pavlovian conditioning
is a gateway to fundamental concepts like prediction error,
attention and information representation, as it has been shown
by the variety of topics addressed by these models. Conse-
quently most of the models that have been presented to date
have the double characteristic of ﬁrstly proposing a simple
implementation to capture the essential features of pavlovian
conditioning and secondly complexifying the model to stick to
a more realistic view of this process [1], [2], [3], [4], [5], [6],
[7], [8].

Pavlovian conditioning is the adaptive process by which a
biologically signiﬁcant stimulus, also known as unconditional
stimulus (US), can be anticipated by learning by a neutral
stimulus, also known as conditioned stimulus (CS). US can
correspond to a reward (some food) or to a punishment (an
electric shock) and automatically triggers a response, not only
at the motor level (e.g. orientation, avoidance) but also at more
internal hormonal and autonomic levels to prepare the body
(e.g. release of stress hormones, acceleration of heart rate).
After some pairings between CS and US, the association CS-
US is learnt and the CS presented alone will trigger a pavlovian
response.

From a modeling point of view, this simple description

might evoke a simple associative rule between CS and US,
except if other phenomena like blocking are considered. In the
blocking protocol, also described as a principle of parsimony,
a stimulus CS1 is paired with a US until acquisition of the
association. Then, the conjunction of two stimuli CS1 and CS2
is paired with the same US. After this process, it appears that
CS1 but not CS2 predicts the US. This can be interpreted
as a parsimonious learning, since in the learnt cases, CS1 is
sufﬁcient to predict US and there is no need to learn on CS2.
In the early 70’s, Rescorla and Wagner [9] brought a decise
answer to this problem, proposing that the associative strength
between CS and US was in fact proportional to the degree of
surprise or of impredictibility of what happens. [10] proposed
a simple implementation of their rule in a perceptron-like
neural network. In this network, each possible CSj activates a
neuron in an input layer, which is directly connected through
a weighted link Wij to an output unit predicting U Si. The
Rescorla-Wagner learning rule is implemented as:

∆Wij = α ∗ β ∗ (U Si − ΣjWij ∗ CSj) ∗ CSij

where α is a parameter standing for the associability
(saliency) of the CS, β for the effectiveness (behavioral impor-
tance) of the US and ΣWij ∗ CSj) is the prediction of U Si by
the network. Consequently, the term (U Si − ΣWij ∗ CSj) can
be seen as the error of prediction of the network, which is a
major ingredient in most approaches of reinforcement learning.
Sutton and Barto [6] have introduced a temporal dimension to
this rule (the CS must begin before the US), using temporal
traces yielding residual neuronal activities when the stimulus
has disappeared.

Even if the Rescorla-Wagner (RW) rule remains of central
interest for modeling pavlovian conditioning, most models that
were published subsequently consisted in considering some
the observed
protocols where that rule cannot explain all
phenomena and in proposing a modiﬁcation of the rule accord-
ingly. This has been the case for several kinds of problems. The
ﬁrst kind of problem is about the way stimuli are represented.
Learning can become complex when a conﬁguration of stimuli
requires a speciﬁc answer by the network. This is the case
for example for compound stimuli (each of CS1 and CS2 in
isolation predicts the US but not CS1&CS2 together: this is
the classical problem of the XOR). This is also the case when
all the surrounding stimuli must be aggregated in a global

pattern called context and when the response of the network
is context dependent (it has for example been observed that
the spatial context of conditioning, the box in which the rat
receives electric shocks, can become a strong predictor of the
US [11]). In all these cases, where the RW rule cannot learn
to predict the US from an input layer made of elemental CSs,
several extensions have been proposed [8], adding new units
in the input layer, corresponding to conﬁgural stimuli or to the
context.

Other kinds of problems are related to the mechanics of
the learning process. The RW rule states that the modiﬁcation
of the weights depends only on the presence of CS and US.
This might be modulated by parameters α and β, but they are
supposed to be constant in the rule. In other words, according
to the RW rule, learning to predict the US does not depend
on the history of conditioning, which is not what is observed
experimentally. Two modeling paths have been developed to
take this problem into account. The Pearce-Hall model [7]
measures the rate with which each stimulus is learned. This
is called salience associability and corresponds to rendering
parameter α variable and dependent on the history of each
CS. A simple implementation is to multiply the RW rule by
abs(U Si − ΣWij), where abs is the absolute value function.
In this case, and as it is observed experimentally, weights
from CSs that already predict US a lot are modiﬁed more
slowly. The Mackintosh model [4] gives a report on attentional
associability which explains which stimuli have access to
the learning process. In this model, good predictors of US
maintain a high associability, to explain for example the fact
that assigning a CS to a new US is quicker after an overtaining
of the CS with previous US.

Both models underline the need to take into account
the recent history of conditioning (it can be mentioned that
conﬁguration of stimuli can develop their own associability
[12]) but they also result in a complexiﬁcation of the learning
rules. The best illustration is probably with so-called hybrid
models [13] which propose to incorporate in one rule all the
elements mentioned above.

Another important problem with the RW rule is the fact
that
it corresponds to acquiring a static and deterministic
view of the world, whereas it can be stochastic (a CS can
predict a US with a certain probability) and changing (a CS-
US rule can be valid one day and disappear the day after),
both concepts referred to, respectively, as known and unknown
uncertainty [14]. The RW rule or the Pearce-Hall model can
compute the probability of known uncertainty as the value
of convergence of the weight, but the unknown uncertainty
can only correspond to an estimation subject to changes at
any moment. Consequently, a special care must be taken for
unknown uncertainty, which is well represented in the case
of extinction. In this protocol [15], a CS-US association is
learned until the CS faithfully predicts the US; then the US
in no longer given (extinction of the association). It is then
observed that the prediction will disappear but this takes a
rather long time (for example in fear conditioning, a CS-US
association can be learned after three pairing but more than
ten are necessary for extinction). More important is the related
phenomenon of renewal: if after the extinction, the US is given
again, the CS-US association is re-established immediately.
This experiment is a strong argument against models based on

the RW rule where the level of CS-US association is ﬂuctuating
with the level of association and is ultimately removed after
extinction. Instead, it proposes that the CS-US association is
not forgotten but only inhibited during extinction and that
renewal consists in releasing that inhibition [16]. Consequently,
whereas some ﬂuctuation, as proposed in the RW rule, can be
used to precisely deﬁne the level (the probability) of CS-US
association, another mechanism must be deﬁned in the case of
unknown uncertainty, when the rule changes.

In summary, this overview underlines the two main char-
acteristics of modeling pavlovian conditioning with ANNs. On
the one hand, the RW rule has had a deep impact on the models
and conﬁrms the preeminence of the error of prediction of the
US in pavlovian conditioning. On the other hand, adapting
the RW rule to a more precise modeling of the behavioral
characteristics reveals difﬁcult in the too simple framework of
a two-layered network, directly predicting the US from the CS.
A key issue in this regard is to take a more insightful view
of the biological substrate of this learning process, which is
not limited to a two layered structure, and to develop more
biologically inspired neuronal networks.

II. CEREBRAL IMPLEMENTATION OF PAVLOVIAN
CONDITIONING

Except for the case of simple somatomotor associations
where the cerebellum is mainly involved [17], another cerebral
structure, the amygdala, is reported to be the key region where
pavlovian conditioning takes place [18]. In this regard, two
main regions have been traditionally described: the basolateral
nuclei (BLA) receiving the sensory input and the central nuclei
CeA for the motor output. More precisely, it has been shown
that the CS and the US activates neurons in BLA and that
the CS-US association is learned herein [19]. Similarly, strong
experimental evidences have shown that CeA receives infor-
mation from BLA and projects to structures responsible for
the motor, hormonal and autonomic expression of pavlovian
responses [20].

Concerning phenomena evoked above and indicating that
pavlovian conditioning is more complex than a simple asso-
ciative rule between elemental CS and US, effects related to
conﬁgural or contextual representations are generally attributed
to the hippocampus [21], known to build arbitrary relations
among separate features of a behavioral episode and projecting
to BLA. On this basis, bio-inspired models of pavlovian
conditioning able to process conﬁgural and contextual stimuli
have been proposed, including a model of the hippocampus
dedicated to the formation of complex patterns acting as CSs
[1], [2], [22], [23].

The prefrontal cortex is undoubtly considered as a ma-
jor cerebral structure involved in temporal representations,
including storage of past activities in working memory and
behavioral sequence representation [24]. Concerning temporal
aspects evoked above for pavlovian conditioning, the infral-
imbic cortex or the homologous structure in primates, the
orbitofrontal cortex, ventral parts of the medial prefrontal
cortex, have been reported to act as a working memory,
keeping track of the recent reward history [25]. It has been
speciﬁcally reported that projections from this structure toward
BLA are necessary for the acquisition of extinction and for ex-
tinction memory [26]. Accordingly, bio-inspired neural models

of extinction have been proposed [27], [28], implementing an
inhibitory role of the medial prefrontal cortex toward CS-US
associations in the amygdala in case of extinction, measured
as a frequency of prediction of the US not followed by its
occurrence.

In their paper describing the role of uncertainty in decision
making [14], Yu and Dayan underline the prominent role
of neuromodulation, speciﬁcally proposing the inﬂuence of
acethylcholine and norepinephrine on the neural substrate to
modulate its activity, respectively as a function of known
and unknown uncertainty. As far as pavlovian conditioning
is concerned, mainly the effect of acetylcholine has been
considered in bio-inspired models [29], underlying that its
release from the basal forebrain is partly due to hormonal
responses emitted from CeA in case of errors of prediction and
modeling its role in changing attentional and learning effects
in the cortex and the hippocampus.

Whereas these bio-inspired neuronal models bring valuable
insights about mechanisms underlying some complex aspects
of pavlovian conditioning, they say few about how all these
mechanisms coexist and interact in amygdalar neural popu-
lations. Particularly, contradictory information might be sent
to BLA from its afferent structures and it might be questioned
how they are incorporated at the neuronal level to elaborate the
more adapted response. Solutions like complex rules proposed
by hybrid models [13] do not seem transposable here for at
least two reasons. They are too complex to be implemented as
a neuronal activation or learning rule and they are not ﬂexible
enough to change autonomously, depending on the changes in
the statistics of external events.

The model that we present in this paper addresses this
problem by incorporating recent ﬁndings from neuroscience in
a novel bio-inspired model of the amygdala. In short, the main
characteristics that we extract from these recent ﬁndings is
that distinct populations of amygdalar neurons receive distinct
afferences from the neuronal structures providing key informa-
tion and underlie distinct evaluations, which are combined and
confronted internally in the amygdala to prepare the pavlovian
response.

More precisely, the distributed neuronal implementation
that we propose in our model relies on the following biological
hints. The basolateral nuclei of the amygdala can in fact
be differenciated as a lateral nucleus, receiving elemental
sensory information from the thalamus and the cortex and a
basal nucleus, receiving more elaborated information from the
hippocampus and the prefrontal cortex [30]. Besides, within
the basal nucleus, it has been shown recently [15] that two
distinct populations of neurons, called high-fear and low-fear
neurons are respectively connected with the hippocampus and
the infralimbic cortex and are respectively engaged in context-
dependent acquisition and renewal (high-fear neurons) and
in extinction (low-fear neurons), whereas fear neurons in the
lateral nucleus can detect simple CS from elemental sensory
information from the thalamus and the cortex. In addition,
inhibitory connections are also reported between these pop-
ulations [31]. Another key difference between the basal and
lateral nucleus exploited by our model is that the activity of
the basal nucleus is particularly modulated by acetylcholine.
For example, in [32] a higher activation in the basal nucleus
is associated to a high level of acetylcholine.

A functional differentiation has also been recently reported
in the lateral part of the central nucleus, concerning the
preparation of the pavlovian response [33]. It is reported in this
paper that in this region in mice, 30% of the neurons (called
CeLon) acquire an excitatory response and 25% a strong
inhibitory response and are together in mutual inhibition. It can
be consequently hypothetized that fear and low-fear neurons
from the lateral and basal nuclei respectively project on these
populations, whose interaction results in the level of pavlovian
response emitted from the central nucleus.

In summary, whereas most models of the amygdala pos-
tulate a simple network, directly connecting a sensory layer
to a motor layer and managing the complex features of
pavlovian conditioning by the design of a complex learning
rules, biological evidences rather propose to consider that
several populations coexist in the amygdala to process different
classes of sensory and motor patterns, in close relation to
the different classes of afferences received by the amygdala.
Several consequences can be drawn from this global picture.
Within such a distributed network, local learning and func-
tioning rules can remain simple. The global behavior of the
network can be more ﬂexible, since several scenarios can be
evaluated in parallel, before the decision emerges from their
competition and coordination. This is more precisely described
in the model that we present now.

III. MODEL DESCRIPTION

Our model aims at illustrating how connections in a neural
network can explain and reproduce behavioral results observed
in pavlovian conditioning. Thus, it describes the amygdala by
modeling its differents parts using different neural populations.
Each population has mainly the same neuronal equations and
parameters, but differs one from the other by its connectivity,
ie. differences in inputs from other populations or from neuro-
modulation, and differences in output projections toward other
populations.

Fig. 1. Main features of our amygdalar network. LA and BAf are two fear
neurons populations, which differ by their afferent connections. LA learns to
predict fear, based on sensory input from cortex and thalamus and projects
to BAf and CeLOn. BAf receives contextual inputs from Hippocampus and
sensory-based prediction from LA, resulting in a prediction based on both
sensory or contextual information. BAe is a population of extinction neurons
receiving contextual inputs from medial Prefrontal Cortex (Infralimbic cortex,
IL) during extinction. BAe and BAf are in mutual inhibition and respectively
project to CeLOn and CeLOff populations in CeA. CeLOn and CeLOff are
also in mutual inhibition. CeLOn activity is considered as the level of US
prediction of the model.

As described in ﬁgure 1, the amygdala is represented by
ﬁve different populations, and encompasses three main infor-
mation ﬂows. First, a population of fear neurons representing
the Lateral Nucleus (LA) receives sensory information from
the cortex (this term in the model will refer to both thalamus
and sensory cortex), and learns to predict fear, based on
these sensory inputs. These neurons project to a population in
the Central Nucleus of the Amygdala (CeLOn) whose level
of activation is considered the main output of the model,
representing the fear response. In cases of pavlovian learning
using sensory cues, this Cortex-LA-CeLOn pathway will learn
to predict US arrival based on sensory information.

In the basal nucleus of the amygdala, another population
of fear neurons (BAf) receives contextual inputs from the
hippocampus, sensory prediction from LA, and projects to
CeLOn. This Hippocampus-BAf-CeLOn pathway allows the
network to make predictions based on contextual information.
Finally, a population of extinction neurons in the basal nucleus
of the amygdala (BAe) receives contextual
information in
situation of extinction from the Infralimbic cortex (IL), and
learns to predict extinction conditioning, ie when predicted US
do not arrive. BAe and BAf neurons are in mutual inhibition,
so that in an extinction situation, neurons in BAe can inhibit
BAf fear prediction, thus inhibiting the prediction of the second
pathway.

BAe neurons project to a population in the central nucleus
of the amygdala, CelOff, which in turn can inhibit CelON
prediction in an extinction situation, inhibiting the sensory
prediction of the ﬁrst pathway. Consequently, the IL-BAf-
CelOff pathway can inhibit both sensory and context-based
predictions in a case of extinction.

Another mechanism taken into account in this model is
the effect of acetylcholine (ach) concentration on the differ-
ent pathways. BAf and BAe activities are enhanced by ach
concentration. A higher level of acetylcholine will increase
BAf and BAe activities, which will favor the second or third
pathway over the ﬁrst one in respectively contextual learning or
extinction learning. At the opposite, a lower ach concentration
can allow sensory-based predictions in LA to win over BA
contextual learning or extinction.

This model is implemented in Python, and is using the
DANA library for neuronal computation [?]. Since we are
focusing on modeling the role of the amygdalar network
in pavlovian conditioning, we did not implement neuronal
dynamics for the other parts of the brain providing inputs to
the network, ie cortex and thalamus for LA, hippocampus for
BAf and infralimbic cortex for BAe. Each of these external
populations is a vector of neurons whose activities are set
according to the studied paradigm.

Each amygdalar neuron is described using the mean ﬁeld
formalism, which consists of two variables: the membrane
potential V and the ﬁring rate U . As we aim at modeling
pavlovian conditioning by using connectivity to induce pavlo-
vian behaviors rather than behavior-speciﬁc equations, all of
our neurons are using the same equation for V and for U :

dV Amyg
i
dt

= (−V Amyg
i

+ F (ΣjW Amyg−Input
ij

∗ U Input
j

))/τ

Parameter
input size
la size
baf size
bae size
CeLOn size
CeLOff size

τ
α
il tau
noise level
θ
ach min
ach max
ach strength
ach uncertainty strength
wmin
wmax
Cel input W
LA to BAf W
LA inhib W
Cel inhib W
BA inhib W

Architectural parameters

Meaning
size of input vectors from cortex, hippo, IL
number of neurons in la
number of neurons in baf
number of neurons in bae
number of neurons in CeLOn
number of neurons in CeLOff

Equation parameters
Amygdala neurons time constant
Modulates learning speed in LA, BAf and BAe
time constant for ach equation
% of neurons intrinsic noise
neurons input threshold
minimum of ach level
maximum of ach level
modulates effect of ach concentration on BA
modulates effect of uncertainty on ach concentration
minimum for modiﬁable weights initialisation
maximum for modiﬁable weights initialisation
constant weights from BLA to Cel
constant weights from LA to BAf
constant weights inside LA
constant weights between CelOn and CelOff
constant weights between BAf and BAe

Value
10
10
10
10
1
1

0.05
1
5
1
0.3
1
2.5
0.5
5
0.01
0.05
0.2
0.1
0.1
0.25
0.05

Fig. 2.
activation and learning rules.

Parameters describing network architecture and parameters used in

U Amyg

i

= noise(sigmoid(V Amyg

i

))−ΣkW Amyg−Inhib
ik

∗U Inhib
k

Parameters are identical for each neuron. τ is a time constant
deﬁning the dynamics of activity evolution and set to 0.05
throughout all the experiments. F is a non linear threshold
function:

F (U ) = max(min value, U − θ)

with min value a tiny constant set to 10−3, and θ the value
of the threshold, set to 0.3.
noise() is a function which represents intrinsic neuronal
noise, by using a uniform distribution centred on the value
sigmoid(V ). Results reported here are robustly obtained with
an interval length of 1% of sigmoid(V ). Yet raising noise up
to 20% does not alter network performance on the different
paradigms.

Fear and extinction learning rules are implemented using
hebbian learning, with a prediction error ERR = (U S −
UCeLOn) as in the Rescorla-Wagner rule.

ij

dW P ost−P re
dt

= ERR ∗ U S ∗ α ∗ U P re

j

∗ U P ost
i

Since extinction neurons need to increase their responsiveness
when the level of prediction of the US is too high, learning
rule is the opposite for extinction neurons and writes:

ij

dW BAe−IL
dt
is the BAe postsynaptic activity, and U IL

= −ERR ∗ α ∗ U BAe

where U BAe
the
presynaptic activity from IL. α is a learning coefﬁcient set to
1.0 for all fear and extinction neurons.

∗ U IL
j

j

i

i

CeLOn and CelOff neurons do not require plasticity, since
their role in our model is only to integrate LA, BAf and BAe
predictions, which does not need learning, at least for the
paradigms tested here.

Both UBAf and UBAe are multiplicatively enhanced by ach

concentration, computed as follows :

ACh = ach strength ∗ (baseline+
ach uncertainty strength ∗ noise(sigmoid(V ACh)))

dV ACh/dt = (−V ACh + F (|ERR|))/τACh
where V ACh is used to compute recent uncertainty which is
reﬂected in ach concentration [14]. baseline is the baseline
to 1.0, τACh is the time
level of tonic acetylcholine, set
constant, set to 5, F is the threshold function and ERR the
prediction error deﬁned above. ach uncertainty strength
modulates the effect of the recent uncertainty V ACh on each
concentration, and is set to 5. ach strength modulates the
overall effect of ach concentration on BA activities, and is set
to 0.5.

IV. EVALUATION OF THE MODEL

All our experiments were organized according to the pro-

tocol described in ﬁgure 3.

Fig. 3. Each trial is composed of three phases of identical duration. In the
ﬁrst phase, only the sensory CS and/or the context is shown to the network.
The second phase is the learning phase, and begins with US arrival. Prediction
error is computed based of the network output at the end of phase 1. During
phase 3, no input is presented and amygdalar neurons return to their baseline
level of activation.

One trial is a single CS-US presentation, and consists in
three phases. In the ﬁrst phase, the cue (CS and/or context) is
presented alone to the network and enough time is given for its
activities to stabilize. In the seconde phase, CS and/or context
is maintained, and the US is presented. In the third phase, no
inputs are presented and neuronal activities go down to their
baseline level.

Fig. 4. Trial 1 (not shown here) was a trial without any stimulus presentation
for network stabilization to baseline values. Fear conditioning takes place from
trial 2 to trial 13. Fear extinction from trial 14 to trial 21. Renewal is tested
in trial 22. Graphs A,B,C,D are showing average activities at the moment of
US arrival. (A) Both LA and BAf activities increase during conditioning. BAe
activity decreases due to BAf inhibition. (B) Due to LA and BAf increase,
CeLOn activity increases, and correctly predicts US arrival after conditioning.
CeLOff activity is inhibited by CeLOn (C) After a few trials, BAe activity
starts to overcome BAf inhibition, and BAe strongly increases, which provokes
BAf inhibition. LA ﬁring rates remain steady. In the renewal context, IL does
not provide any longer extinction information to BAe, which stops BAe ﬁring
and releases its inhibition on BAf. (D) During extinction, CeLOff activity
increases with BAe increase and overcome CeLOn inhibition, still powered
by LA ﬁring. In the renewal trial, CeLOff is no longer sustained by BAe, and
CeLOn activity is restored to conditioning value.

Using this procedure, our network manages to reproduce
classical pavlovian acquisition, contextual extinction and re-
newal results as observed in [15] (cf Fig.5). We also report in
ﬁgure 5 results indicating that our network nicely reproduces
the blocking paradigm.

Fig. 5. Acquisition takes place from trial 2 to 13. During acquisition, a
single sensory CS is presented to the network followed by US arrival (without
context). Blocking takes place starting from trial 14. A new CS is presented
simultaneously to the previous one, followed by US arrival. (A,B) Acquisition
similar to ﬁgure 4. (C) Weights evolution during acquisition. LA weights are
increasing during acquisition while the others remain steady. (D,E,F) Blocking
occurs: since the ﬁrst stimulus is already a good US predictor, no learning
occurs based on the new stimulus presentation.

In all these experiments, each neuronal population shows
different behavior, depending on its connections and inputs.
During acquisition, both LA and BAf learn to predict US
arrival, so that
learning is distributed between these two
populations. During extinction, the IL-BAe-CelOff pathway
extinguishes the other two pathways thanks to BAe learning.
Whereas BAf is inhibited by BAe, LA is still ﬁring and
predicting US arrival, but this prediction is inhibited in CeLOn
by CelOff inhibition. In the last trial, we restore the acquisition
context back and we can observe that renewal is immedi-
ate. Moreover, this network is performing fear conditioning,
extinction and renewal with temporal characteristics similar
to those observed in animals by [15]. Neuronal dynamics
is also consistent with other experimental ﬁndings (learning
distributed between BAf and LA, still fear prediction in LA
when in an extinction process).

Advantages with our distributed US-prediction network
include the facts that it is both able to make prediction of
the US if one pathway is disturbed and that it can use the
more adequate pathway to predict US in normal conditions.
The following experiments were aimed at studying theses
two advantages. In each experiment, after fear acquisition, we
test independantly sensory-based prediction and context-based
prediction of the US, in order to see which neural pathway has
undergone the more learning (Fig.6).

In Fig.6.A, both CS and context are presented to the
network for fear prediction (pairing experiment). Yet after
learning, the network is predicting mostly based on sensory
characteristics of the CS. This phenomenon emerges from the
connections from LA to BAf. While only BAf can perform
context-based learning, LA (by receiving sensory information

process and tries to learn to predict the US based on sensory
inputs under normal circumstances. We have explained above
that by default, there is a bias favoring LA, simply due to the
network connectivity. If this pathway is not performing well,
either because the elemental sensory cues are not sufﬁcient
to predict US or because LA pathway is somewhat impaired,
errors will accumulate, and ach level will raise, which will
favor the IL-BAe-CeLOff pathway for extinction, or the Hippo-
BAf-CeLOn pathway for contextual conditioning. The choice
between the latter two processes is performed on a simple
competitive process, depending on their levels of prediction.
Thus ach concentration plays a critic role by monitoring recent
uncertainty and enables the other two processes to predominate
over the otherwise naturally chosen sensory pathway.

Moreover, as seen in the last experiment, this network
structure remains ﬂexible: if the second process (BAf pathway)
is impaired, the ﬁrst process through LA is still able to learn
and allows the network to make sensory-based predictions.
These characteristics of adaptivity and ﬂexibility emerge from
a multiple layer system, also found in animals and could not
have been obtained by using a single-layer system, even with
complex rules.

V. CONCLUSION

The main ﬁndings of this paper can be ﬁrst discussed on
a behavioral and evolutionary perspective. The initial goal of
pavlovian mechanisms in phylogeny is to increase probability
of survival by triggering rapid and automatic reﬂexes when the
animal faces biologically signiﬁcant stimuli. Along evolution,
these mechanisms have evolved to incorporate more complex
cases. This can be the complexiﬁcation of stimuli in space and
time, including attentional mechanisms in mammals. This can
also be the evolution under voluntary control where CS can
be seen as conditioned reinforcers or goals toward which the
behavior has to be organized.

Concerning brain structure, this can also be summarized
by the recent expansion of the basal nuclei [18], incorporating
new inputs from the hippocampus and the prefrontal cortex
and sending information about conditioned reinforcers towards
the main structures of instrumental conditionning, the basal
ganglia and the prefrontal cortex. But of course these new
capabilities do not replace older ones (survival reﬂexes are
still important in mammals) but just increase the size of the
behavioral repertoire.

These principles are very consistent with what we observe
from the characteristics of our model. In the more simple cases,
the network is tuned in such a way that responses originating
from LA will have a stronger effect and will trigger a fear
response from basic sensory cues. Then, only in the case of
error of prediction of the US, this will trigger acetylcholine,
increasing the inﬂuence of BA, and the network is going to try
to build more complex association from more complex sensory
patterns or a longer history in time.

More generally,

this bio-inspired design of a neuronal
architecture is a plea for getting inspired by the modular
architecture of the brain: Most of our complex cognitive func-
tions result from the competition and collaboration of simple
functional pathways. Such an architecture is more simple to
build during the evolution of species but also of individuals.

Fig. 6. CeLOn activity after learning, when only the CS (blue bar) or only
the context (green bar) is presented. Similar results are observed in animals
in [32].(A) During pairing experiment, both CS and context are presented as
cues for US prediction. After conditioning, prediction is higher for the CS,
while context-based prediction does not differ much from baseline level. (B)
Pairing with increased ach level. CeLOn activity is higher for context-based
prediction. ach increase causes US to be associated with context instead of CS.
(C) During the unpairing experiment, both CS and context are presented to
the network as cues for US prediction. Yet CS intensity is randomly varying
from one trial to another, so that context, whose activity remains the same
from one trial to another, is a better predictor of the US. Consequently, after
learning, the sensory CS alone does not elicit a strong US prediction, while
context does. (D) Unpairing experiment with ach depletion, which impairs
contextual pathway learning. As a result, the sensory pathway is learning US
arrival.

from cortex) and BAf (by receiving LA activations) can per-
form sensory-based learning. Yet, if we set ach constant to 3.0,
ie. around two times the observed ach level in this paradigm,
we observe the opposite phenomenon. Higher ach level means
higher activities in BA, which induces a faster hebbian learning
in BAf. The LA pathway does not have enough time to
stabilize, so that the network is making predictions mostly
based on the context (Fig.6.B), as also reported in [32].

In ﬁgure 6.C, we are also presenting both CS and con-
text
to the network before US arrival during the learning
phase. Yet CS intensity is randomly varied from one trial
to another, by multiplying it with a number randomly drawn
in a uniform distribution between 0 (no CS) and 1 (normal
intensity) (unpairing experiment). Thus, the context becomes
a better predictor of the US than CS, since its intensity is
always the same before US arrival. Figure 6.C shows that in
this experiment, our network is indeed making context-based
predictions. Learning takes longer, around 16 trials, which
allows the measure of uncertainty to rise higher, which in turn
raises ach value and allows the Hippo-BAf-CeLOn pathway
to predominate in learning. Yet if we impair the BAf pathway
in this experiment, by setting ach concentration to 0.5, half of
its baseline level (Fig.6.D), the network is still able to predict
US arrival, by learning it with its LA pathway. If for some
reason the contextual pathway is impaired, the neural network
will learn to predict US arrival based on the sensory pathway,
even in a paradigm in which it would normally favour the
contextual one. All of these results have also been observed
experimentally in animals as reported in [32].

In summary,

the architecture of the neuronal network
model of the amygdala that we propose can be viewed as
three parallel processes and the elaboration of a criterium
for arbitration. The sensory pathway including LA is the ﬁrst

[19] S. K. Barot, Y. Kyono, E. W. Clark, and I. L. Bernstein, “Visualizing
stimulus convergence in amygdala neurons during associative learning,”
Proceedings of the National Academy of Sciences, vol. 105, no. 52, pp.
20 959–20 963, Dec. 2008.

[20] M. D. Cassell, L. J. Freedman, and C. Shi, “The Intrinsic Organization
of the Central Extended Amygdala,” Annals of the New York Academy
of Sciences, vol. 877, no. 1, pp. 217–241, Jun. 1999.

[21] H. Eichenbaum, M. Sauvage, N. Fortin, R. Komorowski, and P. Lipton,
“Towards a functional organization of episodic memory in the medial
temporal lobe,” Neurosci Biobehav Rev., vol. 36, no. 7, pp. 1597–1608,
2012.

[22] M. Meeter, C. E. Myers, and M. A. Gluck, “Integrating Incremental
Learning and Episodic Memory Models of the Hippocampal Region,”
Psychological Review, vol. 112, no. 3, pp. 560–585, Jul. 2005.
[23] R. C. O’Reilly and J. W. Rudy, “Conjunctive Representations in Learn-
ing and Memory: Principles of Cortical and Hippocampal Function,”
Psychological Review, vol. 108, no. 2, pp. 311–345, 2001.
J. M. Fuster, “The Prefrontal Cortex - An Update: Time Is of the
Essence,” Neuron, vol. 30, no. 2, pp. 319–333, 2001.
J. D. Wallis, “Orbitofrontal cortex and its contribution to decision-
making.” Annual review of neuroscience, vol. 30, no. 1, pp. 31–56,
Apr. 2007.

[24]

[25]

[26] D. Sierra-Mercado, N. Padilla-Coreano, and G. J. Quirk, “Dissociable
roles of prelimbic and infralimbic cortices, ventral hippocampus, and
basolateral amygdala in the expression and extinction of conditioned
fear.” Neuropsychopharmacology, vol. 36, no. 2, pp. 529–538, Jan.
2011.

[27] W. M. Pauli, T. E. Hazy, and R. C. O’Reilly, “Expectancy,
Ambiguity, and Behavioral Flexibility: Separable and Complementary
Roles
in
Processing Reward Expectancies,” Journal of Cognitive Neuroscience,
vol.
[Online]. Available:
351–366,
2,
http://dx.doi.org/10.1162/jocn a 00155

and Amygdala

Frontal Cortex

the Orbital

2011.

no.

pp.

24,

of

[28] M. Jan, “Emotion and learning : a computational model of the amyg-

dala,” Ph.D. dissertation, Lund University Cognitive Studies, 2002.

[29] W. M. Pauli and R. C. O’Reilly, “Attentional control of associative
learning–a possible role of the central cholinergic system,” Brain
Research, vol. 1202, pp. 43–53, Apr. 2008.
J. LeDoux, “The amygdala,” Current Biology, vol. 17, no. 20, pp. R868–
R874, Oct. 2007.

[30]

[31] S. Lee, S.-J. Kim, O.-B. Kwon,

J. H. Lee, and J.-H. Kim,
“Inhibitory networks of
the amygdala for emotional memory,”
Frontiers in Neural Circuits, vol. 7, no. 129, 2013. [Online]. Available:
http://www.frontiersin.org/neural circuits/10.3389/fncir.2013.00129/abstract

[32] L. Calandreau, P. Triﬁlieff, N. Mons, L. Costes, M. Marien,
A. Marighetto, J. Micheau, R. Jaffard, and A. Desmedt, “Extracellu-
lar hippocampal acetylcholine level controls amygdala function and
promotes adaptive conditioned emotional response.” The Journal of
neuroscience : the ofﬁcial journal of the Society for Neuroscience,
vol. 26, no. 52, pp. 13 556–13 566, Dec. 2006.

[33] S. Ciocchi, C. Herry, F. Grenier, S. B. E. Wolff, J. J. Letzkus,
I. Vlachos, I. Ehrlich, R. Sprengel, K. Deisseroth, M. B. Stadler,
C. Muller, and A. Luthi, “Encoding of conditioned fear in central
amygdala inhibitory circuits,” Nature, vol. 468, no. 7321, pp. 277–282,
Nov. 2010. [Online]. Available: http://dx.doi.org/10.1038/nature09559

It is more resilient to damages and will integrate more easily
changes by modifying local pathways instead of a unique cost
function. It is certainly of highest interest for designers of
Artiﬁcial Neural Networks to integrate this principle in their
daily practice.

REFERENCES

[1] N. A. Schmajuk and J. J. DiCarlo, “Stimulus conﬁguration, classical
conditioning, and hippocampal function,” Psychol Rev., vol. 99, no. 2,
pp. 268–305, 1992.

[2] A. A. Moustafa, C. E. Myers, and M. A. Gluck, “A neurocomputational
model of classical conditioning phenomena: A putative role for the
hippocampal region in associative learning,” Brain Res., vol. 1276, pp.
180–95, 2009.
J. L. Armony, D. Servan-Schreiber, J. D. Cohen, and J. E. LeDoux,
“Computational modeling of emotion: explorations through the anatomy
and physiology of fear conditioning,” Trends Cogn Sci, vol. 1, no. 1,
pp. 28–34, Apr. 1997.

[3]

[4] N. J. Mackintosh, “A theory of attention: Variations in the associability
of stimuli with reinforcement,” Psychological Review, vol. 82, no. 4,
pp. 276–298, 1975.
J. K. Kruschke, “Toward a uniﬁed model of attention in associative
learning,” Journal of Mathematical Psychology, vol. 45, pp. 812–863,
2001.

[5]

[6] R. S. Sutton and A. G. Barto, “Toward a modern theory of adaptive
networks: expectation and prediction.” Psychological review, vol. 88,
no. 2, pp. 135–170, Mar. 1981.
J. M. Pearce and G. Hall, “A model for Pavlovian learning: variations
in the effectiveness of conditioned but not of unconditioned stimuli,”
Psychological review, vol. 87, no. 6, 1980.
[Online]. Available:
http://view.ncbi.nlm.nih.gov/pubmed/7443916

[7]

[8] L. G. Allan, “Human Contingency Judgments: Rule Based or Associa-
tive?” Psychological Bulletin, vol. 114, no. 3, pp. 435–448, 1993.
[9] R. Rescorla and A. Wagner, “A theory of pavlovian conditioning:
Variations in the effectiveness of reinforcement and nonreinforcement,”
in Classical Conditioning II: Current Research and Theory. Appleton
Century Crofts, 1972, pp. 64–99.

[10] M. A. Gluck and G. H. Bower, “From conditioning to category learning:
an adaptive network model.” Journal of experimental psychology.
General, vol. 117, no. 3, pp. 227–247, Sep. 1988.

[11] M. Fanselow, “Contextual fear, gestalt memories, and the hippocam-
pus,” Behavioural Brain Research, vol. 110, no. 1-2, pp. 73–81, Jun.
2000.

[12] C. V. Buhusi and N. A. Schmajuk, “Attention, conﬁguration, and
hippocampal function,” Hippocampus, vol. 6, no. 6, pp. 621–642, Jan.
1996.

[13] M. E. Le Pelley, “The role of associative history in models of associative
learning: a selective review and a hybrid model.” The Quarterly Journal
of Experimental Psychology, vol. 57, no. 3, pp. 193–243, Jul. 2004.
[Online]. Available: http://dx.doi.org/10.1080/02724990344000141
[14] A. J. Yu and P. Dayan, “Uncertainty, neuromodulation, and attention.”
[Online]. Available:

Neuron, vol. 46, no. 4, pp. 681–692, 2005.
http://dx.doi.org/10.1016/j.neuron.2005.04.026

[15] C. Herry, S. Ciocchi, V. Senn, L. Demmou, C. Muller, and A. Luthi,
“Switching on and off fear by distinct neuronal circuits,” Nature,
vol. 454, no. 7204, pp. 600–606, Jul. 2008. [Online]. Available:
http://dx.doi.org/10.1038/nature07166

[16] S. Maren, “Building and Burying Fear Memories in the Brain,” The

Neuroscientist, vol. 11, no. 1, pp. 89–99, Feb. 2005.

[17] R. F. Thompson and J. E. Steinmetz, “The role of the cerebellum in
classical conditioning of discrete behavioral responses.” Neuroscience,
vol. 162, no. 3, pp. 732–755, Sep. 2009.

[18] R. N. Cardinal, J. A. Parkinson, J. Hall, and B. J. Everitt, “Emotion and
motivation: the role of the amygdala, ventral striatum, and prefrontal
cortex,” Neuroscience & Biobehavioral Reviews, vol. 26, no. 3, pp.
321–352, 2002. [Online]. Available: http://dx.doi.org/10.1016/s0149-
7634(02)00007-6

