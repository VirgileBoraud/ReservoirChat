Joint processing of linguistic properties in brains and language models
Subba Reddy Oota, Manish Gupta, Mariya Toneva

To cite this version:

Subba Reddy Oota, Manish Gupta, Mariya Toneva. Joint processing of
linguistic properties in brains and language models. NeurIPS 2023 - 37th
Conference on Neural Information Processing Systems, Neural Information
Processing Systems, Dec 2023, New Orleans, United States. ￿hal-04400635￿

HAL Id: hal-04400635

https://inria.hal.science/hal-04400635

Submitted on 17 Jan 2024

HAL is a multi-disciplinary open access archive for the deposit and
dissemination of sci- entific research documents, whether they are pub-
lished or not. The documents may come from teaching and research
institutions in France or abroad, or from public or private research
centers.

L’archive ouverte pluridisciplinaire HAL, est destinée au dépôt et à la
diffusion de documents scientifiques de niveau recherche, publiés ou
non, émanant des établissements d’enseignement et de recherche français
ou étrangers, des laboratoires publics ou privés.

Distributed under a Creative Commons Attribution 4.0 International
License

3 2 0 2

v o N 8

] L C . s c [

2 v 4 9 0 8 0 . 2 1 2 2 : v i X r a

Joint processing of linguistic properties in brains and language models

Subba Reddy Oota1,2, Manish Gupta3, Mariya Toneva2 1Inria Bordeaux,
France, 2MPI for Software Systems, Saarbrücken, Germany, 3Microsoft,
India subba-reddy.oota@inria.fr, gmanish@microsoft.com,
mtoneva@mpi-sws.org

Abstract

Language models have been shown to be very effective in predicting brain
record- ings of subjects experiencing complex language stimuli. For a
deeper understanding of this alignment, it is important to understand
the correspondence between the detailed processing of linguistic
information by the human brain versus language models. We investigate
this correspondence via a direct approach, in which we eliminate
information related to specific linguistic properties in the language
model representations and observe how this intervention affects the
alignment with fMRI brain recordings obtained while participants
listened to a story. We investigate a range of linguistic properties
(surface, syntactic, and semantic) and find that the elimination of each
one results in a significant decrease in brain alignment. Specifically,
we find that syntactic properties (i.e. Top Constituents and Tree Depth)
have the largest effect on the trend of brain alignment across model
layers. These findings provide clear evidence for the role of specific
linguistic information in the alignment between brain and language
models, and open new avenues for mapping the joint information
processing in both systems. We make the code publicly available1.

1

Introduction

Language models that have been pretrained for the next word prediction
task using millions of text documents can significantly predict brain
recordings of people comprehending language (Wehbe et al., 2014; Jain &
Huth, 2018; Toneva & Wehbe, 2019; Caucheteux & King, 2020; Schrimpf et
al., 2021; Goldstein et al., 2022). Understanding the reasons behind the
observed similarities between language comprehension in machines and
brains can lead to more insight into both systems.

While such similarities have been observed at a coarse level, it is not
yet clear whether and how the two systems align in their information
processing pipeline. This pipeline has been studied separately in both
systems. In natural language processing (NLP), researchers use probing
tasks to uncover the parts of the model that encode specific linguistic
properties (e.g. sentence length, tree depth, top constituents, tense,
bigram shift, subject number, object number) (Adi et al., 2016; Hupkes
et al., 2018; Conneau et al., 2018; Jawahar et al., 2019; Rogers et al.,
2020). These techniques have revealed a hierarchy of information
processing in multi-layered language models that progresses from simple
to complex with increased depth. In cognitive neuroscience, traditional
experiments study the processing of specific linguistic properties by
carefully controlling the experimental stimulus and observing the
locations or time points of processing in the brain that are affected
the most by the controlled stimulus (Hauk & Pulvermüller, 2004; Pallier
et al., 2011).

More recently, researchers have begun to study the alignment of these
brain language regions with the layers of language models, and found
that the best alignment was achieved in the middle layers of these
models (Jain & Huth, 2018; Toneva & Wehbe, 2019; Caucheteux & King,
2020). This has been

1https://github.com/subbareddy248/linguistic-properties-brain-alignment

37th Conference on Neural Information Processing Systems (NeurIPS 2023).

Figure 1: Approach to directly test for the effect of a linguistic
property on the alignment between a language model and brain recordings.
First, we remove the linguistic property from the language model
representations by learning a simple linear function f that maps the
linguistic property to the language model representations, and use this
estimated function to obtain the residual language model representation
without the contribution of the linguistic property. Next, we compare
the brain alignment (i.e. encoding model performance) before and after
the removal of the linguistic property by learning simple linear
functions g and h that map the full and residual language model
representations to the brain recordings elicited by the corresponding
words. Finally, we test whether the differences in brain alignment
before and after the removal of the linguistic property are significant
and, if so, conclude that the respective linguistic property affects the
alignment between the language model and brain recordings.

hypothesized to be because the middle layers may contain the most
high-level language information as they are farthest from the input and
output layers, which contain word-level information due to the
self-supervised training objective. However, this hypothesis is
difficult to reconcile with the results from more recent NLP probing
tasks Conneau et al. (2018); Jawahar et al. (2019), which suggest that
the deepest layers in the model should represent the highest-level
language information. Taken together, these findings open up the
question of what linguistic information underlies the observed alignment
between brains and language models.

Our work aims to examine this question via a direct approach (see Figure
1 for a schematic). For a number of linguistic properties, we analyze
how the alignment between brain recordings and language model
representations is affected by the elimination of information related to
each linguistic property. For the purposes of this work, we focus on one
popular language model–BERT (Devlin et al., 2018)–which has both been
studied extensively in the NLP interpretability literature (i.e.
BERTology Jawahar et al. (2019)) and has been previously shown to
significantly predict fMRI recordings of people processing language
(Toneva & Wehbe, 2019; Schrimpf et al., 2021). We test the effect of a
range of linguistic properties that have been previously shown to be
represented in pretrained BERT (Jawahar et al., 2019). We use a dataset
of fMRI recordings that are openly available (Nastase et al., 2021) and
correspond to 18 participants listening to a natural story.

Using this direct approach, we find that the elimination of each
linguistic property results in a significant decrease in brain alignment
across all layers of BERT. We additionally find that the syntactic
properties (Top Constituents and Tree Depth) have the highest effect on
the trend of brain alignment across model layers. Specifically, Top
Constituents is responsible for the bump in brain alignment in the
middle layers for all language regions whereas Tree Depth has an impact
for temporal (ATL and PTL) and frontal language regions (IFG and MFG).
Performing the same analyses with a second popular language model, GPT2
(Radford et al., 2019), yielded similar results (see Appendix section
F).

Our main contributions are as follows:

1.  We propose a direct approach to evaluate the joint processing of
    linguistic properties in

brains and language models.

2.  We show that removing specific linguistic properties leads to a
    significant decrease in brain alignment. We find that the tested
    syntactic properties are the most responsible for the trend of brain
    alignment across BERT layers.

3.  Detailed region and sub-region analysis reveal that properties that
    may not impact the whole brain alignment trend, may play a
    significant role in local trends (e.g., Object Number for

2

fMRILinguistic propertyLanguage modelSignificant difference ⇒Ling. prop.
affects alignmentResidual =Original encoding performanceResidual
encoding performanceNaturalistic stimulusThis is Los Angeles. And it’s
the …ATL and IFGOrb regions, Tense for PCC regions, Sentence Length and
Subject Number for PFm sub-region).

We make the code publicly available1.

2 Related Work

Our work is most closely related to that of Toneva et al. (2022), who
employ a similar residual approach to study the supra-word meaning of
language by removing the contribution of individual words to brain
alignment. We build on this approach to study the effect of specific
linguistic properties on brain alignment across layers of a language
model. Other recent work has examined individual attention heads in BERT
and shown that their performance on syntactic tasks correlate with their
brain encoding performance in several brain regions (Kumar et al.,
2022). Our work presents a complementary approach that gives direct
evidence for the importance of a linguistic property to brain alignment.

This work also relates to previous works that investigated the
linguistic properties encoded across the layer hierarchy of language
models (Adi et al., 2016; Hupkes et al., 2018; Conneau et al., 2018;
Jawahar et al., 2019; Rogers et al., 2020). Unlike these studies in NLP,
we focus on understanding the degree to which various linguistic
properties impact the performance of language models in predicting brain
recordings.

Our work also relates to a growing literature that relates
representations of words in language models to those in the brain. A
number of studies have related brain responses to word embedding methods
(Pereira et al., 2016; Anderson et al., 2017; Pereira et al., 2018;
Toneva & Wehbe, 2019; Hollenstein et al., 2019; Wang et al., 2020),
sentence representation models (Sun et al., 2019; Toneva & Wehbe, 2019;
Sun et al., 2020), recurrent neural networks (Jain & Huth, 2018; Oota et
al., 2019), and Transformer methods (Gauthier & Levy, 2019; Toneva &
Wehbe, 2019; Schwartz et al., 2019; Jat et al., 2020; Schrimpf et al.,
2021; Goldstein et al., 2022; Oota et al., 2022b,a; Merlin & Toneva,
2022; Aw & Toneva, 2023; Oota et al., 2023). Our approach is
complementary to these previous works and can be used to further
understand the reasons behind the observed brain alignment.

3 Dataset Curation

Brain Imaging Dataset The “Narratives” collection aggregates a variety
of fMRI datasets collected while human subjects listened to naturalistic
spoken stories. We analyze the “Narratives-21st year” dataset (Nastase
et al., 2021), which is one of the largest publicly available fMRI
datasets (in terms of number of samples per participant). The dataset
contains data from 18 subjects who listened to the story titled “21st
year”. The dataset for each subject contains 2226 samples (TRs-Time
Repetition). The dataset was already preprocessed and projected on the
surface space (“fsaverage6”). We use the multi-modal parcellation of the
human cerebral cortex (Glasser Atlas: consists of 180 ROIs in each
hemisphere) to display the brain maps (Glasser et al., 2016), since the
Narratives dataset contains annotations that correspond to this atlas.
The data covers seven language brain regions of interest (ROIs) in the
human brain with the following subdivisions: (i) angular gyrus (AG: PFm,
PGs, PGi, TPOJ2, and TPOJ3); (ii) anterior temporal lobe (ATL: STSda,
STSva, STGa, TE1a, TE2a, TGv, and TGd); (iii) posterior temporal lobe
(PTL: A4, A5, STSdp, STSvp, PSL, STV, TPOJ1); (iv) inferior frontal
gyrus (IFG: 44, 45, IFJa, IFSp); (v) middle frontal gyrus (MFG: 55b);
(vi) inferior frontal gyrus orbital (IFGOrb: a47r, p47r, a9-46v), (vii)
posterior cingulate cortex (PCC: 31pv, 31pd, PCV, 7m, 23, RSC); and
(viii) dorsal medial prefrontal cortex (dmPFC: 9m, 10d, d32) (Baker et
al., 2018; Milton et al., 2021; Desai et al., 2022).

Extracting Word Features from BERT We investigate the alignment with the
base pretrained BERT model, provided by Hugging Face (Wolf et al., 2020)
(12 layers, 768 dimensions). The primary rationale behind our choice to
analyze the BERT model comes from the extensive body of research that
aims to delve into the extent to which diverse English language
structures are embedded within Transformer-based encoders, a field often
referred to as “BERTology” (Jawahar et al., 2019; Mohebbi et al., 2021).
We follow previous work to extract the hidden-state representations from
each layer of pretrained BERT, given a fixed-length input (Toneva &
Wehbe, 2019). To extract the stimulus features from pretrained BERT, we
constrained the tokenizer to use a maximum context of previous

3

Figure 2: Task Similarity (Pearson Correlation Coefficient) constructed
from the task-wise labels across six tasks. We observe a high
correlation only between Subject Number and Object Number. There are a
number of small positive and negative correlations among the remaining
properties.

20 words. Given the constrained context length, each word is
successively input to the network with at most C previous tokens. For
instance, given a story of M words and considering the context length of
20, while the third word’s vector is computed by inputting the network
with (w1, w2, w3), the last word’s vectors wM is computed by inputting
the network with (wM −20, . . . , wM ). The pretrained Transformer model
outputs word representations at different encoder layers. We use the
#words × 768 dimension vector obtained from each hidden layer to obtain
word-level representations from BERT. For the analyses using GPT-2, we
extract the stimulus features in an identical way from a pretrained
GPT-2, provided by Hugging Face (Wolf et al., 2020) (12 layers, 768
dimensions).

Downsampling Since the rate of fMRI data acquisition (TR = 1.5sec) was
lower than the rate at which the stimulus was presented to the subjects,
several words fall under the same TR in a single acquisition. Hence, we
match the stimulus acquisition rate to fMRI data recording by
downsampling the stimulus features using a 3-lobed Lanczos filter. After
downsampling, we obtain the chunk- embedding corresponding to each TR.

TR Alignment To account for the delay of the hemodynamic response, we
model the hemodynamic response function using a finite response filter
(FIR) per voxel and for each subject separately with 8 temporal delays
corresponding to 12 seconds (Nishimoto et al., 2011).

Probing Tasks Probing tasks (Adi et al., 2016; Hupkes et al., 2018;
Jawahar et al., 2019) help in unpacking the linguistic features possibly
encoded in neural language models. In this paper, we use six popular
probing tasks grouped into three categories–surface (sentence length),
syntactic (tree depth and top constituents), and semantic (tense,
subject number, and object number)–to assess the capability of BERT
layers in encoding each linguistic property. Since other popular probing
tasks such as Bigram Shift, Odd-Man-Out, and Coordination Inversion (as
discussed in Conneau et al. (2018)) have constant labels for our brain
dataset, we focused on the remaining six probing tasks mentioned above.
Details of each probing task are as follows. Sentence Length: This
surface task tests for the length of a sentence. TreeDepth: This
syntactic task tests for classification where the goal is to predict
depth of the sentence’s syntactic tree (with values ranging from 5 to
12). TopConstituents: This syntactic task tests for the sequence of
top-level constituents in the syntactic tree. This is a 20-class
classification task (e.g. ADVP_NP_NP_, CC_ADVP_NP_VP_). Tense: This
semantic task tests for the binary classification, based on whether the
main verb of the sentence is marked as being in the present (PRES class)
or past (PAST class) tense. Subject Number: This semantic task tests for
the binary classification focusing on the number of the subject of the
main clause of a sentence. The classes are NN (singular) and NNS (plural
or mass: “colors”, “waves”, etc). Object Number: This semantic task
tests for the binary classification focusing on the object number in the
main clause of a sentence. Details of these tasks are mentioned in
Conneau et al. (2018).

4

Sentence LengthTreeDepthTopConstituentsTenseSubject NumberObject
NumberSentence Length TreeDepth TopConstituents Tense Subject Number
Object Number
−1−0.500.511.0-0.1380.094-0.0640.0470.002-0.1381.00.1330.126-0.0070.0130.0940.1331.0-0.20.067-0.005-0.0640.126-0.21.0-0.136-0.1040.047-0.0070.067-0.1361.00.6390.0020.013-0.005-0.1040.6391.0Balancing
Classes As discussed in Section 4, our method involves removing one
linguistic property p at a time. Ideally, removing p should not impact
the performance for any other property p′. However, if some classes of p
co-occur very frequently with a few classes of p′, this undesired
behavior may happen. The Left column of Appendix Figure 6 shows the
presence of such frequent class co- occurrences across properties. To
avoid skewed class co-occurrences, we regroup the class labels for three
tasks: Sentence Length, TreeDepth and TopConstituents, as shown in
Appendix Figure 5.

Probing Task Annotations To annotate the linguistic property labels for
each probing task for our dataset, we use Stanford core-NLP stanza
library (Manning et al., 2014) for sentence-level annotations. Further,
for word-level annotations, we assign the same label for all the words
present in a sentence except for the sentence length task.

Probing Tasks Similarity Pearson correlation values between task labels
for each pair of tasks were used to construct the similarity matrix for
the “21st year” stimulus text, as shown in Figure 2. We observe a high
correlation only between Subject Number and Object Number. There are a
number of small positive and negative correlations among the remaining
properties.

4 Methodology

Removal of Linguistic Properties To remove a linguistic property from
the pretrained BERT representations, we use a ridge regression method in
which the probing task label is considered as input and the word
features are the target. We compute the residuals by subtracting the
predicted feature representations from the actual features resulting in
the (linear) removal of a linguistic property from pretrained features
(see Figure 1 for a schematic). Because the brain prediction method is
also a linear function (see next paragraph), this linear removal limits
the contribution of the linguistic property to the eventual brain
prediction performance.

Specifically, given an input matrix Ti with dimension N × 1 for probing
task i, and target word representations W ∈ RN×d, where N denotes the
number of words (8267) and d de- notes the dimensionality of each word
(768 dimension), the ridge regression objective function ∥W − Tiθi∥2 is
f (Ti) = min F where θi denotes the learned weight coefficient for em-
θi bedding dimension d for the input task i, ∥.∥2 F denotes the
Frobenius norm, and λ > 0 is a tunable hyper-parameter representing the
regularization weight for each feature dimension. Using the learned
weight coefficients, we compute the residuals as follows: r(Ti) = W −
Tiθi.

F + λ∥θi∥2

We verified that another popular method of removing properties from
representations–Iterative Null Space Projection (INLP) (Ravfogel et al.,
2020)–leads to similar results (see Appendix Table 4). We present the
results from the ridge regression removal in the main paper due to its
simplicity.

Similar to the probing experiments with pretrained BERT, we also remove
linguistic properties from GPT-2 representations and observe similar
results (see Appendix Table 11).

Voxelwise Encoding Model To explore how linguistic properties are
encoded in the brain when listening to stories, we use layerwise
pretrained BERT features as well as residuals by removing each
linguistic property and using them in a voxelwise encoding model to
predict brain responses. If a linguistic property is a good predictor of
a specific brain region, information about that property is likely
encoded in that region. In this paper, we train fMRI encoding models
using Banded ridge regression (Tikhonov et al., 1977) on stimulus
representations from the feature spaces mentioned above. Before doing
regression, we first z-scored each feature channel separately for
training and testing. This was done to match the features to the fMRI
responses, which were also z-scored for training and testing. The
solution to the banded regression approach is given by f ( ˆβ) = F ,
where Y denotes the voxels matrix across TRs, β denotes the learned
argmin β

F + λ∥β∥2

∥Y − Xβ∥2

regression coefficients, and X denotes stimulus or residual
representations. To find the optimal regularization parameter for each
feature space, we use a range of regularization parameters that is
explored using cross-validation. The main goal of each fMRI encoding
model is to predict brain responses associated with each brain voxel
given a stimulus.

5

Table 1: Word-Level Probing task performance for each BERT layer before
and after removal of each linguistic property using the 21st year
stimuli.

Layers Sentence Length

3-classes (Surface)

before 74.67 69.83 72.31 71.34 72.67 70.38 72.98 72.67 70.50 72.91 70.07
71.77

after 43.28 42.44 46.19 46.43 46.97 44.37 46.55 44.67 45.28 47.93 46.67
42.93

1 2 3 4 5 6 7 8 9 10 11 12

TreeDepth 3-classes (Syntactic) after 42.93 38.88 40.33 38.63 40.88
41.89 41.23 40.08 42.62 41.78 45.47 46.61

before 76.30 76.72 75.76 75.94 76.00 79.02 77.93 76.07 77.15 76.90 77.27
76.39

TopConstituents 2-classes (Syntactic) after 47.28 42.75 48.85 48.00
45.28 43.47 46.43 46.86 44.55 47.76 45.77 48.67

before 77.15 78.60 77.81 78.36 78.60 80.23 80.23 78.90 79.87 78.17 77.69
78.29

Tense 2-classes (Semantic) after 59.25 48.25 44.26 42.56 44.26 44.44
42.62 44.56 47.22 45.47 48.43 45.10

before 87.00 87.18 87.42 88.09 88.39 87.17 88.69 87.42 88.27 88.94 87.24
86.88

Subject Number Object Number

2-classes (Semantic) after 49.95 55.50 48.55 50.12 49.88 55.08 50.24
50.24 52.78 53.68 53.44 51.45

before 92.10 92.32 93.04 93.50 94.05 94.98 95.88 96.10 96.38 96.06 96.94
94.03

2-classes (Semantic) after 47.31 54.59 49.76 50.06 51.45 54.17 47.58
50.18 49.27 50.30 49.52 48.73

before 93.28 93.47 93.80 94.90 93.59 94.50 94.62 95.10 94.56 94.50 94.92
93.95

Cross-Validation The ridge regression parameters were fit using 4-fold
cross-validation. All the data samples from K-1 folds were used for
training, and the generalization was tested on samples from the left-out
fold.

Evaluation Metrics We evaluate our models using Pearson Correlation (PC)
which is a popular metric for evaluating brain alignment (Jain & Huth,
2018; Schrimpf et al., 2021; Goldstein et al., 2022). Let TR be the
number of time repetitions. Let Y = {Yi}T R i=1 denote the actual and
predicted value vectors for a single voxel. Thus, Y ∈ RT R and also ˆY ∈
RT R. We use Pearson Correlation (PC) which is computed as corr(Y, ˆY )
where corr is the correlation function.

i=1 and ˆY = { ˆYi}T R

Implementation Details for Reproducibility All experiments were
conducted on a machine with 1 NVIDIA GEFORCE-GTX GPU with 16GB GPU RAM.
We used banded ridge-regression with the following parameters: MSE loss
function, and L2-decay (λ) varied from 10−1 to 10−3; the best λ was
chosen by tuning on validation data; the number of cross-validation runs
was 4.

5 Results

5.1 Successful removal of linguistic properties from pretrained BERT

To assess the degree to which different layers of pretrained BERT
representation encode labels for each probing task, a probing classifier
is trained over it with the embeddings of each layer. For all probing
tasks, we use logistic regression as the probing classifier. We train
different logistic regression classifiers per layer of BERT using six
probing sentence-level datasets created by Conneau et al. (2018). At
test time, for each sample from 21st year, we extract stimuli
representations from each layer of BERT, and perform classification for
each of the six probing tasks using the learned logistic regression
models. To investigate whether a linguistic property was successfully
removed from the pretrained representations, we further test whether we
can decode the task labels from the residuals for each probing task of
the 21st year stimuli.

Table 1 reports the result for each probing task, before and after
removal of the linguistic property from pretrained BERT. We also report
similar results for GPT2 in Table 11 in the Appendix. Similarly to
earlier works (Jawahar et al., 2019), we find that BERT embeds a rich
hierarchy of linguistic signals also for our 21st year stimuli: surface
information at the initial to middle layers, syntactic information in
the middle, semantic information at the middle to top layers. We verify
that the removal of each linguistic property from BERT leads to reduced
task performance across all layers, as expected.

We further test whether removing information about one property affects
the decoding performance for another property. We observed that most
properties are not substantially affected by removing other task
properties (see Appendix Tables 5, 6, 7, 8, 9 and 10).

5.2 Removal of linguistic properties significantly decreases brain
alignment across all layers

In Figure 3 (left), we present the average brain alignment across all
layers of pretrained BERT before and after the removal of each
linguistic property. Removing each linguistic property leads

6

Figure 3: Brain alignment of pretrained BERT before (blue) and after
(all other bars) removal of different linguistic properties. Left plot
compares the average Pearson correlation across all layers of pretrained
BERT and all voxels, and the same quantity after removal of each
linguistic property. The error bars indicate the standard error of the
mean across participants. The right plot compares the layer-wise
performance of pretrained BERT and removal of one linguistic
property–TopConstituents. A red ∗ at a particular layer indicates that
the alignment from the pretrained model is significantly reduced by the
removal of this linguistic property at this particular layer. The
layer-wise results for removing other linguistic properties differ
across properties, but are significant at the same layers as
TopConstituents and are presented in Appendix Figure 7.

to a significant reduction in brain alignment. In contrast, removing a
randomly generated linguistic property vector (for this baseline, think
about a new task which has no linguistic meaning. The values for each
row is then set to a random value chosen uniformly from across all class
labels) does not significantly affect the brain alignment. This
validates that the reduction in brain alignment observed after removing
the linguistic information is indeed due to the elimination of
linguistic information, rather than to the removal method itself.
Further, we observe that the brain alignment of a random vector is
significantly lower than the residual brain alignment after removal of
each linguistic property. This suggests that there are additional
important properties for the alignment between pretrained BERT and the
fMRI recordings, beyond the ones considered in this work.

In Figure 3 (right), we also report the layer-wise performance for
pretrained BERT before and after the removal of one representative
linguistic property–TopConstituents. We present the results for the
remaining properties in Figure 7 in the Appendix. We also report similar
results for GPT2 in Figure11 in the Appendix. Similarly to previous work
(Toneva & Wehbe, 2019), we observe that pretrained BERT has the best
brain alignment in the middle layers. We observe that the brain
alignment is reduced significantly across all layers after the removal
of the linguistic property (indicated with red cross in the figure). We
observe the most substantial reductions in brain alignment in middle to
late layers. This pattern holds across all tested linguistic properties.
These results provide direct evidence that these linguistic properties
in fact significantly affect the alignment between fMRI recordings and
pretrained BERT.

Statistical Significance To estimate the statistical significance of the
performance differences (across all tasks), we performed a two-tailed
paired-sample t-test on the mean correlation values for the subjects. In
all cases, we report p-values across layers. For all layers, the main
effect of the two-tailed test was significant for all the tasks with p≤
0.05 with confidence 95% . Finally, the Benjamni-Hochberg False
Discovery Rate (FDR) correction for multiple comparisons (Benjamini &
Hochberg, 1995) is used for all tests (appropriate because fMRI data is
considered to have positive dependence (Genovese, 2000)). Overall, the
p-values confirmed that removing each linguistic property from BERT
significantly reduced brain alignment.

Figure 10 in the Appendix displays p-values for the brain alignment of
pretrained BERT before and after the removal of each linguistic property
across all the layers. We observe that the alignment with the whole
brain is significantly reduced across all the layers.

ROI-Level Analysis We further examine the effect on the alignment
specifically in a set of regions of interest (ROI) that are thought to
underlie language comprehension (Fedorenko et al., 2010;

7

Random Vectorpretrained BERTRemoval of Sentence LengthRemoval of
TreeDepthRemoval of TopConstituentsRemoval of TenseRemoval of Subject
NumberRemoval of Object NumberRemoval of All TasksRemoval of Random
Task00.050.1Average across all the layersAvg Pearson
Correlation1234567891011120.060.070.080.090.10.11pretrained BERTRemoval
of TopConstituentsLayer DepthAvg Pearson CorrelationTable 2: ROI-level
(left) and whole brain (right) correlations across layers between 1)
differences in decoding task performance before and after removing each
linguistic property and 2) differences in brain alignment of pretrained
BERT before and after removing the corresponding linguistic property.

IFG IFGOrb MFG PCC dmPFC Whole Brain

Tasks Sentence Length TreeDepth TopConstituents Tense Subject Number
Object Number

PTL

ATL

AG 0.261 0.264 0.220 0.355 0.365 0.421 0.458 0.442 0.489 0.421 0.464
0.516 0.226 0.283 0.307 0.325 0.124 0.201 0.231 0.239 0.306 0.392 0.342
0.313

0.129 0.257 0.453 0.345 0.285 0.503

0.319 0.143 0.436 0.109 0.463 0.459 0.339 0.435 0.228 0.348 0.335 0.328

0.100 0.027 0.463 0.122 0.237 0.001

0.216 0.443 0.451 0.248 0.254 0.263

Table 3: Finer-grained sub-ROI-level correlations across layers between
1) differences in decoding task performance before and after removing
each linguistic property and 2) differences in brain alignment of
pretrained BERT before and after removing the corresponding linguistic
property.

Tasks

AG PFm PGi

ATL

PGs

STGa STSda STSdp A5

Sentence Length 0.386 0.381 0.286 0.258 0.356 0.461 0.479 0.414
TreeDepth 0.479 0.526 0.454 0.336 TopConstituents 0.369 0.365 0.276
0.279 Tense 0.335 0.134 0.068 0.271 Subject Number 0.396 0.203 0.298
0.443 Object Number

0.227 0.515 0.426 0.238 0.270 0.438

0.210 0.550 0.425 0.368 0.225 0.370

0.176 0.525 0.477 0.309 0.246 0.287

PTL

TPOJ1 0.230 0.469 0.428 0.340 0.158 0.328

IFG

45

IFJa

STV SFL

IFSp 44 PSL 0.317 0.246 0.231 0.317 0.372 0.397 0.357 0.287 0.458 0.418
0.430 0.474 0.439 0.516 0.463 0.360 0.398 0.531 0.581 0.353 0.413 0.314
0.328 0.329 0.285 0.377 0.321 0.338 0.302 0.226 0.256 0.283 0.267 0.271
0.164 0.279 0.398 0.310 0.319 0.335 0.318 0.321

Fedorenko & Thompson-Schill, 2014) and word semantics (Binder et al.,
2009). We find that across language regions, the alignment is
significantly decreased by the removal of the linguistic properties
across all layers (see Appendix Figure 8). We further investigate the
language sub-regions, such as 44, 45, IFJa, IFSp, STGa, STSdp, STSda,
A5, PSL, and STV and find that they also align significantly worse after
the removal of the linguistic properties from pretrained BERT (see
Appendix Figure 9).

5.3 Decoding task performance vs brain alignment

While the previous analyses revealed the importance of linguistic
properties for brain alignment at individual layers, we would also like
to understand the contribution of each linguistic property to the trend
of brain alignment across layers. For this purpose, we perform both
quantitative and qualitative analyses by measuring the correlation
across layers between the differences in decoding task performance from
pretrained and residual BERT and the differences in brain alignment of
pretrained BERT and residual BERT. A high correlation for a specific
linguistic property suggests a strong relationship between the presence
of this property across layers in the model and its corresponding effect
on the layer-wise brain alignment. Note that this analysis can provide a
more direct and stronger claim for the effect of a linguistic property
on the brain alignment across layers than alternate analyses, such as
computing the correlation between the decoding task performance and the
brain alignment across layers only at the level of the pretrained model.
We present the results of these analyses for the whole brain and
language regions, and language sub-regions in Tables 2 and 3,
respectively.

Whole Brain Analysis High correlations in the last column of Table 2
indicate that the syntactic NLP tasks TopConstituents and TreeDepth have
the strongest effect on the alignment between BERT and the whole brain.
At the level of the whole brain, surface level and semantic properties
have a moderate effect on the trend in brain alignment across layers.

ROI-Level Analysis Further, we analyze these correlations for each
language brain region sepa- rately, and report the results in the
remaining columns of Table 2. We make the following observations: (1)
Both TreeDepth and TopConstituents are responsible for the bump in brain
alignment not just for the entire brain but also for several language
ROIs. TopConstituents is important across all language ROIs, but most
important in IFG which is related to syntax. This result aligns with
previous work that has found the inferior frontal regions to be
sensitive to syntax (Friederici et al., 2003; Friederici, 2012). (2)
Unlike TopConstituents which has a strong effect on the alignment with
all language ROI, TreeDepth has a strong effect only on alignment with
the temporal (ATL and PTL) and frontal regions (IFG and MFG). (3)
Although semantic properties are not shown to be responsible for the
shape in brain alignment at the whole-brain level, semantic properties
such as Tense, Subject Number and Object Number affect the alignment
more specifically in PCC. This finding agrees with previous work which
suggests the PCC supports word semantics (Binder et al., 2009). (4) The
surface property

8

Figure 4: Voxel-wise correlations across layers between 1) differences
in decoding task performance before and after removing each property and
2) differences in brain alignment of pretrained BERT before and after
removing the corresponding linguistic property. Here L/R denotes the
left and right hemispheres.

Sentence Length has a strong effect on the alignment with the IFG and
MFG, but not as high as the syntactic properties in these language ROIs.

Sub-ROI-Level Analysis Each language brain region is not necessarily
homogeneous in function across all voxels it contains. Therefore, an
aggregate analysis across an entire language region may mask some
nuanced effects. Thus, we further analyze several important language
sub-regions that are thought to exemplify the variety of functionality
across some of the broader language regions (Rolls et al., 2022): AG
sub-regions (PFm, PGi, PGs), ATL sub-regions (STGa, STSda), PTL
sub-regions (STSdp, A5, TPOJ1, PSL, STV, SFL), and IFG sub-regions (44,
45, IFJa, IFSp). We present the correlations for each of these
sub-regions separately in Table 3. We make the following observations:
(1) Although TopConstituents strongly affect the trend in the brain
alignment across layers for the IFG, it strongly affects the trend for
only three sub-regions (44, 45, and IFSp). It is possible that other
factors affect the trend in alignment with IFJa across layers, as this
IFG region is involved in many cognitive processes, including working
memory for maintaining and updating ongoing information (Rainer et al.,
1998; Zanto et al., 2011; Gazzaley & Nobre, 2012). (2) While
TopConstituents was shown to have the strongest effect on the brain
alignment with the whole IFG, the alignment with two of the IFG
sub-regions (IFSp and IFJa) is more strongly affected by Tree Depth. (3)
Subject Number has a medium to strong effect on the alignment with AG
sub-region PFm. This implies that the semantic property Subject Number
is important in at least one sub-region of language ROI. (4) Similarly,
we find Object Number to be important for the trend of alignment across
layers with most language sub-regions of ATL and PTL. Taken together,
these results show that the semantic properties are most responsible for
the trend in brain alignment across layers for many language sub-regions
of ATL, PTL and AG, while syntactic properties have the highest effect
on the alignment with the IFG.

Qualitative Analysis To present the correlations above at an even finer
grain, we show them now at the voxel-wise level in Figure 4. We make the
following qualitative observations: (1) These results confirm that
Sentence Length and Subject Number are the least related to the pattern
of the brain alignment across layers. (2) The effect of Tree Depth, Top
Constituents, and Object Number is more localized to the canonical
language regions in the left hemisphere and is more distributed in the
right hemisphere. (3) The semantic property Object Number has a much
larger effect on the alignment with the left hemisphere. Furthermore,
Appendix Figure 12 shows the voxel-wise correlations across layers when
removing all linguistic properties, instead of each individual one. We
observe that removing all linguistic properties leads to very different
region-level brain maps compared to removing individual

9

Removal of Subject NumberRemoval of TenseL/RRemoval of
TopConstituentsRemoval of Sentence Length Removal of TreeDepth Removal
of Object NumberL/RL/RL/RL/RL/Rlinguistic properties (Figure 4), and
that the remaining correlation across layers after removing all
linguistic properties is not substantial in the key language regions.

6 Discussion and Conclusion

We propose a direct approach for evaluating the joint processing of
linguistic properties in brains and language models. We show that the
removal of a range of linguistic properties from both language models
(pretrained BERT and GPT2) leads to a significant decrease in brain
alignment across all layers in the language model.

To understand the contribution of each linguistic property to the trend
of brain alignment across layers, we leverage an additional analysis for
the whole brain, language regions and language sub-regions: computing
the correlations across layers between 1) differences in decoding task
performance before and after removing each linguistic property and 2)
differences in brain alignment of pretrained BERT before and after
removing the corresponding linguistic property. For the whole brain, we
find that Tree Depth and Top Constituents are the most responsible for
the trend in brain alignment across BERT layers. Specifically,
TopConstituents has the largest effect on the trend in brain alignment
across BERT layers for all language regions, whereas TreeDepth has a
strong effect on a smaller subset of regions that include temporal (ATL
and PTL) and frontal language regions (IFG and MFG). Further, although
other properties may not have a large impact at the whole brain level,
they are important locally. We find that semantic properties, such as
Tense, Subject Number, and Object Number affect the alignment with more
semantic regions, such as PCC (Binder et al., 2009).

One limitation of our removal approach is that any information that is
correlated with the removed linguistic property in our dataset will also
be removed. This limitation can be alleviated by increasing the dataset
size, which is becoming increasingly possible with new releases of
publicly available datasets. It is also important to note that while we
find that several linguistic properties affect the alignment between
fMRI recordings and a pretrained language model, we also observed that
there is substantial remaining brain alignment after removal of all
linguistic properties. This suggests that our analysis has not accounted
for all linguistic properties that are jointly processed. Future work
can build on our approach to incorporate additional linguistic
properties to fully characterize the joint processing of information
between brains and language models. The current study was performed
using experimental stimulus in English and language models trained on
English text. While we expect our results to be generalizable at least
to languages that are syntactically close to English, this should be
explored by future work. Additionally, investigating larger language
models beyond the two models used in our study, BERT and GPT-2, can
contribute to an even more comprehensive understanding of the reasons
for alignment between language models and human brain activity.

The insights gained from our work have implications for AI engineering,
neuroscience and model interpretability–some in the short-term, others
in the long-term. AI engineering: Our work most immediately fits in with
the neuro-AI research direction that specifically investigates the
relationship between representations in the brain and representations
learned by powerful neural network models. This direction has gained
recent traction, especially in the domain of language, thanks to
advancements in language models (Schrimpf et al., 2021; Goldstein et
al., 2022). Our work most immediately contributes to this line of
research by understanding the reasons for the observed similarity in
more depth. Specifically, our work can guide linguistic feature
selection, facilitate improved transfer learning, and help in the
development of cognitively plausible AI architectures. Computational
Modeling in Neuroscience: Researchers have started viewing language
models as useful model organisms for human language processing (Toneva,
2021) since they implement a language system in a way that may be very
different from the human brain, but may nonetheless offer insights into
the linguistic tasks and computational processes that are sufficient or
insufficient to solve them (McCloskey, 1991; Baroni, 2020). Our work
enables cognitive neuroscientists to have more control over using
language models as model organisms of language processing. Model
Interpretability: In the long-term, we hope that our approach can
contribute to another line of work that uses brain signals to interpret
the information contained by neural network models (Toneva & Wehbe,
2019; Aw & Toneva, 2023). We believe that the addition of linguistic
features by our approach can further increase the model interpretability
enabled by this line of work. Overall, we hope that our approach can be
used to better understand the necessary and sufficient properties that
lead to significant alignment between brain recordings and language
models.

10

References

Yossi Adi, Einat Kermany, Yonatan Belinkov, Ofer Lavi, and Yoav
Goldberg. Fine-grained analysis of sentence embeddings using auxiliary
prediction tasks. arXiv preprint arXiv:1608.04207, 2016.

Andrew J Anderson, Douwe Kiela, Stephen Clark, and Massimo Poesio.
Visually grounded and textual semantic models differentially decode
brain activity associated with concrete and abstract nouns. TACL,
5:17–30, 2017.

Khai Loong Aw and Mariya Toneva. Training language models to summarize
narratives improves brain alignment. In The Eleventh International
Conference on Learning Representations, 2023.

Cordell M Baker, Joshua D Burks, Robert G Briggs, Andrew K Conner, Chad
A Glenn, Kathleen N Taylor, Goksel Sali, Tressie M McCoy, James D
Battiste, Daniel L O’Donoghue, et al. A connec- tomic atlas of the human
cerebrum—chapter 7: the lateral parietal lobe. Operative Neurosurgery,
15(suppl_1):S295–S349, 2018.

Marco Baroni. Linguistic generalization and compositionality in modern
artificial neural networks.

Philosophical Transactions of the Royal Society B, 375(1791):20190307,
2020.

Yoav Benjamini and Yosef Hochberg. Controlling the false discovery rate:
a practical and powerful approach to multiple testing. Journal of the
Royal statistical society: series B (Methodological), 57(1):289–300,
1995.

Jeffrey R Binder, Rutvik H Desai, William W Graves, and Lisa L Conant.
Where is the semantic system? a critical review and meta-analysis of 120
functional neuroimaging studies. Cerebral cortex, 19(12):2767–2796,
2009.

Charlotte Caucheteux and Jean-Rémi King. Language processing in brains
and deep neural networks:

computational convergence and its limits. BioRxiv, 2020.

Alexis Conneau, German Kruszewski, Guillaume Lample, Loïc Barrault, and
Marco Baroni. What you can cram into a single! vector: Probing sentence
embeddings for linguistic properties. In ACL 2018-56th Annual Meeting of
the Association for Computational Linguistics, volume 1, pp. 2126–2136.
Association for Computational Linguistics, 2018.

Rutvik Desai, Usha Tadimeti, and Nicholas Riccardi. Proper and common
names in the semantic

system, 2022.

Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. Bert:
Pre-training of deep bidirectional transformers for language
understanding. arXiv preprint arXiv:1810.04805, 2018.

E. Fedorenko, P.-J. Hsieh, A. Nieto-Castanon, S. Whitfield-Gabrieli, and
N. Kanwisher. New method for fMRI investigations of language: Defining
ROIs functionally in individual subjects. Journal of Neurophysiology,
104(2):1177–1194, 2010.

Evelina Fedorenko and Sharon L Thompson-Schill. Reworking the language
network. Trends in

cognitive sciences, 18(3):120–126, 2014.

Angela D Friederici. The cortical language circuit: from auditory
perception to sentence comprehen-

sion. Trends in cognitive sciences, 16(5):262–268, 2012.

Angela D Friederici, Shirley-Ann Rüschemeyer, Anja Hahne, and Christian
J Fiebach. The role of left inferior frontal and superior temporal
cortex in sentence comprehension: localizing syntactic and semantic
processes. Cerebral cortex, 13(2):170–177, 2003.

Jon Gauthier and Roger Levy. Linking artificial and human neural
representations of language. Proceedings of the 2019 Conference on
Empirical Methods in Natural Language Processing and the 9th
International Joint Conference on Natural Language Processing
(EMNLP-IJCNLP), 2019.

Adam Gazzaley and Anna C Nobre. Top-down modulation: bridging selective
attention and working

memory. Trends in cognitive sciences, 16(2):129–135, 2012.

Christopher R Genovese. A bayesian time-course model for functional
magnetic resonance imaging

data. Journal of the American Statistical Association, 95(451):691–703,
2000.

11

Matthew F Glasser, Timothy S Coalson, Emma C Robinson, Carl D Hacker,
John Harwell, Essa Yacoub, Kamil Ugurbil, Jesper Andersson, Christian F
Beckmann, Mark Jenkinson, et al. A multi-modal parcellation of human
cerebral cortex. Nature, 536(7615):171–178, 2016.

Ariel Goldstein, Zaid Zada, Eliav Buchnik, Mariano Schain, Amy Price,
Bobbi Aubrey, Samuel A Nastase, Amir Feder, Dotan Emanuel, Alon Cohen,
et al. Shared computational principles for language processing in humans
and deep language models. Nature neuroscience, 25(3):369–380, 2022.

Olaf Hauk and Friedemann Pulvermüller. Effects of word length and
frequency on the human

event-related potential. Clinical Neurophysiology, 115(5):1090–1103,
2004.

Nora Hollenstein, Antonio de la Torre, Nicolas Langer, and Ce Zhang.
Cognival: A framework for

cognitive word embedding evaluation. In CoNLL, pp. 538–549, 2019.

Dieuwke Hupkes, Sara Veldhoen, and Willem Zuidema. Visualisation
and’diagnostic classifiers’ reveal how recurrent and recursive neural
networks process hierarchical structure. Journal of Artificial
Intelligence Research, 61:907–926, 2018.

Shailee Jain and Alexander Huth. Incorporating context into language
encoding models for fMRI. In

Advances in Neural Information Processing Systems, pp. 6628–6637, 2018.

S Jat, H Tang, P Talukdar, and T Mitchel. Relating simple sentence
representations in deep neural

networks and the brain. In ACL, pp. 5137–5154, 2020.

Ganesh Jawahar, Benoît Sagot, and Djamé Seddah. What does bert learn
about the structure of language? In ACL 2019-57th Annual Meeting of the
Association for Computational Linguistics, 2019.

Sreejan Kumar, Theodore R Sumers, Takateru Yamakoshi, Ariel Goldstein,
Uri Hasson, Kenneth A Norman, Thomas L Griffiths, Robert D Hawkins, and
Samuel A Nastase. Reconstructing the cascade of language processing in
the brain using the internal computations of a transformer-based
language model. bioRxiv, 2022.

Christopher D Manning, Mihai Surdeanu, John Bauer, Jenny Rose Finkel,
Steven Bethard, and David McClosky. The stanford corenlp natural
language processing toolkit. In Proceedings of 52nd annual meeting of
the association for computational linguistics: system demonstrations,
pp. 55–60, 2014.

Michael McCloskey. Networks and theories: The place of connectionism in
cognitive science.

Psychological science, 2(6):387–395, 1991.

Gabriele Merlin and Mariya Toneva. Language models and brain alignment:
beyond word-level

semantics and prediction. arXiv preprint arXiv:2212.00596, 2022.

Camille K Milton, Vukshitha Dhanaraj, Isabella M Young, Hugh M Taylor,
Peter J Nicholas, Robert G Briggs, Michael Y Bai, Rannulu D Fonseka,
Jorge Hormovas, Yueh-Hsin Lin, et al. Parcellation- based anatomic model
of the semantic network. Brain and behavior, 11(4):e02065, 2021.

Hosein Mohebbi, Ali Modarressi, and Mohammad Taher Pilehvar. Exploring
the role of bert token representations to explain sentence probing
results. In The 2021 Conference on Empirical Methods in Natural Language
Processing, pp. 792–806. Association for Computational Linguistics,
2021.

Samuel A Nastase, Yun-Fei Liu, Hanna Hillman, Asieh Zadbood, Liat
Hasenfratz, Neggin Ke- shavarzian, Janice Chen, Christopher J Honey,
Yaara Yeshurun, Mor Regev, et al. The “narratives” fmri dataset for
evaluating models of naturalistic language comprehension. Scientific
data, 8(1): 1–22, 2021.

Shinji Nishimoto, An T Vu, Thomas Naselaris, Yuval Benjamini, Bin Yu,
and Jack L Gallant. Reconstructing visual experiences from brain
activity evoked by natural movies. Current biology, 21(19):1641–1646,
2011.

Subba Reddy Oota, Vijay Rowtula, Manish Gupta, and Raju S Bapi.
Stepencog: A convolutional

lstm autoencoder for near-perfect fmri encoding. In IJCNN, pp. 1–8.
IEEE, 2019.

12

Subba Reddy Oota, Frederic Alexandre, and Xavier Hinaut. Long-term
plausibility of language models and neural dynamics during narrative
listening. In Proceedings of the Annual Meeting of the Cognitive Science
Society, volume 44, 2022a.

Subba Reddy Oota, Jashn Arora, Veeral Agarwal, Mounika Marreddy, Manish
Gupta, and Bapi Raju Surampudi. Neural language taskonomy: Which nlp
tasks are the most predictive of fmri brain activity? NAACL, 2022b.

Subba Reddy Oota, Mounika Marreddy, Manish Gupta, and Bapi Raju
Surampud. Syntactic structure processing in the brain while listening.
Findings of the Association for Computational Linguistics: ACL, 2023.

Christophe Pallier, Anne-Dominique Devauchelle, and Stanislas Dehaene.
Cortical representation of the constituent structure of sentences.
Proceedings of the National Academy of Sciences, 108(6): 2522–2527,
2011.

Francisco Pereira, Bin Lou, Brianna Pritchett, Nancy Kanwisher, Matthew
Botvinick, and Evelina Fedorenko. Decoding of generic mental
representations from functional mri data using word embeddings. bioRxiv,
pp. 057216, 2016.

Francisco Pereira, Bin Lou, Brianna Pritchett, Samuel Ritter, Samuel J
Gershman, Nancy Kanwisher, Matthew Botvinick, and Evelina Fedorenko.
Toward a universal decoder of linguistic meaning from brain activation.
Nature communications, 9(1):1–13, 2018.

Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya
Sutskever, et al. Language

models are unsupervised multitask learners. OpenAI blog, 1(8):9, 2019.

Gregor Rainer, Wael F Asaad, and Earl K Miller. Memory fields of neurons
in the primate prefrontal

cortex. Proceedings of the National Academy of Sciences,
95(25):15008–15013, 1998.

Shauli Ravfogel, Yanai Elazar, Hila Gonen, Michael Twiton, and Yoav
Goldberg. Null it out: Guarding protected attributes by iterative
nullspace projection. Association for Computational Linguistics, 2020.

Anna Rogers, Olga Kovaleva, and Anna Rumshisky. A primer in bertology:
What we know about how bert works. Transactions of the Association for
Computational Linguistics, 8:842–866, 2020.

Edmund T Rolls, Gustavo Deco, Chu-Chung Huang, and Jianfeng Feng. The
human language

effective connectome. NeuroImage, pp. 119352, 2022.

Martin Schrimpf, Idan Asher Blank, Greta Tuckute, Carina Kauf, Eghbal A
Hosseini, Nancy Kan- wisher, Joshua B Tenenbaum, and Evelina Fedorenko.
The neural architecture of language: Integrative modeling converges on
predictive processing. Proceedings of the National Academy of Sciences,
118(45), 2021.

Dan Schwartz, Mariya Toneva, and Leila Wehbe. Inducing brain-relevant
bias in natural language

processing models. Advances in neural information processing systems,
32, 2019.

Jingyuan Sun, Shaonan Wang, Jiajun Zhang, and Chengqing Zong. Towards
sentence-level brain

decoding with distributed representations. In AAAI, pp. 7047–7054, 2019.

Jingyuan Sun, Shaonan Wang, Jiajun Zhang, and Chengqing Zong. Neural
encoding and decoding with distributed sentence representations. IEEE
Transactions on Neural Networks and Learning Systems, 32(2):589–603,
2020.

Andre˘ı Nikolaevich Tikhonov, Vasilij Ja Arsenin, and Vasili˘ı Arsenin.
Solutions of ill-posed problems.

V H Winston, 1977.

Mariya Toneva. Bridging Language in Machines with Language in the Brain.
PhD thesis, Carnegie

Mellon University, 2021.

Mariya Toneva and Leila Wehbe.

Interpreting and improving natural-language processing (in machines)
with natural language-processing (in the brain). Advances in Neural
Information Processing Systems, 32, 2019.

13

Mariya Toneva, Tom M Mitchell, and Leila Wehbe. Combining computational
controls with natural text reveals aspects of meaning composition.
Nature Computational Science, 2(11):745–757, 2022.

Shaonan Wang, Jiajun Zhang, Haiyan Wang, Nan Lin, and Chengqing Zong.
Fine-grained neural

decoding with distributed word representations. Information Sciences,
507:256–272, 2020.

Leila Wehbe, Ashish Vaswani, Kevin Knight, and Tom Mitchell. Aligning
context-based statistical models of language with brain activity during
reading. In Proceedings of the 2014 Conference on Empirical Methods in
Natural Language Processing, pp. 233–243, 2014.

Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement
Delangue, Anthony Moi, Pierric Cistac, Tim Rault, Rémi Louf, Morgan
Funtowicz, et al. Transformers: State-of-the-art natural language
processing. In Proceedings of the 2020 conference on empirical methods
in natural language processing: system demonstrations, pp. 38–45, 2020.

Theodore P Zanto, Michael T Rubens, Arul Thangavel, and Adam Gazzaley.
Causal role of the prefrontal cortex in top-down modulation of visual
processing and working memory. Nature neuroscience, 14(5):656–661, 2011.

14

Appendix

A Distribution of Class Labels Across Each Probing Task

Figure 5 reports the distribution of class labels across each linguistic
property. For the probing tasks such as Sentence Length, Tree Depth, and
Top Constituents, we balance the number of classes to overcome the
imbalance problem. We balance the classes for these three probing tasks
as follows: (i) Sentence Length: 3-classes (≤5, 5-8 and ≥9), (ii)
TreeDepth: 3-classes (5, 6-7 and ≥8), and TopConstituents: 2-classes (1,
≥2).

Figure 5: Distribution of class labels across each linguistic property.
For the probing tasks such as Sentence Length, Tree Depth, and Top
Constituents, we balance the number of classes to overcome the imbalance
problem.

Figure 6 displays the common samples between class labels of pair of
probing tasks. This reports whether the cells are balanced across class
labels of different probing tasks.

15

45224088301022975-89-1213-1617-2021-2526-28<=50100200300400Sentence
LengthClass LabelsFrequency of each class
label4523702975-8>=9<=50100200300400Sentence LengthClass LabelsFrequency
of each class
label3392252001467851374356789101112050100150200250300350TreeDepthClass
LabelsFrequency of each class
label3392255555670100200300400500TreeDepthClass LabelsFrequency of each
class
label484142112811181249575502351114117412317112345678910111213141516171819200100200300400500TopConstituentsClass
LabelsFrequency of each class
label484635120100200300400500600TopConstituentsClass LabelsFrequency of
each class label282837120200400600800TenseClass LabelsFrequency of each
class label1020991202004006008001000Subject NumberClass LabelsFrequency
of each class label10081111202004006008001000Object NumberClass
LabelsFrequency of each class labelFigure 6: Number of common samples
between pair of class labels across probing tasks.

B INLP Projection vs. Our Method

We also implemented the Iterative Null-Space Projection (INLP) method
(Ravfogel et al., 2020) to verify whether our removal method performance
is similar to previously proposed method. We found the results to be
similar. Results using our method are in Table 4. Results using the INLP
method are below.

16

567891011121 2 3 4 5 6 7 TreeDepthSentence
Length9814011162286524336653372117905112062191601067241001110115000000112374511400005671
2 3 TreeDepthSentence
Length98140214440326237451512345678910111213141516171819201 2 3 4 5 6 7
TopConstituentsSentence
Length232515112422316210111712525562278485776585326401226612920240413146010301010073412010302103000011110030102001010000000200100000010000000000015031410412270054202420337121
2 3 TopConstituentsSentence
Length23222010226815014712345678910111213141516171819205 6 7 8 9 10 11
12
TopConstituentsTreeDepth155546104132922641254206521222126113118087033010010984191754171101731471115576621152628319001127380271930112510930100320110220302032120001100221111011101112301010200924000301201100011000125
6 7 TopConstituentsTreeDepth155184122103207348121 2 3 4 5 6 7
TenseSentence Length973555118913757231902113184121 2 3 TenseSentence
Length9735572298113184125 6 7 8 9 10 11 12
TenseTreeDepth1282114318251149311151563942334241125 6 7
TenseTreeDepth12821143182111444121 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16
17 18 19 20
TenseTopConstituents534312012256721386125710392928505456171438865648262105265615121
2 TenseTopConstituents53431229406Table 4: Word-Level: INLP Projection
Method vs Our Removal Method: Probing task accuracy for each BERT layer
after removal of each linguistic property using the 21st year stimuli.

Layers 1 2 3 4 5 6 7 8 9 10 11 12 Avg (INLP) Avg (Ours) Chance
(Probability)

Sentence Length TreeDepth TopConstituents Tense Subject Number Object
Number

38.23 37.03 37.20 38.71 39.18 37.96 39.43 38.85 37.00 38.87 36.15 38.14
38.06 45.30 42.76

57.92 34.36 28.94 28.54 41.17 33.19 35.97 27.32 27.99 36.69 42.68 51.33
37.17 41.77 50.39

49.36 41.47 36.76 54.72 47.27 46.97 36.94 36.94 49.46 36.94 51.93 55.19
45.32 46.30 53.63

50.75 44.13 59.12 40.81 41.54 34.82 45.68 48.77 64.99 45.28 36.27 31.19
45.27 46.36 66.31

50.50 47.61 48.37 48.04 60.27 48.24 50.09 58.09 60.50 56.16 57.65 49.81
52.94 51.75 83.24

50.89 49.20 47.73 56.03 54.48 50.88 60.27 47.18 48.65 47.75 62.87 47.04
51.91 50.24 80.78

B.1 Probing Analysis While Removing Information about a Property and
Testing Another

We run the probing analysis while removing information about a property
and testing another, to see if only information specific about a task is
being removed at a time. The detailed result of each probing task is
presented Tables 5, 6, 7, 8, 9, and 10. We observe that removal of a
task (property) does not affect the performance for other tasks except
for TreeDepth and TopConstituents. Table 5: Layer-wise Probing task
performance for Sentence Length task. Note in tables below AR=After
Removal and BR=before removal.

Layers BR Sentence Length AR Sentence Length AR TreeDepth AR
TopConstituents AR Tense AR SubjNum AR ObjNum

1 2 3 4 5 6 7 8 9 10 11 12 Avg

74.67 69.83 72.31 71.34 72.67 70.38 72.98 72.67 70.50 72.91 70.07 71.77
71.84

43.28 42.44 46.19 46.43 46.97 44.37 46.55 44.67 45.28 47.93 46.67 42.93
45.30

69.47 70.37 71.22 71.64 71.10 69.89 71.22 70.07 70.07 68.92 67.35 66.92
64.01

72.37 73.09 72.85 71.52 74.37 72.91 71.52 70.98 69.35 70.92 70.49 68.62
71.58

72.24 73.28 73.94 73.40 76.24 74.61 75.03 74.06 72.31 71.89 73.06 70.31
73.36

71.52 73.04 73.22 74.00 74.06 74.00 74.12 74.73 73.16 71.95 71.64 71.64
73.09

73.58 74.18 74.12 73.52 76.54 74.79 74.30 72.73 71.83 72.49 71.83 71.40
73.44

Table 6: Layer-wise Probing task performance for TreeDepth task. Note in
tables below AR=After Removal and BR=before removal.

Layers BR TreeDepth AR TreeDepth AR SentenceLength AR TopConstituents AR
Tense AR SubjectNumber AR ObjectNumber

1 2 3 4 5 6 7 8 9 10 11 12 Average

76.30 76.72 75.76 75.94 76.00 79.02 77.93 76.07 77.15 76.90 77.27 76.39
76.79

42.93 38.88 40.33 38.63 40.88 41.89 41.23 40.08 42.62 41.78 45.47 46.61
41.77

76.84 76.48 77.97 77.20 76.48 76.17 77.14 76.05 76.90 76.05 75.15 75.99
76.56

77.62 76.96 76.42 77.08 76.36 76.60 77.56 76.66 77.08 76.54 76.42 76.23
76.70

77.69 76.90 79.62 78.42 78.11 78.11 77.50 76.36 77.93 74.84 76.17 77.75
77.75

75.93 77.63 76.84 77.38 77.67 76.30 77.50 76.06 78.47 76.29 77.56 75.09
75.09

76.78 76.54 75.57 75.82 76.23 77.81 77.81 76.84 77.38 76.42 77.14 76.01
76.70

C Layer-wise Whole Brain Analysis before/after removal of linguistic

properties.

In Figure 7, we report the layer-wise performance for pretrained BERT
before and after the removal of each of the linguistic properties.
Similar to previous work (Toneva & Wehbe, 2019), we observe that
pretrained BERT has best brain alignment in the middle layers across all
properties. We further observe that the alignment after removing the
linguistic property is significantly worse mainly for middle to late
layers. Note that the layers at which there is a significant difference
are indicated with a red dot. This pattern holds across all of the
linguistic properties that we tested. These results provide

17

Table 7: Layer-wise Probing task performance for TopConstituents task.
Note in tables below AR=After Removal and BR=before removal.

Layers BR TopConstituents AR TopConstituents AR SentenceLength AR
TreeDepth AR Tense AR SubjectNumber AR ObjectNumber

1 2 3 4 5 6 7 8 9 10 11 12 Average

77.15 78.60 77.81 78.36 78.60 80.23 80.23 78.90 79.87 78.17 77.69 78.29
78.66

47.28 42.75 48.85 48.00 45.28 43.47 46.43 46.86 44.55 47.76 45.77 48.67
46.30

78.17 77.69 76.36 77.69 77.87 78.71 78.65 77.63 77.76 77.81 78.42 76.36
77.76

78.11 78.54 77.15 77.03 78.42 79.20 78.66 78.36 78.30 77.87 78.84 78.78
78.27

76.72 78.41 77.15 77.81 78.35 77.21 77.39 78.41 78.71 78.41 77.03 75.21
78.16

77.39 77.81 77.69 78.23 77.93 78.54 79.02 79.08 79.87 78.96 78.00 78.30
78.40

77.81 77.93 77.75 77.69 78.36 78.65 79.38 79.44 78.89 78.42 78.00 78.36
78.39

Table 8: Layer-wise Probing task performance for Tense task. Note in
tables below AR=After Removal and BR=before removal.

Layers BR Tense AR Tense AR SentenceLength AR TreeDepth AR
TopConstituents AR SubjectNumber AR ObjectNumber

1 2 3 4 5 6 7 8 9 10 11 12 Average

87.00 87.18 87.42 88.09 88.39 87.17 88.69 87.42 88.27 88.94 87.24 86.88
87.72

59.25 48.25 44.26 42.56 44.26 44.44 42.62 44.56 47.22 45.47 48.43 45.10
46.36

87.00 88.15 87.55 87.42 88.03 86.33 86.52 86.82 87.79 88.75 86.88 86.40
87.30

86.22 87.06 87.30 87.49 88.08 86.70 88.33 87.24 87.84 88.21 87.42 86.64
87.38

85.91 87.54 87.48 86.82 87.73 86.22 88.09 86.64 87.73 86.15 86.94 85.31
86.88

85.07 86.22 87.55 87.36 87.12 87.42 87.30 86.52 87.67 87.90 87.00 85.97
86.93

86.82 86.64 87.18 87.73 87.67 86.46 87.79 84.95 87.48 88.21 86.46 86.40
86.98

Table 9: Layer-wise Probing task performance for Subject Number task.
Note in tables below AR=After Removal and BR=before removal.

Layers BR SubjectNumber AR SubjectNumber AR SentenceLength AR TreeDepth
AR TopConstituents AR Tense AR ObjectNumber

1 2 3 4 5 6 7 8 9 10 11 12 Average

87.00 92.32 93.04 93.50 94.05 94.98 95.88 96.10 96.38 96.06 96.94 94.03
94.19

59.25 55.50 48.55 50.12 49.88 55.08 50.24 50.24 52.78 53.68 53.44 51.45
51.75

87.57 86.40 86.84 86.56 87.78 87.59 87.84 87.35 87.52 87.78 87.29 87.44
87.33

87.76 86.57 86.94 86.52 87.87 87.77 87.94 87.65 87.55 8.07 87.49 87.55
87.46

87.88 86.45 86.77 86.68 87.59 87.76 87.56 87.04 87.32 87.80 87.47 87.64
87.33

87.56 86.15 86.91 86.97 87.70 87.88 87.76 86.85 87.09 87.31 86.97 87.23
87.20

71.61 69.82 70.17 70.84 70.07 70.96 70.66 71.13 70.50 70.91 70.81 70.84
70.69

Table 10: Layer-wise Probing task performance for Object Number task.
Note in tables below AR=After Removal and BR=before removal.

Layers BR ObjectNumber AR ObjectNumber AR SentenceLength AR TreeDepth AR
TopConstituents AR Tense AR SubjectNumber

1 2 3 4 5 6 7 8 9 10 11 12 Average

93.28 93.47 93.80 94.90 93.59 94.50 94.62 95.10 94.56 94.50 94.92 93.95
94.27

47.31 54.59 49.76 50.06 51.45 54.17 47.58 50.18 49.27 50.30 49.52 48.73
50.24

86.63 86.55 86.88 85.81 86.17 86.27 86.38 85.86 85.63 86.21 84.94 85.49
86.07

86.68 86.61 86.84 85.87 86.42 86.45 86.42 85.79 85.61 86.16 84.95 85.33
86.11

86.77 86.63 86.85 85.87 86.48 86.19 86.33 85.79 85.55 86.21 84.90 85.65
86.10

86.83 86.55 86.62 85.79 86.48 86.74 86.39 85.57 85.46 86.16 85.01 85.30
86.09

71.45 70.20 70.15 71.14 70.05 70.61 71.00 70.76 70.20 70.73 70.33 70.49
70.59

direct evidence that these linguistic properties in fact significantly
Figure 7 affect the alignment between fMRI recordings and pretrained
BERT.

18

D Layer-wise Language ROIs Analysis before/after removal of linguistic

properties.

Here, we examine the effect on the alignment specifically in a set of
regions of interest (ROI) that are thought to underlie language
comprehension (Fedorenko et al., 2010; Fedorenko & Thompson-Schill,
2014) and word semantics (Binder et al., 2009). We find that across
language regions, the alignment is significantly decreased by the
removal of the linguistic properties across all layers, as shown in
Figure 8.

E Layer-wise Language sub-ROIs Analysis before/after removal of
linguistic

properties.

We further investigate the language sub-regions, such as 44, 45, IFJa,
IFSp, STGa, STSdp, STSda, A5, PSL, and STV and find that they also align
significantly worse after the removal of the linguistic properties from
pretrained BERT (see Figure 9).

Each language brain region is not necessarily homogeneous in function
across all voxels it contains. Therefore, an aggregate analysis across
an entire language region may mask some nuanced effects. We thus further
analyze several important language sub-regions that are thought to
exemplify the variety of functionality across the broader language
regions (Rolls et al., 2022): STGa, STSda, 44, 45, 55b, STV, SFL, PFm,
PGi, PGs, IFJa and IFSp in the main paper. Here we extend this analysis
to more sub-regions: PSL, STV, SFL, PFm, PGs, PGi. We demonstrate the
correlations for each language brain sub-region separately in Table 3 in
the main paper.

Figure 7: Balanced Classes: Model trained on pretrained BERT features
and removal of different linguistic properties. Each plot compares the
layer-wise performance of pretrained BERT and removal of each probing
task. Bottom plot displays the pretrained BERT vs. removal of all tasks.
A red ∗ at a particular layer indicates that the alignment from the
pretrained model is significantly reduced by the removal of this
linguistic property at this particular layer.

19

1234567891011120.070.080.090.10.11pretrained BERTRemoval of Sentence
LengthLayer DepthAvg Pearson
Correlation1234567891011120.060.070.080.090.10.11pretrained BERTRemoval
of TreeDepthLayer DepthAvg Pearson
Correlation1234567891011120.070.080.090.10.11pretrained BERTRemoval of
TopConstituentsLayer DepthAvg Pearson
Correlation1234567891011120.060.070.080.090.10.11pretrained BERTRemoval
of TenseLayer DepthAvg Pearson
Correlation1234567891011120.070.080.090.10.11pretrained BERTRemoval of
Subject NumberLayer DepthAvg Pearson
Correlation1234567891011120.070.080.090.10.11pretrained BERTRemoval of
Object NumberLayer DepthAvg Pearson
Correlation1234567891011120.070.080.090.10.11pretrained BERTRemoval of
All TasksLayer DepthAvg Pearson CorrelationFigure 8: Avg Pearson
correlations for language regions AG, ATL, PTL, IFG, MFG, IFGOrb, PCC
and dmPFC. Model trained on pretrained BERT features and removal of
different linguistic properties (shown only for important properties for
clarity). Each plot compares the layer-wise performance of pretrained
BERT and removal of each probing task.

F Probing Results: GPT2

Like the probing experiments with BERT in the main paper, we also
perform experiments with GPT2. We find the results to be similar to
BERT, i.e., a rich hierarchy of linguistic signals: initial to middle
layers encode surface information, middle layers encode syntax, middle
to top layers encode semantics. Table 11 reports the result for each
probing task, before and after removal of the linguistic property from
pretrained GPT2. We verify that the removal of each linguistic property
from GPT2 leads to reduced task performance across all layers, as
expected. We also report the layer-wise performance for pretrained GPT2
before and after the removal of one representative linguistic property
(TopConstituents) in Fig. 11. We observe that the brain alignment is
reduced significantly across all layers after the removal of the
linguistic property (indicated with red cross in the figure).

20

1234567891011120.080.10.120.14AGLayer DepthAvg Pearson
Correlation1234567891011120.060.080.1ATLLayer DepthAvg Pearson
Correlation1234567891011120.080.10.120.140.160.18PTLLayer DepthAvg
Pearson Correlation1234567891011120.060.080.10.120.14IFGLayer DepthAvg
Pearson Correlation1234567891011120.060.080.10.120.14MFGLayer DepthAvg
Pearson Correlation1234567891011120.080.10.12IFGOrbLayer DepthAvg
Pearson Correlation1234567891011120.080.10.120.14PCCLayer DepthAvg
Pearson Correlation1234567891011120.080.10.12dmPFCLayer DepthAvg Pearson
CorrelationFigure 9: We extend analyses in Fig. 7 to some language
sub-regions 45, IFJa, IFSp, 55b, STGa, A5, PSL, TPOJ1, STSda, STSdp and
STV. Please refer to caption of Fig. 7 for detailed understanding of
each plot.

Table 11: Word-Level Probing task performance for each GPT2 layer before
and after removal of each linguistic property using the 21st year
stimuli.

Layers Sentence Length TreeDepth TopConstituents

3-classes (Surface) after 30.48 32.50 32.51 33.54 32.53 33.55 33.53
33.52 32.53 32.52 32.50 33.53

before 54.11 54.00 53.02 52.90 52.94 52.47 52.24 52.00 53.03 52.47 52.53
52.83

3-classes (Syntactic) before after before 65.78 32.78 60.88 66.62 33.65
60.52 66.26 33.67 60.46 67.38 34.64 60.94 67.78 33.46 61.43 68.14 33.23
62.21 68.68 34.55 61.43 68.08 31.22 61.43 67.47 33.01 61.19 67.53 33.67
61.37 67.47 34.64 61.19 66.44 34.27 61.06

2-classes (Syntactic) after 45.56 44.55 49.63 49.63 42.34 48.62 48.38
49.39 49.62 48.61 48.63 48.61

1 2 3 4 5 6 7 8 9 10 11 12

21

Subject Number Object Number

Tense 2-classes (Semantic) before after before 76.59 49.78 83.57 77.57
50.79 87.87 77.97 50.78 87.94 77.98 50.78 88.84 77.85 50.39 89.03 78.17
50.79 89.50 78.02 51.68 89.89 78.21 51.81 89.81 78.22 51.17 90.23 78.20
49.57 90.17 77.96 50.78 90.56 77.62 49.78 90.10

2-classes (Semantic) after 49.90 50.91 50.91 50.51 51.05 50.90 50.95
51.81 50.91 49.39 51.63 51.07

2-classes (Semantic) before after 87.17 50.89 87.60 50.88 87.97 50.91
88.10 52.12 88.42 51.87 88.81 50.31 88.98 50.88 89.10 52.12 89.14 52.75
89.09 51.73 89.08 52.53 89.06 54.34

1234567891011120.060.080.144Layer DepthAvg Pearson
Correlation1234567891011120.060.080.10.120.1445Layer DepthAvg Pearson
Correlation1234567891011120.060.080.10.120.14IFJaLayer DepthAvg Pearson
Correlation1234567891011120.080.10.120.140.16IFSpLayer DepthAvg Pearson
Correlation1234567891011120.060.080.10.120.1455bLayer DepthAvg Pearson
Correlation1234567891011120.060.080.10.12STGaLayer DepthAvg Pearson
Correlation1234567891011120.080.10.120.140.160.180.20.220.24A5Layer
DepthAvg Pearson Correlation1234567891011120.060.080.10.120.14PSLLayer
DepthAvg Pearson
Correlation1234567891011120.080.10.120.140.160.18TPOJ1Layer DepthAvg
Pearson Correlation1234567891011120.080.10.120.140.16STSdaLayer DepthAvg
Pearson Correlation1234567891011120.10.120.140.160.180.20.22STSdpLayer
DepthAvg Pearson Correlation1234567891011120.080.10.120.140.16STVLayer
DepthAvg Pearson CorrelationFigure 10: For whole brain, paired t-test
was performed to identify the layers and removal of linguistic
properties where the pretrained BERT model has greater brain alignment
than the removal of each linguistic property, with statistical signifi-
cance. p-values obtained from paired t-test, after false discovery rate
(FDR) correction using the Benjamini–Hochberg (BH) pro- cedure.

Figure 11: Comparison of layer-wise performance of pretrained GPT2 and
removal of one linguistic property–TopConstituents.

Figure 12: Voxel-wise correlations across layers between brain alignment
of pretrained BERT before and after removing all linguistic properties.

22

123456789101112Removal of Sentence LengthRemoval of TreeDepthRemoval of
TopConstituentsRemoval of TenseRemoval of Subject NumberRemoval of
Object Number050n100n150n200nP-valuesPretrained
BERT1234567891011120.030.040.050.060.070.080.090.1GPT2Removal of
TopConstituentsLayer-DepthAvg Pearson CorrelationRemoval of All Tasks
