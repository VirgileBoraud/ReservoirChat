Interactions between hierarchical learning and visual
system modeling : image classification on small datasets.
Thalita Firmo Drumond

To cite this version:

Thalita Firmo Drumond.
Interactions between hierarchical learning and visual system modeling :
image classification on small datasets.. Artificial Intelligence [cs.AI]. Université de Bordeaux, 2020.
English. ￿NNT : 2020BORD0233￿. ￿tel-03129189v2￿

HAL Id: tel-03129189

https://theses.hal.science/tel-03129189v2

Submitted on 5 Feb 2021

HAL is a multi-disciplinary open access
archive for the deposit and dissemination of sci-
entific research documents, whether they are pub-
lished or not. The documents may come from
teaching and research institutions in France or
abroad, or from public or private research centers.

L’archive ouverte pluridisciplinaire HAL, est
destinée au dépôt et à la diffusion de documents
scientifiques de niveau recherche, publiés ou non,
émanant des établissements d’enseignement et de
recherche français ou étrangers, des laboratoires
publics ou privés.

Thèse

présentée pour obtenir le grade de

DOCTEUR DE L’UNIVERSITÉ DE BORDEAUX

École Doctorale de Mathématiques et d’Informatique

Spécialité : Informatique

Interactions between hierarchical learning
and visual system modeling
Image classiﬁcation on small datasets

par
Thalita FIRMO DRUMOND

Sous la direction de M. Frédéric ALEXANDRE et M. Thierry VIÉVILLE

Soutenue le 3 décembre 2020

Membres du jury :
Mme. SAUZÉON, Helène
M. CARRÉ, Philippe
Mme. ESCOBAR, Maria Jose
M. JOUFFRAIS, Christophe
M. VON ZUBEN, Fernando José Full Pr. Univ. Estadual de Campinas, Brésil

Pr.
Présidente
Rapporteur
Pr.
Asc. Pr. Univ. Técnica Federico Santa María, Chile Rapporteure
Examinateur
DR
Examinateur

Univ. de Bordeaux
Univ. de Poitiers

CNRS IPAL IRL2955, Singapour

Title: Interactions between hierarchical learning and visual system modeling: Image classiﬁcation on

small datasets

Abstract: Deep convolutional neural networks (DCNN) have recently protagonized a revolution in large-
scale object recognition. They have changed the usual computer vision practices of hand-engineered
features, with their ability to hierarchically learn representative features from data with a pertinent
classiﬁer. Together with hardware advances, they have made it possible to eﬀectively exploit the
ever-growing amounts of image data gathered online. However, in speciﬁc domains like healthcare
and industrial applications, data is much less abundant, and expert labeling costs higher than those of
general purpose image datasets. This scarcity scenario leads to this thesis’ core question: can these
limited-data domains proﬁt from the advantages of DCNNs for image classiﬁcation? This question
has been addressed throughout this work, based on an extensive study of literature, divided in two
main parts, followed by the proposal of original models and mechanisms.

The ﬁrst part reviews object recognition from an interdisciplinary double-viewpoint. First, it
resorts to understanding the function of vision from a biological stance, comparing and contrasting
to DCNN models in terms of structure, function and capabilities. Second, a state-of-the-art review
is established aiming to identify the main architectural categories and innovations in modern day
DCNNs. This interdisciplinary basis fosters the identiﬁcation of potential mechanisms — inspired
both from biological and artiﬁcial structures — that could improve image recognition under diﬃcult
situations. Recurrent processing is a clear example: while not completely absent from the “deep vision”
literature, it has mostly been applied to videos — due to their inherently sequential nature. From
biology however it is clear such processing plays a role in reﬁning our perception of a still scene. This
theme is further explored through a dedicated literature review focused on recurrent convolutional
architectures used in image classiﬁcation.

The second part carries on in the spirit of improving DCNNs, this time focusing more speciﬁcally
on our central question: deep learning over small datasets. First, the work proposes a more detailed
and precise discussion of the small sample problem and its relation to learning hierarchical features
with deep models. This discussion is followed up by a structured view of the ﬁeld, organizing and
discussing the diﬀerent possible paths towards adapting deep models to limited data settings. Rather
than a raw listing, this review work aims to make sense out of the myriad of approaches in the ﬁeld,
grouping methods with similar intent or mechanism of action, in order to guide the development of
custom solutions for small-data applications. Second, this study is complemented by an experimental
analysis, exploring small data learning with the proposition of original models and mechanisms
(previously published as a journal paper).

In conclusion, it is possible to apply deep learning to small datasets and obtain good results, if
done in a thoughtful fashion. On the data path, one shall try gather more information from additional
related data sources if available. On the complexity path, architecture and training methods can be
calibrated in order to proﬁt the most from any available domain-speciﬁc side-information. Proposals
concerning both of these paths get discussed in detail throughout this document. Overall, while there
are multiple ways of reducing the complexity of deep learning with small data samples, there is no
universal solution. Each method has its own drawbacks and practical diﬃculties and needs to be
tailored speciﬁcally to the target perceptual task at hand.

Keywords: deep learning, image classiﬁcation, small data learning, convolutional neural networks,

transfer learning.

2

Titre : Apports croisés entre l’apprentissage hierarchique et la modélisation du système visuel: Catégori-

sation d’images sur des petits corpus de données

Résumé : Les réseaux neuronaux convolutifs profonds (“deep convolutional neural networks” ou DCNN)
ont récemment révolutionné la reconnaissance d’objets à grande échelle, modiﬁant les pratiques en
vision par ordinateur, consistant à déﬁnir des caractéristiques représentatives “à la main”, désormais
apprises de façon hiérarchique à partir des données, tout en les classiﬁant. Fort de la progression
des performances matérielles, on exploite eﬃcacement des quantités toujours croissantes d’images
recueillies en ligne. Mais, dans des domaines spéciﬁques, comme en santé ou pour certaines applica-
tions, les données sont moins abondantes, et les coûts d’étiquetage par des experts sont plus élevés.
Cette rareté conduit à la question centrale de cette thèse : Ces domaines à données limitées peuvent-ils
bénéﬁcier des avantages des DCNN pour la classiﬁcation des images ? Ce travail repose sur une étude
approfondie de la littérature, divisée en deux parties principales, avant de proposer des modèles et
des mécanismes originaux, expérimentés.

La première partie couvre la reconnaissance des objets d’un double point de vue. Tout d’abord, la
fonction visuelle biologique, est comparée et contrastée avec la structure, la fonction et les capacités des
modèles DCNN. Puis, une revue de l’état-de-l’art identiﬁe les principales catégories d’architectures
et les innovations dans les DCNN récents. Cette base interdisciplinaire favorise l’identiﬁcation des
mécanismes — biologiquement et artiﬁciellement inspirés — qui améliorent la reconnaissance d’images
dans des situations diﬃciles. Le traitement récurrent en est un exemple clair : peu présent au niveau
de la vision profonde, sauf le traitement aux vidéos — en raison du caractère naturellement séquentiel.
Mais la biologie montre clairement qu’un tel traitement joue aussi un rôle dans l’aﬃnement de notre
perception d’une scène ﬁxe. Ce thème est approfondi à travers une revue de la littérature consacrée
aux architectures convolutionnelles récurrentes utilisées en catégorisation d’images.

La deuxième partie se concentre sur notre question centrale : l’apprentissage profond sur de
petits corpus de données. Tout d’abord, le travail propose une discussion plus précise et détaillée
de ce problème et de sa relation avec l’apprentissage hiérarchique des caractéristiques réalisé par
des modèles profonds. Cette discussion est suivie d’une revue structurée du domaine, organisant et
discutant les diﬀérentes voies possibles vers l’adaptation des modèles profonds à des données limitées.
Plus qu’une simple liste, ce travail vise à trouver du sens dans la myriade d’approches du domaine,
en regroupant les méthodes ayant un objectif ou un mécanisme d’action similaire, pour guider le
développement d’application particulières, à petits corpus. Cette étude est complétée par une analyse
expérimentale, explorant l’apprentissage de petits jeux de données avec des modèles et mécanismes
originaux (précédemment publié comme papier de journal).

En conclusion, l’apprentissage profond sur des petits corpus de données peut donner de bons
résultats, si cela se fait de manière réﬂéchie. Au niveau des données, il faut essayer de recueillir plus
d’informations à partir de sources de données supplémentaires connexes. Au niveau de la complexité,
l’architecture et les méthodes d’entraînement peuvent être calibrées aﬁn de tirer le meilleur parti
de toute connaissance spéciﬁque au domaine. Des propositions sont discutées en détail au ﬁl du
document. Il existe de multiples façons de réduire la complexité de l’apprentissage profond avec de
petits échantillons de données, mais il n’y a pas de solution universelle. Chaque méthode a ses propres
inconvénients et diﬃcultés pratiques, devant toujours être adaptée spéciﬁquement à l’application,
c’est-à-dire à la tâche perceptive à accomplir.

Mots-clés : apprentissage profond, catégorisation d’images, apprentissage sur petit corpus de données,

réseaux de neurones convolutifs, apprentissage par transfert.

3

Unité de recherche

Laboratoire Bordelais de Recherche en
Informatique (UMR 5800)
Domaine universitaire
351 cours de la Libération
33405 Talence

INRIA Bordeaux Sud-Ouest
Équipe-projet MNEMOSYNE
200 Avenue de la Vieille Tour
33405 Talence

My thesis in a glimpse The ﬁeld of artiﬁcial intelligence has made many advances in the last
decade, especially with deep learning for image recognition. Despite being biologically inspired, these
deep neural networks function in a quite diﬀerent way from our natural vision. Essentially, it is a
mathematical object with numerical parameters that can be adjusted automatically, using large sets of
previously labeled images. Only after “seeing” thousands of cats, dogs, cars, trees, people, etc., will the
network be able to recognize these elements in new images (without understanding their meaning).
Having access to large databases of labeled images is unfortunately not possible in all ﬁelds of
application. On speciﬁc industrial problems or in medical imaging for example, it can be diﬃcult or
even impossible to obtain hundreds of diﬀerent images of the same condition, patient, etc... In addition,
image labeling is more expensive since it requires an expert opinion.

This motivates the central question of this thesis: How can we take advantage of deep neural
networks on small image datasets? This work moves a step towards this answer through an extensive
literature review, complemented by an experimental study including the proposition of original models
and mechanisms.

Ma thèse en un clin d’œil Le domaine de l’intelligence artiﬁcielle a connu diverses avancées
dans la dernière décennie, en particulier avec le “deep learning” pour la reconnaissance d’images.
Malgré une inspiration biologique, ces réseaux neuronaux profonds ont ﬁnalement un fonctionnement
bien diﬀérent de notre vision naturelle. Essentiellement, il s’agit d’un objet mathématique avec des
paramètres numériques qu’on peut ajuster de façon automatique, ayant recours à des larges corpus
d’images pré-étiquetées. Ce n’est donc qu’après “avoir vu” des milliers de chats, chiens, voitures,
arbres, personnes, etc, que le réseau sera capable de reconnaître ces éléments sur des nouvelles images
(sans en comprendre le sens).

Avoir accès à des grandes bases d’images étiquetées n’est malheureusement pas possible sur
tous les domaines d’application. Pour des problématiques industrielles ou en imagerie médicale, par
exemple, il peut être diﬃcile voire impossible d’obtenir des centaines d’images variées d’un même
problème, patient, etc. De plus, l’étiquetage de ces images est coûteux car il demande un avis expert.
C’est là où réside la question centrale de cette thèse : comment peut-on proﬁter des avantages des
réseaux de neurones profonds sur de petits corpus d’images ? Ce travail fait un pas vers cette réponse
via une étude bibliographique étendue, complémenté par une étude expérimentale comprenant des
propositions de modèles et mécanismes originaux.

4

Fred et Thierry, un énorme immensurable merci à
tous les deux.
Merci de m’avoir accepté dans votre équipe.
Merci de m’avoir guidé dans ce voyage de ouf.
Merci de m’avoir traité comme une collègue, une
collaboratrice.
Merci de vote conﬁance et encouragement à tous les
moments.
Bref, sans vous, ça ne se serait pas passé aussi bien.

Big thanks to all my mnemo-friends, old an new.
You all make this team a great environment to work,
a safe-place to share ideas and be creative.
Thank you Mamie ICK for taking such good care of
all of us.
Thank you Mr B our zen master.
Thank you Astroboy for being a constant reminder
of what it is to be young and passionate by your
research. And for all the board games :)
Thank you Mme SP, our oﬃcial event hostess, for
keeping us together.
Thank you Miss RS a.k.a. DA BOSS xD for your
encouragements and random hugs of support.

Obrigada a minha família querida, que torce por
mim, de longe, mesmo sem entender muito bem o
que eu faço.

Obrigada ao meu companheiro de vida, minha nova
família, por sempre estar aqui, por todo o suporte,
de longe e de perto, sempre.

5

Table of Contents

List of Figures

List of Tables

Acronyms

1 Introduction

.

1.1 Context and motivation .

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
1.1.1 The revolution of deep learning . . . . . . . . . . . . . . . . . . . . . . .
1.1.2 Limits of bio-inspiration . . . . . . . . . . . . . . . . . . . . . . . . . . .
1.1.3 The problem of small datasets . . . . . . . . . . . . . . . . . . . . . . . .
1.1.4 Deep learning literature . . . . . . . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
1.2.1 Object recognition tasks . . . . . . . . . . . . . . . . . . . . . . . . . . .
1.2.2 Other relevant deep architectures . . . . . . . . . . . . . . . . . . . . . .
1.3 Thesis focus and contributions . . . . . . . . . . . . . . . . . . . . . . . . . . . .

1.2 Related topics . .

.

.

.

.

.

11

14

15

17
17
17
17
18
19
20
20
21
23

I Object recognition with deep convolutional neural networks

26

2 Convolutional neural networks and visual system modeling
.

.

.

.

.

.

Introduction . .

2.1
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
2.2 Convolutional neural networks . . . . . . . . . . . . . . . . . . . . . . . . . . .
2.2.1 Convolutional layers . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
2.2.2 Pooling or subsampling . . . . . . . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . . . . . . .
2.2.3 Activation functions
2.3 Visual system: a schematic overview . . . . . . . . . . . . . . . . . . . . . . . .
2.3.1 A hierarchical system . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
2.3.2 The schematic two-stream model . . . . . . . . . . . . . . . . . . . . . .
2.4 The object identiﬁcation pathway in relation to CNNs . . . . . . . . . . . . . .
2.4.1 Core object recognition . . . . . . . . . . . . . . . . . . . . . . . . . . . .
2.4.2 Early vision: from retina to V1 cortex . . . . . . . . . . . . . . . . . . . .
2.4.2.1 Retinotopy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
2.4.2.2 Receptive ﬁelds . . . . . . . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . . . . . .
Infero-temporal cortex . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

2.4.3 Mid-level visual areas
2.4.4

2.5 Discussion .

.

.

.

.

.

.

.

.

27
27
29
29
30
31
32
32
33
34
34
37
37
38
39
39
40

6

Table of Contents

. .
2.5.1 Comparisons of cortical representations and CNN representations
2.5.2 Main diﬀerences between biology and basic feedforward CNNs . . . .
2.5.2.1
Processing in retina and LGN . . . . . . . . . . . . . . . . . . .
2.5.2.2 Recurrent processing . . . . . . . . . . . . . . . . . . . . . . . .
. . . . . . . .
2.5.2.3
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
2.6 Conclusion .

Interaction between dorsal and ventral streams
.

.

.

.

.

.

.

.

3 Feedforward CNN architectures for object recognition
.

.

.

3.1
.
3.2 Single pathway models .

.

3.3 Parallel pathway archs .

.

.
.

3.3.1

3.2.1

Introduction . .

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
First modern architectures . . . . . . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3.2.1.1 Alexnet
3.2.1.2 Zeiler and Fergus . . . . . . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3.2.1.3 OverFeat .
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. .
3.2.1.4 VGG .
3.2.2 Parameter-saving architectures . . . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Sequence of parallel blocks: the Inception family . . . . . . . . . . . . .
3.3.1.1 Role of auxiliary losses . . . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . .
3.3.1.2 Variations and derivations
3.3.2 Architectures featuring forward shortcuts . . . . . . . . . . . . . . . . .
3.3.2.1 Residual connections . . . . . . . . . . . . . . . . . . . . . . . .
3.3.2.2 Gated shortcuts . . . . . . . . . . . . . . . . . . . . . . . . . . .
3.3.2.3 Multiple forward shortcuts . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3.4.1 Relation between forward shortcuts and recurrent networks . . . . . .
3.4.2 Attempts at understanding the success of residual shortcuts . . . . . .
3.4.3
Feature reuse by concatenation vs memory eﬃciency . . . . . . . . . .
3.4.4 Width vs depth on ResNets . . . . . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

3.4 Discussion .

3.5 Conclusion .

.

.

.

.

.

4 Recurrent and feedback CNN architectures for object recognition
.

Introduction . .

4.2.1
4.2.2

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
4.1
4.2 Functionalities brought by recurrent processing . . . . . . . . . . . . . . . . . .
Spatial context integration . . . . . . . . . . . . . . . . . . . . . . . . . .
Iterative processing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
4.2.2.1
Iterative spatial attention . . . . . . . . . . . . . . . . . . . . .
4.2.2.2 Handling occlusion and image clutter . . . . . . . . . . . . . .
4.2.3 Response modulation . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
4.3.1 Recurrence within layers . . . . . . . . . . . . . . . . . . . . . . . . . . .
Intra-layer temporal recurrence . . . . . . . . . . . . . . . . . .
4.3.1.1
Intra-layer spatio-temporal recurrence . . . . . . . . . . . . . .
4.3.1.2
Feedback between layers . . . . . . . . . . . . . . . . . . . . . . . . . . .
Explicit biological inspiration . . . . . . . . . . . . . . . . . . .
4.3.2.1

4.3 Architectural trends .

4.3.2

.

.

.

40
42
43
44
45
45

47
47
49
49
49
50
51
51
52
52
53
54
54
55
55
56
57
59
59
60
61
61
62

63
63
64
64
66
67
68
68
69
69
69
73
74
75

7

Table of Contents

4.4 Discussion .

.

.

.

.

.

.

.

.

4.3.2.2

Ladder networks . . . . . . . . . . . . . . . . . . . . . . . . . .
4.3.3 Hybrid models with added recurrent layers . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
4.4.1
Feedback vs recurrent feedforward . . . . . . . . . . . . . . . . . . . . .
Internal representations on feedback networks . . . . . . . . . . . . . .
4.4.2
4.4.3 Training considerations . . . . . . . . . . . . . . . . . . . . . . . . . . . .
4.4.3.1
Temporal recurrence depth . . . . . . . . . . . . . . . . . . . .
4.4.3.2 Computational requirements . . . . . . . . . . . . . . . . . . .
4.4.4 Biological plausibility . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

.

.

.

.

.

.

.

.

4.5 Conclusion .

II

Image classiﬁcation on small datasets

76
77
79
79
79
80
80
81
81
83

84

.

.
.

.
.

.
.

.
.

5.3.1

Introduction . .

5.3.2 Unlabeled data .

5.1
.
5.2 Problem statement

5 A review of strategies to use deep learning under limited data
.
.

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
.
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
.
. . . . . . . . . . . . . . . . . . . . . . . . . . . . .
5.2.1
Small data scenarios
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
5.2.2 Related problems .
5.2.3
Implicit and explicit knowledge . . . . . . . . . . . . . . . . . . . . . . .
5.2.4 Knowledge transfer . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
5.3 Axis I: Get more data .
Synthetic data .
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
5.3.1.1 Augmentation at the input space . . . . . . . . . . . . . . . . .
5.3.1.2 Augmentation in the feature space . . . . . . . . . . . . . . . .
5.3.1.3 Augmentation through generative modeling . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
5.3.2.1
Semi-supervised learning . . . . . . . . . . . . . . . . . . . . .
5.3.2.2 Weak supervision . . . . . . . . . . . . . . . . . . . . . . . . .
5.3.2.3 Active learning . . . . . . . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Pre-training and ﬁne-tuning . . . . . . . . . . . . . . . . . . .

85
85
86
86
87
88
89
90
91
91
92
92
94
94
95
97
98
5.3.3.1
98
5.3.3.2 Zero-shot learning . . . . . . . . . . . . . . . . . . . . . . . . . 101
5.4 Axis II: Reduce model complexity . . . . . . . . . . . . . . . . . . . . . . . . . . 102
5.4.1 Explicit regularization . . . . . . . . . . . . . . . . . . . . . . . . . . . . 103
5.4.2 Architecture adaptation . . . . . . . . . . . . . . . . . . . . . . . . . . . 106
Intra-layer structure . . . . . . . . . . . . . . . . . . . . . . . . 106
Inter-layer structure . . . . . . . . . . . . . . . . . . . . . . . . 107
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 108
5.4.3.1 Meta-learning: learning to learn . . . . . . . . . . . . . . . . . 108
5.4.3.2 Curriculum learning . . . . . . . . . . . . . . . . . . . . . . . . 109
5.4.3.3 Multi-task learning . . . . . . . . . . . . . . . . . . . . . . . . . 111
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 112

5.4.3 Training strategies .

5.3.3 Related datasets .

5.5 Conclusion .

5.4.2.1
5.4.2.2

.

.

.

.

.

.

.

.

.

.

8

Table of Contents

6.1

6 Analysis of DCNN applied to small sample learning using data prototypes

6.2 Related works .

6.3 Model proposed .

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.
.

113
Introduction . .
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 113
6.1.1 The data requirement challenge . . . . . . . . . . . . . . . . . . . . . . . 113
6.1.2 The interpretability issue . . . . . . . . . . . . . . . . . . . . . . . . . . . 114
6.1.3 On network architecture . . . . . . . . . . . . . . . . . . . . . . . . . . . 115
6.1.4 Hyperparameter dependence . . . . . . . . . . . . . . . . . . . . . . . . 116
6.1.5 The present contribution . . . . . . . . . . . . . . . . . . . . . . . . . . . 116
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 117
6.2.1 Prototypes in literature . . . . . . . . . . . . . . . . . . . . . . . . . . . . 117
Few-shot learning and learning to learn . . . . . . . . . . . . . . . . . . 118
6.2.2
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 120
Interpretability .
6.2.3
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 121
.
6.3.1 Model architecture . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 121
6.3.2 Model speciﬁcation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 122
6.3.2.1 Direct use of the prototypes . . . . . . . . . . . . . . . . . . . . 123
6.3.2.2 Combining prototype-encoded and original features . . . . . 124
6.3.2.3 Relation between prototypes and category information . . . . 125
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 125
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 125
Studying the model under ﬁxed features . . . . . . . . . . . . . . . . . . 126
Study of a sample episode . . . . . . . . . . . . . . . . . . . . . 127
6.4.2.1
. . . . . . . . . . . . . . . . . . . 131
Interpretability of the model
6.4.2.2
6.4.2.3 Comparison over multiple episodes . . . . . . . . . . . . . . . 132
6.4.3 Comparison over diﬀerent training sets with varying sizes . . . . . . . 132
6.4.4 Experiments in the meta-learning paradigm . . . . . . . . . . . . . . . . 137
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 138
6.5.1 Performances and use of the algorithm . . . . . . . . . . . . . . . . . . . 139
6.5.2 Perspectives and future work . . . . . . . . . . . . . . . . . . . . . . . . 140
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 141

6.4.1 Datasets
6.4.2

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

6.5 Discussion .

6.6 Conclusion .

6.4 Experiments and results .
.

.

.

.

.

.

7 Conclusion

142
7.1 Summary of contributions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 142

7.1.1 Understanding object recognition from an interdisciplinary

.

.

.

7.1.2

stance .
Image classiﬁcation over small datasets with deep models

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 142
. . . . . . . 144
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 145
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 147

7.2 Further developments
.
7.3 Open perspectives .

.

.
.

.
.

.

.

.

.

Appendix

150

A Prototype model derivation and formal interpretation

151
A.1 Sample to prototype association . . . . . . . . . . . . . . . . . . . . . . . . . . . 151
A.2 Reminder on softmax function . . . . . . . . . . . . . . . . . . . . . . . . . . . . 151

9

Table of Contents

A.3 Deriving the model variational equations . . . . . . . . . . . . . . . . . . . . . 152
A.4 Analysis of the k-means extended metric . . . . . . . . . . . . . . . . . . . . . . 152
A.5 Probabilistic interpretation of representing samples by prototypes . . . . . . . 153
A.6 Duality between partition, prototypes and metric . . . . . . . . . . . . . . . . . 154
A.7 Relation between softmax and prototypes . . . . . . . . . . . . . . . . . . . . . 155

B Methodology for hyperparameter analysis on prototype model with ﬁxed input

features

157

159
C Relevant benchmark datasets in object recognition
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 159
.
C.1 MNIST . .
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 160
.
C.2 Omniglot .
C.3 CIFAR 10 and 100 .
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 160
C.4 ImageNet classiﬁcation 2012 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 160
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 161

C.4.1 mini-Imagenet .

.
.
.

.
.
.

.
.
.

.
.
.

.
.

.
.

.
.

.
.

.

.

D Résumé étendu en français

.

D.1 Contexte et motivation .

162
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 162
D.1.1 La revolution du « deep learning » . . . . . . . . . . . . . . . . . . . . . 162
D.1.2 Limites de la bio-inspiration . . . . . . . . . . . . . . . . . . . . . . . . . 163
D.1.3 Le problème des petits corpus de données . . . . . . . . . . . . . . . . . 164
D.1.4 Litterature sur le « deep learning » . . . . . . . . . . . . . . . . . . . . . 165
D.2 Positionnement du travail et plan de la thèse . . . . . . . . . . . . . . . . . . . 166
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 167
D.3 Résumé des contributions

D.3.1 Étude et compréhension de la reconnaissance d’objets

d’un point de vue interdisciplinaire

. . . . . . . . . . . . . . . . . . . . 167

D.3.2 Classiﬁcation d’images sur des corpus restreints

avec des réseaux profonds . . . . . . . . . . . . . . . . . . . . . . . . . . 169

Index

Bibliography

171

172

10

List of Figures

1.1 Thesis organization diagram.

. . . . . . . . . . . . . . . . . . . . . . . . . . . .

. .

. .

. .

2.1 Typical convolutional neural network (CNN). Credits: Aphex34 CC BY-SA 4.0
2.2 A simpliﬁed anatomic schematic of the visual neural pathways in the brain,
from retina to the primary visual cortex (V1). Credits: Miquel Perello Nieto
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
CC BY-SA 4.0 .
2.4 After reaching the primary cortex in the occipital lobe, visual processing is
roughly divided in two streams or patwhays: the dorsal pathway goes up to
the parietal lobe, while the ventral pathway goes lower towards the inferior
temporal lobe. Credits: OpenStax College CC BY 3.0 . . . . . . . . . . . . . . .
2.3 Anatomical hierarchy of brain regions implicated in visual processing, accord-
ing to Felleman and Van Essen (1991). The ventral pathway associated to “core
. . . . . . . .
object recognition” is highlighted in red. Credits: Cortes (2012).

3.1 Proposed taxonomy of feedforward CNN architectures. Each family is repre-
sented by an archetypal small module of 3-4 layers. Top and bottom circles
. . . . . . . . . . . . . . . .
stand for module’s input and output, respectively.
3.2 Diagram representing an “inﬂuence genealogy” of some important CNN mod-
els for computer vision. Dates correspond to arXiv ﬁrst release or date of
publication, whichever is the earliest. . . . . . . . . . . . . . . . . . . . . . . . .

4.1 Proposed taxonomy of recurrent and feedback CNN architectures. Each family
is represented by an archetypal small module of 3-4 layers. Top and bottom
. . . . . . . . . . . .
circles stand for module’s input and output, respectively.
4.2 Schematic representation of the recurrent structure of diﬀerent spatio-temporal
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
4.3 Feedback nets predict an output at every time-step, connecting the loss to
intermediate hidden states and changing how features are learned. Adapted
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
from Zamir et al (2017).

recurrent models.

. .

. .

.

5.1

Illustrative diagram diﬀerentiating the diﬀerent small data scenarios ranked in
the text. Rectangles represent data matrices (with samples as rows and features
as columns). Diﬀerent colors mark diﬀerent types of data (see legend in the
top right corner) and dashed lines delimit distinct datasets. . . . . . . . . . . .
5.2 Knowledge sources .
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
5.3 Strategies for deep learning under small data. This diagram illustrates the point
. . . . . . . . . . . . . . . . . . . . . . . . . .

of view presented in this chapter.

. .

24

28

33

34

36

47

48

64

73

79

87
89

90

11

List of Figures

5.4 Main architectural schemes for zero-shot learning.

. . . . . . . . . . . . . . . . 102

6.1 The three layer model. The input data is fed to a convolution neural network,
transforming the original image into a set of feature vectors. Then the in-
formation in this high dimensional feature space is summarized via a set of
prototypes, in order to understand the landscape. Finally, the relation between
a given data point and the label to infer is calculated through their proximity
to the prototypes.

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 121

. .

. .

.

6.2 Left: Sub-sample of 10 classes from the Omniglot dataset, showing 5 samples
per class (total is 20 per class). Right: T-SNE visualization of the Inception v3
features for the 200 samples of this subset, see text for details.

. . . . . . . . . 127

6.3 Mean accuracy (with standard deviation bars) obtained during grid search for
the inverse regularization parameter C and the number of clusters, under L2
regularization. Top: direct model. Bottom: combined model.

. . . . . . . . . . 129

6.4 Average training loss on the k-mean algorithm as a function of the number
of prototypes. The mean square distance between samples and prototypes
decreases until a plateau (sometimes called elbow) and then either re-increases,
as visible in this example, or do not signiﬁcantly re-decreases as shown in Fig. 6.9
for other datasets.

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 130

.

.

.

.

6.5 Veriﬁcation that the introduction of a priori information on the prototype
category has no signiﬁcant impact on the performances, as soon as the number
for prototypes is high enough. Graphs show mean accuracy (with standard
deviation bars) obtained during grid search under the best regularization
parameter found. Left: under L1 regularization, C = 104. Right: under L2
regularization, C = 102. .

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 131

.

6.6 The top-4 closest training samples visually illustrate what is being represented
by each prototype. For each prototype p1, p2, .., its related class c2, c5, .. is
written, this “main” class being estimated as the most probable class proposed
by our algorithm. The number of samples corresponding to the related cluster
is given. .

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 132

. .

. .

. .

. .

.

6.7 T-SNE visualizations of dataset points (as Inception v3 features) together with
learned prototypes, indicated by black markers. Each class is identiﬁed by color,
and the predicted class for each prototype is annotated. Misclassiﬁed points
are over-marked by an “x” of the predicted class color. Top: visualization of
the training set; Bottom: visualization of the test set.

. . . . . . . . . . . . . . . 133

6.8 Box plots for test accuracies over 100 episodes. Boxes extend between 1st and
3rd quartiles (IQR), with median value noted at the bottom and marked by
a green line. Bars mark a range of ±1.5 IQR from quartiles, with outliers as
circles. Our models are marked with a \*. . . . . . . . . . . . . . . . . . . . . . . 134

6.9 Performances on the k-means algorithm as a function of the number of proto-
types, for training subsets with 500 samples from MNIST and CIFAR10 datasets.
In these and contrary to Fig. 6.4, the optimal value corresponds to an elbow in
both cases.

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 136

. .

. .

. .

. .

12

List of Figures

6.10 Mean accuracies over standard test sets for MNIST and CIFAR10 datasets, for
increasing training set sizes. Results are averaged over 10 diﬀerent training
subsets. Our models are marked with a \*.

. . . . . . . . . . . . . . . . . . . . . 137

7.1 Architectural taxonomy of CNNs: feedforward and feedback. Each family is
represented by an archetypal small module of 3-4 layers. Top and bottom circles
stand for module’s input and output, respectively.

. . . . . . . . . . . . . . . . 143

13

List of Tables

4.1 Recurrent convolutional architectures from a functional point of view . . . . .
4.2 Summary of convolutional recurrent architectures. . . . . . . . . . . . . . . . .

70
78

6.1 Statistical signiﬁcance for all pairs of classiﬁers tested on Omniglot. “++” and
“+” mark all pairs which presented a signiﬁcant diﬀerence (for p < 0.01 and
p < 0.05 respectively), while "o"s mark those which did not. Non-reported
pairs were found to be signiﬁcantly diﬀerent with p < 0.01 (except for direct
L1 vs. direct L2 at 30 classes, for which p < 0.05). . . . . . . . . . . . . . . . . . 135

6.2 Average test accuracy (%) for 5-shot learning on Omniglot over 1000 episodes.
We compare to results reported by two other works: Matching networks
(Vinyals et al, 2016) and Prototypical networks (Snell et al, 2017).

. . . . . . . 138

C.1 Information on datasets mentioned throughout this thesis.

. . . . . . . . . . . 159

14

Acronyms

aIT anterior infero-temporal. 82

ANN artiﬁcial neural network. 42

BN batch normalization. 75

BPTT backpropagation through time. 80

CGRU convolutional gated recurrent unit (GRU). 71

CIFAR Canadian Institute for Advanced Research. 82

cIT central infero-temporal. 82

CNN convolutional neural network. 11, 17, 18, 20–22, 28–32, 42, 43, 45, 47, 49, 62–64, 81, 82,

85, 86, 89, 92, 95, 98, 99, 105, 107, 108, 149, 161–163, 165

ConvRNN convolutional recurrent neural network. 75, 81, 82

CV computer vision. 49

DAE denoising autoencoder. 23

DCNN deep convolutional neural network. 28, 46, 49, 63, 85, 86

DNN deep neural network. 18, 20, 43, 46, 83, 88, 102, 103, 147, 149, 163

GAN generative adversarial network. 22, 23, 93

GPU graphical processing unit. 17, 49, 147, 162

GRU gated recurrent unit. 15, 22, 69, 71

HoG histograms of Gaussians. 27

ILSVRC ImageNet large scale visual recognition challenge. 17, 161, 162

IT infero-temporal. 18, 33, 39, 40, 75, 163

LGN lateral geniculate nucleus. 33, 42, 75

15

Acronyms

LOC lateral occipital cortex. 41

LSTM long-short term memory. 22, 69, 71–74

MLP multi-layer perceptron. 29, 30

PCN predictive coding network. 67

pIT posterior infero-temporal. 82

RBM restricted Boltzmann machine. 22, 67

ReLU rectiﬁed linear unit. 31, 75

ResNet residual network. 31, 72

RNN recurrent neural network. 22, 71, 75

SAE sparse autoencoder. 23

SGD stochastic gradient descent. 49, 110

SIFT scale-invariant feature transform. 27

SRN simple recurrent network. 72, 74

SVHN Street-view house numbers. 82

SVM support vector machine. 27

TPE tree-structured Parzen estimator. 75

V1 primary visual cortex. 33

VAE variational autoencoder. 23, 93

16

Chapter 1

Introduction

1.1 Context and motivation

1.1.1 The revolution of deep learning

Image recognition has undergone a revolution in the past decade, majorly led by the
successful performances obtained using deep neural networks. Even though these models
had been around since the late 80s – early 90s (LeCun et al, 1990a), their successful application
had been limited by both data and hardware requirements. Recent advances in hardware —
with the possibility of treating large matrix operations in parallel with consumer graphical
processing units (GPUs) — and in data availability — with the widespread use of digital
cameras and online photo sharing platforms — have been decisive in changing this scenario.
Quite emblematic of this revolution was the 12% accuracy improvement in the 2012 edition
of the ImageNet large scale visual recognition challenge (ILSVRC), which ended up to be a
hallmark of the successful use of convolutional neural networks (CNNs) for general purpose
object recognition.

These machine learning models have not only achieved unprecedented accuracy at object
recognition, but have also brought a new paradigm of jointly learning feature extraction and
classiﬁcation, within a single model. Indeed, this end-to-end training paradigm, mapping
images to classes directly, has become a de facto standard in most computer vision works.
It is often argued that this manner of proceeding — learning from examples — is closer to
how humans see and learn to recognize objects in nature. However, such similarities between
computer and biological neural vision exist on a rather superﬁcial level, while our neurons
and cortical regions operate on a much more complex fashion, implementing functions absent
from typical CNNs.

1.1.2 Limits of bio-inspiration

Neural networks are made of successive interconnected layers of artiﬁcial neurons, which
are loosely inspired by the functioning of natural neuronal cells. More speciﬁcally, they model
the thresholded information propagation performed by neurons, when they selectively pass

17

1. Introduction

1.1 Context and motivation

along an electric action potential. One artiﬁcial neuron is a composed mathematical function,
that ﬁrst computes a linear combination of its inputs, then puts the resulting output through a
non-linearity, which emulates the biological thresholding mechanism. This modeling is highly
simpliﬁed and neglects any temporal aspects relevant to the functioning of real neurons.

Bio-inspiration is also present at a higher level, in the way neurons are organized and the
patterns they learn. Deep neural networks (DNNs) take their naming predicate from their
archetypal architecture consisting in a stack of multiple neuron layers. Each layer takes in
outputs of its previous counterpart, conducting one further step of information treatment
before feeding it to the subsequent one. This incremental processing structure, when trained
on natural image datasets, has been shown to function in a hierarchical fashion, similar to
the functional organization of the diﬀerent cortical regions involved in our own biological
vision. Early layers tend to learn to detect low level image features such as parts of borders in
diﬀerent orientations — in a functional analogy to our primary visual cortex — while later
layers get specialized in detecting more abstract concepts and ultimately the image class — in
an analogous role to that of the infero-temporal (IT) cortex.

While this functional similarity seems to be present, there is much left unaccounted for in
typical feedforward CNNs. Shortcut connections between regions, local recurrent processing,
long-range feed back connections, attentional modulation — these are all features absent
from these models and reputed to play important roles in the processing of a visual scene.
Recurrent processing for instance is believed to act in recognizing objects under visual clutter,
a task in which CNNs may have some diﬃculty. One may wonder how the incorporation of
such functionalities could help the performance of CNNs, both in quantitative and qualitative
fashion. Furthermore, one may wonder which of these improvements would be the most
relevant to any particularly diﬃcult scenario.

While a detailed study of this problem is not the core objective of this thesis (the reader
may refer to (Medathati et al, 2016) for a detailed review), this work is careful when discussing
bio-inspiration and plausibility of reviewed and developed architectures. Without attachment
to any particular level of biological plausibility, biological function and structure have served
as a transversal reference for both the experimental developments and literature review, being
addressed at multiple occasions throughout this work.

1.1.3 The problem of small datasets

All this progress however is linked to the widespread availability of large-scale datasets,
with thousands of samples per image category, amounting to millions of images in the full
dataset. As large neural networks have a huge number of learnable parameters, a great number
of examples is necessary for the model to learn a pertinent feature space representation and
achieve generalization in its predictions. On smaller datasets, such large models are likely
to overﬁt training data and not generalize to the target data. Many if not most domains are

18

1. Introduction

1.1 Context and motivation

actually more likely to produce small labeled datasets, for a myriad of reasons. For instance,
in medical imaging diagnostics, trials with each single patient are limited, some conditions
are rarely encountered, and labeling is costly as it demands one or multiple experts opinion.
In industry, the context of images taken from a production plant, a particular machine, or
a pipeline step, may be speciﬁc enough that a dedicated dataset would need to be collected
onsite. This same dataset would later require an expert technician to label whichever faulty
or deviant condition they may be trying to automatically identify. The fact is that on most
organizations not directly working with data collection, but simply willing to automate a
certain internal process, composing a dedicated dataset is not straightforward, neither in terms
of cost nor logistics. Therefore, in most of these cases, one may have to deal with challenging
conditions in terms of data availability for the application of any machine learning method,
and deep learning in particular.

In many such cases, the ﬁrst reﬂex of a well-trained machine learning engineer may be to
recur to less complex models — like decision trees for instance — and in particular to ensemble
versions of them — like random forests or XGboost. Then again, let us not forget our interest
in exploiting image data. The data-oriented features learned through deep models seem to
play a fundamental role in the recent breakthroughs of image recognition. Previous feature
engineering methods have not yielded a comparable level of success in image classiﬁcation.
Moreover, these data-specialized features may be all the more invaluable to domain-speciﬁc
recognition, in which general visual features may not be as discriminant as would be a set
of task or domain-related speciﬁcities. This conﬂicting will of modeling small datasets in a
data-oriented fashion without overﬁtting is the main motivation topic behind the present work.
Throughout this work we seek to understand the hierarchical feature learning performed by
deep neural networks — in particular convolutional architectures — while mapping out the
circumstances under which they can be successfully exploited under limited training data
availability. A detailed exploration of this problem with an analysis of its diﬀerent composing
parts constitutes a major part of this thesis’ work.

1.1.4 Deep learning literature

Overall, research in the machine learning community has heavily shifted towards deep
networks-based work recently. Indeed, conferences speciﬁcally related to the topic (NeurIPS,
ICML, IJCNN, among others) have seen an exponential increase in the number of submissions
and overall participation. Additionally, the pre-publishing of articles on open online platforms,
such as ArXiv, has also set and increased pace in the ﬁeld, with interactions, paper citations
and derivative works all happening much faster than a typical peer-reviewed publication cycle.
It is a diﬃcult and time consuming matter on itself to navigate through this ever-growing
literature corpus, trying to discern promising trends from ephemeral hacks.

When trying to focus on the speciﬁc problem of small data learning, one will eventually re-

19

1. Introduction

1.2 Related topics

alize it brings on a few more particular diﬃculties. First, this is not one, but multiple problems.
Several diﬀerent practical settings can be referred to as being some form of small data learning.
Secondly, not that many works have tried to directly measure and address the diﬃculty of
training CNNs on small datasets, rather addressing similar diﬃculties encountered in other
sub-ﬁelds (e.g. ﬁne-grained classiﬁcation, metric learning, transfer learning, meta-learning,
to name a few). These two aspects combined lead to a third general observation: the current
state of knowledge in this area is not readily available to anyone with an incipient interest in
this problem. Instead, it takes reading works from multiple related areas in order to map out
the challenges and levers of action in face of any particular form of data scarcity. It is therefore
paramount to revisit these diﬀerent areas, structuring and linking apparently disconnected
studies covering these multiple aspects of the subject. This knowledge organization eﬀort is
one of the major aspects of this thesis’ work.

1.2 Related topics

Given the context of this work, some notions parallel to the core topics of CNNs and
image classiﬁcation will be occasionally mentioned in the course of the following chapters.
Namely, it is important that the reader has a basic familiarity with other closely related object
recognition tasks, as well as a minimal notion of other contemporary DNN models developed
(or popularized) over the past decade. The following sections thus provide brief explanations
on these topics, pointing towards speciﬁc references for further information. The reader
familiar with these concepts may skip the current section and proceed to reading section 1.3.

1.2.1 Object recognition tasks

Besides image classiﬁcation, object recognition may concern other more speciﬁc tasks that
aim to provide more detailed information than simply a global image label. The following
paragraphs describe some relevant object recognition tasks, particularly focusing on those
performed on still images. Object recognition on videos is considered out of the scope of this
thesis.

Image classification In plain image classiﬁcation, each sample gets an image level label,
regardless of the presence of objects corresponding to other labels. In some datasets, the ideal
labels are quite clear for whomever is carrying the annotation process, because only one object
is present per image. This is the case with the handwritten digits dataset MNIST and the
multi-alphabet character dataset Omniglot (see more on these datasets in appendix C). For
datasets containing realistic images, like ImageNet, MS-COCO and others, there is naturally
more ambiguity in identifying the target class for an image.

Object localization and detection In object detection and localization, models have

20

1. Introduction

1.2 Related topics

to predict an object’s presence and position within the input image. Both tasks are similar and
their names are occasionally interchanged. Usually, the name object localization is associated
with image-level classiﬁcation. In this case, a single label is predicted, and the corresponding
object within the image is contoured. Object detection is more general and assumes the model
will try to recognize and localize multiple objects within the image —- which implies in
possible multiple labels per image. Object detection is thus a multi-label classiﬁcation problem,
in which the presence or absence for each category is predicted (often on a probability scale).
In both cases, it is necessary to predict image coordinates (a double regression problem)
for the recognized object category (or for each instance of all detected categories). Most often
the ﬁnal goal is to predict a bounding box enclosing each occurrence of the detected objects. It
is evident these tasks requires even more costly annotations, composed of label plus bounding
box coordinates.

The ImageNet challenge also provided speciﬁc datasets for both these tasks, derived
from the original classiﬁcation one, but having undergone additional annotation. Winner
models also followed the CNN trend, with additional machinery dedicated to bounding box
prediction. For more on the advances obtained in these tasks through CNNs, the reader may
refer to the surveys by Agarwal et al (2018) and Zou et al (2019).

Semantic segmentation Dividing an image into its composing parts, providing a label
for each of them: that is the goal of semantic segmentation. More than simply predicting
bounding boxes, this task involves predicting more precise boundaries for each recognized
element. When all elements of a scene need to be identiﬁed, the task is also referred to as scene
labeling. When only some instances of particular objects are to be detected, the task is also
known as object segmentation or instance segmentation.

This task is performed thanks to speciﬁc datasets which are annotated with contours
dividing the diﬀerent labeled parts. Typically, these annotations get converted into a target
image that is pixel-wise labeled by applying the annotation masks over the original images,
attributing to each pixel the label corresponding to its containing segment. Given this target,
the predicting network has to output a single-class prediction for each input image pixel.
Diﬃculties particular to performing this task with CNNs include the need for heavy pixel-
wise labeling, the challenge of identifying precise borders and mapping up the predicted
segmentation (often sub-sampled) to the input image. A review of recent advances on this
front can be read in Garcia-Garcia et al (2017).

1.2.2 Other relevant deep architectures

Despite the protagonist role of convolutional models in the popularization of deep net-
works, they were not the sole architecture family taking part in the latest advances. Other kinds
of deep models have equally evolved along the past few years, achieving similar widespread
status in their respective application ﬁelds. Here we cover brieﬂy some of these models, which

21

1. Introduction

1.2 Related topics

get mentioned throughout this thesis, providing references for further detailed information.

Recurrent neural networks The ﬁrst Recurrent neural networks (RNNs) have been
proposed not long after the ﬁrst feedforward models (e.g. Rumelhart and McClelland, 1987;
Elman, 1990). These networks incorporate a time dimension, such that a recurrent unit’s
output will be dynamic. At any instant t, its output h[t] will not only depend on the input
x[t] but also on the previous output value h[t − 1]. Currently used models have improved on
this simple recurrent structure, mainly trying to circumvent particular training diﬃculties of
RNNs (related to vanishing or exploding gradients, refer to Bengio et al, 1994). Long-short
term memory (LSTM) networks are one successful example. First proposed by Hochreiter
and Schmidhuber (1997), they are more capable of learning long-term dependencies, making
them appropriate to sequence modeling applications (refer to Goodfellow et al, 2016g, for
more details this type of task).

Diﬀerent models may feature other memory or gating structures and incorporate additional
internal states in the output computation (refer to Yu et al, 2019, for a review). Gates can be
composed of extra neurons within a recurrent unit, with memory cells corresponding to the
current result of gating computations. Along with LSTM units, gated recurrent units (GRU),
ﬁrst proposed by Cho et al (2014), are also widely used today. An LSTM unit has a separate
memory cell, along with input, output and forget (memory cell overwriting) gates. Forget and
input gates control which information should be kept ( from the current input and from the
past), being used to calculate the next memory cell state. The output gate computes the next
output value, combining this newly computed memory cell state with the previous output
and the current input. GRUs are simpler, with no explicit memory cell. They still count with
an update gate — deciding which input information to keep/ignore for the next output —- and
a reset gate — controlling how much past information inﬂuences the next output.

In general, recurrent network models are widely used for language modeling (e.g. Mikolov
et al, 2013), language translation (e.g. Wu et al, 2016) and also for audio processing and speech
recognition (e.g. Sundermeyer et al, 2015). In image processing, they are mainly applied
to tasks involving video, such as video captioning (Shetty and Laaksonen, 2015), action
detection (Xu et al, 2019), video segmentation (Pavel et al, 2015; Siam et al, 2017), video
super-resolution (Shetty and Laaksonen, 2015), to cite a few. Recurrent CNN models applied
to image classiﬁcation will be reviewed in chapter 4.

Generative models Besides discriminative models — like most classiﬁcation and regres-
sion predictive models — another approach in statistical learning concerns generative models.
While discriminative models estimate the probability of an outcome — a discrete label or
real value — conditioned on data samples, i.e. p(y|x), generative models also model data
samples directly, either on their own i.e. p(x) or jointly with labels, i.e. p(x, y). Deep generative
models (refer to Goodfellow et al, 2016d, for an overview) include a variety of autoencoders,
stochastic models (like the restricted Boltzmann machine (RBM)), and generative adversarial

22

1. Introduction

1.3 Thesis focus and contributions

networks (GANs).

Autoencoder architectures, as the name suggests, are trained to predict the input sample,
encoding it through a mirrored architecture (refer to Goodfellow et al, 2016a, for a textbook
introduction to autoencoders). First, the encoding part maps an input (say, an image) to a
middle layer of neurons. Then, the decoding part maps the value of these neurons back to an
input-like sample (say, another image). There are several variations of this basic architectural
principles, such as sparse autoencoders (SAEs) (e.g. Makhzani and Frey, 2014) denoising
autoencoders (DAEs) (ﬁrst proposed in Vincent et al, 2008) and variational autoencoders
(VAEs) (ﬁrst proposed in Kingma and Welling, 2014).

Another important group are the generative adversarial networks, ﬁrst proposed by Good-
fellow et al (2014) (see Creswell et al, 2017, for an overview). These architectures have two
sub-models — the generator and the discriminator — interacting in a zero-sum game1, one
trying to “fool” the other. On one side, the generator takes a random seed as input and maps it
out to an image. On the other side, the discriminator takes this image as input and tries to pre-
dict whether it is real or artiﬁcially generated. The objective function enforces the generator to
produce images that fool the discriminator, while the latter is enforced to improve its detection
of artiﬁcial images (refer to the tutorial by Goodfellow, 2016, for detailed explanations). Ever
since their ﬁrst proposal in 2014, a surprising high number of variations has been proposed in
the literature2, turning research on this type of architecture into a ﬁeld in itself. GAN models
have been successfully applied to realistic data generation or transformation in multiple
domains, including not only image and video (e.g. with CycleGAN by Zhu et al, 2017a), but
also audio (e.g. with WaveGAN by Donahue et al, 2019) and text (e.g. with MaksGAN by
Fedus et al, 2018).

1.3 Thesis focus and contributions

In the ﬁrst section of this introduction we have established the diﬃculty and general
interest of applying deep learning to small datasets. Even while restricting the scope to object
recognition, and particularly to image classiﬁcation, there is still a large diversity of approaches
in the domain. Given the rapid evolution of deep learning research and the large corpus of
literature, it is indispensable to review the state-of-the art in order to place any novel proposals.
Moreover, as the small data scenarios are multiple, it becomes necessary to clarify and distinct
the diﬀerent versions of these problems prior to addressing any particular instance of it. We
have therefore addressed this question through two main methodological axes (see ﬁg. 1.1):

(cid:73) An extensive literature review work targeted at posing a clear and concise view of the

1Zero-sum game in the game-theory sense of the term.
2Occasionally referred to as the “GAN zoo”. See https://github.com/hindupuravinash/the-gan-

zoo for a frequently updated list

23

1. Introduction

1.3 Thesis focus and contributions

ﬁeld and the problem to be treated (chapters 2 to 5);

(cid:73) Experimental propositions exploring novel mechanisms within the reviewed framework

(chapter 6).

Figure 1.1 Thesis organization diagram.

Outline From our discussion it is also clear that the problem of object recognition with
CNNs on small datasets is in fact a meta-problem enclosing multiple sub-problems. As such,
it is necessary to (i) identify its composing parts and (ii) decide which and how to address
each of them. We have thus decided for a two-part organization of this work, ﬁrst addressing
object recognition (part I), then following with a speciﬁc treatment of the small data case
(part II).

In part I we have approached object recognition from an interdisciplinary point of view,

discussing artiﬁcial CNNs as well as their biologically inspired aspects:

(cid:73) First of all, we present the basic functioning of object recognition, both in CNNs and in
the brain (chapter 2). In particular, we review recent work comparing CNN and cortical
representations, and summarize functional and architectural features not modeled by
typical CNNs.

(cid:73) As modern capabilities of object recognition have been achieved with feedforward
CNNs, this category of models is reviewed and organized in chapter 3. While other
reviews on the matter have been published in the course of this thesis work, they did not

24

Extensive literature reviewCNN architectures for image classificationRecurrent CNNs for image classificationStrategies for DL on small datasetsExperimental propositionsPrototype-based learning and interpretabilityFew-shot learning with flexible prototypesGeneral domainDeep learningSmall data Image classificationTransversal aspectsRelation to bioplausibility and visual system modelingHyperparameter understanding and analysisScience popularizationFocusContributions1. Introduction

1.3 Thesis focus and contributions

necessarily frame the subject in a way pertinent to the work developed here. Therefore
it was in any case relevant to revise the progress history of architectural principles and
innovations, highlighting the trends pertinent to this present work.

(cid:73) Complementing the previous review work, chapter 4 addresses recurrent and feedback
CNN models for image classiﬁcation. The chapter aims to organize the reviewed models
according to their use of recurrence, from both functional and architectural perspectives.
Besides proposing a literature survey with innovative focus and perspectives, the study
of recurrent processing in CNNs for image classiﬁcation further exempliﬁes the potential
knowledge exchange between neuroscientiﬁc modeling and artiﬁcial neural networks.

Having posed our paradigm of object recognition, we proceed to addressing the conditions

corresponding to small data learning in part II in two steps:

(cid:73) A more detailed description of the problem is presented in chapter 5, including a review
of the main strategies present in the deep learning literature. This chapter is an eﬀort
towards organizing existing knowledge in the ﬁeld, while linking it to related tasks
presenting similar diﬃculties.

(cid:73) Ultimately, the work is completed by experimental propositions within the small data
framework, including the proposition of novel mechanisms and perspectives, building
upon existing deep models.

Eventually, a typical thesis work tends to open many more research questions than it closes.
After an extensive review work, it is natural to identify spaces of possible contribution and
interaction between ﬁelds that could help advance knowledge. As these could be the subject
of many other thesis, these open perspectives will be exposed and discussed in the thesis
conclusion.

25

Part I

Object recognition with deep
convolutional neural networks

.

.

.

.

.

Introduction .

2 Convolutional neural networks and visual system modeling
.

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
2.1
2.2 Convolutional neural networks . . . . . . . . . . . . . . . . . . . . . . . . . .
2.3 Visual system: a schematic overview . . . . . . . . . . . . . . . . . . . . . .
2.4 The object identiﬁcation pathway in relation to CNNs . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . . . . . .
2.5 Discussion .
.
. . . . . . . . . . . . . . . . . . . . . . . . . . . .
2.6 Conclusion .

.
.

.
.

.
.

.
.

.
.

.
.

.
.

.
.

3 Feedforward CNN architectures for object recognition
.

.

.

.

.

3.1
3.2
3.3
.
3.4 Discussion .
3.5 Conclusion .

Introduction .
.
Single pathway models
Parallel pathway archs .
.
.

.
.

.
.

.
.

.
.

.
.

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . . . . . .
.
. . . . . . . . . . . . . . . . . . . . . . . . . . . .
.
. . . . . . . . . . . . . . . . . . . . . . . . . . . .
.

.
.
.

4 Recurrent and feedback CNN architectures for object recognition

.

.

.

.

.

.

4.1
4.2
4.3 Architectural trends .
.
.
4.4 Discussion .
.
4.5 Conclusion .

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Introduction .
Functionalities brought by recurrent processing . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . . . . . .

.
.
.

.
.
.

.
.
.

.
.

.
.

.
.

.
.

27
27
29
32
34
40
45

47
47
49
52
59
62

63
63
64
69
79
83

26

Chapter 2

Convolutional neural networks and visual system
modeling

2.1 Introduction

Traditionally, object recognition was tackled from a pure computer vision framework,
including a thoughtfully designed feature extraction algorithm, in conjunction with some
robust machine learning model, for instance a support vector machine (SVM), to correctly
classify the object category (Andreopoulos and Tsotsos, 2013). The key point is that these
features were not learned from data, but demanded careful engineering from image processing
specialists, leveraging knowledge of intrinsic image properties and/or image statistics (from
natural or domain-speciﬁc images Torralba and Oliva, 2003; Hyvärinen et al, 2009), which
were relevant to the problem at hand. The computed features were condensed into a feature
vector, also referred to as an image descriptor.

Designing image descriptors was an important line of research of its own until the early
2010s (Zheng et al, 2018). Image descriptors are typically obtained after non-linear ﬁltering
operations, which detect basic image characteristics (such as color, texture or higher order
statistics) — a process known as feature extraction. Features can be computed globally from
the entire image, but since 2003 the study of local descriptors - such as scale-invariant feature
transform (SIFT) (Lowe, 2004) and histograms of Gaussians (HoG) (Dalal and Triggs, 2005)
— gained importance Zheng et al (2018). In that case, images are partitioned with features
being computed for each part — object/background segmentation for instance. Then these
local features can be aggregated (for instance, computing histograms) into a single feature
vector.

Meanwhile, inspired by how text documents could be represented via a “bag-of-words”
model, image descriptors started to be encoded according to how they represented the
database at hand, before being directly used for classiﬁcation or retrieval, Sivic and Zis-
serman (2003) being an early proponent of this approach. The idea was to create a dictionary
of visual words — via clustering for example — that will correspond to diﬀerent feature
dimensions in the ﬁnal representation vector. It is worth noticing this strategy has brought a
learning component to the usual recognition pipeline, as the “bag-of-visual-words” is usually

27

2. CNNs and visual system modeling

2.1 Introduction

Figure 2.1 Typical CNN. Credits: Aphex34 CC BY-SA 4.0

learned from the dataset. This combination of feature extraction and “bag-of-features” was
extensively used in both image classiﬁcation and retrieval, before the popularity rise of deep
networks (Yang et al, 2007; Zheng et al, 2018).

It was with surprise, during the Large-Scale Image Recognition Challenge of 2012, that
the community received the news that a deep convolutional neural network (DCNN) fed
with raw pixels with little pre-processing had beaten all the traditional methods based on
handcrafted features by a signiﬁcant margin (Krizhevsky et al, 2012; Cardon et al, 2018).
With inspirations from the neurobiology of the visual cortex, convolutional networks are
named after the basic image processing operation they perform, cascaded with point-wise
non-linearities and sub-sampling (pooling) (see ﬁg. 2.1). This class of models has been
around long before this technical breakthrough, but had not yet proved able to outperform
well founded computer vision methods in practice. Availability of large datasets together with
improvements in hardware and GPU programming tools were fundamental for the recent
success of these large architectures.

With this result, an important paradigm shift intervened in the ﬁeld of object recognition.
Instead of concentrating eﬀorts in feature engineering and the extraction of good descriptors,
the use of deep neural networks can implicitly extract intermediate representations of the
input data, achieving high accuracy in their classiﬁcation. The hierarchical way in which visual
features are detected by deep networks parallels the hierarchy of the early visual cortex, but
considering only a feed-forward simpliﬁcation of it. These relations will be further discussed
in the course of this chapter (sections 2.4 and 2.5.2).

Early versions of hierarchical neural architectures with local receptive ﬁelds date back to
the 1980s, with the Neocognitron architecture (Fukushima, 1980), based on functional and
architectural principles observed in the early visual cortex (Hubel and Wiesel, 1962). This bio-
inspired model sparkled the development of the ﬁrst backpropagation-trained convolutional
networks designed by LeCun et al (1990a), who successfully applied the model to handwritten
digit recognition. After Krizhevsky et al in 2012, many architectural innovations were proposed

28

2. CNNs and visual system modeling

2.2 Convolutional neural networks

including parallel branches (Szegedy et al, 2015) and forward shortcut connections (He et al,
2016a). These recent advances will be discussed in more detail in chapter 3.

Along with the initial bio-inspiration, other functional similarities have been observed in
CNNs trained on natural data and the way they hierarchically extract and integrate visual
features. Conversely, much of the functionality of the biological visual system remains unac-
counted for in these convolutional models. In the following sections, the basic functioning of
modern convolutional networks is presented along with a description of its main building
blocks. We then follow along to a brief description of the current knowledge about the visual
system from neuroscience. Since our focus remains being artiﬁcial networks, this text has no
intention of being a self contained introduction to visual system modeling. Both these intro-
ductory descriptions set base for the subsequent discussion on the relation between CNNs
and visual cortex modeling, highlighting to which level and extent they mimic biological
function, along with aspects that remain absent from mainstream models.

2.2 Convolutional neural networks

Convolutional neural networks (also known as CNNs or ConvNets) are typically consti-
tuted of at least two convolution layers. Since convolutions are linear operations, cascading
such layers would be reducible to a single linear operator. On a ConvNet, however, as on a
traditional multi-layer perceptron (MLP), this operation is followed by a non-linear opera-
tion, the activation function. Every few layers, a spatial subsampling (pooling) operation
is performed, aggregating information from multiple neurons in the previous layer. These
operations and their functions will be discussed below. The reader familiar with these concepts
can skip to section 2.3.

Since the focus here is on object recognition from images, this description of convolutional
neural networks refers typically to the case where 2D convolutions are applied to images.
Nevertheless, CNNs are applicable to other domains such as audio (for instance Hershey
et al, 2017) and even text processing (e.g. Kim, 2014), using typically 1D convolutions.

2.2.1 Convolutional layers

A convolution is a standard linear operation, widely used in signal processing as a ﬁltering
operation. In 2D, a convolution is the operation used to apply a ﬁlter (or kernel) to an image.
Intuitively speaking, a convolution consists in reversing the kernel and sliding it over every
position in the image, multiplying the overlapping pixels and adding them up to generate
one pixel of the ﬁltered image. More strictly, the operation typically performed in neural
networks skips the ﬁlter reversing part, corresponding actually to a cross correlation operator.
However, in the neural network community, it became standard to refer to this operation as
convolution, and this is the deﬁnition used throughout this thesis. A mathematical expression

29

2. CNNs and visual system modeling

2.2 Convolutional neural networks

of the (discrete) convolution operation (in the neural network sense) can be given as follows
(Goodfellow et al, 2016b, chapter 9):

S(i, j) = (I ∗ K)(i, j) =

H
(cid:88)

W
(cid:88)

m

n

I(i + m, j + n)K(m, n)

(2.1)

where I is the input image matrix, K is the ﬁlter kernel matrix and H, W are the image’s
height and width, in number of pixels.

From a traditional neural networks point of view, this operation can be described as follows.
Each pixel of an image correspond to one of the input neurons, which are arranged in a 2D grid.
Each pixel of the output image corresponds to a hidden or output layer neuron. Connectivity
between the two layers, however, will not be thorough but limited to local vicinities: each
output neuron is connected to a sub-grid of the input layer. The synaptic weights of this local
connectivity mask corresponds to the weights the convolution ﬁlter. For the correspondence
to be complete, these weights should be shared among all output neurons. In summary, a
convolution layer can be seen as a locally connected neural layer with shared weights.

These characteristics largely reduce the number of parameters in a CNN, if compared
to a traditional fully-connected MLP. It is an interesting example of architectural domain
adaptation to reduce model complexity, a theme further discussed in chapter 5. Another
interesting characteristic of CNNs derived directly from this weight sharing (or sliding ﬁlter)
is its equivariance to translations: a spatially translated object results in its activation being
equivalently translated on later layers.

Variants of the basic convolution layer include strided convolution (where the step taken in
the sliding process is larger than 1) (Springenberg et al, 2014), dilated (or à trous) convolution
and deconvolution widely used for semantic segmentation (Chen et al, 2016; Wang et al,
2017b), tiled convolution (where instead of a single kernel matrix, a set of kernels is circled
through as we slide over the input) (Le et al, 2010), among others.

As done in traditional image processing, convolutions with a particular ﬁlter work as
pattern detectors. Early visualizations of ﬁlters learned by a CNN trained over the large scale
ImageNet dataset (see appendix C) indeed demonstrated how those of the ﬁrst layers resemble
basic traditional detectors, such as Gabor ﬁlters (orientation) and color ﬁlters, particularly
in the ﬁrst layers (Zeiler and Fergus, 2014). As we rise in the hierarchy, it becomes more
complicated to understand the patterns being detected, but the principle is the same.

2.2.2 Pooling or subsampling

Another operation present in the pipeline architecture of a ConvNet is spatial subsampling.
In this operation the input divided in portions with a regular grid, with each part being
summarized to a single value, reducing the dimension of the feature maps. This operation is

30

2. CNNs and visual system modeling

2.2 Convolutional neural networks

known as pooling or subsampling. Typical pooling operations are the max pooling (where
the region is summarized by the largest value among them) and the average pooling (region
replaced by its mean). When it is important to avoid loosing too much spatial resolution,
a frequent alternative is to delay subsampling to the ﬁnal layer, applying a global average
pooling at the ﬁnal feature maps and just before the output classiﬁer layer — such as done in
GoogleNet (Szegedy et al, 2015) or in residual networks (ResNets) (He et al, 2016a). More
recently, an adaptive pooling strategy has been proposed for speciﬁc applications, using
traditional segmentation algorithms to deﬁne an adaptive pooling mesh (Tsai et al, 2015).
It has also been proposed to substitute pooling layers for strided convolutions, which also
achieve spatial aggregation and dimensionality reduction, but with learnable parameters
(Springenberg et al, 2014). Nevertheless, max-pooling has worked well in practice and remains
the most popular subsampling operation in CNNs.

2.2.3 Activation functions

In traditional neural networks the neurons have an non-linear activation function. Orig-
inally a thresholding Heaviside function, common smooth substitutes are the hyperbolic
tangent and the sigmoid function. These two activation functions are bounded, saturating for
both positive and negative extremes. Additionally, they are diﬀerentiable, which is a neces-
sary property for the backpropagation algorithm. They were most common when building
shallow networks, but more recently, the rectiﬁed linear unit (ReLU) has proven to work
better experimentally, specially when dealing with deeper networks (Glorot and Bengio, 2010;
Jarrett et al, 2009). These functions are applied to each neuron independently, on a given layer.
Using the ReLU means particularly that only positive values get through to the following
layer. Although this function is not diﬀerentiable everywhere — since it has a discontinuity at
0 — it is so in a piece-wise manner — before and after 0. This property is used in order to
derive an adapted version of gradient backpropagation through ReLU units.

An experimental analysis by Glorot and Bengio (2010), monitoring activations and gradi-
ents has brought some light on the reason of ReLU’s success. While the saturation of sigmoid
and tanh units is not a signiﬁcant issue when using shallow networks, it can slow down (or
even impede) convergence for deeper networks — a problem known as the vanishing gradients.
These saturating activations have derivatives that tend to vanish with their corresponding
backprogation updates on lower layers, due to successive multiplications by increasingly
small values. On the other hand, ReLU activation does not saturate, and its derivative avoids
the vanishing of lower layer gradients.

Some other activation functions have been explored, beginning with variants of the ReLU
such as the leaky-ReLU, the exponential and scaled exponential linear units (ELU and SELU)
(see a comparison by Pedamonti, 2018), but also extending to completely diﬀerent approaches
such as interpolating functions (Wang et al, 2018a).

31

2. CNNs and visual system modeling

2.3 Visual system: a schematic overview

2.3 Visual system: a schematic overview

To clarify to which extent CNNs are related to the functioning of our biological vision, it
is important to understand how this process takes place in the brain and how it is modeled
from a neuroscience point of view.

Before discussing similarities and diﬀerences between biology and CNNs, it is important
to have in mind at least a rough notion of visual cortex organization and function (section 2.3).
More detailed descriptions will follow while discussing the object recognition pathway and
its similarities to feedforward convolutional networks (section 2.4) and particularly when
discussing aspects missing from these basic feedforward models (section 2.5.2).

In order to build a global picture, this section presents a brief overview of two important
aspects of the visual system: its hierarchical organization and the traditional division in dorsal
and ventral streams. Readers familiar with these topics may skip to section 2.4.

2.3.1 A hierarchical system

The biological visual system is traditionally viewed a hierarchical succession of specialized
brain regions. This idea goes back to Marr (1982), who ﬁrst proposed a model in three levels,
each computing increasingly complex properties from the visual stimuli. In his model, these
hierarchical levels processed information sequentially, aggregating outputs from the previous
level. First, the primal sketch level would detect light intensity changes and how they are
geometrically organized. Pooling from the ﬁrst level features, the 2 1
2-D sketch level should
convey information associated with surfaces and their orientation in space, the perceived
distance to the viewer, their reﬂectance and illumination, dealing with discontinuities in these
quantities. The ﬁnal 3D sketch level, though keeping some surface information, would shift
the perspective to the object, portraying a representation of its dimensional structure (Marr,
1982, chapter 1).

The general idea of a hierarchical organization was supported later by anatomical studies,
in particular by Felleman and Van Essen (1991), who proposed a description of the visual
cortex organized in a hierarchy of regions, with ascending and descending connections (see
ﬁg. 2.3). Later, several neurophysiological studies have observed how neurons of lower or
upper regions are tuned to prefer more or less complex stimuli, resonating with the general
idea of incremental perception of visual features (although not complying precisely with the
geometrical view by Marr of 2.5D and 3D representations, as discussed further in section 2.4).
In a nutshell, a more modern view of Marr’s hierarchy would be comparing the primal sketch
level to the early-vision front end, a second sketch level to mid-level areas extracting higher-
level features, with ﬁnally a third sketch level corresponding to upper regions computing
more abstract representations.

32

2. CNNs and visual system modeling

2.3 Visual system: a schematic overview

As far as this ﬁrst rough description is concerned,
visual perception starts at the retina, with photorecep-
tive cells stimulating ganglion cells that form the optic
nerve. These optic ﬁbers run to the center of the brain,
with connections to the thalamus, mainly the lateral
geniculate nucleus (LGN), but also the pulvinar (Pul)
(Cortes, 2012). From the thalamus, optical ﬁbers go
to the occipital lobe – the back of the brain – to the
primary visual cortex (V1) (see ﬁg. 2.2). The primary
visual cortex detects basic visual indices, such as ori-
entation patterns, which are fed to upper regions in
the visual system anatomical hierarchy. Even though a
major sequentially hierarchical path can be identiﬁed
(highlighted in red in ﬁg. 2.3), including mainly areas V2, V3,V4 and IT, the interconnection
pattern between regions is more complex and includes multiple parallel connections and
shortcuts. A more detailed description, focusing on regions and mechanisms relevant for
object recognition, will be done in the following sections.

Figure 2.2 A simpliﬁed anatomic schematic
of the visual neural pathways in the brain,
from retina to the primary visual cortex (V1).
Credits: Miquel Perello Nieto CC BY-SA 4.0

2.3.2 The schematic two-stream model

Besides its remarkable hierarchical organization, another prevalent view of the visual
system is its anatomical division in a dorsal and a ventral streams. Neurophysiological experi-
ments (e.g. Mishkin et al, 1983) have led to a popular (although rather schematic) view of
these two streams as functionally distinct (ﬁg. 2.4):

(cid:73) The dorsal pathway, also known as “Where” (or “Where-How”) pathway, is implicated
in processing of movement and localization of objects. This pathway interacts with
motor areas, being also involved in the ability to manipulate an observed object.

(cid:73) The ventral pathway, also referred to as the “What” pathway, mostly implicated in

processing object identiﬁcation and/or categorization.

Looking at a lower level, one can see this specialization and division of processing actually
starts earlier. In the retina, photoreceptive cells feed into ganglion cells of diﬀerent kinds, which
in turn yield pathways with distinct functions. To mention the two most well known, there is
the magnocellular-pathway which has a faster communication of spatially coarser luminance-
based inputs, while the parvocellular-pathway conveys more contrast-based detailed spatial
information (particularly from the central vision) at the expense of a lower time sensitivity. The
fast magnocellular pathway is implicated in fast processing of movement, and concentrates
towards the dorsal pathway, correlating with its function of motion processing. The slower

33

2. CNNs and visual system modeling

2.4 The object identification pathway in relation to CNNs

parvo-cellular pathway conveys detailed information mostly used in the ventral pathway for
more precise object identiﬁcation.
The reader may refer to speciﬁc
literature for details, such as Unger-
leider and Haxby (1994) for more
on the two-stream view, or Goodale
and Milner (1992) for more on the
“Where/How” pathway.

Figure 2.4 After reaching the primary cortex in the occipital lobe,
visual processing is roughly divided in two streams or patwhays:
the dorsal pathway goes up to the parietal lobe, while the ventral
pathway goes lower towards the inferior temporal lobe. Credits:
OpenStax College CC BY 3.0

This schematic view of function-
ally distinct regions distributed in
two independent streams is clas-
sic in the ﬁeld, although rather
imprecise. Indeed, under detailed
scrutiny, the direct identiﬁcation be-
tween anatomy and function is not
completely accurate, as there are two-way connections linking non-adjacent regions as well as
connecting ventral and dorsal streams. These and other aspects that portray a more complex
view of the visual system will be discussed in section 2.5.2. For instance, Casagrande (1994)
discuss the limits of this oversimplifying two-stream view, proposing a third pathway, which
is closely related to non-standard retina cells (as discussed in Gollisch and Meister, 2010)1.
This additional stream is related to fast reaction to perceived dangers, structuring a coarse and
fast recognition tightly linked to sensory-motor action, thus beyond the scope of our study.

2.4 The object identification pathway in relation to CNNs
Overall, CNNs reﬂect the organization of the feedforward part of the ventral pathway,
though in a very simpliﬁed manner. There are arguments to support this feedforward path
from retina to IT is enough to explain our basic object recognition abilities (DiCarlo et al,
2012). However, more complex tasks such as tracking a moving object or identiﬁcation under
occlusion might demand more complex mechanisms currently ignored by standard CNNs
(Roelfsema, 2006). This section dives into the “what” pathway and explains its main properties,
while drawing a parallel with similar characteristics found in standard ConvNets.

2.4.1 Core object recognition

Primates are capable of precise identiﬁcation or coarse categorization within less than
100 ms (Fabre-Thorpe et al, 1998). Additionally we are robust to a multitude of identity-

1Readers particularly interested in this topic may refer to Teftef et al (2013) for a review and modeling of

these retinal cells, or to Carvajal (2014) for their relation with cortical visual system.

34

2. CNNs and visual system modeling

2.4 The object identification pathway in relation to CNNs

preserving transformations such as object position, size and pose, lighting conditions and
background context. This cognitive ability is deﬁned by DiCarlo et al (2012) as the problem
of core object recognition. It is of course a very basic part of visual perception as a whole, and
does not account for the totality of visual tasks primates can accomplish.

Experiments observing electrophysiological signals from neuronal populations in the
cortex of primates (e.g. Fabre-Thorpe et al, 1998) support that core object recognition can be
achieved within exposition intervals as short as 100 ms. This fast-brain processing mechanism
proposed by Fabre-Thorpe et al has also been modeled computationally. In particular, Viéville
and Crahay (2004a) have proposed an implementation training a shallow neural network
along with solving a primal SVM classiﬁer.

Furthermore, this time is suﬃcient for observation of related feed-forward activity up
to the IT cortex, indicating that some form of recognition can be performed even before
any top-down mechanism kicks in. While more recent work has highlighted the important
role played by feedback loops and recurrences in vision as a whole (e.g. Roelfsema, 2006),
feed-forward mechanisms have been shown suﬃcient to explain this restricted ability of fast
“core object recognition” (DiCarlo et al, 2012). This fast-brain recognition is however limited to
simpler cases, in which there is relatively little ambiguity about the object to be recognized.

Building invariance Computationally, to make a decision on the identity of an object, a
subject should have a neuronal representation of the visual scene, with some set of neurons
“reading out” this representation to provide or not a strong activation signal concerning the
object category, following its presence or absence in a given part of the visual ﬁeld (DiCarlo
and Cox, 2007). Additionally, since primates are able to recognize objects across a multitude
of transformations — position, pose, illumination and clutter — these representations would
ideally be invariant to these identity-preserving transformations (DiCarlo et al, 2012).

Given the hierarchical aspect of the ventral stream, the search for an invariant representa-
tion translates to how the visual system can incrementally compute such invariants, obtaining
approximately the same higher level activations for diﬀerent initial retinal stimuli arising
from the same object (or category). A geometrical intuitive description of this framework is
to think about diﬀerent object categories represented as entangled manifolds in the retinal
space (DiCarlo and Cox, 2007). By separating dimensions related to each identity preserv-
ing transformation, the processing in each visual area takes a step towards untangling the
object manifolds, allowing categorization to be achieved by a linear readout performed by a
population of neurons.

35

2. CNNs and visual system modeling

2.4 The object identification pathway in relation to CNNs

Figure 2.3 Anatomical hierarchy of brain regions implicated in visual processing, according to Felleman and
Van Essen (1991). The ventral pathway associated to “core object recognition” is highlighted in red. Credits:
Cortes (2012).

36

2. CNNs and visual system modeling

2.4 The object identification pathway in relation to CNNs

2.4.2 Early vision: from retina to V1 cortex

Visual processing is not done exclusively by cortical areas. As the ﬁrst luminous impulses
ﬁre up retinal ganglion cells, information processing is already taking place. Moreover, the
way luminous signals are acquired and transmitted is intertwined to how later processing
stages are organized. The central part of the visual ﬁeld is captured through the fovea, a
portion of the retina more densely packed with receptors than its surroundings. This variation
in the concentration of receptors implies in a higher resolution central vision associated with a
lower-resolution periphery vision. As a result, eye movements are essential in order to acquire
a higher resolution perception of an entire scene. Most animals perform rapid eye movements
(between 200 and 500 ms) (Land, 1999; DiCarlo et al, 2012), acquiring diﬀerent “shots” of
the same scene. As we are mainly concerned with recognition on still images, details of this
acquisition mechanism are out of the scope of this review. For the following, descriptions
concern the treatment of a unique visual frame, a single snapshot of the perceived scene

Some characteristics of the pre-cortical vision and early V1 processing are also tightly
linked to the anatomy of image acquisition, such as the preservation of the spatial topology
in the retina — a property known as retinotopy — and in consequence the spatially localized
receptive ﬁelds. These characteristics have analogous counterparts in convolutional models,
and will thus be further described in the following sections.

2.4.2.1 Retinotopy

The visual ﬁeld is not perceived uniformly by the retina, with the center of the visual
ﬁeld being over-represented in comparison to peripheral regions — due to the higher density
of receptors present in the foveal region. Still, 2D spatial vicinities are retained, such that
retinal perception implements a non-orthogonal transformation of the visual ﬁeld. It has been
observed, in experiments within cat’s cortex (Hubel and Wiesel, 1962), that V1 retains this
particular retinal topological organization, a property known as retinotopy. In primate visual
cortex, retinotopic maps have been observed also in V2 and V3 regions, and the posterior
region of the IT cortex (pIT) (DiCarlo et al, 2012). By analogy, it can be said that retinotopy is
also a characteristic of convolution layers and, together with spatial pooling, helps to build up
tolerance to small translations.

This 2D representation of the visual ﬁeld present in these early regions raises interesting
problems that have to be solved in the path towards object recognition. First, such spatial
representation needs to give place to a more abstract representation, invariant (or at least
tolerant) to spatial transformations that preserve object identity. This issue is partially ad-
dressed by CNNs, which achieve at later layers a more category-centered representation,
being equivariant to translations. Second, the retinotopic representation being eye-referenced,
achieving a pose invariant representation of an observed three-dimensional object may require

37

2. CNNs and visual system modeling

2.4 The object identification pathway in relation to CNNs

a shift in perspective to a diﬀerent spatial frame of reference. This ability is not fully explained
only by a feed forward pipeline, not present in standard CNNs.

2.4.2.2 Receptive fields

Standard receptive ﬁelds in the retina are of center-surround type, as observed by Hart-
line (1940) and Kuﬄer (1953). Having an ON-OFF or OFF-ON response, they perform the
computational function of ﬁltering the “raw image” captured by the photo-receptors. At the
functional level, such ﬁlters either implement contrast detection — detecting local spatial
intensity variation — or motion detection — detecting temporal intensity variation. Later
Hubel and Wiesel (1959, 1962) also recognized these concentric receptive ﬁelds on LGN, while
in the primary visual cortex (V1), diﬀerent elongated center-surround cells were observed.
Furthermore, in their study of cat’s V1 cortex, they noticed the existence of more sophisti-
cated receptive ﬁelds, which were classiﬁed as simple, complex and hypercomplex cells. Though
all respond to bars and edges in particular orientations, simple cells are spatially spread de-
tectors, while complex cells pool from the activation of simple cells, locally building tolerance
towards spatial translation. A similar process goes on for hypercomplex cells, though they
exhibit a clear non-linear behavior while complex cells are only linear.

Complex and hypercomplex cells are also selective to directions, while the latter are
selective to lengths as well. It was later demonstrated that this separation in simple or complex
receptive ﬁelds is not static, but actually highly adaptive depending on the visual input
statistics (Fournier et al, 2011).

This pooling mechanism, together with the orientation selectivity, served as inspiration
for many computational models of the visual cortex (e.g. by Riesenhuber and Poggio, 1999;
Serre et al, 2005), and for bio-inspired computer vision models such as the Neocognitron
(Fukushima, 1988). As described in the previous section, the same architectural feature has
been carried over to modern CNNs. The successive aggregation of small receptive ﬁelds
amounts to neurons responding to larger portions of the visual ﬁeld, at the expense of a
reduced spatial resolution. While in the brain there is another pathway specialized in spatial
localization, standard CNNs used in object recognition simply lack spatial resolution at
higher layers, with ad-hoc mechanisms being used to achieve tasks such as localization and
segmentation (see chapter 3).

As of their learned receptive ﬁelds, visualizations of ﬁlters learned in the ﬁrst layers of a
CNN demonstrate how some of them correspond to similar basic detectors of orientation,
center-surround, striped patterns and so on (Zeiler and Fergus, 2014; Springenberg et al,
2014). Nevertheless, detectors learned by upper layers are more complex not prone to such
an intuitive observation, even though many eﬀorts have been made towards producing
semantically meaningful visualizations of their preferred stimuli (see Olah et al, 2017, for a
review and interactive examples).

38

2. CNNs and visual system modeling

2.4 The object identification pathway in relation to CNNs

2.4.3 Mid-level visual areas

Although computations performed by the primary visual cortex and the infero-temporal
cortex have been studied and understood to high detail, less is known about the computations
performed in mid-level processing. Due to multiple phenomena such as clutter, occlusion,
and 2D retinal representation, visual input representation is often impoverished, ambiguous,
incomplete and noisy. Therefore obtaining an object-level representation invariant to identity
preserving transformations demands not simply feature extraction, but actual feature inference
from image statistics (Purves et al, 2014). There is evidence to support that mid-level areas
such as V2 and V4 play an important role in attending to these demands.

While secondary visual cortex (V2) shares many sensitivity characteristics with the previ-
ous V1 area — including edges, color, orientation, spatial frequency — it is also sensitive to
other cues such as angle and curvature (Kubilius et al, 2015). In addition, V2 neurons are
sensitive to second-order edges, illusory contours inferred from diﬀerences in other visual
cues such as texture patterns. This sensitivity has also been observed in V4, and includes
inferring potential borders from discontinuities in orientation, motion and contrast (Kubilius
et al, 2015). Another perception encoded by V2 cortex is border ownership, starting to give
edges an object pertinence sense and thus deﬁning contours (Perry and Fallah, 2014).

V4 neurons combine orientation responses from both V1 and V2 cortices, eﬀectively
encoding angles and curvature. It is no surprise then that neurons tuned to simple geometric
shapes have also been identiﬁed in this area, although no extensive mapping is known (Perry
and Fallah, 2014). V4 cortex has also been observed to be sensitive to complex curved fragments
and three-dimensional parts of objects (Kubilius et al, 2015). This region also seems to be of
importance to color vision, with center-surround receptive ﬁelds representing perceived color
(as opposed to physical color), as well as hue-tuned cells invariant to luminance (Perry and
Fallah, 2014).

2.4.4 Infero-temporal cortex

The IT cortex is usually referred to as the region responsible for object identiﬁcation, and
the idea of “grandmother neurons” — object-speciﬁc tuned neurons — often arises when
comparing classiﬁer CNNs to biology. While it may be an appealing view easy to explain,
current knowledge portrays a more nuanced picture of which stimuli the IT cortex actually
responds to and how it participates in object recognition.

A ﬁrst striking observation is the diﬀerence in organization, when compared to the previous
cortical regions. Although retinotopic maps are still observed in posterior IT, retinotopy is
lost on central and anterior IT. Instead, a more semantic anatomical organization seems to
have taken place. This view is supported by the existence of some task-specialized regions,
particularly in face processing, identiﬁed in imaging studies (e.g. Freiwald et al, 2009).

Multiple experiments (e.g. Majaj et al (2015)) have demonstrated that object identity can

39

2. CNNs and visual system modeling

2.5 Discussion

be inferred from IT neuronal activity, using a simple weighted sum scheme (i.e. a linear
regression) . Individual IT neurons are activated by at least moderately complex combinations
of visual features, and maintain their relative object selectivity over small to moderate changes
in position, size, pose, illumination and background clutter (DiCarlo et al, 2012).

It was long thought that single neurons were highly selective towards a particular object
while invariant to transformations in its position, pose, etc. This idea of object-speciﬁc neurons
became known as “grandmother neurons”, and has been questioned ever since. In fact most IT
neurons are not exclusively selective of one kind of object, but broadly tuned and responding
to many diﬀerent images and objects. Moreover, it has been observed that neurons with the
highest shape selectivity are the least tolerant to these transformations, going against the idea
of "grandmother neurons".

Indeed, a more contemporary view of IT portrays a distributed representation of visual
semantics, with sub-populations of neurons being responsible for detecting particular con-
cepts, instead of individual neurons. Furthermore, with such a distributed representation,
individual neurons need not be invariant to any transformation, but tolerant to some small
transformations for the visual stimuli. The aggregation of multiple tolerances to diﬀerent
transformations could then build suﬃcient invariances across a neuron population (DiCarlo
et al, 2012).

This population coding view implies that the dimensionality of the IT cortex representation
does not necessarily correspond directly to the number of neurons involved. In fact, the
intrinsic dimensionality of this semantic space has been estimated in a neurophysiological
study by Lehky et al (2014), based on stimuli-response recordings on 647 neurons in the
macaque IT cortex. Their analysis has indicated an approximate dimension of 100 independent
features, which is a surprisingly low number when compared to the 102 to 103-dimensional
vectors typically present in typical CNNs’ upper layers. This fast comparison however neglects
manifold hypothesis that typical data points expectedly lie near a manifold of lower intrinsic
dimension, embedded in this high dimensional space. In this case, semantic representation in
upper CNN layers may also have a much inferior intrinsic dimension.

2.5 Discussion

2.5.1 Comparisons of cortical representations and CNN representa-

tions

The success of CNNs in computer vision has also incited interest from the computational
neuroscience community. Multiple studies have compared, under equal stimuli, registers of
IT neuron populations — both electrophysiological and fMRI — to representations learned
by standard CNNs — which had previously been supervisedly trained on large datasets of

40

2. CNNs and visual system modeling

2.5 Discussion

natural images. The representations extracted from the CNNs, though not optimized to ﬁt the
neural recordings, were highly predictive of IT activity — both single and multi-unit (Yamins
and DiCarlo, 2016).

Using DCNN models by Krizhevsky et al (2012), Zeiler and Fergus (2014) and Yamins
et al (2014), Cadieu et al (2014) have compared their representations to V4 and IT cell record-
ings from monkeys. While the ﬁrst two models were designed for the ImageNet recognition
challenge, the third was trained on the same (smaller) dataset used to obtain IT neuronal
recordings, attaining both high performance and high predictivity of IT neuronal activity.
They have also included simpler bio-inspired models such as HMAX (Riesenhuber and Pog-
gio, 1999), as well as some V1 and V2-like models in the analysis, though their categorization
performance is near chance. On all DCNN models, Cadieu et al observed that the representa-
tion obtained from the penultimate layer can well predict IT multi-unit responses. Moreover,
DCNNs perform comparably to IT multi-units on an object categorization task (and better
than single units or than V4 representations).

Similarly, Khaligh-Razavi and Kriegeskorte (2014) have analyzed some unsupervised and
supervised bio-inspired models, and the supervised DCNN by Krizhevsky et al (2012). They
have observed that models which are not strongly supervised fail to explain IT data (monkey
cell recordings and human fMRI), not correlating with its representational structure. On the
contrary, well performing supervised models present a similar response structure to that of
IT populations, including great clustering of representational patterns by category as well as
within-category dissimilarity patterns.

In a study by Eickenberg et al (2016), the comparison was extended to diﬀerent levels of
both artiﬁcial and biological hierarchies. Feature maps from diﬀerent layers were extracted
from the OverFeat network (Sermanet et al, 2013) — also trained on ImageNet — and used
in a linear model to predict fMRI activations. They observed that while lower layers of the
network (1-2) predict better responses in v1 and v2, upper layers (3-5) predict better responses
in upper areas (V3a, V3b and lateral occipital cortex (LOC)), with no clear preference for
predicting v4 responses, which got predicted by all layers with equivalent accuracy. Overall,
early layers correlate to early visual areas, while top layers correlate more with higher visual
areas. The correspondence of intermediate levels however is not clear.

A large-scale study comparing CNNs, humans and monkeys was done by Rajalingham et al
(2018). They were put perform the “same” visual recognition task, over the same dataset. Of
course, the equivalence of the tasks between animals and CNNs is debatable, but in this case
it simply meant that the network had to classify the same stimuli images presented to human
and monkey subjects. Beyond global accuracy metrics, they have also observed accurate
prediction of confusion patterns — at object-level — could be made by several state-of-the-art
image classiﬁcation CNNs (Krizhevsky et al, 2012; Zeiler and Fergus, 2014; Szegedy et al,
2015; Simonyan and Zisserman, 2015; Szegedy et al, 2016a; He et al, 2016a). However, when
examining the discrimination performance on individual images, models were signiﬁcantly

41

2. CNNs and visual system modeling

2.5 Discussion

non-predictive of primate behavior, showing that current CNN models do not fully account
for behavioral patterns of primates. The performed task consisted in binary discrimination
after brief presentation (100ms) of a synthetic naturalistic image. Synthetic images were used
to produce controlled multiple view points of 3D objects laid over an uncorrelated realistic
background (avoiding classiﬁcation by covariant background, common on natural images).
In a follow up eﬀort to extensively and systematically benchmark how closely diﬀerent
models explain neuronal data, Schrimpf et al (2018) proposed Brain-score: an ensemble of
both neural and behavioral benchmarks to score how similar an a artiﬁcial neural network
(ANN) is to brain-like mechanisms of object recognition. ANNs with higher performance
on ImageNet tend to have higher functional similarity to the ventral stream, scoring high on
predicting V4, IT and behavioral data. However for the highest performing models (over 70%
top-1 accuracy), this correlation is weaker and the variability between models is non-trivial,
leading to reject the hypothesis of any direct correlation (and potential causality) between
good ImageNet performance and high predictivity of brain activity. Moreover, considerable
variability in activity (both neural and behavioral) remains unpredicted by any models.
From the multiple models evaluated up to now, the top-3 brain-like models are the deep
shortcut architectures DenseNet-169 (Huang et al, 2017) and ResNet-101 (He et al, 2016a),
and also the shallower and more closely bio-inspired Cornet-S (Kubilius et al, 2018)). The
project has an associated updatable platform for scoring and comparing models, released
under brain-score.org, where both ANN models and neuronal or behavioral data can
be submitted to augment the benchmark.

Overall, many comparisons have been made, revealing links between natural and artiﬁcial
representations at diﬀerent levels. It is worth noticing that feedforward CNNs have not
provided accurate models of ventral neuronal activity when trained under easier conditions or
on unsupervised tasks (Nayebi et al, 2018; Hong et al, 2016; Khaligh-Razavi and Kriegeskorte,
2014, more on section 2.5.1). This indicates current models need a suﬃciently challenging task
and/or supervision in order to learn representations that correlate with those along the ventral
stream. Moreover, while low and top levels alone present clearer correlations to V1 and IT
cortices, intermediate layers and mid-level areas do not correlate as clearly. Diﬀerences are in
anyway expected, given that many elements of visual processing, including the participation
of extra-cortical areas, are not at all modeled in these CNN architectures.

2.5.2 Main differences between biology and basic feedforward CNNs
The current understanding of the visual system goes well beyond the feed forwards fast
ventral stream recognition. Notably neglected in most deep learning literature are the roles of
extra-cortical structures and recurrent mechanisms, such as:

(cid:73) Advanced processing and encoding done in retina and thalamic structures (LGN and

Pulvinar);

42

2. CNNs and visual system modeling

2.5 Discussion

(cid:73) Interaction between dorsal and ventral streams — thus between recognition and local-

ization;

(cid:73) The role of recurrent processing and feedback connections.

These three topics are brieﬂy discussed in the next few sections. Among these, the incor-
poration of recurrent processing is occasionally done when dealing with videos — that is,
sequential images. Actually, beyond sequential treatment, recurrent processing has other
functions related to a more reﬁned treatment of a visual scene, functions which are starting to
get more attention from the DNN community, as reviewed later in chapter 4. The other two
topics however remain largely unexplored together with CNN models in image recognition.

2.5.2.1 Processing in retina and LGN

Standard CNN models take as input a raw pixel-based image representation. Taking them
as a model of biological vision carries an implicit assumption that luminous intensities are
directly processed by the visual cortex without any pre-processing or encoding whatsoever.
Of course this is an oversimpliﬁcation that portrays as irrelevant any computations performed
by pre-cortical areas. A more thorough study of the role of retinal and thalamic structures in
visual processing makes clear their participation is not to be ignored.

Although often depicted as a passive sensor, the retina has a much more complex structure
and function. Several cortex-like computations have been identiﬁed in the retina of several
vertebrate species (see e.g. Kastner and Baccus (2013) for a review). In mammals, retina is
formed by ﬁve layers of cells that form a complex recurrent network (with both feedback and
lateral connections). It acts as a spatio-temporal encoder of the luminous stimuli, producing an
adaptive, sparse, over-complete and temporally precise representation (Gollisch and Meister,
2010).

In higher mammals, each point in the visual ﬁeld is sampled by about 20 diﬀerent ganglion
cells, with irregular receptive ﬁelds and varying spatio-temporal selectivity, thus outputting a
variety of basic visual features (Masland, 2001). Retinal ganglion cells are capable of encoding
complex features such as basic shapes (static or moving), also predicting changes in the
perceived visual ﬁeld and dynamically self-adapting to such temporal changes.

Overall, instead of providing pure luminance information, as does a camera sensor, the
retina mostly encodes changes in the perceived environment, with lower activity when staring
a static scene. When recording a video, a retina-like sensor would already output a spatially
compressed stream, instead of a simple frame sequence. As detailed in Gollisch and Meister
(2010) this corresponds to a “shallow” spatio-temporal processing (as modeled in Teftef
et al (2013) for instance) that computes image contrast and temporal changes. Moreover,
non-standard retinal cells also react to particular visual events having a characteristic spatio-
temporal signature, also being involved in motion anticipation Berry et al (1999).

43

2. CNNs and visual system modeling

2.5 Discussion

Similarly, there is evidence that thalamic participation in the visual process goes beyond
being a simple relay between retina and the visual cortex, implementing a layer of tempo-
ral compression on top of the retinal spatial compression. Pattern motion selectivity and
center-surround receptive ﬁelds have been identiﬁed in cat’s pulvinar and monkey’s LGN,
respectively. Particularly the latter is under control of feedback information coming from the
cortex, an example of top-down modulation returning to inﬂuence an early stage of vision
(Medathati et al, 2016). Furthermore, this feedback to the thalamus completes a recurrent
processing loop involved in detecting visual events and selecting visual targets. A more sophis-
ticated modeling of the thalamic participation in vision hs been done by Carvajal et al (2013),
who has modeled the thalamus as a distributed computational hub aggregating processing
results from cortical and sub-cortical structures (such as the superior colliculus).

2.5.2.2 Recurrent processing

Few models of object recognition include recurrent processing, even though it is eﬀective
in integrating information over large portions of the visual ﬁeld. Recurrent processing allows
top-down propagation of attentional modulation, contextual cues and other prior knowledge,
integrating with low-level bottom-up information and aﬀecting our ﬁnal perception, beyond
the ﬁrst 100 ms (see Lamme et al, 1998, for a review).

This top-down modulation seems to play a relevant role in dealing with cluttered scenes,
partial occlusion and grouping parts of objects, for example, which are relevant for more
complex tasks such as semantic scene segmentation and object tracking (Herzog and Clarke,
2014; Medathati et al, 2016).

The ability to group forms and contours so as to segment a scene to its composing objects
makes use of recurrent processing. Even though contrast and contour detection happens
quickly at V1 and V2 areas, recognizing segments relevant to a speciﬁc task happens after a
temporal delay involving feedback and lateral connections (Medathati et al, 2016).

When modeling the object recognition stream as feedforward pooling-based pipeline,
detailed information is lost at every pooling stage. In this model, for a target object, at every
stage only nearby clutter should harm recognition, and the more clutter the worse it should
be. However some contradicting experimental evidence has been observed (e.g. Herzog
and Clarke (2014)). In fact, even for a very basic recognition task, demanding only edge
and direction discrimination (processed at V1 cortex), nearby distracting shapes can aﬀect
recognition in manners not predicted by the pooling model. For instance, adding more
distractors may help performance (instead of hurting), while a rotation applied to the same
distractors can degrade performance.

This suggests a more global processing of visual information (obtained at higher areas of
the visual pipeline) can inﬂuence very low-level processing (at the level of V1), thus pointing
to the action of feedback connections. Additionally, other experiments observed signiﬁcant

44

2. CNNs and visual system modeling

2.6 Conclusion

inﬂuence of clutter in low-level processing only for exposition times higher than 160ms, but
no eﬀect below 120ms, arguing for the action of feedback connections in the extra exposition
time (Herzog and Clarke, 2014).

2.5.2.3 Interaction between dorsal and ventral streams

The classical view of ventral and dorsal streams as functionally independent and distinct,
as interesting as it may be as a global ﬁrst view of the visual system, is clearly over-simpliﬁed.
Not only the are not independent, they also are not the only processing pipelines int he
visual system. As exempliﬁed below, there are multiple communications between these two
pathways, integrating diﬀerent types of features at diﬀerent stages (Perry and Fallah, 2014).
Additionally, at a lower level, there are cell types other than magno and parvo cells, that
constitute other processing streams (Casagrande, 1994), all interacting among themselves.

Following the anatomical hierarchy, interactions between the magno and parvo pathways
can be observed as early as in V1 cortex, where their signals get mixed and propagated to
V2 and V3 areas. An inﬂuence of magnocellular signals over the ventral pathway could for
instance explain why fast and coarse signals tune activity in the temporal cortex, inﬂuencing
face recognition mechanisms (Giese and Poggio, 2003). At mid-level vision, exchange of color
and motion information takes place between areas V4 (traditionally attributed to the ventral
stream) and V5/MT (traditionally attributed to the dorsal stream). Interactions have also
been observed as a strong inﬂuence of form signals – supposedly processed by the ventral
stream – onto local motions analysis and motion integration – which would be the work
of the dorsal stream. Such interactions occur at multiple stages in the anatomical hierarchy,
playing an important role in resolving motion ambiguities, interpolating occluded information,
segmenting the optical ﬂow or in recovering an object’s 3D structure (Medathati et al, 2016).

2.6 Conclusion

Our understanding of brain function and particularly of the visual system has evolved
signiﬁcantly over the years. Ever since Hubel and Wiesel (1959), there has been a great
accumulation of experimental evidence, together with theoretical modeling and descriptive
eﬀorts, that have led to the current state of knowledge in the ﬁeld. Hypothesis have been
made at multiple levels — single neurons, populations, cortical and extra-cortical regions —
and put to the test of experimental observations. While some mechanisms got to be pretty
well-described — like the tuning of V1 and V2 neurons to particular low level visual cues —
some other still long for a detailed understanding — such as the role of some inter-region
connections or of extra-cortical regions involved in the visual.

Some architectural patterns and functional mechanisms have indeed worked as inspiration
in the ﬁrst CNN designs — namely the locally-connective ﬁelds and the hierarchical process-

45

2. CNNs and visual system modeling

2.6 Conclusion

ing. Their level of bio-plausibility remains though rather shallow, with purely feedforward
architectures dominating among the most used models, as reviewed in the next chapter 3.
Knowledge in the ﬁeld has advanced greatly since the early 90s, with novel principles of
recurrent treatment, attention modulation and long-range interactions having been observed
as crucial for more reﬁned visual treatments. The adoption of these new mechanisms by
the DNN community has been done occasionally but is not widespread, as surveyed in the
following chapter 4 . The study of these novel architectures may be able to inform neuro-
science about the pertinence and eﬀectiveness of these principles in accomplishing a visual
recognition task, hopefully shedding light on computational mechanisms previously ignored
or underestimated by the neuroscience community.

Being a descriptive science, results may occasionally contradict theoretical predictions or
reveal unexpected mechanisms, leading to reformulate the state of what is currently known.
One must keep this epistemic status of neuroscientiﬁc principles in mind, being open to
their eventual reconsideration or even complete dismissal. Attempts at incorporating such
principles to machine learning models should be aware of the context from which these
principles have emerged and of the hypothesis considered in their formulation. On one hand,
a naive accumulation of neuro-inspired principles may result in incompatible theories being
brought into the same model, or simply be unhelpful as the operation conditions for a given
mechanism may not be veriﬁed in the application domain. On the other hand, bringing in the
right mechanism can account for a signiﬁcant improvement, or even bring on novel hypothesis
to the neuroscience modeling.

Reciprocally, besides modeling brain function, deep learning research could also take inspi-
ration from neuroscientiﬁc methodology. While we don’t have detailed theoretical descriptions
of DCNNs “behavior”, taking a descriptive approach, similar to that of neuroscience, is a
potential path towards building knowledge about the higher-level functioning of these models.
Overall, the well-informed interaction between the neuro and computer vision communities
has the potential of being fruitful for both domains.

46

Chapter 3

Feedforward CNN architectures for object recognition

3.1 Introduction

Even though feedforward architectures may seem limited in variability at a ﬁrst glance, the
last few years have seen a variety of architectural principles emerge around the basic single
pipeline architecture. Multiple parallel pathways (section 3.3), shortcuts or skip-connections
(section 3.3.2) and bottleneck structures have been proposed by diﬀerent works, bringing
improvements in accuracy, computational burden or other qualitative aspects of a classiﬁcation
model.

Given the centrality of the subject of object recognition to this thesis, it is important to
review the main modern CNN architectures targeted at this aim. The ﬁeld has been and
continues to move fast, with almost simultaneous works sharing common inﬂuences and also
directly inﬂuencing each other, as depicted by the diagram in ﬁg. 3.2. The next sections lay
down a portrait of the current state-of-the-art, focusing on feedforward architectures applied
to the task of image classiﬁcation. We propose to organize these propositions according to their
usage of parallel proceesing patways within the architecture, as schematized in ﬁg. 3.1. While
other object recognition tasks may be mentioned occasionally, architectures dedicated to them
are not of central concern. The goal is not to make an extensive list of architectures, rather
focusing on the general principles that got widespread, and the works that have proposed or
popularized them.

Figure 3.1 Proposed taxonomy of feedforward CNN architectures. Each family is represented by an archetypal
small module of 3-4 layers. Top and bottom circles stand for module’s input and output, respectively.

47

Single pathwayParallel pathwaysParallel pathways: forward shortcutsIdentity shortcutsGated shortcutsDensely connected shortcutsIntra-layerrecurrenceHybrid recurrentRecurrent with feedbackInter-layer feedbackFeedforward connectionsRecurrent/feedback connections3. Feedforward CNN architectures

3.1 Introduction

Figure 3.2 Diagram representing an “inﬂuence genealogy” of some important CNN models for computer vision.
Dates correspond to arXiv ﬁrst release or date of publication, whichever is the earliest.

48

SegmentationObj. localizationor detectionImage classificationLeNet-5LeCun et al.1998AlexnetKrizhevsky et al.2012VGGSymonian & ZissermanSep 2014ZF netZeiler & FergusNov 2013ResNetsHe et al.Dec 2015OverfeatSermanet et al.Dec 2013GoogLeNetSzegedy et al.Sep 2014FullyCNNShelhamer et al.Nov 2014Inception (v4)Inception-ResNetSzegedy et al.Feb 2016XceptionF. CholletOct 2016Wide ResNetsZagoruyko & KomodakisMay 2016DeconvNetNoh et al.May 2015SegNetBadrina-rayananet alNov 2015DeepLab ASPP(DeepLab+ResNet)Chen et al.Jun 2016PSP netZhao et al.Dez 2016FullResResNetsPohlenNov 2016DenseNetsHuang et al.Aug 2016R-CNNGirshick et al.Nov 2013Fast R-CNNGirshick et al.Apr 2015Mask R-CNNHe et al.Mar 2017MobileNetHoward et al.Apr 2017Separableconv.Sifre, 2014SqueezeNetHoward et al.Feb 2016Highway NetsSrivastava et al.May 2015U-netRonne-begeret al.May 2015DeepLab(Conv. à trous)Chen et al.Dec 2014DilatedConvNetYu & ColtunNov 2015Inception (v3)Szegedy et al.Dez 20153. Feedforward CNN architectures

3.2 Single pathway models

3.2 Single pathway models

The ﬁrst major CNN architectures to achieve success in ImageNet classiﬁcation were a
single-pathway stack of convolutions, pooling and fully connected layers. Even though more
recent architectures have better accuracy and/or are more economic in terms of parameter
count, these ﬁrst models have the pioneering merit, having set de facto standards for CNN
design and training that remain relevant today. Besides, most of these models have been used
as a starting point when attempting to tackle new practical problems with CNNs, and are
still of interest for those trying to experimentally study and understand the computational
“behavior” of a basic but functional CNN.

3.2.1 First modern architectures

3.2.1.1 Alexnet

Alexnet, the ﬁrst DCNN model to win the ImageNet challenge, in 2012, achieved Top-5
error of 18.2% and top-1 error of 40.7% (while the best previous approaches achieved next
to 26% and 46%, respectively) (Krizhevsky et al, 2012). Even lower scores were achieved
through network ensembles. Developed mainly by Alex Krizhevsky, a student in the group
of G. Hinton, this work brought up many technical innovations that continued to be used
by future architectures, including the use of ReLU activations for faster learning, and both
data augmentation and dropout regularization as essential to avoid overﬁtting. They also
observed slight reductions in error rates by using a local normalization and overlapping
pooling windows.

Foreseeing future practices, this work also tried pre-training the networks on previous
versions of the ImageNet dataset to achieve better results. Nowadays using ImageNet pre-
trained CNNs is a standard starting point to tackle most computer vision (CV) problems.
Training used stochastic gradient descent (SGD) with momentum and weight decay, the
latter acting not only as a regularizer but also reducing the training error (thus improving
optimization). A learning rate reduction policy was also used (based on plateaus of the
validation error). The model with 60 million parameters needed to be split up in two consumer
GPUs for 5 to 6 days, training for 90 epochs. Most of these training strategies remained on the
models that followed. Overall, this work demonstrated the power of deep networks, settling
that a highly over-parameterized deep CNN model, given enough data and clever engineering,
can generalize, and that even better than traditional CV approaches.

49

3. Feedforward CNN architectures

3.2 Single pathway models

3.2.1.2 Zeiler and Fergus

Following Alexnet, many diﬀerent research groups took the CNN path when proposing
solutions to the ImageNet challenge. The winner of the classiﬁcation challenge, Clarifai, was
designed based on work by Zeiler and Fergus (2014), who proposed a novel method to
allow visualization of patterns that maximize network activations. They coupled their CNN
classiﬁer to an auxiliary feature decoder architecture that tries to reverse the transformations
induced by the main network, by applying “approximate inverse” transforms in the opposite
order. In this way, the decoder net is a mirrored version of the main one, in which:

1. Max pooling is replaced by “unpooling”, which up-samples the feature map (with zero
padding). The location of the activation is chosen to be the same that was chosen at the
corresponding pooling stage of the main network;

2. Convolutions are replaced by “deconvolutions” which are actually just convolutions

with transposed ﬁlters;

3. ReLU is not replaced, to keep feature maps non-negative.

The entire model is trained on ImageNet classiﬁcation, obtaining at the same time a classiﬁer
net and a feature decoder net. The visualized patterns are speciﬁc to each input image and
represent parts of the image relevant to the activation of each feature map.

Provided this diagnostic tool, several experiments were performed, including invariance to
translation, rotation and scale, sensitivity to partial occlusion of objects, and reusing features
for other datasets. Overall, they observed that features were not random but presented many
desirable aspects, which increase with network depth, such as compositionality, robustness
to small transformations (except rotations) and class predictability. Early layers converged
faster and detected basic patterns, while deeper layers took longer to converge and could
detect more abstract patterns such as wheels, eyes or faces. Occlusion studies allowed to
verify for some images that semantically meaningful image parts were indeed implicated in
classiﬁcation (although no misclassiﬁcation example was discussed). Ablation studies and
testing diﬀerent model sizes led them to argue for the importance of the deep hierarchy as
opposed to any single layer and indicated points in the network that could beneﬁt from more
parameters without incurring in overﬁtting (namely middle convolutional layers instead of
top fully connected layers). Finally, their network design has proﬁted from the empirical
knowledge gathered from this exploratory study.

The proposed architecture in itself is not extremely innovative (5 convolution layers + 2
fully connected), but their design methodology is remarkable for attempting to understand
more about the networks functioning before proposing changes. For its new method of fea-
ture visualization, the work has also settled an important milestone for interpretability in
DCNNs, even though this aspect is not strongly explored in the paper: visualizations were
not explicitly used to explain predictions and no incorrect predictions were analyzed. Fur-
thermore, their visualization method has inspired follow-up works in semantic segmentation,

50

3. Feedforward CNN architectures

3.2 Single pathway models

where convolution-deconvolution architectures such as U-Net (Ronneberger et al, 2015) or
SegNet(Badrinarayanan et al, 2017) became common practice.

3.2.1.3 OverFeat

The winner of the Imagenet localization challenge in 2013, OverFeat, besides having
advanced a bit lower in the error rates (around 39% top-1 and 17% top-5), proposed an
integrated approach to solve object classiﬁcation, localization and detection all with the same
network (Sermanet et al, 2013). Overall there is not much diﬀerence in the architecture: both
AlexNet and OverFeat are constituted of 5 convolutional layers and 2 regular fully connected
layers on the top (plus the output classiﬁcation layer), with max-pooling after the 1st, 2nd
and 4th layers. Local normalization and overlapping pooling were dropped (augmenting the
number of parameters to 144 million), and stride on ﬁrst convolution layers reduced.

The main innovation is in the inference procedure. They process the input image at multiple
scales to obtain multiple class distribution vectors combined by averaging. For localization, the
output classiﬁcation layer gives place to a set of regressors (one for each class), trained over
features from the last convolutional layer of the network to predict bounding box coordinates
for annotated objects. Then both regressor and classiﬁer are used across all locations and
scales. Class predictions are grouped within each predicted bounding box to provide both a
class and the conﬁdence of the classiﬁcation, and bounding boxes are iteratively aggregated
to provide a ﬁnal prediction. A similar scheme is adopted for object detection, except that
an extra “background” class is used to label regions where no object has been detected, and
bounding box regressors are not used.

Although more eﬃcient object detectors followed (for instance Region-proposing CNNs
(Girshick et al, 2014)), OverFeat architecture has remained relevant particularly because it
has been the ﬁrst major model to be released together with its weights, allowing to use it as a
feature extractor. Using pre-trained models of-the-shelf has become a standard procedure
ever since, with CNN features often providing a strong baseline result for image classiﬁcation
(Razavian et al, 2014). Besides its use as a ﬁxed feature extractor, OverFeat has also served
as base architecture on multiple works, such as image classiﬁcation and detection on MS-
COCO dataset, semantic segmentation of outdoor scenes (Pinheiro and Collobert, 2015), and
multiple object detection inside a storage shelf or bin (Schwarz et al, 2017)

3.2.1.4 VGG

Oxford’s Visual Geometry Group (VGG) innovated in 2014 proposing a deeper family
of architectures (9 to 16 convolutional layers + 2 fully connected + output layer), but using
smaller ﬁlters — 3x3 instead of 7x7 and 5x5 — to keep the total number of parameters
manageable (between 133 and 144 million depending on the net’s depth) (Simonyan and

51

3. Feedforward CNN architectures

3.3 Parallel pathway archs

Zisserman, 2015). The intuition behind stacking 3x3 ﬁlters is that a larger receptive ﬁeld can be
achieved. Indeed, as far as receptive ﬁeld size is concerned, two (three) 3x3 convolutions are
equivalent to a 5x5 (7x7) convolution, but with less parameters. Local response normalization
was also dropped, as it demanded to much computations for no gain in performance. Their
best single nets achieved 24% top-1 and 7% top-5 error rates on ImageNet 2014 classiﬁcation
task.

This is one of the ﬁrst works that propose successful deeper networks together with
a simple architectural principle, exploring multiple versions with diﬀerent depths : VGG-
11,13,16 and 19 layers. This architecture has been reused and adapted by multiple works
(eg.Shelhamer et al (2017) or Badrinarayanan et al (2017)) to diﬀerent applications including
semantic segmentation, and it became a popular option of pre-trained architecture used for
transfer learning.

3.2.2 Parameter-saving architectures

Besides these pioneer architectures, some others are worth noticing due to their particular
interest in reaching good accuracy under less computational resources. Smaller models can
be trained on less powerful hardware and need less memory. When deployed, a smaller
trained network demands less bandwidth to be distributed/downloaded and is more suitable
to be run in embedded devices with limited resources. A ﬁrst example on this direction is
SqueezeNet, an architecture reaching AlexNet’s performance under 50 times less parameters
(Iandola et al, 2016). On one hand, their main strategies are to reduce the size of most ﬁlters
(3x3 to 1x1) while decreasing the number of input channels for those layers which remain 3x3
convolutions. On the other hand, down-sampling is delayed to upper layers, so that feature
maps do not get too small to fast, severely hindering accuracy. Another small model family is
MobileNet (Howard et al, 2017). While SqueezeNet focuses simply on model size, MobileNet
is also concerned with inference speed. Their main strategy to reduce computations is the use
of channel-wise (or depth-wise) separable convolutions, while two other relevant aspects are
left as hyperparameters: a width multiplier — controlling the number of channels in each
layer — and a resolution multiplier — to act on input image resolution. Together, all these
allow to provide options for diﬀerent accuracy vs. computational burden trade-oﬀs, suiting
diﬀerent budgets.

3.3 Parallel pathway archs

Parallel to the development of single path DCNNs, other groups explored the eﬀect of
adding parallel paths to basic architectures, in simple or complex ways. One very simple way
of implementing multiple pathways is to jointly train multiple nets and using their average
prediction as output, an approach that has been tested by Ciresan et al (2012). Although simple

52

3. Feedforward CNN architectures

3.3 Parallel pathway archs

to explain, this approach produces a very large model highly demanding on computational
resources. There are more subtle ways of adding parallelism to the computations performed
in CNNs without incurring in such extreme burden, besides providing interesting insights
into the eﬀectiveness of deep networks. Diﬀerent propositions of parallel architectures have
in common that they allowed training of deeper networks. Some approaches allow reduction
of parameters, others focus on memory usage or number of computations. In what follows,
the main tendencies of parallel architectures together with their main representative works
are reviewed. When suitable, further discussion is provided on the rationale behind certain
design choices and why they were successful in practice and/or widely adopted by the deep
learning community.

3.3.1 Sequence of parallel blocks: the Inception family

This family of models is characterized by a succession of parallel blocks — inception
modules — combined by concatenation of the feature maps (Szegedy et al, 2015). The rationale
behind the inception modules is that the scale of features detected on images can vary widely
and thus ﬁxing the size of the kernels (an thus the receptive ﬁelds) is insuﬃcient and arbitrary.
The solution proposed in the inception block is to have a multitude of kernel sizes applied in
parallel, creating multiple paths.

Before or after each path, 1x1 convolutional layers reduce the computational burden via
dimensionality reduction, allowing the stacking of more blocks without achieving a too large
model to compute or too many parameters. It is worth noticing that a convolution by a 1x1
ﬁlter is equivalent to a linear combination of input feature maps/channels, without touching
the spatial dimensions, eﬀectively decoupling spatial ﬁltering and channel-wise ﬁltering
(Chollet, 2016). Therefore they can be seen as a convolutional implementation of a channel-
wise fully-connected layer, with each input channel connected to each output channel through
a single weight. Finally, fully connected layers give place to a simple global average pooling
prior to the output layer, cutting even further down on the parameter count. For instance, the
ﬁrst inception model, known as GoogleNet, has 22 layers and yet 9x fewer parameters than
AlexNet (7 million versus 60 million (Szegedy et al, 2016b)), while being more accurate. It
has also less computations than its contemporary the VGG model — 1.5 billion ﬂops (Szegedy
et al, 2015) versus 19.6 billion FLOPS (He et al, 2016a) — although the latter has the advantage
of lower resolution loss and better single net accuracy.

In the interest of further reducing computations and increasing depth, two principles were
adopted for Inception V2 and V3: replacing 5×5 by two 3×3 convolutions (equivalent receptive
ﬁeld as discussed for VGG net) and replacing n × n convolutions by 1xn and nx1 convolutions
(implementing a factorized ﬁlter with 2 vectors instead of single ﬁlter matrix). Furthermore,
instead of simply stacking these two asymmetric convolutions, each ﬁlter-vector is applied
in parallel, to avoid an exaggerate dimension reduction. For inception V3 in particular, they

53

3. Feedforward CNN architectures

3.3 Parallel pathway archs

added another path with factorized 7x7 convolutions, amounting to a 42-layer model with
only 2.5 times more computations than 23-layer Inception V1. The third version was trained
on 50 GPU in parallel for 100 epochs, being one of the earliest to beneﬁt from distributed
training powered by the Tensorﬂow framework (Abadi et al, 2016).

3.3.1.1 Role of auxiliary losses

As deeper networks are more prone to suﬀer from vanishing gradients during optimization,
they propose using auxiliary losses trained on outputs obtained from 2 intermediate points
of the network. Each loss is a standard classiﬁcation cross-entropy loss, but computed over
predictions obtained from diﬀerent network paths. The total loss is then a weighted sum of
the main loss (from the main output) and auxiliary losses (from the auxiliary paths).

These auxiliary losses are supposed to help making features of earlier layers more discrim-
inative, help gradient backpropagation and act as a regularizer. However, even if this auxiliary
loss strategy has been kept throughout the evolution of the basic inception architecture, the
authors conjecture that they act more as a regularizer, as experimental evidence — auxiliary
branches could be removed without much aﬀecting performances or convergence — question
their eﬀective participation in the tuning of lower layers (Szegedy et al, 2016b).

3.3.1.2 Variations and derivations

Further work on this family of architectures intended to simplify the design, making the
inception blocks more uniform (Inception V4), also exploring the incorporation of residual
connections (Inception ResNet) (Szegedy et al, 2016a). They observed increased training
speed with residual connections, and a slightly improved accuracy when compared to simi-
larly expensive Inception models (in number of computations, Inception V3 comparable to
Inception ResNet V1 and Inception V4 comparable to Inception ResNet v2). Their results
point towards the use of residual connections having a complementary eﬀect to that of the
inception blocks.

An interesting variation proposed by Chollet (2016), the Xception model seeks to make
more eﬀective use of the 22 million parameters of the Inception V3 model, while achieving
better accuracy. The hypothesis is that channel and spatial processing can be completely
decoupled, being more eﬃcient to perform depth-wise separable convolutions — spatial
convolutions applied independently to each channel. With nearly the same number of param-
eters, the improvement observed over Inception V3 is attributed to a supposed increase in
the eﬃcient use of the parameters. Furthermore, Xception converged faster on both datasets
tested. The inclusion of residual connections improves validation accuracy signiﬁcantly.

54

3. Feedforward CNN architectures

3.3 Parallel pathway archs

3.3.2 Architectures featuring forward shortcuts

Forward shortcuts or skip connections are bottom-up links that skip one or more layers.
The output from the source layer will then be combined with the target layer, either by feature
map concatenation or by some arithmetical operation such as summation. An early usage
of skip connections is presented in an architecture for semantic segmentation by Shelhamer
et al (2017), who use them to gather information from larger resolution feature maps from
earlier layers (before pooling operations). Later, they were used mainly to allow training of
very deep networks. The following paragraphs discuss these architectures, their common and
innovative aspects, trying to summarize current knowledge on the reason for their success.
Newer models generalizing the shortcuts idea in diﬀerent manners are also reviewed.

3.3.2.1 Residual connections

On deeper nets, training accuracy could be at least as good as that of a shallower coun-
terpart. The intuition behind this claim is simple: by construction, a shallower model could
be implemented by the deeper one by setting some of its layers to the identity function. So
there has to be at least an equivalent solution with a deeper network, but optimization is
not being able to ﬁnd it. The shortcuts in ResNet (short for residual networks) come then
as a mean to facilitate the implementation of these identity functions (He et al, 2016a). The
original motivation stated in the paper was to deal with the degradation that intervenes
when stacking too many layers. Processing of a given layer can be completely skipped by the
identity shortcut path. Actually, since the identity shortcut output is summed to the output of
the skipped layers, a residual mapping is achieved. That is, for a given input x, the function
implemented by the residual block — the output of layers and shortcut — will be H(x), where
F (x) := H(x) − x is a residual function implemented by the stacked layers bypassed by the
shortcut.

A later reformulation by He et al (2016b) pre-pends ReLU and BN operations before the
convolution layers inside the residual function, so that the new pre-activated residual network
can be given by the recurrence relation

which recursively yields that

xl+1 = xl = F (xl, Wl),

xL = xl +

L−1
(cid:88)

i

F (xi, Wi),

(3.1)

(3.2)

for any L-th layer and L > l. By analyzing the error gradient expression for this network (see
discussion by He et al (2016b)), one can observe that it decomposes into two additive terms:
one linked to the weights of previous layers and one independent of them, directly linked to

55

3. Feedforward CNN architectures

3.3 Parallel pathway archs

a given xL, eﬀectively acting as a reverse gradient shortcut. This analysis supports the claim
that shortcuts help gradient ﬂow during optimization, since they ensure the gradient of a
layer does not vanish even if weights are really small.

a. Variations and derivations

Residual Networks have achieved outstanding record breaking results on image recogni-
tion, object localization and detection on benchmarks such as ImageNet (winner of the 2015
classiﬁcation challenge), MS COCO, CIFAR-10 and 100 (He et al, 2016a,b). Their success led
residual connections to become popular architectural feature to experiment on any model
family. For instance, SqueezeNet’s small but eﬀective architecture can achieve even better
accuracy if residual connections are added (Iandola et al, 2016). Residual connections also
help Inception-type architectures, as demonstrated by Szegedy et al (2016a), and have also
been experimented with on generative adversarial networks (e.g. Mehrotra and Dukkipati
(2017)).

On another note, many direct variations of the initial model were proposed in follow-up
works. A simple variation proposed by Shen et al (2016) adds a multiplicative weight λl to
the residual F (xl, Wl) that is initialized to zero, thus inducing all residuals to eﬀectively start
as zero. This variant reduces overﬁtting on very deep models on CIFAR10, with maximum
test accuracy achieved by a 1192 layer model (versus a 112 layer model, for an equivalent
plain ResNet).

In ResNext (Xie et al, 2017a), another deriving model, channels are sliced into groups
before applying separated convolutions for each of them. The trick reduces parameters and
computations allowing to compute more ﬁlters (more channels on each layer) at the same
parameter and computational budget. (if you split channels in b groups, you have w\*h\*in/b
\*out/b \*b parameters instead of w\*h\*in\*out). With the increased number of ﬁlters, it works a
bit better than plain ResNet.

3.3.2.2 Gated shortcuts

Through a slightly diﬀerent reasoning, Srivastava et al (2015) concurrently proposed a
similar shortcut architecture: highway networks. Also motivated by the diﬃculties of training
very deep networks, they propose a principle inspired from an unrolled LSTM, adding gated
connections towards the following layers. For a given input x, the output of a (coupled)
highway block is

y = H(x, WH) · T (x, WT ) + x · (1 − T (x, WT )),

where the transformation gate T (x, WT ) learns to regulate the information ﬂow between layer
(ﬁrst term) and shortcut(second term).

Both shortcut approaches achieved successful training by SGD of extremely deep networks
— 1001 layers for ResNet (on ImageNet) and 900 for Highway nets (on MNIST and CIFAR-10

56

3. Feedforward CNN architectures

3.3 Parallel pathway archs

and 100). The hypothesis that very deep networks might work better by learning identity
functions on some layers is reinforced through experimental observations in Srivastava et al
(2015), where activation’s throughout highway blocks often remain the same for a signiﬁcant
number of blocks.

Highway networks have worked better than plain ResNets on some natural language
processing tasks. Greﬀ et al (2016) propose a comparison between parameter matched versions
of ResNet and Highway nets on a language modeling task. They observe that the learned
gating is crucial for improving performance on the task, and hypothesize that in tasks where
partial feature adaptive replacement or transformation is necessary, highway networks have
an advantage over plain residual shortcuts.

3.3.2.3 Multiple forward shortcuts

Many works taking inspiration from ResNets generalized the residual shortcut idea to

some form of multiple forward shortcut architecture.

a. Multiple paths by self-similarity

Larsson et al (2016) proposed a multi-path architecture based on the repetition of a simple
expansion rule. This generates FractalNets, an architecture with large nominal depth but still
having shorter paths to ease gradient ﬂow. This architectural principle also allows training of
very deep networks (up to 160), and works better under drop-path regularization – a version
of dropout proposed by the authors to avoid co-adaptation of sub-paths so that every path
learns to make reliable predictions. Their experiments observed that although the fractal
structure helps training, in inference time the deepest sub-net can be used alone, with little
eﬀect in accuracy. Overall, this model could be an interesting alternative to learn a complex
model in training time that automatically provides a smaller and faster version at inference
time, which could be useful for computationally restrained applications.

b. Multi-level ResNets

One line of thought consists in proposing some generalization of the forward shortcuts idea.
Initially some works added other level of shortcuts on top of the existing ones. Building on top
of the hypothesis that optimizing residual mappings is easier, Zhang et al (2016b) hypothesize
that a residual mapping of residual mappings is even easier. They design then a multilevel
model named ResNet of ResNets (RoR), constituted by adding another level of shortcuts every
2 residual blocks. Targ et al (2016) propose ResNet in ResNet (RiR), an architecture mixing
residual and conventional CNNs by having two pathways — one residual stream with identity
shortcuts and another transient stream without — that partially communicate inside each
block. This generalized residual block has suﬃcient expressive power to learn mixes between
plain CNNs and ResNets. Their RiR architecture consists then in replacing each convolutional

57

3. Feedforward CNN architectures

3.3 Parallel pathway archs

layers within a ResNet by one of such generalized residual blocks. Both approaches improve
ResNet test accuracy on CIFAR10 and 100 datasets, with an arguable upside for RoR since it
is simpler to implement, does not add to training time and achieves better results.

c. Generalized forward shortcuts

On a second moment, forward shortcuts were generalized to a more extreme extent, with
input connections coming from all preceding layers. A ﬁrst proposal in this direction was
DenseNet (Huang et al, 2017), a streamlined architecture of stacked dense blocks. These
blocks ar composed of multiple composite layers (BN - ReLU - 3x3 conv), featuring forward
shortcuts to all following composite layers inside the block. In this way, an L-layer block
has L(L+1)
shortcut connections. All incoming feature maps are combined by concatenation
(and not addition like in ResNets). This makes them more comparable to Inception networks,
that are similarly structured as a sequence of internally parallel blocks. 1x1 convolutions as
bottleneck layers between dense blocks to limit computational burden

2

One motivation behind this dense blocks is to exploit potential feature reuse from previous
layers. Indeed, analysis of the weights in a trained DenseNet indicate that deeper layers within
a dense block do reuse features from earlier layers. Another beneﬁt is to be more parameter
eﬃcient than plain ResNets. Experiments by Huang et al (2017) obtained models with less
parameters and less computations than ResNet for same error rate (observed on ImageNet and
CIFAR). For instance, a DenseNet-BC with 0.8M parameters achieves accuracy comparable to
pre-activated ResNet-1001 with 10.2M parameters.

DeludgeNet is a second proposal on the same line, generalizing forward shortcuts within
blocks that are stacked together (Kuen et al, 2016). Similarly to DenseNets, a block is formed
by multiple composite layers, each layer receiving input from all previous layers within a
block DeludgeNets use a pre-activated bottleneck composite layer (formed by 3xBN-ReLU-
Conv). Within this layer, 1x1 convolutions compress channels at the beginning and expand
at the end, reducing the computational burden of applying 3x3 convolutions directly on
many concatenated feature maps. Shortcut inputs go through 1x1 cross-layer depth-wise
convolutions prior to being concatenated and fed to the next composite layer. This operation
consists of a channel-separable convolution, that summarizes each channel dimension ci
from all previous layers l − 1, l − 2, . . . onto a single feature map, keeping the number of
channels constant for the next layer l (instead of having a growing number of channels as in a
DenseNet block). This should allow to save-up in the number of parameters, when compared
to DenseNets.

The architecture yielded better results on CIFAR 10/100 when compared to ResNets. Com-
parison to DenseNets is less evident, as models of similar parameter count have close results,
although DeludgeNets achieve so with less computations (GFLOPS). A less pronounced
improvement is also observed on ImageNet experiments. Comparing two models with similar
GFLOPs and performance on ImageNet, DelugeNet has more parameters than its DenseNet

58

3. Feedforward CNN architectures

3.4 Discussion

counterpart (no result of a DenseNet of similar parameter count is reported).

3.4 Discussion

3.4.1 Relation between forward shortcuts and recurrent networks
The success of shortcut architectures, in particular ResNets, led to further works exploring
and experimenting with their behavior under shuﬄing and removal of inner block layers
and even entire blocks (Veit et al, 2016). Surprisingly, a very limited eﬀect on accuracy is
observed when these networks are submitted to these “lesions”. A more pronounced drop
is observed for early layers or layers right after a change in dimensionality. At a ﬁrst glance,
these results challenge the hierarchical representational view of deep networks, with each
layer building up on and detecting more abstract features than the previous ones. Under this
hypothesis, shuﬄing the representational levels makes no sense and should severely degrade
performance (which has indeed been observed for the one-stream VGG-15 by Veit et al (2016),
in which layer removal could rise classiﬁcation error up to 90%). These observations led Veit
et al (2016) to postulate that ResNets work as an ensemble by averaging (exponentially) many
sub-networks, each only using a subset of all layers, thus justifying the robustness to layer
removal and shuﬄing.

Reconciling shortcut architectures and hierarchical representations, Greﬀ et al (2016)
propose to view them performing an unrolled iterative estimation. As discussed in their work,
these architectures can be seen as a simpliﬁed recurrent network (for ResNets) or an LSTM
(for Highway nets) “unrolled” over time. In each residual/highway block, the ﬁrst layer learns
a ﬁrst good initial estimate that is only reﬁned by subsequent layers. Therefore, all layers in a
block are working on the same level of abstraction, the same features. The transitions from
a set of blocks — a stage — of higher to another stage of lower dimensionality (through a
change in the number of feature maps) would also mean transitions of abstraction levels.
Under this view, it makes sense that layers within a block (except for the ﬁrst) can be removed
and interchanged (to some degree) with little impact on accuracy, since (1) they are merely
ﬁne-tuning the ﬁlters from previous layers and (2) they are working on the same reference
input towards a common output.

Foreseeing the utility of forward skip connections, Liang and Hu (2015) note that their
recurrent convolutional architecture when time-unfolded corresponds to a CNN with multiple
paths from input to output layer, and hypothesize it may facilitate learning. Analogously,
Liao and Poggio (2016) provide a similar perspective, under a bio-inspired framework. They
observe that a residual block with shared weights can be reformulated as a recurrent system.
They propose then a stacked recurrent model, with recurrent hidden layers modeling each
stage of the ventral cortical hierarchy, including identity shortcuts between cortical regions. The

59

3. Feedforward CNN architectures

3.4 Discussion

weight sharing condition seems not to hinder performance signiﬁcantly, as their experiments
obtained similar validation accuracy (on CIFAR-10) for both shared and un-shared weight
versions. This model will be discussed in more detail with other recurrent convolutional
models in chapter 4.

3.4.2 Attempts at understanding the success of residual shortcuts

While the intuition behind suing shortcuts seems reasonable on a ﬁrst look, it remains
important to try and understand from a theoretical point of view why and how residual
shortcuts help the training of very deep neural networks. Several works have taken steps
towards this goal, trying to formalize how the addition of shortcuts inﬂuences the optimization
landscape and how it aﬀects SGD-based training (e.g. Orhan and Pitkow, 2017; Philipp et al,
2018) One interesting discussion we will develop hereafter concerns attempts at understanding
which would be the optimal shortcut length in order to obtain the optimization beneﬁts of
these architectures.

Experimental observations by He et al (2016a) indicate that using shortcuts every 2
layers (2-shortcut) works better in practice than 1-shortcut or 3-shortcut networks. While this
empirical intuition is useful in practice, it remains important to understand from a theoretical
point of view whether (and why) 2-shortcut is indeed an optimal choice. Hardt and Ma (2016)
have demonstrated that loss landscape has no spurious local minima for arbitrarily deep linear
1-shortcut residual networks (given that all weight matrices have small Frobenius norms).
Apparently contradicting previous empirical results — 1-shortcuts did not ease training in
practice — actually this result simply exposes the fundamentally diﬀerent behavior of the
original non-linear shortcut-1 ResNet, indicating that studying it via a linear proxy may not
be suﬃcient to understand this phenomena.

Building up on this work, Li et al (2017) have demonstrated theoretical support fo this
empirical observation, this time including ReLU non-linearities. They analyzed the Hessian
matrix of a simpliﬁed ResNet (only standard fully-connected layers) of arbitrary depth, and
shortcut lengths. Both theoretical analysis by Hardt and Ma and experimental results by Li
et al indicate that as ResNets go deeper, weights tend to converge near zero during training,
motivating to analyze the Hessian matrix around this point (here noted H0)1.

They have reached the following conclusions:

(cid:73) For shortcut-1 networks, H0 has a block Toeplitz structure, which is known to have

exploding condition numbers2 for increasing network depth.

1In practice of course, since zero is a saddle point for this optimization problem, weights were initialized to

small random values around zero (Xavier initialization multiplied by 0.01)

2The condition number of a matrix A is given by: cond(A) = σmax
σmin

where σmax, σmin are the maximum and
minimum singular values of A. In case A is normal, i.e. AAT = AT A, this can be simpliﬁed to cond(A) = |λ(A)|max
|λ(A)|min
where |λ(A)|max , |λ(A)|min are the maximal and minimal eigenvalues of A in absolute value. (according to Li

60

3. Feedforward CNN architectures

3.4 Discussion

(cid:73) For shortcut-n networks, n ≥ 2, zero is a saddle point of order n − 1, with H0 having a

zero diagonal. In particular, for n ≥ 3, H0 is a zero matrix.

(cid:73) For the special shortcut-2 case, H0 presents a particular eigenvalue structure3 such that
condition numbers are independent of network depth. Thus, optimization (around zero)
should work similarly for either shallower or deeper shortcut-2 networks.

Large condition numbers can have a large impact on convergence of ﬁrst order methods,
justifying why shortcut-1 networks are no better than no-shortcut ones. Moreover, for shortcut-
2 networks, zero is a strict saddle point, which have been proven to be easy to escape from.
Together with depth independent condition numbers, this helps explaining why training is
easier using shortcuts with length 2. Note that these theoretical results are not valid for weight
initializations other than (near-)zero, (eg. Xavier or MRS) — with experimental evidence
demonstrating diﬀerent convergence behaviors for other initializations.

3.4.3 Feature reuse by concatenation vs memory efficiency

Architectures featuring shortcuts may allow reusing low level features at upper levels of
the network. This inﬂuence of previous feature maps can be done directly, by concatenating
them with those at the destination layer, as done in DenseNets. Another form is to combine
source and destination through some linear combination, as is done with residual connections
(combination by summation).

In the case of DenseNets and DelugeNets, a drawback of aggregating these densely con-
nected shortcuts by concatenation is that outputs from each layer need to be retained for
computations on the next layer. The same does not happen when aggregation by summation
is used (which is the case of ResNets). The issue is more pronounced on DenseNets, since
even under a constant number of feature maps k, dense blocks have a linear growth rate of
the number of output feature maps: for an input with ko channels and a dense block with L
layers producing k feature maps each, the output will have k0 + k(L − 1). Therefore, there is
an increase in memory demanded during both training and inference. As reported by Kuen
et al (2016), both DeludgeNets and DenseNets require more GPU memory than ResNets,
although the ﬁrst is more memory-eﬃcient than the second. Altogether, this increase in
memory requirement (alongside small margins of accuracy improvement) may explain why
ResNets remained most popular over these densely-connected alternatives.

3.4.4 Width vs depth on ResNets

As stated earlier, many layers in residual blocks have little participation in the ﬁnal accuracy
and can be changed or removed. Thus it can be hypothesized that, under suﬃcient depth,

et al, 2017, version 1, section 2).

3k copies of ±(cid:112)σ(AT A) where k equals the number of shortcut connections.

61

3. Feedforward CNN architectures

3.5 Conclusion

increasing the number of ﬁlters in each layer of a ResNet can be a more eﬀective way to use
parameters than simply augmenting layer depth. Besides, a wider and not-so-deep architecture
is more computationally eﬃcient for the same number of parameters. In fact, ﬁtting more
channels is more adapted to proﬁt from GPU parallelism than adding sequential layers. With
this in mind, Zagoruyko and Komodakis (2016) performed a series of experiments with wide
residual networks, and demonstrate that thoughtful widening of ResNets is more eﬀective to
improve accuracy than increasing their depth. For instance, a wider 16-layer model that is
as accurate on ImageNet as ResNet-1001, with roughly the same number of parameters and
being much faster to train. Additionally, they could successfully train networks with more
parameters than ResNet-1001 without incurring in overﬁtting or performance degradation.
Finally, these results bring more complexity to the discussion of deep vs shallow networks,
highlighting the role of width (number of channels) as potentially determinant when deciding
whether to “go deeper” in the number of layers.

3.5 Conclusion

Despite focusing only on feedforward architectures, this review conﬁrms the diversity of
architectural devices that have been at play on modern CNN architectures. The ﬁeld has seen
an explosion of diﬀerent techniques and methodologies, some of which having had more
impact and longevity than others. In terms of architectural features, residual connections
have been an important mark. After the fast evolution of architectures between 2012 and
2015, ResNet-based architectures have remained state-of-the-art. Many implicit regularization
methods have been introduced together with particular architectures, like dropout with
AlexNet, or batch norm with ResNets. Beyond simply training better networks, some analysis
tools have also been developed along the way, such as the deconvolution-based visualization
method proposed by Zeiler (2014), at the base of many later feature visualization works.

The success of residual networks has also called attention to their relationship to recurrent
architectures, and how they implement a form of time-unrolled recurrence. This observation
opens an interesting line of inquiry about how and when recurrent-like mechanisms could
help training more accurate or faster-convergence models. Furthermore, it resonates with
recent neuroscientiﬁc knowledge on the importance of recurrent processing in the visual
pipeline. From a qualitative point of view, it can be promising to experiment with similar
mechanisms associated to CNNs in order to asses whether analogous functionality — like
dealing with visual clutter, occluded borders or context-dependent recognition — could be
achieved. In this spirit, the next chapter reviews forms of recurrent and feedback connections
implemented in current CNN architectures aimed at image classiﬁcation.

62

Chapter 4

Recurrent and feedback CNN architectures for object
recognition

4.1 Introduction

Recurrent networks naturally come to mind when dealing with sequential data, such
as video, audio and text, since recurrent processing is intrinsically linked with temporal
or sequential processing. In computer vision, they are often on the table when tasks have
an intrinsic time component, such as object tracking on videos (e.g. Ning et al, 2017), or
when doing multi-modal tasks linking vision and text, like visual question answering or
image/video caption generation (e.g. Donahue et al, 2017; Ballas et al, 2015).

However, recurrent processing is not only useful for sequential inputs: it can also iteratively
help to reﬁne processing over static inputs. In biological vision, there is evidence — both
anatomical and physiological — that feedback connections and local recurrences play an
important role in object recognition (Spoerer et al, 2017; Nayebi et al, 2018), and are likely
involved in recognition under challenging conditions possibly due to obtaining more robust
object representations (Wyatte et al, 2014). Even static input stimuli are capable of inducing
dynamic neuronal response trajectories (Issa et al, 2018). Nevertheless, these functional aspects
of recurrent processing remain scarcely explored in the context of DCNNs. Such works are the
object of this review, which aims at covering the functional beneﬁts of introducing recurrences
and feedbacks to DCNNs (section 4.2), while also summarizing the main architectural variants
exploited to this aim (section 4.3).

Earlier forms of CNNs with recurrent processing consisted mainly in weight sharing
between subsequent layers, which is equivalent to a time-unrolled representation of a recurrent
network (e.g. Pinheiro and Collobert, 2014). This type of model has been used to study the
inﬂuence of diﬀerent architectural aspects — namely number of layers, number of parameters
and number of feature maps — on model’s accuracy (Eigen et al, 2013). More recently, the
idea of recurrence through parameter sharing could be encountered in the work of Savarese
and Maire (2019), although in a more indirect and implicit fashion. They have constrained
their convolutional layers to learn linear combinations of templates from a bank of ﬁlters.
Therefore weights get indirectly shared through these templates, even though learned weights

63

4. Recurrent CNNs

4.2 Functionalities brought by recurrent processing

may get to modulate their activation.

Even without any particular functionality as target, the addition of recurrent processing
may improve the overall accuracy of the system. A few works have explored whether enabling
a CNN with recurrent processing outperforms its equivalent feedforward counterpart (Wen
et al, 2018; Spoerer et al, 2017; Liang and Hu, 2015). Even though they may not outperform
larger recent models such as ResNets and their derivatives, in some cases they have achieved
similar performances, with the advantage of doing so with less parameters (e.g. Nayebi et al,
2018; Liao and Poggio, 2016). More generally, recurrence mechanisms have proven to be
useful to improve classiﬁcation performance of traditional feedforward architectures, such as
Inception-v3 (Vallet and Sakamoto, 2016) or Inception-v4 (Alom et al, 2017).

Figure 4.1 Proposed taxonomy of recurrent and feedback CNN architectures. Each family is represented by an
archetypal small module of 3-4 layers. Top and bottom circles stand for module’s input and output, respectively.

4.2 Functionalities brought by recurrent processing

4.2.1 Spatial context integration

While recurrent processing quickly brings to mind its relation to time dynamics, local
spatial recurrence is equally relevant in reﬁning our visual perception of a scene.
In the
model by Liang and Hu (2015), each unit receives feedback from a local patch around it.
Architecture is such that the size of this inﬂuencing neighborhood is increased at each time
step, iteratively integrating more and more global contextual information.

The model proposed by Visin et al (2015), ReNet, intends to implement context integration
via lateral connections, using bi-directional recurrent layers that integrate information in
two steps — over columns then over rows. Visin et al argue these lateral connections should
allow to remove redundant features at diﬀerent locations of the image, helping to extract
a more compact representation. Their model was applied to classiﬁcation tasks on MNIST,
CIFAR-10 and SVHN (see chapter C for a brief description of these datasets), with competitive
quantitative results reported (among its contemporaries). Unfortunately a qualitative analysis

64

Single pathwayParallel pathwaysParallel pathways: forward shortcutsIdentity shortcutsGated shortcutsDensely connected shortcutsIntra-layerrecurrenceHybrid recurrentRecurrent with feedbackInter-layer feedbackFeedforward connectionsRecurrent/feedback connections4. Recurrent CNNs

4.2 Functionalities

of the types of ﬁlters learned by this network and its function was left for future works.

Xie et al (2017b) propose a spatial integration scheme similar to ReNet, with an additional
proposal of integrating their L-RNN module to pre-trained CNNs, interleaving convolutional
and recurrent modules to model both local features and long range spatial dependencies,
respectively. This strategy was particularly valuable for semantic segmentation tasks (on
MS-COCO and PASCAL VOC 2012), which have limited amount of labeled data available
(in relation to the large number of predictions that need to be done, since pixel-wise labeling
is the target). For classiﬁcation, it can also be a strategy to reduce model size: on CIFAR-10,
accuracy results were comparable to those of a ResNet-164, while using only 15 layers and
less parameters.

The spatially hierarchical recurrent model by Zuo et al (2016), where recurrence is done
over a multi-scale pyramid of equivalent feature maps, also uses lateral connections for
spatial context integration. Besides lateral connections between patches in a same spatial scale,
patches on a lower hierarchical level inﬂuence corresponding patches in a higher level.

In fact, the use of recurrent models for spatial context integration has been further explored
for the task of semantic segmentation, where the evident inﬂuence of a larger global context
over local predictions clearly pushes towards modeling this relation more explicitly. It is the
case of Visin et al (2015), who apply a variant of their ReNet model to this task, and also the
case of Layer-RNN. For a broader review on this particular task, the reader may refer to the
review by Garcia-Garcia et al (2017) (particularly section 4.2.5).

A similar consideration can be done for the object detection and/or localization task.
For instance, the Inside-Outside Net model by Bell et al (2016) obtains contextual features
with 4-directional spatial recurrent layers applied to convolutional feature maps of a VGG
network (layer conv5). The spatial recurrence here is similar to the one presented by Visin
et al (2015) and Xie et al (2017b), with lateral connections linking image patches horizontally
and vertically. For each candidate region of interest, these contextual features are combined
with intermediate features (from layers conv3, 4 and 5) to feed a classiﬁcation pipeline. Their
architecture has reached state-of the art detection performance on PASCAL VOC 2012 and
MS COCO datasets.

Contextual information may also come in the form of a segmentation mask, as in the model
by Shrivastava and Gupta (2016), which augments a standard object detection architecture
— Faster R-CNN (Ren et al, 2015) with feedback inputs to lower layers from an accessory
semantic segmentation task. Here segmentation information is expected to guide the proposal
of regions of interest (ROI) on which classiﬁcation with a CNN is attempted in order to detect
objects. It can be seen as a contextual priming process derived from global spatial information,
including border assignment as it is an important product of semantic segmentation. While
the combination of both tasks could indeed improve detection results (in terms of mean
intersection-over-union or mean average precision), the applicability of their method is
limited to datasets including segmentation labels, which are more expensive to obtain and

65

4. Recurrent CNNs

4.2 Functionalities

rarely available for custom real-life datasets.

What-where interaction Both recognition and localization are performed by the same
model in the work by Cao et al (2015). It consists of a CNN enabled with feedback connections
from predicted outputs, which help selecting relevant activations and suppress irrelevant
responses. Using only image-level labels, the feedforward pass performs a weakly super-
vised localization proposing regions of interest (ROIs), which are further processed for ﬁnal
classiﬁcation. When using a pre-trained VGG as base network, they achieved competitive lo-
calization performance when compared to another pixel-wise supervised VGG based method.
Finally the spatial focus introduced by feedback signals could reduce the dependency on a
heavily-labeled scheme.

Beyond classiﬁcation, spatial context integration through recurrence has also been targeted
in other contexts such as image generation (van den Oord et al, 2016) and salience detection
(Liu and Han, 2018).

4.2.2 Iterative processing

When facing complex and ambiguous scenes, a longer time is needed by our brain to
completely process and parse the scene’s elements, iteratively reﬁning its internal represen-
tation. This processing includes feedback propagation of top-down information and lateral
interactions between same layers neurons. This functionality is referred hereafter as iterative
processing. Analogously, in computer vision, iterative processing of images allows to reﬁne
judgment on particular locations or features. One should expect that incorporating such
functionality to CNNs is likely to lead to more conﬁdent predictions.

An advantage of iterative processing is the possibility to have a ﬁrst coarse answer in the
fraction of the total inference time, further reﬁning it in case of need (if the scene is complex or
ambiguous, for instance). This notion of best output so-far is important for practical scenarios,
for instance in robotic navigation, where a fast evaluation of the scene must be quickly available
at all times (Zamir et al, 2017).

Another possibility is to allow for responses to diﬀerent features of the stimuli at diﬀerent
levels of the recurrence. This “behavior” has been observed with the loopy CNN model by
Caswell et al (2016), even though it was not explicitly coded for in the architecture. Cao et al
(2015) achieve a similar functionality with a more explicit model that uses feedback signals
to iteratively focus salient parts of the image, selectively ignoring irrelevant information
and reﬁning the ﬁnal prediction. Using a pre-trained GoogleNet (ImageNet 2012) as basis,
attempting re-classiﬁcation with the feedback enabled version — that focuses attention on
regions of interest — has improved top-5 and top-1 errors bey 1.29% and 1.79% respectively
(Cao et al, 2015) .

In any case, iterative processing may as well allow intermediate representations to be
reﬁned so as to obtain more conﬁdent predictions. For instance, Wen et al (2018) propose a

66

4. Recurrent CNNs

4.2 Functionalities

bi-directional recurrent CNN (VGG-like) applied to image classiﬁcation (on CIFAR, MNIST
and SVHN). Inspired from predictive coding theory in neuroscience, this type of model
processes the input information in a fundamentally diﬀerent manner. Instead of computing
and propagating representations forwards, each and every layer in a predictive coding network
(PCN) targets to minimize the error between top-down prediction — actually the upper layer
representation modulated though multiplicative weights — and bottom-up input — which in
turn is the error computed by the previous layer. As a result, representations are dynamically
adapted, progressively reﬁning ﬁnal classiﬁcation predictions. A variant of this network, using
only local recurrent processing (Han et al, 2018), yielded better results than the earlier version.
It has also been tested on ImageNet, allowing improvements around 1% when compared to
similar-size ResNets. Internal representations get updated to match top-down information,
making classiﬁcation decision sharper as time unfolds.

4.2.2.1 Iterative spatial attention

Several works have proposed networks with a recurrent mechanism to take a sequence
of crops of the original image, predicting regions of interest to be further processed. This
mechanism can be regarded as a simulation of eye saccades, taking glimpses at diﬀerent
locations of the visualized scene.

Since Fu et al (2017) focus on ﬁne-grained classiﬁcation, they use this kind of mechanism
to localize regions of the image that better help discriminate between classes, zooming into
and extracting higher-resolution features from these regions.

Another network implementing spatial attention has been proposed by Ba et al (2015),
but there the idea is to iteratively integrate information of “glimpses” from diﬀerent regions,
instead of zooming into the current image view for detailed perception. Another model which
combines foveal glimpses, but using RBMs is the one by Larochelle and Hinton (2010). On
the same line, Sønderby et al (2015) propose a recurrent version of the spatial transformer
network 1 (He et al, 2015) that will sequentially focus on individual digits in a sequence.

By adding a recurrent block on top of a standard CNN,Vallet and Sakamoto (2016) tackle
a multi-label classiﬁcation problem with an image-to-sequence model, which implicitly pro-
cesses successive locations in the image, outputting a sequence of corresponding labels.

Stretching beyond image classiﬁcation, the same idea of using recurrent mechanisms
to implement spatial attention has been applied on image captioning Xu et al (2015) and
semantic segmentation Mnih et al (2014).

1Spatial transformer networks (Jaderberg et al, 2015) iteratively compute a transformed view on the input

image to improve classiﬁcation results.

67

4. Recurrent CNNs

4.2 Functionalities

4.2.2.2 Handling occlusion and image clutter

Iterative processing can also serve the purposes of handling partially occluded objects, by
iteratively assigning perceived borders to diﬀerent visual elements and eventually inferring a
likely completion of the occluded part. This is in line with the human visual system, capable
of doing fast recognition under low-noise conditions, but takes longer to correctly process
cluttered and partially occluded objects.

An early proposal of a feedback-enabled neural model, that can recognize and restore
partially occluded patterns, has been presented by Fukushima (2005). The model tries to com-
plete learned patterns using top down signals. Furthermore, it extrapolates and interpolates
visible edges to complete unlearned patterns.

More recently, Spoerer et al (2017) adapted a basic CNN with either lateral connections
(self-recurrences), top-down (feedback) connections between adjacent layers, or both at the
same time. Their study aimed to evaluate whether and how much these connections help
with recognition under occlusion, clutter and Gaussian additive noise. To isolate observation
of these eﬀects, they produced a dataset with images of single or multiple digits which could
be partially occluded by fragments of other digits. While lateral connections were enough to
recognize occluded single digits under light levels of debris, recognition of digits under higher
levels of degradation started taking beneﬁt from top-down connections. Feedforward networks
however were slightly better at generalizing to un-occluded images. Recurrent networks
were also better at identifying multiple cluttered digits on the same image, with lateral
connections being crucial since the model with only top-down feedback was outperformed
by an equivalent feedforward model. Similarly, recurrent models could better handle MNIST
images under Gaussian noise, although here top-down connections were more eﬀective than
lateral connections at higher noise levels (lower SNR).

Cao et al (2015) did observe that with feedback connections, classiﬁcation gets much
improved on ImageNet images in which the target object occupies a small percentage of the
total area. While overall improvement is of almost 2% (1%), when object is at most 20% of the
image the improvement is of 5% (almost 4%) for top-1 (top-5) accuracy. This can be seen as a
form of robustness to clutter, since the model is capable of ignoring the majority of the image
to focus on the recognition target.

4.2.3 Response modulation

Modulatory feedback signals can be responsible for reinforcing features (either channel
or spatial-wise) contributing positively for a correct prediction, masking out those which
hinder it. In CNNs, those reinforcements can happen channel-wise, selecting feature maps, or
spatially, selecting regions of interest on a group of feature maps — which can be seen as an
implementation of spatial inhibition.

In general, spatial inhibition through modulatory feedback connections will also help

68

4. Recurrent CNNs

4.3 Architectural trends

with cluttered scenes by focusing attention on relevant parts of the image. An example is
the model by Cao et al (2015). They add to a base CNN feedback layers with binary control
variables, that will selectively focus on locations of the feature maps which were relevant to
the predictions, eliminating the inﬂuence of irrelevant features. During a feedback iteration,
control variables are optimized to maximize currently predicted class score (under L1 sparsity
inducing regularization). Salient regions highlighted by the feedback process directly indicate
regions considered or dismissed when making a certain prediction, adding an inherent
explainability aspect to this CNN model (that is otherwise achievable by ad-hoc methods, (see
Guidotti et al, 2018, for a speciﬁc survey).

An explicit modulatory mechanism is also implemented by Li et al (2018), with top-down
information ﬂowing through modulatory masks that multiply convolutional feature maps,
improving prediction conﬁdence over iterations. In a less explicit way, the LoopyNet model
by Caswell et al (2016) also implements modulatory feedback, particularly in the case where
their loop layer has parameters and its output combined with the input by multiplication.

Stollenga et al (2014) propose and ad-hoc modulatory mechanism that is learned on top of
a previously trained CNN. In fact, their system learns a policy to map the observed current
activations to a corresponding modulatory action over these same activations. While the
learning procedure is complex — it uses an evolutionary policy search strategy — this method
has the advantage of being applicable to any existent pre-trained network.

4.3 Architectural trends

4.3.1 Recurrence within layers

4.3.1.1 Intra-layer temporal recurrence

When thinking of recurrent CNNs it is straightforward to imagine layers that are recurrent
and convolutional at the same time. Several works have experimented with this kind of archi-
tecture, reformulating diﬀerent recurrent units, such as GRU or LSTM, to have a convolutional
form (see 1.2 for a brief description of GRU and LSTM).

Convolutional recurrent cell The most simple form is to add a self temporal link,
implementing a simple recurrent layer, as done by Liang and Hu (2015); Liao and Poggio
(2016); Spoerer et al (2017). For a unit located at (i, j) spatial coordinates, on th k-th feature
map, its pre-activation zijk[t] is given by:

zijk[t] = (wf

k )T h(i,j)[t] + (wr

k)T x(i,j)[t − 1] + bk

(4.1)

69

4. Recurrent CNNs

4.3 Architectural trends

Table 4.1 Recurrent convolutional architectures from a functional point of view

Model Name

Target tasks

Datasets

Functional goals

Visin et al (2015)

Visin et al (2016)

Liang and Hu (2015)

Xie et al (2017b)

Zuo et al (2016)

Ba et al (2015)

Fu et al (2017)

Zamir et al (2017)

ReNet

ReSeg

Recurrent CNN (RCNN)

Classiﬁcation

MNIST, CIFAR-10, SVHN

Spatial context integration

Semantic Segmentation

Spatial context integration

MNIST, CIFAR-10
SVHN

and 100,

Spatial context integration

Layer-RNN

Classiﬁcation,
mentation

Semantic

Seg-

CIFAR-10, Pascal VOC 2012

Spatial context integration

Hierarchical RNN (HRNN)

Object and scene classiﬁcation

Places 205, SUN397, MIT indoor,
ILSVRC 2012

Spatial context integration

Deep
Model (DRAM)

Recurrent

Attention

Sequential digit classiﬁcation on
SVHN

SVHN

Localize and recognize; Iterative
spatial attention (multiple loca-
tions)

Recurrent
tional network (RA-CNN)

attention convolu-

Fine-grained classiﬁcation

CUB Birds, Stanford Dogs, Stan-
ford Cars

Iterative spatial attention (zoom
in to a particular location)

Feedback Networks

Classiﬁcation and taxonomic
prediction, Human pose estima-
tion

CIFAR-100, Stanford Cars, MPII
Human Pose

Iterative processing, on-the-ﬂy
predictions

Vallet and Sakamoto (2016)

Convolutional Recurrent Neural
Network (CRNN)

Multi-label classiﬁcation (multi-
ple objects per image)

MS-COCO

Iterative processing

Stollenga et al (2014)

Li et al (2018)

Caswell et al (2016)

Wen et al (2018)

Han et al (2018)

Wang et al (2014)

Cao et al (2015)

Deep Attention Selective net-
work (dasNet)

Classiﬁcation

CIFAR-10 and 100

Activity modulation; Attention

Learning with Rethinking (LR)

Classiﬁcation

CIFAR-10
background-image,
2012

and 100, MNIST-
ILSVRC

Activity modulation; feature se-
lection

Loopy Neural Networks (Loopy-
Net)

Deep predictive coding net-
works
global
(PCN) with
recurrent processing

Deep predictive coding net-
works (PCN) with local recur-
rent processing

Classiﬁcation

MNIST, CIFAR-10

Modulatory feedback (not ex-
plitly stated)

Classiﬁcation

Classiﬁcation

MNIST, CIFAR-10
SVHN

and 100,

Iterative processing

CIFAR 10 and 100, SVHN, Ima-
geNet 2012

Iterative processing

Attentional Neural Network

Classiﬁcation

MNIST,
noise

MNIST-background

Modulatory feedback (atten-
tional mask)

Feedback CNN Look and think
twice

Classiﬁcation, Re-classiﬁcation,
weakly-supervised localization

Imagenet 2014

Modulatory feedback (atten-
tional mask)

70

4. Recurrent CNNs

4.3 Architectural trends

where h(i,j)[t] and x(i,j)[t − 1] denote feedforward and recurrent inputs, respectively, corre-
sponding to the 2D patch centered at (i, j), both in vectorized form. The vectorized weights
are given by wf

k (feedback), with bk as bias.

k (feedforward) and wr

Convolutional LSTM Alternatively, convolutions can be integrated with LSTM units, as
done by Zamir et al (2017). For a layer l, taking Xl[t] as input and Hl as the corresponding
hidden state, the LSTM equations become:

il[t] = σ (cid:0)W l
xi
W l
xf

f l[t] = σ
˜C l[t] = tanh (cid:0)W l

(cid:16)

(Xl−1[t]) + W l
hi
(Xl−1[t]) + W l
hf

xc(Xl−1[t]) + W l

(Hl[t − 1])(cid:1)
(cid:17)

(Hl[t − 1])
hc(Hl[t − 1])(cid:1)

Cl = f l[t] ◦ Cl[t − 1] + il[t] ◦ ˜C l[t]
o[t] = σ (cid:0)W l
Xl[t] = Hl

xo(Xl−1[t]) + W l
H[t] = ol[t] ◦ tanh (cid:0)Cl[t](cid:1)

ho(Hl[t − 1])(cid:1)

input gate

forget gate

cell gate

output gate

(4.2)

(4.3)

(4.4)

(4.5)

(4.6)

(4.7)

where W l
xi
is the sigmoid function, and ◦ is the Hadamard (point-wise) product.

(·)t is the convolution operator — single or multi-layer — with parameters W l

xi, σ

Convolutional GRU Naturally one can also implement a convolutional GRU unit as in the
multi-label classiﬁcation model by Vallet and Sakamoto (2016), or the semantic segmentation
model by (Ballas et al, 2015). Following a similar notation, we have:

xz (Xl−1[t]) + W l
xr(Xl−1[t]) + W l

zl[t] = σ (cid:0)W l
rl[t] = σ (cid:0)W l
˜H l = tanh (cid:0)W l
H = (1 − z[t]) ◦ Hl[t − 1] + z[t] ◦ ˜H l[t]

hz (Hl[t − 1])(cid:1)
hr(Hl[t − 1])(cid:1)

x(Xl−1[t]) + W l

h(rl[t] ◦ Hl[t − 1])(cid:1)

update gate

reset gate

(4.8)

(4.9)

(4.10)

(4.11)

Vallet and Sakamoto (2016) observed higher accuracy results when using convolutional GRUs
(CGRUs) instead of its non-convolutional version, in both resolutions tested 2. Their model
consists of a pre-trained Inception v3 network for feature map extraction, followed by a RNN
block made of residual CGRU blocks and a classiﬁer output layer 3. Since it is an image-to-
sequence model, more than correctly labeling elements in the image, it is important that it gets
to detect most objects — high recall — while avoiding false detection — high precision. Both
metrics were improved with convolutional GRUs, except in the case of their higher resolution
model, which had slightly lower precision. This reduction is expected anyways, since this
version of the model was fed with features from an earlier stage of Inception v3 — farther

2Resolution of the feature maps extracted from diﬀerent points of Inception V3.
3Dropout and 1x1 convolutions are used prior to the RNN block, the latter performing dimensionality

reduction, while global average pooling is done prior to the classiﬁcation layer.

71

4. Recurrent CNNs

4.3 Architectural trends

from the classiﬁcation layers and thus less discriminative — than the ones that fed the lower
resolution version.

Convolutional reciprocal-gated cell Targeting to provide a computational model of
ventral activity, Nayebi et al (2018) test multiple variants of a convolutional recurrent model.
Besides testing simple recurrent network (SRN) and LSTM recurrent cells, they propose a
novel reciprocal gated cell, which has yielded more accurate and parameter eﬃcient results
in their ImageNet experiments. This particular choice of recurrent structure was crucial for
model accuracy, as even after hyperparameter tuning both their model and the other standard
baselines, their reciprocal-gated cell models achieved signiﬁcant better accuracy. This module
combines a hidden unit h and a memory cell c through the ﬂowing update equations. For a
certain layer (cid:96) at time instant t:

t+1 = (cid:0)1 − σ (cid:0)W (cid:96)
a(cid:96)
t = f (cid:0)a(cid:96)
h(cid:96)

(cid:1)

t

ch ∗ c(cid:96)
t

and for the memory cell update:

(cid:1)(cid:1) ◦ x(cid:96)

t + (cid:0)1 − σ (cid:0)W (cid:96)

hh ∗ h(cid:96)
t

(cid:1)(cid:1) ◦ h(cid:96)

t

t+1 = (cid:0)1 − σ (cid:0)W (cid:96)
˜c(cid:96)
t = f (cid:0)˜c(cid:96)
c(cid:96)

(cid:1)

t

hc ∗ h(cid:96)
t

(cid:1)(cid:1) ◦ x(cid:96)

t + (cid:0)1 − σ (cid:0)W (cid:96)

cc ∗ c(cid:96)
t

(cid:1)(cid:1) ◦ c(cid:96)

t

(4.12)

(4.13)

(4.14)

(4.15)

where x(cid:96)
hidden unit, and c(cid:96)

t is the hidden unit input, a(cid:96)
t and ˜c(cid:96)

t h(cid:96)

tare the pre-and post-activation output values of the

t are the pre and post-activation values of the memory cell.

The rationale behind this formulation is to obtain a recurrent cell that has both gated
feedback signals — a improving gradient ﬂow over time steps — and bypassing forward
connections — improving gradient ﬂow to over layer depth, as with identity shortcuts in
ResNets. Overall, it is often the case that models will include some form of forward shortcuts —
usually residual connections — in addition to recurrence links, such as in the model by Zamir
et al (2017) which features residual skip connections every 2 layers (for mild improvements
on CIFAR-100 dataset). Similarly, the CRNN model by Vallet and Sakamoto (2016) features
a residual block including 3 CGRU units, while the bio-inspired model of Liao and Poggio
(2016) uses recurrent shortcut-2 residual blocks in its composition. The rationale behind this
usage is the same used for feedforward networks: these connections are expected let gradients
ﬂow further back thus improving convergence and overall performance.

Temporal recurrence within a block of layers Naturally, self-recurrent links can
cover more than a single layer. That is the case with LoopyNets, where feedback signals
skip 3 layers (Caswell et al, 2016), or the bio-inspired model by Liao and Poggio (2016),
where it skips over 1 or 2 layers. Similarly, Feedback Nets (Zamir et al, 2017) experimented
with feedback loops every 1 or 2 layers, going to the extreme case of a single feedback loop

72

4. Recurrent CNNs

4.3 Architectural trends

skipping all layers. They empirically observed that often skipping over 2 or 3 layers led to
better performances. A parallel can be made between this result and the theoretical and
experimental analysis by Li et al (2017), supporting that residual shortcuts with length 2
speciﬁcally have particular properties leading to improved convergence rate (when initialized
around zero, see section 3.4.2 for more details on this work).

4.3.1.2 Intra-layer spatio-temporal recurrence

Many have proposed spatial recurrence layers, which are not explicitly convolutional, but
can be viewed as a particular form of convolutional recurrent network. Most works presented
in section 4.2.1 (namely Visin et al, 2015; Liang and Hu, 2015; Xie et al, 2017b; Zuo et al,
2016; Bell et al, 2016) use this type of architecture, which is hereafter discussed here in more
detail. They all share a similar mechanism of 2D recurrence between image patches (see
ﬁg. 4.2), which has been strongly inspired by multidimensional recurrent networks (Graves
and Schmidhuber, 2012) which had been applied successfully to handwritten digit recognition.
However, the following models implement 1D recurrence relations between vectorized image
patches — and not 2D between pixels.

Figure 4.2 Schematic representation of the recurrent structure of diﬀerent spatio-temporal recurrent models.

For instance, Visin et al (2015) propose two-step bi-directional recurrent layers (with GRU
or LSTM units). Images (or intermediate feature maps) are divided into patches in a grid
pattern. The ﬁrst recurrent layer connects patches in a column, doing a vertical sweep. This is
repeated horizontally by the second layer. No explicit convolution is done, neither pooling is
used, although authors argue their model can be seen as a variant of CNN where pooling has
been replaced by lateral connections — which emulate the local competition among features
induced by max pooling — and a non-overlapping convolution is performed.

The Layer-RNN model by Xie et al (2017b) features similar architectural principles, with
spatial recurrent modules, named L-RNN, that scan along each row and column Instead of

73

MDRNNReNetInside-Outside NetLayer-RNN moduleconcat.Layer-RNN module4. Recurrent CNNs

4.3 Architectural trends

using bi-directional RNNs, each of these modules has two layers of stacked 1D RNNs for each
sweep direction (left-right and right-left for horizontal orientation, bottom-up, and top-down
for vertical orientation), producing a set of feature maps that ﬁnally get combined by sum or
concatenation. Almost the same recurrent structure is found in Inside-Outside Net (Bell et al,
2016), except that each direction is processed independently and the four diﬀerent outputs
get concatenated. Here again convolutional modules (residual blocks in their classiﬁcation
model) are replaced by their recurrent modules (L-RNN), although the spatial organization
of L-RNN allows to decompose its computations into a convolutional part and a recurrent part.
Furthermore, this rationale supports the addition of modiﬁed L-RNN modules to pre-trained
CNNs, leaving the convolutional part to be computed with the pre-existing convolutional
layers, only introducing spatial recurrence after each layer.

A similar kind of recurrence was proposed by Zuo et al (2016), in what they call a convolu-
tional hierarchical recurrent network (C-HRNN). In these modules recurrent interactions take
place, not only between neighbor tiles, but also corresponding tiles at diﬀerent scales (from
lower to higher resolution maps), incorporating spatial context over multiple scales. After
extracting feature maps with some CNN layers, they get pooled at multiple scales and divided
into spatial patches that get pre-processed by the so-called hierarchical recurrent layers. Both
SRN and LSTM have been evaluated as the basic recurrence mechanism implemented by these
layers, with LSTM often (but not always) yielding mild improvements over the SRN version.
No clear preference has been established by their experiments, indicating this might be an
application dependent choice. Particularly in the case of limited computational resources, it
might be more interesting to keep it simple with SRNs since performance gains from LSTM
were not extremely relevant.

4.3.2 Feedback between layers

Feedback between layers has been implemented in several works. For instance, the deep
predictive coding network by Wen et al (2018) has feedback between all subsequent layers.
Feedback Net, besides featuring ConvLSTM layers, has explicit feedback connections every 1,
2 or n layers (Zamir et al, 2017) . Vallet and Sakamoto (2016) also include a single feedback
link from output to the input of their RNN block, skipping over several residual CGRU blocks.
The main idea here is to reuse information from representations of higher abstraction levels.
Feedback links most of the time are simply propagated by an identity function, ultimately
combined with the input of the receiving layer via addition, though some works experiment
with multiplication or concatenation.

An exception to these identity feedbacks are architectures which aim to implement explicit
modulatory mechanisms. In this case, the feedback information often goes through some
neuron layers to generate modulatory maps — namely via feature masks to be applied over
existing feature maps (by multiplication) thus implementing feature selection at spatial and/or

74

4. Recurrent CNNs

4.3 Architectural trends

channel level. Most models presented under section 4.2.3 follow this type of architecture
(namely Li et al, 2018; Stollenga et al, 2014; Cao et al, 2015).

Particularly, Cao et al (2015) explore both adding or multiplying the feedback signal, the
ﬁrst yielding better performances than the latter. Using a pre-trained GoogleNet (ImageNet
2012) as basis, attempting re-classiﬁcation with the feedback enabled network version — that
focuses attention on regions of interest — has improved top-5 and top-1 errors by 1.29% and
1.79% respectively.

4.3.2.1 Explicit biological inspiration

Looking closer at the connection structure between the elements of the visual system, a
computational model aiming to represent this architecture would necessarily need feedback
connection between regions. Liao and Poggio (2016) have conjectured that a class of moder-
ately deep RNNs is a biologically plausible model of the ventral stream in visual cortex. With
this in mind, they have proposed an architecture where each implicated thalamo-cortical
area — from LGN to IT — is modeled by a recurrent residual block — taking inspiration from
residual networks (He et al, 2016a) — in which the recurrent link includes an identity path
skipping over one layer. Besides self-block recurrences, there are connections in both directions
— either between subsequent layers or, in a densely connected version, between each and every
pair of layers. Since no feedback from retina to cortex has been observed, retina is modeled by
a “pre-net” (1 to 3 3x3 convolution layers) which receives no feedback signals. Even though
evidence points that recurrent processing is present among retinal cells (Gollisch and Meister,
2010), authors have remained with a simple feedforward modeling. There is also a “post-net”
(batch normalization (BN), ReLU, global average pooling and fully connected layer) to output
classiﬁcation vectors from IT representation. Both time-invariant and time-variant (which is a
form of residual net, see section 3.4.1) versions have been analyzed.

In a more extensive experimental analysis, Nayebi et al (2018) have studied several variants
of convolutional recurrent neural networks (ConvRNNs) based on diﬀerent forms of recurrent
cells and feedback architectures. Over 5000 trials of hyperparameter search 4 have been
performed prior to selecting a speciﬁc ConvRNN model. They have deﬁned an architecture
search space varying multiple aspects such as the path combination operation (add, tanh and
multiply, sigmoid and multiply), the choice of convolutional kernel size and where/whether to
use depth-separable convolutions. The large sample size allowed to observe some tendencies
among the best performing models that support the reciprocal-recurrent local design: it was
indeed better to have both gated feedback and forward shortcuts on the same cell. On a global
scale, the search also pointed to long-range feedbacks between speciﬁc layers which would
often boost (or reduce) accuracy.

While computationally expensive, this search allowed selecting particular connections

4Using Bayesian tree-structured Parzen estimator (TPE) algorithm (Bergstra and Bengio, 2012).

75

4. Recurrent CNNs

4.3 Architectural trends

that helped performance, instead of having to learn weights for all possible connections
during training (as implicitly done by Liao and Poggio). With the carefully selected model,
a good predictive of primate neuronal activity and dynamic trajectories could be obtained
(particularly for higher level areas V4 and IT), while at the same time achieving good object
categorization accuracy. Their experiments have demonstrated that not only a well-designed
recurrent model performing a challenging real-life-like task — ImageNet classiﬁcation — can
be more accurate than feedforward ones, not only on the task itself but equally as a dynamic
model of primate object recognition under presentation of still images.

4.3.2.2 Ladder networks

Ladder network is an architecture inspired from denoising autoencoders (DAE). It is not
convolutional but it is worth mentioning due to its use of feedback and lateral connections. The
ﬁrst proposals of this architecture targeted unsupervised (Valpola, 2014) and semi-supervised
(Rasmus et al, 2015) learning tasks. More recently, Prémont-Schwarz et al (2017) proposed a
recurrent version, but mainly for temporal modeling purposes, although it has also proven
useful for perceptual grouping on still images.

The architecture is composed of two feedforward encoding cascades of layers — one clean
and another with additive noise, both sharing the same weights —- and a feedback decoding
cascade of layers, each receiving lateral input from its corresponding layer on the noise bottom-
up path. The combination of lateral connections and upper layer feedback signal is done via
a linear combination plus a multiplicative term mixing both signals. A second instance of
the same function, but this time going through a sigmoid non-linearity, complements the
combination. The role of the feedback path is to denoise features from the noisy feedforward
path, learning to do so by comparing its outputs to the corresponding features from the clean
feedforward path. Here lies the main architectural diﬀerence regarding DAE, in which noise
is only added to input which is the only information being denoised by the decoder. This
denoising objective for each layer yields a non-supervised cost, that may be used alongside a
classiﬁcation cost on semi or fully supervised tasks.

Pezeshki et al (2015) conducted a detailed empirical study of how diﬀerent design elements
contribute to its performance, both on semi-supervised and fully supervised tasks. They have
veriﬁed that the additive noise at every layer — an thus a corresponding reconstruction
cost — acts as a regularizer, improving generalization. While it may be a way of leveraging
information from unsupervised data, in the fully supervised scenario the reconstruction cost
terms may become irrelevant, as observed in their experiments: hyperparameter tuning (grid
or random search) yielded zero weighs for the reconstruction cost on all but the ﬁrst layer.
Moreover, lateral connections turned out to be a vital component of the architecture, being
more important than additive noise. In particular, reconstruction costs were also irrelevant
(zero weight) when lateral connections were removed. Regarding the combination function

76

4. Recurrent CNNs

4.3 Architectural trends

of lateral and feedback connections, they observed the sigmoid term to be of little importance,
while removing the multiplicative term led to a stronger degradation.

4.3.3 Hybrid models with added recurrent layers

Let us now consider models that integrated recurrence by adding some form of recurrent
layer (simple, GRU, LSTM or others) to a basic CNN architecture, usually (but not always)
between the last convolutional layer and the output layer. It is a strategy widely used on video
processing (see for e.g. Donahue et al, 2017; Ng et al, 2015), where models typically extract
features from video frames using a 2D CNN and feed them to a recurrent model in order to
characterize the video’s temporal structure (Ballas et al, 2015). In this section however the
focus is on architectures that model other recurrence relations on still images.

A recurrent multi-scale architecture is used by Fu et al (2017), with one VGG-style feed-
forward network for each scale. In addition, an attention layer predicts a region of the current
scale’s input to be cropped and fed to the next one, performing a select-and-zoom iterative
process. After 3 iterations, features from all scales are used for predictions. While classiﬁcation
is achieved through a regular softmax cross-entropy loss, prediction of the next attended
region comes from a inter-scale ranking loss that aims to always select a more discriminative
region for the next scale. Both are optimized alternately.

Another kind of hybridization is proposed by Xie et al (2017b) when they add recurrent
layers after each convolutional layer of a pre-trained network. An advantage of this method,
as argued by the authors, is that it is possible to add recurrent layers to a pre-trained CNN
and only ﬁne-tune the parameters of the newly added layers, reducing total training time. In
fact this approach improved performance in all scenarios tested in their work. More generally,
this modularity advantage is not speciﬁc to their model, but is extendable to any hybrid
CNN+RNN model, which can support resorting to these models when data is relatively
scarce and using a pre-trained network is a necessity.

77

4. Recurrent CNNs

4.3 Architectural trends

Table 4.2 Summary of convolutional recurrent architectures.

Model Name

Architecture

Intra-layer
rence

recur-

Explicit conv. re-
current layers

Inter-layer
back

feed-

"External"
back

feed-

Hybrid
CNN+RNN

Can
easily
be
added to a pre-
trained net?

Visin et al (2015)

Visin et al (2016)

ReNet

ReSeg

Yes, replaces conv.
layers by spatial
RNN

Yes, replaces conv.
layers by spatial
RNN

Liang
(2015)

and Hu

Recurrent CNN
(RCNN)

Yes

Xie et al (2017b)

Layer-RNN

Yes, interleaves or
replace conv.
lay-
ers with L-RNN
modules

Zuo et al (2016)

Hierarchical RNN
(HRNN)

Yes

Ba et al (2015)

Fu et al (2017)

Deep
Recurrent
Attention Model
(DRAM)

atten-
Recurrent
tion convolutional
network
(RA-
CNN)

Yes, on top recur-
rent layers

In the attention
prediction
net-
work

Zamir et al (2017)

Feedback
works

Net-

Yes, recurrent con-
volutional blocks

Vallet
Sakamoto (2016)

and

Stollenga
(2014)

et

al

Li et al (2018)

Caswell
(2016)

et

al

Wen et al (2018)

Wang et al (2014)

Cao et al (2015)

Convolutional
Recurrent Neural
Network (CRNN)

Deep Attention
Selective network
(dasNet)

Learning with Re-
thinking (LR)

Loopy
Neural
Networks (Loopy-
Net)

Deep
predictive
coding networks
(PCN)
with
global
recurrent
processing

Attentional Neu-
ral Network

Feedback
CNN
Look and think
twice

Yes

No

No

Yes, intra-block of
conv layers

Yes

No

No

No

No

Yes

No

No

No

No

Yes, convolutional
GRU, LSTM and
RNN

Yes, convolutional
GRU

No

No

Yes

No

No

No

No

No

No

No

No

No

No

Yes

No

Yes

Yes

No

Yes

No

Yes

No

No

No

No

No

Yes,
indirect
feedback via addi-
tional modules

Yes, Only to chose
attention focus for
next scale network

No

No

No

No

No

No

Yes

No

No

No

No

Yes

Yes,
integrates
CNN with HRNN
on top

Yes

Yes

No

No

No

No

No

No

N/A

No

No

No

No

Yes

Yes

Yes

Yes

No

Yes

Yes

Yes

No

No

Yes

No

78

4. Recurrent CNNs

4.4 Discussion

4.4 Discussion

4.4.1 Feedback vs recurrent feedforward

An interesting discussion raised by Zamir et al (2017) is the diﬀerence between recurrent
networks with inter-layer feedback — which they name recurrent feedback nets — and
recurrent nets with only self-layer recurrences — which they name recurrent feedforward
(see supplementary material from Zamir et al, 2017). With self-recurrences, there is no
combination of diﬀerent levels of abstraction. In particular, there is no direct inﬂuence of the
network’s current output over its activity. Conversely, once feedback is added, higher level
information is dynamically propagated top-down at every iteration. Moreover, a prediction
output has to be available at every timestep since it provides a feedback signal which allows
dynamic adaptation, reﬁning predictions at each iteration (see ﬁg. 4.3). This forces the model to
make meaningful predictions at every timestep, even if it might be changed in later iterations.
Zamir et al (2017) have studied their model with and without feedbacks (leaving only self-
recurrences) and observed that removing feedbacks and leaving only recurrences changed the
model’s ability to make early and taxonomically correlated predictions (in which predicted
labels are iteratively narrowed down to subcategories).

Figure 4.3 Feedback nets predict an output at every time-step, connecting the loss to intermediate hidden states
and changing how features are learned. Adapted from Zamir et al (2017).

4.4.2 Internal representations on feedback networks

In the Feedback net model by Zamir et al (2017), a recurrent feedback CNN, which gener-
ates an output at every time step is applied to image classiﬁcation. They argue their model
adjusts its representations on an abstract coarse to ﬁne scale, contrasting it to the typical

79

t-2t-2t-1tt-1tOutputlayer n-1layer nt-2t-2t-1tt-1tOutputOutputOutputlayer n-1layer nRecurrent feedforwardInputInputLossLossLossLossRecurrent feedback4. Recurrent CNNs

4.4 Discussion

hierarchical organization of features on depth of a network. This claim is partially supported
by t-SNE visualizations of how the representation evolves through network depth (for a feed-
forward net) or iterations (for a feedback net), even though it seems that these aspects – depth
and time iterations — are not necessarily equivalent to base this comparison. Nevertheless,
it remains that activation maps observed for layers of equivalent “virtual depth” (= depth
× iterations) were qualitatively diﬀerent from those presented by a purely feedforward or
even a “recurrent feedforward” network (this idea is further discussed in the next section).
Additionally, their model’s predictions seem to conform to a hierarchical structure of the
learned classes: as the “virtual depth” increases, predictions get narrowed, say from hamster
to rabbit, to quote one example from the paper. This aspect has emerged naturally from
the architecture, while the same has not been observed for feedforward models, even when
trained with a an auxiliary loss considering both coarse and ﬁne-grained labels.

4.4.3 Training considerations

4.4.3.1 Temporal recurrence depth

Starting from static feedforward models, the inclusion of time dimension consequently
adds some related extra hyperparameters. Some examples are the input stimulus duration
(how long to keep input image presentation), temporal recurrence depth (how long to unroll
the model during backpropagation through time (BPTT) training ), readout time (how many
time iterations to run before using output as prediction, during test/deployment phase),
among others. While not many works explore the eﬀects of these hyperparameters on their
model’s function and accuracy, quite a few at least mention or experiment with the temporal
recurrence depth. Most models do so to a moderate extent — from 2 to a few tenths of
iterations.

Caswell et al (2016) for example unroll their network in time for 3 iterations. In a more
thorough exploration, Zamir et al (2017) test training diﬀerent network depths (12, 15, 18, 21)
and time iterations(though their main experiments all used T = 4 iterations). They observed
that for a given network depth, there is an ideal number of iterations, with performance
degrading for higher or lower values. In particular for their model, training with T = 4
iterations was ideal for a 12-layer network and T = 8 for an 8-layer network. Additionally,
having feedback (having T > 1) was always better than not having any. This issue was also
explored brieﬂy by Liao and Poggio (2016), but varying time iterations only during test.
Having trained with T = 10, a similar eﬀect has been observed: test error drops until T = 10
then re-increases if further iterations are done. However since in this case no analysis changing
T during training was done, this result could be due to overﬁtting to the speciﬁc time-depth
condition.

80

4. Recurrent CNNs

4.4 Discussion

Overall, it is natural to expect such limit, since more time iterations implicate repeated
application of the same ﬁlters, which might at some point lead to strong information loss.
From another point of view, a parallel can be made with degradation in very feedforward
deep networks, but considering that a recurrent network has a larger virtual depth (time ×
depth) as T increases.

The distinct nature of predictive coding models leads to expect a diﬀerent behaviors
regarding the number of recursive iterations. Wen et al (2018) tested T = {0, 1, · · · , 6} for
their PCN model, and noted that larger T tended to lead to faster convergence and better
accuracy. Indeed throughout the iterations it is possible to see how the network reﬁnes its
predictions and corrects itself, particularly for ambiguous images. It is natural to expect such
convergence behavior given the objective of individual layers to predict next level predictions
with minimal error.

4.4.3.2 Computational requirements

With recurrent models, the need to represent internal states in the computing graph leads
to a larger memory need during training. As observed by Vallet and Sakamoto (2016), it
can be important to limit the input size of features feeding recurrent blocks. Using features
extracted from diﬀerent points of an Inception V3 network, they had either 8 × 8 × 2048
(0.13 M parameters) or 17 × 17 × 768 (0.22 M parameters) inputs. To limit memory usage
and ﬁt the model inside their available hardware, a 1x1 convolutional layer as used to reduce
dimensionality to 256 channels, prior to their residual CGRU sub-network.

When processing still images, a recurrent model in general will require T iterations of
feedforward and feedback passes, against a single feedforward pass of a plain CNN. Consid-
ering both top-down and bottom-up passes take N FLOPS, a CRNN will take 2T N FLOPS
against only N FLOPS for a CNN. However, if the input is a video, this gap is straightened,
with CRNNs taking 2N per frame, against N per frame on a CNN (as remarked by Wen et al,
2018).

On the bright side, recurrent models can be capable of achieving state-of-the-art results
under a lower number of trainable parameters, thus reducing the computational impact of
time-unrolling and storing hidden states. For instance, the median ConvRNN by Nayebi et al
(2018) could achieve the ResNet-34’s top-1 ImageNet performance (around 73% accuracy)
under only 75% of the parameters and half the number of layers.

4.4.4 Biological plausibility

Feedforward CNNs have not provided accurate models of ventral neuronal activity when
trained for simpler tasks or on unsupervised tasks (Hong et al, 2016; Khaligh-Razavi and
Kriegeskorte, 2014, more on section 2.5.1). As reported by Khaligh-Razavi and Kriegeskorte

81

4. Recurrent CNNs

4.4 Discussion

(2014) (more on section 2.5.1), CNNs trained on unsupervised tasks have not yielded accurate
models of per-image (not average) neural responses, particularly in the higher visual cortex.
Training for real complex tasks seems to be critical to obtain a highly predictive model of th
ventral stream activity, including the case of recurrent models (Nayebi et al, 2018). In this
sense, though many works make reference to biological inspiration, few actually try to model
neuronal activity and perform well on realistic benchmarks such as ImageNet (see table 4.1).
Mild improvements on simpler datasets (such as Canadian Institute for Advanced Research
(CIFAR) and Street-view house numbers (SVHN)), observed by Liao and Poggio (2016) for
instance, might be simply due to an extra number of parameters of the model rather than an
actual contribution of recurrent processing.

The hypothesis of recurrent processing only being useful under challenging conditions has
been studied and experimentally challenged by Kar et al (2019). By comparing performances
of primates (humans and monkeys) to that of a feedforward CNN, Kar et al (2019) could
identify challenging images which could not be well categorized by the non-recurrent CNN
model. Investigating further IT response to such images, measurements indicated they would
take longer to be processed, taking extra ∼30 ms on average to observe ﬁrst activity signals
on IT cortex. As expected, this delay was reﬂected in the non-recurrent model abilities: even
though early IT responses could be well explained, late activity (around 100-150 ms) could
not. In this latter case, very deep nets and shallow recurrent models were the best predictors,
suggesting the need for further iterations of non-linear transformations for challenging inputs,
be it in the form of more layers or temporal recurrence.

The model by Nayebi et al (2018) has proven to be a step towards a more bio-plausible
ConvRNN model. In their work, extensive hyperparameter and architecture search has been
performed prior to selecting a speciﬁc ConvRNN conﬁguration. Out of more than 5000
model-samples, the median accuracy model was later fully trained on ImageNet and had
its predictability of neural activity analyzed. Their fully-trained median ConvRNN was
capable of correctly classify images that take longer to be decoded , which are challenging
for feedforward models according to the study of Kar et al (2019). Comparisons between
primate neuronal activity and model activity (under equal static visual stimuli) demonstrated
how a particular form of recurrent structure is determinant for an accurate modeling of the
activity of the ventral stream. Not only it could well-predict time-average values but also
predicted dynamic neuronal response trajectories for single-images highly correlated to the
neurological ground-truth. Representations learned by this ConvRNN were compared highly
predictive of neuronal population recordings of higher visual areas — particularly linking
upper layers 6 to 8/9 with areas V4, anterior infero-temporal (aIT) and central infero-temporal
(cIT)/posterior infero-temporal (pIT), respectively. Furthermore, the complex connectivity of
their ConvRNN appeared to be critical to explain neuronal dynamics, as a simpler baseline
dynamic model could not achieve similarly accurate predictions.

82

4. Recurrent CNNs

4.5 Conclusion

4.5 Conclusion

There have been many studies trying to integrate recurrent mechanisms into CNNs, for
purposes other than explicit image-sequence treatment. Some studies seek to understand
whether these mechanisms can bring the functionalities they are reputed to perform in our
brains — like the study of recognition under occlusion by Spoerer et al (2017). Reasonably,
these studies often concern themselves with simpliﬁed synthetic datasets, with controllable
variability, in order to allow deduction of more precise conclusions. Unfortunately, this also
implicates in results that may not translate well in practice to more realistic images. Studying
this type of mechanisms in application to real-world data remains a topic under-explored in
experimental research.

Other works, more concerned with practical results, tackle directly more realistic problems,
at the expense of a clearer understanding of how the inclusion of recurrent processing and/or
feedback loops has brought any improvements. The complexity of the task and of the entire
architecture fog the ability to conclude whether these additions were actually able to fulﬁll
any of the functional “purposes” their analogous counterparts serve in our own natural
visual system. Moreover, the inclusion of recurrence complicates the theoretical analysis of
DNNs even more, further reducing the possibility of developing an intuitive comprehension
of their inner functioning. It is therefore important to advance theoretical analysis of these
architectures.

From a neurological point of view, it can be argued that the brain does not “stack up more
layers” in order to process a complex input, it simply takes longer with recurrent loops over
the same network structure (Wen et al, 2018). In that sense, the inclusion of recurrences also
presents itself as an alternative to the trend of “going deeper” with the inclusion of ever more
layers to feedforward models. The relationship between residual networks and recurrent
layers points towards the possibility of running shallower models over multiple time-steps as
lower parameter-count option.

Moreover, it is a potential method for having similar performances under many less
parameters that deserves further experimental and theoretical exploration. In particular, their
suitability to small data regimes remains to be studied. The lower dimension of this model
space could be particularly important in situations of limited data availability. However,
the relationship between model size and generalization is not that straightforward for deep
networks and is closely related to how they are optimized, as discussed in the next chapter.
This hypothesis could thus be strengthened by further experimental testing and theoretical
developments.

83

Part II

Image classiﬁcation on small datasets

.

.

Introduction .
.
Problem statement .

5 A review of strategies to use deep learning under limited data
.
.
.
.
.
.

.
5.1
. . . . . . . . . . . . . . . . . . . . . . . . . . . .
5.2
.
. . . . . . . . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . . . . . .
5.3 Axis I: Get more data .
5.4 Axis II: Reduce model complexity . . . . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
5.5 Conclusion .

.
.
.

.

.

.

.

.

.

.

6 Analysis of DCNN applied to small sample learning using data prototypes

.

.
.

Introduction .

.
. . . . . . . . . . . . . . . . . . . . . . . . . . . .
.
6.1
.
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
6.2 Related works .
.
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
6.3 Model proposed .
6.4 Experiments and results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
6.5 Discussion .
.
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
6.6 Conclusion .

.
.
.

.
.
.

.
.
.

.
.

.
.

.
.

.
.

.
.

.
.

85
85
86
90
102
112

113
113
117
121
125
138
141

84

Chapter 5

A review of strategies to use deep learning under
limited data

5.1 Introduction

Following the growth of Internet-based companies in the last decades, data collection
from all aspects of everyday life has become commonplace to a level that other industries
increasingly take interest in making proﬁt from their own data as well. However, collecting
and labeling large-scale datasets is not as ubiquitous as it may seem. Under certain application
domains, building such dataset is expensive, if not practically impossible. Diﬃculties may arise
from the limited occurrence of the objects under consideration — unique medical conditions,
infrequent machine faults or rare animals in nature, for instance. Alternatively, data scarcity
may simply be due to the novelty of the targeted object. In either case, the ability to infer
patterns and learn to generalize predictions from few samples is paramount to successfully
exploiting available data.

On the image domain, CNNs have proven invaluable in achieving a new level of prediction
accuracy, when compared to traditional hand-engineered features, in diverse domains. The
greatest breakthroughs, however, have intervened in the context of large-scale datasets. The
concept of large-scale is of course relative to multiple factors. Intuitively, one may account
the quantity of samples per category, the total number of such categories, the diversity of
conditions images were taken, as factors weighting in for the appreciation of a given dataset as
suﬃciently large — or conversely, insuﬃciently small. Nevertheless, it remains that CNNs in
general need a signiﬁcant quantity of data in order to successfully learn meaningful features
together with class boundaries.

From a theoretical perspective, the complexity of the model family composed by DCNNs
is generally high, taking into consideration the typically very large number of learnable
parameters. Generalization boundaries predicted by usual complexity theories (see discussion
by Jakubovitz et al (2018) and ﬁrst chapters of Shalev-Shwartz and Ben-David (2014)) provide
relationships between error rate (in test, thus generalization capability), number of training
samples, and the cardinality of the model family considered during learning. Even for modest
sized CNNs, the cardinality of the model search space is so high that an impossibly high

85

5. Deep learning with limited data

5.2 Problem statement

number of training samples is necessary. Yet, CNNs generalize on large-scale-but-theoretically-
insuﬃcient-data.

Explanations for such counter-intuitive behavior are subjects of current theoretical and
experimental research (Jakubovitz et al, 2018). Intuitively, it is hypothesized that even though
model space is large, the way in which networks are trained has a high likelihood of exploring
only a little portion of this space, which contains local minima of high generalization capability.
Guiding learning towards these solutions seems more diﬃcult under limited data, calling for
a special attention to learning methodologies applied in this scenario.

Mapping out the existing strategies, methodologies and techniques which potentially
increase the likelihood of learning over limited data are the main objectives of this review
chapter. The following matters will discuss and categorize several works that manage to apply
DCNNs successfully under some form of data availability constraint. When suitable, works
relevant to other related topics (section 5.2.2) will also be reviewed in order to complement
the selection of potentially useful strategies. We choose to address this matter from the dual
perspective of training set size vs model complexity, which deﬁne the two main axes of this
review (sections 5.3 and 5.4). The focus is divided according to the lever of actuation: either
more data is to be used, or model complexity should be reduced — either directly through
architectural constraints, or indirectly through particular training strategies aiming to guide
the learning process. It is blatantly evident that the amount of research in the ﬁeld of neural
networks has expanded exponentially over the past few years. As such, this survey is not
intended to be thorough on works concerning small sample deep learning and related ﬁelds,
nor will it describe such works in detail, rather focusing on aspects pertinent to the structured
view we propose.

5.2 Problem statement

5.2.1 Small data scenarios

The expressions “small sample learning” or “learning under limited data” are suﬃciently
broad to encompass multiple situations regarding the availability of labeled or unlabeled
data. Diﬀerent strategies may apply for each situation (schematically depicted in ﬁg. 5.1):

A. There may be a considerable amount of labeled data, but it remains insuﬃcient in regard

of the total number of input features used for learning;

B. There may be limited labeled data, but a large amount of unlabeled data on the exact
same domain, that can be leveraged by a semi-supervised or weakly-supervised strategy;
C. There may be limited labeled data on the target task, but there are related datasets from
the same or other domains that can be leveraged by a transfer learning approach;

86

5. Deep learning with limited data

5.2 Problem statement

Figure 5.1 Illustrative diagram diﬀerentiating the diﬀerent small data scenarios ranked in the text. Rectangles
represent data matrices (with samples as rows and features as columns). Diﬀerent colors mark diﬀerent types
of data (see legend in the top right corner) and dashed lines delimit distinct datasets.

D. There may be limited labeled data on each category, but a large number of categories
makes a larger dataset in total. Transfer learning might still be relevant in this scenario,
which is closely related to ﬁne-grained classiﬁcation;

E. In a worst case scenario, there is little labeled data and eventual source domains are too
diﬀerent to have a positive inﬂuence in learning the target task. In that case, explicit
knowledge about the target application and domain may be invaluable in achieving this
rather impossible task.

5.2.2 Related problems

The previously described scenarios naturally link small sample learning to other subareas
and frameworks studied within machine learning literature. Despite their common ground,
these other areas diﬀer in their main targeted issue as well as their usual methods. Nevertheless,
similarities are suﬃcient to consider these subareas as an important source of methodological
ideas relevant to learning on not-so-big datasets. Hereafter we brieﬂy discuss some of these
related problems.

High-dimensional data Regardless of the reason leading to a small dataset, high dimen-
sional input spaces are a frequently related issue. Data from neuroimaging studies are a
representative example on this matter. Due to constraints in the number of participants and
access to equipment, usually few trials are made, leading to small datasets. If we are to use the
raw data directly, each example has millions of voxels, leading to a poorly sampled input space,

87

labeled imagesunlabeled imagesrelated datacross-domain datadatasetclass 1class 2class iclass n......BACDEmnnumber of samplesnumber of features5. Deep learning with limited data

5.2 Problem statement

regardless of how many volunteers participate in the study. In such situations dimensionality
reduction and feature extraction methods are often necessary steps. More recently, some
studies have managed to use DNNs for diﬀerent sub-tasks linked to MRI imaging — such
as image restoration, segmentation and classiﬁcation — to varied degrees of success (see
Lundervold and Lundervold, 2019, for a specialized review).

Imbalanced classes and oversampling In imbalanced datasets, some categories are
under-represented with respect to the the remaining ones. These classes need to be learned
on “small class-speciﬁc data”, although other classes and the overall data set may have a
large amount of samples. Class imbalance can be alleviated by oversampling techniques (for
instance by sampling batches with a higher probability for the under-represented classes),
but results are limited if the overall data is anyway small. It can be the case that only some
particular classes are under-represented, leading to unbalanced classiﬁers. When the overall
amount of images is suﬃciently large, oversampling techniques like boosting can bring
suﬃcient improvement. However, plain oversampling cannot increase the sampling coverage
of the input space, which is desirable under small data constraints.

Image retrieval In image retrieval, the goal is to provide a ranked list of database images
according to their similarity to a given query sample. By analogy between query and test
samples, and between the database and the training set, one could frame classiﬁcation in
a similar fashion: rank training samples by similarity to the test ones, then compute class
predictions from this ranking. This line of reasoning has been exploited for instance by
Triantaﬁllou et al (2017), for few-shot learning (discussed in section 5.4.3.1). Information
retrieval in general is also concerned with larger databases and fast query treatments, which
are not of interest for small data learning.

Fine-grained classification Fine-grained classiﬁcation problems generally comprise
speciﬁc sub-classes within a same object or scene category. Some examples are identifying
particular car models (Krause et al, 2013) or bird species (Wah et al, 2011). In this type
of problems, diﬀerences between classes are more subtle, which make learning distinctive
features more diﬃcult. Moreover, it is often the case that the number of ﬁne-grained categories
is so large that, even with tens of thousands of images, the number of samples per category is
relatively small, approximating to a small sample learning scenario.

5.2.3 Implicit and explicit knowledge

Human memory capabilities can be categorized between procedural and declarative.
While the later concerns knowledge one can enunciate and transmit explicitly in a given
language code, the ﬁrst is less evidently considered knowledge even though it is every much
as important, if not more, than any explicit knowledge one may declare. Procedural memory
concerns our acquired or innate abilities to act on the world under diﬀerent situations. It is

88

5. Deep learning with limited data

5.2 Problem statement

our “know-how”, our “savoir-faire”, an implicit knowledge one may not be able to easily
explain despite being able to perform accordingly.

Explicit knowledge can be very useful in tailoring a model architecture or loss function to
a particular need. Quoting a widely used example, using speciﬁc computer vision knowledge
on image ﬁlters was crucial when choosing to share weights across all locations in a locally
connected layer — making it an actual convolutional layer. Such choice has a signiﬁcant impact
on model size and complexity, being primordial for the success of CNNs. Other examples of
useful prior explicit knowledge will be given across this chapter.

Figure 5.2 Knowledge sources

5.2.4 Knowledge transfer

The idea of sharing information between tasks or domains to help solving a target task has
a direct inspiration on human cognitive abilities. For instance, a guitar player should spend
signiﬁcantly less time when learning to play the bass, in comparison to a not-musically-trained
individual, due to the fact that his previous knowledge is relevant to solving this new task.
Analogously, one can imagine that knowledge gained by a machine learning model could
help another in accomplishing a diﬀerent but somehow related task.

As deﬁned by Pan and Yang (2010) (and restated by Weiss et al, 2016; Ruder, 2017b),
knowledge transfer or transfer learning aims to improve learning of a predictive function on
a target task by making use of knowledge from a source task, given that source and target

89

DataModelExplicit regularizationTrainingstrategyArchitecturePredictionsImplicit knowledge sharingExplicit knowledge sharingKnowledge sources►Related data−Image−Cross-modal►Related learned models−Pre-trained weights►Domain/application specific−Invariances, structure, noise►Conceptual structure−Taxonomies, ontologies, hierarchies, etc5. Deep learning with limited data

5.3 Axis I: Get more data

domains and/or tasks are diﬀerent. In traditional machine learning there is usually an implicit
assumption that training and test are done on datasets of the same domain — that is, presenting
identical distributions P (X) and represented on the same feature space (X ). Such requirement
is partially waived in this deﬁnition of transfer learning, since domains may diﬀer. However,
this deﬁnition is broad enough to include situations where domain is the same/similar, with
the diﬀerence in tasks characterizing the knowledge transfer setting.

Figure 5.3 Strategies for deep learning under small data. This diagram illustrates the point of view presented in
this chapter.

5.3 Axis I: Get more data

It may seem contradictory to expect more data whilst discussing means for learning under
limited data budgets. It is however a hard limitation (though diﬃcultly quantiﬁed in practice)
that a minimum amount of data variability — corresponding to a representative sampling of
(likely regions on) the input space — is necessary for any statistical model — and for deep
networks in particular — to infer invariants that will lead to a suﬃciently correct mapping of
the label space. If not enough variability is present, there are diﬀerent strategies that can be
used to increase a model’s sampling of the image space, from basic random data augmentation
to more complex generative modeling (section 5.3.1).

Alternatively, it is often the case that the limitation is mostly present in terms of labeling
eﬀorts than in amounts of raw unlabeled images. These occasions are adapted to unsupervised
feature learning and semi-supervised strategies (section 5.3.2). If some extra labeling work can

90

recurrencesparsity (L1)low parameter countskip-connectionsgeometric constraintsbatch normweight decayauxiliar loss functionssmoothness (L2)meta-learningmulti-task learningDataModelepisodical trainingExplicit regularization TrainingstrategyArchitecture●Do data augmentation○domain-speciﬁc transformations○interpolation/extrapolation in intermediate feature spaces○synthetic images through generative models●Use unsupervised data○semi-supervised learning○weak supervision○active learning●Use other related datasets○pre-training + ﬁne-tuning○metric learning○zero-shot learningsemi-supervised learningmetric learningweight-sharingdropoutcurriculum learningattentionalmechanismsauxiliar taskson weightson representationsbuilt-in invariances5. Deep learning with limited data

5.3 Axis I: Get more data

be aﬀorded, active learning strategies can help on making it more eﬃcient (section 5.3.2.3).
Finally, one can also resort to other datasets, generic or domain speciﬁc, that can be used
in either unsupervised or supervised pre-training (section 5.3.3.1). Related datasets for other
modalities can also help in building a semantically meaningful representation, as exempliﬁed
by zero-shot learning approaches (section 5.3.3.2). These three aspects — synthetic data,
unlabeled data and other datasets — guide the presentation of data-related strategies in the
following subsections.

5.3.1 Synthetic data

Artiﬁcially augmenting training data has been widely done in the image recognition
domain, from LeNet (Lecun et al, 1998) in 1998 until today. It sheds some light on how
fundamental and widespread this practice is to notice that all the ImageNet challenge-winning
models since 2012 have made use of some data augmentation strategy. Of course it is not
restricted to deep networks and applicable to almost any statistical learning method.

Data augmentation is particularly beneﬁcial when the ratio model complexity/dataset
size is too high: more data samples reduce the risk of overﬁtting with complex models (like
most deep networks). Even though the case of large deep networks exacerbates the need
for extra data, feeding a shallow network with augmented data is not necessarily worthless:
analogous boosts in performance can be obtained, although possibly less pronounced than
those obtained with deep over-parameterized networks (as observed by Chatﬁeld et al, 2014).

5.3.1.1 Augmentation at the input space

The simplest augmentation method is to randomly sample training images to be corrupted
with a small quantity of noise, additive or otherwise, while keeping the labels of the original
images. On a more structured perspective, this “noise” can take the form of pre-deﬁned
distortions and transformations (Poggio and Vetter, 1992; Simard et al, 2003), often derived
from domain or application-speciﬁc symmetries. This can be easily exempliﬁed in the image
domain: a generic image classiﬁer ideally should output the same labels for a mirrored image
or a slightly rotated one.

The most eﬃcient augmentation methods in general will try to generate synthetic images
that are both semantically valid — meaning a realistic image is generated — and diverse —
meaning a large variety of transformations is applied aiming to cover most degrees of freedom
to which the model should learn to be invariant (Xie et al, 2019).

Multiple image transforms can be applied in sequence and/or at random for a more diverse
augmentation: image jittering or random crops, relevant rotations, changes in brightness and
contrast, horizontal or vertical ﬂipping. It remains nonetheless essential to consider which
transformations could actually be harmful for a given target application. For instance in

91

5. Deep learning with limited data

5.3 Axis I: Get more data

medical imaging, horizontal mirroring transformations are at times avoided as they may
produce anatomically implausible images (e.g. Liu et al, 2019).

Overall, the more variability, the better, as long as generated images are realistic considering

the application scenario.

5.3.1.2 Augmentation in the feature space

While several semantically valid transformations are intuitive for the image domain,
ﬁnding such transformations can be less obvious in other domains. This diﬃculty motivates
the design of augmentation procedures intervening at features space. In the case of neural
networks, this translates to creating new data points directly at some intermediate layer.
For instance, DeVries and Taylor (2017) proposed one such method which generates new
samples directly on feature space by manipulating vector representations of an autoencoder.
Of course such methods are also a possibility for image CNNs, alongside traditional image
augmentation.

Implicitly, feature space augmentation obtains new samples through some combination of
feature vectors computed from the original training images. In the work by DeVries and Taylor
(2017), a sequence autoencoder was trained and then used to encode input samples into con-
text vectors. Augmentation was produced by applying noise, interpolations or extrapolations
to such vector representations, which can be used directly as feature vectors for classiﬁer
training. By extension, such generated vector codes can also be fed to the trained decoder
to obtain corresponding input representations, which could in turn be used for training or
simply to provide more clarity on the visual quality of the generated data.

Similar augmentation methods can be done over CNN features, without the need for a
decoding process. For instance, the MixUp method proposed by Zhang et al (2018) uses
convex combinations of feature vectors — and corresponding label indicator vectors — to
generate virtual samples. It has been successfully applied to semi-supervised training CNNs
for image classiﬁcation in follow-up works (Berthelot et al, 2019; Verma et al, 2019; Liu et al,
2019). Together with the unsupervised augmentation method proposed by Xie et al (2019),
these works support that a well-modeled augmentation noise — going beyond simple image
transformations — can improve accuracy, particularly in semi-supervised tasks — that is
under a limited number of labels.

5.3.1.3 Augmentation through generative modeling

The previous example of feature space augmentation by DeVries and Taylor (2017) is also
a case of augmentation through generative modeling — in case the generated codes get to be
decoded into new input images. Overall, generating new synthetic images that go beyond
simple geometric transformations requires an explicit and generative modeling of the data

92

5. Deep learning with limited data

5.3 Axis I: Get more data

distribution (see section 1.2.2 for some brief descriptions of deep generative models).

Most recent image data augmentation work has relied on GAN model variants — for
instance DAGAN model by Antoniou et al (2018)— with a smaller number of works experi-
menting with VAE models (e.g. Pesteie et al, 2019) or even combinations of both (like Bao
et al, 2017).

These models implicitly estimate the data manifold from the samples available, from
which new images will be sampled. It is not clear whether new knowledge is truly obtained
through this process. Intrinsically, using them to generate new images can be seen as a more
advanced form of interpolating and extrapolating from known images. Therefore generative
data augmentation cannot extrapolate to completely unseen categories (or parts thereof). In
terms of internal representations, classes which are better modeled by disjoint clusters should
have training samples representing each of them: generalization to a completely un-sampled
cluster is impossible. As a result, these models are most likely to be useful when at least a
basic pool of images covering all classes of interest is available.

While able to produce plausible example images, these generative methods are not fully

reliable.

Output quality is diﬃcult to automatically assess (due to lack of appropriate metrics,
see Theis et al, 2016) and can remain quite irregular, resulting in a noisy dataset containing
unrealistic images (in regards to the target application). Generally, synthesis quality is often
highly sensitive to model hyper-parameters (and to the input noise vector in GANs). Thus it
is prudent to check the overall quality and main modes of error (i.e. main cases of nonsense
images generated) to eventually ﬁlter out unsuitable samples if necessary 1. Some research
works have carried out a sort of visual Turing test, in which a pool of images is randomly
sampled from both the generator model and the original data, with human experts judging
how realistic each sample is (for instance Baur et al, 2018). However, a manual validation
procedure may be rather impractical and expensive in a production scenario.

Additionally, training these models also requires a substantial dataset. Many works achieve
realistic generation by learning a class-agnostic data model (e.g. Baur et al, 2018), which
implicitly increases the amount of training examples per class (since samples from all classes
are combined). In this case, synthetic unlabeled data may be later incorporated into a semi-
supervised strategy (section 5.3.2.1).

Class-aware generation may be more attainable with ﬁne-grained datasets (e.g. Bao et al,
2017). Despite a relatively small sample for each class, images are more closely related among
classes — since they all belong to a single “super-class” — making up a larger eﬀective training
set. Nevertheless, learning class-aware models over really small datasets remains a challenging
task, subject to most of the same diﬃculties discussed throughout this chapter. Therefore
it is no surprise to encounter works experimenting combinations of GAN and some of the

1It might be the case that such inadequate images do not compose a signiﬁcant proportion within the artiﬁcial

dataset thus not hindering overall classiﬁcation accuracy signiﬁcantly

93

5. Deep learning with limited data

5.3 Axis I: Get more data

strategies discussed here. To mention some examples:

(cid:73) Souﬁ and Valdenegro-Toro (2019) use a generative model to translate related image
data — symbolic traﬃc signs — into the target application domain — on-road sign
recognition.

(cid:73) If only a few classes are under-represented, it is possible to derive minority class examples
by learning to transform from generic to speciﬁc images, as done by Koga et al (2018).

(cid:73) Meta-learning: learn-to-learn a model that synthesize images from few examples, such
as Clouâtre and Demers (2019); Hong et al (2020b,a) (see section 5.4.3.1 for more on
meta-learning).

5.3.2 Unlabeled data

Labeling sometimes is the major bottleneck (due to time or human expertise availability
constraints). In that case, if extra unlabeled data samples are available, there are multiple ways
to proﬁt from the information they carry. Evidently, unlabeled data can be used to generate
synthetic data through some generative model, as discussed before. This section however
focuses on more direct uses of unlabeled image sets.

Unlabeled data can be helpful in learning a more complete representation of the target
dataset. They be included in the training process, side-to-side with labeled samples, in a
semi-supervised learning algorithm, further discussed in section 5.3.2.1. In case labeling new
samples is possible, eﬃcient labeling is a concern of active learning, further discussed in
section 5.3.2.3, which can also be associated with deep networks. If a detailed labeling is too
costly, another alternative is to simplify the labeling task as much as possible, appealing to
weaker forms of supervision (section 5.3.2.2. For instance, for a scene semantic segmentation
task, if having a fully pixel-wise labeled image is too expensive, we can consider having only
bounding boxes roughly circling the main objects of the scene.

5.3.2.1 Semi-supervised learning

Many semi-supervised algorithms have been proposed over the years, although only a
small number of them have been applied recently in the context of deep models, which are
the focus of this chapter. For further information on general semi-supervised methods, the
reader may refer, for instance, to the reference book by Chapelle et al (2006b).

Under a neural network framework, unlabeled data most often goes into calculating addi-
tional loss terms which enforce some a priori assumption about the data distribution (Chapelle
et al, 2006a). First of all, it is implicitly assumed that these images bring novel information on
the data distribution p(x) that is relevant to the inference of the prediction function p(x|y).

94

5. Deep learning with limited data

5.3 Axis I: Get more data

Otherwise, the additional information may not help or even hinder classiﬁcation, introducing
irrelevant or counter-productive biases into the learning process.

Besides this hypothesis, diﬀerent types of semi-supervised loss terms derive from diﬀerent
assumptions. For instance, it can be assumed that the label-predicting function is smoother
in high-density regions than in low-density regions, so that two close points in such a high-
density region should have corresponding labels similarly close to each other. It implies that
nearby points (say, in a cluster) should have close labels, which allows extending labels to
nearby unlabeled examples. This hypothesis motivates strategies relying on weak-labeling or
pseudo-labeling (see section 5.3.2.2), also serving as motivation for certain active learning
methods (section 5.3.2.3).

Such notion of a homogeneous neighborhood motivates the clustering assumption: as-
suming nearby points tend to have similar labels implicates points in the same cluster are
likely to belong to the same category. This also implies that the decision boundary between
categories should lie in a low density region, as the opposite case implicates in a cluster which
likely represents a single category. Multiple works have relied on this hypothesis, such as
prototypical networks (Snell et al, 2017) which have been applied to semi-supervised few-shot
learning scenarios (Boney and Ilin, 2017). Since classiﬁcation on these models essentially
relies on a nearest centroid classiﬁer, it is evident that a coherent neighborhood — at the CNN
feature space — is key for correct predictions.

Another related assumption is the manifold hypothesis, that is, that high-dimensional
data tend to lie close to a low-dimensional manifold. This hypothesis being true, an algorithm
can be designed to search for solutions lying close to one such manifold, reducing the eﬀective
dimensionality of the problem. This hypothesis has motivated semi-supervised learning
works featuring low-dimensional manifold regularization prior to the revival of large neural
networks (e.g. Belkin and Niyogi, 2004). A similar method has been used recently in the
context of CNNs for image categorization, being easily extendable to incorporate unlabeled
samples into the regularization term (Zhu et al, 2017b). This and other types of regularizations
derived from a priori assumptions will be further discussed in section 5.4.1.

When labeled images are much fewer than unlabeled, a model is very likely to overﬁt
to the small set of labeled samples if no care is taken. Thus in semi-supervised training it
is important to dose the inﬂuence of the supervised loss term, which can be achieved by
controlling the learning rate — increasing it during training according to some annealing
function as done by Xie et al (2019) — or the balancing between supervised and unsupervised
losses.

5.3.2.2 Weak supervision

While gathering an expert labeled dataset may be expensive, it may be possible to gather
lower quality labels for an existing pool of unlabeled images. Depending on the application

95

5. Deep learning with limited data

5.3 Axis I: Get more data

domain, multiple paths can be taken: having non-experts produce coarse or imprecise labels,
gathering textual labels from the context in which the image was taken (say for web gathered
data), using pre-trained classiﬁers (alone or in committee) to provide an automated pseudo-
labeling.

As an example, let us discuss the case of automaticaly labeling web collected data — a
method also known as webly-supervision. When categories of interest correspond to images
which can be found on online search tools using the labels as queries, such images may be
used to constitute an augmented dataset, or even an entire training set (which can be seen as
a form of zero-shot learning). Methods for learning from automatically collected web images
have been studied by several works across the years (e.g. Fergus et al, 2010; Chen and Gupta,
2015). Of course labels obtained in this fashion are not as trustworthy as careful expert manual
annotations. However, if the signal-to-noise ratio is suﬃcient, this dataset may be a useful
source of knowledge.

Using this kind of methodology, Kaur et al (2017) combined web-retrieved and manually
curated data in order to improve food image classiﬁcation. Similarly, Krause et al (2016) were
able to achieve state of art accuracy on ﬁne-grained classiﬁcation benchmarks in four domains:
dog breeds, bird species, Lepidoptera2 species as well as aircraft models. High accuracy could
already be reached using only web-collected noisy-labeled datasets, without any manually
annotated training samples from the original benchmark datasets. As expected, combining
both training sets yields even better performances.

Reasoning about the kinds of systematic label noise proper to the collection process can be
useful to ﬁlter out part of the ambiguous or out-of-domain examples in a given sample. For
instance Krause et al focused on reducing two types of noise: cross-domain — e.g. anything
other than a bird retrieved with a bird query — and cross-category – e.g. a bird example
incongruent with the query label used in retrieval. Their data analysis showed that, although
diﬃcult to remove without manual intervention, both types of noise could be managed.
Overall, cross-domain noise was not too high (max 34.2%) and tended to reduce with the
total quantity of retrieved images. With respect to cross-category noise, it could be reduced
via a heuristic of eliminating ambiguous images — those appearing in more than one search
result.

Of course this method is only applicable when the target domain is common enough
to have a high number of images freely available on the web. Such a drawback makes this
alternative highly infeasible in very speciﬁc applications, particularly within industry and
healthcare.

2a biological taxonomic order including butterﬂies and moths

96

5. Deep learning with limited data

5.3 Axis I: Get more data

5.3.2.3 Active learning

Much like semi-supervised strategies, active learning aims to make the most out of unla-
beled data, although in a complementary fashion. While semi-supervised learning is interested
in enriching model’s knowledge on the data distribution, active learning is concerned with
acquiring new knowledge on the label distribution in an eﬃcient manner. This is then a strat-
egy to be envisioned when a labeling expert has limited availability but can still contribute by
labeling a few extra samples. Furthermore, it can be combined with semi-supervised labeling
for possibly better results (see for instance Siméoni et al, 2019).

Due to the high level of expertise required in labeling, a common scenario for active
learning is the medical imagery domain. A recent example is the work by Folmsbee et al
(2018). This work is concerned with a particular health application — oral cavity cancer
image-based diagnosis — which has intrinsically low quantities of data with a costly expert-
dependent labeling process. Their pipeline of active learning has a specialist on the loop: it
aims to semi-automate the labeling task by having an initial model provide guess labels for
images. These weak labels are in turn qualitatively evaluated by the specialist who ranks them
according to his perception of their accuracy. The 5 worst-classiﬁed get labeled and used as
training set for another training session. This is repeated until either suﬃcient accuracy is
achieved or no more unlabeled samples are left. Their results show this procedure — after 3
iterations — increases ﬁnal accuracy by ∼3%.

The source of unlabeled examples may take multiple forms, from a simple pool of previ-
ously acquired data to an on-line stream of data. In either case, the main diﬀerence between
diﬀerent active learning proposals in general is the selection strategy applied over the unla-
beled set at each active learning cycle (also referred to as acquisition function). Such a cycle
alternates between model training and label acquisition, being repeated as long as needed or
data is available (see Settles, 2010, for a review).

For instance, when using an uncertainty sampling strategy, after being trained over a (small)
labeled dataset, model’s conﬁdence levels over its predictions are used to select samples for
labeling, focusing on those with the least conﬁdent predictions. While being a popular class
of acquisition functions, it depends on computing a reliable estimate of model uncertainty,
which is not always straightforward to obtain for neural network models. Wang et al (2017a)
have attempted using entropy of softmax predictions as an indicator of uncertainty, although
it has been observed by other works (see for instance Papernot and McDaniel, 2018) that
CNN softmax outputs can be very conﬁdently wrong. An eﬀective ensemble-based approach
has been used by Beluch et al (2018), although being a computationally heavy option since it
relies on training multiple CNN models. Less resource intensive selection schemes can be
achieved by exploring diﬀerent dropout paths inside the same network, as explored by Gal
et al (2017).

Besides considering selection of individual examples, another concern in deep active

97

5. Deep learning with limited data

5.3 Axis I: Get more data

learning is to select an eﬃcient query batch. In fact, most approaches have considered a
traditional active learning scenario where a few samples are selected at every cycle, not being
concerned with selecting suﬃciently large sets forming a representative sample of model
diﬃculties. In general, top-k unreliable predictions are selected, regardless of them being
very similar or representative of other unselected samples. Although it is a valid choice for
selecting a few samples, better schemes can be imagined when selecting a larger query batch
for labeling. Besides, since training CNNs is usually time demanding, requiring an expert to
wait for each training cycle for only then labeling a few samples is impractical, time-ineﬃcient
and potentially costly. Some works exploring this issue are Ash et al (2019); Gissin and
Shalev-Shwartz (2019); Kirsch et al (2019); Shui et al (2019); Yin et al (2017).

Despite all eﬀorts into designing a good selection strategy, it is often the case that diﬀerences
between diﬀerent uncertainty selection functions is quite minor. Furthermore, experiments
by Siméoni et al (2019) indicate these diﬀerences may be of low signiﬁcance for image
classiﬁcation with CNNs, when compared to the gains obtained by unsupervised pre-training
or semi-supervised learning based on label propagation (Iscen et al, 2019).

5.3.3 Related datasets

Datasets of similar nature, covering similar types of natural objects or scenes, can also be a
knowledge source when the target dataset is too small. Such data may be used to help learning
a useful feature representation space, in particular concerning lower level features, which
have a larger chance of being common between related datasets. Besides related image data,
other modalities can also be included during the representation learning process in order
to reduce the dependence from image examples — an idea taken to its extreme in zero-shot
learning (section 5.3.3.2).

5.3.3.1 Pre-training and fine-tuning

In the image recognition domain, the popularization of CNN models and the ImageNet
competition has lead to a situation where most mainstream models have open-access im-
plementations (in one or multiple major deep learning frameworks) and have their trained
weights available for download. Initially crafted for the 1000-classes prediction task, they
started being reused for other tasks and datasets, with minor adaptations, leading to suc-
cessful results (e.g. Razavian et al, 2014). This widespread re-use of supervised pre-trained
models is one of the most common forms of transfer learning , where at least source and
target tasks are diﬀerent (since the source and target categories diﬀer).

One way of proﬁting from a pre-trained model is to reuse the its learned weights, transfer-
ring at least those of the ﬁrst layers of a network trained for a task A to a network that will
perform a task B. Learning task B will train mostly the parameters of the ﬁnal layers, maybe

98

5. Deep learning with limited data

5.3 Axis I: Get more data

ﬁne-tuning the ones transferred from task A. This form of transfer learning can be seen as
a way to start training on better initial conditions. A simpler form of knowledge transfer is
to use the previously trained model as a feature extractor for a subsequent classiﬁer trained
on the target task, with the original weights not being adjusted at all during training (eg:
OverFeat + SVM Razavian et al, 2014). In this case no feature learning takes place over the
target dataset/task. Both methods work on the assumption that tasks A and B share some
low-level features. This seems to be particularly true for visual tasks, where reusing part of
a network trained with general image data has given surprising results in several domains,
such as dermatology diagnostics(Esteva et al, 2017), lesion detection on CT scans (Shin et al,
2016) and industrial machinery diagnosis (Xiao et al, 2019), to cite a few.

Unsupervised pre-training On a similar rationale of re-using a previously learned feature
representation space, it is also possible to learn a dedicated representation especially for the
task at hand. Under restricted labeled data, unlabeled samples can eventually be used in this
case. If the overall target dataset remains small, other related datasets may be necessary in
order to have suﬃcient information to guide model training. Once the representation is learned,
the model can be ﬁne tuned or used as a feature extractor, in the same way supervisedly
pre-trained models are used.

Generative models, like the ones discussed for data augmentation (section 5.3.1) can be
used for representation learning, given enough unlabeled and/or related data. Unsupervised
pre-training with autoencoders for instance, was commonly used in the early days of CNNs,
but less so in more recent works (Goodfellow et al, 2016f). Considering big data scenarios,
unsupervised pre-training — which ignores class information during early training — can
induce an excessive bias in the representation learned by the CNN leading to underﬁtting in
later supervised training. Under low-data regimes, however, this regularizing eﬀect can be
beneﬁcial, since overﬁtting is a greater concern.

Some variants of unsupervised representation learning are referred to as self-supervised,
in general when a proxy supervised task is designed such that supervision can be derived
automatically from the task deﬁnition. For instance (Doersch et al, 2015), a proxy task can be
to predict the spatial relationship between two image patches: is patch B above, below, left
of or right of patch A? By building a patch cropping procedure that keeps this information,
supervision is directly available from the data generation process itself. In this sense, the model
is said to be self-supervised because even only unlabeled data is available, and supervision is
implicit to the task the model is performing.

Metric learning Another form of learning a representation through a deep network is
to use metric learning losses (see Kaya and Bilge, 2019, for a review). These models do not
intend to model the data distribution directly. Instead, they target learning a representation
in which distances get preserved. The exact type of implicit geometric prior depends on the
choice of metric loss. A well-known example is Siamese networks, using contrastive loss

99

5. Deep learning with limited data

5.3 Axis I: Get more data

(e.g. Koch et al, 2015). This learning objective tries to minimize the distance between same
class sample pairs, while maximizing distance under diﬀerent class pairs. No higher order
relationships (among more than 2 points) are modeled in this case. Note that in general, for
a given set of samples, some form of supervision is necessary in order to decide between
maximizing or minimizing the corresponding distance term in the loss function. Hence it is
not a method capable of directly exploiting available unlabeled data, being more interesting
to apply to related source datasets (in a transfer learning paradigm). After learning some
form of geometric relationship among the input images, the learned mapping can be applied
to source or target datasets as a feature extractor. This same geometric nature allows the use
of a simple nearest-neighbors classiﬁer, though more complex schemes can be envisioned.

Fine-tuning weights and architecture When considering neural network models,
transfer learning usually comprises an architectural adaptation side, either because of a
diﬀerence in the number of classes in the dataset, or because the prediction task is inherently
diﬀerent. In Zeiler and Fergus (2014), their CNN model was originally targeted at ImageNet,
but they also tested it in other datasets by redesigning and retraining the ﬁnal layers to match
the new number of classes. In the case of a diﬀerent task, changing might be more extreme.
As an example let us consider semantic segmentation. In this task, where all pixels of an
image have to be individually classiﬁed, it is common to reuse pre-trained architectures but
changing the ﬁnal fully connected layers to convolutional ones (Shelhamer et al, 2017). For
such task, the multiple pooling layers have a major drawback of reducing resolution and
limiting the precision of the boundaries arising from the ﬁnal pixel-class prediction. With
that in mind, diﬀerent adaptations have been proposed such as skip-pooling connections
(Shelhamer et al, 2017), dilated (à trous) convolution (Chen et al, 2016; Yu and Koltun, 2016)
and even the use of a decoding architecture (Noh et al, 2016; Badrinarayanan et al, 2017).

Besides direct changes to the architecture, careful adjustment of hyperparameters for each
layer is crucial to a successful ﬁne-tuning. Experiments have observed more than doubled
accuracy after proper calibration of learning rates (Dube et al, 2018). Particularly, having
diﬀerent learning rates for last and internal layers — or even a graduation following layer
depth — can be signiﬁcantly beneﬁcial to ﬁnal accuracy. The intuition is that upper levels of
representation are more task speciﬁc thus needing more adjustment than lower ones. How far
the transferred layers should be kept untouched or ﬁne-tuned is related to multiple factors,
including the size of the target dataset, as demonstrated by Soekhoe et al (2016). Their overall
conclusion is: the smaller the target dataset is, the more rigid the weight transfer should be.
Another important factor is the nature of the datasets and tasks involved and how similar they
are between source and target domains. Fayek et al (2018) observed it to be more relevant
than the choice of architecture regarding representation transferability between domains or
tasks. Furthermore, this relationship is not necessarily symmetric: dataset A being relevant to
dataset B has no implication on the relevance of B to A.

100

5. Deep learning with limited data

5.3 Axis I: Get more data

In general, ﬁne-tuning a representation learned over diﬀerent source data is a helpful
form of transfer learning on small data. Obtaining good accuracy results is however not as
straight-forward as it may seem at a ﬁrst glance. While some intuitive relations between
dataset/task similarity and strength of ﬁne-tuning have been observed experimentally, there
is no systematic method to measure the former and choose the latter accordingly. For each
target task or dataset, only a case-based experimental analysis can guide decisions on how
much to keep from the original learned parameters.

5.3.3.2 Zero-shot learning

Zero-shot learning assumes a critical scenario where samples have to be classiﬁed into
categories which may have presented no labeled examples during training. The original
formulation of this problem assumes disjoint training and test label sets — i.e. none of the
categories seen during training are present in test time. In practice however, using a training
set as diverse as ImageNet ends up violating this assumption (since it may contain classes
which overlap with those in the test set) (Xian et al, 2018). An alternative formulation, dubbed
generalized zero-shot learning, assumes a broader test situation, where both seen and unseen
categories can be predicted. This setting poses an additional diﬃculty since most zero-shot
models tend to display a strong bias towards predicting seen training classes in detriment of
the unseen test ones (Rahman et al, 2018). Naturally, performance of current models in this
situation, which is closer to a real incremental learning, tends to be much lower than in simple
zero-shot learning, pointing to the need for further research on this topic (Xian et al, 2018).
As previously discussed, the lack of information — in this case the complete absence of
labeled training samples — has to be compensated with additional knowledge sources: some
prior information on the unseen target classes has to be used. Notice that, even though no
visual samples of test categories are available, zero-shot learning implicitly assumes that the
set of possible test labels is known. In that sense, at least some textual information — the
class label — can be used as a semantic target to gather information on the designated class.
Additionally, unsupervised textual data on the subject can be compiled into a word vector
representation, in order to leverage implicit knowledge from pre-trained word embeddings,
such as word2vec (Mikolov et al, 2013). These word models are often used in zero-shot
learning to help construct a mapping between category labels from seen and unseen classes.
The implicit semantic relationships represented in these embeddings may be suﬃciently
aligned to distinctive visual features allowing to discern between classes. In this way, the word
embedding allows a connection between training images and test labels, necessary for zero-
shot prediction for unseen categories. Leveraging information from a semantic embedding
requires some textual information to be available on all target categories (in order to link
images to words), implying all possible categories need to known beforehand.

Overall, all zero-shot learning methods have to address this base problem of connecting

101

5. Deep learning with limited data

5.4 Axis II: Reduce model complexity

Figure 5.4 Main architectural schemes for zero-shot learning.

observed and non-observed classes through some form of auxiliary information that is related
to their visually distinguishing properties Xian et al (2018). This may be done by:

(cid:73) joint learning of a visual-semantic class embedding;
(cid:73) learning of a compatibility function mapping from visual to semantic space or
(cid:73) mapping from semantic to visual space.

We schematized these methods in ﬁg. 5.4, including some literature examples. For a more
detailed review of zero-shot learning, refer to the survey by Xian et al (2018).

Being a very challenging task, accuracy in zero-shot learning is generally low, making
it unsuitable for practical applications. Nonetheless the methodology brings cross-modal
learning to the table, a path possibly worth exploring alongside direct learning over target
image samples

5.4 Axis II: Reduce model complexity

Restricting the parameter space on large models, such as DNNs, is typically an important
strategy to avoid overﬁtting, which is a major concern when dealing with small datasets.
Conventional measures of complexity (e.g. Radamacher complexity or VC-dimension) score

102

Feature extractors (e.g. pre-trained networks)Mappings to be learned for zero-shot predictionLabel spaceClassifierCompatibility functionImage embedding(e.g. CNN upper layers)Word embedding(e.g. word2vec)Semantic featurespaceVisual featurespaceCommon embedding spaceLabel spaceWord embedding(e.g. word2vec)Image embedding(e.g. CNN upper layers)Compatibility functionClassifierSemantic featurespaceVisual featurespaceAuxiliar data●Text attributes●Text descriptionImage dataLabel spaceClassifierCompatibility functionImage embedding(e.g. CNN upper layers)Word embedding(e.g. word2vec)Semantic featurespaceVisual featurespaceXian et al., 2016…Auxiliar data●Text attributes●Text descriptionImage dataAuxiliar data●Text attributes●Text descriptionImage dataChangpinyo et al., 2017Zhang et al., 2017…Common embedding spaceVisual to semantic mappingSemantic to visual mappingorFrome et al., 2013Rahman et al., 2018…Norouzi et al., 2014…5. Deep learning with limited data

5.4 Axis II: Reduce model complexity

high for such large models and thus predict low generalization capabilities, as well as extremely
high bounds for the amount of training data necessary (for a given error rate). At the same
time, the large parameter space of a deep model may be one reason behind its ability of
learning complex patterns through SGD optimization. In fact, recent progress with large
deep networks has also highlighted the fact that the relationship between their parameter
count and eﬀective model complexity is somewhat unclear (refer for instance to the survey
by Jakubovitz et al, 2018).

Being highly over-parametrized, DNNs have proven capable of perfectly ﬁtting training
data, even on randomized labels (Zhang et al, 2016a). Despite this apparent over-ﬁtting, they
are capable of retaining good generalization capabilities on real test data. This behavior is
counter-intuitive from a traditional statistical learning point of view, as it is not predicted by
usual model complexity measures. It is hypothesized that there exists some form of complexity
measure (and corresponding generalization bounds) that would score SGD-optimized DNNs
low enough in order to explain their perfect-ﬁtting-yet-generalizing capabilities (deriving such
measure is the subject of current theoretical research around deep learning, see for instance
Jakubovitz et al (2018); Neyshabur et al (2019)).

One heuristic explanation (Fan et al, 2019) is based on the limited power of SGD methods,
which are used for network training. The intuition is that even though the space of possible
functions is large, optimizing over real data has a tendency to explore only a sub-space of
lower complexity functions, resulting in a low “eﬀective complexity” model. It is as if the
choice of optimization method itself acted as an implicit regularization mechanism. From this
explanation, it stands out that controlling model complexity in deep networks is not simply
connected to model size, but also to how the parameter-space is explored. Both aspects are
discussed in the following sections.

5.4.1 Explicit regularization

Regularization methods are an integral part of machine learning and more importantly so
under data restriction circumstances (Kukačka et al, 2017). Traditionally in machine learning
literature, regularization is presented as a weighted penalty term added to the main loss
function (usually related to the training error). These constraints impose limits to the model
class being optimized, and are important for generalization, specially for convex optimization
models.

Nonetheless, it has become mainstream to regard regularization as any modiﬁcations to
the learning algorithm aimed at reducing generalization error, regardless of its inﬂuences
to training error (as implied by the deﬁnitions of Goodfellow et al, 2016e; Kukačka et al,
2017). Under this broader perspective, traditional penalty-based methods are referred to as
explicit regularization, while other more indirect methods are dubbed as implicit regularization.
Hernández-García and König (2019) propose a more precise deﬁnition of this division,

103

5. Deep learning with limited data

5.4 Axis II: Reduce model complexity

considering explicit regularization as any methods designed speciﬁcally to constrain model
capacity, without begin a fundamental part of the architecture. Any other methods having
regularizing eﬀects without bearing this intent fall into the implicit category.

This broader notion of regularization has opened space for multiple practices to be framed
as forms of implicit regularization, leading to multiple intersections with other categories
discussed in this review. For instance, referring to the survey by Kukačka et al (2017) on
regularization, data augmentation and other data transformations as well as the choice of
optimization methods, ensemble learning and other training strategies, are known for having
an eﬀective regularizing eﬀect. Given the breadth of this umbrella term, this section is focused
on explicit regularization forms. Relevant implicit methods are treated in their own speciﬁc
sections.

Regularizing weights Weight Lp -norm penalties are classical forms of explicit regulariza-
tion which have been used in machine learning for years. In particular, smoothness-inducing
L2-norm is one of the most commonly used. Less wide-spread in deep supervised models is
the use of sparsity-inducing L1-norm Beyond Lp-norms, weight-decay (e.g. Simonyan and
Zisserman, 2015; He et al, 2016a) and dropout variations (e.g. Srivastava et al, 2014; Wan et al,
2013) are the most common forms of explicit weight regularization. On one hand, weight
decay is equivalent to L2 penalties (see for instance Simonyan and Zisserman, 2015; He et al,
2016a), also acting as a smoothness-inducing prior. On the other hand, dropout techniques
have a more complex eﬀect. These methods randomly set to zero a percentage of neuronal
connections during each training iteration, preventing these synaptic weights from being
updated during gradient back propagation. As a result, a sparsity-analogous eﬀect is obtained:
even though the overall weight matrix is not sparse, samples tend to be somewhat sparsely
encoded, with fewer connections participating simultaneously for each single prediction.

In any case, explicit weight regularization methods often target a rather direct reduction
of the eﬀective number of parameters. As previously mentioned, this simpliﬁed link between
parameter count and model complexity seems not to be a suitable theory for describing deep
networks behavior. Other assumptions, not directly connected with reducing the number of
parameters, could lead to designing more appropriate regularization mechanisms. Advances
on this theoretical front may lead to better insights on if and how connections should (not) be
constrained. Let us consider for instance the assumption that a well generalizing model should
be robust to small input perturbations. By analogy with dynamic systems, such stability to
inputs is characterized by matrices with low spectral norm. With this intuition in mind,
Yoshida and Miyato (2017) have proposed this norm as a new form weight regularization.
Their experiments on CIFAR-10 show smaller generalization gaps and higher test accuracy,
although no results under smaller training (sub-)sets are provided.

Regularizing internal representations A general form of regularizing weights indi-
rectly is to impose structural constraints to representations learned by particular layers. For

104

5. Deep learning with limited data

5.4 Axis II: Reduce model complexity

instance, the work by Zhu et al (2017b) has indeed analyzed how their proposed regulariza-
tion inﬂuences generalization on small training sub-sets (of MNIST, CIFAR-10, SVHN). Using
manifold regularization, they have observed improved generalization gap for decreasing train-
ing set sizes on all three datasets, when compared to weight decay or dropout regularization.
This work is an example of regularizing internal representations so they meet pre-deﬁned
criteria, which in this case is to get data points to lie close to some low dimensional manifold.
Coordinates on this ideal manifold are estimated as the CNN weight training progresses, in an
alternate optimization loop3. In practice, regularization is implemented through a proximity
term enforcing conformation of internal representation to the estimated manifold coordinates
for each data point.

Also aiming for learning on small datasets, Belharbi et al (2017) propose a regularization
that constrains hidden layers to learn class-wise invariant representations. Their regularization
term is basically a sum of pairwise distances between points of the same class, for each class,
thus enforcing same-class cluster to be formed. Similar functions involving pairwise distances
— such as contrastive loss (Koch et al, 2015), N-pair (Sohn, 2016) or triplet loss (Schroﬀ
et al, 2015) — have been used for deep metric learning with CNNs in order to learn class-
discriminant representations. On the same line, the regularization term proposed by Cheng
et al (2018) also focuses on maximizing inter-class separation (and also minimizing intra-class
scatter), with pairwise distances composed with a hinge function as regularizing loss term.
In this work a discriminative-stacked autoencoder is trained in two stages — unsupervised
metric learning then supervised with metric learning regularization — in order to obtain a
classiﬁer model.

Despite similarities, it is worth noting they target a slightly diﬀerent task: the latter solves
image set classiﬁcation as opposed to its single image counterpart. Moreover, it applies the
metric learning regularization on all hidden layers, while Belharbi et al (2017) have observed
better results if the penalty is applied only on the latter layers. Notice however that they
focus on similar pairs to enforce intra-class similarity , relying solely on the classiﬁcation
cross-entropy loss to learn inter-class distance. This latter loss term tends to have a greater
inﬂuence on later layers and less so on earlier ones. Alternatively, Cheng et al (2018), also
include dissimilar pairs in the metric learning loss, bringing both inﬂuences to all layers,
which could explain the usefulness of their term on earlier layers.

Experiments by Belharbi et al (2017) have demonstrated signiﬁcant improvements on
reduced training subsets, when regularization is applied to the last hidden layer, although tests
were only performed on MNIST data. On their turn, Cheng et al (2018) obtained successful
results on four face recognition datasets as well as on the ETH-80 object recognition dataset.
Overall, metric-based regularization seems promising, particularly considering the success of
similar metric learning loss functions applied to ﬁne-grained classiﬁcation (e.g. Movshovitz-

3more speciﬁcally using alternating direction method of multipliers (ADMM) (Boyd et al, 2011)

105

5. Deep learning with limited data

5.4 Axis II: Reduce model complexity

Attias et al, 2017) and face recognition (Schroﬀ et al, 2015).

Regularizing network’s output Some output regularization methods are particularly
useful in conjunction with data augmentation or semi-supervised learning (Berthelot et al,
2019). In fact unsupervised loss terms in semi-supervised settings (previously discussed in
section 5.3.2.1) are also a form of regularizing networks output, as well as metric learning
losses. Let us consider the example of consistency regularization. In this case the objective is
to enforce an example and its augmented variants to have all the same label, with an unsu-
pervised loss. This type of penalty may also intervene in any case of randomized treatment
of the original samples, such as randomized transformations or diﬀerent dropout trials. An
example is the transformation-stability loss term proposed by Sajjadi et al (2016), which was
applied to a few typical image benchmark datasets, including ImageNet. They simulated a
small labeled sample setting by training with only a portion of available labels and could
reduce the error rate for all the datasets tested.

5.4.2 Architecture adaptation

Architectural choices can have an important impact on the learning capability of the model
and thus can be a lever for enhancing learning from small datasets. On one hand, simple
architectural changes may directly result in reducing the total number of parameters. On the
other hand, more structured adaptations may relocate computational resources in a manner
more appropriate to the target task at hand. In any case, structure can be introduced both
within and between layers as will be discussed bellow. Such modiﬁcations can be inspired
from domain-speciﬁc expertise, after a thorough analysis of the functional elements involved
in the accomplishment of a particular target task.

5.4.2.1 Intra-layer structure

At a lower level, structuring weights inside layers can be a means to reduce the total number
of parameters and model complexity. A classical example is the weights of convolutional
layers. As discussed in section 2.2.1, convolutional layers act as locally connected layers with
shared weights, in comparison to fully connected deep architectures. These two characteristics
— local connections and weight sharing — eﬀectively reduce the number of parameters and
can be considered in other applications that could beneﬁt from the translation equivalence
intrinsic to this connectivity pattern. Analogously, domain speciﬁcity may also motivate the
design of particular layers and connectivity schemes which could be helpful in achieving
better solutions for a data-restrained task.

Instead of assuming scalar values, the entries of a weight matrix can follow a family
of suitable functions that will enforce certain invariances (e.g., weights as a function of an
angle or a scale-factor in relation with rotation or zoom invariance) and symmetries (e.g.

106

5. Deep learning with limited data

5.4 Axis II: Reduce model complexity

isotropic diﬀusion, or linear combination of horizontal and vertical diﬀusion) speciﬁc to the
application domain. It is the case for Gabor CNNs (Luan et al, 2018) which modulates kernel
matrices with random pre-deﬁned Gabor ﬁlters, in an aim to improve invariance to scale
and orientation. Other examples of achitectural adaptations building rotation invariance are
the transform-invariant-pooling layer (Laptev et al, 2016) — which focuses on the response
of the main orientation within the feature map — and also Oriented Response Networks
(ORN) (Follmann and Bottger, 2018) — which rotate kernels in multiple directions before
convolutions. These models can achieve performances comparable or superior to state-of-the-
art models, using a smaller number of parameters.

Another track is (by analogy with the kernel trick) to consider linear combination of
predeﬁned local operators, each operator being known as eﬃcient to extract some cue. This
includes also non-linear combination, as for instance, considering normalized gain control.
The idea here would be to go toward something more generic thanks to these combinations
and consequently less “expensive”. An example is to constrain kernels to be spatially separable,
as done in (Sironi et al, 2015), which reduces the number of free parameters. This technique
has been applied to modern CNNs such as Xception (Chollet, 2016) and MobileNet (Howard
et al, 2017).

Some works have tried to reduce the number of synaptic weights by iterating a network
pruning step and a re-training step. This idea of optimizing network connections a posteriori
is not new (LeCun et al, 1990b; Hassibi et al, 1993), but just recently has been applied to
deep architectures. For instance, in the work of Han et al (2015), the ﬁrst training pass aims
at getting a coarse connectivity pattern, by thresholding out weak connections. Then they
re-train to actually learn weights, iterating between pruning and re-training.

While the strategies mentioned in this section can reduce model complexity, their helpful-

ness under limited data has not yet been experimentally explored.

Eliminating weights or simplifying the connectivity pattern explicitly reduces the space
of learnable hypothesis, and may have unexpected qualitative eﬀects on the results of SGD
optimization. Nonetheless they are expected to be helpful whenever the targeted invariances
are relevant to the task at hand.

5.4.2.2 Inter-layer structure

Besides introducing structure into the convolutional layers, layers and layer groups can
be designed to a particular function, with dedicated modular inter-connections. Moreover,
shortcuts or recurrent connections may lead to an eased optimization ( refer to sections 3.3.2
and 4.3, where several such examples have been discussed). We recall here some previously
cited examples:

(cid:73) Feedback connections can implement an iterative attention reﬁnement mechanism as

done by Fu et al (2017) for ﬁne grained bird species recognition;

107

5. Deep learning with limited data

5.4 Axis II: Reduce model complexity

(cid:73) Multiple glimpses of an object can be integrated with a dedicated attentional architecture

(Ba et al, 2015);

(cid:73) Adding feedback connections to standard models can improve ﬁne-grained classiﬁcation

(Zamir et al, 2017).

Again, under limited data, over-complexifying the model should be avoided, and only resorted
to if simpler architectures do not meet performance requirements. In that case, adaptations
shall always be motivated by intrinsic properties of the domain or task at hand.

5.4.3 Training strategies

Training strategies may not explicitly reduce the number of parameters, but may alleviate
the optimization burden while incorporating knowledge from diﬀerent sources. This section
covers such techniques which, while not acting directly on network architecture, can reduce
the complexity of ﬁnding a good model within a given model class.

5.4.3.1 Meta-learning: learning to learn

Meta-learning refers to techniques which try to accumulate “experience” from solving
multiple source tasks in order to more eﬀectively tackle a given target task. In other words,
the designed system would be learning to learn, during a meta-training phase, in order to be a
better learner on a speciﬁc task — during a meta-testing phase. In a broad sense, any method
accumulating information from accessory tasks and data can be placed under this category,
which could include for instance most techniques discussed in section 5.3. (see Vanschoren,
2018, for a review).

Regarding CNNs and image classiﬁcation, diﬀerent strategies of meta-learning have been
applied. Beyond generically learning to learn, meta-learning methods may have several
focuses, as identiﬁed by Shu et al (2018). For instance Finn et al (2017) method learns to learn
a good initial state for further ﬁne-tuning, in what can be seen as learning to transfer learn.
Alternatively, some methods will meta-learn (part of) the optimization algorithm, in what
can be seen as learning to optimize. An example is the work by Ravi and Larochelle (2017)
which uses an LSTM meta-learner to learn how to provide a good learning rate sequence for
network training. Proposals in this ﬁeld have multiplied over the past few years, making it
premature to deﬁne a strong taxonomy of meta-deep-learning approaches (refer to the survey
of Vanschoren (2018) for a speciﬁc overview). Considering the intended scope of this review,
the focus hereafter will be on one-shot and few-shot learning applications of meta-learning.

One and Few-shot learning In the recent context of deep networks, these methods are
often applied in the context of limited data, to solving classiﬁcations tasks with only a few
samples per class: few-shot and one-shot learning. Few-shot learning refers to classiﬁcation

108

5. Deep learning with limited data

5.4 Axis II: Reduce model complexity

tasks where a model is to learn to discriminate between N unseen classes given k examples of
each, with k usually below 5 (Triantaﬁllou et al, 2017). One-shot learning corresponds to the
speciﬁc case where k = 1. This class of tasks is usually referred to in the form k-shot N -way
tasks.

Most works on this track use similar data during both meta-training and meta-testing
phases, with disjoint class sets (e.g. Vinyals et al, 2016; Ravi and Larochelle, 2017; Snell et al,
2017; Finn et al, 2017, to name a few). During meta-training, the classiﬁer model is trained
sequentially on similar k-shot N -way tasks, each time on a diﬀerent set of N classes. After
accumulating experience in discriminating between N classes with only k samples for each,
the model is ﬁnally trained on the target set of N classes. This organization of the meta-training
process is referred to as episodic training (ﬁrst presented by Vinyals et al, 2016).

Applying this framework in practice thus requires such a similar (labeled) dataset, which
may not be a realistic assumption in certain domains. Indeed the development of few-shot
learning has mainly turned around benchmark datasets — mainly Omniglot (multi-alphabet
character recognition) and mini-Imagenet ( subset of classes from main ImageNet) — which
have a large quantity of images in total due to a very large number of classes. Therefore, by
using all non-target classes during meta-training, learning ends being up still dependent on
a signiﬁcant amount of labeled data. As with any transfer learning approach, the closer the
source data distribution is to the target data distribution, the more helpful the knowledge
accumulated from source data should be. Again, in practice, available data may not be as
similar as it is the case with these benchmarks.

Nevertheless, some works have successfully applied meta-learning strategies to very spe-
ciﬁc domains. For instance, Prabhu et al (2018) tackle a complicated problem of dermatological
diagnosis. The class distribution in this task has challenging characteristics intrinsic to the
data generation process. Firstly, it is heavily imbalanced due to some skin conditions being
much more prevalent than others. Secondly, each class sample is highly heterogeneous, as a
single diagnostic category may present itself under several visually diﬀerent skin conditions.
Starting from plain prototypical networks — a well known method in the few-shot learning
community by Snell et al (2017) — they propose an adapted version that accommodates for
the multi-modal nature of these classes. Out of 200 diﬀerent classes, the largest 150 base classes
are used as meta-training data, while the 50 remaining are targeted during meta-testing — as
if they were “novel” classes. They could achieve an average precision around 30% on 5-shot
and 50% on 10-shot tasks — the best results they achieved with pre-trained and ﬁne-tuned
networks stay around 20% and 40% , respectively.

5.4.3.2 Curriculum learning

Considering the human ability to learn, it seems natural to carry learning from simpler to
more complex concepts, building-up connections amongst them or deﬁning derived notions

109

5. Deep learning with limited data

5.4 Axis II: Reduce model complexity

from such concepts. Indeed not only humans but also many animal species have been observed
to learn better when examples are not randomly presented but organized in a meaningful
order, focusing on the learner’s zone of proximal development — presented in educational
research as learning objectives attainable with some expert guidance (see for instance Matusov,
2001; Walker, 2010).

Designing such organization or curriculum for human learning is traditionally an object
of study for educational research and cognitive sciences. Nevertheless, this concept has
inspired works exploring curriculum learning in the context of machine learning (Bengio
et al, 2009), including for deep networks(Hacohen and Weinshall, 2019). Translated to the
machine learning context, the goal of curriculum learning is to propose an order on training
samples according to their estimated diﬃculty so as to achieve better generalization and/or
faster convergence during training (Hacohen and Weinshall, 2019). Indirectly the method is
analogous to numerical continuation methods (Gulcehre et al, 2016), in the sense that it will
start with a simpler model — due to the focus on easier parts of the data being modeled —
that will slowly be deformed into a more complex one — as the more diﬃcult data points are
joined into the mini-batches.

In general, a curriculum learning policy requires the deﬁnition of two functions. First, a
scoring function that estimates the diﬃculty level of a sample. Second, a pacing function that
deﬁnes which and how many samples will be considered at each training iteration. In the
context of SGD-based training, it resolves to a function sampling and proposing a sequence
of mini-batches. Diﬀerent proposals vary mainly on choices made in the design of these two
functions.

For instance, Weinshall et al (2018) have obtained a scoring function via transfer learning.
After training an SVM classiﬁer on top of pre-trained CNN features, its margin-related
prediction conﬁdence was used as a diﬃculty score. Pacing was determined by a step-based
increasing policy, either with ﬁxed size or adaptive steps (considering the current training loss
value). This step policy was responsible for increasing the probability of harder examples being
chosen for a mini-batch as training progresses. Hacohen and Weinshall (2019) extend these
experiments, additionally exploring a self-taught scoring function and diﬀerent exponential
decay pacing functions.

Related methods The core ideas of curriculum learning have inspired other related tech-
niques such as curriculum dropout — an adaptation of the usual regularization technique
that dynamically increases dropout rate during training (Morerio et al, 2017). The supporting
rationale is that feature co-adaptation — which dropout aims to prevent — is unlikely to occur
early during training. Instead, dropout would be needlessly complicating the task way too
early. With curriculum dropout, this diﬃculty is gradually increased. In practice, small test
accuracy improvements (at most +1%) have been observed across most image benchmarks
considered by Morerio et al.

110

5. Deep learning with limited data

5.4 Axis II: Reduce model complexity

The general principle of increasing diﬃculties can also be applied to the decision procedure
of a classiﬁer, when a class hierarchy is available. One such example is the recurrent model by
Zamir et al (2017) (discussed in chapter 4), which reﬁnes its predictions iteratively after each
recurrence step. Since a valid output is provided at every iteration, it is possible to change
target labels at each iteration, gradually increasing their speciﬁcity within the class hierarchy.
Guiding learning from coarser to ﬁner-grained targets is a means of enforcing a curriculum
by leading the model to make easy-to-hard decisions (for instance, ﬁrst decide for a vehicle,
then for a bike, then for tandem bike).

Overall, curriculum learning has experimentally demonstrated being capable of speeding
up convergence during early training and, on more diﬃcult tasks (eg. ﬁner grained distinc-
tions), achieving local minima which improve generalization (Weinshall et al, 2018; Hacohen
and Weinshall, 2019). On a simpler setting — that of a convex linear model — Weinshall et al
have theoretically demonstrated this convergence property, which stems from the expected
variance of gradients across samples with increasing diﬃculty. The higher the sample diﬃ-
culty, the higher the gradient variance on that point, increasing the chances of steering oﬀ the
local optima leading path. There may also be a link to numerical continuation, a method that
can also lead to a generalization boost. Nevertheless, such improvements may only be noticed
on harder tasks, in which class distinguishing features are not so clear. This may also be the
case when learning over small datasets, although this perspective is yet to be experimentally
validated.

5.4.3.3 Multi-task learning

The general idea of multi-task learning is to leverage domain-speciﬁc information from
related training tasks in order to improve generalization on the target task. While it remains
unclear what deﬁnes a related task (Ruder, 2017a, reviews some deﬁnitions), in the context of
DCNNs it is intuitive to think of tasks which share internal representation levels. Thus it is
straightforward to think of multiple tasks sharing early layer parameters. Indeed, typical multi-
task strategies applied to deep models involve some form of shared representation learning,
either by hard parameter sharing (wired within the architecture) or constraint-enforced soft
parameter sharing. A down-side of these approaches is that, besides using some domain-
speciﬁc intuitions, there is no principled way of deciding which levels of representations to
share between the two tasks. A less heavy bias is possible in soft sharing, particularly with
architectures which dedicate resources (i.e. speciﬁc layers with learnable parameters) to learn
what to share.

Using auxiliary tasks Beyond explicitly sharing features, multi-tasking can intervene
directly as a training strategy, by the means of relevant auxiliary tasks. Again, what is consid-
ered “relevant” may vary widely among diﬀerent domains. A series of examples are raised

111

5. Deep learning with limited data

5.5 Conclusion

by Ruder (2017a), of which a few are worth mentioning hereafter. When parts of the input
are more diﬃcult to be learned, an auxiliary task can be to focus speciﬁcally on these parts. It
was the case of semantic segmentation for autonomous driving in the work of Caruana (1997)
in which an extra task detecting only road lanes (which form a small portion of the typical
images) helped them being more detectable by the main task. In cases where there are extra
features (e.g. domain-related meta-data) which are not being used as input, an auxiliary task
can be to predict these features from the input image.

When predicting ﬁne-grained categories, an auxiliary task of making coarser predictions on
super-classes can help guide the learned representation towards a more class-related structure.
It can happen for instance in medical diagnosis, if the diﬀerent conditions being predicted
can be grouped into coarser groups according to a 3-stage risk scale (e.g. low, medium or
high). Again, focusing on the representation structure, auxiliary tasks of autoencoding or
metric learning can also be applied.

After all, the adequate auxiliary task is highly dependent on the available side-data and
the domain of application. Reﬂecting on how the target task can be decomposed and which
are its main diﬃculties can help identify points which could beneﬁt from this extra bias.
Another remaining design choice is how to balance between target and auxiliary tasks. Besides
weighing between the two, one might imagine to dynamically increase the inﬂuence of the
latter across training epochs, aiming at enforcing the introduced bias to avoid overﬁtting
during late training.

5.5 Conclusion

Deep learning with small data samples is a complex task, that can be made possible if
additional sources of knowledge — including domain speciﬁc expertise — get incorporated
into the learning process. On one hand, novel information may come from incorporating
more data into the mix. This includes data augmentation, use of unlabeled data, other related
datasets or even cross-domain data. On the other hand, knowledge can impact choices that
eﬀectively reduce model complexity — either by regularizing its capacity or by guiding
training process through particular strategies.

Overall, there are multiple ways of reducing the complexity of deep learning with small
data samples. However, each of them has a limited impact and has its own drawbacks and
diﬃculties. Besides, the impact of combined measures can sometimes be deleterious and has
not been extensively studied. Without a universal solution, each target application needs to
be analyzed on its strengths and diﬃculties, compared to other tasks studied in literature, in
order to identify promising strategies.

112

Chapter 6

Analysis of DCNN applied to small sample learning
using data prototypes

Note: This chapter has been published as a journal paper:

Drumond et al, 2019.
using data-prototypes”.
1662-5188.

doi: 10.3389/fncom.2018.00100 .

“Bio-inspired analysis of deep learning on not-so-big data
ISSN

Frontiers in Computational Neuroscience, 12, 100.

6.1 Introduction

Deep neural networks have had a great success in many domains, especially in visual
recognition tasks. From AlexNet in 2012 (Krizhevsky et al, 2012) to Residual Networks in 2015
(He et al, 2016a), this class of models has shown outstanding performances at the Large Scale
Image Recognition Challenge (aka ImageNet), motivating the use of deep learning in multiple
domains such as speech recognition and language processing (LeCun et al, 2015). The key
idea is that, at least for threshold units with positive weights, reducing the number of layers
induces an exponential complexity increase for the same input/output function (Håstad and
Goldmann, 1991). On the reverse, it is a reasonable assumption, numerically veriﬁed, that
increasing the number of layers yields an input/output function compact representation1, as
a hierarchical composition of local functions (Goodfellow et al, 2016c).

6.1.1 The data requirement challenge

However, deep learning remains very ineﬃcient concerning data requirements. Most
successful results are reported on large databases. For the simple handwritten digit recognition
task, on the MNIST database we were already at 60K images for 10 classes (Lecun et al,
1998). For the complex ImageNet challenge, we reached more than 1M images for 1K classes
(Krizhevsky et al, 2012). While large tech companies may have access to large amounts
of labeled and unlabeled data, this is not the case in many domains, where the ability to

1Here compact means that adding a network layer allows a better input-output mapping approximation or a
mapping considering a higher functional sub-space for a number of units which would have been exponentially
higher with decreasing the number of layers.

113

6. DCNNs with data-prototypes

6.1 Introduction

generalize from only a few tenths of examples per class is required. This limitation not only
concerns industrial application requirements but is also a strong limitation as far as modeling
cognitive processes is concerned.

Elaborating over this necessity, Mouret (2016) argues for the three basic precepts to deal
with small corpus of data, also called micro-data learning: (i) actively search about which
is the most relevant data to consider (active learning), (ii) exploit every bit of information
(detailed learning), (iii) use as much as possible prior knowledge. In fact, the quick learning
ability of humans and animals is largely due to our prior knowledge about the world we
interact with and is referred to as transfer learning (Weiss et al, 2016). This can be performed
considering general knowledge, beyond ad-hoc application dependent choices. In practice,
learning from limited data often requires embedding of prior knowledge at some stage, be it
at the input data pre-processing, the architecture choice, cost functions and regularization
rules, or even as smart training strategies. Following this track are works focused in few-shot
learning (Dong et al, 2017; Rahman et al, 2018), which deals with very few learning samples
(usually less than ten), when not only one sample, or zero (i.e., only a priori information).

We would like to study how to investigate a middle range of a few tenths of samples.
We may call this situation “not-so-big-data”. The rational for this is two-fold: On one hand
it appears that learning entirely new concepts of forms in human (e.g., reading characters
(Leroy, 1967)) does not require one or a very few number of samples, but more than ten. On
the other hand, several industrial applications are able to provide ten to hundred samples for
a given perceptual tasks, but not thousands. Such not-so-big-data learning is an extension of
few-shot and micro-data learning, reusing several key features such as transfer learning, as
reviewed in the section 6.2.2.

6.1.2 The interpretability issue

A step further, we argue that in order to be able to introduce prior knowledge at a general
level (and not only using an ad-hoc mechanism limited to a single application), the lever is to
provide an interpretable processing. Interpretable mechanisms can help to better tune the
architecture with small data set, as discussed in this paper. Interpretability also requires a
data description easy to explain to a lay audience, and means to provide an explanation for
algorithmic decisions that may aﬀect citizen life. We have such requirement in mind in this
contribution, as already addressed in Drumond et al (2017b).

When considering such an issue in the present literature (e.g., in Kim et al (2016), or Zhao
and Park (2016) it appears that interpretability is understood as “results are interpretable”.
However, if we really want to propose some easy to share and explainable mechanism, in order
to be able to state that the process is transparent, we must not only look for interpretable results.
We also must attempt to consider easily understood processes, i.e. interpretable mechanisms.
This is the reason why in this paper we are going to take the risk to study to which extent

114

6. DCNNs with data-prototypes

6.1 Introduction

a “non trivial but easy to explain” mechanism, used with a small amount of data, can still
provide performances close to the best state of the art performances.

6.1.3 On network architecture

One of the intuitions behind the success of deep learning is that stacking multiple layers
induces learning of a hierarchical representation, a successive composition of local functions
that ends up describing higher level concepts as reviewed in e.g., (Bengio and LeCun, 2007).
This includes, for convolutional neural networks (CNN) with weight sharing, the capability to
take global, e.g., translational invariant, features into account (Goodfellow et al, 2016b). That
aspect of deep architectures has a strong parallel with our current knowledge of representa-
tions in the brain, especially in the visual pathway from retina until the infero-temporal cortex,
where object identiﬁcation is performed. This feed-forward pathway is indeed hierarchical and
is responsible for our primary (ﬁrst ≈ 100 ms) visual identiﬁcation capabilities (Fabre-Thorpe
et al, 1998). When considering, however, the complete visual system, a simple feed-forward
pipeline cannot represent all the computations taking place in the brain. Identiﬁcation is only
part of our visual system, namely the What ventral pathway, associated to the Where-How
dorsal pathway (Milner and Goodale, 1995). Furthermore, there are dynamic mechanisms,
feedback modulations, shortcuts, lateral inhibition, to cite a few, that are often disregarded
(Medathati et al, 2016).

Concerning the connectivity patterns within the visual system (Bullier, 2001), the capa-
bility to mix features from diﬀerent levels of the hierarchy, as observed regarding the role
of the pulvinar (Cortes, 2012), has to be considered. Integrating focus of attention within
certain regions of the feature space (Saalmann et al, 2012), and other functionalities such as
on-the-ﬂy adaptation to incoming data, in link with the few-short learning paradigm (further
discussed in section 6.2.2) is also important to take into account2. All these functionalities
require rather general recurrent architectures (Medathati et al, 2016). The possibility to pro-
vide a framework in which not only feed-forward or speciﬁc recurrent architectures can be
taken into account is addressed by other works (Viéville et al, 2017) and is beyond the scope
of this paper. The present proposal is mainly inspired on how the infero-temporal cortex has
a kind of prototypical representation, with neurons tuned to respond to particular categories
(Viéville and Crahay, 2004b).

2Further aspects of feed-back functionality, such as on-line computations with feed-backs, will not be consid-

ered here.

115

6. DCNNs with data-prototypes

6.1 Introduction

6.1.4 Hyperparameter dependence

Automated machine learning3 is “the process of automating the end-to-end process of
machine learning”, because the complexity of adjusting the hyperparameters, including
selecting a suitable method, becomes easily time-consuming when not intractable. To this end,
the general idea is to consider a standard machine-learning algorithm and to add on “top of
it” another algorithmic mechanism, e.g., another machine learning algorithm dedicated to
automatic hyperparameter adjustment, with the caveat of generating other hyperparameters
for the meta-learning algorithm and without formal guaranty that this accumulation of
mechanisms is optimal.

What corresponds to hyperparameters in the brain or for a fully autonomous system
is managed in three ways: It is either modulated by other structures (such as the diﬀerent
cortico-thalamic pathways through the basal ganglia (McHaﬃe et al, 2005)) and at diﬀerent
time-scales (such as short-term versus long-term synaptic plasticity (Cooper et al, 2004)), or
integrated as learning parameters, the system being able to learn new parameters and to adapt
also the way it learns as a coherent process. A third track is to design robust processes in the
sense that hyperparameters precise values are not critical. A key issue in a distributed system
such as the brain, is that hyperparameters are usually global while still implemented via local
processes (e.g., neuro-modulation). Some are also related to the network construction (e.g.,
the number of layers).

Here we are going to carefully study these aspects, in order to make explicit to which
extents the proposed method is related to robust hyperparameters, thus without requirement
about questionable value adjustment. If not, the hyperparameter adjustment is going to be
managed using standard hyperparameter adjustment methods, and the interpretability of
the such meta-parameter adjustment is also going to be made explicit.

6.1.5 The present contribution

Bio-inspired improvements of deep learning extend far beyond the three issues reviewed
here, as discussed recently in Marcus (2018). The biological plausibility of deep-learning is
another issue, see Bengio et al (2016) for a recent discussion. In a nutshell, there is a clear
correlation between deep-learning CNN states and the primary visual cortex macroscopic
activity as observed in Mensch et al (2017), while the contribution of deep-learning as a tool to
better understand the brain is not obvious as explained in Medathati et al (2016). Nevertheless
these issues are beyond the scope of this paper.

Here we would like to revisit the notion of prototypes, as a tool to improve deep learning
on not-so-big data, considering some aspects of the brain architecture and addressing also

3The notions of “automated-machine-learning”, “meta-learning”, including “meta-optimization” and “hy-
perparameter” and the related “hyperparameter optimization”, have precise meaning in machine-learning, and
we assume this is known to the reader.

116

6. DCNNs with data-prototypes

6.2 Related works

the hyperparameter dependence issue. There are multiple deﬁnitions and usages of what is
called prototypes. Here prototypes are centers of a k-means procedure over training samples,
acting as data-representatives in the feature space. The present work explores this notion of
prototypes for interpretability and classiﬁcation under not-so-big datasets, building up on
the idea introduced in Drumond et al (2017b) with more comprehensive experiments on real
datasets and including comparison with few-shot meta-learning methodologies. This work
focuses on convolutional networks and applications to vision, although what is proposed in
this paper is general and applicable to other deep learning frameworks.

Our main claim is that such data prototypes may help address the not-so-big data issue
in an interpretable fashion, considering a few bio-inspired aspects made explicit in this
introduction. Proposing a solution to both aforementioned issues — “not-so-big-data” learning
together with data and process interpretability — is the main contribution of the paper. The
key point of our proposal is the notion of data prototypes, as made explicit in the sequel. In
order to introduce this notion, we need to discuss one aspect of network architecture and
point out issues regarding the hyperparameters.

In the next section we are going to review the literature related to this subject, then
formalize the model description, in order to experiment the idea in the subsequent section,
allowing us to discuss based on these results how the issues quoted here can be addressed,
while proposing several perspectives of this work.

6.2 Related works

6.2.1 Prototypes in literature

The term prototypes can be found in the literature under diﬀerent meanings: a priori

information, representation in clusters, quantiﬁcation of space, as we discuss now.

Jetley et al (2015) proposes a prototypical priors layer, with a priori chosen prototype
images of road signs, encoded using a HoG (histogram of oriented gradients) descriptor, and
added as ﬁxed units of the penultimate layer. Here, the network is ultimately trained to match
the HoG representation of the prototypes but it is assumed to exist a standard representative
image per class in the input space to be encoded as a prototype unit.

In prototypical networks (Snell et al, 2017), prototypes are deﬁned as class centroids in
the feature space spanned by the embedding CNN. In this simple approach, the nearest-
prototype is used to classify a given sample. This proved to be eﬀective on the considered
datasets. However, this does not respond to the scenario of metric learning proposed in (Song
et al, 2017). Also derived from this work, Gaussian prototypical networks (Fort, 2017) predict
a covariance radius for each prototype, yielding some insight on the discriminating force of
each of them.

117

6. DCNNs with data-prototypes

6.2 Related works

Self-organizing maps, or the dictionary sparse representation methods (Rubinstein et al,
2010), perform a prototypical sampling on the data space (Hecht and Gepperth, 2016) and
allow to represent what is known about a data distribution, using methods quoted in proto-
typical networks and known as optimizing statistical criteria (Banerjee et al, 2005).

Bio-inspired models also consider the notion of prototypes, as in, e.g., (Serre et al, 2007)
which introduce a general framework for the recognition of complex visual scenes, that follows
the organization of visual cortex building an increasingly complex and invariant feature
representation and considering a redundant dictionary of features for object categorization.
Furthermore, (Viéville and Crahay, 2004b) has related the notion of prototypes to a SVM
model of the inferior temporal object recognition brain area.

6.2.2 Few-shot learning and learning to learn

The importance of learning new concepts from small data-sets motivated the study of
few-shot learning tasks. Few-shot learning refers to the ability of learning to discriminate
between N unseen classes given k examples of each, with k usually below 5 (Triantaﬁllou et al,
2017). This task is also referred to as k-shot N-way learning. One-shot learning is a special
case of this setting, where the system must generalize from a single example for each class.
Slightly diﬀerent is zero-shot learning, where no example of a given class is available in the
target domain (e.g., images) whereas information on the categories originates from other
domains (e.g., textual descriptions) (Goodfellow et al, 2016f).

Learning a deep discriminative model for a large number of classes has high data require-
ment, and is prone to overﬁtting if applied directly in a few-shot data framework. For this
reason, usually some form of transfer learning is used to tackle this problem: a model is
trained on other classes before attacking the N new ones. Since the model learned in this
pre-training phase will have to be adapted to the target classes, few-shot classiﬁcation can also
be seen as a form of “learning how to learn”, which is a very sensible framework when the
goal is to learn whichever new categories to come. In this spirit, pre-training is a meta-training
phase, where we learn a meta-model that can learn any set of N classes given to it. Using the
model on new k-shot N-way tasks corresponds to a meta-testing phase, where for each task
some inner training may take place.

There are diﬀerent ways of implementing this meta-learning setting 4, but any such should
have a meta-training and meta-testing phase, with their respective class-wise disjoint datasets
DM train and DM test. Details on each phase vary between propositions, but globally meta-
training works like some sort of pre-training, where the model is trained on some discrimina-
tive task over the classes in DM train, while constructing a representation that will be useful to
generalize to new classes in DM test. In this sense, this methodology can still be seen as a form

4not to be confused with meta-learning in the sense of hyperparameter tuning and automatic machine

learning

118

6. DCNNs with data-prototypes

6.2 Related works

of transfer learning. Later, meta-testing phase will consist of actually performing the k-shot
N-way task multiple times, for diﬀerent subsets of N classes drawn from DM test. Each subset
itself has to be divided into training and test splits, in order to have kN reference samples for
the new classes from one and evaluate performance on the other.

To give a clearer example, let us present a common organization of meta-learning: episodic
training. First proposed by Vinyals et al (2016), it has continued to be adopted in other recent
works (Santoro et al, 2016; Snell et al, 2017; Ravi and Larochelle, 2017; Fort, 2017; Ren et al,
2018). Arguing that approximating meta-training to meta-testing conditions could enhance
learning, they proposed that, during each step in the meta-training phase, the model be
trained on a diﬀerent k-shot N-way task, with new N classes drawn from DM train. Each such
task is called an episode, and demands not only kN examples as a training (or support) set
but also some examples of the N classes to serve as a test or query set. During this phase,
the error over this query set can be used to adjust the model, while in meta-testing only the
support set will be used as a reference to classify the query samples.

In line with the above discussion, many of the recent works focused on this problem,
seek to learn an embedding space over the meta-training set that will hopefully generalize
for unseen classes in meta-testing. This common feature space allows to compare test with
training examples to decide on their class, usually with some kind of nearest neighbors
algorithm, but sometimes resorting to more complicated models. Siamese nets (Koch et al,
2015) are an early example of such models, in which two identical networks are used to map
a pair of examples into a learned metric space so that they can be compared via a distance
function. The whole network is trained to predict whether an input pair belongs or not to
the same class, this being repeated for multiple pairs. Matching networks (Vinyals et al,
2016) work on a one-shot setting, also relying on learning a network that will map support
examples of each class to an embedding space, to be later matched to the query example. The
embedding is composed by CNNs providing inputs to LSTMs, providing a context aware
embedding that models dependence between the CNN feature vectors for each support point,
and also between support points and query point. Prototypical nets (Snell et al, 2017) also
learn an embedding based on a CNN, with the matching between support and query samples
performed by a nearest class means classiﬁer. The CNN is adjusted during meta-training,
with a cross entropy loss function over the points in the query set, for multiple episodes.

This line of work is in close relation with metric learning, which aims to adapt a metric
function over feature vectors for a given dataset (Bellet et al, 2013). If a signiﬁcant metric
is learned, distance-based classiﬁcation becomes a relevant alternative, as exempliﬁed by
Mensink et al (2013). They consider metric learning methods for two distance-based classiﬁers,
the k-nearest neighbor (k-NN) and nearest class mean (NCM), and propose new methods
for NCM allowing to model more complex class distributions with multiples centers per class.
This possible complexity in class distribution cannot be captured by local metric learning
methods, as is the case with current deep metric learning. As discussed by Song et al (2017)

119

6. DCNNs with data-prototypes

6.2 Related works

they are incapable of identifying scattered classes, with multiple clusters in the space. In
response, they propose to learn an embedding function that directly maximizes a clustering
metric (normalized mutual information).

Using memory augmented networks has also been explored in the context of few-shot
learning (Santoro et al, 2016). The idea is to build on top of a Neural Turing Machine (Graves
et al, 2014), an implementation of a content-based access memory for neural networks, adapt-
ing it to the one-shot learning task. This is yet another meta-learning approach, where the
recurrent network is not trained to predict directly a speciﬁc set of classes, but tries to predict
the right classiﬁcation at each time-step based on the sample-class associations it could learn
and keep in memory on the previous time steps. It still needs to see a large number (more
than 10k) of episodes to make good predictions, incrementally making better predictions as it
sees up to 10 examples of the same class. Compared to human memory, its functioning could
be seen as a working memory, that can match new samples to recently seen examples but
limited to a low amount of distinct categories.

6.2.3 Interpretability

Interest in the ﬁeld of interpretable machine learning has raised in the last years, partly
inspired by the ever-growing impact of machine learning systems in society. Nevertheless,
interpretability is a broad term still lacking a precise deﬁnition, with open discussions on
what it is and how to quantify it (Doshi-Velez and Kim, 2017; Lipton, 2016). One common
understanding is to equate it to explainability — the ability to provide explanations to a
model’s predictions or, even better, the reasoning process behind its predictions.

Understanding the reasoning behind complex models such as deep neural networks is
a diﬃcult task. In visual recognition applications, one common eﬀort is to try to visualize
what types of features have been learned by certain units or layers of a convolutional network.
This is usually achieved by optimizing network input to maximize the activations of the
layer of interest. Since the ﬁrst visualizations produced with DeconvNet (Zeiler and Fergus,
2014), there have been many propositions to improve the quality of the input reconstruction,
including the use of regularization priors that enforce more “natural-looking” images (see
Olah et al, 2017, for a review). Another way of producing such images is to search the
training set for image patches maximizing the activations. This approach has the advantage
of producing real examples, although not necessarily specifying which features in the image
led to it to be put in a particular category.

In-between these feature visualization strategies is the problem of attribution, where the
goal is to identify which regions of the input image were responsible for maximizing a chosen
activation (Sundararajan et al, 2017; Bach et al, 2015). An example of attribution procedure
is LIME, a method that locally approximates the model around the output prediction and
goes back to the input image highlighting superpixels most responsible for its predicted class

120

6. DCNNs with data-prototypes

6.3 Model proposed

Figure 6.1 The three layer model. The input data is fed to a convolution neural network, transforming the original
image into a set of feature vectors. Then the information in this high dimensional feature space is summarized
via a set of prototypes, in order to understand the landscape. Finally, the relation between a given data point
and the label to infer is calculated through their proximity to the prototypes.

(Ribeiro et al, 2016). Other works are interested in generating some salience map information
over the input image (Bach et al, 2015; Shrikumar et al, 2017). While feature visualization is
still abstract and away from verbal human-level explanation, attribution or salience maps are
grounded on real images and can provide some level of justiﬁcation.

Even though these methods were developed having deep CNNs in mind, some of them
can be generally applied to explain other classes of models. The explanation procedure itself
can be seen as an explanation model, trained to provide justiﬁcations given the inputs and
outputs of the black-box prediction model. Lundberg and Lee (2017) deﬁnes additive feature
attribution methods, a class of local explanation models, unifying diverse approaches from
literature (including Ribeiro et al, 2016; Shrikumar et al, 2017; Bach et al, 2015). Another way
to use an accessory model as explanation is to distill the network into a class of allegedly
interpretable models — such as decision trees — training the explanation model to mimic the
networks predictions (Frosst and Hinton, 2017).

6.3 Model proposed

6.3.1 Model architecture

Here we introduce a prototype matching layer as proposed in Snell et al (2017), after the
embedding provided by a CNN, deﬁned by a set of prototypes sampling the input distribution
in the feature space. This layer is a softmax taking both the sample features and the sample
prototype proximity into account. This allows grouping examples with respect to the induced
metric learned by the CNN layers, and taking the competition between prototypes into account.
Diﬀering from Snell et al (2017), this output feeds an additional ﬁnal softmax classiﬁer layer,
that correlates the prototype’s matching to class labels. This allows to introduce a soft but

121

Input images{(Ii,li)}i∈{1,M}Feature vectorsPrototypesCNNSample-to-prototype associationPrototype-to-class association6. DCNNs with data-prototypes

6.3 Model proposed

sparse prototype-to-class label assignment: A given prototype is encouraged to represent a
unique class, but in ambiguous situations this mapping is not hardwired. It also diﬀers from
alternative mechanisms such as support-vector machines, Kohonen-like maps, or radial basis
functions (such as, e.g., in Lyu and Simoncelli (2009)).

Some speciﬁcity with respect to usual architectures using prototypes are taken into account

here:

(cid:73) The prototype layer is not the ﬁnal layer but an intermediate upper-layer of the architec-
ture, as a complementary information to perform the perceptual task. Here classiﬁcation
is the task, but this extends to other perceptual tasks.

(cid:73) A prototype is a “data prototype” in the sense that its role is not only to reveal if a
neighborhood of the feature space belongs to a given category of the classiﬁcation task,
but also to represent at a macroscopic level the feature space itself (e.g., which regions
are to be taken into account, whether a category corresponds to a connected region or
not, whether a region contains adversarial samples, etc). As a consequence, we neither
hard-wire sample to prototype matching nor prototype to class label assignment, but let
the estimation provide the best description of the data, given the classiﬁcation task, in
an interpretable way, as discussed below. This is quite diﬀerent from the related works
reviewed in the previous section.

(cid:73) Given a dataset, the ﬁnal task-related layer is fed with two alternative combined inputs:
(i) The whole feature sample vector, and: (ii) The data in relation with the prototype
space. With the former choice only, the prototype layer role is simply to represent the
data in the feature space but is not involved in the classiﬁcation task. With the latter
choice only, the large dimensional feature sample (here of dimension 2048, see details
in the next section) reduces to a very low dimensional space (less than 50 in our setup).
This very likely introduces some bias, but may limit overﬁtting.

Let us now turn to the formal detailed description of the model.

6.3.2 Model specification

We consider5 a set of labeled images {· · · (Ii, li) · · · }, i ∈ {1, M }, labels being ﬁnite li ∈
{1, N }. This input space I is embedded in a feature space X of huge dimension D through a

5Notations: Vectors and matrices are written in bold, the vector dot-product writes xT x(cid:48), i.e., as a matrix
product with the row vector transpose of the left column vector. The Heaviside function writes H(u). Partial
derivatives are written in compact form, e.g., ∂xn f (x) means ∂f (x)
. The notation δP stands for 1 if the property
∂xn
P is true and 0 otherwise (e.g., δ2>1 = 1). The notation {a, b} stands for an integer interval and [a, b] for a
real interval. When considering a vector x augmented by new dimension c we simply write (x, c) for the
corresponding element in the Cartesian product of the corresponding spaces.

122

6. DCNNs with data-prototypes

6.3 Model proposed

function f : I → X , here deﬁned by the CNN. We introduce the notion of prototype in order
to discriminate between twisted features at the output of some CNN.

To this end, we propose to consider the estimation of a ﬁxed-size set of prototypes in the
feature space pj, j ∈ {1, J}, J ≥ N . The fact this set is ﬁxed is going to be discussed at the
experimental stage, showing that the hyperparameter J is robust.

We are in a supervised learning paradigm considering samples {· · · (xi, li) · · · } providing

examples of association between features and categories.

We proceed in two steps. First, qj(x) = p(x ∈ Qj) is the probability for the feature vector x
of a sample, to be associated to the j-th prototype. This association is written as x ∈ Qj, where
Qj is the set of samples associated to the given prototype. Interestingly enough, our model
does not implicitly assume that the Qj form a partition of the feature space, as discussed in
Appendix A.5. These regions may overlap or uncover the whole space. Furthermore a sample
may be sparsely represented, thanks to the soft-max criterion, by several prototypes as in a
dictionary representation method (see e.g., Rubinstein et al, 2010). We approximate qj(x) as
a function of the proximity −(cid:107)x − pj(cid:107) to the prototypes, writing:

qj(x) = νj

(cid:0)−(cid:107)x − pj(cid:107)2/2(cid:1) ,

(6.1)

where νj(·) stands for the soft-max distribution, the related D × J weight matrix of this
layer corresponding to prototypes coordinates in the feature space X . See Appendix A1 for a
detailed presentation of this equation.

Then, cl(x) = p(l|x) is the probability for a sample to be associated to the label of index
l. For the purpose of analyzing diﬀerent aspects of the given architecture, we consider two
alternatives: direct use of the prototypes and combined use of prototypes and features.

6.3.2.1 Direct use of the prototypes

The label of sample is estimated by another softmax layer:

cl(x) = νl

(cid:0)wT

l q(x)(cid:1) ,

(6.2)

the related J × N weight matrix corresponding to the prototype-to-class association. This
design choice introduces an important dimensional reduction (see e.g., Shalev-Shwartz
and Ben-David, 2014, Chap 23) in the processing. It is a strong choice and it is going to be
numerically studied against a vanilla alternative made explicit in the next subsection.

Considering an approximate cross-entropy criterion to adjust the parameters given sample

features xi and their label li yields the following minimization:

C = −

(cid:90)

X

p(x) log (c(x)) +

1
C

|wl|d (cid:39) −

1
M

(cid:88)

i

log (cli(xi)) +

1
C

|wl|d,

(6.3)

123

6. DCNNs with data-prototypes

6.3 Model proposed

where d ∈ {1, 2} corresponds to the L1 or L2 norm, while C is a hyperparameter weighting
the regularization term.

A straightforward derivation (see Appendix A3 for the details) of the related normal

equations leads to an estimation-minimization method:

- The ∂pj C = 0 equation yields a k-means estimation of the prototypes given the samples,
weighted by the prototype proximity. This deep relation between divergence estimation
and k-means algorithms is known (Banerjee et al, 2005) and will allow us to derive an
eﬃcient implementation, and to minimize the role of meta-parameters for this step. In our
implementation we have experimented that considering only a standard k-means initialized
by a k-means++ mechanism is numerically suﬃcient.

- ∂wlC = (cid:80)

i [δl=li − cl(xi)] q(xi) + R, where R stands for regularization terms, yields a
Hebbian-like interpretable 1st order rule for adjusting the prototype-to-class association, as a
function of each training sample a priori class label.

6.3.2.2 Combining prototype-encoded and original features

The combined model uses the probabilities for a given input sample to correspond to the
prototypes in order to predict the class. The input sample is encoded via these numbers. It
is obvious to decode such information, i.e., to reconstruct the predicted sample given this
information:

(cid:88)

˜x def=

qj(x) pj,

(6.4)

j

where ˜x is the simple Bayesian estimation of x given p(x ∈ Qj), providing6 a simpliﬁed form
of linear autoencoder mechanism (Goodfellow et al, 2016a).

When D (cid:29) J, it might be the case that the prototype information is insuﬃcient to allow a
good classiﬁcation performance. Conversely, using a large J may interfere with interpretability,
a large number of prototypes being harder to analyses and eventually being less meaningful.
To this end, we are also going to also consider

cl(x) = νl

(cid:0)wT

l (x | ˜x)(cid:1) = νl

(cid:16)

w(cid:48)T

l x | ˜w(cid:48)T

l ˜x

(cid:17)

,

(6.5)

| ˜w(cid:48)T

in the upper classiﬁcation layer, where | is a vector concatenation operator and w(cid:48)T
l =
(w(cid:48)T
l ). This provides the following layer with both features and prototype-encoded
l
information to make a classiﬁcation decision. Additionally, comparing w(cid:48)T
l allows to
numerically evaluate the contributions of both paths identifying to what extent the reduction
of information from the whole data features to a prototype-encoded representation is relevant

l with ˜w(cid:48)T

6Obviously, if the classiﬁcation task is performed on ˜x, i.e., if we consider cl(x) = νl

(cid:16)

w

(cid:48)T
l ˜x

(cid:17)

, this is

l q(x)(cid:1), with w
equivalent to the previous form cl(x) = νl
parameterization of the classiﬁcation layer using D × N weights, but with only J × N degrees of freedom.

l , thus simply correspond to an over-

(cid:48)T
l pj = wT

(cid:0)wT

124

6. DCNNs with data-prototypes

6.4 Experiments and results

to the classiﬁcation decision.

6.3.2.3 Relation between prototypes and category information

Another issue with respect to the state of the art is, as proposed in Rippel et al (2016),
to consider the prototypes as a mixture between unsupervised information (sampling the
feature space without any knowledge) and supervised hardwired information, each prototype
being hardwired to a given category. In order to further understand the relationship between
the data prototypes and the categorization, since in alternative approaches prototypes are
often “hard-wired” to a given category, we have also investigated an extension of the k-means
algorithm step on the learning set, taking also the learning sample category into account.

To this end the following extended metric for the k-means algorithm applied on learning

samples is considered:

d ((xi, li), (xi(cid:48), li(cid:48))) = |xi − xi(cid:48)|2 + β

(cid:88)

j

δli(cid:54)=li(cid:48)

(6.6)

In words we augment the feature space by new dimensions corresponding to each categories
in order to move apart samples related to diﬀerent categories. Clearly for β = 0 this reduces
to our original setup, whereas for large values of β, we make explicit in Appendix A.4 how
this allows to hard-wire prototypes to categories.

This complementary tool is not related to performances but to only better understand
this aspect of the problem. Additionally, it is important to understand that there is a deep
relationship between a softmax classiﬁcation layer and a prototype representation, as discussed
in details in Appendix A7.

6.4 Experiments and results

Here we perform a series of experiments to gain intuition about the proposed model, test
its performance under a few-shot setting and demonstrate its potentialities as an interpretable
alternative. In summary we used two experimental methodologies: ﬁrst a k-means based
implementation over ﬁxed features, followed by a second end-to-end implementation used in
a meta-learning setting. In both cases, we work under few-shot learning conditions, exploring
the performance of these models for not-so-big data situations.

6.4.1 Datasets

A known benchmark dataset for few-shot learning is the Omniglot dataset (Lake et al,
2011). It consists of images of 1622 characters from 50 diﬀerent alphabets, each drawn by
20 diﬀerent people. The small number of samples per class and the large number of classes

125

6. DCNNs with data-prototypes

6.4 Experiments and results

make it a challenging problem to learn all the classes simultaneously. Therefore we will work
on episodes: class subsets of N classes randomly picked among the 1622 characters (see Fig.
6.2:Left for an example).

To study the eﬀect of increasing training set sizes, we will use two larger standard bench-
mark datasets: MNIST7 and CIFAR108. Both datasets comprise 10 diﬀerent classes. MNIST
has 28x28 images of handwritten digits, 60K samples in the training set and 10K in the test set.
CIFAR10 has 60K 32x32 color images of 10 object categories, with 50K in the training set and
the remaining 10K on the test set. From these datasets, it will be possible to sample training
subsets ranging from few-shot to many-shot situations.

6.4.2 Studying the model under fixed features

Contrary to usual few-shot learning paradigms we do not consider here meta-learning
as discussed in section 6.2.2, but a transfer learning paradigm: by using a general purpose
pre-trained CNN, we skip any meta-training routines that allow learning CNN ﬁlters on a
particular few-shot dataset. We use ﬁxed features extracted with a standard CNN architecture
pre-trained on ImageNet data, namely Inception v3 (Szegedy et al, 2015), that has successfully
been used in transfer learning settings (for instance Esteva et al, 2017; Shin et al, 2016). Features
are normalized in the range [0, 1]. Based on features extracted from the penultimate layer of
this network, our model has to learn to predict from very few samples (see Fig 6.2:Right for a
visualization example of this feature space for a sample episode of Omniglot dataset). Fixing
the embedding network allows to isolate and assess performance variations due to the ﬁnal
layers of the model, under equal input features. Assessing whether the tested models allow
learning of a more appropriate representation is addressed in section 6.4.4.

Except for experiments with increasing training set sizes (section 6.4.3), all experiments
in this section are performed on Omniglot dataset. In comparison to meta-learning method-
ologies, we are skipping the meta-training phase, where the embedded representation is
learned, and going directly to meta-testing, where for each independent episode, the model is
actually only learning to predict from few-shot data, for a certain quantity N of classes. Thus
we operate direct learning on each episode, with a training data set for parameter estimation
and a test set for checking generalization. Each episode is split in half, with 10N samples
for training and 10N samples for testing. When hyperparameter tuning is needed, 5x2-fold
cross-validation over the training set is used, leaving 5N samples to train and 5N to validate.
Once the hyperparameters are chosen, the model is re-trained on the entire training set. To
see how the model performs over the entire dataset, observations are repeated for a large
number of episodes.

With those two simpliﬁed design choices (using ﬁxed features and performing direct

7http://yann.lecun.com/exdb/mnist
8https://www.cs.toronto.edu/ kriz/cifar.html

126

6. DCNNs with data-prototypes

6.4 Experiments and results

Figure 6.2 Left: Sub-sample of 10 classes from the Omniglot dataset, showing 5 samples per class (total is 20
per class). Right: T-SNE visualization of the Inception v3 features for the 200 samples of this subset, see text for
details.

learning), these results cannot be fairly compared to other few-shot meta-learning approaches
(this will be addressed in section 6.4.4). More precisely, we withdraw from learning the CNN
layers, which are not adapted to the target data to give a speciﬁc representation, relying on
transfer learning instead. Moreover, using the direct model only, it drastically restrains the
classiﬁcation number of degrees of freedom from thousands to a few tenths. This is done on
purpose in order to study to what extents this compromises the result. Nevertheless, we also
know how to also guaranty performances, using the so-called combined model. In both cases,
we compare our propositions to other classical classiﬁers tested in the same setting, namely:
softmax, SVM and nearest centroids.

To visualize how data samples and prototypes are distributed in space, we obtain a
2D non-linear projection using T-SNE (Maaten and Hinton, 2008) over the data samples
feature vectors together with the prototypes coordinates pj in the feature space, as shown
in Fig. 6.2:Right. Such mechanism preserves local neighborhood of closed samples, whereas
long range distances can not be interpreted since skewed by the non-linear projection: The
map only reﬂects the similarities between the high-dimensional inputs in a stochastic, but not
metric way.

Code and further analysis for this section and section 6.4.3 are available at https://

gitlab.inria.fr/mnemosyne/data\_prototypes.

6.4.2.1 Study of a sample episode

Hyperparameter adjustment is a key factor in the success of any machine learning model.
This ﬁrst analysis focuses on gaining intuition on the behavior of the model on a sample
episode with N = 10 classes (shown in Fig. 6.2). The aim is to study its hyperparameters,
experiment with visualization of prototypes and data samples in a common space and try

127

samples - classes 1 to 10123456789106. DCNNs with data-prototypes

6.4 Experiments and results

to understand the relation between prototypes and their attributed class. In this section we
consider only the hyperparameters introduced by the formulation presented in section 6.3.2.
More details on these and other hyperparameters can be found in Appendix B.

In the current experimental setting, our base model has two hyperparameters: the inverse
regularization strength (C) and the number of clusters, thus of prototypes (J). We explored
10 values of C ∈ [10−3, 108] and 10 values of J ∈ [2N, 5N ], where N = 10 is the number
of classes (see Fig. 6.3). For the direct model under L2 regularization, we can identify that
average performance is stable for C ≤ 10−1, and more sensitive around larger C values in
(102, 106], raising around C ≤ 102. For for L1 larger values are preferred, presenting a stable
score as soon as C ≤ 102. For the combined model, we have a behavior similar to direct-L1
under both regularizations, with any values above a certain threshold being equivalently
good (10−2 for L2 and 101 for L1). Since no clear preference could be stated between L1 and L2
regularization, both regularizations keep being analyzed in the following (and are included
in the comparative analysis in section 6.4.2.3).

Regarding the number of prototypes J, as visible in Fig. 6.3, a higher number of prototypes
is preferred by the direct model, while the combined model does not seem to depend on
it. However, for the direct model, using a too large number of prototypes would ultimately
amount to a nearest-neighbors-like algorithm and possibly counteract on their interpretability
purpose (too many prototypes representing too many base concepts to support a simple
explanation), while overﬁtting and poor generalization performances are expected. With the
combined model, we can avoid this issue by choosing a lower number of prototypes while
keeping high performances.

Nevertheless, a minimal number of prototypes can be important for interpretability, but can
be ignored when looking only at accuracies in cross-validation. This motivates using another
method for choosing the appropriate number of prototypes. As far as data representation is
concerned, we can simply rely on usual k-mean prototype count adjustment methods. This
is usually done by sweeping some range of values for the number of clusters and keeping
the one minimizing its loss or, in case of saturation as J grows, keeping the lowest value
that reaches close to minimal loss. We exemplify this procedure in Fig. 6.4 for an Omniglot
10-shot episode, which suggests a number of prototypes around 20. Statistical signiﬁcance
of the observed elbow curve has been veriﬁed. More precisely, considering a least-squares
adjustment of a parametric elbow model against a constant value model, the related Fisher
ratio test probability threshold is p = 0.2 on the non-normalized values. It is only p = 0.3 on the
normalized values, and it is more than p = 0.001 (non-normalized) and p = 0.2 (normalized)
on the MINST data set reported on Fig. 6.9 and only p = 0.3 for the CIFAR 10 data set. We
have tested for several parametric models (cubic, piece-wise linear, exponential) and obtained
the same results. We hypothesize this is due to due to very small set of data used (10 samples
by data point). However, as far as interpretability is concerned it is still interesting to have
an estimation of a reasonable order of magnitude of the number of prototypes. We also are

128

6. DCNNs with data-prototypes

6.4 Experiments and results

Figure 6.3 Mean accuracy (with standard deviation bars) obtained during grid search for the inverse regulariza-
tion parameter C and the number of clusters, under L2 regularization. Top: direct model. Bottom: combined
model.

129

102100102104106108inverse regularization C0.500.550.600.650.700.750.800.85mean accuracy L2n prototypes J10141823273236414550101520253035404550n prototypes J0.500.550.600.650.700.750.800.85mean accuracy L2inverse regularization C1e-032e-023e-015e+008e+011e+032e+044e+056e+061e+08102100102104106108inverse regularization C0.500.550.600.650.700.750.800.850.90mean accuracy L2n prototypes J10141823273236414550101520253035404550n prototypes J0.500.550.600.650.700.750.800.850.90mean accuracy L2inverse regularization C1e-032e-023e-015e+008e+011e+032e+044e+056e+061e+086. DCNNs with data-prototypes

6.4 Experiments and results

Figure 6.4 Average training loss on the k-mean algorithm as a function of the number of prototypes. The mean
square distance between samples and prototypes decreases until a plateau (sometimes called elbow) and then
either re-increases, as visible in this example, or do not signiﬁcantly re-decreases as shown in Fig. 6.9 for other
datasets.

going to observe in the sequel that this number is not critical regarding performances, so that
this rough estimate is suﬃcient.

In summary, we can choose the number of prototypes in the clustering phase based
directly on its unsupervised loss, optimizing the number of prototypes for data representation.
Altogether, the key points here are that this hyperparameter is to be considered more as a way
to optimize the data interpretability than the classiﬁcation performances, with the possibility
of being automatically adjusted.

When using the extended metric described in section 6.3.2.3, we have an extra hyperpa-
rameter β weighting the added class-aware term. Based on the previous analysis for C and
J, we decided to constrain the search of C ∈ [102, 106] and reduce the number of parameters
searched to 3. For J, we still search on the same range but limit the number of parameters to
5. Fig. 6.5 shows accuracy results on cross validation for diﬀerent pairs of β and J (with C
ﬁxed on the best value found by grid search). The contribution of this term for a ﬁxed value
of J is not clear, at this stage, but it is interesting to notice that when J = N = 10 there is an
improvement until a certain threshold, followed by a plateau ( β lower than ≈ 7.8 under both
L1 and L2 regularizations). This can indicate that for large enough β the class-aware term
has dominated the positioning of each cluster undermining the inﬂuence of the ﬁrst distance-
to-prototypes term. It could also be that for small numbers of prototypes this additional
term (that encourages prototypes to cluster samples corresponding to a unique category) has
a positive inﬂuence on performances, whereas it is no more the case when the number of
prototypes is high enough. We consider this result as a good indication that the compromise
between a good data representation good classiﬁcation performances seems possible with
our so called data-prototypes.

130

1020304050n prototypes200210220230240250Mean of squared distancesto the assigned prototyperaw features1020304050n prototypes9095100105110115[0,1] normalizationK-means objective vs number of prototypes6. DCNNs with data-prototypes

6.4 Experiments and results

Figure 6.5 Veriﬁcation that the introduction of a priori information on the prototype category has no signiﬁcant
impact on the performances, as soon as the number for prototypes is high enough. Graphs show mean accuracy
(with standard deviation bars) obtained during grid search under the best regularization parameter found. Left:
under L1 regularization, C = 104. Right: under L2 regularization, C = 102.

6.4.2.2 Interpretability of the model

As previously discussed, prototypes in our model lie in the same feature space as the
data and correspond to virtual examples. In this section we demonstrate how this fact can
support explanations about the model’s decisions. For such, we provide a visualization for
each prototype by looking at its closest training samples, in Fig. 6.6. To observe prototypes
in the feature space, we use T-SNE visualizations of training and test samples in the feature
space together with prototypes (ﬁgure 6.7). Visualizations in this section correspond to our
main model combining features and prototypes, under L2 regularization. With this model,
since the performance is not sensitive to the number of prototypes, J = 10 prototypes was the
value chosen by cross validation.

We observe the representative images obtained are coherent with the prototype classes,
except for prototype 7, which was classiﬁed as class 2 but had a closest sample coming
from class 7 (Fig. 6.6). This could be due to the fact explained by the fact that both classes
correspond to very similar characters (both look like a lowercase “g” under diﬀerent rotations,
see ﬁgure 6.2), and indeed the T-SNE visualization shows these classes are very mixed in the
feature space. Additionally, class 5 is also mixed in and corresponds to a similar character.
Indeed, the top-2 most likely classes for p7 predicted with close probability were c2 with
87% c7 with 7% (see ﬁgure 6.7), indicating p7 lies in a slightly more ambiguous region of the
feature space. In a scenario with an adaptive number of prototypes, this prototype-to-class
association information could serve as an index for adding more prototypes in the region.

Representation by the closest training sample illustrates how each prototype can be rep-
resented by a corresponding input, having the advantage of being a hyperparameter-free
method yielding real images. Of course feature visualization methods based on input opti-
mization could also be applied, but appropriately tuning such models is fundamental for

131

0246810class weight 0.600.650.700.750.800.85mean accuracy L1n prototypes J10203040500246810class weight 0.600.650.700.750.800.85mean accuracy L2n prototypes J10203040506. DCNNs with data-prototypes

6.4 Experiments and results

Figure 6.6 The top-4 closest training samples visually illustrate what is being represented by each prototype.
For each prototype p1, p2, .., its related class c2, c5, .. is written, this “main” class being estimated as the most
probable class proposed by our algorithm. The number of samples corresponding to the related cluster is given.

obtaining realistic image representations and out of the scope of this work.

6.4.2.3 Comparison over multiple episodes

Extending this analysis, we now compare test accuracies over 100 random episodes for
diﬀerent model variants, in order to obtain results of statistical signiﬁcance. As reference
methods we have a softmax regression layer (multinomial regression), an SVM and a nearest
class centroids classiﬁer (like the classiﬁer layer used by Snell et al (2017)). From our proposal
we test 4 variants: both combined and direct models, using L1 or L2 regularization (as deﬁned
in 6.3.2). Test accuracy results for 100 episodes are displayed in Figure 6.8.

Statistical signiﬁcance of the results are veriﬁed by a non-parametric Friedman test with
post-hoc Nemenyi tests (with p ≤ 0.05, see table 6.1) (Demšar, 2006). No signiﬁcant diﬀerences
between both regularizations could be observed for the direct model, while L2 is signiﬁcantly
superior for the combined model. Between direct and combined, combined is signiﬁcantly
better in both cases. Regarding the baseline comparisons, we highlight that the combined
model with L2 regularization diﬀers signiﬁcantly from a SVM for N = 20, 30, although no
signiﬁcant diﬀerence to softmax could be observed. Additionally, all models diﬀer signiﬁcantly
from nearest-centroids.

6.4.3 Comparison over different training sets with varying sizes

In order to conﬁrm our results we have considered two diﬀerent datasets: MNIST and
CIFAR10. These datasets have larger training sets, allowing to subsample training sets of size
larger than 20N (which was the case for Omniglot). Additionally, they have a large standard

132

p 1 - c 45 samplesp 2 - c 910 samplesp 3 - c 107 samplesp 4 - c 810 samplesp 5 - c 315 samplesp 6 - c 116 samplesp 7 - c 224 samplesp 8 - c 61 samplesp 9 - c 103 samplesp 10 - c 69 samples6. DCNNs with data-prototypes

6.4 Experiments and results

Figure 6.7 T-SNE visualizations of dataset points (as Inception v3 features) together with learned prototypes,
indicated by black markers. Each class is identiﬁed by color, and the predicted class for each prototype is
annotated. Misclassiﬁed points are over-marked by an “x” of the predicted class color. Top: visualization of the
training set; Bottom: visualization of the test set.

133

 p1 c4:1.00 p2 c9:1.00 p3 c10:1.00 p4 c8:1.00 p5 c3:0.99,c7:0.01 p6 c1:0.99,c4:0.01 p7 c2:0.87,c7:0.07 p8 c6:1.00 p9 c10:1.00 p10 c6:1.00classes12345678910 p1 c4:1.00 p2 c9:1.00 p3 c10:1.00 p4 c8:1.00 p5 c3:0.99,c7:0.01 p6 c1:0.99,c4:0.01 p7 c2:0.87,c7:0.07 p8 c6:1.00 p9 c10:1.00 p10 c6:1.00classes123456789106. DCNNs with data-prototypes

6.4 Experiments and results

Figure 6.8 Box plots for test accuracies over 100 episodes. Boxes extend between 1st and 3rd quartiles (IQR),
with median value noted at the bottom and marked by a green line. Bars mark a range of ±1.5 IQR from
quartiles, with outliers as circles. Our models are marked with a \*.

134

\*combined (L1)\*direct L1\*combined (L2)\*direct L2nearest centroidssoftmaxSVM0.00.20.40.60.81.010 classes0.920.820.940.820.850.940.93\*combined (L1)\*direct L1\*combined (L2)\*direct L2nearest centroidssoftmaxSVM0.00.20.40.60.81.020 classes0.880.740.910.740.800.910.89\*combined (L1)\*direct L1\*combined (L2)\*direct L2nearest centroidssoftmaxSVM0.00.20.40.60.81.030 classes0.860.690.900.710.770.890.87Omniglot - mean test accuracy - 100 episodes6. DCNNs with data-prototypes

6.4 Experiments and results

Table 6.1 Statistical signiﬁcance for all pairs of classiﬁers tested on Omniglot. “++” and “+” mark all pairs
which presented a signiﬁcant diﬀerence (for p < 0.01 and p < 0.05 respectively), while "o"s mark those which
did not. Non-reported pairs were found to be signiﬁcantly diﬀerent with p < 0.01 (except for direct L1 vs. direct
L2 at 30 classes, for which p < 0.05).

10 classes

20 classes

30 classes

Models

L2

combined L1

combined L2 softmax SVM softmax SVM L2

softmax SVM L2

L1
o
combined L1 ++
combined L2 ++
++
SVM

++
-
++
o

++
++
-
o

++
++
o
++

++
o
o
-

++
++
o
++

o
++
++
+
++ ++
++

-

++
++
o
++

++
o
++ ++
++ ++
++

-

test set (10K samples) over which to evaluate the performances. Class distribution in these
datasets is approximately balanced, and the distribution is preserved when sampling the
training subsets. We explored training subsets of size 100, 200, 300, 500, 750, 1000 (that is,
10, 20, 30, 40, 50, 75, 100 samples per class on average). The idea is to evaluate performances
ranging from few-shot data (here 10 samples per class) to not-so-big data (here a few tenths
of samples per class). For hyperparameter selection we proceed exactly as done for Omniglot,
by 5x2 cross-validation. All models are retrained over the whole training set using the best
validation parameters. Statistical signiﬁcance is also evaluated in the same way (Friedman
non-parametric test + Nemenyi post-test). We report the mean test accuracy, averaged over 10
diﬀerent random training subsets, all evaluated on the standard test partition for each dataset.
We also have numerically studied for these new datasets whether the k-means prototype
count automatic adjustment is still numerically valid, as reported in Fig. 6.9, after Fig. 6.4. We
thus have now observations for Omniglot (sample 10-shot episode), and MNIST and CIFAR10
(training subset with 500 samples). Such a method indicates 20 clusters for Omniglot and
CIFAR10, but a larger number for MNIST (between 30 and 50 depending on a saturation
tolerance). The optimal value does not correspond to a minimum but is still detectable as
an elbow corresponding to the occurrence of a plateau. This result is not always statistically
signiﬁcant. It is the case for MNIST but not for CIFAR10.

A ﬁrst evaluation of the means (and standard deviations, see ﬁgure 6.10) allows to observe
that our combined models perform best or similar to a softmax or an SVM classiﬁer, all
performing better than nearest centroids or our direct models, which is congruent with results
obtained on Omniglot (but here on a larger test set). Particularly for MNIST, the nearest
centroids classiﬁer is considerably lower than the top performing methods.

Considering statistical signiﬁcance of the comparisons, on MNIST our combined model
with L2 regularization is consistently better than nearest centroids, although the same can be
said about softmax. In most cases, for both datasets, combined models, softmax and SVM
are signiﬁcantly better than either of the direct models, but comparison between them is
inconclusive. For CIFAR10 the signiﬁcance results are less conclusive, but we do observe
some signiﬁcance in the superiority of the combined model (L1 regularization) over nearest-

135

6. DCNNs with data-prototypes

6.4 Experiments and results

Figure 6.9 Performances on the k-means algorithm as a function of the number of prototypes, for training
subsets with 500 samples from MNIST and CIFAR10 datasets. In these and contrary to Fig. 6.4, the optimal value
corresponds to an elbow in both cases.

136

10203040506070n prototypes320340360380400Intra-cluster MSEMnist - raw features10203040506070n prototypes45505560Mnist - [0,1] normalized10203040506070n prototypes1950200020502100Intra-cluster MSECifar10 - raw features10203040506070n prototypes60626466Cifar10 - [0,1] normalizedK-means objective vs number of prototypes6. DCNNs with data-prototypes

6.4 Experiments and results

Figure 6.10 Mean accuracies over standard test sets for MNIST and CIFAR10 datasets, for increasing training set
sizes. Results are averaged over 10 diﬀerent training subsets. Our models are marked with a \*.

centroids (between 200 - 1000 training samples). Detailed results for statistical testing of all
classiﬁer pairs for all training set sizes can be consulted in the code repository for this paper.

6.4.4 Experiments in the meta-learning paradigm

To allow a fair comparison to usual few-shot learning paradigms, we carried on end-to-end
training of the model under meta-learning conditions. We continue to use Omniglot dataset
described above, with 4 rotations per character used for data augmentation (0, 90, 270, 360
degrees), and use episodical training, following the methodology of Snell et al (2017). We use
the same CNN architecture (4 layers, 3x3 kernels, resulting in a 64 dimension embedding)
and experimental setup, based on their publicly available implementation9.

In summary, the task here is to prepare a meta-model which will be able to learn to classify
N classes based on k training samples, for diﬀerent subsets of N classes. For this, the full
architecture is meta-learned over a some episodes sampled from a meta-training set containing
1200 characters, with episodes from a meta-validation set containing 172 characters being
used to evaluate and early-stop the meta-training, while the remaining 423 characters are
used to generate meta-testing episodes (subsets of N classes not seen in the meta-training
phase).

More speciﬁcally, the meta-training phase is carried on 100 randomly chosen 5-shot 60-
way episodes. Another 100 5-shot 5-way episodes are sampled to form a meta-validation set.
Meta-training is stopped after 200 epochs with no improvement on the meta-validation set,
keeping the best model so far. At meta-test time, we apply the model to solve 5, 10, 20 and
30-shot learning tasks on 1000 episodes sampled from previously unseen classes.

Since these experiments are more computationally intensive, using cross-validation to
choose hyperparameters becomes prohibitive. We ﬁxed J = 2N , i.e. 2 prototypes per class and

9Code for prototypical networks available at https://github.com/jakesnell/prototypical-
networks, under MIT license. Our fork is available at ]urlhttps://github.com/thalitadru/prototypical-networks

137

1001001001001001001001001001002002002002002002002002002002003003003003003003003003003003005005005005005005005005005005007507507507507507507507507507501000100010001000100010001000100010001000training set samples0.550.600.650.700.750.800.850.90mean test accuracyMnist - mean accuracy on test set(10 random training subsets)\*combined (L1)\*direct L1\*combined (L2)\*direct L2nearest centroidssoftmaxSVM1001001001001001001001001001002002002002002002002002002002003003003003003003003003003003005005005005005005005005005005007507507507507507507507507507501000100010001000100010001000100010001000training set samples0.400.450.500.550.600.650.700.75mean test accuracyCifar10 - mean accuracy on test set(10 random training subsets)\*combined (L1)\*direct L1\*combined (L2)\*direct L2nearest centroidssoftmaxSVM6. DCNNs with data-prototypes

6.5 Discussion

L2 regularization of 10−4 (via weight decay). Optimization of the complete model, including
CNN weights, is done with an Adam optimizer with initial learning rate of 10−2 (and default
moment estimation parameters). For each episode the top two layers of model need to be
ﬁtted on the new classes using the training (or support) k-shot examples. This optimization
was run for 200 iterations, with an initial learning rate of 0.1 (also using Adam). The test (or
target) examples serve to evaluate the model and, when in meta-training phase, calculate the
loss and gradients that will adjust the bottom CNN weights.

We compare our accuracy results over 1000 test episodes to two other propositions in the
literature: Matching networks (Vinyals et al, 2016) and Prototypical networks (Snell et al,
2017) (see table 6.2). These are seminal works in the ﬁeld of few-shot learning and remain
competitive compared to more recent proposals (for instance Garcia and Estrach (2018) or
Finn et al (2017)). For prototypical networks, we re-ran the models using the code released
by the authors to obtain results for more values of N classes. Slightly diﬀerent results are
normal, since we did not do the ﬁnal retraining step , where the model is retrained in the full
meta-training set (including the portion separated for meta-validation).

Overall, we can observe that learning the CNN weights through this meta-training ap-
proach yields better performances in comparison to using ﬁxed features, as expected. Consid-
ering that no hyperparameter tuning was done, we still obtain good results, a little lower than
the state-of-the-art, even though they degrade faster as the number of classes goes up. Some
discussion on this result is presented in the next section. Between combined and direct model,
we also observe that the former performs better at a higher number of classes N = 20, 30,
while the second is better for N = 5, 10.

Table 6.2 Average test accuracy (%) for 5-shot learning on Omniglot over 1000 episodes. We compare to results
reported by two other works: Matching networks (Vinyals et al, 2016) and Prototypical networks (Snell et al,
2017).

Method

5 classes

10 classes

20 classes

30 classes

Matching Networks
Matching Networks
- ﬁne tuning
Prototypical Networks
Prototypical Networks
(re-run)

98.9

98.7

99.7

-

-

-

98.5

98.7

98.9

-

-

-

99.54±0.07

99.17±0.06

98.57±0.06

98.01±0.06

Direct - 2N prototypes
Combined - 2N prototypes

98.4 ± 0.2
97.1 ± 0.2

97.2 ± 0.2
96.3 ± 0.2

94.8 ± 0.3
96.2 ± 0.1

92.6 ±0.4
95.9 ±0.1

6.5 Discussion

138

6. DCNNs with data-prototypes

6.5 Discussion

6.5.1 Performances and use of the algorithm

We have proposed a simple three-step model, applied to classiﬁcation tasks on visual data
under very small (few-shot on Omniglot) to not-so-big datasets (subsets from MNIST or
CIFAR10). Let us now discuss the main questions presented in the course of this work in the
light of our experimental results.

- Is the setup able to properly learn such a task in an interpretable way? Our models were capable
of performing the classiﬁcation tasks, both under ﬁxed features and under the meta-learning
paradigm, while proﬁting from the explainability support that can be provided by our rather
simple architecture. Our “data prototypes” that can be used to provide a visual explanation
of the model’s internal representations, by indicating ambiguous classiﬁcation regions for
example. Some mathematical discussions on how the prototypes induce a partition of the
feature space are presented in Appendix A5 and A6. This explanatory power is however
limited when using the combined model, since raw features are also considered in prediction.
Prioritizing interpretability by using only the direct model yields reduced performances
under ﬁxed features, indicating a trade-oﬀ between interpretability and classiﬁcation accuracy
in this case.

All together, this is no more than a variant of the notions of prototypes used in the ﬁeld,
but with the objective to both represent the data in an unsupervised way and the supervised
information. The name “data prototype” is chosen particularly because they may be considered
as virtual samples that summarize what has been learned during the learning phase, acting
as a local descriptor in the feature space. Being virtual samples, they could be fed to feature
visualization techniques to provide a graphic explanation (here exempliﬁed by taking the
closest training samples as a visualization proxy).

Another non negligible aspect is the fact that our proposed architecture, schematized
in Fig. 6.1 is “easy to explain” to non-specialists : (i) features are extracted (by the deeper
layers), (ii) the data is organized in regions (parameterized by prototypes) and (iii) the
classiﬁcation is performed combining all information. Our will to provide an interpretable
and understandable process is not only a wish but corresponds to real interaction with
large public targets, including providing didactic resources on these subjects, as reported in
Drumond et al (2017a) or available in Kaadoud and Viéville (2016).

- To which extents does the prototype dimensional reduction impairs the global performances?
Under ﬁxed features, indeed we have a strong dimensionality reduction which impairs the
performance of our direct model, which justiﬁes the use of a combination of features and
prototype information in our main model. This way it is possible to both beneﬁt from the
prototype layer and obtain optimized performances as good as or better than a standard
method.

In meta-learning paradigm, we also learn the features by learning the weights of a CNN that
feeds our model. In this case, since the features are learned together with our prototype model,

139

6. DCNNs with data-prototypes

6.5 Discussion

the class representations should become more adapted to a prototype-based discrimination,
resulting in higher accuracies than under ﬁxed features even for the direct model. Moreover,
the dimensionality reduction was not as strong because we use a 64 dimension embedding
and 2N prototypes.

Combining these two options allows the user to both obtain state of art performances and
interpretable results. With respect to other comparable existing methods, we have obtained
similar performances, except when considering meta-learning with a large number of classes.
This is explained by the fact that we have not optimized hyper-parameters in this case, which
had already been done in the ﬁxed-features paradigm.

We can also hypothesize that our algorithm, since based on a reduced set of prototypes that
acts as support-vectors of the classiﬁcation (See Viéville and Crahay, 2004b, for a development
of the link between support-vectors and prototypes), may have good generalization properties,
e.g., may limit overﬁtting which is to be expected in a not-so-big data setup. This is indeed
the case for the direct model. For the combined model, as detailed in Appendix A7, we may
interpret the softmax layer as piece-wise linear classiﬁer considering O(L2) prototypes. As a
perspective of this work, going in depth in this interpretation may be an interesting issue.

- Is the hyperparameter adjustment automatic at the end-user level? The main hyperparameters
we introduce are the number of prototypes and a typical regularization strength, this last one
being not too critic as long as it is not too strong (C > 102). Even if the number of prototypes
is a non-negligible choice in terms of data representation, with the combined model we
eliminate sensitivity to this hyper parameter in terms of performance. However, in terms of
interpretability, this leads to choosing a small number of prototypes that might no represent
so well classes in the feature space. Conversely, with the direct model, we are led to choose
an always large number of prototypes at the risk of overﬁtting, because at the limit (one
prototype by learning sample) the method reduces to a nearest-neighbor classiﬁer, known
to be of poor generalization performances. Here, we ﬁx this issue by proposing to choose
the number of prototypes in the clustering phase based directly on its unsupervised loss,
optimizing it for data representation. We have experimentally veriﬁed the feasibility of this
method for the diﬀerent data sets. Comparing to other methods, this seems to be the main
new qualitative result to point out.

6.5.2 Perspectives and future work

Beyond these outcomes, general or application dependent extensions of the method can

be pointed out.

+ Consider incremental learning, where learning can continue when given new samples,
by updating the prototypes and the related category prediction. This can be achieved for
instance through incremental k-means, which is a standard process (See, e.g., Yadav and Singh,
2015). Applying cross-entropy minimization in an incremental manner is also straightforward,

140

6. DCNNs with data-prototypes

6.6 Conclusion

iteratively adding loss terms for newly arrived samples.

+ Consider prototype editing, where (i) redundant prototypes within the same connected
component can be deleted, while (ii) learning samples detected as exceptions and generat-
ing a classiﬁcation error can be taken into account via a new prototype. Additionally, and
adaptive mechanism for determining the number of prototypes could better explain the data
representation, improving interpretability of the feature space, while eliminating one sensi-
tive hyperparameter of the model. In domain-speciﬁc applications where classes might be
composed of many diﬀerent subclasses, a sensible number of prototypes could better identify
these subclasses and provide means of representing the diﬀerent subgroups.

+ Interacting with the deep-learning lower layers, since the knowledge of the prototypes may
help disentangling the lower-layer feature extraction. A class disentanglement is a likely cause
behind the improved performances in the meta-learning setting (when compared to using
ﬁxed features), since all layers are trained end-to-end. In a transfer learning setting, we could
proceed to the ﬁne-tuning of the upper layers of the pre-trained CNN to try to achieve a similar
result. Moreover, disentanglement could be enforced implicitly via low dimensional manifold
regularization (Zhu et al, 2017b), or using generative latent factor models (Hoogeboom, 2017).
Another form of interaction could be the introduction of shortcuts from lower layers to the
feature layer in order to increase the prototype components, analogous to other architectures
incorporating some form of forward shortcut (Shelhamer et al, 2017; He et al, 2016a; Huang
et al, 2017).

+ Integrate knowledge from unlabeled examples is also a possibility. These examples can
represented in the same feature space as other labeled samples and prototypes, using same
embedding CNN to extract this representation. These examples then can be taken into account
when computing the prototype coordinates, analogously to what has been demonstrated
by Ren et al (2018). Particularly when trying to solve ambiguous regions where the system
makes mistakes, a related track is to develop some active learning heuristics and infer which
new examples could be of most help if labeled.

6.6 Conclusion

We analyzed how considering data prototypes at a diﬀerent level with respect to the state of
the art allows to both reasonably work with small data sets, and with an interpretable view of
the obtained results. The proposed architecture is minimal and combine both the performances
of a standard method and the capability to observe the feature space representation.

At the methodological level, we also pay attention at exploring in details the performances
and limitations of the proposed set-up, in an analogous way as biological experiments are
conducted, considering in details all hyperparameters involved in the process. This is somehow
diﬀerent from simply “winning the game” with respect to some deep learning benchmarks.

141

Chapter 7

Conclusion

7.1 Summary of contributions

7.1.1 Understanding object recognition from an interdisciplinary

stance

When comparing CNNs and neuroscientiﬁc models of vision (reviewed in chapter 2),
similarities have been found in multiple interdisciplinary works. On the functional side,
early and late layers have been shown to be highly predictive of activity of V1-V2 and V4-IT
cortical areas, respectively, considering data from both neurophysiological responses (Cadieu
et al, 2014; Yamins and DiCarlo, 2016) and fMRI activity (Eickenberg et al, 2016). On a
more “behavioral” side, CNNs have been shown to make similar classiﬁcation decisions to
those made by primates (when trained on suﬃciently challenging tasks), having presented
confusion matrix patterns similar to both humans and monkeys (Rajalingham et al, 2018).

These similarities are restricted to fast-brain core object recognition, corresponding the
ﬁrst hundred milliseconds of cortical processing. More complex visual processing has been
shown to depend on functional principles and architectural paths not modeled in typical
CNNs. We have surveyed three main aspects:

(cid:73) Advanced processing and encoding done in retina and thalamic structures, such as
spatio-temporal compressing and computational integration of multiple cortical areas,
respectively;

(cid:73) Interaction between dorsal and ventral streams — thus between recognition and local-
ization. Dorsal and ventral streams share information on motion, color and form, at
multiple stages of both hierarchies;

(cid:73) The role of recurrent processing and feedback connections towards a more reﬁned visual
perception under challenging conditions. Local and long-range recurrences — including
the previously mentioned connections with thalamic and dorsal areas — are crucial in
allowing reﬁnement and disambiguation of object boundaries, interpolating missing
information from local spatial recurrences and integrating motion processing cues.

Of these three principles, recurrent processing is the most general one, as it is present at

142

7. Conclusion

7.1 Summary of contributions

several levels of the vision hierarchy, which has motivated reviewing how this mechanism
has been integrated to CNNs in the recent literature.

Since the ﬁrst simple and feedforward CNNs, many architectural innovations have been
presented over the years, as reviewed in chapters 2 and 4. Both chapters have organized
feedforward and feedback recurrent architectures according to their connectivity patterns,
resulting in the taxonomy summarized in ﬁg. 7.1, where each family is represented by an
archetypal small module of 3-4 layers (in a typical architecture, multiple such modules may
be associated to form the full network).

Figure 7.1 Architectural taxonomy of CNNs: feedforward and feedback. Each family is represented by an
archetypal small module of 3-4 layers. Top and bottom circles stand for module’s input and output, respectively.

This work has allowed to identify the extent to which bio-inspired principles are taken
into consideration for architectures targeted at image classiﬁcation. Parallels have been made
between some architectural innovations — such as multiple feedforward shortcuts and feed-
back connections — and anatomical/functional mechanisms in the neural visual processing
pipeline. Nevertheless, these mechanisms are not well understood regarding the high-level

143

Single pathwayParallel pathwaysParallel pathways: forward shortcutsIdentity shortcutsGated shortcutsDensely connected shortcutsIntra-layerrecurrenceHybrid recurrentRecurrent with feedbackInter-layer feedbackFeedforward connectionsRecurrent/feedback connections7. Conclusion

7.1 Summary of contributions

functionalities they bring to artiﬁcial vision on realistic images.

7.1.2 Image classification over small datasets with deep models

Having placed our view of the current status of image classiﬁcation, we have proceeded
towards framing the special case of small datasets. As reviewed in chapter 5, among the wide
and heterogeneous variety of approaches to the issue, we have identiﬁed ﬁve general situations
possibly falling under the designations “learning on small datasets” or “learning under
limited data” (summarized in section 5.2.1 and ﬁg. 5.1). We have proposed this taxonomy
after identifying three main levers inﬂuencing the level of information scarcity inherent to a
dataset which are mainly related to:

(cid:73) The ratio between the amount of data samples and the data dimensionality;
(cid:73) The quantity of samples per class and the number of classes;
(cid:73) The availability of additional data, be it unlabeled samples from the same dataset, data

from a similar domain or even cross-domain related data.

The isolation of these three factors has allowed the identiﬁcation of related tasks, which
contribute with methodologies we have taken into account in our review process.

Following this conceptualization step, we have proposed an integrated view of approaches
pertinent to solving the multiple facets of the “small data learning” problem. These diﬀerent
small data situations can proﬁt from diﬀerent strategies, which we have organized in two
main axes:

(cid:73) One data-centered, regrouping methodologies consisting of using additional data in

the training process;

(cid:73) Another model-centered, regrouping methodologies which inﬂuence training complex-

ity, either by acting on the architecture or more globally on the training strategy.

This review has allowed us to identify that few works address the issue of small data
learning directly. Nevertheless, by identifying its underlying issues, it was possible to rank a
considerable amount of possibilities of action, by leveraging related literature in data aug-
mentation, semi-supervision, unsupervised representation learning, transfer learning, metric
learning, multi-task learning, meta-learning and curriculum learning. Moreover, boundaries
in this framework are not rigid, such that these diﬀerent aspects in each of this ﬁelds may be
related to diﬀerent categories. The presentation of possible solutions is innovative in the sense
that it is quite pragmatic and problem oriented: the reader is invited to ask him or herself
about his own practical problem, identifying its diﬃculties and strengths, relating them to
the possibilities ranked within the survey.

On the experimental side, we have proposed a novel class-ﬂexible version of Prototypical
networks (Snell et al, 2017), an architecture targeted at solving the few-shot learning problem.

144

7. Conclusion

7.2 Further developments

In our model the prototypes are no longer ﬁxed-class centroids. Instead, their relationship to
each of the classes and their placement in the feature space get both learned from data. This
new formulation results in data-representative prototypes, partitioning the feature vector
space (as analyzed in section 6.3 and appendix A). Ultimately, data samples will be associated
to a feature space partition, each of them associated to class probabilities that can be used to
explain the network’s predictions, bringing some degree of interpretability to at least the later
steps of its decision making process.

This model was analyzed under two small data learning strategies.

(cid:73) First, a transfer learning paradigm, consisting of reusing a pre-trained CNN as a feature

extractor;

(cid:73) Second, a meta-learning paradigm, similar to the one used in the original prototypical

networks.

The ﬁrst method has an advantage of being faster to train, since features for each data
point are ﬁxed, facilitating the study of hyperparameter sensitivity. With this approach, we
could demonstrate how the proposed concept of data-prototypes provides a mechanism for
explaining network predictions, enhancing interpretability.

The second method involves learning the network end-to-end, thus co-learning feature
extraction and the prototype based classiﬁcation together. Furthermore, with this step we
have tackled few-shot learning, one of the many presentation forms of the small data learning
problem. This additional experimental track allowed to conclude that adapting the learned
representation together is of major importance in achieving higher accuracy, in comparison to
the previous ﬁxed-feature method.

7.2 Further developments

At the course of this research work, there were many possible paths to be taken, at multiple
stages of its development. For each path taken, others inevitably had to be left for future en-
deavors. Hence some of the possible straightforward extensions and developments following
this thesis work are summarized bellow.

(cid:73) Study what has been done in other image recognition tasks: Integrating mechanisms from
object detection and segmentation could bring extra information to a classiﬁcation model
trained with limited data, implementing a multi-task learning paradigm. Furthermore,
neuroscientiﬁc evidence supports the participation of localization information from
the dorsal stream to reﬁne recognition in the ventral stream — a successful example
of multi-task system. In speciﬁc cases, tasks like pose estimation, image inpainting or
super-resolution could also be relevant.

145

7. Conclusion

7.2 Further developments

(cid:73) Study what has been done in video related tasks: Neuroscience points towards temporal
processing being important for disambiguation in segmenting and recognizing an object
in a scene, interpolating missing contours and occluded parts. In case short videos can
be as easily collected as photographs, integrating motion processing mechanisms and
video object segmentation have the potential of helping complicated and ambiguous
classiﬁcation tasks.

(cid:73) Study neuro-inspired models not targeted at image classiﬁcation: Our visual systems performs
diﬀerent tasks together and simultaneously, with evidence pointing towards many cases
of mutual inter-task cooperation. One could expect that while modeling more complex
tasks like object tracking could help elucidate fundamental principles underlying the
global visual function. One example are predictive learning mechanisms — which
involve predicting future stimuli then comparing them to actual perception — that
occur all along the visual system. The model proposed by O’Reilly and Rohrlich (2018)
for instance relies heavily on this principle, attempting to explain the construction of
invariant representations without explicit supervision signals

(cid:73) Experiment with recurrent CNN models on small data settings: Since recurrence can allow to
cut down the number of network parameters, it would be interesting to study experi-
mentally if this reduction helps generalization in practice. Before proposing yet another
model variant, it would be interesting to test existing propositions reviewed in chapter 4,
both in controlled data scenarios — to facilitate the interpretation of results — and in
realistic ones — to observe how their practical generalization evolves with decreasing
dataset sizes.

(cid:73) Experiment with other small data learning methodologies: Following up on the use of a
pre-trained network done in section 6.4.2, an evident next step would be to ﬁne-tune
at least its later layers. This could be a less computationally intensive alternative to the
end-to-end meta-learning paradigm tested in section 6.4.4. Additionally, unsupervised
representation learning methods could be associated to the proposed layer, in a similar
pre-training plus ﬁne-tuning paradigm.

(cid:73) Experiment with the proposed models on more complex datasets: Experiments with more
complex datasets could maybe indicate whether the prototype class-ﬂexibility could be
more useful. A contemporary work, featuring a similar model, with 2 prototypes per
class, has shown promising results in a dermatology dataset containing few samples for
most of its disease categories (Prabhu et al, 2018). Moreover, it would allow to validate
our proposition in more realistic scenarios.

(cid:73) Propose a recurrent version of the class-ﬂexible prototype mechanism: When trained end-
to-end, gradients updating networks weights and prototype coordinates are always

146

7. Conclusion

7.3 Open perspectives

computed at every training step. We could for instance have a hybrid arch with recurrent
prototype estimation, which would implicitly accelerate prototype reﬁnement in regards
to learning on other layers. It would however add a complexity which might not pay oﬀ
if data is insuﬃcient or of low complexity.

(cid:73) Experiment with structuring regularization penalties: Inducing an underlying structure from
the available data samples is one method towards learning a pertinent representation
with potential for generalization. It is the case of the LDMNet model (by Zhu et al, 2017b,
discussed in section 5.4.1), which encourages a low-dimensional manifold structure onto
the last hidden layer, resulting in a lower generalization gap. Analogously, the prototype
structure we proposed could be re-formulated as a “soft constraint”, with the use of an
equivalent regularization penalty (instead of the current “hard” architectural constraint).
On one hand, the penalty could involve pushing same-class close-by elements towards
the same prototype, but in a multi-modal fashion, similarly to some metric learning
losses (e.g. magnet loss Rippel et al, 2016). On the other hand, the loss term could involve
enforcing a minimum margin between prototypes to promote sharper boundaries (e.g.
Wang et al, 2018b).

7.3 Open perspectives

This work has led to the identiﬁcation of some methodological and technical diﬃculties
surrounding its research topics. Besides more immediate developments, acknowledging these
diﬃculties has motivated broader reﬂections on open research perspectives, encouraging to
rethink the current practices of the ﬁeld. Hereafter are some comments on the challenges of
most relevance to the prospective research ideas proposed in this section:

(cid:73) The (excessively) high rate of new publications in DNN literature: New models are proposed
frequently, intending to improve previous results to some extent. However, not that
many works try to analyze and bring further understanding onto what has already
been created. Most experiments are aimed at reducing error rate a few percent points,
often lacking exploratory experiments to understand more about the novel mechanisms
proposed (for instance, doing architecture ablation studies, testing robustness to diﬀerent
forms of input perturbation or measuring the generalization gap across reduced dataset
sizes).

(cid:73) Computational costs: Powerful GPUs and computing clusters have been playing an im-
portant role in the development of deep networks. Despite an increasing access to these
computational resources, most actors may never have the capabilities of major tech
companies and their leading research groups. On one hand, training multiple variants

147

7. Conclusion

7.3 Open perspectives

of the same model or simply searching for good hyperparameters is necessary. On
the other hand, they quickly multiply computational costs associated with any deep
learning research or application. Moreover, multiple repetitions would be necessary
to potentially obtain statistically meaningful results, increasing computing time even
further.

(cid:73) Hyperparameter dependency: There is a strong focus on obtaining practical results (say,
high accuracy on benchmark dataset XYZ). Regarding hyperparameters, this focus often
implicates on merely ﬁnding a good set of values for them, without further reﬂection on
the model’s robustness to their variation. Models that are too dependent on them are
likely more diﬃcult to be reused in diﬀerent application domains. Moreover, actors with
limited computational budget would be likely inclined towards more robust models,
since hyperparameter tuning multiplies computational costs,

(cid:73) Statistical soundness of results: While many search the next-one-percent accuracy improve-
ment, the statistical signiﬁcance of the obtained results is often unclear. In part due to
the computational burden, many works could not repeat experiments over diﬀerent
data splits in order to cross validate their results. Furthermore, the degree to which
comparisons of architecturally distinct models are fair or even meaningful is usually
vague.

On that account, here we highlight some possibilities of potential research contributions,

in relationship with the present work:

(cid:73) Take methodological inspiration from neuroscience: Neuroscience is deeply experimental.
To try and understand any given cognitive function, neuroscientists make hypothesis
diverse nature, concerning for instance the correlated activity of neuronal populations,
the functions they perform locally, the circuits in which the participate and global compu-
tations thereby implemented. Experiments are then designed to verify these hypothesis,
incrementally ruling out unﬁtting explanations of the observed brain phenomena. To
the end of better specifying functional capabilities of working deep networks, a similar
methodological approach could be taken. Exploratory work could look for function
specialized neural “regions”, “circuits” or “populations”. There are already some initia-
tives encouraging such “reverse engineering” of existing models as a relevant research
methodology in the ﬁeld (e.g. Cammarata et al, 2020). The proximity to mathematical
theory may lead the computer science community to dismiss this kind of knowledge
as not rigorous enough (in a mathematical sense). Nevertheless, this methodology
has allowed great advances in the neuroscientiﬁc knowledge, and could bring similar
understandings about deep networks. Eventually, experimental insights could inspire
novel theoretical explorations (and vice-versa).

148

7. Conclusion

7.3 Open perspectives

(cid:73) Understand which functionalities diﬀerent forms of recurrent processing brings to computer
vision: In a similar spirit to Spoerer et al (2017), further studies involving recurrent
CNNs could explore how to use recurrence to implement complex visual functions,
which are associated with analogous mechanisms present in the brain. Besides testing
on controlled data, it is also relevant to verify if the implemented functions translate
to realistic data. On another note, it is also important to study how the introduction of
recurrence inﬂuences the cost function landscape and thus the optimization process,
analogously what has been proposed in studies of forward shortcuts and the ResNet
architecture (e.g. Li et al, 2017).

(cid:73) Experimentally assess the data needs of standard CNN models: Theoretical eﬀorts in explain-
ing generalization capability of DNNs have indeed advanced, though the quest for
tighter generalization bounds continues. Meanwhile, from an experimental perspective,
it could be informative to study generalization ability of the main standard models, on
decreasing dataset sizes, in order to estimate their sample size-generalization error rela-
tion. Methodological aspects to be careful about comparability between diﬀerent results,
regarding hyperparameters choices. One ﬁrst possibility is to keep hyperparameters
from the original works (although some may need adjustments to allow convergence).
A larger computational budget could allow a second methodology including hyperpa-
rameter tuning for each subset size.

(cid:73) Experimentally assess the transferability of standard CNN models: Many practical applica-
tions of deep CNNs to particular application domains can be found if searching for
domain speciﬁc literature. Fine-tuning pre-trained networks is a practice frequently
found, such that a meta-analysis gathering multiple applications could be informative
on the transferability of standard architectures. Cross-referencing results could point
towards which models have been more suitable for transfer learning, under which cir-
cumstances and under which application domains. One could hypothesize that domains
with similar recognition challenges would correlate in their preference for a particular
model architecture.

(cid:73) Develop methodologies to proﬁt from domain speciﬁc implicit knowledge: Leveraging prior
knowledge on the application domain can be a valuable method to improve perfor-
mances on small datasets, as discussed in chapter 5. In many cases however, knowledge
employed in an expert’s decision are mostly implicit, making it diﬃcult to transform it
in explicit architecture adaptations or training methods. Methodologies to model this
implicit knowledge computationally (e.g. Kaadoud, 2018) could be useful in identifying
principles to be incorporated in CNN models, helping guide learning towards solutions
better adapted to the target application.

149

Appendix

A Prototype model derivation and formal interpretation

A.1 Sample to prototype association . . . . . . . . . . . . . . . . . . . . . . . . .
A.2 Reminder on softmax function . . . . . . . . . . . . . . . . . . . . . . . . . .
A.3 Deriving the model variational equations . . . . . . . . . . . . . . . . . . . .
A.4 Analysis of the k-means extended metric . . . . . . . . . . . . . . . . . . . .
. . . . .
A.5 Probabilistic interpretation of representing samples by prototypes
A.6 Duality between partition, prototypes and metric . . . . . . . . . . . . . . .
A.7 Relation between softmax and prototypes . . . . . . . . . . . . . . . . . . . .

B Methodology for hyperparameter analysis on prototype model with ﬁxed input

features

C Relevant benchmark datasets in object recognition
.
C.1 MNIST .
C.2 Omniglot
.
C.3 CIFAR 10 and 100 .
C.4

. . . . . . . . . . . . . . . . . . . . . . . . . . . .
.
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
ImageNet classiﬁcation 2012 . . . . . . . . . . . . . . . . . . . . . . . . . . .

.
.
.

.
.
.

.
.
.

.
.

.
.

.
.

.
.

.

.

D Résumé étendu en français

D.1 Contexte et motivation .
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
D.2 Positionnement du travail et plan de la thèse . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . . . . . .
D.3 Résumé des contributions .

151
151
151
152
152
153
154
155

157

159
159
160
160
160

162
162
166
167

150

Appendix A

Prototype model derivation and formal interpretation

A.1 Sample to prototype association

We approximate the probability qj(x) for the feature vector x of a sample, to be associated

to the j-th prototype writing:

qj(x)

def= τ νj (−(cid:107)x − pj(cid:107)2/2)
= τ νj
= τ νj
using the soft-max function:

(cid:0)pT
(cid:0)pT

j x − (cid:107)pj(cid:107)2/2 − (cid:107)x(cid:107)2/2(cid:1) by expansion
j x − (cid:107)pj(cid:107)2/2(cid:1)

by oﬀset invariance

τ νj (x) def= exp(fj (x)/τ )

(cid:80)

j(cid:48) exp(fj(cid:48) (x)/τ )

writing fj(x) def= pT
j x − (cid:107)pj(cid:107)2/2, thus ∂pj fj(x)T = x − pj. In the core of the paper we omit
the temperature τ without loss of generality since integrated in the fj(·) parameters. See
appendix A.2 for a review of the basic equations used in this paper.

More generally we could consider fj(x) def= −(cid:107)x − pj(cid:107)d/d, yielding ∂pj fj(x) ∗ T = (cid:107)x −

pj(cid:107)d−2 (x − pj), in order to deal with more than the L2 norm (e.g., for sparse estimation).

A.2 Reminder on softmax function

The softmax function generalizes the logistic function and enjoys the facts that:

j τ νj (x) = 1, τ νj (x) fj→fj +o = τ νj (x) , τ /τ (cid:48)νj (x) = τ νj (x)τ (cid:48) (cid:46)(cid:80)

0 ≤ τ νj (x) ≤ 1, (cid:80)
j(cid:48) νj(cid:48) (x)τ (cid:48)
,
in words, yields probability distributions with with oﬀset invariance and power eﬀect of the
temperature τ , while:

τ νj (x) = maxj(fj(x)) τ →o = 1

J + 1

fj(x) − 1
J

τ J
computes the maximal values at low temperature, while approximating the given aﬃne
operator at high temperature. Moreover, for some parameter θj(cid:48) of the fj(cid:48)(x) we obtain:

(cid:80)

(cid:17)
j(cid:48) fj(cid:48)(x)

+ O (cid:0) 1
τ 2

(cid:1) ,

(cid:16)

τ ∂θj(cid:48) τ νj(cid:48)(x) = τ νj(x) (δj=j(cid:48) − τ νj(cid:48)(x)) ∂θj(cid:48) fj(cid:48)(x),

while for some parameter θ of the x we obtain:

τ ∂θτ νj(x) = τ νj(x)

(cid:16)

∂xfj(x) − (cid:80)

j(cid:48) τ νj(cid:48)(x) ∂xfj(cid:48)(x)

(cid:17)

∂θx.

Considering an approximate cross-entropy criterion to adjust the values of a standard

151

A. Model derivation and interpretation

A.3 Deriving the model variational equations

soft-max criterion yields the following minimization:
C = − (cid:82)
(cid:39) − 1
N
= − 1
N
= − 1
τ N

X p(x) log (ν(x))
(cid:80)
i log (ν(xi))
(cid:80)
i log (νli(xi))
(cid:80)
i fli(xi) + log

(cid:17)
j(cid:48) exp(fj(cid:48)(x)/τ )

(cid:16)(cid:80)

approximating p() on the data samples
since each sample is associated to one class

by substitution and factorization

yielding the gradient, for a parameter θj(cid:48) of the function fj(cid:48)(x):
−τ ∂θj(cid:48) C = (cid:0) 1

i δj(cid:48)=li − τ νj(cid:48)(x)(cid:1) ∂θj(cid:48) fj(cid:48)(x).

(cid:80)

N

A.3 Deriving the model variational equations

Considering an approximate cross-entropy criterion to adjust the parameters given samples

xi and their label li yields the following minimization:

C = − (cid:82)
(cid:39) − 1
N

X p(x) log (c(x))
(cid:80)
i log (cli(xi))

yielding:

−N τ ∂wlCT = (cid:80)

−N τ ∂pj(cid:48) CT = (cid:80)

i [δl=li − cl(xi)]
(cid:123)(cid:122)
(cid:124)
(cid:125)
ζi
(cid:32)
(cid:34)

(cid:88)

i

(cid:124)

j

approximating p() on the data samples

q(xi)

(cid:88)

(cid:33)

(cid:35)

cl(xi) wlj

qj(xi) (δj=j(cid:48) − qj(cid:48)(xi))

(xi − pj(cid:48))

wlij −

l

(cid:123)(cid:122)
ξij(cid:48)

(cid:125)

so that we can write, for some suﬃciently small (cid:15):

∆wl = (cid:15) (cid:80)

i ζi q(xi) and pj = (cid:80)

i ξij xi/ (cid:80)

i ξij

at each step, and leading to:

(cid:73) expectation (estimated the prototypes as weighted mean over the samples),
(cid:73) minimization (decreasing the criterion by adjusting the soft-max weights) mechanism.

With such an approach there is a weak clustering of the samples with respect to a prototype,

e.g., samples with diﬀerent labels can be related to the same prototype.

A.4 Analysis of the k-means extended metric

Let us consider the for a given sample xi the augmented feature space of dimension D + J:
(xi, ci) where ci ∈ [0, 1]J are the a-priori probabilities for the sample of index i to belong to
each category. For a learning sample (xi, li) of known category li we obviously have cik = δli=k.
Such augmented dimensions act as a level-set over the feature space.

Let us consider a standard k-means algorithm on such extended feature space, for some

β > 0:

152

A. Model derivation and interpretation

A.4 Probabilistic interpretation

(pj, cj) = (cid:80)

i ξij (xi, ci)/ (cid:80)

i ξij, with jx = arg min(cid:107)xi − pj(cid:107)2 + β (cid:107)ci − cj(cid:107)2

with ξij = δj=jx ∈ {0, 1} for a hard k-means algorithm, while more general soft k-means
mechanism with ξij ≥ 0 (as in the previous subsection) could be introduced, the prototype
being the centroid of the samples belonging to this cluster.

If β = 0 the augmented dimensions are not taken into account, and we are left with the

original k-means mechanism.

If 2 β > M def= maxii(cid:48) |xi − xi(cid:48)|2 then it is easy to verify that two samples with diﬀerent
categories can not be in the same cluster, providing that the number of prototype is not lower
than the number of category.

To verify this fact, let us consider two samples (xi, li) and (xi(cid:48), li(cid:48)) with xi (cid:54)= xi(cid:48) and li (cid:54)= li(cid:48) so that

(cid:107)ci − ci(cid:48)(cid:107)2 = (cid:80)

k(δli=k − δli(cid:48) =k)2 = 2

since for k = li and k = li(cid:48) the values in the summation diﬀers by a value of 1. As a consequence,
regarding their extended distance

(cid:107)xi − xi(cid:48)(cid:107)2 + β (cid:107)ci − ci(cid:48)(cid:107)2 = (cid:107)xi − xi(cid:48)(cid:107)2 + 2β > M
it is higher than any sample pair within the same category. Furthermore, if a prototype corresponds

to samples of the same category its within-cluster maximal square distance to each sample is lower
than M , as being the centroid of the samples belonging to this cluster. As consequence, as soon as two
prototypes are used in the algorithm, if these two samples are in the same cluster, the within-cluster

distance is going to be higher than any solution with clusters only grouping samples of the same

category.

Therefore, considering a k-means algorithm with a proper initialization mechanism that
minimizes the within-cluster distance, we have a mechanism that weight the importance of
taking the a-priori information about category into account.

A.5 Probabilistic interpretation of representing samples by

prototypes

Representing the sample x by prototypes means approximating the x distribution by a

distribution only function of the prototypes, e.g.:
x (cid:39) Eˆq(x) = (cid:80)

j qj(x) pj, with ˆq(x) def= (cid:80)
where ˆq(x) approximates the true sample probability distribution p(x) as a discrete distribu-
tion, given the prototypes.

j qj(x) δ(x − pj)

Another view is to consider a partition {· · · , Pj, · · · } of the space induced by the prototypes

(i.e., with pj ∈ Pj, see Appendix C), yielding:

j p(xi ∈ Pj) p(pj|xi) = (cid:80)
for some κij = p(xi ∈ Pj). Here the partition has not to be made explicit, only the κij have to
be estimated.

q(xi) = (cid:80)

j κij qj(xi)

Very easily, we obtain (cid:80)

j κij = 1 (since Pj forms a partition), while the κj

def= (cid:80)

i κij is the

153

A. Model derivation and interpretation

A.6 Duality between partition, prototypes and metric

expectation of the number of sample in the partition, i.e. associated to the prototype. If κj = 0
the prototype is inactive, i.e., not associated to any sample. If κij ∈ {0, 1}, i.e, if we know
whether xi ∈ Pj or not, i.e., is related to this prototype or not. In such a situation, the constraint
(cid:80)
i κij is
the number of samples associated to a given prototype. This restrained modeling is not what
is proposed in this paper.

j κij = 1 states that each sample is associated to a unique prototype, while κj

def= (cid:80)

Moreover, the fact we consider for cl(x):

p(l|x) = τ νl

(cid:0)wT

l p(pj ∈ Qj|x)(cid:1) (cid:54)= (cid:80)

j p(l|pj ∈ Qj) p(pj ∈ Qj|x)

simply means that we do not consider that Qj, namely the set of samples associated to the
j-th prototype, corresponds to a partition of the sample space X , but that the corresponding
regions may overlap, while some regions may not correspond to any samples associated to
any prototypes.

A.6 Duality between partition, prototypes and metric

Given a set of prototypes P = {· · · pj · · · } in a topological space X we can consider a

partition of the space P = {· · · Pj · · · } around the prototypes, i.e. such that

pj ∈ Pj (cid:54)= ∅, ∪jPi = X , ∀i, j, ˚Pj ∩ ˚Pi = ∅.
The last condition means that we do not require the intersection to be empty but only its
interior (i.e., maximal open set). This notion of partition is thus related to a topology. Roughly
speaking, this means that we do not take into account what happens at the frontier between
two subsets of the partition. For any point, but those at the frontier between two subsets, we
can deﬁne its partition subset index j = p(x) = {j, x ∈ Pj}.

Given a set of prototypes, any metric induces such a partition, writing:

Pj = {x ∈ X , d(x, pj) <= minj(cid:48)d(x, pj(cid:48))}

On the reverse, given a partition and a topology, the ultrametric:
d(x, y) = δx(cid:54)=y (1 + δp(x)(cid:54)=p(y)) ∈ {0, 1, 2}

is a trivial metric compatible with the partition (i.e. ﬁtting in the previous deﬁnition).

More interesting is the fact that given any partition with a metric, and choosing a precision
(cid:15) there exists a countable set of prototypes such that the given partition is a subset of the
partition induced by these prototypes, up to the (cid:15) precision. If X is bounded, e.g. compact,
the prototype set if ﬁnite. Let us consider this case. Any compact set has always a ﬁnite cover.
As being a metric space, it always has a ﬁnite cover by balls of a given radius, say B(pi, (cid:15)/2).
From this construction, we only keep the prototypes corresponding to the center of balls that
intersect the initial partition subsets frontiers. It is then easy to prove that this induce, up to (cid:15),
a partition:

pj ∈ Pj (cid:54)= ∅, ∪jPi = X , ∀i, j, Pj ∩ Pi ⊂ B(pi, (cid:15)),
where Pj is deﬁned from the metric as given above. Such a construction is related to vector

154

A. Model derivation and interpretation

A.7 Relation between softmax and prototypes

support machines, the given prototypes being somehow the classiﬁcation support set.

A.7 Relation between softmax and prototypes

In our model speciﬁcation we relate a prototype representation to a softmax function

writing

qj(x) = νj (−(cid:107)x − pj(cid:107)2/2) .
Let us develop here the inverse relation and see to which extent we can link a softmax function
to prototypes.

Consider an aﬃne softmax function:

τ νl (x) def= exp(fl(x)/τ )

(cid:80)

j(cid:48) exp(fj(cid:48) (x)/τ )

with fl(x) def= wT

l x + w0

l and the decision rule

lx = arg maxl(cid:48) τ νl(cid:48) (x)

This yields a piece-wise linear segmentation of the feature space1. Writing wll(cid:48) = wl − wl(cid:48)

we obtain:

for the N (N − 1)/2 category pairs.

For each inequality we may consider any pair of points pll(cid:48), pl(cid:48)l for which the separation

lx = {l, ∀l(cid:48) (cid:54)= l, wT

ll(cid:48) x + w0

ll(cid:48) ≥ 0}

hyperplane deﬁned by wT

ll(cid:48) x + w0

ll(cid:48) = 0 is the median. We can this write2:

1Since:

τ νl (x)

⇔

⇔

⇔

(cid:80)

exp(fl(x)/τ )
l(cid:48)(cid:48) exp(fl(cid:48)(cid:48) (x)/τ )
exp(fl(x)/τ )
fl(x)

(cid:80)

exp(fl(cid:48) (x)/τ )
l(cid:48)(cid:48) exp(fl(cid:48)(cid:48) (x)/τ )

>
< τ νl(cid:48) (x)
>
<
>
< exp(fl(cid:48)(x)/τ )
>
< fl(cid:48)(x)

the denominators being identical and the exponential being a strictly increasing function, we make explicit this
piece-wise linear segmentation.

2We easily derive:

⇔

(cid:107)x(cid:107)2 − 2pT

d(x, pll(cid:48))
d(x, pll(cid:48))2
ll(cid:48) x + (cid:107)pll(cid:48)(cid:107)2
⇔
⇔ −2(pll(cid:48) − pl(cid:48)l)T x + (cid:107)pll(cid:48)(cid:107)2 − (cid:107)pl(cid:48)l(cid:107)2
ll(cid:48) x + (cid:107)pll(cid:48)(cid:107)2 − (cid:107)pl(cid:48)l(cid:107)2
⇔
ll(cid:48) x − 4 α λ(cid:107)wll(cid:48)(cid:107)2
−4 λ (cid:0)wT
ll(cid:48) x + w0
ll(cid:48)
ll(cid:48) x + w0
wT
ll(cid:48)

−4 λ wT

−4 λ wT

⇔

⇔

⇔

(cid:1) <
> 0
>
< 0

<
> d(x, pl(cid:48)l)
<
> d(x, pl(cid:48)l)2
<
> (cid:107)x(cid:107)2 − 2pT
<
> 0
<
> 0
<
> 0

l(cid:48)l x + (cid:107)pl(cid:48)l(cid:107)2

.

155

A. Model derivation and interpretation

A.7 Relation between softmax and prototypes

mll(cid:48)
pll(cid:48)
pl(cid:48)l

def= w⊥
ll(cid:48) − α wll(cid:48)
def= mll(cid:48) + λ wll(cid:48)
def= mll(cid:48) − λ wll(cid:48)
ll(cid:48)/(cid:107)wll(cid:48)(cid:107)2

α def= w0

for any λ > 0 and any vector w⊥
deﬁned up to D N (N − 1)/2 degrees of freedom (λ and w⊥
constraint, for each category pair).

ll(cid:48), wll(cid:48) ⊥ w⊥

ll(cid:48) = 0. These pairs of points pll(cid:48), pl(cid:48)l are thus
ll(cid:48) ∈ RD subject to an orthogonality

Furthermore, from a geometrical point of view, it is coherent to require that lpll(cid:48) = l, in
words that each prototype belongs to a polytope Ωl corresponding to the label l, i.e., that
∀l, l(cid:48), l(cid:48)(cid:48)l (cid:54)= l(cid:48), l (cid:54)= l(cid:48)(cid:48), wT
ll(cid:48)(cid:48) > 0. This corresponds to a linear programming problem
with D N degrees of freedom and (N (N − 1)/2)2 inequalities, thus with solutions in the
general case as soon as D > N 3/4 + O(N 2), i.e., as soon as the number of features is high
enough with respect to the number of categories.

ll(cid:48)(cid:48) pll(cid:48) + w0

Is it possible to reduce the number of prototypes, i.e., that pll(cid:48)

?= pll(cid:48)(cid:48) for some of the
N (N −1) prototypes ? This generates N additional linear constraints for each prototype merge,
and the non trivial fact that prototype pairs are to live into the same connected component of
a given Ωl has to be taken into account. A simple count of the number of degrees of freedom
shows that the number of constraints is in the general case twice the number of possible
adjustment. Prototype merge is thus possible, but not completely.

The softmax decision rules is thus equivalent to a nearest-neighbor algorithm considering

O(N 2) prototypes.

156

Appendix B

Methodology for hyperparameter analysis on
prototype model with ﬁxed input features

As far as signiﬁcance and interpretability of the results is concerned a key point is the
inﬂuence and adjustment of the algorithm hyper-parameters. We have already discussed
those for which it was worth studying speciﬁcally their inﬂuence, but let us now brieﬂy review
exhaustively all of them.

Experiments are performed in Python with help of basic scientiﬁc libraries, especially the
machine learning library scikit-learn (Pedregosa et al, 2011), from which comes implementa-
tions for k-means and cross-entropy multinomial (softmax) regression.

Regarding the k-means algorithm and its k-means++ initialization heuristic, we have to

consider:

(cid:73) The number J of clusters, studied in this section.
(cid:73) The number R of random draws of initial conditions of the expectation-minimization

algorithm.

(cid:73) The maximal number K of iteration of the expectation-minimization algorithm.
(cid:73) The tolerance E on the criterion variation in order to detect the convergence.
(cid:73) The extended criterion hyper-parameter β introduced in the previous section.
(cid:73) A choice between two algorithm variants which mainly diﬀer in computational eﬃciency,

the faster one being chosen.

Here given a data set we easily compute the maximal and minimal distances between

clusters:

M def= maxii(cid:48) |xi − xi(cid:48)|2 and m def= minii(cid:48) |xi − xi(cid:48)|2,

allowing us to adjust of ﬁx these hyper-parameters.

We have observed that the number R of random draws is not signiﬁcant as soon as suﬃcient
(typically R > 10). The maximal number of iterations K has not to be bounded because the
algorithm always converges. The tolerance E is easy to infer from the data, because as soon
as the expectation step of the k-means algorithm does not “redistribute” samples between
clusters the algorithm is expected to converge in one step. This occurs as soon as the criterion
variation magnitude is lower than the minimal distance between samples, i.e. as soon as
E (cid:28) m, say 10 times lower.

157

B. Methodology for hyperparameter analysis

The number J of clusters is to be adjusted as studied in this section, but we know in which
bounds, since we can easily set as minimal number the number of categories (i.e., considering
one cluster by category), and set as maximal number the number of learning samples (i.e.,
falling back to a nearest-neighbor algorithm).

Finally, through β is a parameter to be observed and adjusted as studied in this section, we
also know in which bounds, since β = 0 corresponds to the not taking a-priori information
into account and β = M to hard-wire prototypes on categories, as analyzed in appendix A.4.
Regarding the second step of the method — the cross-entropy minimization — we have to

consider similarly:

(cid:73) The choice of minimization solver.
(cid:73) The maximal number K of iterations of the minimization algorithm.
(cid:73) The tolerance E on the criterion variation in order to detect the convergence.
(cid:73) The choice between LD, D ∈ {1, 2} regularization.
(cid:73) The regularization balance weight C.

A softmax function being considered here, we can again calculate the output variation
under which the algorithm convergence is negligible. The classiﬁcation decision does not
vary for variations of the output below c = minjj(cid:48) |cj = cj(cid:48)| as being a comparison between
two outputs, while cj ∈ [0, 1].

For L2 penalty, L-BFGS solver was chosen for its faster convergence (less iterations). The
algorithm always converged allowing us not to consider K as a signiﬁcant value, at a tolerance
E = 10−4. Given some restrictions by the library, only one solver option was available for L1
penalties (SAGA solver). Tolerance was relaxed for SAGA solver so as to achieve convergence
within the same K iterations (E = 10−1). The initial point for both solvers is always taken at
zero, thus no hyper-parameter or heuristic is to be considered.

Beyond these parameters, the more signiﬁcant parameters C and D have been studied in

the text.

In addition to these two sets of parameters we have discussed the α ∈ [0, 1] shortcut gain

allowing us to better understand the performances ans limit of our method.

All together, the literature knowledge, simple rule of thumbs on the data values, the
concrete understanding of the proposed algorithms and speciﬁc numerical studies of more
critical parameters allows us to both propose a reproducible piece of experimental results and
a method than can be reused without any opaque or application dependent hyper-parameters
adjustment, that are not done by the hyper-parameter adjustment layer or the proposed
method.

158

Appendix C

Relevant benchmark datasets in object recognition

The purpose of this appendix is to provide a brief description on datasets mentioned
throughout the thesis. It is meant to be a quick reference for readers, summarizing the most
relevant information on each dataset. On each case, the reader is invited to refer to the original
dataset companion papers (cited in table C.1 bellow)for more detailed descriptions.

Table C.1 Information on datasets mentioned throughout this thesis.

Dataset

Domain

Input space

Number of images (per class)

Handwritten dig-
its
General purpose
photographs

General purpose
photographs

28×28 grayscale

32×32 RGB

total
70 000

60 000

training
60 000 (6000)

50 000 (5000)

32×32 RGB

60 000

50 000 (500)

validation
-

-

-

test
10 000

10 000

10 000

Number of classes

10

10

100

102

Flower species

RGB, various sizes

8 189 (40–258 per
class)

1 020 ( 10)

1 020 ( 10)

6 149 (20-238, 60
avg)

General purpose
photos
from
Flicker and alike

Car photos cate-
gorizes by Make-
Model-Year
Bird photos cate-
gorized by species

RGB, various sizes

+1.4 million

RGB, various sizes

16 185

1 281 167
(732–1300)

8 144 (50% of each
class)

RGB, various sizes

11 788

5 994

50 000 (50)

100 000 (100)

1000

-

-

8 041 (50% of each
class)

5 794

196

200

Dataset

Domain

Input space

Number of images

100×100

grayscale

32 460
char.)

(20

per

Number of classes
meta-training
1200 characters

meta-validation
-

meta-test
423 characters

total
1623 characters

Flowers-

MNIST
(Lecun et al, 1998)
CIFAR-10
(Krizhevsky,
2009)
CIFAR-100
(Krizhevsky,
2009)
Oxford
102
(Nilsback
and
Zisserman, 2008)
ImageNet classiﬁ-
cation
(Russakovsky
et al, 2015)
Stanford Cars-196
(Krause
al,
2013)
CUB-Birds-200
2011
(Wah et al, 2011)

et

Omniglot
(Lake et al, 2011)

and

mini-Imagenet
(Ravi
Larochelle, 2017)
mini-Imagenet
closed
et al, 2016)

-
(Vinyals

Handwritten
from
characters
al-
50 diﬀerent
phabets
(30 for
meta-training, 20
for meta-testing)
Subset
of
geNet 2012

Ima-

RGB, 84×84

Subset
of
geNet 2012

Ima-

RGB, 84×84

(600 samples per
class)

(600 samples per
class)

64

80

16

-

20

20

100

100

C.1 MNIST

MNIST is a dataset containing small images of handwritten digits, labeled 0 to 9. Pictures
have been basically pre-processed to have digits centered and size-normalized. A large number
(˜6000) of straining samples per digit-class is available (see more details in table C.1).

Dataset compilation was part of the work of Lecun et al (1998), which achieved signiﬁcant
success with a backpropagation trained convnet. Nowadays, this dataset is usually serves

159

C. Relevant benchmark datasets in object recognition

C.2 Omniglot

as a starting point for tutorials, or a sanity-check debugging dataset to verify minimum
function of classiﬁcation models. It is also often used to demonstrate how diﬀerent methods
learn diﬀerent embeddings for the same data, and also how diﬀerent visualization methods
diﬀerently portray a same high-dimensional embedding space in 2D or 3D.

C.2 Omniglot

Omniglot dataset was organized by Lake et al (2011). It consists of images of 1622 characters
from 50 diﬀerent alphabets, each drawn by 20 diﬀerent people (see table C.1 for more details).
The small number of samples per class and the large number of classes make it a challenging
problem to learn all the classes simultaneously. This dataset is generally used in meta-learning
works (few-shot and one-shot learning, see section 5.4.3.1 and section 6.2.2) in which a meta-
model is meta-trained on 30 alphabets, then used to learn classiﬁers over the remaining 20
alphabets.

C.3 CIFAR 10 and 100
Images CIFAR datasets (Krizhevsky, 2009) are composed of tiny 32×32 color images, labeled
into 10 or 100 categories. It can be manually downloaded at https://www.cs.toronto.
edu/~kriz/cifar.html, although most deep learning packages have dedicated functions
to download and use within the training code. Original images are issued from the 80 million
tiny images dataset (Torralba et al, 2008)1.

Labels In CIFAR-10, images are labeled into one of 10 categories: airplane, automobile,
bird, cat, deer, dog, frog, horse, ship, and truck. For CIFAR-100, images are organized in
20 superclasses, each containing 5 speciﬁc classes, resulting in total 100 labels. These ﬁner-
grained classes include more animals (like bees, butterﬂies or kangaroos), small objects (like
cups and bowls), tree types (like oak, pine), people, vehicles, among others.

Images having very low resolution, it is expected that some objects are hardly identiﬁable
— even for humans. Therefore close to perfect model performances are not necessarily a goal
per se and should be interpreted carefully.

C.4 ImageNet classification 2012

ImageNet designates a large-scale database, available at http://image-net.org, ﬁrst
organized by Princeton University (Deng et al, 2009), later joined by Stanford and others

1Tiny Images dataset was later withdrawn due to identiﬁcation of bias against political minorities (in the
work of Prabhu and Birhane, 2020), see https://groups.csail.mit.edu/vision/TinyImages/ for a
retraction note.

160

C. Relevant benchmark datasets in object recognition

C.4 ImageNet classification 2012

(Russakovsky et al, 2015). As of August 2020, the oﬃcial web page reports 14 197 122 images,
related to 21 841 currently indexed concepts (also called “synonym sets” or synsets). This
database has been the source of datasets feeding the ImageNet large scale visual recognition
challenge (ILSVRC), a competition held for 8 years, between 2010 and 2017.

Although the challenge was not restricted to classiﬁcation tasks — also comprising object
localization and detection — it is the classiﬁcation dataset which got to be commonly referred
as the “ImageNet” dataset. Its form and content have remained unchanged since the 2012
edition — in which CNNs were top-ranked for the ﬁrst time — and it is often used as data
source for most oﬀ-the-shelf pre-trained networks available online.

Images Images are photographs having been collected online from Flickr2 and other search
engines. This has resulted in a diverse dataset, both in terms of format and content. Size and
aspect ratio vary widely, as well as the the number of objects, clutter, and their pose within
the image. Since not all images are free of rights, an individual access demand is required
prior to downloading the data. More information is provided in table C.1.

Labels Image categories are based upon Wordnet 3.0 — a previously established word
hierarchy.Content covers natural scenes and living-beings, as well as man-made objects
and settings. The chosen 1000 label set contains both leaf and internal nodes taken from
this hierarchy, meaning images can naturally belong to more than one category — through
eventual parent-child relations within the concept tree. Additionally, photographs often depict
multiple objects within the same scene. Nonetheless, the classiﬁcation dataset counts with a
single ground truth label per image.

C.4.1 mini-Imagenet

This is a subset devised by Vinyals et al (2016) for meta-learning few-shot experiments.
They sampled 100 classes out of the original 1000, collecting 600 examples per class. 80 classes
are used for training and 20 for testing. Unfortunately the actual classes and data splits used
were not released at the time, leading to the creation of a new subset shortly after: Ravi and
Larochelle (2017) have sampled a diﬀerent set of 100 classes, divided into 64 for meta-training,
16 for meta-validation and 20 for testing (table C.1). Since this second subset has been publicly
released3 it ended up being the most used by follow-up works in few-shot learning.

2https://www.flickr.com/ is an online space for uploading and sharing photographs and graphic

content in general.
3Available
miniImagenet.

at

https://github.com/twitter/meta-learning-lstm/tree/master/data/

161

Appendix D

Résumé étendu en français

D.1 Contexte et motivation

D.1.1 La revolution du « deep learning »

La reconnaissance d’images a connu une révolution au cours de la dernière décennie,
principalement suite aux améliorations de performances obtenues grâce aux réseaux neu-
ronaux profonds. Même si ces modèles existaient depuis la ﬁn des années 80 – début des
années 90 (LeCun et al, 1990a), leur application réussie avait été limitée par les exigences en
matière de données et de matériel de calcul. Les progrès récents en pouvoir de calcul — avec
la possibilité de traiter les opérations à grande matrice en parallèle avec les consommateurs
GPUs — et dans la disponibilité des données — avec l’utilisation généralisée des appareils
photo numériques et des plateformes de partage de photos en ligne — ont été décisifs pour
changer ce scénario. L’amélioration de 12 % en précision dans l’édition 2012 du concours
ILSVRC est emblématique de cette révolution, qui a ﬁni par être un jalon d’une utilisation
réussie des réseaux convolutifs (CNNs) pour la reconnaissance d’objets à usage général.

Ces modèles d’apprentissage machine ont non seulement atteint une précision sans précé-
dent en matière de reconnaissance d’objets, mais ont également apporté un nouveau para-
digme d’extraction et de catégorisation des caractéristiques d’apprentissage en commun, au
sein d’un modèle unique. En eﬀet, ce paradigme d’entraînement de bout en bout, en faisant
correspondre directement les images aux étiquettes classes, est devenu un standard de facto
dans la plupart des travaux de vision par ordinateur. Il est souvent avancé que cette façon
de procéder — en apprenant à partir d’exemples — est plus proche de la façon dont les
humains voient et apprennent à reconnaître les objets dans la nature. Cependant, de telles
similitudes entre la vision informatique et la vision neurale biologique existent à un niveau
plutôt superﬁciel, alors que nos neurones et nos régions corticales fonctionnent de manière
beaucoup plus complexe, mettant en œuvre des fonctions absentes des CNNs typiques.

162

D. Résumé étendu en français

D.1 Contexte et motivation

D.1.2 Limites de la bio-inspiration

Les réseaux de neurones sont constitués de couches successives de neurones artiﬁciels
interconnectés, qui s’inspirent vaguement du fonctionnement des cellules neuronales na-
turelles. Plus précisément, ils modélisent la propagation de l’information à seuil eﬀectuée
par les neurones, lorsqu’ils transmettent sélectivement un potentiel d’action électrique. Un
neurone artiﬁciel est une compositions de fonctions mathématiques, qui calcule d’abord une
combinaison linéaire de ses entrées, puis fait passer la sortie résultante par une non-linéarité
qui imite le mécanisme de seuil biologique. Cette modélisation est très simpliﬁée et néglige
tout aspect temporel pertinent pour le fonctionnement des vrais neurones.

La bio-inspiration est également présente à un niveau plus élevé, dans la façon dont les
neurones sont organisés et les modèles qu’ils apprennent. Les réseaux profonds (DNNs)
prennent leur prédicat de dénomination de leur architecture archétypique consistant en
un empilement de multiples couches de neurones. Chaque couche reçoit les sorties de son
homologue précédent, eﬀectuant ensuite une autre étape de traitement de l’information, avant
de transmettre le résultat à la couche suivante. Cette structure de traitement incrémentielle,
lorsqu’elle est formée sur des ensembles de données d’images naturelles, a été démontré
comme fonctionnant de manière hiérarchique, similaire à l’organisation fonctionnelle des
diﬀérentes régions corticales impliquées dans notre propre vision biologique. Les premières
couches ont tendance à apprendre à détecter les caractéristiques des images de bas niveau telles
que les parties de bordures dans diﬀérentes orientations — dans une analogie fonctionnelle
avec notre cortex visuel primaire — tandis que les couches suivantes se spécialisent dans la
détection de concepts plus abstraits et, en ﬁn de compte, dans la classe des images — dans un
rôle analogue à celui du cortex IT.

Bien que cette similitude fonctionnelle semble être présente, il reste beaucoup de choses
inexpliquées dans les CNNs feedforward typiques. Les connexions de raccourci entre régions,
le traitement local récurrent, les connexions de feedback à longue portée, la modulation d’atten-
tion — ce sont autant de caractéristiques absentes de ces modèles et réputées pour jouer un
rôle important dans le traitement d’une scène visuelle. On sait par exemple que le traitement
récurrent permet de reconnaître des objets sous un encombrement visuel, une tâche dans
laquelle les CNNs peuvent avoir quelques diﬃcultés. On peut se demander comment l’incor-
poration de telles fonctionnalités pourrait aider les performances des CNN, à la fois de manière
quantitative et qualitative. En outre, on peut se demander laquelle de ces améliorations serait
la plus pertinente dans un scénario particulièrement diﬃcile.

Bien qu’une étude détaillée de ce problème ne soit pas l’objectif principal de cette thèse
(le lecteur peut se référer à (Medathati et al, 2016) pour un examen détaillé), ce travail
est prudent lorsqu’il s’agit de bio-inspiration et de plausibilité des architectures révisées et
développées. Sans s’attacher à un niveau particulier de plausibilité biologique, la fonction et
la structure biologiques ont servi de référence transversale pour à la fois les développements

163

D. Résumé étendu en français

D.1 Contexte et motivation

expérimentaux et la revue de la littérature, qui sont abordés à plusieurs reprises tout au long
de ce travail.

D.1.3 Le problème des petits corpus de données

Tous ces progrès sont toutefois liés à la disponibilité généralisée de corpus de données
à grande échelle, avec des milliers d’échantillons par catégorie d’images, s’élevant à des
millions d’images dans l’ensemble des données. Comme les grands réseaux neuronaux ont
un nombre énorme de paramètres à apprendre, un grand nombre d’exemples est nécessaire
pour que le modèle d’apprendre une représentation pertinente de l’espace de présentation
et de généraliser ses prédictions. Sur des ensembles de données plus petits, de tels modèles
de grande taille sont susceptibles de sur-ajuster aux données d’entraînement et de ne pas
généraliser aux données cibles.

De nombreux domaines, si ce n’est la plupart, sont en fait plus susceptibles de produire
de petits corpus de données étiquetés, pour une multitude de raisons. Par exemple, dans le
domaine des diagnostics par imagerie médicale, les essais avec chaque patient sont limités,
certaines conditions sont rarement rencontrées et l’étiquetage est coûteux car il exige l’avis
d’un ou plusieurs experts. Dans l’industrie, le contexte des images prises à partir d’une
usine de production, d’une machine particulière ou d’une étape d’un pipeline peut être
suﬃsamment spéciﬁque pour qu’un corpus de données dédié doive être collecté sur place. Ce
même corpus de données nécessitera plus tard qu’un technicien expert identiﬁe manuellement
toute condition défectueuse ou déviante. Le fait est que dans la plupart des organisations
qui ne travaillent pas directement avec la collecte de données, mais simplement désireuse
d’automatiser un certain processus interne, la composition d’un corpus de données dédié
n’est pas simple, ni en termes de coût ni de logistique. Par conséquent, dans la plupart de ces
cas, on peut être confronté à des conditions diﬃciles en termes de disponibilité des données
pour l’application de toute méthode d’apprentissage machine, et l’apprentissage profond en
particulier.

Dans de nombreux cas, le premier réﬂexe d’un ingénieur en apprentissage de machines
bien formé peut être de revenir à des modèles moins complexes — comme les arbres de
décision par exemple — et en particulier à des versions d’ensemble de ceux-ci — comme les
forêts aléatoires ou XGboost. Mais n’oublions pas non plus notre intérêt pour l’exploitation des
données sous forme d’images. Les caractéristiques orientées vers les données apprises par les
modèles profonds semblent jouer un rôle fondamental dans la les récentes percées en matière
de reconnaissance d’images. Les méthodes précédentes de conception de caractéristiques
(feature engineering) n’ont pas eu un niveau de succès comparable dans la catégorisation des
images. En outre, ces caractéristiques spéciﬁques aux données peuvent être d’autant plus
précieuses pour la reconnaissance quand on est dans un domaine très particulier, dans lequel
les caractéristiques visuelles générales peuvent ne pas être aussi discriminantes comme le

164

D. Résumé étendu en français

D.1 Contexte et motivation

serait un ensemble de caractéristiques spécialisées liées à une tâche ou à un domaine. Cette
volonté conﬂictuelle de modéliser de petits corpus de données de manière centrée sur les
données est la principal motivation derrière le présent travail. Tout au long de ce manuscrit,
nous cherchons à comprendre l’apprentissage des caractéristiques hiérarchiques eﬀectué par
les réseaux neuronaux profonds — en particulier les architectures convolutives — tout en
déﬁnissant les circonstances dans lesquelles elles peuvent être exploitées avec succès dans le
cadre de la disponibilité limitée des données pour l’entraînement. Une exploration détaillée
de ce problème avec une analyse de ses diﬀérentes parties constitutives constitue une part
importante du travail de cette thèse.

D.1.4 Litterature sur le « deep learning »

Dans l’ensemble, la recherche dans la communauté de l’apprentissage machine s’est
fortement orientée récemment vers le travail en réseau profond. En eﬀet, les conférences
spéciﬁquement liées au sujet (NeurIPS, ICML, IJCNN, entre autres) ont connu une augmen-
tation exponentielle du nombre de soumissions et de la participation globale. En outre, la
pré-publication d’articles sur des plateformes en ligne ouvertes, telles que ArXiv, a également
donné et accéléré le rythme dans ce domaine, avec des interactions — des citations et des
travaux dérivés — qui se passent tous dans un rythme beaucoup plus rapide qu’un cycle de
publication typique, avec examen par les pairs. Il s’agit d’une question diﬃcile et longue en
soi de naviguer à travers ce corpus littéraire toujours croissant, en essayant de discerner les
tendances prometteuses des idées éphémères.

En essayant de se concentrer sur le problème spéciﬁque de l’apprentissage avec petits
corpus de données — small data learning, on ﬁnira par se rendre compte qu’elle entraîne
quelques diﬃcultés plus particulières. Premièrement, il ne s’agit pas d’un seul mais de
plusieurs problèmes. On peut parler de plusieurs contextes pratiques diﬀérents comme
étant une forme d’apprentissage small data. Deuxièmement, peu d’ouvrages ont tenté de
mesurer et d’aborder directement la diﬃculté de l’entraînement CNNs sur de petits corpus de
données, en abordant plutôt les diﬃcultés similaires rencontrées dans d’autres sous-domaines
(par exemple, catégorisation ﬁne, apprentissage métrique, apprentissage par transfert, méta-
apprentissage, pour n’en citer que quelques-uns). La combinaison de ces deux aspects conduit
à une troisième observation générale : l’état actuel des connaissances dans ce domaine n’est pas
facilement disponible à toute personne ayant un intérêt naissant pour ce problème. Au lieu de
cela, il faut lire des papiers de plusieurs domaines connexes aﬁn d’établir les déﬁs et les leviers
d’action face à toute forme particulière de rareté des données. Il est donc primordial de revisiter
ces diﬀérents domaines, en structurant et en reliant des études apparemment déconnectées
qui couvrent ces multiples aspects du sujet. Cet eﬀort d’organisation des connaissances est
l’un des aspects majeurs du travail de cette thèse.

165

D. Résumé étendu en français

D.2 Positionnement du travail et plan de la thèse

D.2 Positionnement du travail et plan de la thèse

Dans la première section de cette introduction, nous avons établi la diﬃculté et l’intérêt
général d’appliquer l’apprentissage approfondi à de petits ensembles de données. Même
en limitant le champ d’application à la reconnaissance d’objets, et en particulier à l’image il
existe encore une grande diversité d’approches dans ce domaine. Compte tenu de l’évolution
rapide de la recherche sur l’apprentissage profond et du vaste corpus de littérature, il est
indispensable de faire le point sur l’état de l’art aﬁn de placer toute proposition nouvelle. En
outre, comme les scénarios de données de petite taille sont multiples, il devient nécessaire
de clariﬁer et de distinguer les diﬀérentes versions de ces problèmes avant d’aborder un
cas particulier. Nous avons donc abordé cette question à travers deux axes méthodologiques
principaux (voir ﬁgure 1.1) :

(cid:73) Un travail d’analyse documentaire approfondi visant à présenter une vision claire et

concise du domaine et le problème à traiter (cf. chapitres ??) ;

(cid:73) Propositions expérimentales explorant de nouveaux mécanismes dans le cadre révisé

(cf. chapitre 6).

Plan Il ressort également de notre discussion que le problème de la reconnaissance d’objets
avec des CNN sur de petits ensembles de données est en fait un méta-problème englobant de
multiples sous-problèmes. En tant que tel, il est nécessaire (i) d’identiﬁer les parties qui le
composent et (ii) de décider lesquelles et comment traiter chacune d’entre elles. Nous avons
donc décidé d’organiser ce travail en deux parties, en abordant d’abord la reconnaissance des
objets (part I), suivi d’un traitement spéciﬁque du petit cas de données (part II).

Dans la part I, nous avons abordé la reconnaissance d’objets d’un point de vue interdisci-
plinaire, en discutant des CNN artiﬁcielles ainsi que de leurs aspects d’inspiration biologique :

(cid:73) Tout d’abord, nous présentons le fonctionnement de base de la reconnaissance d’objets,
à la fois dans les CNN et dans le cerveau (cf. chapitre 2). En particulier, nous passons
en revue les travaux récents comparant les CNN et les représentations corticales, et
résumer les caractéristiques fonctionnelles et architecturales non modélisées par les
CNN typiques.

(cid:73) Comme les capacités modernes de reconnaissance d’objets ont été réalisées avec les
CNNs feedforward, cette catégorie de modèles est examinée et organisée dans le chapitre
3. Alors que d’autres examens sur le sujet ont été publiés au cours de ce travail de
thèse, ils n’ont pas nécessairement formulé le sujet d’une manière pertinente pour le
travail développé ici. Il était donc en tout cas pertinent de réviser l’histoire du progrès
des principes et des innovations architecturales, en mettant en évidence les tendances
pertinentes pour le présent travail.

166

D. Résumé étendu en français

D.3 Résumé des contributions

(cid:73) Complétant le travail de révision précédent, le chapitre 4 traite des modèles CNN
récurrents et de rétroaction pour la catégorisation des images. Le chapitre vise à organiser
les modèles examinés en fonction de leur utilisation de la récurrence, d’un point de vue
fonctionnel et architectural. En plus de proposer une étude de la littérature avec des
perspectives et des points de vue innovants, l’étude des traitements récurrents dans
les CNN pour la catégorisation des images illustre également le potentiel d’échange de
connaissances

Après avoir posé notre paradigme sur la reconnaissance d’objets, nous abordons les conditions
correspondant à l’apprentissage sur small data dans II en deux étapes :

(cid:73) Une description plus détaillée du problème est présentée dans le chapitre 5, y compris
un examen des principales stratégies présentes dans la littérature sur l’apprentissage
approfondi. Ce chapitre est un eﬀort d’organisation des connaissances existantes dans le
domaine, tout en les reliant à des tâches connexes présentant des diﬃcultés similaires.

(cid:73) Finalement, le travail est complété par des propositions expérimentales dans le cadre
des small data, y compris la proposition de nouveaux mécanismes et perspectives, en
s’appuyant sur les modèles profonds existants.

En ﬁn de compte, un travail de thèse typique a tendance à ouvrir beaucoup plus de
questions de recherche qu’il n’en ferme. Après un travail d’examen approfondi, il est naturel
d’identiﬁer les espaces de contribution et d’interaction possibles entre les domaines qui
pourraient contribuer à faire progresser les connaissances. Comme ceux-ci pourraient faire
l’objet de nombreuses autres thèses, ces perspectives ouvertes seront exposées et discutées
dans la conclusion de la thèse.

D.3 Résumé des contributions

D.3.1 Étude et compréhension de la reconnaissance d’objets

d’un point de vue interdisciplinaire

En comparant les CNN et les modèles neuroscientiﬁques de la vision (passés en revue au
chapitre 2), Des similitudes ont été trouvées dans de multiples travaux interdisciplinaires.
Sur le plan fonctionnel, il a été démontré que les couches précoces et tardives sont hautement
prédictives de l’activité des zones corticales V1-V2 et V4-IT, respectivement, en considérant
les données des deux réponses neurophysiologiques (?Yamins and DiCarlo, 2016) et l’activité
IRMf (Eickenberg et al, 2016). D’un point de vue plus « comportemental », Il a été démontré
que les CNN prennent des décisions de catégorisation similaires à celles prises par les primates

167

D. Résumé étendu en français

D.3 Résumé des contributions

(lorsqu’ils sont entraînés à des tâches suﬃsamment diﬃciles), ayant présenté des modèles de
matrice de confusion similaires à ceux des humains et des singes (Rajalingham et al, 2018).
Ces similitudes se limitent à la reconnaissance rapide des objets du noyau cérébral, corres-
pondant aux cent premières millisecondes de traitement cortical. Il a été démontré que des
traitements visuels plus complexes dépendent de principes fonctionnels et de chemins archi-
tecturaux non modélisés dans les CNN typiques. Nous avons étudié trois aspects principaux :

(cid:73) Traitement et codage avancés eﬀectués respectivement dans la rétine et les structures
thalamiques, tels que la compression spatio-temporelle et l’intégration computationnelle
de plusieurs zones corticales ;

(cid:73) Interaction entre les ﬂux dorsal et ventral — donc entre la reconnaissance et la localisation.
Les ﬂux dorsaux et ventaux partagent des informations sur le mouvement, la couleur et
la forme, à plusieurs niveaux des deux hiérarchies ;

(cid:73) Le rôle des connexions récurrentes de traitement et de rétroaction vers une perception
visuelle plus raﬃnée dans des conditions diﬃciles. Récurrences locales et à long terme —
y compris les connexions susmentionnées avec les zones thalamiques et dorsales — sont
cruciales pour permettre d’aﬃner et de désambiguïser les frontières entre les objets,
l’interpolation des informations manquantes à partir des récurrences spatiales locales et
l’intégration des signaux de traitement des mouvements.

De ces trois principes, le traitement récurrent est le plus général, car il est présent à plusieurs
niveaux de la hiérarchie de la vision, ce qui a motivé l’examen de la manière dont ce mécanisme
a été intégré aux CNN dans la littérature récente.

Depuis les premiers CNN simples et à ﬂux continu, de nombreuses innovations architectu-
rales ont été présentées au ﬁl des ans, comme le montrent les chapitres ??. Les deux chapitres
ont organisé les architectures récurrentes de feedforward et de feedback en fonction de leurs
modèles de connectivité, ce qui donne la taxonomie résumée dans la ﬁgure 7.1, où chaque
famille est représentée par un petit module archétypal de 3-4 couches (dans une architecture
typique, plusieurs de ces modules peuvent être associés pour former le réseau complet).

Ce travail a permis de déterminer dans quelle mesure les principes bio-inspirés sont pris
en considération pour les architectures ciblées sur la catégorisation des images. Des parallèles
ont été établis entre certaines innovations architecturales — tels que les multiples raccourcis
en avant (feedforward) et les connexions de retour d’information (feedback) — et des méca-
nismes anatomiques/fonctionnels dans le pipeline de traitement visuel neural. Néanmoins,
ces mécanismes ne sont pas bien compris en ce qui concerne les fonctionnalités de haut niveau
qu’ils apportent à la vision artiﬁcielle sur des images réalistes.

168

D. Résumé étendu en français

D.3 Résumé des contributions

D.3.2 Classification d’images sur des corpus restreints

avec des réseaux profonds

Après avoir placé notre vue sur l’état actuel de la classiﬁcation des images, nous avons
procédé à l’encadrement du cas particulier des petits ensembles de données. Comme nous
l’avons vu dans le chapitre 5, parmi la grande variété et l’hétérogénéité des approches de
la question, nous avons identiﬁé cinq situations générales susceptibles de relever des déno-
minations "Apprendre sur de petits ensembles de données ou "apprentissage sous données
limitées" (résumé dans la section 5.2.1 et la ﬁgure 5.1). Nous avons proposé cette taxonomie
après avoir identiﬁé trois principaux leviers inﬂuençant le niveau de rareté de l’information
inhérent à un corpus de données qui sont principalement liés à

(cid:73) Le rapport entre la quantité d’échantillons et la dimensionnalité des données ;
(cid:73) La quantité d’échantillons par classe et le nombre de classes ;
(cid:73) La disponibilité de données supplémentaires, qu’il s’agisse d’échantillons non-étiquetés
provenant du même corpus de données, des données d’un domaine similaire ou même
des données liées à plusieurs domaines.

L’isolement de ces trois facteurs a permis d’identiﬁer des tâches connexes, qui contribuent
aux méthodologies que nous avons prises en compte dans notre processus de révision.

Suite à cette étape de conceptualisation, nous avons proposé une vision intégrée des
approches pertinent pour résoudre les multiples facettes du problème de l’apprentissage
sur small data. Ces diﬀérentes situations de petites données peuvent bénéﬁcier de diﬀérentes
stratégies, que nous avons organisées en deux axes principaux :

(cid:73) Le premier centré sur les données, regroupant les méthodologies consistant à utiliser

des données supplémentaires dans le processus d’entraînement ;

(cid:73) Le deuxième centré sur le modèle, regroupant les méthodologies qui inﬂuencent la
complexité de l’entraînement, soit en agissant sur l’architecture, soit plus globalement
sur la stratégie d’entraînement.

Cet examen nous a permis de constater que peu d’ouvrages abordent directement la
question de l’apprentissage sur small data. Néanmoins, en identiﬁant ses problèmes subjacents,
il a été possible de classer un nombre considérable de possibilités d’action, en tirant parti de
la littérature connexe dans augmentation des données, semi-supervision, l’apprentissage de
la représentation non supervisée, l’apprentissage par transfert, l’apprentissage de métrique,
l’apprentissage multitâche, le méta-apprentissage et l’apprentissage via curriculum. En outre,
les frontières dans ce cadre ne sont pas rigides, de sorte que ces diﬀérents aspects dans chacun
de ces domaines peuvent être liés à diﬀérentes catégories. Cette présentation des solutions
possibles est innovante dans le sens qu’elle est assez pragmatique et axée sur les problèmes : le
lecteur est invité à s’interroger sur son propre problème pratique, en identiﬁant ses diﬃcultés
et ses points forts, en les mettant en relation avec les possibilités discutés dans la revue.

169

D. Résumé étendu en français

D.3 Résumé des contributions

Sur le plan expérimental, nous avons proposé une nouvelle version des réseaux prototy-
piques (Snell et al, 2017) (une architecture visant à résoudre le problème de l’apprentissage en
quelques coups), mais plus souple au niveau des classes. Dans notre modèle, les prototypes ne
sont plus des centroïdes de classe ﬁxe. Au lieu de cela, leur relation avec chacune des classes
et leur placement dans l’espace de caractéristiques sont tous les deux appris des données.
Cette nouvelle formulation permet d’obtenir des prototypes représentatifs des données, en
partitionnant l’espace vectoriel des caractéristiques (comme analysé dans la section 6.3 et
l’annexe A). En ﬁn de compte, les échantillons de données seront associés à une partition de
l’espace des caractéristiques, chacun d’entre eux étant associé à des probabilités de classe, qui
peuvent être utilisées pour expliquer les prédictions du réseau, apportant un certain degré de
l’interprétabilité, au moins aux étapes ultérieures de son processus décisionnel.

Ce modèle a été analysé dans le cadre de deux stratégies d’apprentissage small data :

(cid:73) Premièrement, un paradigme d’apprentissage par transfert, consistant à réutiliser une

CNN préformée comme extracteur de caractéristiques ;

(cid:73) Second, un paradigme de méta-apprentissage, similaire à celui utilisé dans les réseaux

prototypiques originaux.

La première méthode a l’avantage d’être plus rapide à mettre en œuvre, puisque les
caractéristiques de chaque point de données sont ﬁxes, ce qui facilite l’étude de la sensibilité
des hyperparamètres. Avec cette approche, nous avons pu démontrer comment le concept
proposé de data-prototypes fournit un mécanisme permettant d’expliquer les prévisions du
réseau, améliorer l’interprétabilité.

La deuxième méthode consiste à apprendre le réseau de bout en bout, Ainsi, l’extraction
des caractéristiques de co-apprentissage et la catégorisation basée sur les prototypes sont
combinées. De plus, avec cette étape, nous avons abordé l’apprentissage en quelques clics,
l’une des nombreuses formes de présentation du petit problème d’apprentissage des données.
Cette piste expérimentale supplémentaire a permis de conclure que l’adaptation commune
de la représentation apprise est d’une importance majeure en obtenant une précision plus
élevée, par rapport à la méthode précédente des caractéristiques ﬁxes.

170

Index

active learning, 97

acquisition function, 97
querry batch selection, 97

bio-inspiration, 28
limits, 17, 42

convolutional neural networks, 29

convolutional layers, 29
pooling, 30

Convolutional recurrent networks

Conv. GRU, 71
Conv. LSTM, 71
cortical hierarchy, 32

data augmentation, 91

extra-cortical processing

retina, 43
thalamus, 43

ImageNet, 28
Inception, 53

neural networks

activations, 31
autoencoders, 22

GAN, 22
generative models, 22
GRU, 22
LSTM, 22
recurrent networks, 22
ReLU, 31

object recognition

object detection, 20
object localization, 20
semantic segmentation, 21

recurrent processing in vision, 44
attentional modulation, 44
perceptual grouping, 44
retina, 43
spatial reﬁnement, 44
time-scale, 44

retina, 37

retinal processing, 43

transfer learning, 89
two-stream model of vision, 33

dorsal pathway, 33
interactions, 45
ventral pathway, 33, 34

171

Bibliography

Abadi, M., Barham, P., Chen, J., Chen, Z., Davis, A., Dean, J., Devin, M., Ghemawat, S., Irving, G., Isard, M.,
Kudlur, M., Levenberg, J., Monga, R., Moore, S., Murray, D. G., Steiner, B., Tucker, P., Vasudevan, V., Warden,
P., Wicke, M., Yu, Y. and Zheng, X. (2016). “TensorFlow: A system for large-scale machine learning”. In 12th
USENIX Symposium on Operating Systems Design and Implementation (OSDI 16), pp. 265–283. Cited on page 54.

Agarwal, S., Terrail, J. O. D. and Jurie, F. (2018). “Recent Advances in Object Detection in the Age of Deep

Convolutional Neural Networks”.

arxiv: 1809.03193 . Cited on page 21.

Alom, M. Z., Hasan, M., Yakopcic, C. and Taha, T. M. (2017). “Inception Recurrent Convolutional Neural

Network for Object Recognition”.

arxiv: 1704.07709 . Cited on page 64.

Andreopoulos, A. and Tsotsos, J. K. (2013). “50 Years of object recognition: Directions forward”. Computer
Vision and Image Understanding, 117, no. 8, 827–891. ISSN 10773142. doi: 10.1016/j.cviu.2013.04.005 .
Cited on page 27.

Antoniou, A., Storkey, A. and Edwards, H. (2018). “Data Augmentation Generative Adversarial Networks”.

arXiv:1711.04340 [cs, stat].

arxiv: 1711.04340 . Cited on page 93.

Ash, J. T., Zhang, C., Krishnamurthy, A., Langford, J. and Agarwal, A. (2019). “Deep Batch Active Learning by
arxiv: 1906.03671 . Cited on

Diverse, Uncertain Gradient Lower Bounds”. arXiv:1906.03671 [cs, stat].
page 98.

Ba, J., Mnih, V. and Kavukcuoglu, K. (2015). “Multiple Object Recognition with Visual Attention”. In International
arxiv: 1412.7755v2 .

Conference on Learning Representations (ICRL), pp. 1–10. ISBN 978-1-4244-6516-3.
Cited on pages 67, 70, 78, and 108.

Bach, S., Binder, A., Montavon, G., Klauschen, F., Müller, K.-R. and Samek, W. (2015). “On Pixel-Wise Expla-
nations for Non-Linear Classiﬁer Decisions by Layer-Wise Relevance Propagation”. PLOS ONE, 10, no. 7,
e0130140. ISSN 1932-6203. doi: 10.1371/journal.pone.0130140 . Cited on pages 120 and 121.

Badrinarayanan, V., Kendall, A. and Cipolla, R. (2017). “SegNet: A Deep Convolutional Encoder-Decoder
Architecture for Image Segmentation”. IEEE Transactions on Pattern Analysis and Machine Intelligence, 39, no. 12,
2481–2495. ISSN 01628828. doi: 10.1109/tpami.2016.2644615 .
arxiv: 1511.00561 . Cited on pages
51, 52, and 100.

Ballas, N., Yao, L., Pal, C. and Courville, A. (2015). “Delving Deeper into Convolutional Networks for Learning
arxiv: 1511.06432 . Cited on pages 63, 71, and 77.

Video Representations”.

Banerjee, A., Merugu, S., Dhillon, I. S. and Ghosh, J. (2005). “Clustering with Bregman Divergences”. Journal of
Machine Learning Research, 6, 1705–1749. ISSN 08856125. doi: 10.1007/s10994-005-5825-6 . Cited on
pages 118 and 124.

Bao, J., Chen, D., Wen, F., Li, H. and Hua, G. (2017). “CVAE-GAN: Fine-Grained Image Generation through

Asymmetric Training”. arXiv:1703.10155 [cs].

arxiv: 1703.10155 . Cited on page 93.

Baur, C., Albarqouni, S. and Navab, N. (2018). “Generating Highly Realistic Images of Skin Lesions with GANs”.

arXiv:1809.01410 [cs, eess].

arxiv: 1809.01410 . Cited on page 93.

172

BIBLIOGRAPHY

Belharbi, S., Chatelain, C., Hérault, R. and Adam, S. (2017). “Neural Networks Regularization Through Class-
arxiv: 1709.01867 . Cited on page

wise Invariant Representation Learning”. arXiv:1709.01867 [cs, stat].
105.

Belkin, M. and Niyogi, P. (2004). “Semi-supervised learning on riemannian manifolds”. Machine Learning, 56,
no. 1-3, 209–239. ISSN 08856125. doi: 10.1023/b:mach.0000033120.25363.1e . Cited on page 95.

Bell, S., Zitnick, C. L., Bala, K. and Girshick, R. (2016). “Inside-Outside Net: Detecting Objects in Context
with Skip Pooling and Recurrent Neural Networks”. In 2016 IEEE Conference on Computer Vision and Pattern
Recognition (CVPR), vol. 2016-Decem, pp. 2874–2883. IEEE. ISBN 978-1-4673-8851-1. doi: 10.1109/cvpr.
2016.314 .

arxiv: 1512.04143 . Cited on pages 65, 73, and 74.

Bellet, A., Habrard, A. and Sebban, M. (2013). “A Survey on Metric Learning for Feature Vectors and Structured

Data”. Tech. Rep., Laboratoire Hubert Curien UMR 5516.

arxiv: 1306.6709 . Cited on page 119.

Beluch, W. H., Genewein, T., Nurnberger, A. and Kohler, J. M. (2018). “The Power of Ensembles for Active
Learning in Image Classiﬁcation”. In 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition,
pp. 9368–9377. doi: 10.1109/CVPR.2018.00976 . Cited on page 97.

Bengio, Y. and LeCun, Y. (2007). “Scaling Learning Algorithms towards {AI}”. Large Scale Kernel Machines, ,

no. 1, 321–360. ISSN 00099104.

arxiv: 1011.1669v3 . Cited on page 115.

Bengio, Y., Lee, D.-H., Bornschein, J. and Lin, Z. (2016). “Towards Biologically Plausible Deep Learning”. Tech.

Rep..

arxiv: 1502.04156 . Cited on page 116.

Bengio, Y., Louradour, J., Collobert, R. and Weston, J. (2009). “Curriculum learning”. In Proceedings of the 26th
Annual International Conference on Machine Learning - ICML ’09, pp. 41–48. ACM Press, Montreal, Quebec,
Canada. ISBN 978-1-60558-516-1. doi: 10.1145/1553374.1553380 .
arxiv: 1011.1669v3 . Cited on
page 110.

Bengio, Y., Simard, P. and Frasconi, P. (1994). “Learning long-term dependencies with gradient descent is
diﬃcult”. IEEE Transactions on Neural Networks, 5, no. 2, 157–166. ISSN 1941-0093. doi: 10.1109/72.279181
. Cited on page 22.

Bergstra, J. and Bengio, Y. (2012). “Random Search for Hyper-Parameter Optimization”. Journal of Machine

Learning Research, 13, 281–305. ISSN 1532-4435. Cited on page 75.

Berry, M. J., Brivanlou, I. H., Jordan, T. A. and Meister, M. (1999). “Anticipation of moving stimuli by the retina”.

Nature, 398, no. 6725, 334–338. ISSN 00280836. doi: 10.1038/18678 . Cited on page 43.

Berthelot, D., Carlini, N., Goodfellow, I., Papernot, N., Oliver, A. and Raﬀel, C. A. (2019). “MixMatch: A Holistic
Approach to Semi-Supervised Learning”. In H. Wallach, H. Larochelle, A. Beygelzimer, F. d\textquotesingle
Alché-Buc, E. Fox and R. Garnett (eds.), Advances in Neural Information Processing Systems 32, pp. 5050–
5060. Curran Associates, Inc. url: http://papers.nips.cc/paper/8749-mixmatch-a-holistic-
approach-to-semi-supervised-learning.pdf. Cited on pages 92 and 106.

Boney, R. and Ilin, A. (2017). “Semi-Supervised Few-Shot Learning with Prototypical Networks”. NIPS

Workshops, pp. 1–5.

arxiv: 1711.10856 . Cited on page 95.

Boyd, S., Parikh, N., Chu, E., Peleato, B. and Eckstein, J. (2011). “Distributed Optimization and Statistical
Learning via the Alternating Direction Method of Multipliers”. 3, no. 1, 1–122. doi: 10.1561/2200000016 .
Cited on page 105.

Bullier, J. (2001). “Integrated model of visual processing”. Brain research reviews, 36, no. 2-3, 96–107. ISSN

01650173. doi: 10.1016/s0165-0173(01)00085-6 . Cited on page 115.

Cadieu, C. F., Hong, H., Yamins, D. L. K., Pinto, N., Ardila, D., Solomon, E. A., Majaj, N. J. and DiCarlo, J. J. (2014).
“Deep Neural Networks Rival the Representation of Primate IT Cortex for Core Visual Object Recognition”.
PLoS Computational Biology, 10, no. 12, e1003963. ISSN 15537358. doi: 10.1371/journal.pcbi.1003963 .

173

BIBLIOGRAPHY

arxiv: 1406.3284 . Cited on pages 41 and 142.

Cammarata, N., Carter, S., Goh, G., Olah, C., Petrov, M. and Schubert, L. (2020). “Thread: Circuits”. Distill, 5,

no. 3, e24. ISSN 2476-0757. doi: 10.23915/distill.00024 . Cited on page 148.

Cao, C., Liu, X., Yang, Y., Yu, Y., Wang, J. and Wang, Z. (2015). “Look and Think Twice : Capturing Top-Down
Visual Attention with Feedback”. Proceedings of the IEEE International Conference on Computer Vision, pp.
2956–2964. url: http://openaccess.thecvf.com/content\_iccv\_2015/html/Cao\_Look\_and\_
Think\_ICCV\_2015\_paper.html. Cited on pages 66, 68, 69, 70, 75, and 78.

Cardon, D., Cointet, J.-P. and Mazières, A. (2018). La Revanche Des Neurones, vol. 211. ISBN 978-2-348-04068-9.

doi: 10.3917/res.211.0173 . Cited on page 28.

Caruana, R. (1997). “Multitask Learning”. Machine Learning, 28, no. 1, 41–75. ISSN 1573-0565. doi: 10.1023/A:

1007379606734 . Cited on page 112.

Carvajal, C. (2014). “Dynamic interplay between standard and non-standard retinal pathways in the early
thalamocortical visual system : A modeling study”. These de doctorat, Université de Lorraine. url: https:
//www.theses.fr/2014LORR0209. Cited on page 34.

Carvajal, C., Viéville, T. and Alexandre, F. (2013). “Impact of the Konio pathway in the thalamocortical visual
system: A modeling study”. BMC Neuroscience, 14, no. S1, P6. ISSN 1471-2202. doi: 10.1186/1471-2202-
14-s1-p6 . Cited on page 44.

Casagrande, V. (1994). “A third parallel visual pathway to primate area V1”. Trends in Neurosciences, 17, no. 7,

305–310. ISSN 0166-2236. doi: 10.1016/0166-2236(94)90065-5 . Cited on pages 34 and 45.

Caswell, I., Shen, C. and Wang, L. (2016). “Loopy Neural Nets : Imitating Feedback Loops in the Human Brain”.

Tech. Rep.. Cited on pages 66, 69, 70, 72, 78, and 80.

Chapelle, O., Schölkopf, B. and Zien, A. (2006a). “Introduction to Semi-Supervised Learning”. In Semi-Supervised
Learning, Adaptive Computation and Machine Learning, pp. 1–12. MIT Press, Cambridge, Mass. ISBN 978-0-
262-03358-9. Cited on page 94.

Chapelle, O., Schölkopf, B. and Zien, A. (eds.) (2006b). Semi-Supervised Learning. Adaptive Computation and

Machine Learning. MIT Press, Cambridge, Mass. ISBN 978-0-262-03358-9. Cited on page 94.

Chatﬁeld, K., Simonyan, K., Vedaldi, A. and Zisserman, A. (2014). “Return of the Devil in the Details: Delving
arxiv: 1405.3531 . Cited

Deep into Convolutional Nets”. ISSN 1-901725-52-9. doi: 10.5244/c.28.6 .
on page 91.

Chen, L.-C., Papandreou, G., Kokkinos, I., Murphy, K. and Yuille, A. L. (2016). “DeepLab: Semantic Image
arxiv:

Segmentation with Deep Convolutional Nets, Atrous Convolution, and Fully Connected CRFs”.
1606.00915 . Cited on pages 30 and 100.

Chen, X. and Gupta, A. (2015). “Webly Supervised Learning of Convolutional Networks”. In Proceedings of the
IEEE International Conference on Computer Vision, pp. 1431–1439. url: https://openaccess.thecvf.com/
content\_iccv\_2015/html/Chen\_Webly\_Supervised\_Learning\_ICCV\_2015\_paper.html.
Cited on page 96.

Cheng, G., Zhou, P. and Han, J. (2018). “Duplex Metric Learning for Image Set Classiﬁcation”. IEEE Transactions
on Image Processing, 27, no. 1, 281–292. ISSN 1057-7149. doi: 10.1109/tip.2017.2760512 . Cited on page
105.

Cho, K., van Merrienboer, B., Gülçehre, Ç., Bougares, F., Schwenk, H. and Bengio, Y. (2014). “Learning Phrase
Representations using RNN Encoder-Decoder for Statistical Machine Translation”. arXiv:1406.1078 [cs, stat],
abs/1406.1.

arxiv: 1406.1078 . Cited on page 22.

Chollet, F. (2016). “Xception: Deep Learning with Depthwise Separable Convolutions”.

arxiv: 1610.02357 .

174

BIBLIOGRAPHY

Cited on pages 53, 54, and 107.

Ciresan, D., Meier, U. and Schmidhuber, J. (2012). “Multi-column deep neural networks for image classiﬁcation”.
In IEEE Conference on Computer Vision and Pattern Recognition, pp. 3642–3649. IEEE. ISBN 978-1-4673-1228-8.
doi: 10.1109/cvpr.2012.6248110 . Cited on page 52.

Clouâtre, L. and Demers, M. (2019). “FIGR: Few-shot Image Generation with Reptile”. arXiv:1901.02199 [cs,

stat].

arxiv: 1901.02199 . Cited on page 94.

Cooper, L. N., Intrator, N., Blais, B. S. and Shouval, H. Z. (2004). Theory of Cortical Plasticity. World Scientiﬁc

Publishing. Cited on page 116.

Cortes, N. (2012). “The role of the Pulvinar in the transmission of information in the visual hierarchy”. Ph.D.

thesis, UMPC. Cited on pages 11, 33, 36, and 115.

Creswell, A., White, T., Dumoulin, V., Arulkumaran, K., Sengupta, B. and Bharath, A. A. (2017). “Generative

Adversarial Networks: An Overview”. Tech. Rep..

arxiv: 1710.07035 . Cited on page 23.

Dalal, N. and Triggs, B. (2005). “Histograms of Oriented Gradients for Human Detection”. In 2005 IEEE
Computer Society Conference on Computer Vision and Pattern Recognition (CVPR’05), vol. 1, pp. 886–893. IEEE.
ISBN 0-7695-2372-2. doi: 10.1109/cvpr.2005.177 . Cited on page 27.

Demšar, J. (2006). “Statistical Comparisons of Classiﬁers over Multiple Data Sets”. Journal of Machine Learning
Research, 7, no. Jan, 1–30. ISSN ISSN 1533-7928. url: http://www.jmlr.org/papers/v7/demsar06a.
html. Cited on page 132.

Deng, J., Dong, W., Socher, R., Li, L.-J., Kai Li, Li Fei-Fei, Wei Dong, Jia Deng, Kai Li, Socher, R. and Li-Jia Li
(2009). “ImageNet: A large-scale hierarchical image database”. In 2009 IEEE Conference on Computer Vision
and Pattern Recognition, pp. 248–255. IEEE. ISBN 978-1-4244-3992-8. doi: 10.1109/cvpr.2009.5206848 .
Cited on page 160.

DeVries, T. and Taylor, G. W. (2017). “Dataset Augmentation in Feature Space”.

arxiv: 1702.05538 . Cited

on page 92.

DiCarlo, J. J. and Cox, D. D. (2007). “Untangling invariant object recognition”. Trends in Cognitive Sciences, 11,

no. 8, 333–341. ISSN 13646613. doi: 10.1016/j.tics.2007.06.010 . Cited on page 35.

DiCarlo, J. J., Zoccolan, D. and Rust, N. C. (2012). “How Does the Brain Solve Visual Object Recognition?”
Neuron, 73, no. 3, 415–434. ISSN 0896-6273. doi: 10.1016/j.neuron.2012.01.010 . Cited on pages 34,
35, 37, and 40.

Doersch, C., Gupta, A. and Efros, A. A. (2015). “Unsupervised Visual Representation Learning by Context
Prediction”. In Proceedings of the 2015 IEEE International Conference on Computer Vision (ICCV), ICCV ’15, pp.
1422–1430. IEEE Computer Society, Santiago, Chile. ISBN 978-1-4673-8391-2. doi: 10.1109/ICCV.2015.167
. Cited on page 99.

Donahue, C., McAuley, J. and Puckette, M. (2019). “Adversarial Audio Synthesis”. arXiv:1802.04208 [cs].

arxiv:

1802.04208 . Cited on page 23.

Donahue, J., Hendricks, L. A., Rohrbach, M., Venugopalan, S., Guadarrama, S., Saenko, K. and Darrell, T. (2017).
“Long-Term Recurrent Convolutional Networks for Visual Recognition and Description”. IEEE Transactions
on Pattern Analysis and Machine Intelligence, 39, no. 4, 677–691. ISSN 01628828. doi: 10.1109/tpami.2016.
2599174 . Cited on pages 63 and 77.

Dong, X., Zheng, L., Ma, F., Yang, Y. and Meng, D. (2017). “Few-shot Object Detection”. pp. 1–11.

arxiv:

1706.08249 . Cited on page 114.

Doshi-Velez, F. and Kim, B. (2017). “Towards A Rigorous Science of Interpretable Machine Learning”. Tech.

Rep..

arxiv: 1702.08608 . Cited on page 120.

175

BIBLIOGRAPHY

Drumond, T., Viennot, L., Viéville, T. and François, V. (2017a). “Jouez avec les neurones de la machine”. Blog

Binaire LeMonde.fr, pp. 1–3. url: https://hal.inria.fr/hal-01620451. Cited on page 139.

Drumond, T. F., Viéville, T. and Alexandre, F. (2017b). “Using prototypes to improve convolutional networks
interpretability”. In Annual Conference on Neural Information Processing Systems: Transparent and Interpretable
Machine Learning in Safety Critical Environments Workshop. Long Beach, United States. url: https://hal.
inria.fr/hal-01651964. Cited on pages 114 and 117.

Drumond, T. F., Viéville, T. and Alexandre, F. (2019). “Bio-inspired Analysis of Deep Learning on Not-So-
Big Data Using Data-Prototypes”. Frontiers in Computational Neuroscience, 12, 100. ISSN 1662-5188. doi:
10.3389/fncom.2018.00100 . Cited on page 113.

Dube, P., Bhattacharjee, B., Petit-Bois, E. and Hill, M. (2018). “Improving Transferability of Deep Neural

Networks”. arXiv:1807.11459 [cs, stat].

arxiv: 1807.11459 . Cited on page 100.

Eickenberg, M., Gramfort, A., Varoquaux, G. and Thirion, B. (2016). “Seeing it all: Convolutional network layers
map the function of the human visual system”. NeuroImage. ISSN 10538119. doi: 10.1016/j.neuroimage.
2016.10.001 . Cited on pages 41, 142, and 167.

Eigen, D., Rolfe, J., Fergus, R. and LeCun, Y. (2013). “Understanding Deep Architectures using a Recursive

Convolutional Network”.

arxiv: 1312.1847 . Cited on page 63.

Elman, J. L. (1990). “Finding Structure in Time”. Cognitive Science, 14, no. 2, 179–211. ISSN 1551-6709. doi:

10.1207/s15516709cog1402\_1 . Cited on page 22.

Esteva, A., Kuprel, B., Novoa, R. A., Ko, J., Swetter, S. M., Blau, H. M. and Thrun, S. (2017). “Dermatologist-level
classiﬁcation of skin cancer with deep neural networks”. Nature, 542, no. 7639, 115–118. ISSN 0028-0836. doi:
10.1038/nature21056 . Cited on pages 99 and 126.

Fabre-Thorpe, M., Richard, G. and Thorpe, S. J. (1998). “Rapid categorization of natural images by rhesus
monkeys.” Neuroreport, 9, no. 2, 303–308. ISSN 0959-4965. doi: 10.1097/00001756-199801260-00023 .
Cited on pages 34, 35, and 115.

Fan, J., Ma, C. and Zhong, Y. (2019). “A Selective Overview of Deep Learning”.

arxiv: 1904.05526 . Cited

on page 103.

Fayek, H. M., Cavedon, L. and Wu, H. R. (2018). “On the Transferability of Representations in Neural Networks

Between Datasets and Tasks”. arXiv:1811.12273 [cs, stat].

arxiv: 1811.12273 . Cited on page 100.

Fedus, W., Goodfellow, I. and Dai, A. M. (2018). “MaskGAN: Better Text Generation via Filling in the\_\_\_\_\_\_”.

arXiv:1801.07736 [cs, stat].

arxiv: 1801.07736 . Cited on page 23.

Felleman, D. J. and Van Essen, D. C. (1991). “Distributed hierarchical processing in the primate cerebral cortex”.

Cerebral Cortex. ISSN 14602199. doi: 10.1093/cercor/1.1.1 . Cited on pages 11, 32, and 36.

Fergus, R., Fei-Fei, L., Perona, P. and Zisserman, A. (2010). “Learning Object Categories From Internet Image
Searches”. Proceedings of the IEEE, 98, no. 8, 1453–1466. ISSN 1558-2256. doi: 10.1109/JPROC.2010.
2048990 . Cited on page 96.

Finn, C., Abbeel, P. and Levine, S. (2017). “Model-Agnostic Meta-Learning for Fast Adaptation of Deep
Networks”. In International Conference on Machine Learning, pp. 1126–1135. Sydney. ISBN 978-1-5108-5514-4.
arxiv: 1703.03400 . Cited on pages 108, 109, and 138.

Follmann, P. and Bottger, T. (2018). “A Rotationally-Invariant Convolution Module by Feature Map Back-
Rotation”. In 2018 IEEE Winter Conference on Applications of Computer Vision (WACV), pp. 784–792. doi:
10.1109/WACV.2018.00091 . Cited on page 107.

Folmsbee, J., Liu, X., Brandwein-Weber, M. and Doyle, S. (2018). “Active deep learning: Improved training
eﬃciency of convolutional neural networks for tissue classiﬁcation in oral cavity cancer”. In 2018 IEEE 15th

176

BIBLIOGRAPHY

International Symposium on Biomedical Imaging (ISBI 2018), pp. 770–773. doi: 10.1109/ISBI.2018.8363686
. Cited on page 97.

Fort, S. (2017). “Gaussian Prototypical Networks for Few-Shot Learning on Omniglot”. arXiv preprint.

arxiv:

1708.02735 . Cited on pages 117 and 119.

Fournier, J., Monier, C., Pananceau, M. and Frégnac, Y. (2011). “Adaptation of the simple or complex nature
of V1 receptive ﬁelds to visual statistics”. Nature Neuroscience, 14, no. 8, 1053–1060. ISSN 10976256. doi:
10.1038/nn.2861 . Cited on page 38.

Freiwald, W. A., Tsao, D. Y. and Livingstone, M. S. (2009). “A face feature space in the macaque temporal lobe”.

Nature Neuroscience, 12, no. 9, 1187–1196. ISSN 1097-6256. doi: 10.1038/nn.2363 . Cited on page 39.

Frosst, N. and Hinton, G. (2017). “Distilling a Neural Network Into a Soft Decision Tree”. NIPS.

arxiv:

1711.09784 . Cited on page 121.

Fu, J., Zheng, H. and Mei, T. (2017). “Look closer to see better: Recurrent attention convolutional neural
network for ﬁne-grained image recognition”. Proceedings - 30th IEEE Conference on Computer Vision and Pattern
Recognition, CVPR 2017, 2017-Janua, 4476–4484. doi: 10.1109/cvpr.2017.476 . Cited on pages 67, 70, 77,
78, and 107.

Fukushima, K. (1980). “Neocognitron: A self organizing neural network model for a mechanism of pattern
recognition unaﬀected by shift in position.” Biological cybernetics, 36, no. 4, 193–202. ISSN 0340-1200. doi:
10.1007/bf00344251 .

arxiv: 1011.1669v3 . Cited on page 28.

Fukushima, K. (1988). “Neocognitron: A Hierarchical Neural Network Capable of Visual Pattern Recognition”.
Neural Networks, 1, no. 2, 119–130. ISSN 08936080. doi: 10.1016/0893-6080(88)90014-7 . Cited on page
38.

Fukushima, K. (2005). “Restoring partly occluded patterns: A neural network model”. Neural Networks, 18,

no. 1, 33–43. ISSN 08936080. doi: 10.1016/j.neunet.2004.05.001 . Cited on page 68.

Gal, Y., Islam, R. and Ghahramani, Z. (2017). “Deep Bayesian active learning with image data”. In Proceedings of
the 34th International Conference on Machine Learning - Volume 70, ICML’17, pp. 1183–1192. JMLR.org, Sydney,
NSW, Australia. Cited on page 97.

Garcia, V. and Estrach, J. B. (2018). “Few-Shot Learning with Graph Neural Networks”. In International Conference
on Learning Representations, pp. 1–13. url: https://openreview.net/forum?id=BJj6qGbRW. Cited on
page 138.

Garcia-Garcia, A., Orts-Escolano, S., Oprea, S., Villena-Martinez, V. and Garcia-Rodriguez, J. (2017). “A Review
arxiv: 1704.06857 . Cited on pages

on Deep Learning Techniques Applied to Semantic Segmentation”.
21 and 65.

Giese, M. A. and Poggio, T. (2003). “Neural mechanisms for the recognition of biological movements”. Nature

Reviews Neuroscience, 4, no. 3, 179–192. ISSN 1471-003X. doi: 10.1038/nrn1057 . Cited on page 45.

Girshick, R., Donahue, J., Darrell, T. and Malik, J. (2014). “Rich Feature Hierarchies for Accurate Object Detection
and Semantic Segmentation”. IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 580–587.
ISSN 10636919. doi: 10.1109/cvpr.2014.81 .

arxiv: 1311.2524 . Cited on page 51.

Gissin, D. and Shalev-Shwartz, S. (2019). “Discriminative Active Learning”. arXiv:1907.06347 [cs, stat].

arxiv:

1907.06347 . Cited on page 98.

Glorot, X. and Bengio, Y. (2010). “Understanding the diﬃculty of training deep feedforward neural networks”.
Proceedings of the 13th International Conference on Artiﬁcial Intelligence and Statistics (AISTATS), 9, 249–256. ISSN
15324435. Cited on page 31.

Gollisch, T. and Meister, M. (2010). “Eye Smarter than Scientists Believed: Neural Computations in Circuits of

177

BIBLIOGRAPHY

the Retina”. Neuron, 65, no. 2, 150–164. ISSN 08966273. doi: 10.1016/j.neuron.2009.12.009 . Cited on
pages 34, 43, and 75.

Goodale, M. A. and Milner, D. A. (1992). “Separate visual pathways for perception and action”. Trends in
Neurosciences, 15, no. 1, 20–25. ISSN 0166-2236. doi: 10.1016/0166-2236(92)90344-8 . Cited on page
34.

Goodfellow, I. (2016). “NIPS 2016 Tutorial: Generative Adversarial Networks”. Tech. Rep.. arxiv: 1701.00160

. Cited on page 23.

Goodfellow, I., Bengio, Y. and Courville, A. (2016a). “Autoencoder”.
http://www.deeplearningbook.org. Cited on pages 23 and 124.

In Deep Learning. MIT Press. url:

Goodfellow, I., Bengio, Y. and Courville, A. (2016b). “Convolutional Networks”. In Deep Learning, pp. 330–372.

MIT Press. url: http://www.deeplearningbook.org. Cited on pages 30 and 115.

Goodfellow, I., Bengio, Y. and Courville, A. (2016c). “Deep Feedforward Networks”. In Deep Learning, pp.

169–229. MIT Press. url: http://www.deeplearningbook.org. Cited on page 113.

Goodfellow, I., Bengio, Y. and Courville, A. (2016d). “Deep Generative Models”. In Deep Learning, pp. 658–729.

MIT Press.

arxiv: 1504.06787v3 . Cited on page 22.

Goodfellow, I., Bengio, Y. and Courville, A. (2016e). “Regularization for Deep Learning”. In Deep Learning, pp.

216–261. MIT Press. url: http://www.deeplearningbook.org. Cited on page 103.

Goodfellow, I., Bengio, Y. and Courville, A. (2016f). “Representation Learning”. In Deep Learning, pp. 528–559.

MIT Press. url: http://www.deeplearningbook.org. Cited on pages 99 and 118.

Goodfellow, I., Bengio, Y. and Courville, A. (2016g). “Sequence Modeling : Recurrent and Recursive Nets”. In
Deep Learning, pp. 373–422. MIT Press. url: http://www.deeplearningbook.org. Cited on page 22.

Goodfellow, I., Pouget-Abadie, J. and Mirza, M. (2014). “Generative Adversarial Networks”. arXiv preprint arXiv:
arxiv: 1406.2661v1 . Cited on page 23.

. . . , pp. 1–9. ISSN 10495258.

Graves, A. and Schmidhuber, J. (2012). “Oﬄine Handwriting Recognition with Multidimensional Recurrent

Neural Networks”. In NIPS, pp. 1–8. doi: 10.1007/978-1-4471-4072-6\_12 . Cited on page 73.

Graves, A., Wayne, G., Danihelka, I. and Deepmind, G. (2014). “Neural Turing Machines”.

arxiv: 1410.5401

. Cited on page 120.

Greﬀ, K., Srivastava, R. K. and Schmidhuber, J. (2016). “Highway and Residual Networks learn Unrolled Iterative

Estimation”.

arxiv: 1612.07771 . Cited on pages 57 and 59.

Guidotti, R., Monreale, A., Ruggieri, S., Turini, F., Pedreschi, D. and Giannotti, F. (2018). “A Survey Of Methods
arxiv: 1802.01933 . Cited

For Explaining Black Box Models”. ISSN 03600300. doi: 10.1145/3236009 .
on page 69.

Gulcehre, C., Moczulski, M., Visin, F. and Bengio, Y. (2016). “Mollifying Networks”. arXiv:1608.04980 [cs].

arxiv: 1608.04980 . Cited on page 110.

Hacohen, G. and Weinshall, D. (2019). “On The Power of Curriculum Learning in Training Deep Networks”.

arXiv:1904.03626 [cs, stat].

arxiv: 1904.03626 . Cited on pages 110 and 111.

Han, K., Wen, H., Zhang, Y., Fu, D., Culurciello, E. and Liu, Z. (2018). “Deep Predictive Coding Network with

Local Recurrent Processing for Object Recognition”.

arxiv: 1805.07526 . Cited on pages 67 and 70.

Han, S., Pool, J., Tran, J. and Dally, W. J. (2015). “Learning both Weights and Connections for Eﬃcient Neural
arxiv: 1506.02626 .

Networks”. pp. 1–9. ISSN 01406736. doi: 10.1016/s0140-6736(95)92525-2 .
Cited on page 107.

178

BIBLIOGRAPHY

Hardt, M. and Ma, T. (2016). “Identity Matters in Deep Learning”. pp. 1–20.

arxiv: 1611.04231 . Cited on

page 60.

Hartline, H. K. (1940). “The Receptive Fields of Optic Nerve Fibers”. American Journal of Physiology-Legacy
Content, 130, no. 4, 690–699. ISSN 0002-9513. doi: 10.1152/ajplegacy.1940.130.4.690 . Cited on page
38.

Hassibi, B., Stork, D. G. and Wolﬀ, G. J. (1993). “Optimal brain surgeon and general network pruning”. In
IEEE International Conference on Neural Networks - Conference Proceedings, vol. 1993-Janua, pp. 293–299. ISBN
0-7803-0999-5. doi: 10.1109/icnn.1993.298572 . Cited on page 107.

Håstad, J. and Goldmann, M. (1991). “On the power of small-depth threshold circuits”. Computational Complexity,

1, no. 2, 113–129. ISSN 1016-3328, 1420-8954. doi: 10.1007/bf01272517 . Cited on page 113.

He, K., Zhang, X., Ren, S. and Sun, J. (2015). “Spatial Pyramid Pooling in Deep Convolutional Networks for
Visual Recognition”. IEEE Transactions on Pattern Analysis and Machine Intelligence, 37, no. 9, 1904–1916. ISSN
01628828. doi: 10.1109/tpami.2015.2389824 .

arxiv: 1406.4729 . Cited on page 67.

He, K., Zhang, X., Ren, S. and Sun, J. (2016a). “Deep Residual Learning for Image Recognition”. In 2016 IEEE
Conference on Computer Vision and Pattern Recognition (CVPR), pp. 770–778. doi: 10.1109/cvpr.2016.90 .
arxiv: 1512.03385 . Cited on pages 29, 31, 41, 42, 53, 55, 56, 60, 75, 104, 113, and 141.

He, K., Zhang, X., Ren, S. and Sun, J. (2016b). “Identity Mappings in Deep Residual Networks”. In ECCV 2016:
Computer Vision – ECCV 2016, 1, pp. 630–645. ISBN 978-3-319-46493-0. doi: 10.1007/978-3-319-46493-
0\_38 .

arxiv: 1603.05027 . Cited on pages 55 and 56.

Hecht, T. and Gepperth, A. (2016). “Computational advantages of deep prototype-based learning”. Lecture Notes
in Computer Science (including subseries Lecture Notes in Artiﬁcial Intelligence and Lecture Notes in Bioinformatics),
9887 LNCS, 121–127. ISSN 16113349. doi: 10.1007/978-3-319-44781-0\_15 . Cited on page 118.

Hernández-García, A. and König, P. (2019).

“Data augmentation instead of explicit regularization”.

arXiv:1806.03852 [cs].

arxiv: 1806.03852 . Cited on page 103.

Hershey, S., Chaudhuri, S., Ellis, D. P. W., Gemmeke, J. F., Jansen, A., Moore, R. C., Plakal, M., Platt, D., Saurous,
R. A., Seybold, B., Slaney, M., Weiss, R. J. and Wilson, K. (2017). “CNN architectures for large-scale audio
classiﬁcation”. In 2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), pp.
131–135. doi: 10.1109/ICASSP.2017.7952132 . Cited on page 29.

Herzog, M. H. and Clarke, A. M. (2014). “Why vision is not both hierarchical and feedforward”. Frontiers in
Computational Neuroscience, 8, 135. ISSN 1662-5188. doi: 10.3389/fncom.2014.00135 . Cited on pages 44
and 45.

Hochreiter, S. and Schmidhuber, J. (1997). “Long Short-Term Memory”. Neural Comput., 9, no. 8, 1735–1780.

ISSN 0899-7667. doi: 10.1162/neco.1997.9.8.1735 . Cited on page 22.

Hong, H., Yamins, D. L. K., Majaj, N. J. and DiCarlo, J. J. (2016). “Explicit information for category-orthogonal
object properties increases along the ventral stream”. Nature Neuroscience, 19, no. 4, 613–622. ISSN 1097-6256.
doi: 10.1038/nn.4247 . Cited on pages 42 and 81.

Hong, Y., Niu, L., Zhang, J. and Zhang, L. (2020a). “MatchingGAN: Matching-based Few-shot Image Generation”.

arXiv:2003.03497 [cs, eess].

arxiv: 2003.03497 . Cited on page 94.

Hong, Y., Niu, L., Zhang, J., Zhao, W., Fu, C. and Zhang, L. (2020b). “F2GAN: Fusing-and-Filling GAN for

Few-shot Image Generation”. arXiv:2008.01999 [cs].

arxiv: 2008.01999 . Cited on page 94.

Hoogeboom, E. (2017). “Few-shot Classiﬁcation by Learning Disentangled Representations”. MSc, University

of Amsterdam. Cited on page 141.

Howard, A. G., Zhu, M., Chen, B., Kalenichenko, D., Wang, W., Weyand, T., Andreetto, M. and Adam, H.

179

BIBLIOGRAPHY

(2017). “MobileNets: Eﬃcient Convolutional Neural Networks for Mobile Vision Applications”.
1704.04861 . Cited on pages 52 and 107.

arxiv:

Huang, G., Liu, Z., v. d. Maaten, L. and Weinberger, K. Q. (2017). “Densely Connected Convolutional Networks”.
In 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 2261–2269. doi: 10.1109/
cvpr.2017.243 .

arxiv: 1608.06993 . Cited on pages 42, 58, and 141.

Hubel, D. H. and Wiesel, T. N. (1959). “Receptive ﬁelds of single neurones in the cat’s striate cortex”. The Journal
of Physiology, 148, no. 3, 574–591. ISSN 00223751. doi: 10.1113/jphysiol.1959.sp006308 . Cited on
pages 38 and 45.

Hubel, D. H. and Wiesel, T. N. (1962). “Receptive ﬁelds, binocular interaction and functional architecture in the
cat’s visual cortex”. The Journal of Physiology. ISSN 14697793. doi: 10.1113/jphysiol.1962.sp006837 .
arxiv: 1011.1669v3 . Cited on pages 28, 37, and 38.

Hyvärinen, A., Hurri, J. and Hoyer, P. O. (2009). Natural Image Statistics. ISBN 978-1-84882-490-4. Cited on page

27.

Iandola, F. N., Han, S., Moskewicz, M. W., Ashraf, K., Dally, W. J. and Keutzer, K. (2016). “SqueezeNet:
arxiv: 1602.07360 . Cited on pages 52 and 56.

AlexNet-level accuracy with 50x fewer parameters and”.

Iscen, A., Tolias, G., Avrithis, Y. and Chum, O. (2019). “Label Propagation for Deep Semi-Supervised
In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp.
Learning”.
5070–5079. url: http://openaccess.thecvf.com/content\_CVPR\_2019/papers/Iscen\_Label\_
Propagation\_for\_Deep\_Semi-Supervised\_Learning\_CVPR\_2019\_paper. Cited on page 98.

Issa, E. B., Cadieu, C. F. and Dicarlo, J. J. (2018). “Neural dynamics at successive stages of the ventral visual
stream are consistent with hierarchical error signals”. eLife, 7, no. 1, 1–24. ISSN 2050084X. doi: 10.7554/
elife.42870 . Cited on page 63.

Jaderberg, M., Simonyan, K., Zisserman, A. and Kavukcuoglu, K. (2015). “Spatial Transformer Networks”. In

Nips, pp. 1–14. doi: 10.1038/nbt.3343 .

arxiv: 1506.02025 . Cited on page 67.

Jakubovitz, D., Giryes, R. and Rodrigues, M. R. D. (2018). “Generalization Error in Deep Learning”. ISSN
arxiv: 1808.01174 . Cited on pages 85, 86,

0167-577X. doi: 10.1016/j.matlet.2011.09.042 .
and 103.

Jarrett, K., Kavukcuoglu, K., Ranzato, M. and LeCun, Y. (2009). “What is the best multi-stage architecture for
object recognition?” Proceedings of the IEEE International Conference on Computer Vision, pp. 2146–2153. ISSN
1550-5499. doi: 10.1109/iccv.2009.5459469 . Cited on page 31.

Jetley, S., Romera-Paredes, B., Jayasumana, S. and Torr, P. (2015). “Prototypical Priors: From Improving
Classiﬁcation to Zero-Shot Learning”. In Xianghua Xie Mark W. Jones and G. K. L. Tam (eds.), Proceedings
of the British Machine Vision Conference (BMVC), pp. 120.1–120.12. BMVA Press. ISBN 1-901725-53-7. doi:
10.5244/c.29.120 .

arxiv: 1512.01192 . Cited on page 117.

Kaadoud, I. C. (2018). “Apprentissage de séquences et extraction de règles de réseaux récurrents : application
au traçage de schémas techniques.” Ph.D. thesis, Université de Bordeaux. url: https://tel.archives-
ouvertes.fr/tel-01771685. Cited on page 149.

Kaadoud, I. C. and Viéville, T. (2016). “L’apprentissage profond : une idée à creuser ?” Interstices. url:
https://interstices.info/lapprentissage-profond-une-idee-a-creuser/. Cited on page
139.

Kar, K., Kubilius, J., Schmidt, K., Issa, E. B. and DiCarlo, J. J. (2019). “Evidence that recurrent circuits are critical
to the ventral stream’s execution of core object recognition behavior”. Nature Neuroscience, 22, no. 6, 974–983.
ISSN 1097-6256. doi: 10.1038/s41593-019-0392-5 . Cited on page 82.

Kastner, D. B. and Baccus, S. A. (2013). “Insights from the retina into the diverse and general computations of

180

BIBLIOGRAPHY

adaptation, detection, and prediction”. Current Opinion in Neurobiology. ISSN 09594388. doi: 10.1016/j.
conb.2013.11.012 . Cited on page 43.

Kaur, P., Sikka, K. and Divakaran, A. (2017). “Combining Weakly and Webly Supervised Learning for Classifying

Food Images”. arXiv:1712.08730 [cs].

arxiv: 1712.08730 . Cited on page 96.

Kaya, M. and Bilge, H. Ş. (2019). “Deep Metric Learning: A Survey”. Symmetry, 11, no. 9, 1066. doi: 10.3390/

sym11091066 . Cited on page 99.

Khaligh-Razavi, S.-M. and Kriegeskorte, N. (2014). “Deep Supervised, but Not Unsupervised, Models May
Explain IT Cortical Representation”. PLoS Computational Biology, 10, no. 11, e1003915. ISSN 1553-7358. doi:
10.1371/journal.pcbi.1003915 . Cited on pages 41, 42, and 81.

Kim, B., Khanna, R. and Koyejo, O. O. (2016). “Examples are not Enough, Learn to Criticize! Criticism for
Interpretability”. Advances in Neural Information Processing Systems 29, pp. 2280–2288. Cited on page 114.

Kim, Y. (2014). “Convolutional Neural Networks for Sentence Classiﬁcation”. arXiv:1408.5882 [cs].

arxiv:

1408.5882 . Cited on page 29.

Kingma, D. P. and Welling, M. (2014). “Auto-Encoding Variational Bayes”. arXiv:1312.6114 [cs, stat].

arxiv:

1312.6114 . Cited on page 23.

Kirsch, A., van Amersfoort, J. and Gal, Y. (2019). “BatchBALD: Eﬃcient and Diverse Batch Acquisition for Deep
Bayesian Active Learning”. In H. Wallach, H. Larochelle, A. Beygelzimer, F. d\textquotesingle Alché-Buc, E. Fox
and R. Garnett (eds.), Advances in Neural Information Processing Systems 32, pp. 7024–7035. Curran Associates,
Inc. url: http://papers.nips.cc/paper/8925-batchbald-efficient-and-diverse-batch-
acquisition-for-deep-bayesian-active-learning.pdf. Cited on page 98.

Koch, G., Zemel, R. and Salakhutdinov, R. (2015). “Siamese Neural Networks for One-Shot Image Recognition”.

In ICML - Deep Learning Workshop, vol. 37. Cited on pages 100, 105, and 119.

Koga, T., Nonaka, N., Sakuma, J. and Seita, J. (2018). “General-to-Detailed GAN for Infrequent Class Medical

Images”. arXiv:1812.01690 [cs, stat].

arxiv: 1812.01690 . Cited on page 94.

Krause, J., Sapp, B., Howard, A., Zhou, H., Toshev, A., Duerig, T., Philbin, J. and Fei-Fei, L. (2016). “The
Unreasonable Eﬀectiveness of Noisy Data for Fine-Grained Recognition”. In Lecture Notes in Computer Science
(Including Subseries Lecture Notes in Artiﬁcial Intelligence and Lecture Notes in Bioinformatics), vol. 9907 LNCS,
arxiv: 1511.06789 .
pp. 301–320. ISBN 978-3-319-46486-2. doi: 10.1007/978-3-319-46487-9\_19 .
Cited on page 96.

Krause, J., Stark, M., Deng, J. and Fei-Fei, L. (2013). “3D object representations for ﬁne-grained categorization”.
In 4th International IEEE Workshop on 3D Representation and Recognition (3dRR-13). Sydney, Australia. doi:
10.1109/ICCVW.2013.77 . Cited on pages 88 and 159.

Krizhevsky, A. (2009). “Learning Multiple Layers of Features from Tiny Images”. Tech. Rep.. Cited on pages

159 and 160.

Krizhevsky, A., Sutskever, I. and Hinton, G. E. (2012). “ImageNet Classiﬁcation with Deep Convolutional Neural
Networks”. In F. P. a. C. J. C. B. a. L. B. a. K. Q. Weinberger (ed.), Advances in Neural Information Processing
Systems 25, pp. 1097–1105. Curran Associates, Inc. Cited on pages 28, 41, 49, and 113.

Kubilius, J., Schrimpf, M., Nayebi, A., Bear, D., Yamins, D. L. K. and DiCarlo, J. J. (2018). “CORnet: Modeling
biorxiv: 408385 . Cited on

the Neural Mechanisms of Core Object Recognition”. doi: 10.1101/408385 .
page 42.

Kubilius, J., Wagemans, J. and Op de Beeck, H. P. (2015). “A conceptual framework of computations in mid-level
vision”. Frontiers in computational neuroscience, 8, no. December, 158. ISSN 1662-5188. doi: 10.3389/fncom.
2014.00158 . Cited on page 39.

181

BIBLIOGRAPHY

Kuen, J., Kong, X., Wang, G. and Tan, Y.-P. (2016). “DelugeNets: Deep Networks with Eﬃcient and Flexible

Cross-layer Information Inﬂows”.

arxiv: 1611.05552 . Cited on pages 58 and 61.

Kuﬄer, S. W. (1953). “Discharge Patterns And Functional Organization of Mammalian Retina”. Journal of
Neurophysiology, 16, no. 1, 37–68. ISSN 0022-3077. doi: 10.1152/jn.1953.16.1.37 . Cited on page 38.

Kukačka, J., Golkov, V. and Cremers, D. (2017).

“Regularization for Deep Learning: A Taxonomy”.

arXiv:1710.10686 [cs, stat].

arxiv: 1710.10686 . Cited on pages 103 and 104.

Lake, B. M., Salakhutdinov, R. R., Gross, J. and Tenenbaum, J. B. (2011). “One shot learning of simple visual
concepts”. In L. Carlson, C. Hoelscher and T. F. Shipley (eds.), Proceedings of the 33rd Annual Conference of the
Cognitive Science Society (CogSci 2011), vol. 1, pp. 2568–2573. Curran Associates, Inc., Boston, Massachusetts,
USA. Cited on pages 125, 159, and 160.

Lamme, V. A. F., Supèr, H. and Spekreijse, H. (1998). “Feedforward, horizontal, and feedback processing in
the visual cortex”. Current Opinion in Neurobiology, 8, no. 4, 529–535. ISSN 09594388. doi: 10.1016/s0959-
4388(98)80042-1 . Cited on page 44.

Land, M. F. (1999). “Motion and vision: Why animals move their eyes”. Journal of Comparative Physiology A:
Sensory, Neural, and Behavioral Physiology, 185, no. 4, 341–352. ISSN 0340-7594, 1432-1351. doi: 10.1007/
s003590050393 . Cited on page 37.

Laptev, D., Savinov, N., Buhmann, J. M. and Pollefeys, M. (2016). “TI-POOLING: Transformation-Invariant
Pooling for Feature Learning in Convolutional Neural Networks”. In 2016 IEEE Conference on Computer Vision
and Pattern Recognition (CVPR), pp. 289–297. doi: 10.1109/CVPR.2016.38 . Cited on page 107.

Larochelle, H. and Hinton, G. E. (2010). “Learning to combine foveal glimpses with a third-order Boltz-
mann machine”. url: https://papers.nips.cc/paper/4089-learning-to-combine-foveal-
glimpses-with-a-third-order-boltzmann-machine. Cited on page 67.

Larsson, G., Maire, M. and Shakhnarovich, G. (2016). “FractalNet: Ultra-Deep Neural Networks without

Residuals”.

arxiv: 1605.07648 . Cited on page 57.

Le, Q. V., Ngiam, J., Chen, Z., Chia, D., Koh, P. W. and Ng, A. Y. (2010). “Tiled convolutional neural networks”.

In Advances in Neural Information Processing Systems 23 (NIPS 2010). Cited on page 30.

LeCun, Y., Bengio, Y. and Hinton, G. (2015). “Deep learning”. Nature, 521, no. 7553, 436–444. ISSN 0028-0836.

doi: 10.1038/nature14539 .

arxiv: 1312.6184v5 . Cited on page 113.

LeCun, Y., Boser, B., Denker, J. S., Henderson, D., Howard, R. E., Hubbard, W. and Jackel, L. D. (1990a). “Hand-
written Digit Recognition with a Back-Propagation Network”. ADVANCES IN NEURAL INFORMATION PRO-
CESSING SYSTEMS, 2, 396–404. url: http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.
1.1.32.5076. Cited on pages 17, 28, and 162.

Lecun, Y., Bottou, L., Bengio, Y. and Haﬀner, P. (1998). “Gradient-based learning applied to document recogni-
tion”. Proceedings of the IEEE, 86, no. 11, 2278–2324. ISSN 00189219. doi: 10.1109/5.726791 . Cited on
pages 91, 113, and 159.

LeCun, Y., Denker, J. S. and Solla, S. A. (1990b). “Optimal brain damage”. In D. S. Touretzky (ed.), Advances in
Neural Information Processing Systems, vol. 2, pp. 598–605. Morgan-Kaufmann. url: http://papers.nips.
cc/paper/250-optimal-brain-damage.pdf. Cited on page 107.

Lehky, S. R., Kiani, R., Esteky, H. and Tanaka, K. (2014). “Dimensionality of Object Representations in Monkey
Inferotemporal Cortex”. Neural Computation, 26, no. 10, 2135–2162. ISSN 0899-7667. doi: 10.1162/neco\_a\_
00648 . Cited on page 40.

Leroy, A. (1967). “L’apprentissage de la lecture chez les jeunes enfants : Acquisition des lettres de l’alphabet et
maturité mentale.” Enfance; psychologie, pedagogie, neuropsychiatrie, sociologie, 20, no. 1, 27–55. ISSN 0013-7545.
doi: 10.3406/enfan.1967.2408 . Cited on page 114.

182

BIBLIOGRAPHY

Li, S., Jiao, J., Han, Y. and Weissman, T. (2017). “Demystifying ResNet”. pp. 1–13.

arxiv: 1611.01186v2 .

Cited on pages 60, 73, and 149.

Li, X., Jie, Z., Feng, J., Liu, C. and Yan, S. (2018). “Learning with rethinking: Recurrently improving convolutional
neural networks through feedback”. Pattern Recognition, 79, 183–194. ISSN 00313203. doi: 10.1016/j.
patcog.2018.01.015 .

arxiv: 1708.04483 . Cited on pages 69, 70, 75, and 78.

Liang, M. and Hu, X. (2015). “Recurrent convolutional neural network for object recognition”. In Computer
Vision and Pattern Recognition (CVPR), 2015 IEEE Conference On, vol. 07-12-June, pp. 3367–3375. ISBN 978-1-
4673-6964-0. doi: 10.1109/cvpr.2015.7298958 .
arxiv: 1306.2795v1 . Cited on pages 59, 64, 69, 70,
73, and 78.

Liao, Q. and Poggio, T. (2016). “Bridging the Gaps Between Residual Learning, Recurrent Neural Networks
arxiv: 1604.03640 . Cited on pages 59, 64, 69, 72, 75, 76, 80,

and Visual Cortex”. Tech. Rep. 047, CBMM.
and 82.

Lipton, Z. C. (2016). “The Mythos of Model Interpretability”. In ICML Workshop on Human Interpretability in

Machine Learning.

arxiv: 1606.03490v3 . Cited on page 120.

Liu, N. and Han, J. (2018). “A Deep Spatial Contextual Long-Term Recurrent Convolutional Network for Saliency
Detection”. IEEE Transactions on Image Processing, 27, no. 7, 3264–3274. ISSN 10577149. doi: 10.1109/tip.
2018.2817047 . Cited on page 66.

Liu, Y., Jain, A., Eng, C., Way, D. H., Lee, K., Bui, P., Kanada, K., Marinho, G. d. O., Gallegos, J., Gabriele, S.,
Gupta, V., Singh, N., Natarajan, V., Hofmann-Wellenhof, R., Corrado, G. S., Peng, L. H., Webster, D. R., Ai, D.,
Huang, S., Liu, Y., Dunn, R. C. and Coz, D. (2019). “A deep learning system for diﬀerential diagnosis of skin
diseases”. arXiv:1909.05382 [cs, eess].

arxiv: 1909.05382 . Cited on page 92.

Lowe, D. G. (2004). “Distinctive image features from scale-invariant keypoints”. International Journal of Computer
arxiv: cs/0112017 . Cited

Vision. ISSN 09205691. doi: 10.1023/b:visi.0000029664.99615.94 .
on page 27.

Luan, S., Chen, C., Zhang, B., Han, J. and Liu, J. (2018). “Gabor Convolutional Networks”. IEEE Transactions
arxiv:

on Image Processing, 27, no. 9, 4357–4366. ISSN 1941-0042. doi: 10.1109/TIP.2018.2835143 .
1705.01450v3 . Cited on page 107.

Lundberg, S. M. and Lee, S.-I. (2017). “A Uniﬁed Approach to Interpreting Model Predictions”. In I. Guyon,
U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan and R. Garnett (eds.), Advances in Neural
arxiv: 1705.07874 . Cited on
Information Processing Systems 30, pp. 4765–4774. Curran Associates, Inc.
page 121.

Lundervold, A. S. and Lundervold, A. (2019). “An overview of deep learning in medical imaging focusing
on MRI”. Zeitschrift für Medizinische Physik, 29, no. 2, 102–127. ISSN 0939-3889. doi: 10.1016/j.zemedi.
2018.11.002 . Cited on page 88.

Lyu, S. and Simoncelli, E. P. (2009). “Nonlinear Extraction of Independent Components of Natural Images
Using Radial Gaussianization”. Neural Computation, 21, no. 6, 1485–1519. ISSN 0899-7667, 1530-888X. doi:
10.1162/neco.2009.04-08-773 . Cited on page 122.

Maaten, L. V. D. and Hinton, G. (2008). “Visualizing Data using t-SNE”. Journal of Machine Learning Research 1,
arxiv: 1307.1662 . Cited on

620, no. 1, 267–84. ISSN 1940-6029. doi: 10.1007/s10479-011-0841-3 .
page 127.

Majaj, N. J., Hong, H., Solomon, E. A. and DiCarlo, J. J. (2015). “Simple Learned Weighted Sums of Inferior
Temporal Neuronal Firing Rates Accurately Predict Human Core Object Recognition Performance”. Journal
of Neuroscience, 35, no. 39, 13402–13418. ISSN 0270-6474, 1529-2401. doi: 10.1523/JNEUROSCI.5181-
14.2015 . Cited on page 39.

183

BIBLIOGRAPHY

Makhzani, A. and Frey, B. (2014). “K-Sparse Autoencoders”. arXiv:1312.5663 [cs].

arxiv: 1312.5663 . Cited

on page 23.

Marcus, G. (2018). “Deep Learning: A Critical Appraisal”. pp. 1–27.

arxiv: 1801.00631 . Cited on page 116.

Marr, D. (1982). Vision: A Computational Investigation into the Human Representation and Processing of Visual

Information. Henry Holt and Co., Inc., New York, NY, USA. ISBN 0-7167-1567-8. Cited on page 32.

Masland, R. H. (2001). “Neuronal diversity in the retina”. Current Opinion in Neurobiology, 11, no. 4, 431–436.

ISSN 09594388. doi: 10.1016/s0959-4388(00)00230-0 . Cited on page 43.

Matusov, E. (2001). “Vygotskij’s Theory of Human Development and New Approaches to Education”. In N. J.
Smelser and P. B. Baltes (eds.), International Encyclopedia of the Social and Behavioral Sciences, pp. 16339–16343.
Pergamon, Oxford. ISBN 978-0-08-043076-8. doi: 10.1016/B0-08-043076-7/02407-4 . Cited on page
110.

McHaﬃe, J. G., Stanford, T. R., Stein, B. E., Coizet, V. and Redgrave, P. (2005). “Subcortical loops through the basal
ganglia”. Trends in Neurosciences, 28, no. 8, 401–407. ISSN 01662236. doi: 10.1016/j.tins.2005.06.006 .
Cited on page 116.

Medathati, N. V. K., Neumann, H., Masson, G. S. and Kornprobst, P. (2016). “Bio-inspired computer vision:
Towards a synergistic approach of artiﬁcial and biological vision”. Computer Vision and Image Understanding,
150, 1–30. ISSN 10773142. doi: 10.1016/j.cviu.2016.04.009 . Cited on pages 18, 44, 45, 115, 116,
and 163.

Mehrotra, A. and Dukkipati, A. (2017). “Generative Adversarial Residual Pairwise Networks for One Shot

Learning”. Tech. Rep..

arxiv: 1703.08033 . Cited on page 56.

Mensch, A., Mairal, J., Bzdok, D., Thirion, B. and Varoquaux, G. (2017). “Learning Neural Representations of
Human Cognition across Many fMRI Studies”. In I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus,
S. Vishwanathan and R. Garnett (eds.), Advances in Neural Information Processing Systems 30, pp. 5883–5893.
Curran Associates, Inc.

arxiv: 1710.11438 . Cited on page 116.

Mensink, T., Verbeek, J., Perronnin, F. and Csurka, G. (2013). “Distance-Based Image Classiﬁcation: Generalizing
to New Classes at Near-Zero Cost”. IEEE Transactions on Pattern Analysis and Machine Intelligence, 35, no. 11,
2624–2637. ISSN 0162-8828. doi: 10.1109/tpami.2013.83 . Cited on page 119.

Mikolov, T., Sutskever, I., Chen, K., Corrado, G. S. and Dean, J. (2013). “Distributed Representations of
Words and Phrases and their Compositionality”. In C. J. C. Burges, L. Bottou, M. Welling, Z. Ghahramani
and K. Q. Weinberger (eds.), Advances in Neural Information Processing Systems 26, pp. 3111–3119. Curran
Associates, Inc. url: http://papers.nips.cc/paper/5021-distributed-representations-of-
words-and-phrases-and-their-compositionality.pdf. Cited on pages 22 and 101.

Milner, D. and Goodale, M. (1995). The Visual Brain in Action. Oxford University Press, Great Clarendon Street,
ISBN 0-19-852472-2. url: http://www.amazon.com/exec/obidos/

Oxford OX2 6DP, second edn..
redirect?tag=citeulike07-20&path=ASIN/0198524722. Cited on page 115.

Mishkin, M., Ungerleider, L. G. and Macko, K. A. (1983). “Object vision and spatial vision: Two cortical
pathways”. Trends in Neurosciences. ISSN 01662236. doi: 10.1016/0166-2236(83)90190-x . Cited on
page 33.

Mnih, V., Heess, N., Graves, A. and Kavukcuoglu, K. (2014). “Recurrent Models of Visual Attention”.

arxiv:

1406.6247 . Cited on page 67.

Morerio, P., Cavazza, J., Volpi, R., Vidal, R. and Murino, V. (2017). “Curriculum Dropout”. arXiv:1703.06229 [cs,

stat].

arxiv: 1703.06229 . Cited on page 110.

Mouret, J.-B. (2016). “Micro-Data Learning: The Other End of the Spectrum”.

arxiv: 1610.00946 . Cited on

page 114.

184

BIBLIOGRAPHY

Movshovitz-Attias, Y., Toshev, A., Leung, T. K., Ioﬀe, S. and Singh, S. (2017). “No Fuss Distance Metric Learning
using Proxies”. 2017 IEEE International Conference on Computer Vision (ICCV), pp. 360–368. ISSN 15505499.
doi: 10.1109/iccv.2017.47 .

arxiv: 1703.07464 . Cited on page 105.

Nayebi, A., Bear, D., Kubilius, J., Kar, K., Ganguli, S., Sussillo, D., DiCarlo, J. J. and Yamins, D. L. K. (2018).
arxiv: 1807.00053 .

“Task-Driven Convolutional Recurrent Models of the Visual System”. pp. 5290–5301.
Cited on pages 42, 63, 64, 72, 75, 81, and 82.

Neyshabur, B., Li, Z., Bhojanapalli, S., LeCun, Y. and Srebro, N. (2019). “The role of over-parametrization
in generalization of neural networks”. In International Conference on Learning Representations. url: https:
//openreview.net/forum?id=BygfghAcYX. Cited on page 103.

Ng, J. Y.-H., Hausknecht, M., Vijayanarasimhan, S., Vinyals, O., Monga, R. and Toderici, G. (2015). “Beyond

Short Snippets: Deep Networks for Video Classiﬁcation”.

arxiv: 1503.08909 . Cited on page 77.

Nilsback, M.-E. and Zisserman, A. (2008). “Automated ﬂower classiﬁcation over a large number of classes”. In

Indian Conference on Computer Vision, Graphics and Image Processing. Cited on page 159.

Ning, G., Zhang, Z., Huang, C., Ren, X., Wang, H., Cai, C. and He, Z. (2017). “Spatially supervised recurrent
convolutional neural networks for visual object tracking”. In 2017 IEEE International Symposium on Circuits
and Systems (ISCAS), pp. 1–4. IEEE. ISBN 9781467368520. doi: 10.1109/ISCAS.2017.8050867 . Cited on
page 63.

Noh, H., Hong, S. and Han, B. (2016). “Learning deconvolution network for semantic segmentation”. Proceedings
of the IEEE International Conference on Computer Vision, 11-18-Dece, 1520–1528. ISSN 15505499. doi: 10.1109/
iccv.2015.178 .

arxiv: 1505.04366 . Cited on page 100.

Olah, C., Mordvintsev, A. and Schubert, L. (2017). “Feature Visualization”. Distill, 2, no. 11, e7. ISSN 2476-0757.

doi: 10.23915/distill.00007 . Cited on pages 38 and 120.

van den Oord, A., Kalchbrenner, N. and Kavukcuoglu, K. (2016). “Pixel Recurrent Neural Networks”. Interna-

tional Conference on Machine Learning (ICML).

arxiv: 1601.06759 . Cited on page 66.

O’Reilly, R. and Rohrlich, J. (2018). “Deep Predictive Learning in Vision”. In 2018 Conference on Cognitive
Computational Neuroscience. Cognitive Computational Neuroscience, Philadelphia, Pennsylvania, USA. doi:
10.32470/CCN.2018.1242-0 . Cited on page 146.

Orhan, A. E. and Pitkow, X. (2017). “Skip Connections Eliminate Singularities”. pp. 1–16.

arxiv: 1701.09175

. Cited on page 60.

Pan, S. J. and Yang, Q. (2010). “A Survey on Transfer Learning”. IEEE Transactions on Knowledge and Data
Engineering, 22, no. 10, 1345–1359. ISSN 1041-4347. doi: 10.1109/tkde.2009.191 . Cited on page 89.

Papernot, N. and McDaniel, P. (2018). “Deep k-Nearest Neighbors: Towards Conﬁdent, Interpretable and Robust

Deep Learning”.

arxiv: 1803.04765 . Cited on page 97.

Pavel, M. S., Schulz, H. and Behnke, S. (2015). “Recurrent convolutional neural networks for object-class
segmentation of RGB-D video”. Proceedings of the International Joint Conference on Neural Networks, 2015-Septe.
ISSN 08936080. doi: 10.1109/ijcnn.2015.7280820 . Cited on page 22.

Pedamonti, D. (2018). “Comparison of non-linear activation functions for deep neural networks on MNIST

classiﬁcation task”. , no. 3.

arxiv: 1804.02763 . Cited on page 31.

Pedregosa, F., Varoquaux, G., Gramfort, A., Michel, V., Thirion, B., Grisel, O., Blondel, M., Prettenhofer, P., Weiss,
R., Dubourg, V., Vanderplas, J., Passos, A., Cournapeau, D., Brucher, M., Perrot, M. and Duchesnay, E. (2011).
“Scikit-learn: Machine Learning in Python”. Journal of Machine Learning Research, 12, 2825–2830. Cited on page
157.

Perry, C. J. and Fallah, M. (2014). “Feature integration and object representations along the dorsal stream visual

185

BIBLIOGRAPHY

hierarchy”. Frontiers in Computational Neuroscience, 8, 84. ISSN 1662-5188. doi: 10.3389/fncom.2014.00084
. Cited on pages 39 and 45.

Pesteie, M., Abolmaesumi, P. and Rohling, R. N. (2019). “Adaptive Augmentation of Medical Data Using
Independently Conditional Variational Auto-Encoders”. IEEE Transactions on Medical Imaging, 38, no. 12,
2807–2820. ISSN 1558-254X. doi: 10.1109/TMI.2019.2914656 . Cited on page 93.

Pezeshki, M., Fan, L., Brakel, P., Courville, A. and Bengio, Y. (2015). “Deconstructing the Ladder Network
arxiv: 1511.06430 . Cited on page 76.

Architecture”. In Proceedings of Machine Learning Research, vol. 48.

Philipp, G., Carbonell, J. G. and Song, D. (2018). “Gradients explode - deep networks are shallow - resnet

explained”. , no. 2017. Cited on page 60.

Pinheiro, P. and Collobert, R. (2014). “Recurrent convolutional neural networks for scene labeling”. Proceedings

of The 31st International Conference . . . , 32, no. June, 82–90.

arxiv: 1306.2795 . Cited on page 63.

Pinheiro, P. O. and Collobert, R. (2015). “From image-level to pixel-level labeling with Convolutional Networks”.
In IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 1713–1721. IEEE. ISBN 978-1-4673-
6964-0. doi: 10.1109/cvpr.2015.7298780 . Cited on page 51.

Poggio, T. A. and Vetter, T. (1992). “Recognition and structure from one 2D model view: Observations on

prototypes, object classes and symmetries”. Tech. Rep., MIT. Cited on page 91.

Prabhu, V., Kannan, A., Ravuri, M., Chablani, M., Sontag, D. and Amatriain, X. (2018). “Prototypical Clustering

Networks for Dermatological Disease Diagnosis”.

arxiv: 1811.03066 . Cited on pages 109 and 146.

Prabhu, V. U. and Birhane, A. (2020).

“Large image datasets: A pyrrhic win for computer vision?”

arXiv:2006.16923 [cs, stat].

arxiv: 2006.16923 . Cited on page 160.

Prémont-Schwarz, I., Ilin, A., Hao, T. H., Rasmus, A., Boney, R. and Valpola, H. (2017). “Recurrent Ladder
Networks”. In I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan and R. Garnett
(eds.), Advances in Neural Information Processing Systems 30, pp. 6009–6019. Curran Associates, Inc.
arxiv:
1707.09219 . Cited on page 76.

Purves, D., Monson, B. B., Sundararajan, J. and Wojtach, W. T. (2014). “How biological vision succeeds in the
physical world.” Proceedings of the National Academy of Sciences of the United States of America, 111, no. 13, 4750–5.
ISSN 1091-6490. doi: 10.1073/pnas.1311309111 . Cited on page 39.

Rahman, S., Khan, S. and Porikli, F. (2018). “A Uniﬁed Approach for Conventional Zero-Shot, Generalized
Zero-Shot, and Few-Shot Learning”. IEEE Transactions on Image Processing, 27, no. 11, 5652–5667. ISSN
10577149. doi: 10.1109/tip.2018.2861573 .

arxiv: 1706.08653 . Cited on pages 101 and 114.

Rajalingham, R., Issa, E. B., Bashivan, P., Kar, K., Schmidt, K. and DiCarlo, J. J. (2018). “Large-Scale, High-
Resolution Comparison of the Core Visual Object Recognition Behavior of Humans, Monkeys, and State-of-
the-Art Deep Artiﬁcial Neural Networks”. The Journal of Neuroscience, 38, no. 33, 7255–7269. ISSN 0270-6474.
doi: 10.1523/jneurosci.0388-18.2018 . Cited on pages 41, 142, and 168.

Rasmus, A., Valpola, H., Honkala, M., Berglund, M. and Raiko, T. (2015). “Semi-Supervised Learning with
Ladder Networks”. In NIPS’15 Proceedings of the 28th International Conference on Neural Information Processing
arxiv: 1507.02672 .
Systems, vol. 2, pp. 3546–3554. MIT Press Cambridge, MA, USA, Montreal, Canada.
Cited on page 76.

Ravi, S. and Larochelle, H. (2017). “Optimization as a model for few-shot learning”. In International Conference
on Learning Representations (ICRL), pp. 1–11. url: https://openreview.net/forum?id=rJY0-Kcll&
noteId=rJY0-Kcll. Cited on pages 108, 109, 119, 159, and 161.

Razavian, A. S., Azizpour, H., Sullivan, J., Carlsson, S., Sharif, A., Hossein, R., Josephine, A., Stefan, S. and
Royal, K. T. H. (2014). “CNN Features oﬀ-the-shelf : An Astounding Baseline for Recognition”. CVPRW ’14
Proceedings of the 2014 IEEE Conference on Computer Vision and Pattern Recognition Workshops, pp. 512–519. ISSN

186

BIBLIOGRAPHY

21607516. doi: 10.1109/cvprw.2014.131 .

arxiv: 1403.6382 . Cited on pages 51, 98, and 99.

Ren, M., Triantaﬁllou, E., Ravi, S., Snell, J., Swersky, K., Tenenbaum, J. B., Larochelle, H. and Zemel, R. S. (2018).
arxiv: 1803.00676 .

“Meta-Learning for Semi-Supervised Few-Shot Classiﬁcation”. In ICLR, pp. 1–15.
Cited on pages 119 and 141.

Ren, S., He, K., Girshick, R. and Sun, J. (2015). “Faster R-CNN: Towards Real-Time Object Detection with Region
arxiv:

Proposal Networks”. Nips, pp. 1–10. ISSN 01689002. doi: 10.1016/j.nima.2015.05.028 .
1506.01497v1 . Cited on page 65.

Ribeiro, M. T., Singh, S. and Guestrin, C. (2016). “Why Should {I} Trust You?: Explaining the Predictions of Any
arxiv: 1602.04938 .

Classiﬁer”. In 22nd ACM SIGKDD Conference on Knowledge Discovery and Data Mining.
Cited on page 121.

Riesenhuber, M. and Poggio, T. (1999). “Hierarchical models of object recognition in cortex.” Nature neuroscience,

2, no. 11, 1019–25. ISSN 1097-6256. doi: 10.1038/14819 . Cited on pages 38 and 41.

Rippel, O., Paluri, M., Dollar, P. and Bourdev, L. (2016). “Metric Learning with Adaptive Density Discrimination”.
arxiv: 1511.05939 . Cited on pages 125

In International Conference on Learning Representations (ICRL).
and 147.

Roelfsema, P. R. (2006). “Cortical Algorithms for Perceptual Grouping”. Annual Review of Neuroscience, 29,
no. 1, 203–227. ISSN 0147-006X. doi: 10.1146/annurev.neuro.29.051605.112939 . Cited on pages
34 and 35.

Ronneberger, O., Fischer, P. and Brox, T. (2015). “U-Net: Convolutional Networks for Biomedical Image
Segmentation”. In N. Navab, J. Hornegger, W. M. Wells and A. F. Frangi (eds.), Medical Image Computing and
Computer-Assisted Intervention – MICCAI 2015, vol. LNCS 9351, pp. 234–241. Springer International Publishing,
Cham. ISBN 978-3-319-24574-4. doi: 10.1007/978-3-642-40763-5 . Cited on page 51.

Rubinstein, R., Bruckstein, A. M. and Elad, M. (2010). “Dictionaries for Sparse Representation Modeling”.
Proceedings of the IEEE, 98, no. 6, 1045–1057. ISSN 0018-9219. doi: 10.1109/jproc.2010.2040551 . Cited
on pages 118 and 123.

Ruder, S. (2017a). “An Overview of Multi-Task Learning in Deep Neural Networks”. arXiv:1706.05098 [cs, stat].

arxiv: 1706.05098 . Cited on pages 111 and 112.

Ruder, S. (2017b). “Transfer Learning - Machine Learning’ s Next Frontier”. url: http://ruder.io/

transfer-learning/. Cited on page 89.

Rumelhart, D. E. and McClelland, J. L. (1987). “Learning Internal Representations by Error Propagation”. In
Parallel Distributed Processing: Explorations in the Microstructure of Cognition: Foundations, pp. 318–362. MITP.
ISBN 978-0-262-29140-8. url: http://ieeexplore.ieee.org/document/6302929. Cited on page 22.

Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., Huang, Z., Karpathy, A., Khosla, A., Bernstein,
M., Berg, A. C. and Fei-Fei, L. (2015). “ImageNet large scale visual recognition challenge”. International Journal
of Computer Vision (IJCV), 115, no. 3, 211–252. doi: 10.1007/s11263-015-0816-y .
arxiv: 1409.0575
. Cited on pages 159 and 161.

Saalmann, Y. B., Pinsk, M. A., Wang, L., Li, X. and Kastner, S. (2012). “The Pulvinar Regulates Information
Transmission Between Cortical Areas Based on Attention Demands”. Science, 337, no. 6095, 753–756. ISSN
0036-8075. doi: 10.1126/science.1223082 . Cited on page 115.

Sajjadi, M., Javanmardi, M. and Tasdizen, T. (2016). “Regularization With Stochastic Transformations and Per-
turbations for Deep Semi-Supervised Learning”.
In D. D. Lee, M. Sugiyama, U. V. Luxburg, I. Guyon
and R. Garnett (eds.), Advances in Neural Information Processing Systems 29, pp. 1163–1171. Curran As-
sociates, Inc. url: http://papers.nips.cc/paper/6333-regularization-with-stochastic-
transformations-and-perturbations-for-deep-semi-supervised-learning.pdf. Cited on

187

BIBLIOGRAPHY

page 106.

Santoro, A., Bartunov, S., Botvinick, M., Wierstra, D. and Lillicrap, T. (2016). “One-shot Learning with Memory-
arxiv:

Augmented Neural Networks”. arXiv preprint. ISSN 19449224. doi: 10.1002/2014gb005021 .
1605.06065 . Cited on pages 119 and 120.

Savarese, P. H. P. and Maire, M. (2019). “Learning Implicitly Recurrent CNNs Through Parameter Sharing”.

arxiv: 1902.09701 . Cited on page 63.

Schrimpf, M., Kubilius, J., Hong, H., Majaj, N. J., Rajalingham, R., Issa, E. B., Kar, K., Bashivan, P., Prescott-Roy,
J., Schmidt, K., Yamins, D. L. K. and DiCarlo, J. J. (2018). “Brain-Score: Which Artiﬁcial Neural Network for
Object Recognition is most Brain-Like?” doi: 10.1101/407007 .

biorxiv: 407007 . Cited on page 42.

Schroﬀ, F., Kalenichenko, D. and Philbin, J. (2015). “FaceNet: A uniﬁed embedding for face recognition and
clustering”. In Conference on Computer Vision and Pattern Recognition (CVPR), vol. 07-12-June, pp. 815–823.
IEEE. doi: 10.1109/cvpr.2015.7298682 .

arxiv: 1503.03832 . Cited on pages 105 and 106.

Schwarz, M., Milan, A., Lenz, C., Mu, A., Periyasamy, A. S., Schreiber, M., Sch, S. and Behnke, S. (2017). “NimbRo
Picking : Versatile Part Handling for Warehouse Automation”. IEEE International Conference on Robotics and
Automation (ICRA), pp. 3032–3039. doi: 10.1109/icra.2017.7989348 . Cited on page 51.

Sermanet, P., Eigen, D., Zhang, X., Mathieu, M., Fergus, R. and LeCun, Y. (2013). “OverFeat: Integrated
arxiv: 1312.6229 . Cited on

Recognition, Localization and Detection using Convolutional Networks”.
pages 41 and 51.

Serre, T., Wolf, L., Bileschi, S., Riesenhuber, M. and Poggio, T. (2007). “Robust object recognition with cortex-
IEEE transactions on pattern analysis and machine intelligence, 29, no. 3, 411–426. doi:

like mechanisms”.
10.1109/TPAMI.2007.56 . Cited on page 118.

Serre, T., Wolf, L. and Poggio, T. (2005). “Object recognition with features inspired by visual cortex”. Proceedings
of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2, 994–1000. ISSN 10636919.
doi: 10.1109/cvpr.2005.254 .

arxiv: cs/0112017 . Cited on page 38.

Settles, B. (2010). “Active Learning Literature Survey”. Tech. Rep.. Cited on page 97.

Shalev-Shwartz, S. and Ben-David, S. (2014). Understanding Machine Learning: From Theory to Algorithms.
Cambridge University Press. ISBN 1-107-05713-2. doi: 10.1017/CBO9781107298019 . Cited on pages 85
and 123.

Shelhamer, E., Long, J. and Darrell, T. (2017). “Fully Convolutional Networks for Semantic Segmentation”. IEEE
Transactions on Pattern Analysis and Machine Intelligence, 39, no. 4, 640–651. ISSN 0162-8828. doi: 10.1109/
tpami.2016.2572683 .

arxiv: 1605.06211 . Cited on pages 52, 55, 100, and 141.

Shen, F., Gan, R. and Zeng, G. (2016). “Weighted residuals for very deep networks”. In International Conference on
Systems and Informatics, ICSAI, pp. 936–941. ISBN 978-1-5090-5521-0. doi: 10.1109/icsai.2016.7811085
.

arxiv: 1605.08831 . Cited on page 56.

Shetty, R. and Laaksonen, J. (2015). “Video captioning with recurrent networks based on frame- and video-level
arxiv: 1512.02949 . Cited on page 22.

features and visual content classiﬁcation”. arXiv:1512.02949 [cs].

Shin, H.-C., Roth, H. R., Gao, M., Lu, L., Xu, Z., Nogues, I., Yao, J., Mollura, D. and Summers, R. M. (2016). “Deep
Convolutional Neural Networks for Computer-Aided Detection: CNN Architectures, Dataset Characteristics
and Transfer Learning”. IEEE Transactions on Medical Imaging, 35, no. 5, 1285–1298. doi: 10.1109/tmi.2016.
2528162 . Cited on pages 99 and 126.

Shrikumar, A., Greenside, P. and Kundaje, A. (2017). “Learning Important Features Through Propagating

Activation Diﬀerences”.

arxiv: 1704.02685 . Cited on page 121.

Shrivastava, A. and Gupta, A. (2016). “Contextual Priming and Feedback for Faster R-CNN”. In B. Leibe,

188

BIBLIOGRAPHY

J. Matas, N. Sebe and M. Welling (eds.), Computer Vision – ECCV 2016, vol. 9905, pp. 330–348. Springer
International Publishing, Cham. ISBN 978-3-319-46447-3. doi: 10.1007/978-3-319-46448-0\_20 . Cited
on page 65.

Shu, J., Xu, Z. and Meng, D. (2018). “Small Sample Learning in Big Data Era”. ISSN 1872826X. doi: arXiv:

1808.04572v1 .

arxiv: 1808.04572 . Cited on page 108.

Shui, C., Zhou, F., Gagné, C. and Wang, B. (2019). “Deep Active Learning: Uniﬁed and Principled Method for

Query and Training”. arXiv:1911.09162 [cs, stat].

arxiv: 1911.09162 . Cited on page 98.

Siam, M., Valipour, S., Jagersand, M. and Ray, N. (2017). “Convolutional gated recurrent networks for video
segmentation”. In 2017 IEEE International Conference on Image Processing (ICIP), pp. 3090–3094. doi: 10.1109/
ICIP.2017.8296851 . Cited on page 22.

Simard, P. Y., Steinkraus, D. and Platt,

J. (2003).

works Applied to Visual Document Analysis”.
us/research/publication/best-practices-for-convolutional-neural-networks-
applied-to-visual-document-analysis/. Cited on page 91.

url:

“Best Practices for Convolutional Neural Net-
https://www.microsoft.com/en-

Siméoni, O., Budnik, M., Avrithis, Y. and Gravier, G. (2019). “Rethinking deep active learning: Using unlabeled

data at model training”. arXiv:1911.08177 [cs].

arxiv: 1911.08177 . Cited on pages 97 and 98.

Simonyan, K. and Zisserman, A. (2015). “Very Deep Convolutional Networks for Large-Scale Image Recognition”.
arxiv: 1409.1556 . Cited on pages

In International Conference on Learning Representations (ICRL), pp. 1–14.
41, 51, and 104.

Sironi, A., Tekin, B., Rigamonti, R., Lepetit, V. and Fua, P. (2015). “Learning Separable Filters”. IEEE Transactions
on Pattern Analysis and Machine Intelligence, 37, no. 1, 94–106. ISSN 0162-8828, 2160-9292. doi: 10.1109/
TPAMI.2014.2343229 . Cited on page 107.

Sivic, J. and Zisserman, A. (2003). “Video Google: A text retrieval approach to object matching in videos”. In
Proceedings Ninth IEEE International Conference on Computer Vision, pp. 1470–1477 vol.2. IEEE, Nice, France.
ISBN 978-0-7695-1950-0. doi: 10.1109/ICCV.2003.1238663 . Cited on page 27.

Snell, J., Swersky, K. and Zemel, R. (2017). “Prototypical Networks for Few-shot Learning”. In I. Guyon,
U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan and R. Garnett (eds.), Advances in Neural
arxiv: 1703.05175 . Cited on
Information Processing Systems 30, pp. 4077–4087. Curran Associates, Inc.
pages 14, 95, 109, 117, 119, 121, 132, 137, 138, 144, and 170.

Soekhoe, D., van der Putten, P. and Plaat, A. (2016). “On the Impact of Data Set Size in Transfer Learning Using
Deep Neural Networks”. In H. Boström, A. Knobbe, C. Soares and P. Papapetrou (eds.), Advances in Intelligent
Data Analysis XV: 15th International Symposium, IDA 2016, Stockholm, Sweden, October 13-15, 2016, Proceedings,
pp. 50–60. Springer International Publishing, Cham. ISBN 978-3-319-46349-0. doi: 10.1007/978-3-319-
46349-0\_5 . Cited on page 100.

Sohn, K. (2016). “Improved Deep Metric Learning with Multi-class N-pair Loss Objective”. 30th Conference
on Neural Information Processing Systems, , no. Nips, 1857–1865. ISSN 10495258. doi: 10.1080/02678373.
2017.1304463 . Cited on page 105.

Sønderby, S. K., Sønderby, C. K., Maaløe, L. and Winther, O. (2015). “Recurrent Spatial Transformer Networks”.

pp. 1–9.

arxiv: 1509.05329 . Cited on page 67.

Song, H. O., Jegelka, S., Rathod, V. and Murphy, K. (2017). “Deep Metric Learning via Facility Location”. In
arxiv: 1612.01213 .

IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 5382–5390.
Cited on pages 117 and 119.

Souﬁ, N. and Valdenegro-Toro, M. (2019). “Data augmentation with Symbolic-to-Real Image Translation GANs

for Traﬃc Sign Recognition”. arXiv:1907.12902 [cs, stat].

arxiv: 1907.12902 . Cited on page 94.

189

BIBLIOGRAPHY

Spoerer, C. J., McClure, P. and Kriegeskorte, N. (2017). “Recurrent Convolutional Neural Networks: A Better
Model Of Biological Object Recognition Under Occlusion”. Frontiers in Psychology, 8, 1551. ISSN 1664-1078.
doi: 10.3389/fpsyg.2017.01551 . Cited on pages 63, 64, 68, 69, 83, and 149.

Springenberg, J. T., Dosovitskiy, A., Brox, T. and Riedmiller, M. (2014). “Striving for Simplicity: The All

Convolutional Net”.

arxiv: 1412.6806 . Cited on pages 30, 31, and 38.

Srivastava, N., Hinton, G., Krizhevsky, A., Sutskever, I. and Salakhutdinov, R. (2014). “Dropout: Prevent NN from
overﬁtting”. Journal of Machine Learning Research, 15, 1929–1958. ISSN 15337928. doi: 10.1214/12-aos1000
.

arxiv: 1102.4807 . Cited on page 104.

Srivastava, R. K., Greﬀ, K. and Schmidhuber, J. (2015). “Highway Networks”.

arxiv: 1505.00387 . Cited on

pages 56 and 57.

Stollenga, M. F., Masci, J., Gomez, F. and Schmidhuber, J. J. (2014). “Deep Networks with Internal Selective
arxiv: 1407.3068 . Cited on pages 69, 70, 75,

Attention through Feedback Connections”. pp. 3545–3553.
and 78.

Sundararajan, M., Taly, A. and Yan, Q. (2017). “Axiomatic Attribution for Deep Networks”. In International

Conference on Machine Learning.

arxiv: 1703.01365 . Cited on page 120.

Sundermeyer, M., Ney, H. and Schlüter, R. (2015). “From Feedforward to Recurrent LSTM Neural Networks for
Language Modeling”. IEEE/ACM Transactions on Audio, Speech, and Language Processing, 23, no. 3, 517–529.
ISSN 2329-9304. doi: 10.1109/TASLP.2015.2400218 . Cited on page 22.

Szegedy, C., Ioﬀe, S., Vanhoucke, V. and Alemi, A. (2016a). “Inception-v4, Inception-ResNet and the Impact of

Residual Connections on Learning”. Arxiv, p. 12.

arxiv: 1602.07261 . Cited on pages 41, 54, and 56.

Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed, S., Anguelov, D., Erhan, D., Vanhoucke, V. and Rabinovich, A.
(2015). “Going deeper with convolutions”. In IEEE Conference on Computer Vision and Pattern Recognition
(CVPR), pp. 1–9. ISBN 978-1-4673-6964-0. doi: 10.1109/cvpr.2015.7298594 .
arxiv: 1409.4842 .
Cited on pages 29, 31, 41, 53, and 126.

Szegedy, C., Vanhoucke, V., Ioﬀe, S., Shlens, J. and Wojna, Z. (2016b). “Rethinking the Inception Architecture
for Computer Vision”. Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern
Recognition (CVPR), pp. 2818–2826.

arxiv: 1512.00567 . Cited on pages 53 and 54.

Targ, S., Almeida, D. and Lyman, K. (2016). “Resnet in Resnet: Generalizing Residual Architectures”.

arxiv:

1603.08029 . Cited on page 57.

Teftef, E., Carvajal, C., Viéville, T. and Alexandre, F. (2013). “When early vision in the retina attempts to
take decisions about visual motion events : The role of konio cells”. url: https://hal.inria.fr/hal-
00826099. Cited on pages 34 and 43.

Theis, L., van den Oord, A. and Bethge, M. (2016).

“A note on the evaluation of generative models”.

arXiv:1511.01844 [cs, stat].

arxiv: 1511.01844 . Cited on page 93.

Torralba, A., Fergus, R. and Freeman, W. (2008). “80 Million Tiny Images: A Large Data Set for Nonparametric
Object and Scene Recognition”. IEEE Transactions on Pattern Analysis and Machine Intelligence, 30, no. 11,
1958–1970. ISSN 0162-8828. doi: 10.1109/TPAMI.2008.128 . Cited on page 160.

Torralba, A. and Oliva, A. (2003). “Statistics of natural image categories”. Network (Bristol, England), 14, no. 3,

391–412. ISSN 0954-898X. doi: 10.1088/0954-898x/14/3/302 . Cited on page 27.

Triantaﬁllou, E., Zemel, R. and Urtasun, R. (2017). “Few-Shot Learning Through an Information Retrieval Lens”.

Tech. Rep..

arxiv: 1707.02610 . Cited on pages 88, 109, and 118.

Tsai, Y.-H., Hamsici, O. C. and Yang, M.-H. (2015). “Adaptive region pooling for object detection”. In 2015
IEEE Conference on Computer Vision and Pattern Recognition (CVPR), vol. 07-12-June, pp. 731–739. IEEE. ISBN

190

BIBLIOGRAPHY

978-1-4673-6964-0. doi: 10.1109/cvpr.2015.7298673 . Cited on page 31.

Ungerleider, L. G. and Haxby, J. V. (1994). “"What" and "where" in the human brain”. Current Opinion in
Neurobiology, 4, no. 2, 157–165. ISSN 0959-4388. doi: 10.1016/0959-4388(94)90066-3 . Cited on page
34.

Vallet, A. and Sakamoto, H. (2016). “Convolutional Recurrent Neural Networks for Better Image Understanding”.
In 2016 International Conference on Digital Image Computing: Techniques and Applications (DICTA), pp. 1–7. IEEE.
ISBN 978-1-5090-2896-2. doi: 10.1109/dicta.2016.7797026 . Cited on pages 64, 67, 70, 71, 72, 74, 78,
and 81.

Valpola, H. (2014). “From neural PCA to deep unsupervised learning”. pp. 1–23.

arxiv: 1411.7783 . Cited

on page 76.

Vanschoren, J. (2018). “Meta-Learning: A Survey”. arXiv:1810.03548 [cs, stat].

arxiv: 1810.03548 . Cited on

page 108.

Veit, A., Wilber, M. and Belongie, S. (2016). “Residual Networks Behave Like Ensembles of Relatively Shallow

Networks”. ISSN 10495258.

arxiv: 1605.06431 . Cited on page 59.

Verma, V., Lamb, A., Kannala, J., Bengio, Y. and Lopez-Paz, D. (2019). “Interpolation Consistency Training for

Semi-Supervised Learning”. arXiv:1903.03825 [cs, stat].

arxiv: 1903.03825 . Cited on page 92.

Viéville, T. and Crahay, S. (2004a). “A deterministic biologically plausible classiﬁer”. Neurocomputing, 58-60,

923–928. ISSN 09252312. doi: 10.1016/j.neucom.2004.01.147 . Cited on page 35.

Viéville, T. and Crahay, S. (2004b). “Using an Hebbian Learning Rule for Multi-Class SVM Classiﬁers”. Journal
of Computational Neuroscience, 17, no. 3, 271–287. ISSN 0929-5313. doi: 10.1023/b:jcns.0000044873.
20850.9c . Cited on pages 115, 118, and 140.

Viéville, T., Hinaut, X., Drumond, T. F. and Alexandre, F. (2017). “Recurrent neural network weight estima-
tion through backward tuning”. Research Report RR-9100, INRIA. url: https://hal.inria.fr/hal-
01610735. Cited on page 115.

Vincent, P., Larochelle, H., Bengio, Y. and Manzagol, P.-A. (2008). “Extracting and composing robust features
with denoising autoencoders”. In Proceedings of the 25th International Conference on Machine Learning - ICML ’08,
pp. 1096–1103. ACM Press, Helsinki, Finland. ISBN 978-1-60558-205-4. doi: 10.1145/1390156.1390294 .
Cited on page 23.

Vinyals, O., Blundell, C., Lillicrap, T., Kavukcuoglu, K. and Wierstra, D. (2016). “Matching Networks for One

Shot Learning”. NIPS.

arxiv: 1606.04080 . Cited on pages 14, 109, 119, 138, 159, and 161.

Visin, F., Kastner, K., Cho, K., Matteucci, M., Courville, A. and Bengio, Y. (2015). “ReNet: A Recurrent Neural
arxiv: 1505.00393 . Cited on pages 64, 65, 70,

Network Based Alternative to Convolutional Networks”.
73, and 78.

Visin, F., Romero, A., Cho, K., Matteucci, M., Ciccone, M., Kastner, K., Bengio, Y. and Courville, A. (2016).
“ReSeg: A Recurrent Neural Network-Based Model for Semantic Segmentation”. IEEE Computer Society
Conference on Computer Vision and Pattern Recognition Workshops, pp. 426–433. ISSN 21607516. doi: 10.1109/
cvprw.2016.60 .

arxiv: 1511.07053v1 . Cited on pages 70 and 78.

Wah, C., Branson, S., Welinder, P., Perona, P. and Belongie, S. (2011). “The Caltech-UCSD Birds-200-2011
Dataset”. Tech. Rep. CNS-TR-2011-001, California Institute of Technology. url: http://www.vision.
caltech.edu/visipedia/papers/CUB\_200\_2011.pdf. Cited on pages 88 and 159.

Walker, R. A. (2010). “Sociocultural Issues in Motivation”. In P. Peterson, E. Baker and B. McGaw (eds.),
International Encyclopedia of Education (Third Edition), pp. 712–717. Elsevier, Oxford. ISBN 978-0-08-044894-7.
doi: 10.1016/B978-0-08-044894-7.00629-1 . Cited on page 110.

191

BIBLIOGRAPHY

Wan, L., Zeiler, M., Zhang, S., LeCun, Y. and Fergus, R. (2013). “Regularization of neural networks using
arxiv: 1509.08985 . Cited

dropconnect”. In International Conference on Machine Learning, 1, pp. 109–111.
on page 104.

Wang, B., Luo, X., Li, Z., Zhu, W., Shi, Z. and Osher, S. J. (2018a). “Deep Neural Nets with Interpolating Function

as Output Activation”.

arxiv: 1802.00168 . Cited on page 31.

Wang, K., Zhang, D., Li, Y., Zhang, R. and Lin, L. (2017a). “Cost-Eﬀective Active Learning for Deep Image
Classiﬁcation”. IEEE Transactions on Circuits and Systems for Video Technology, 27, no. 12, 2591–2600. ISSN
1051-8215. doi: 10.1109/TCSVT.2016.2589879 . Cited on page 97.

Wang, P., Chen, P., Yuan, Y., Liu, D., Huang, Z., Hou, X. and Cottrell, G. (2017b). “Understanding Convolution
arxiv: 1702.08502 . Cited on page 30.

for Semantic Segmentation”.

Wang, Q., Zhang, J., Song, S. and Zhang, Z. (2014). “Attentional Neural Network: Feature Selection Using
Cognitive Feedback”. In Z. Ghahramani, M. Welling, C. Cortes, N. D. Lawrence and K. Q. Weinberger
(eds.), Advances in Neural Information Processing Systems 27, pp. 2033–2041. Curran Associates, Inc.
arxiv:
1411.5140 . Cited on pages 70 and 78.

Wang, Y., Wu, X.-M., Li, Q., Gu, J., Xiang, W., Zhang, L. and Li, V. O. K. (2018b). “Large Margin Few-Shot

Learning”.

arxiv: 1807.02872 . Cited on page 147.

Weinshall, D., Cohen, G. and Amir, D. (2018). “Curriculum Learning by Transfer Learning: Theory and
arxiv: 1802.03796 . Cited on pages 110

Experiments with Deep Networks”. arXiv:1802.03796 [cs].
and 111.

Weiss, K., Khoshgoftaar, T. M. and Wang, D. (2016). “A survey of transfer learning”. Journal of Big Data, 3, no. 1,

9. ISSN 2196-1115. doi: 10.1186/s40537-016-0043-6 . Cited on pages 89 and 114.

Wen, H., Han, K., Shi, J., Zhang, Y., Culurciello, E. and Liu, Z. (2018). “Deep Predictive Coding Network for

Object Recognition”.

arxiv: 1802.04762 . Cited on pages 64, 66, 70, 74, 78, 81, and 83.

Wu, Y., Schuster, M., Chen, Z., Le, Q. V., Norouzi, M., Macherey, W., Krikun, M., Cao, Y., Gao, Q., Macherey, K.,
Klingner, J., Shah, A., Johnson, M., Liu, X., Kaiser, Ł., Gouws, S., Kato, Y., Kudo, T., Kazawa, H., Stevens, K.,
Kurian, G., Patil, N., Wang, W., Young, C., Smith, J., Riesa, J., Rudnick, A., Vinyals, O., Corrado, G., Hughes,
M. and Dean, J. (2016). “Google’s Neural Machine Translation System: Bridging the Gap between Human
and Machine Translation”. arXiv:1609.08144 [cs].

arxiv: 1609.08144 . Cited on page 22.

Wyatte, D., Jilk, D. J. and O’Reilly, R. C. (2014). “Early recurrent feedback facilitates visual object recognition
under challenging conditions”. Frontiers in Psychology, 5, no. JUL, 674. ISSN 16641078. doi: 10.3389/fpsyg.
2014.00674 . Cited on page 63.

Xian, Y., Lampert, C. H., Schiele, B. and Akata, Z. (2018). “Zero-Shot Learning - A Comprehensive Evaluation
of the Good, the Bad and the Ugly”. IEEE Transactions on Pattern Analysis and Machine Intelligence, , no. c. ISSN
0162-8828. doi: 10.1109/tpami.2018.2857768 . Cited on pages 101 and 102.

Xiao, D., Huang, Y., Qin, C., Liu, Z., Li, Y. and Liu, C. (2019). “Transfer learning with convolutional neural
networks for small sample size problem in machinery fault diagnosis”. Proceedings of the Institution of
Mechanical Engineers, Part C: Journal of Mechanical Engineering Science, 233, no. 14, 5131–5143. ISSN 0954-4062.
doi: 10.1177/0954406219840381 . Cited on page 99.

Xie, Q., Dai, Z., Hovy, E., Luong, M.-T. and Le, Q. V. (2019). “Unsupervised Data Augmentation for Consistency

Training”. arXiv:1904.12848 [cs, stat].

arxiv: 1904.12848 . Cited on pages 91, 92, and 95.

Xie, S., Girshick, R., Dollár, P., Tu, Z. and He, K. (2017a). “Aggregated residual transformations for deep neural
networks”. In Proceedings - 30th IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2017, pp.
arxiv: 1611.05431 . Cited on
5987–5995. ISBN 978-1-5386-0457-1. doi: 10.1109/cvpr.2017.634 .
page 56.

192

BIBLIOGRAPHY

Xie, W., Noble, A. and Zisserman, A. (2017b). “Layer Recurrent Neural Networks”. pp. 1–17. url: https://
ayearofai.com/rohan-lenny-3-recurrent-neural-networks-10300100899b. Cited on pages
65, 70, 73, 77, and 78.

Xu, K., Ba, J., Kiros, R., Cho, K., Courville, A., Salakhutdinov, R., Zemel, R. and Bengio, Y. (2015). “Show, Attend
arxiv: 1502.03044 . Cited on page 67.

and Tell: Neural Image Caption Generation with Visual Attention”.

Xu, M., Gao, M., Chen, Y.-T., Davis, L. S. and Crandall, D. J. (2019). “Temporal Recurrent Networks for Online
Action Detection”. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pp. 5532–5541.
url: https://openaccess.thecvf.com/content\_ICCV\_2019/html/Xu\_Temporal\_Recurrent\_
Networks\_for\_Online\_Action\_Detection\_ICCV\_2019\_paper.html. Cited on page 22.

Yadav, A. and Singh, G. (2015). “Incremental k-means clustering algorithms: A review”. International Journal of
Latest Trends in Engineering and Technology, 5, no. 4. url: http://portal.acm.org/citation.cfm?id=
1596883. Cited on page 140.

Yamins, D. L. and DiCarlo, J. J. (2016). “Eight open questions in the computational modeling of higher sensory
cortex”. Current Opinion in Neurobiology, 37, 114–120. ISSN 0959-4388. doi: 10.1016/j.conb.2016.02.001
. Cited on pages 41, 142, and 167.

Yamins, D. L. K., Hong, H., Cadieu, C. F., Solomon, E. A., Seibert, D. and DiCarlo, J. J. (2014). “Performance-
optimized hierarchical models predict neural responses in higher visual cortex”. Proceedings of the National
Academy of Sciences, 111, no. 23, 8619–8624. ISSN 0027-8424. doi: 10.1073/pnas.1403112111 .
arxiv:
0706.1062v1 . Cited on page 41.

Yang, J., Jiang, Y.-G., Hauptmann, A. G. and Ngo, C.-W. (2007). “Evaluating bag-of-visual-words representations

in scene classiﬁcation”. doi: 10.1145/1290082.1290111 . Cited on page 28.

Yin, C., Qian, B., Cao, S., Li, X., Wei, J., Zheng, Q. and Davidson, I. (2017). “Deep Similarity-Based Batch Mode
Active Learning with Exploration-Exploitation”. In 2017 IEEE International Conference on Data Mining (ICDM),
pp. 575–584. IEEE, New Orleans, LA. ISBN 978-1-5386-3835-4. doi: 10.1109/ICDM.2017.67 . Cited on
page 98.

Yoshida, Y. and Miyato, T. (2017). “Spectral Norm Regularization for Improving the Generalizability of Deep

Learning”. arXiv:1705.10941 [cs, stat].

arxiv: 1705.10941 . Cited on page 104.

Yu, F. and Koltun, V. (2016). “Multi-Scale Context Aggregation by Dilated Convolutions”. In International

Conference on Learning Representations (ICRL).

arxiv: 1511.07122 . Cited on page 100.

Yu, Y., Si, X., Hu, C. and Zhang, J. (2019). “A Review of Recurrent Neural Networks: LSTM Cells and Network
Architectures”. Neural Computation, 31, no. 7, 1235–1270. ISSN 0899-7667. doi: 10.1162/neco\_a\_01199 .
Cited on page 22.

Zagoruyko, S. and Komodakis, N. (2016). “Wide Residual Networks”. Arxiv.

arxiv: 1605.07146 . Cited on

page 62.

Zamir, A. R., Wu, T. L., Sun, L., Shen, W. B., Shi, B. E., Malik, J. and Savarese, S. (2017). “Feedback networks”.
In Proceedings - 30th IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2017, vol. 2017-Janua,
pp. 1808–1817. ISBN 978-1-5386-0457-1. doi: 10.1109/cvpr.2017.196 .
arxiv: 1612.09508 . Cited on
pages 11, 66, 70, 71, 72, 74, 78, 79, 80, 108, and 111.

Zeiler, M. (2014). “Hierarchical Convolutional Deep Learning in Computer Vision”. Ph.D. thesis, New York

University. Cited on page 62.

Zeiler, M. D. and Fergus, R. (2014). “Visualizing and Understanding Convolutional Networks”. Lecture Notes
in Computer Science, 8689, 818–833. ISSN 978-3-319-10589-5. doi: 10.1007/978-3-319-10590-1\_53 .
arxiv: 1311.2901 . Cited on pages 30, 38, 41, 50, 100, and 120.

Zhang, C., Bengio, S., Hardt, M., Recht, B. and Vinyals, O. (2016a). “Understanding deep learning requires

193

BIBLIOGRAPHY

rethinking generalization”.

arxiv: 1611.03530 . Cited on page 103.

Zhang, H., Cisse, M., Dauphin, Y. N. and Lopez-Paz, D. (2018). “Mixup: Beyond Empirical Risk Minimization”.

arXiv:1710.09412 [cs, stat].

arxiv: 1710.09412 . Cited on page 92.

Zhang, K., Sun, M., Han, T. X., Yuan, X., Guo, L. and Liu, T. (2016b). “Residual Networks of Residual Networks:
Multilevel Residual Networks”. 14, no. 8, 1–12. ISSN 1051-8215. doi: 10.1109/tcsvt.2017.2654543 .
arxiv: 1608.02908 . Cited on page 57.

Zhao, Y. and Park, I. M. (2016). “Interpretable Nonlinear Dynamic Modeling of Neural Trajectories”. In D. D.
Lee, M. Sugiyama, U. V. Luxburg, I. Guyon and R. Garnett (eds.), Advances in Neural Information Processing
Systems 29, pp. 3333–3341. Curran Associates, Inc.

arxiv: 1608.06546 . Cited on page 114.

Zheng, L., Yang, Y. and Tian, Q. (2018). “SIFT Meets CNN: A Decade Survey of Instance Retrieval”. IEEE
Transactions on Pattern Analysis and Machine Intelligence, 40, no. 5, 1224–1244. ISSN 0162-8828. doi: 10.1109/
arxiv: 1608.01807 . Cited on pages 27 and 28.
tpami.2017.2709749 .

Zhu, J.-Y., Park, T., Isola, P. and Efros, A. A. (2017a). “Unpaired Image-to-Image Translation Using Cycle-
Consistent Adversarial Networks”. In 2017 IEEE International Conference on Computer Vision (ICCV), pp.
2242–2251. doi: 10.1109/ICCV.2017.244 . Cited on page 23.

Zhu, W., Qiu, Q., Huang, J., Calderbank, R., Sapiro, G. and Daubechies, I. (2017b). “LDMNet: Low Dimensional

Manifold Regularized Neural Networks”.

arxiv: 1711.06246 . Cited on pages 95, 105, 141, and 147.

Zou, Z., Shi, Z., Guo, Y. and Ye, J. (2019). “Object Detection in 20 Years: A Survey”.

arxiv: 1905.05055 .

Cited on page 21.

Zuo, Z., Shuai, B., Wang, G., Liu, X., Wang, X., Wang, B. and Chen, Y. (2016). “Learning Contextual Dependence
With Convolutional Hierarchical Recurrent Neural Networks”. IEEE Transactions on Image Processing, 25, no. 7,
2983–2996. ISSN 10577149. doi: 10.1109/tip.2016.2548241 .
arxiv: 1509.03877 . Cited on pages
65, 70, 73, 74, and 78.

This bibliography contains 352 references.

194

