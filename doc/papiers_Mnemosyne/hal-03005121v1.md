Stability analysis of a neural field self-organizing map
Georgios Is Detorakis, Antoine Chaillet, Nicolas P. Rougier

To cite this version:

Georgios Is Detorakis, Antoine Chaillet, Nicolas P. Rougier. Stability analysis of a neural field self-
￿hal-
organizing map. Journal of Mathematical Neuroscience, 2020, ￿10.1186/s13408-020-00097-6￿.
03005121￿

HAL Id: hal-03005121

https://inria.hal.science/hal-03005121

Submitted on 13 Nov 2020

HAL is a multi-disciplinary open access
archive for the deposit and dissemination of sci-
entific research documents, whether they are pub-
lished or not. The documents may come from
teaching and research institutions in France or
abroad, or from public or private research centers.

L’archive ouverte pluridisciplinaire HAL, est
destinée au dépôt et à la diffusion de documents
scientifiques de niveau recherche, publiés ou non,
émanant des établissements d’enseignement et de
recherche français ou étrangers, des laboratoires
publics ou privés.

1

2

3

4

5

6

7

8

9

10

11

12

13

14

15

16

17

18

19

20

21

22

23

24

25

26

27

28

29

30

31

32

33

34

35

36

37

38

39

40

41

42

43

44

45

46

47

48

Stability analysis of a neural ﬁeld self-organizing map
Georgios Is. Detorakis1, †

, and Nicolas P. Rougier4,5

, Antoine Chaillet2,3, †

1adNomus Inc., San Jose, CA, USA
2CentraleSup´elec, Univ. Paris Saclay, Laboratoire des Signaux et Syst`emes, Gif-sur-Yvette, France
3Institut Universitaire de France
4Inria Bordeaux Sud-Ouest, Bordeaux, France
5Institut des maladies neurod´eg´en´eratives, CNRS , Universit´e de Bordeaux, France
†
These authors contributed equally to this work

Abstract This work provides theoretical conditions guaranteeing that a self-organizing map eﬃciently
develops representations of the input space. The study relies on a neural ﬁelds model of spatiotemporal
activity in area 3b of the primary somatosensory cortex. We rely on Lyapunov’s theory for neural
ﬁelds to derive theoretical conditions for stability. The theoretical conditions are veriﬁed by numerical
experiments. The analysis highlights the key role played by the balance between excitation and inhibi-
tion of lateral synaptic coupling and the strength of synaptic gains in the formation and maintenance
of self-organizing maps.

Keywords self-organizing maps, neural ﬁelds, Lyapunov function, asymptotic stability, neural net-
works.

1 Introduction

Self-organizing maps (SOMs) are neural networks mapping a high-dimensional space to a low-
dimensional one, through unsupervised learning. They were ﬁrst introduced by Grossberg (see [14] for
a review), and later by Kohonen [19]. SOMs are widely used in computer science and data analysis
for quantization and visualization of high dimensional data [37, 24]. They also constitute a suitable
tool in computational neuroscience to study the formation and maintenance of topographic maps in
primary sensory cortices such as the visual cortex [30, 23] and the somatosensory cortex [13, 33]. Many
variations and applications of Kohonen’s SOM algorithm can be found in [16] and [26].

A type of self-organizing map based on neural ﬁelds theory has been introduced in [8], where neural
ﬁelds are used to drive the self-organizing process. Neural ﬁelds are integrodiﬀerential equations that
describe the spatiotemporal dynamics of a cortical sheet [3, 4, 5]. The SOM proposed in [8] describes
the topographic organization of area 3b of the primary somatosensory cortex of monkeys [21, 27]. The
model relies on an earlier work [28] known as Dynamic SOM (DSOM) algorithm. DSOM provides
an online SOM learning algorithm where the Kohonen’s SOM time-dependent learning rate and
neighborhood function have been replaced by time-invariant ones. DSOM’s neighborhood function and
learning rate solely depend on the distance of the winner unit (i.e., the most active neuron) from the
input. The model proposed in [8, 9] combines the DSOM time-invariant learning rate and neighborhood
function with Oja’s learning rule [25]. As thoroughly described in [8, 9], the model is compatible
with anatomical evidence of how area 3b in monkeys develops, maintains and reorganizes topographic
representations of a skin patch of the index ﬁnger.

In this work, we provide theoretical insights on the stability and convergence of the neural ﬁeld SOM
algorithm proposed in [8, 9] by studying a more general class of systems than the one proposed
originally in [8]. We use Lyapunov’s stability theory adapted to neural ﬁeld dynamics [10]. Since
typical activation functions employed in the model (such as absolute values or rectiﬁcation functions)
are not necessarily diﬀerentiable, we do not rely on linearization techniques but rather directly assess
the stability of the original nonlinear dynamics. Yet, the obtained results are local, meaning they are
valid only for initial conditions in the vicinity of the considered equilibrium. Nonetheless, we show
that they agree with numerical simulations. The stability conditions derived in this work can be used
towards the direction of tuning neural ﬁeld models such that they achieve the best possible results in
developing self-organizing maps and thus more generalized representations. Moreover, the conditions

1

49

50

51

52

53

54

55

56

57

we propose indicate that the balance between lateral excitation and inhibition keeps the system stable,
thus ruling out possible conﬁgurations in which learning does not take place properly. These ﬁndings
are in line with both experimental observations [29, 18] and computational modeling [34, 35, 36].

The paper is organized as follows. In Section 2, we recall the SOM model under concern and its basic
mechanisms. In Section 3, we present our main theoretical results, which we confront to numerical
simulations in Section 4. A discussion on the obtained results is provided in Section 5. Mathematical
proofs are given in Section 6.

2 Self-organizing neural ﬁelds

2.1 Neural population dynamics

We consider the following neural ﬁelds equation

τ

∂u
∂t (r, t) = −u(r, t) + ∫

Ω

wl(∣r − r

′

∣)rect(u(r

′

, t))dr

′ + I,

(1)

where Ω is a connected and compact subset of Rq (q = 1, 2, 3). For q = 2, the integral of a function
g ∶ Ω = Ω1 × Ω2 → R is to be understood as ∫
Ω g(r)dr = ∫
g(r1, r2)dr2dr1 with r = (r1, r2), and
similarly for q = 3. u(r, t) represents the mean membrane potential at position r ∈ Ω and time t ≥ 0.
τ is a positive decay time constant and I denotes an external input. wl is a function that represents
the strength of lateral synaptic coupling. It is given by

Ω2

Ω1

∫

where the excitation and inhibition synaptic weights are typically given by

wl(x) = we(x) − wi(x),

we(x) = Kee

−x2

/2σ2
e

wi(x) = Kie

−x2

/2σ2
i

(2)

(3a)

(3b)

with Ke, Ki, σe, σi > 0. In [8, 9], the input is provided through a two-dimensional skin model. The skin
model is composed of a two-dimensional grid and receptors. The receptors are points distributed on the
surface of the grid (uniformly). When a stimulus is applied on the grid, the receptors sample the input
signal and convey the information to the cortical model. The skin stimulus is a noisy Gaussian-like
function and the input to the neural ﬁelds model is provided by the following function I:

I(r, p, t) = 1 − ∣wf (r, t) − s(p)∣1

m

,

(4)

m is a function that maps the
where ∣ ⋅ ∣1 denotes the 1-norm: ∣x∣1 = ∑m
m. For instance, for a tactile stimulus at
raw input from the two-dimensional skin space to [0, 1]
position p ∈ R2 on the skin, s(p) ∈ Rm could be deﬁned as the normalized distance from p to each
receptor’s location, thus potentially of much higher dimension than 2. For a more detailed description
of receptors’ model please see [9]. wf ∶ Ω × R≥0 → Rm represents feed-forward synaptic weights whose
value is updated according to

i=1 ∣xi∣, and s ∶ R2 → [0, 1]

∂wf
∂t (r, t) = γ (s(p) − wf (r, t)) ∫

Ω

we(∣r − r

′

∣)rect(u(r

′

, t))dr

′

,

(5)

58

59

60

61

62

where γ is a positive constant that represents the learning rate and rect(x) = max{x, 0}. It is worth
m for all r ∈ Ω and all t ≥ 0 given any initial
observing that, since s(p) ∈ [0, 1]
m for all r ∈ Ω (this can be seen by observing that the entries
conditions satisfying wf (r, 0) ∈ [0, 1]
∂wf
∂t (r, t) are negative as soon as the corresponding entries of wf (r, t) become greater than 1;
of
similarly, they are positive when the corresponding entries of wf (r, t) get below 0: see (5)). Hence,

m, wf (r, t) ∈ [0, 1]

2

63

64

65

66

67

68

69

70

71

72

73

74

75

76

77

78

79

80

81

82

83

84

85

86

87

88

89

90

91

92

93

94

95

96

97

98

99

100

101

102

103

104

105

106

107

108

109

110

111

112

∣wf (r,t)−s(p)∣1
m

∈ [0, 1] at all times. The expression (4) can thus be interpreted as a high input when the

feedforward weights are close to s(p) and a lower input when these are more distant.

The overall model Eq. (1, 4, 5) reﬂects the dynamics of a cortical neural population in combination
with a learning rule of the feed-forward connections wf , which convey information from receptors to the
cortical sheet. As described in [8, 9], this model can express a variety of diﬀerent behaviors, depending
on the lateral connectivity kernels we and wi.

The main advantage of the learning rule given by Eq. (5) is that it is a biologically plausible modiﬁcation
of the DSOM learning rule [28]. In DSOM the learning rate and neighborhood function are time-
invariant and can adapt to the input according to one single parameter, called elasticity. This particular
modiﬁcation leads to the following behavior: if the winner neuron (i.e., the neuron that has the shortest
distance from the input stimulus to its corresponding codebook–weight) is close to the stimulus, then
the neighborhood function shrinks around it. This results in making the weights of neurons within the
dynamic neighborhood stronger and the weights of the other units weaker. However, when the winning
unit is very far from the current input, the neighborhood function exhibits a broad activity pattern,
promoting learning of every unit in the network. Therefore, in [8], the neighborhood function has been
′
replaced by the term ∫
providing a more realistic and biological plausible
learning algorithm for self-organizing maps in the context of neuroscience.

Ω we(∣r − r

∣)rect(u(r

, t))dr

′

′

2.2 Self-organizing maps

We start by brieﬂy describing how the SOM model introduced in [8] and [9] works. The algorithm
starts by initializing the feed-forward weights randomly (usually uniformly) and the neural ﬁeld activity
u(r, 0) is set to zero. The second step is to sample the input space by randomly drawn samples of
dimension m from an input distribution. At every epoch one sample is given to the neural ﬁeld Eq. (1)
and (5) through Eq. (4). This ﬁrst step is depicted in Figure 1 A, where a two-dimensional point
p = (p1, p2) is sampled from a uniform distribution p1, p2 ∼ U(0, 1). The samples are mapped to the
neural space through the function s and then are passed to Eq. (4). At this point we should point
out that there are two ways of presenting stimuli while training a self-organizing map. The ﬁrst is to
predetermine an amount of input samples and present one at each epoch (on-line learning) and the
second is to collect all the input samples into a batch and give all of them at once to the network
(batch learning). In this work we use the former (on-line learning) since it is biologically plausible.

Then the algorithm proceeds with computing the numerical solution of Eq. (1) and (5). To that
aim, Eq. (1) and Eq. (5) are discretized and solved numerically using Euler’s forward method. The
numerical solution of Eq. (1) is typically a bell-shaped curve (bump) centered on the neuron which
is the closest unit to the input sample and therefore is called winner neuron or best matching unit
(BMU). In Figure 1B this is depicted as a black disc on a discrete lattice. The lattice represents a
discretization of the ﬁeld where each tile corresponds to a neuron. Neurons that lie within the vicinity
(within the black disc in Figure 1 B) deﬁned by the solution of Eq. (1) update their weights based
on Eq. (5). The rest of the neurons feed-forward weights remain in their previous state. Once the
temporal integration of Eq. (1) and Eq. (5) is complete the activity of the ﬁeld is reset to its baseline
activity. Then another input sample is drawn and the whole process repeats itself. Once the number
of epochs has been exhausted, the learning stops and the mapping process has been completed.

To make the aforementioned algorithm directly comparable to Kohonen SOM [19] we provide some
insights. First, in Kohonen’s SOM we compute the distance between the input and the codebooks.
Here we do the same using Eq. (4). The neighborhood function that Kohonen’s SOM uses to update
the feed-forward weights is replaced here by the numerical solution of the neural ﬁeld (Eq. (1)) and
′
more precisely by the term ∫
. Both the learning rate and the width of the
neighborhood function are time-independent in our case as opposed to Kohonen’s SOM where they
are both time-dependent. Our learning rule is diﬀerent since we use a modiﬁed Oja rule [25], which
is based on Hebbian learning [15] and it is therefore biologically plausible [1]. The dimensionality
reduction in both models, the Kohonen and ours, takes place at the level of the learning rule. This
means that Eq. (5) is responsible for learning the representations and mapping the input distribution

Ω we(∣r − r

∣)rect(u(r

, t))dr

′

′

3

113

(of dimensions m) on a manifold of lower dimension q ∈ {1, 2, 3}.

Figure 1: Neural ﬁeld self-organizing map. Graphical representation of the learning algorithm
introduced in [8, 9]. A Tactile bi-dimensional stimuli are mapped to an m-dimensional space through a
function s that involves the skin receptors. This function is used to update the codebooks, which are
then mapped to the neural space Ω of lower dimension. The input I receives the mapped input sample
and provides input to the neural ﬁeld and codebooks equations. B The numerical steady-state solution
of Eq. (1) (i.e., bump) deﬁnes the neighborhood (the group of neurons) that will have its neurons
updating their codebooks based on Eq. (5).

114

115

116

117

118

119

120

121

122

123

124

125

3 Explicit conditions for stability

The most important question when one trains a self-organizing map is: Will the learning process
converge and properly map the input space to the neural one? In most of the cases, it is not possible to
predict this. However, in the speciﬁc case of the self-organizing algorithm provided by [8], we show
here that it is possible to obtain an analytical condition that guarantee the stability of the equilibrium
point of system (1)-(5). Stability during learning is a pre-requisite to generate a meaningful mapping
and thus a proper topographic map. Moreover, a byproduct of deriving such a stability condition is to
provide some insights on how to properly tune model parameters.

To this end, we now proceed to the mathematical analysis of the model. For the sake of generality, the
adopted mathematical framework is slightly wider than merely Eq. (1, 4, 5) and encompasses more
general classes of activation functions and synaptic kernels. We start by introducing the considered
class of systems, and then provide suﬃcient conditions for its stability and convergence.

126

3.1 Model under study

The self-organizing neural ﬁeld Eq. (1, 4, 5) is a particular case of the more general dynamics

τ

∂u
∂t (r, t) = −u(r, t) + ∫
∂wf
∂t (r, t) = γ (s(p) − wf (r, t)) ∫

wl(r, r

Ω

′

)fl(u(r

′

, t))dr

′ + fs(wf (r, t) − s(p))

′

we(r, r

)fe(u(r

′

, t))dr

′

,

Ω

(6a)

(6b)

127

128

where τ, γ > 0, wl, we ∈ L2(Ω2, R), the set of all square-integrable functions from Ω2 to R, and fe, fl
and fs are Lipischitz continuous functions.

4

pInput Space (p)Neural Space (r)s(p)s(p)ABwf Codebookℝ2ℝmΩ ⊂ ℝq129

3.2 Existence of equilibrium patterns

Assuming that inf r∈Ω ∫
the following equations:

Ω we(r, r

′

∗
)fe(u

(r

′

))dr

′ ≠ 0, any equilibrium pattern (u

∗

, w

∗
f ) of (6) satisﬁes

∗
u

(r) = fs(0) + ∫
Ω

∗
f (r) = s(p).

w

wl(r, r

′

∗
)fl(u

(r

′

))dr

′

(7a)

(7b)

130

Since ωl ∈ L2(Ω2, R), [11, Theorem 3.6] ensures the existence of at least one such equilibrium pattern.

131

3.3 Stability analysis of Eq. (6)

of a system ˙x(t) = f (x(t)), where x(t) ∶ Ω → Rn for each ﬁxed t ≥ 0,
We recall that an equilibrium x
is called globally exponentially stable if there exist k, ε > 0 such that, for all admissible initial conditions,
it holds that

∗

∥x(t) − x

∗

∥ ≤ k∥x(0) − x

∗

∥e

−εt, ∀t ≥ 0,

(8)

where ∥ ⋅ ∥ denotes the spatial L2-norm. This property thus ensures that all solutions go to the
∗
equilibrium conﬁguration x
in the L2 sense (global convergence), and that the transient overshoot
is proportional to the L2-norm of the distance between the initial conﬁguration and the equilibrium
(stability). The equilibrium pattern x
is said to be locally exponentially stable if (8) holds only for
solutions starting suﬃciently near from it (in the L2 sense). We refer the reader to [10] for a deeper
discussion on the stability analysis of neural ﬁelds.

∗

Our main result proposes a suﬃcient condition for the local exponential stability of Eq. (6). Its proof
is given in Section 6.1.
Theorem 1. Let Ω be a compact connected set of Rq, wl ∈ L2(Ω2, R) and we ∶ Ω2 → R be a bounded
function. Assume further that fl, fs and fe are Lipschitz continuous functions, and let (cid:96)l denote the
∗
∗
Lipschitz constant of fl. Let (u
f ) denote any equilibrium of Eq. (6), as deﬁned in Eq. (7). Then,
under the conditions that

, w

√

∫

∫

Ω

Ω

wl(r, r′

)2dr′dr <

1
(cid:96)l
′ > 0,

∫

inf
r∈Ω

Ω

we(r, r

′

∗
)fe(u

(r

′

))dr

(9)

(10)

∗
the equilibrium pattern (u

, w

∗
f ) is locally exponentially stable for Eq. (6).

Condition (9) imposes that the synaptic weights of the lateral coupling wl be suﬃciently small: stronger
lateral synaptic weights can be tolerated if the maximum slope (cid:96)l of the activation function fl is
low enough, meaning that the system given by Eq. (6a) is less self-excitable. Recall that, if fl is a
diﬀerentiable function, then (cid:96)l can be picked as the maximum value of its derivative. Nonetheless,
Theorem 1 does not impose such a diﬀerentiability requirement, thus allowing to consider non-smooth
functions such as absolute values, saturations, or rectiﬁcation functions. Note that it was shown in [32]
that condition (9) ensures that the system owns a single equilibrium pattern. It is also worth stressing
that the slopes of the functions fs and fe do not intervene in the stability conditions.

∗
Condition (10) requires a suﬃcient excitation in the vicinity of the equilibrium u
∗
it imposes that the considered equilibrium pattern u

does not lie in a region where fe is zero.

. Roughly speaking,

132

133

134

135

136

137

138

139

140

141

142

143

144

145

146

147

148

149

150

151

3.4 Stability analysis of the SOM neural ﬁelds

Theorem 1 provides a stability condition for the model described by Eq. (6). We next apply it
to the model given in [8] in order to derive more explicit and testable stability conditions. More

5

precisely, the self-organizing neural ﬁelds Eq. (1, 4, 5) can be put in the form of Eq. (6) by letting
fe(x) = fl(x) = rect(x), fs(x) = 1 − ∣x∣1
m

and

′

) = Kee
′

) = Kie

−∣r−r

−∣r−r

′

′

2
∣

/2σ2
e

2
∣

/2σ2
i

we(r, r

wi(r, r
′

wl(r, r

) = we(r, r

′

) − wi(r, r

′

).

In view of (7), the equilibrium patterns of Eq. (1, 4, 5) are given by

∗
u

(r) = 1 + ∫

∗
f (r) = s(p).

w

Ω

wl(r, r

′

∗
)rect(u

(r

′

))dr

′

(11a)

(11b)

(11c)

(12a)

(12b)

152

153

154

155

156

157

158

159

The Lipschitz constant of fl is (cid:96)l = 1. Based on this, we can also derive the following corollary, whose
proof is provided in Section 6.2.
Corollary 1. Assume that Ω is a compact and connected set of Rq and let we, wi and wl be as in
(11). Then, under the condition that

−∣r−r

(Kee

′

2
∣

/2σ2

e − Kie

−∣r−r

′

2
∣

/2σ2

2
i )

′

dr

dr < 1,

∫

∫

Ω

Ω

(13)

∗
the equilibrium (u

, w

∗
f ), as deﬁned in Eq. (12), is locally exponentially stable for Eq. (1)-(5).

A particular case for which local exponential stability holds is when the excitation and inhibition weight
functions are suﬃciently balanced. Indeed, it appears clearly that Eq. (13) is fulﬁlled if Ke ≃ Ki and
σe ≃ σi. See the discussion in Section 5 for further physiological insights on this condition.

The integral involved in (13) can be solved explicitly. For instance, in the two-dimensional case (q = 2),
the condition boils down to the following.

Corollary 2. Assume that Ω = [a, b] × [a, b] for some a, b ∈ R with b ≥ a and let we, wi and wl be as
in (11). Deﬁne

ξa,b(σ) ∶= (2σ2

(e

2
− (a−b)

2σ2 − 1) + σ

√

2π(a − b)Erf (

2

))

, ∀σ > 0,

a − b
√
2
σ

where Erf ∶ R → (−1, 1) denotes the Gauss Error Function. Then, under the condition that

K2

e ξa,b(σe/

√
2) + K2

i ξa,b(σi/

2) − 2KeKiξa,b

√

⎛
⎜
⎝

√

σeσi
e + σ2
σ2
i

⎞
⎟
⎠

< 1,

(14)

(15)

160

∗
the equilibrium (u

, w

∗
f ), as deﬁned in Eq. (12), is locally exponentially stable for Eq. (1)-(5).

Plenty of approximations are available for the Erf function in the literature. For instance, the following
expression approximates it with a 5.10

−4 error:

Erf(x) ≃ 1 −

1
(1 + a1x + a2x2 + a3x3 + a4x4)4 ,

161

162

163

with a1 = 0.278393, a2 = 0.230389, a3 = 0.000972, a4 = 0.078108; see for instance [2]. The Erf function
is also commonly implemented in mathematical software, thus making Eq. (15) easily testable in
practice.

6

164

165

166

167

168

169

170

171

172

173

174

175

176

177

178

179

180

181

182

183

184

185

186

187

188

189

190

191

192

193

194

195

196

197

198

199

200

201

202

4 Numerical assessment on a two-dimensional map

In order to numerically assess whether the above stability condition correctly predicts the performance
of the learning process, we focus on a simple example of a two-dimensional map (q = 2) and a
two-dimensional input space (n = 2). Furthermore, we choose s(p) to be the identity function since we
do not consider any receptors: the position of the tactile stimuli is assumed to be directly available.
This choice is motivated by the fact that the presence or absence of a receptors grid does not aﬀect the
theoretical results of the current work. We refer to [8, 9] for a more complex application of the neural
ﬁeld self-organizing algorithm.

We sample two-dimensional inputs from a uniform distribution. Therefore we have si(p) = (p1, p2)
where i indicates the i-th sample, and p1, p2 ∼ U(0, 1). In all our simulations we use 7000 sample
points and we train the self-organizing map over each of them (7000 epochs). It is worth stressing
the diﬀerence between the training time (epochs) and the simulation time. The former refers to the
iterations over all the input samples (stimuli): one such input is presented to the model at each
epoch. The latter is attributed to the numerical temporal integration of Eq. (1)-(5). Each epoch thus
corresponds to a predeﬁned number of simulation steps. At the end of each epoch the activity of the
neural ﬁeld is reset to baseline activity before proceeding to the next epoch.

4.1 Parameters and simulation details

40

i,j=1( i

The neural ﬁelds equations are discretized using k = 40 × 40 units. Accordingly, the two-dimensional
model Eq. (1)-(5) is simulated over a spatial uniform discretization Ωd of the spatial domain Ω =
[0, 1] × [0, 1], namely Ωd = ⋃40
, j
40 ). The considered input space, over which the stimuli are
uniformly distributed, is also [0, 1] × [0, 1] (two-dimensional input vectors). The temporal integration is
performed using the forward Euler method, whereas the spatial convolution in Eq. (1)-(5) is computed
via the Fast-Fourier Transform (FFT). The learning process runs for 7000 epochs. The components
of the feed-forward weights are initialized from a uniform distribution U(0, 0.01) and the neural ﬁeld
activity is set to zero. At each epoch, we feed a stimulus to Eq. (1)-(5) and the system evolves according
to its dynamics while the feed-forward weights are being updated. Then we reset the neural ﬁelds
activity to zero. We run each experiment ten times using a diﬀerent pseudo-random number generator
(PRNG) seed each time (the PRNG seeds are given in Appendix 6.3: the same initial conditions and
set of PRNG seeds sequence were used in each experimental condition).

The source code is written in Python (Numpy-, Numba-, Sklearn, and Matplotlib-dependent) and are
freely distributed under the GPL 3-Clause License (https://github.com/gdetor/som\_stability).
All the parameters used in numerical simulations are summarized in Table 1. All simulations ran on an
Intel NUC machine equipped with an Intel i7-10th generation processor and 32 GB of physical memory,
running Ubuntu Linux (20.04.1 LTS, Kernel: 5.4.0-47-generic). The simulation of one self-organizing
map consumes 493 MB of physical memory and it took 2671 seconds to run the 7000 epochs.

Ke
0.90

Figure 2

Figure 3

3.0

σe
0.11

0.11

Ki
0.86

2.80

σi
1.0

1.0

τ

1.0

1.0

dt

t

γ

epochs

0.015

0.015

25.0

25.0

0.002

0.002

7 000

7 000

Table 1: Simulation parameters. Ke and Ki are the amplitudes of excitatory and inhibitory lateral
connections, respectively. σe and σi are the variances of excitatory and inhibitory lateral connections,
respectively. τ is the decay time constant, dt is the integration time step in ms, t is the simulation
time in seconds. γ is the learning rate. In each epoch one stimulus is presented to the model.

4.2 SOM’s quality measures

We measure the quality of the self-organizing maps using two performance indicators: the distortion
D [6] and the δx − δy representation [7]. We recall here that Ωd is the spatial uniform discretization
of Ω = [0, 1] × [0, 1] and k = 40 × 40 is the number of nodes (neurons). Furthermore, for each

7

203

204

205

206

207

208

209

210

211

212

213

214

215

216

217

218

219

220

221

222

223

224

225

226

227

228

229

230

231

232

233

234

235

236

237

238

239

240

241

242

j ∈ {1, . . . , k}, wj
∗
the spatial discretization and t

∗
f (t

) denotes the steady-state value of the feed-forward weights at the j-th node of

corresponds to the time at the end of an epoch.

The distortion assesses the quality of a self-organizing map. It measures the loss of information over
the learning process.
In other words, it indicates how good a reconstruction of an input will be
after the mapping of all inputs to a lower-dimensional neural map. In a sense, distortion measures
how well a SOM algorithm “compresses” the input data with respect to the neighborhood structure.
Mathematically, the distortion is computed according to its discrete approximation

D =

1
n

n
∑
i=1

minj∈{1,...,k}∣si(p) − wj

f (t

∗

2,

)∣

(16)

where n is the number of samples we use during the training of the self-organizing map.

Distortion is essentially an indicator of the map convergence, but it is not a reliable tool for assessing
its quality. To gauge the quality of the map, we use the δx − δy representation [7]. It shows when a
map preserves the topology of the input space and hence how well a topographic map is formed. In
order to estimate the δx − δy, we compute all the pairwise distances between the feed-forward weights,
) − wj
δx = δx(i, j) = ∣wi
)∣, and all the distances between the nodes of the uniform discretization
2, δy(i, j) = ∣yi − yj∣, for each i, j = 1, . . . , k, where yi are the discrete nodes of
of the input space [0, 1]
Ωd. We plot the δx − δy (i.e., δx is the ordinate and δy the abscissa) along with a straight line, named
Lδx−δy, that crosses the origin and the mean of δx points. If the point cloud representation of δx − δy
closely follows the line Lδx−δy then the map is considered well-formed and preserves the topology of
the input space.

∗
f (t

f (t

∗

In order to quantify the δx − δy representation through a scalar performance index, we perform a linear
regression on the point cloud of δx − δy without ﬁtting the intercept (magenta line in ﬁgures) and we
i=1(ai − bi)2, where ai ∈ Lδx−δy, and
get a new line named L∆. Then we deﬁne the measure P =
bi ∈ L∆. Naturally, P should approach zero as the two lines are getting closer, indicating that the
self-organizing map respects the topology of the input space and thus it is well-formed.

∑k

√

4.3 Stable case

We start by simulating the model described by Eq. (1)-(5) with the parameters given in ﬁrst line of
Table 1. With these parameters, Condition (15) is fulﬁlled (0.47 < 1) and Corollary 2 predicts that the
equilibrium is exponentially stable over each epoch. Accordingly, the model succeeds in building up a
self-organizing map as shown in panel A of Figure 2. The white discs indicate the feed-forward weights
after learning and the black dots indicate the input data points (two-dimensional rectangular uniform
distribution).

Panels B and C show the δx − δy representation and the distortion, respectively. We observe that the
δx − δy representation indicates a correlation between the feed-forward weights and the rectangular grid
points (aligned with the mean of δx–red line). This means that the self-organizing map is well-formed
and conserves the topology of the input. Moreover, the distortion declines and converges towards
0.0025 pointing out ﬁrst that the loss of information during learning is low and that the structure in
the self-organizing map is preserved. However, the boundary eﬀects (the density of points is higher
at the boundary of the map in panel A) aﬀect both the distortion (it does not converge to zero – see
panel C in Figure 2) and the δx − δy representation (it is not perfectly aligned with the red line – see
panel B in Figure 2). In spite of these boundary eﬀects, the obtained δx − δy performance indicator is
good (P = 0.01).

∗ = (0.25, 0.25),
The evolution of the norm-2 of feed-forward weights of three randomly chosen units (r
(0.1, 0.225), (0.35, 0.075)) is shown in the panel D of Figure 2. This implies that the weights converge
to an equilibrium after a transient period of about 2000 epochs. The oscillations around the equilibrium
are due to a repeated alteration of the input stimulus which causes a shift to the feed-forward weights
values of each winner neuron (see [8] for more details).

8

Figure 2: Two-dimensional SOM performance in the stable case. A Feed-forward weights (white
discs) as they have been organized into a topographic map after 7000 epochs. The input in this
case is a two-dimensional rectangular uniform distribution (black dots). B δx − δy representation
(black cloud), mean of δx (red line), and the linear regression of the δx − δy representation (magenta
line). The fact that the cloud is aligned around the red line indicates that the topographic map
is well-organized, as conﬁrmed by a good index performance P = 0.01. C Distortion indicates that
the loss of information during the learning process decreases and the mapping of the input data
to a two-dimensional self-organizing map respects the structure of the neighborhoods. D Temporal
∗ = (0.25, 0.25), (0.1, 0.225),
evolution of norm-2 of feed-forward weights of three neurons placed at r
and (0.35, 0.075)). Condition (15) is fulﬁlled and therefore the weights converge to an equilibrium
giving rise to a well-formed topographic map.

9

A01020y0.00.20.40.60.81.01.2xB= 0.01035007000Epochs0.00.00250.0050.00750.010.01250.0150.01750.02DistortionC035007000Epochs0.00.20.40.60.81.0wf(r\*,t)Dr\*=(0.25, 0.25)r\*=(0.1, 0.225)r\*=(0.35, 0.075)243

244

245

246

247

248

249

250

251

252

253

254

255

256

257

258

259

260

261

262

263

264

265

266

267

268

269

270

271

272

273

274

275

276

277

278

279

280

281

282

283

284

285

286

287

288

289

4.4 Unstable case

The second line of Table 1 provides parameters for which Condition (15) is violated (5.25 > 1).
According to our theoretical predictions, the model might not be stable and thus may not be able to
develop any self-organizing map at all. In order to make sure that this is the case (and not merely a
transient eﬀect), we have let the training take more epochs (20 000). Nevertheless, we present here only
the 7 000 ﬁrst epochs for consistency with the rest of our experiments. This situation is illustrated in
Figure 3, where the self-organizing process has failed to generate a well-formed map (panel A). In this
case it is apparent that self-organization process has failed to generate a topographic map.

The δx − δy representation in panel B of Figure 3 looks like a diﬀused cloud, indicating that there is no
correlation between the grid points and the feed-forward weights meaning that there is no preservation
of the topology of the input space. Accordingly the performance index reaches the value P = 0.41, thus
higher than the stable case. Moreover, the distortion in panel C of Figure 3 oscillates without converging
to an equilibrium pointing out that the loss of information remains high and therefore the mapping is
∗ = (0.25, 0.25), (0.1, 0.225),
not successful. Finally, the norm-2 of feed-forward weights of three units (r
(0.35, 0.075)) are shown in panel D: it is apparent that they do not converge to an equilibrium. Instead
they oscillate violently and they never stabilize around an equilibrium conﬁguration.

4.5 Numerical Assessment of Corollary 2

Finally, we numerically tested Condition (15) of Corollary 2 for diﬀerent values of the parameters Ke
and Ki (all other parameters remained the same as in Table 1). For each pair (Ke, Ki) we computed
the left-hand side of Eq. (15), the distortion D (averaged over the last 10 epochs), and the δx − δy
performance index P: see Figure 4. We observe that, for high values of Ke and Ki, the stability
condition of Corollary 2 is violated (the black solid line overpasses the black dashed line). The distortion
(orange curve) closely follows the left-hand side of Condition (15) (up to a scaling factor), suggesting
that distortion can serve as a measure of stability of the system (1)-(5). Furthermore, the distortion
and the δx − δy performance index P indicate that the learning process degrades for high values of
(Ke, Ki), in line with the fact that Condition (15) is violated. Figure 5 conﬁrms this good alignment
between the theoretical stability condition and the performance of the self-organizing map: for the ﬁrst
ﬁve cases it properly maps the input space to the neural one, whereas the topology of the input space
is not preserved in the last two cases and a malformed topographic map is obtained.

5 Conclusion

In this work, we have presented theoretical conditions for the stability of a neural ﬁelds system coupled
with an Oja-like learning rule [25]. Numerical assessments on a two-dimensional self-organizing map
indicate that the theoretical condition is closely aligned with the capacity of the network to form a
coherent topographic map.

Previous works have shown through simulations that the dynamical system described by Eq. (1)-(5)
can develop topographic maps through an unsupervised self-organization process [8, 9]. The model
relies on the activity of a neural ﬁeld to drive a learning process. This type of models are capable of
developing topographic maps and reorganize them in face of several kinds of disturbances. Here, we
proceed to a rigorous theoretical analysis of such kind of models by employing neural ﬁelds Lyapunov
theory.

The obtained stability conditions are reminiscent of those obtained for general neural ﬁelds dynamics,
in which the spatial L2-norm of synaptic weights plays an essential role [10, 32, 12]. In our setting,
these conditions translate in a good balance between excitation and inhibition for the exponential
stability of the model’s equilibrium, thus allowing the self-organizing process to develop topographic
maps. It is worth stressing that the proof techniques employed here do not rely on a linearization of
the system around the considered equilibrium; it thus allows to cover activation functions that are not
diﬀerentiable (such as classical saturation or rectiﬁcation functions).

10

Figure 3: Two-dimensional SOM performance in the unstable case. A Feed-forward weights (white
discs) as they have failed to organize into a topographic map after 7000 epochs. The input in this case
is a two-dimensional rectangular uniform distribution (black dots). B δx − δy representation (black
cloud), mean of δx (red line), and the linear regression of the δx − δy representation (magenta line).
The fact that the cloud looks diﬀused indicates that the topographic map is not well-organized, as
conﬁrmed by a high value of P = 0.41. C Distortion indicates that the loss of information during the
learning process never drops (converges to an equilibrium) instead it oscillates. This means that the
mapping of the input data to a two-dimensional map has failed. D Temporal evolution of norm-2 of
∗ = (0.25, 0.25), (0.1, 0.225), and (0.35, 0.075)). The
feed-forward weights of three neurons placed at r
condition (15) is violated and accordingly the weights do not converge to an equilibrium.

11

A01020y0.00.20.40.60.81.01.2xB= 0.41035007000Epochs0.00.00250.0050.00750.010.01250.0150.01750.02DistortionC035007000Epochs0.00.20.40.60.81.0wf(r\*,t)Dr\*=(0.25, 0.25)r\*=(0.1, 0.225)r\*=(0.35, 0.075)Figure 4: Numerical investigation of Corollary 2. Eight diﬀerent pairs of the parameters (Ke, Ki)
were used to investigate the conservativeness of the stability condition given by Corollary 2. We ran
eight diﬀerent simulations for 7 000 epochs keeping always the rest of the parameters same as in Table
1 and the same PRNG seed as before (7659). The black curve indicates the numerical value of the
left-hand side of (15): stability is guaranteed if it is below the black dashed line. The green curves
indicates the δx − δy performance index P. The orange curve represents the distortion D averaged
of the 10 last epochs. It is apparent that as the values of (Ke, Ki) increase the Corollary 2 becomes
violated and the self-organizing map is fails to map the input space to the neural one (see Figure 5 for
more details).

12

(0.3, 0.25)(0.4, 0.35)(0.5, 0.44)(0.7, 0.63)(0.9, 0.86)(1.0, 0.92)(2.0, 1.85)(3.0, 2.85)(Ke,Ki)0.01.02.03.04.05.0Stability ConditionStability ConditionDistortion0.00.050.10.150.20.250.30.350.40.00250.0030.00350.0040.00450.005DistortionFigure 5: Numerical Investigation of Corollary 2. For the same eight experiments as in Figure 4,
the obtained self-organizing map is provided (ﬁrst line), together with its δx − δy representation
(second line) and the evolution of the distortion (third line). The mean δx is represented as a red line,
whereas the slope of the linear regression is given as a magenta line. A: (Ke = 0.30, Ki = 0.25), B:
(Ke = 0.4, Ki = 0.35), C: (Ke = 0.5, Ki = 0.45), D: (Ke = 0.7, Ki = 0.63), E: (Ke = 0.9, Ki = 0.86), F:
(Ke = 1.0, Ki = 0.92). In line with Figure 4, a relevant map is obtained for the ﬁrst ﬁve experiments (for
which Condition (15) is fulﬁlled), whereas for the two last self-organizing maps G: (Ke = 2, Ki = 1.85),
H: (Ke = 3, Ki = 2.85) the stability condition (15) is violated. This violation results in a non-stable
neural ﬁeld equation and thus the self-organizing maps do not learn properly the representations.

13

ABCDEFGH03060y0.00.20.40.60.81.01.2x=0.02103060y=0.01803060y=0.01703060y=0.01403060y=0.01103060y=0.01103060y=0.0803060y=0.414035007000Epochs0.00.0050.010.0150.02Distortion035007000Epochs035007000Epochs035007000Epochs035007000Epochs035007000Epochs035007000Epochs035007000Epochs290

291

292

293

294

295

296

297

298

299

300

301

302

303

304

305

306

307

308

309

310

311

312

313

314

315

These stability conditions provide a means to identify the parameters set within which the unsupervised
learning works eﬃciently, and thus provides an indication on how to tune them in practice. In particular,
they can be used to further investigate how the dynamics of an underlying system aﬀects the learning
process during an unsupervised training process and what is the eﬀect of the parameters on the ﬁnal
topographic map: as Figure 4 indicates, the parameters of the model directly aﬀect the quality of
the topographic map. However, a limitation of the present work is that it does not oﬀer a way to
choose the parameters in an optimal way. Furthermore, although the conditions provided by Theorem 1
guarantee stability of the neural ﬁeld, they do not predict the quality of the obtained map: stability
ensures that the learning will converge to an equilibrium, but the quality of the obtained map strongly
depends on the structure of this equilibrium, hence on the chosen initial values of the feed-forward
weights. This is a well-known problem with self-organizing maps [19] that is generally solved using
a decreasing neighborhood, starting from a very wide one. In our case, the neighborhood function
is directly correlated with the proﬁle of the ﬁeld activity and is ﬁxed (stereotyped). We thus cannot
always ensure the proper unfolding of the map. It is to be noted that when the neighborhood of a
Kohonen is kept ﬁxed, it suﬀers from similar problems. Nevertheless, the numerical assessment of the
proposed theoretical stability conditions suggest that the stability condition accurately predicts the
emergence of topographic maps through unsupervised learning: see Figures 4 and 5.

Other works have studied stability conditions for Kohonen maps and vector quantization algorithms,
using methods from linear systems stability theory [31] or through energy functions [?]. However, these
works focus on the learning rule for the Kohonen self-organizing maps [20] and the dynamics are not
explicitly given by dynamical systems. Our work goes beyond by taking into account not only the
learning dynamics, but also the neural dynamics that drives the self-organizing process.

Last but not least, it has been shown that neural adaptation is crucial in the development of the
neocortex [22] and neurons tend to adapt their input/output relation according to the statistics of the
input stimuli. Our theoretical results provide conditions under which this input/output adaptation
successfully takes place at least at a computational level.

316

6 Proof of the theoretical results

317

6.1 Proof of Theorem 1

In order to place the equilibrium at the origin, we employ the following change of variables:

∗
˜u(r, t) = u(r, t) − u
˜wf (r, t) = wf (r, t) − w

(r)
∗
f (r),

∗
where u
(6) can be written as

and w

∗
f denote the equilibrium patters of Eq. (6), as deﬁned in Eq. (7). Then, the system

τ

∂ ˜u
∂t (r, t) = −˜u(r, t) + ∫
∂ ˜wf
∂t (r, t) = −γ ˜wf (r, t) ∫

Ω

we(r, r

′

) ˜fe(˜u(r

′

, t))dr

′

.

Ω

wl(r, r

′

′

) ˜fl(r

, ˜u(r

′

, t))dr

′ + ˜fs( ˜wf (r, t))

(17a)

(17b)

where, for all x ∈ R and all r ∈ Ω,

∗
˜fl(r, x) = fl(x + u

∗
(r)) − fl(u

(r))

˜fs(x) = fs(x) − fs(0)
(r)).

∗
˜fe(r, x) = fe(x + u

318

319

320

With this notation, it holds that ˜fl(r, 0) = ˜fs(0) = 0 for all r ∈ Ω, meaning that (17) owns an
equilibrium at zero. The stability properties of the origin of (17) thus determines those of the equilibria
of (6).

14

321

322

323

324

325

326

First observe that, since we is a bounded function and Ω is compact, there exists ¯ωe > 0 such that

we(r, r

′

2dr
)

′ ≤ ¯w2

e , ∀r ∈ Ω.

∫

Ω

(18)

In order to assess the stability of (17), one may be tempted to rely on linearization techniques.
Nevertheless, the linearized system (17) around the origin would necessarily involve the derivative of
fs at zero, which may be undeﬁned if fs is not diﬀerentiable at zero (which is the case for the system
of interest (1)-(5) where fs involves an absolute value). Consequently, the proof we propose here relies
on Lyapunov methods [17] that were extended to neural ﬁelds in [10].

Consider the following Lyapunov functional:

V (t) ∶=

τ
2

∫

Ω

˜u(r, t)

2dr + ρ
2γ

∫

Ω

˜wf (r, t)

2dr,

(19)

where ρ > 0 denotes a parameter whose value will be decided later. First observe that the following
bounds hold at all t ≥ 0:

α (∥˜u(⋅, t)∥

2 + ∥ ˜wf (⋅, t)∥

2

) ≤ V (t) ≤ α (∥˜u(⋅, t)∥

2 + ∥ ˜wf (⋅, t)∥

2

) ,

(20)

where α ∶= 1
2
(6) reads

min{τ ; ρ/γ} > 0 and α ∶= 1
2

max{τ ; ρ/γ} > 0. The derivative of V along the solutions of

˙V (t) = τ ∫

˜u(r, t)

Ω

∂ ˜u(r, t)
∂t

dr + ρ
γ

∫

Ω

˜wf (r, t)

∂ ˜wf (r, t)
∂t

dr

= ∫

Ω

˜u(r, t) [−˜u(r, t) + ∫

Ω

wl(r, r

′

′

) ˜fl(r

, ˜u(r

′

, t))dr

′ + ˜fs( ˜wf (r, t))] dr

− ρ ∫

Ω

[ ˜wf (r, t)

2 ∫

Ω

we(r, r

′

′

) ˜fe(r

, ˜u(r

′

, t))dr

′

] dr.

(21)

Moreover, denoting by (cid:96)s, (cid:96)e and (cid:96)l the Lipschitz constants of fs, fe and fl respectively, it holds that,
for all x ∈ R and all r ∈ Ω.

∣ ˜fl(r, x)∣ ≤ (cid:96)l∣x∣
∣ ˜fs(x)∣ ≤ (cid:96)s∣x∣
∣ ˜fe(r, x) − ˜fe(r, 0)∣ ≤ (cid:96)e∣x∣.

(22)

(23)

(24)

Applying the Cauchy-Schwarz inequality and using Eq. (22), it follows that

wl(r, r

′

′

) ˜fl(r

, ˜u(r

′

, t))dr

∫

Ω

′ ≤ ∫

∣wl(r, r

′

′

)∣ ∣ ˜fl(r

, ˜u(r

′

, t))∣dr

′

Ω
≤ (cid:96)l ∫
Ω
√

′

∣wl(r, r

′

)∣ ∣˜u(r

′

, t)∣dr
√

Hence, using again Cauchy-Schwarz inequality,

≤ (cid:96)l

∫

Ω

wl(r, r′

)2dr′

˜u(r′, t)2dr′.

∫

Ω

˜u(r, t) [∫

∫

Ω

Ω

wl(r, r

∣˜u(r, t)∣

≤ (cid:96)l ∫

Ω
√

⎡⎢⎢⎢⎢⎢⎢⎢⎣

′

) ˜fl(r
√

′

′

, ˜u(r

, t))dr

′

] dr
√

wl(r, r′

)2dr′

˜u(r′, t)2dr′

∫

Ω

∫

Ω
√

dr

⎤⎥⎥⎥⎥⎥⎥⎥⎦

≤ (cid:96)l

˜u(r, t)2dr

∫

Ω

[∫

∫

Ω

Ω

wl(r, r′

)2dr′ ∫

Ω

˜u(r′, t)2dr′

] dr.

15

Observing that ∫

Ω ˜u(r

′

′

2dr

, t)

is independent of r and deﬁning

√

¯wl ∶=

∫

∫

Ω

Ω

wl(r, r′

)2dr′dr,

it follows that

˜u(r, t) [∫

∫

Ω

Ω

wl(r, r

′

′

) ˜fl(r

, ˜u(r

′

, t))dr

′

] dr ≤ (cid:96)l ¯wl ∫

˜u(r, t)

2dr.

Ω

Furthermore, using Eq. (23), we have that

(25)

(26)

∫

Ω

˜u(r, t) ˜fs(wf (r, t))dr ≤ (cid:96)s ∫
Ω
√

∣˜u(r, t)∣ ∣wf (r, t)∣dr

√

≤ (cid:96)s

˜u(r, t)2dr

∫

Ω

∫

Ω

wf (r, t)2dr

Invoking the inequality 2ab ≤ (a2

/λ + λb2

) for all a, b ∈ R and all λ > 0, we obtain that

˜u(r, t) ˜fs( ˜wf (r, t))dr ≤

∫

Ω

(cid:96)s
2 (λ ∫

Ω

˜u(r, t)

2dr + 1
λ

∫

Ω

˜wf (r, t)

2dr) ,

(27)

327

for any λ > 0.

Now, assumption (10) ensures that inf r∈Ω ∫
such that

Ω we(r, r

′

′

) ˜fe(r

, 0)dr

′ > 0. It follows that there exists c > 0

we(r, r

′

′

) ˜fe(r

, 0)dr

′ ≥ 2c, ∀r ∈ Ω.

∫

Ω

Consequently, using (24) and Cauchy-Schwarz inequality, we get that, for any v ∈ L2(Ω, R),

we(r, r

′

′

) ˜fe(r

, v(r

′

))dr

∫

Ω

′ = ∫

Ω
≥ 2c − ∫

we(r, r
(cid:187)(cid:187)(cid:187)(cid:187)(cid:187)
Ω
≥ 2c − (cid:96)e ∫
Ω
√

′ + ∫

′

′

′

) ˜fe(r

, 0)dr
(cid:187)(cid:187)(cid:187)(cid:187)(cid:187)
(cid:187)(cid:187)(cid:187)(cid:187)(cid:187)
˜fe(r
(cid:187)(cid:187)(cid:187)(cid:187)(cid:187)
(cid:187)(cid:187)(cid:187)(cid:187)(cid:187)
we(r, r

we(r, r
(cid:187)(cid:187)(cid:187)(cid:187)(cid:187)

)

)

′

′

v(r

, v(r
(cid:187)(cid:187)(cid:187)(cid:187)(cid:187)

)
√

′

′

dr

′

we(r, r

Ω

′

)) − ˜fe(r

′

) ( ˜fe(r
(cid:187)(cid:187)(cid:187)(cid:187)(cid:187)
, 0)

′

, v(r

′

)) − ˜fe(r

′

, 0)) dr

′

′

dr

≥ 2c − (cid:96)e

we(r, r′

)2dr′

∫

Ω

v(r′

)2dr′

∫

Ω

≥ 2c − (cid:96)e ¯we∥v∥,

where the last bound comes from (18). Let Bε denote the ball (in L2-norm) of radius ε > 0, that is:
Bε ∶= {v ∈ L2(Ω, R) ∶ ∥v∥ < ε}. Letting ε ∶= c/(cid:96)e ¯we, we conclude from the above expression that

we(r, r

′

′

) ˜fe(r

, v(r

′

))dr

′ ≥ c, ∀r ∈ Ω, ∀v ∈ Bε.

∫

Ω

(28)

Consider an initial condition such that ˜u(⋅, 0) ∈ Bε and let T ∈ [0, +∞] denote the time needed for
˜u(⋅, t) to leave Bε. Then it holds by deﬁnition that ˜u(⋅, t) ∈ Bε for all t ∈ [0, T ) and ˜u(⋅, T ) ∉ Bε if T
is ﬁnite. Note that, by continuity of solutions, T > 0. Moreover, in view of (28),

we(r, r

′

′

) ˜fe(r

, ˜u(r

′

, t))dr

′ ≥ c, ∀t ∈ [0, T ), ∀r ∈ Ω.

(29)

∫

Ω

Combining Eq.(21), (22), (23), and (29), we obtain that, for all t ∈ [0, T ),

˙V (t) ≤ − (1 − (cid:96)l ¯wl − λ(cid:96)s

2 ) ∫

˜u(r, t)

2dr − (ρc − (cid:96)s
2λ

) ∫

Ω

Ω

˜wf (r, t)

2dr

16

Pick λ = (1 − (cid:96)l ¯wl)/(cid:96)s. Note that λ > 0 since (cid:96)l ¯wl < 1 by assumption (see Eq. (9)). Then the choice
ρ = (cid:96)s
cλ

> 0 leads to:

(cid:96)2
s
c(1−(cid:96)l ¯wl)

=

˙V (t) ≤ − 1
≤ − 1
2

2 − ρc

2 ∥˜u(⋅, t)∥
min{1 ; ρc} (∥˜u(⋅, t)∥

2 ∥ ˜wf (⋅, t)∥

2

2 + ∥ ˜wf (⋅, t)∥

2

) .

Using (20) and letting α ∶= 1
2α

min{1 ; ρc} > 0, we ﬁnally obtain that

Integrating, this gives V (t) ≤ V (0)e

˙V (t) ≤ −αV (t), ∀t ∈ [0, T ).
−αt for all t ∈ [0, T ), which yields, using (20),

∥˜u(⋅, t)∥

2 + ∥ ˜wf (⋅, t)∥

2 ≤

α
α (∥˜u(⋅, 0)∥

2 + ∥ ˜wf (⋅, 0)∥

2

−αt, ∀t ∈ [0, T ).

) e

(30)

, then ∥˜u(⋅, t)∥ + ∥ ˜wf (⋅, t)∥ < ε
Thus, if initial conditions are picked within the L2-ball of radius
at all times t ≥ 0. This means that, for these initial conditions, solutions never leave the ball Bε, hence
T = +∞. Eq. (30) thus ensures exponential stability on this set of initial conditions.

√α
√
α
ε

6.2 Proof of Corollary 1

Assumption described by Eq. (13) is equivalent to requiring ¯wl < 1, with ¯wl deﬁned in Eq. (25). Since
the Lipschitz constant of the rectiﬁcation is (cid:96)l = 1, this makes Eq. (9) fulﬁlled.
∗
Moreover, we claim that the solution u
∗
of Ω with non-zero measure. To see this, assume on contrary that u
∗
it holds that rect(u

of the implicit Eq. (12) is necessarily positive on some subset
(r) ≤ 0 for almost all r ∈ Ω. Then

(r)) = 0 for almost all r ∈ Ω, which implies that

328

329

330

331

332

333

wl(r, r

′

∗
)rect(u

(r

′

))dr

′ = 0, ∀r ∈ Ω.

∫

Ω

∗
In view of Eq. (12), this implies that u
∗
Consequently, as claimed, u
Recalling that Ω is here assumed to be a compact set, it follows that

is necessarily positive on some subset Ω

(r) = 1 for all r ∈ Ω, thus leading to a contradiction.
+
of Ω with non-zero measure.

∫

inf
r∈Ω

Ω

e

−∣r−r

′

2
∣

/2σ2

∗
e rect(u

(r))dr ≥ inf
r∈Ω

∫

e

Ω+

−∣r−r

′

2
∣

/2σ2

∗
e u

(r)dr > 0,

334

which makes Eq. (10) satisﬁed. The conclusion then follows from Theorem 1.

335

6.3 Proof of Corollary 2

The following one-dimensional relation holds:

∫

b

a

b

∫
a

e

2

− ∣x−y∣

2σ2 dxdy =

√

ξa,b(σ).

(31)

In order to compute its two-dimensional counterpart, let r = (r1, r2) and r
Ω = [a, b] × [a, b],

′ = (r

′
1, r

′
2). Then, for

∫

∫

Ω

Ω

− ∣r−r
e

′
2
∣
2σ2 dr

′

dr = ∫

b

b

∫

∫

b

∫

b

a

a

a

a

Using Fubini’s theorem, it follows that

′
exp (− (r1 − r
1)

2 + (r2 − r
2σ2

′
2
2)

) dr

′
1dr

′
2dr1dr2.

− ∣r−r

′
2
∣
2σ2 dr

′

e

dr

∫

∫

Ω

Ω

= ∫

b

b

∫

a

a

′
2
exp (− (r1 − r
1)
2σ2

) (∫

b

b

∫

a

a

′
2
exp (− (r2 − r
2)
2σ2

) dr2dr

′
′
2) dr1dr
1

17

From Eq. (31), this gives:

∫

∫

Ω

Ω

− ∣r−r
e

′
2
∣
2σ2 dr

′

dr = ∫

b

b

∫

′
2
exp (− (r1 − r
1)
2σ2

√

′
ξa,b(σ)dr1dr
1

)

a

a
= ξa,b(σ).

The left-hand term of Eq. (13) then reads:

∫

∫

Ω

Ω

(Kee

′

2

− ∣r−r
∣
2σ2

e − Kie

2

′

2

− ∣r−r
∣
2σ2
i )

′

dr

dr = ∫

∫

Ω

Ω

′

2

∣

− ∣r−r
e + K2
σ2
i e

∣

− ∣r−r
σ2
i − 2KeKie

′

2

⎛
K2
e e
⎜
⎝

(32)

′

dr

dr

⎞
⎟
⎠

− ∣r−r
√
2

′

2

σeσi
∣
e +σ2
σ2
i

= K2

e ξa,b(σe/

√
2) + K2

i ξa,b(σi/

2) − 2KeKiξa,b

√

⎛
⎜
⎝

√

σeσi
e + σ2
σ2
i

⎞
⎟
⎠

,

336

which concludes the proof.

337

338

339

PRNG Seed

We ran both the stable and non-stable experiments ten times with diﬀerent PRNG seeds. All the
PRNG seeds we used are: 10, 74, 433, 721, 977, 1330, 3433, 5677, 9127, 7659.

340

Acknowledgments

341

Not applicable.

342

Funding

343

This work was partially funded by grant ANR-17-CE24-0036.

344

345

346

347

348

349

350

351

352

Abbreviations

SOM Self-organizing Map

DSOM Dynamic Self-organizing Map

FFT Fast Fourier Transform

PRNG Pseudo Random Number Generator

Availability of data and materials

The source code used in this work for running the simulations, analysing the results and plotting the
ﬁgures, is freely distributed under the GPL-3 License and can be found here: https://github.com/
gdetor/som\_stability.

353

Ethics approval and consent to participate

354

Not applicable.

355

356

357

Competing interests

All three authors declare that the research was conducted in the absence of any commercial or ﬁnancial
relationships that could be construed as a potential conﬂict of interest.

18

358

Consent for publication

359

Not applicable.

360

361

362

363

364

365

366

367

368

369

370

371

372

373

374

375

376

377

378

379

380

381

382

383

384

385

386

387

388

389

390

391

392

393

394

395

396

397

398

Author’s contributions

GID conceived the idea, wrote the code, designed and ran the numerical experiments, AC performed
the mathematical derivation and analysis. GID, AC, and NPR contributed to preparing, writing, and
revising the manuscript.

References

[1] Larry F Abbott and Sacha B Nelson. Synaptic plasticity: taming the beast. Nature neuroscience,

3:1178–1183, 2000.

[2] M. Abramowitz and I.A. Stegun. Handbook of Mathematical Functions with Formula, Graphs and

Mathematical Tables. Dover Publications, 1983.

[3] S. Amari. Dynamics of pattern formation in lateral-inhibition type neural ﬁelds. Biological

cybernetics, 27(2):77–87, 1977.

[4] Paul C Bressloﬀ. Spatiotemporal dynamics of continuum neural ﬁelds. Journal of Physics A:

Mathematical and Theoretical, 45(3):033001, 2012.

[5] S. Coombes. Waves, bumps, and patterns in neural ﬁeld theories. Biological Cybernetics, 93(2):91–

108, 2005.

[6] Thomas M Cover and Joy A Thomas. Elements of information theory. John Wiley & Sons, 2012.

[7] Pierre Demartines. Organization measures and representations of kohonen maps. In First IFIP

Working Group, volume 10. Citeseer, 1992.

[8] Georgios Is Detorakis and Nicolas P Rougier. A neural ﬁeld model of the somatosensory cortex:
formation, maintenance and reorganization of ordered topographic maps. PloS one, 7(7):e40257,
2012.

[9] Georgios Is Detorakis and Nicolas P Rougier. Structure of receptive ﬁelds in a computational
model of area 3b of primary sensory cortex. Frontiers in Computational Neuroscience, 8(76), 2014.

[10] Olivier Faugeras, Fran¸cois Grimbert, and Jean-Jacques Slotine. Absolute stability and complete
synchronization in a class of neural ﬁelds models. SIAM Journal on Applied Mathematics,
69(1):205–250, 2008.

[11] Olivier Faugeras, Romain Veltz, and Fran¸cois Grimbert. Persistent neural states: stationary
localized activity patterns in nonlinear continuous n-population, q-dimensional neural networks.
Neural computation, 21(1):147–187, 2009.

[12] Mathieu N Galtier, Olivier D Faugeras, and Paul C Bressloﬀ. Hebbian learning of recurrent

connections: a geometrical perspective. Neural computation, 24(9):2346–2383, 2012.

[13] Kamil A Grajski and Michael Merzenich. Neural network simulation of somatosensory rep-
In Advances in neural information processing systems, pages 52–59,

resentational plasticity.
1990.

[14] Stephen Grossberg. Physiological interpretation of the self-organizing map algorithm. 1994.

[15] Donald Olding Hebb. The organization of behavior: A neuropsychological theory. Psychology

Press, 2002.

[16] Samuel Kaski, Jari Kangas, and Teuvo Kohonen. Bibliography of self-organizing map (som)

papers: 1981–1997. Neural computing surveys, 1(3&4):1–176, 1998.

19

399

400

401

402

403

404

405

406

407

408

409

410

411

412

413

414

415

416

417

418

419

420

421

422

423

424

425

426

427

428

429

430

431

432

433

434

435

436

437

438

439

440

441

[17] H. Khalil. Nonlinear systems. Macmillan Publishing Co., 2nd ed., New York, 1996.

[18] Robert T Knight, W Richard Staines, Diane Swick, and Linda L Chao. Prefrontal cortex regulates
inhibition and excitation in distributed neural networks. Acta psychologica, 101(2):159–178, 1999.

[19] Teuvo Kohonen. Self-organized formation of topologically correct feature maps. Biological

cybernetics, 43(1):59–69, 1982.

[20] Teuvo Kohonen. Self-organizing maps, volume 30. Springer, 2001.

[21] Leah A Krubitzer and Jon H Kaas. The organization and connections of somatosensory cortex in

marmosets. The Journal of Neuroscience, 10(3):952–974, 1990.

[22] Rebecca A Mease, Michael Famulare, Julijana Gjorgjieva, William J Moody, and Adrienne L
Fairhall. Emergence of adaptive computation by single neurons in the developing cortex. The
Journal of Neuroscience, 33(30):12154–12170, 2013.

[23] Risto Miikkulainen, James A Bednar, Yoonsuck Choe, and Joseph Sirosh. Computational maps in

the visual cortex. Springer Science & Business Media, 2006.

[24] Nasser M Nasrabadi and Yushu Feng. Vector quantization of images based upon the kohonen
self-organizing feature maps. In Proc. IEEE Int. Conf. Neural Networks, volume 1, pages 101–105,
1988.

[25] Erkki Oja. Simpliﬁed neuron model as a principal component analyzer. Journal of mathematical

biology, 15(3):267–273, 1982.

[26] Merja Oja, Samuel Kaski, and Teuvo Kohonen. Bibliography of self-organizing map (som) papers:

1998-2001 addendum. Neural computing surveys, 3(1):1–156, 2003.

[27] HX Qi, TM Preuss, and JH Kaas. Somatosensory areas of the cerebral cortex: architectonic

characteristics and modular organization. The senses: A comprehensive reference, 6:143, 2008.

[28] Nicolas Rougier and Yann Boniface. Dynamic self-organising map. Neurocomputing, 74(11):1840–

1847, 2011.

[29] Michael Schaefer, Hans-Jochen Heinze, and Michael Rotte. Task-relevant modulation of primary
somatosensory cortex suggests a prefrontal–cortical sensory gating system. Neuroimage, 27(1):130–
135, 2005.

[30] Joseph Sirosh and Risto Miikkulainen. Ocular dominance and patterned lateral connections in a
self-organizing model of the primary visual cortex. Advances in Neural Information Processing
Systems, pages 109–116, 1995.

[31] Mauro Tucci and Marco Raugi. Stability analysis of self-organizing maps and vector quantization
algorithms. In The 2010 International Joint Conference on Neural Networks (IJCNN), pages 1–5.
IEEE, 2010.

[32] Romain Veltz and Olivier Faugeras. Local/global analysis of the stationary solutions of some
neural ﬁeld equations. SIAM Journal on Applied Dynamical Systems, 9(3):954–998, 2010.

[33] Stuart P Wilson, Judith S Law, Ben Mitchinson, Tony J Prescott, and James A Bednar. Modeling
the emergence of whisker direction maps in rat barrel cortex. PloS one, 5(1):e8778, 2010.

[34] Jing Xing and George L Gerstein. Networks with lateral connectivity. i. dynamic properties
mediated by the balance of intrinsic excitation and inhibition. Journal of neurophysiology,
75(1):184–199, 1996.

[35] Jing Xing and George L Gerstein. Networks with lateral connectivity. ii. development of neuronal
grouping and corresponding receptive ﬁeld changes. Journal of neurophysiology, 75(1):200–216,
1996.

20

442

443

444

445

[36] Jing Xing and George L Gerstein. Networks with lateral connectivity. iii. plasticity and reorgani-

zation of somatosensory cortex. Journal of neurophysiology, 75(1):217–232, 1996.

[37] Hujun Yin. Learning nonlinear principal manifolds by self-organising maps. In Principal manifolds

for data visualization and dimension reduction, pages 68–95. Springer, 2008.

21

