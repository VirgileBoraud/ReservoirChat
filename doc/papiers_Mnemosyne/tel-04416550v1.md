Temporal dynamics in the neural representation of
sensorimotor tasks : investigation of the song-timing
network in birds.
Fjola Hyseni

To cite this version:

investigation
Fjola Hyseni. Temporal dynamics in the neural representation of sensorimotor tasks :
of the song-timing network in birds.. Other [cs.OH]. Université de Bordeaux, 2023. English. ￿NNT :
2023BORD0351￿. ￿tel-04416550￿

HAL Id: tel-04416550

https://theses.hal.science/tel-04416550

Submitted on 25 Jan 2024

HAL is a multi-disciplinary open access
archive for the deposit and dissemination of sci-
entific research documents, whether they are pub-
lished or not. The documents may come from
teaching and research institutions in France or
abroad, or from public or private research centers.

L’archive ouverte pluridisciplinaire HAL, est
destinée au dépôt et à la diffusion de documents
scientifiques de niveau recherche, publiés ou non,
émanant des établissements d’enseignement et de
recherche français ou étrangers, des laboratoires
publics ou privés.

THÈSE PRÉSENTÉE

POUR OBTENIR LE GRADE DE

DOCTEUR DE
L’UNIVERSITÉ DE BORDEAUX

ÉCOLE DOCTORALE MATHEMATIQUES ET INFORMATIQUE

SPÉCIALITÉ : Informatique

Par Fjola Hyseni

Dynamique temporelle dans la représentation neuronale des tâches

sensorimotrices : étude du réseau de contrôle du chant chez les oiseaux.

Sous la direction de : Nicolas P. ROUGIER
Co-directeur : Arthur LEBLOIS

Soutenue le 1er Décembre 2023

Membres du jury :
Mme. Adrienne FAIRHALL Professeur
M. Albert COMPTE
Professor
Mme. Daniela VALLENTIN Chargée de recherche MPI, Seewiesen
M. Hervé ROUAULT
M. Alexander PITTI
M. Arthur LEBLOIS
M. Nicolas P. ROUGIER

Université Aix Marseille
Chargé de recherche
CY Cergy-Paris Université
Professeur
Chargé de recherche
Université de Bordeaux
Directeur de recherche Université de Bordeaux

University of Washington
IDIBAPS

Rapporteure
Rapporteur
Examinatrice
Examinateur
Examinateur
Co-directeur de these
Directeur de these

Temporal dynamics in the neural representation of sensorimotor tasks: inves-

tigation of the song-timing network in songbirds.

Abstract:
Temporally precise movement patterns underlie many motor skills, yet the origin
of temporal control in motor behaviors remains unclear. The zebra finch song
system has shown to be an outstanding model to study temporal control and se-
quential neuronal activity in the order of tens to hundreds of milliseconds. Like
human speech, birdsong relies on a tight muscle coordination, with its premotor
nucleus, HVC, responsible for the precise control of song tempo. Current compu-
tational models of HVC rely on the synfire chain, a purely feedforward network
model that can account for HVC sequential activity. Synfire chains are however
not robust to noise and function for a narrow range of feedforward weights, thus
requiring fine tuning during learning. On the contrary, attractor dynamics pro-
vide networks with robust functional properties that make them an alternative to
feedforward models. Therefore, we propose that HVC neuronal dynamics may
be modelled using a Ring Attractor with a narrow Gaussian connectivity profile,
where recurrent connections allow the formation of an activity bump that remains
stable across a wide range of weights.In the case of asymmetrical connectivity,
the bump of activity moves across the network, generating sequential neuronal
activity. We show that the width of the activity bump, and thus the duration
of transient neuronal activation, can be decreased to reproduce the brief activity
bursts of HVC neurons. Additionally, we reproduce a syllable duration plasticity
experiment by implementing a reward covariance reinforcement learning rule in
the network. Consistent with behavioral results, the change in duration is specific
to the target syllable. Lastly, we investigate further with an EI network model
of spiking neurons and show that with a more biologically plausible and precise
model, we are able not only to reproduce HVC’s fast spiking dynamics, but also
perform with specificity a behavioral learning paradigm to modify syllable du-
ration. These findings are confronted with behavioral results of daily duration
changes in birds underdoing a Conditional Auditory Feedback protocol to adap-
tively change syllable duration.

Keywords: Timing, Songbirds, HVC, Ring Attractor, AdEx

3

Dynamique temporelle dans la représentation neuronale des tâches sensori-

motrices : étude du réseau de contrôle du chant chez les oiseaux.

Résumé:
La précision temporelle des mouvements est à la base de nombreuses tâches motri-
ces et actions innées, mais l’origine du contrôle temporel dans les comportements
moteurs n’est toujours pas claire. Le système de chant du diamant mandarin
s’est révélé être un excellent modèle pour étudier le contrôle temporel et l’activité
neuronale séquentielle sur des durées de quelques dizaines à quelques centaines
de millisecondes. Comme la parole humaine, le chant des oiseaux repose sur
une coordination musculaire précise, le noyau prémoteur, HVC, étant respons-
able du contrôle du tempo du chant. Les modèles théoriques actuels de HVC
reposent sur la chaîne de propagation de synchronie (’synfire chains’), un modèle
de réseau purement feedforward qui peut rendre compte de l’activité séquentielle
dans HVC. Cependant, les chaînes de propagation de synchronie ne sont pas ro-
bustes au bruit et fonctionnent pour une gamme étroite de poids synaptiques,
et nécessitent donc un réglage fin pendant l’apprentissage. A l’inverse, la dy-
namique d’attracteurs confère aux réseaux des propriétés fonctionnelles robustes
qui en font une alternative aux modèles de type "feedforward". Par conséquent,
nous proposons que la dynamique neuronale de la HVC puisse être modélisée
à l’aide d’un attracteur en anneau avec un profil de connectivité gaussien étroit,
où les connexions récurrentes permettent la formation d’une bosse d’activité qui
reste stable à travers une large gamme de poids. Dans le cas d’une connectivité
asymétrique, la bosse d’activité se déplace à travers le réseau, générant une activ-
ité neuronale séquentielle. Nous montrons que la largeur de la bosse d’activité,
et donc la durée de l’activation neuronale transitoire, peut être réduite pour re-
produire les brèves bouffées d’activité observées dans les neurones de HVC. En
outre, nous reproduisons une expérience de plasticité de la durée des syllabes
en implémentant une règle d’apprentissage par renforcement dite ’de covariance’
dans le réseau. Conformément aux résultats comportementaux, le changement de
durée est spécifique à la syllabe cible. Enfin, nous poursuivons nos recherches
avec un modèle de réseau Excitateur-Inhibiteur de neurones à potentiels d’action
et montrons qu’avec un modèle plus plausible et plus précis sur le plan biologique,
nous sommes capables non seulement de reproduire la dynamique neuronale de
HVC, mais aussi d’expliquer les modifications de la durée des syllabes observées
dans un paradigme d’apprentissage comportemental. Ces résultats sont confron-
tés aux résultats comportementaux des changements quotidiens de durée chez les
oiseaux soumis à un protocole de rétroaction auditive conditionnelle pour modi-
fier de manière adaptative la durée des syllabes.

Mots-clés: Timing, Oiseaux Chanteurs, HVC, Ring Attractor, AdEx

4

Résumé:

Dans ce manuscrit, nous visons à étudier l’organisation temporelle du contrôle
moteur à une échelle inférieure à la seconde dans le modèle animal des oiseaux
chanteurs à l’aide de la modélisation computationnelle. Dans le chapitre 1, nous
présentons le concept plus large du temps dans la perception et l’action, la tax-
onomie du timing dans les neurosciences, les différentes échelles du timing et ses
substrats anatomiques/neuraux. Parmi les substrats anatomiques, nous distin-
guons le noyau prémoteur des oiseaux chanteurs comme un modèle biologique
particulièrement adapté de la synchronisation motrice à l’échelle de dizaines et de
centaines de millisecondes. Contrairement aux mécanismes sous-jacents plus com-
plexes des mammifères, les oiseaux chanteurs possèdent un ensemble spécifique
de noyaux cérébraux interconnectés, connu sous le nom de "système de chant",
responsable de l’acquisition et de l’exécution de la tâche sensorimotrice de la pro-
duction du chant. Il s’agit d’une structure plus simple à étudier, tant sur le plan
expérimental que sur le plan informatique. En outre, les processus de production
et d’apprentissage du chant des oiseaux ressemblent à ceux de la parole humaine.
C’est pourquoi, dans le chapitre 2, nous présentons tout d’abord l’anatomie et le
comportement des oiseaux chanteurs dans le contexte de la production vocale et
de l’apprentissage, ainsi que les similitudes avec les mammifères. Nous termi-
nons le chapitre en nous concentrant uniquement sur la synchronisation motrice,
sa plasticité et les noyaux impliqués dans son émergence chez l’oiseau chanteur.
Dans l’ensemble, nous pensons que les chapitres 1 et 2 ont mis en évidence la
pertinence et les avantages de l’utilisation des circuits de timing du chant chez les
oiseaux chanteurs pour modéliser le controle temporel fin des actions à l’échelle
inférieure à la seconde. Le chapitre suivant, le chapitre 3, présente un ensemble
d’hypothèses et d’approches théoriques du timing moteur inférieur à la seconde,
allant des principales classes de modèles utilisées chez différentes espèces (princi-
palement les mammifères) aux modèles spécifiquement dédiés à la simulation de
la dynamique du timing du chant chez l’oiseau. Nous essayons de positionner ces
derniers dans l’une des classes plus larges et de fournir une correspondance entre
un modèle spécifique et un modèle plus général. Enfin, nous incluons une section
sur les systèmes dynamiques et les attracteurs, en tant que classe de modèles ro-
bustes qui peuvent être proposés pour modéliser la dynamique temporelle dans
les noyaux contrôlant le timing du chant: HVC (utilisé comme un nom propre).

En bref, nous considérons que les circuits de timing du chant chez l’oiseau
chanteur sont représentatifs du timing moteur à l’échelle inférieure à la seconde.
Nous partons du principe que la dynamique observée chez l’oiseau chanteur pour-
rait permettre de mieux comprendre le contrôle temporel chez d’autres taxons, y
compris chez l’humain, en particulier parce que la tâche à accomplir, le chant des
oiseaux, est très similaire à la parole humaine. Pour étudier la timing moteur
sub-seconde, nous utilisons une approche théorique et formulons deux questions
principales:

5

• Quelle est la dynamique sous-jacente qui donne lieu au contrôle temporel

précis d’une tâche sensorimotrice apprise ?

• Quels sont les mécanismes qui permettent la flexibilité comportementale du

timing moteur ?

Le noyau prémoteur HVC a été modélisé soit comme une structure de timing
autonome, soit comme un élément d’un système distribué, d’où émerge le timing.
Dans les deux cas, l’hypothèse d’une structure de type chaîne, qui crée une généra-
tion de séquences, est avancée. Nous commençons le chapitre 5 en nous concen-
trant sur le modèle de chaîne Synfire, qui est considéré comme la norme dans la
modélisation du noyau HVC. Nous étudions tout d’abord sa flexibilité temporelle
en explorant la plage de poids synaptiques possibles qui permet la propagation de
la chaîne synaptique, puis nous explorons la robustesse du modèle au bruit dans
l’entrée et les poids synaptiques. Cette étude nous incite à rechercher un modèle
plus robuste. Idéalement, ce modèle devrait refléter la structure présumée d’une
aire corticale et de HVC, en incorporant des connexions récurrentes excitatrices
et l’inhibition. En même temps, il devrait conserver une configuration en forme
de chaîne pour tenir compte de la force d’entraînement (propagation en chaîne).
Ces caractéristiques requises évoquent le concept d’un type particulier de modèle
d’attracteur en anneau, capable de progresser à travers ses points fixes ou ses états
d’attracteur.

Nous formulons cette proposition au chapitre 5, et progressons étape par étape
pour (i) prouver que les propriétés revendiquées sont intégrées dans le mod-
èle, (ii) montrer les différents mécanismes possibles drive time, c’est-à-dire faire
en sorte que l’activité se propage dans le réseau, entraînant la génération de
séquences, et enfin (iii) montrer qu’une architecture d’attracteur en anneau peut
modéliser les caractéristiques les plus spécifiques du noyau HVC, c’est-à-dire le
caractère éparse de l’activité relative au chant et la durée des bouffées de potentiels
d’action. En outre, nous explorons cette architecture neuronale à deux niveaux
de complexité neuronale, un modèle neuronal basé sur le taux de décharge et
un modèle neuronal à potentiels d’action, ainsi que dans un réseau excitateur-
inhibiteur (EI). Cela permet de s’assurer que nos résultats ne sont pas le fruit
de l’approche simplifiée que nous suivons, mais qu’il s’agit plutôt d’une carac-
téristique qui peut être appliquée à différents modèles. Il permet également de
montrer l’importance de l’architecture dans la conduite du comportement, ce qui
est conforme à l’hypothèse d’un modèle d’horloge de population (D. V. Buonomano
and Laje, 2010).

Cependant, nous ne manquons pas de reconnaître la pertinence plus importante
d’un modèle de potentiels d’action pour simuler les spécificités de la dynamique
de HVC, c’est-à-dire le nombre de potentiels d’action par bouffée et la durée des
bouffées. La dynamique des bouffées dépend à la fois de la force synaptique et
des propriétés intrinsèques du neurone, qui sont modélisées par l’adaptation dé-
clenchée par les potentiels d’action dans un modèle de neurone adaptatif exponen-
tiel ’intègre et décharge’ (AdEx). Avec les modèles basés sur le taux de décharge et

6

AdEx, nous montrons également les résultats d’une inhibition simulée au niveau
du HVC. Cela pourrait servir de prédiction et guider les études expérimentales.

En outre, le HVC peut être seul à contribuer au timing moteur, ou il peut être
guidé par des zones cérébrales en amont : le noyau auditif NIf (nucleus interfa-
cialis of the nidopallium) et/ou le noyau thalamique Uva (nucleus uvaeformis)
(détaillé dans le chapitre 2). Alors que les études de lésion du NIf (Cardin et al.,
2005) ont révélé que le NIf n’est pas nécessaire à la production de chant chez
l’adulte, plusieurs études ont montré que l’Uva est très important dans la pro-
duction de chant (Coleman and E. T. Vu, 2005) et une étude récente a montré qu’il
pilote un ensemble particulier de neurones dans le HVC, ceux qui déchargent à
la limite des syllabes (Moll et al., 2023). Étant donné qu’il ne semble pas y avoir de
latéralisation (Long and M. S. Fee, 2008) dans la production du chant, il est probable
que l’entrée Uva ait un effet sur le timing. En tant que tel, UVA envoie une entrée
séquentielle atteignant les deux noyaux HVC (droit et gauche) à des moments dis-
tincts du chant et n’aurait aucun effet sur les séquences des bouffées, dont nous
supposons toujours qu’elles sont générées au sein de l’HVC. Un modèle testant
cette hypothèse est également ajouté à la section 5.4.

La présence d’une plasticité comportementale dans le chant des oiseaux a été
révélée initialement par des expériences de changement de hauteur et de durée
des syllabes à l’aide d’un paradigme de rétroaction auditive conditionnelle (Con-
ditional Auditory Feedback) (détaillé au chapitre 2). Au chapitre 6, nous visons
à reproduire numériquement ce paradigme comportemental pour inciter à un
changement de durée dans les deux sens, c’est-à-dire pour allonger et raccourcir
la durée de la syllabe cible, à l’aide d’une règle d’apprentissage par renforcement
de la récompense-covariance. L’une des principales caractéristiques de cette ex-
périence comportementale, qui représente un défi théorique, est le fait que seul
le segment ciblé (syllabe) est affecté. Dans une représentation numérique simpli-
fiée de ce comportement, un ensemble de neurones représente une syllabe. Dans
une architecture de chaîne synchrone, un ensemble de neurones, et plus précisé-
ment deux couches de neurones non connectés, représentent le début et la fin de
la syllabe et la mise à jour des poids ne se produit que dans les connexions en-
tre ces deux couches, ce qui fait que les neurones des deux couches sont actives
de manière plus proche dans le temps (raccourcissement de la durée) ou plus loin
dans le temps (allongement de la durée). Comme les poids entre les autres couches
ne sont pas mis à jour, il n’y a pas d’effet sur les autres syllabes/segments. Cepen-
dant, lors de l’utilisation de réseaux neuronaux connectés de manière récurrente,
une diminution de la durée peut avoir lieu de différentes manières, et un neurone
ne se projette pas uniquement vers l’avant, ce qui fait que ses autres synapses
sont également mises à jour, ce qui aurait un effet sur de multiples "ensembles"
de neurones, dont certains ne sont pas affectés au segment cible. On peut donc
observer un effet sur d’autres syllabes, désigné sous le nom d’"interférence entre
les syllabes".

Au chapitre 6, nous examinons tout d’abord si, avec l’architecture de l’attracteur
en anneau et la règle d’apprentissage choisie, un changement de durée est pos-

7

sible. Ensuite, nous vérifions comment les poids sont modifiés pour obtenir ce
changement. Nous avons d’abord émis l’hypothèse d’une modification positive
locale des poids, similaire à celle observée dans la chaîne synchrone, dans le
cas d’un raccourcissement de la durée. De plus, nous avons fait l’hypothèse
que ce changement devrait être très étroitement focalisé au niveau des neurones
pré- et postsynaptiques affiliés à la syllabe cible. De cette manière, aucun effet
sur les autres syllabes ne serait observé. Avant de commencer les simulations
d’apprentissage, nous avons testé cette hypothèse en ajoutant un tel changement
à la matrice de poids et nous avons confirmé notre hypothèse. Cependant, il
ne s’agirait pas d’un mécanisme robuste et comme nous le montrerons dans le
chapitre 6, ce n’est pas le mécanisme que nous observons. En outre, des mé-
canismes d’apprentissage légèrement différents sont observés lorsque nous com-
parons 4 modèles différents, (i) basé sur le taux de décharge, (ii) Exponential
Integrate-and-Fire (EIF), (iii) AdEx neuron model et (iv) réseau EI. Enfin, bien
qu’avec toutes les versions de notre modèle, nous soyons capables d’acquérir un
changement de durée sans interférence dans aucune des syllabes, nous observons
un effet intriguant au niveau de l’exécution. Il s’agit d’un léger changement dans
la syllabe suivante, qui s’estompe lorsque l’on fait la moyenne de plusieurs exécu-
tions, dans les différentes simulations aec différentes initialisations. Pour confron-
ter cette observation à des preuves expérimentales, nous analysons les données
d’une expérience de décalage de durée, menée au laboratoire par un collègue.
Dans la dernière section du chapitre 6, nous présentons ces données, qui révèlent
comment la durée de la syllabe cible change au fil des jours et les effet collatéraux
sur la syllabe suivante.

Le dernier chapitre (chapitre 7) est consacré à une discussion générale sur les
implications de nos résultats et leur position dans la littérature. Dans une per-
spective plus large sur le timing, nous présentons un modèle d’attracteur en an-
neau, qui s’inscrit dans la classe des modèles d’horloges de population, comme
une approche théorique du timing moteur subseconde. À l’instar des horloges de
population, ce modèle offre un timing robuste et flexible. Dans la perspective de
l’oiseau chanteur et des neurosciences théoriques, nous discutons de l’émergence
possible d’un tel modèle structuré à partir de l’apprentissage initial du chant et de
la manière dont nous pouvons reproduire numériquement l’apprentissage par im-
itation auprès d’un tuteur adulte, pendant la période sensorielle et sensorimotrice
de l’apprentissage du chant. En outre, nous proposons que les chaînes de synfire
et les attracteurs en anneau puissent en fait se situer dans un continuum. En-
fin, nous suggérons une règle d’apprentissage supplémentaire pour expliquer le
retour à la durée de base, observé après l’arrêt du CAF.

8

List of Publications

1. F. Hyseni, N. P. Rougier, et al. “Attractor dynamics drive flexible timing in bird-
International Conference on Artificial Neural Networks. Springer. 2023,

song.” In:
pp. 112–123. doi: 10.1007/978-3-031-44198-1\_10

2. F. Hyseni, N. Rougier, et al. “Comparative study of the synfire chain and ring attrac-
tor model for timing in the premotor nucleus in male Zebra Finches.” In: ESANN
2023-European Symposium on Artificial Neural Networks, Computational Intelligence and
Machine Learning. 2023, pp. 647–652. doi: 10.14428/esann/2023.ES2023-120

Peer- Reviewed Conferences

1. F. Hyseni, N. Rougier, et al. “An Attractor Model of the Temporal Dynamics of the
Songbird’s Premotor Nucleus.” In: 32nd Annual Computational Neuroscience Meeting
(CNS). Leipzig, Germany, 2023

2. F. Hyseni, N. Rougier, et al. “Temporal Dynamics in an Attractor Model of the Song-
bird’s Premotor Nucleus.” In: Computational and Systems Neuroscience (COSYNE).
Lisbon, Portugal, 2022. url: https://www.world- wide.org/cosyne- 22/temporal- dynamics-
attractor-model-songbirds-b261b11a/

Invited Talk

1. F. Hyseni, N. Rougier, et al. “A model of Sequence Timing in Songbird’s Premotor
Nucleus.” In: Student Conference on Biological Sciences (SCBS). Tirana, Albania, 2021.
url: 10.5281/zenodo.5877414

9

ACKNOWLEDGEMENTS

I would like to express my deepest gratitude to my supervisors, Nicolas Rougier
and Arthur Leblois. I still remember our interview and the follow up email, which
convinced me that this was the ideal position for me. However, given my medical
background, it indeed required a considerable leap of faith on your part to extend
this opportunity to me and I am immensely grateful for your trust. Your guidance
has not only allowed me to grow within my particular field of study, but also to
acquire a profound understanding on what it means to be a good and rigorous
scientist.

I would like to extend my thanks to the members of the jury - Prof. Albert
Compte, Prof. Adrienne Fairhall, Dr. Hervé Roualt, Dr. Daniela Vallentin and
Dr. Alexander Pitti - for accepting the responsibility of reviewing and examining
this thesis. Additionaly, I would like to express my appreciation the members of
my PhD committe, Pierre-Yves Oudeyer and Nicolas Giret, with whom I had the
pleasure to hold annual meetings to discuss the progress of my thesis. Their com-
ments and encouragment over the years have been very valuable.

A special thanks to Roman Ursu, whose experimental contributions have been
very important for the second part of this thesis, as detailed in Chapter 6. Our
engaging discussions have provided more insight into the behavioral paradigm,
and have guided our exploration of interference in the duration shift experiments.
This resulted in very important findings. I would also like to express my grati-
tude to all the members of the songbird group - Remya, Eduarda, Carmen, Xavier,
Nathan, Anindita - for the fruitful discussions.

Moreover, I have been very fortunate to be part of two amazing teams, Mnemosyne

and Team 4 at the IMN, and I would like to thank both for welcoming me so
warmly and for the opportunity to delve into the knowledge of their expertise.
Through our weekly team meetings, I have gained extensive knowledge in vari-
ous domains, of experimental and computational neuroscience.

An important aspect of my scientific journey in Bordeaux has been my engage-
ment with open science.
In this regard, I am particularly thankful to Eduarda
Centeno for introducing me to BordeauxTea. Our collaboration culminated in
an Open Science Workshop in October 2023, days before the submission of this
manuscript. I would like to extend a special thank you to Nicolas for his support
throughout the organization, as well as for his invaluable remarks and sugges-
tions. I also express my gratitude to the Bordeaux Neurocampus and to all the
organizers - Arthur, Deepshika, Yoni, Juan, Nathan, Chloé, Ankur, and Carmen
- and speakers. I hope this workshop becomes a tradition that continues in the
years to come.

10

A heartfelt thanks to the Mnemosyne people and my friends here in Bordeaux -
Remya, Snigdha, Nikos, Naomi, Deepshika, Eduarda, Chloé, Hugo, Axel, Ankur,
Melodie, Maeva, Adrien - for being like a second family these past few years. Get-
ting to know you, sharing this journey, and gaining such brilliant friends has been
an absolute pleasure. Snigdha, my teammate, roommate, and confidante, I will
always cherish our long evening discussions over dinner or tea.

A loving thank you to my partner, Meti, for whom I have no words to properly
convey my gratitude. You have been there at every step of the way, closely by
my side, helpful, understanding, sometimes critical, encouraging and always lov-
ing, supportive and confident in me. Very briefly, it is wonderful to be so deeply
understood. Also, thank you to my friends - Cansu, Tomi, Sukhi, Zeynep, Erta,
Suard, Semi, Asjon, Tedi - who followed this journey remotely. Despite the dis-
tance, I have always felt your presence and immensely enjoyed travelling together.

Last, but not least, the warmest gratitude, to my family- my mother, Bukuri, my
father, Sajet, and my brother, Sueld - thank you for being the best support system
I could ever hope for. I cannot express how crucial your unwavering belief in me
and your love has been throughout this journey. Thank you for your patience,
encouragement, confidence and especially, Sueld, for always having the wisest
advice.

It has been a beautiful experience.
Thank you.

11

Contents

Contents

1 Timing

.

.

1.1 Taxonomy of Timing .

. . . . . . . . . . . . . . . . . . . . . . . . .
Sensory and Motor Timing . . . . . . . . . . . . . . . . . . . .
1.1.1
1.1.2
Implicit and Explicit Timing . . . . . . . . . . . . . . . . . . .
1.1.3 Retrospective and Prospective Timing . . . . . . . . . . . . . .
Interval and Pattern Timing . . . . . . . . . . . . . . . . . . . .
1.1.4
1.2 Timing at Different Temporal Scales . . . . . . . . . . . . . . . . . . .
1.3 Proposed Neural Mechanisms . . . . . . . . . . . . . . . . . . . . . . .
1.4 Neural Substrates of Motor Timing . . . . . . . . . . . . . . . . . . . .

2 Songbirds and Birdsong: Vocalizations and Timing

.

2.1 Cognition and Anatomy in Birds . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . .
2.2 What do songbirds teach us about vocalizations?
2.2.1 Vocal production . . . . . . . . . . . . . . . . . . . . . . . . . .
2.2.2 Vocal learning .
. . . . . . . . . . . . . . . . . . . . . . . . . .
2.2.3 Parallels with Human Speech . . . . . . . . . . . . . . . . . . .
2.3 Neural Networks for Song Perception and Production . . . . . . . .
2.3.1 Auditory Pathway . . . . . . . . . . . . . . . . . . . . . . . . .
2.3.2 Anterior Forebrain Pathway (AFP) . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . . . .
2.3.3 Motor Pathway .
2.4 Anatomical Substrates of Motor Timing In Songbirds . . . . . . . . .
2.4.1 A Local Motor Timing System: Premotor Nucleus HVC . . .
2.4.2 A Distributed Motor Timing System in Songbirds? . . . . . .
2.4.3 Plasticity of Motor Timing . . . . . . . . . . . . . . . . . . . . .

3 Models of Subsecond Motor Timing in Neuroscience
.
.
3.1 General Models .
.
.
3.2 Models of HVC .
.
3.3 Attractor Networks .

. . . . . . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . . . .

.
.
.

.
.

4 Objectives and Overview of the Thesis

5 A Robust Model of Motor Timing

5.1 Robustness of the State of the Art Model: Synfire Chain . . . . . . .
5.2 The Rate-Based Ring Attractor Model of HVC . . . . . . . . . . . . .
5.2.1 Model and Methods . . . . . . . . . . . . . . . . . . . . . . . .
5.2.2 Conditions for a Stationary Bump . . . . . . . . . . . . . . . .
5.2.3 Mechanisms Generating a Drifting Bump . . . . . . . . . . . .
5.2.4 Asymmetric Connectivity Profile to Model HVC . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . . .
5.2.5 Discussion .

.

.

.

.

13

15
17
19
20
20
20
21
22
25

29
29
32
32
34
36
37
37
39
40
42
42
44
46

47
47
51
52

55

59
60
66
66
69
71
75
76

13

Contents

5.3 A Spiking Neural Network Model of HVC . . . . . . . . . . . . . . .
5.3.1 Model and Methods . . . . . . . . . . . . . . . . . . . . . . . .
5.3.2
Symmetric Rectangular Connectivity Profile . . . . . . . . . .
5.3.3 Asymmetric Gaussian Connectivity Profile . . . . . . . . . . .
5.3.4 Conditions for a Drifting Bump . . . . . . . . . . . . . . . . .
5.3.5 Predictions from the Models . . . . . . . . . . . . . . . . . . .
5.3.6 Discussion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
5.4 Extended model with thalamic (Uva) Input: Synchrony? . . . . . . .
5.5 An EI Network Model of HVC . . . . . . . . . . . . . . . . . . . . . .

6 A Flexible Model of Motor Timing: Behavioral Adaptation

79
79
82
83
83
86
89
90
92

95

.

. . . . .

6.2.1 Results .

6.2 Learning in the Rate-Based Model

6.1 Reinforcement Learning: Numerical Implementation of the CAF ex-
perimental Paradigm . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . . .

96
98
98
6.3 Learning in the SNN . . . . . . . . . . . . . . . . . . . . . . . . . . . . 103
. . . . . . . . . . . . . . . . . . . . . . . . . 104
6.4 Learning in the EI Network Model . . . . . . . . . . . . . . . . . . . . 109
6.5 Comparing Model Results to Experimental Data . . . . . . . . . . . . 112
. . . . . . . . . . . . . . . . . . . . . . . . . 113
. . . . .
. . . . .
. . . . . . . . . . . . . . . . . . . . . . . . . 114
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 115

6.5.1 Methods .
.
6.5.2 Results .
.
.

6.6 Discussion .

6.3.1 Results .

. . . . .

.

.

7 Discussion and Conclusions

119
7.1 A Robust and Flexible Model of Motor Timing using Attractors . . . 119
. . . . . . . . . . . . . . . . . . . . . . . 120
7.1.1 Rate and SNN Model
7.1.2 Relating the EI model with the Literature . . . . . . . . . . . . 121
7.2 Biological Relevance and Interpretation . . . . . . . . . . . . . . . . . 121
. . . . . . . . . . . . . . . . . . . . . . . . . 121
7.2.1 Motor Timing . . .
7.2.2 Learning Rule for Behavioral Adaptation . . . . . . . . . . . . 124
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 128
7.3.1 Cellular and Network Properties . . . . . . . . . . . . . . . . . 128
7.3.2 HVC in Bengalese Finches and Canaries . . . . . . . . . . . . 129
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 130
7.4.1 A Continuum? Synaptic Chains to Asymmetric Ring Models 130
7.4.2
Initial Learning in Unstructured Networks . . . . . . . . . . . 130
7.4.3 Return to Baseline Duration . . . . . . . . . . . . . . . . . . . . 131

7.4 Perspectives .

7.3 Limitations .

.

.

.

.

.

List of Figures

List of Tables

Bibliography

14

133

141

143

1 Timing

"If you slow speech down too much, it becomes unintelligible and if you speed a musical
piece too much, it ceases to be music. " D. Buonomano (2017)

.

.

1.1 Taxonomy of Timing .

. . . . . . . . . . . . . . . . . . . . . . . . .
Sensory and Motor Timing . . . . . . . . . . . . . . . . . . . .
1.1.1
1.1.2
Implicit and Explicit Timing . . . . . . . . . . . . . . . . . . .
1.1.3 Retrospective and Prospective Timing . . . . . . . . . . . . . .
Interval and Pattern Timing . . . . . . . . . . . . . . . . . . . .
1.1.4
1.2 Timing at Different Temporal Scales . . . . . . . . . . . . . . . . . . .
1.3 Proposed Neural Mechanisms . . . . . . . . . . . . . . . . . . . . . . .
1.4 Neural Substrates of Motor Timing . . . . . . . . . . . . . . . . . . . .

17
19
20
20
20
21
22
25

Time is an ubiquitous concept, present in almost every aspect of our lives, linked
both to perception and action, at many different scales (microseconds to millions
of years). It is important when performing temporally precise movements, such as
pressing the brakes at the right moment before hitting another car, and also when
discussing age or history from years, decades or centuries ago. Time is linked
to memory, as a key factor in remembering when an event took place and it is
linked to future planning, in determining when an action should be performed.
We implicitly rely on time when determining event order, which is a key factor
in causality and associative learning. Time is crucial to communication through
language and cognition, in general. Moreover, its essence can clearly be witnessed
in some disciplines, such as music, dance, sports etc., where several dimensions
of time are combined.

Its broad presence in our everyday lives and its conceptualization, is illustrated
by the fact that the word time is currently the most used word in the English
language. Such usage should imply an understanding of the concept of time, as
broad and empirical as this may be. However, defining time is a different chal-
lenge. If we were to refer to dictionary definitions, time is a nonspatial continuum
that is measured in terms of events which succeed one another from past through
present to future (Merriem-Webster); or the entity measured in years, days, hours,
minutes, seconds (Cambrigde). Both definitions rely on two different aspects of
time, while not encompassing them both and not adding other important prop-
erties thereof. For the purpose of this manuscript, a richer definition of time is

15

1 Timing

crucial. Therefore, in this general introduction, we will try to present several field-
specific definitions, in an attempt to build a broader background of time, after
which we will focus on its role and representation in neuroscience.

To date, there are two main physical notions of time. The classical notion sug-
gested by Newton, defines time as an ’absolute’ and universal quantity that flows
independently of objects and events in space. Classical mechanics and dynamical
systems theory rely strongly on this notion of time. For instance, the state of an
object is described with differential equations involving time derivatives (Strogatz,
1994). The other notion of time is the one suggested by Einstein (1915) through
the theory of relativity. Time is referred to as a fourth dimension, which is lo-
cally defined in space and can shrink or expand depending on the surrounding
objects/events.

Time is tightly linked to event order and thus the principle of causality. Despite
the differences in both notions, in essence, the principle of causality, states that
cause precedes effect and implies a directionality of time, from past (or present,
cause) to present (future, effect). These notions and principles have had a big
impact on how we perceive, conceptualize and address time (Rovelli, 2019).

In philosophy, several aspects of time are addressed. These include its definition
and properties, its linearity, direction, relative or absolute nature and its percep-
tion. The main two philosophical notions of time are summarized by the theories
of presentism and eternalism, which relate to the aforementioned physical no-
tions (D. Buonomano and Rovelli, 2021). Presentism states that the present state of
the world is real, the past has passed and the future is yet to come. On the other
hand, eternalism suggests a four dimensional block (3 spatial dimensions + time),
where past, present and future coexist and are equally real.

A long-standing philosophical debate is whether time is a measurable quantity
or a notion purely based on our perception. An important theory in this regard
is Bergson’s theory (Bergson, 1889), which claims that time is an ever-changing and
indivisible term that cannot be measured and even if measured, such measure
would not reflect the reality of our perception. This suggests that the approaches
we use to metricize time as we metricize space, although practical, do not offer an
accurate description of time.

Although per definition time is a nonspatial continuum, we tend to “spatialize”
it in our daily conversations (Casasanto and Boroditsky, 2008; Traugott, 1978). Indeed,
we strongly associate time to space because the latter is a concrete and tangible
concept. Across cultures and languages, many spatial metaphors or phrases are
present, i.e. length of a speech, shorter duration and back in the past.

The spatial metaphors of time share similarities, but the vocabulary is some-
times not consistent between different languages and cultures (Boroditsky, 2018).
For instance, in English we refer to time with the front/back vocabulary, where
time is placed in a horizontal axis with the future in the front and the past in the
back. However, in Aymara language, the future is placed in the back and the past
in the front (Núñez and Sweetser, 2006). Moreover, other languages may place time
in the vertical axis (up/down for future/past in Mandarin Chinese (Boroditsky,

16

1.1 Taxonomy of Timing

Fuhrman, et al., 2011)) or even use cardinal directions (Australian Aboriginal com-
munity (Boroditsky and Gaby, 2010)). These findings show that there are different
ways in which time is addressed and therefore perceived.

In neuroscience, several test batteries have been proposed and implemented to
unravel the underlying neural substrates of time, both in physiological and patho-
logical conditions. A common outcome of many of these studies, is that a multi-
tude of cognitive processes are associated with time and temporal processing. For
instance, time is not only present in tasks that explicitly or implicitly necessitate
a temporal computation (interval discrimination, duration estimation, sequence
generation), but it is also linked to metacognitive tasks such as understanding
concepts, memory, time travel, envisioning future actions and planning.

Moreover, our perception of time “durée” (Bergson, 1889) is complex and subjec-
tive; it is not linear, but can expand or shrink based on a number of internal and
external factors. Despite this, time in neuroscience is generally considered to be
linearly evolving. Its accuracy is not claimed at all scales, but there are mecha-
nisms operating at timescales which are as objective as our traditional clock, i.e.
the circadian rhythm. On the other hand, mechanisms of time-telling at shorter
scales, such as for instance milliseconds, are much less known. Experimental
findings show neurons accurately tune to specific interval durations after training
(Gouvêa et al., 2015; Kawai et al., 2015). These findings give rise to the question of
whether there is an internal representation of time (clock-like) and if so, if it is
universal or different across scales and modalities.

Due to the complexity of time in neuroscience, several aspects need to be dis-
cussed in detail.
In the following sections, we will first present a taxonomy of
timing based on evidence from the literature. Then, we will summarize briefly the
different scales of time, alongside their underlying mechanisms. Lastly, we will
focus on the proposed neural mechanisms of motor timing at the scale of tens to
hundreds of milliseconds.

1.1 Taxonomy of Timing

Timing is crucial for a wide range of sensorimotor tasks. However, there
are numerous uncertainties regarding the underlying mechanisms. For instance,
sensory and motor timing may not rely on the same circuitry, there could be
different mechanisms for different scales of timing (subsecond, suprasecond etc.)
and the underlying mechanisms could be dedicated or intrinsic (R. Ivry and Schlerf,
2008). To address the broader question of timing, a series of relevant tasks has
been identified, the collection of which has given rise to a series of experimental
paradigms that have been implemented. According to Paton and D. V. Buonomano
(2018), any task that is based on interval or duration, and requires a timing device
to be solved, can be considered a timing tasks. Broadly, timing tasks are divided
into three main categories (Grondin, 2010): (i) duration/interval discrimination, (ii)
production and (iii) reproduction.

17

1 Timing

Figure 1.1: Taxonomy of Timing. A representation of the taxonomy of timing, compiled
based the evidence provided throughout the years (Breska and R. B. Ivry, 2016;
J. Coull and Nobre, 2008; Grondin, 2010; M. Mauk and D. Buonomano, 2004):
namely sensory/motor, implicit/explicit, prospective/retrospective and inter-
val/pattern timing. Each of the limits of these dimensions is shown to engage
different mechanisms, hence bringing the necessity of separating it into subdo-
mains when studying timing. Whereas the other domains represent separate
dimensions, prospective/retrospective timing is a subdivision of explicit tim-
ing. On the side, different tasks, where different aspects of timing can be
studied, are illustrated.

To position the investigated tasks and formulate more systematic hypotheses,
a taxonomy of timing is necessary. A taxonomy of timing implies a good under-
standing of the shared and different mechanisms, underlying different tasks. As
such, it is still an open and challenging aspect in neuroscience and there exists
several proposals. J. Coull and Nobre (2008) proposes at least two dimensions and
four timing sub-domains. The first dimension is that of perceptual and motor
timing, whereas the second is implicit and explicit timing. Although these sub-
domains would lie in a continuum in their respective dimensions, specific neural
mechanisms play a role in each of the two ends of the spectrum. A review of
such findings in the neuroimaging (fMRI) literature is provided by J. Coull and No-
bre (2008), who show that implicit and explicit timing recruit different circuitries.
Moreover, they show and suggest that so do sensory and motor timing. A third
dimension of timing is suggested by Grondin (2010), that of prospective and ret-
rospective timing. On the other hand, Paton and D. V. Buonomano (2018) suggest a
different second and third dimension. In their review, they summarize the timing
dimensions as 3: (i) sensory and motor timing, (ii) subsecond and suprasecond
and (iii) interval and pattern timing.

There are similarities and differences, originating from the field and tasks in-
vestigated, between these three proposed taxonomies. We consider all four pro-
posed dimensions and illustrate each in figure 1.1 alongside their respective timing

18

TimingSensoryExplicitImplicitMotorImplicitExplicitEyeblink ConditioningTemporal OrientationInterval/ DiscretePattern/ ContinousCircle Drawing, speech productionRhythm- based PredictionsEx: Morse codeRhythmic Pattern (Song)RetrospectiveProspectiveInterval ReproductionInterval ProductionInterval ReproductionRetrospectiveProspectiveInterval DiscriminationInterval ComparisonInterval DiscriminationRepetitive Isochronous TappingAction in anticipation of an external eventInterval ReproductionInterval ReproductionInterval DiscriminationInterval DiscriminationSequences of Intervals, Bisection, GeneralizationComplex Pattern ReproductionIsochrony- based JudgementsIsochrony- based Judgements1.1 Taxonomy of Timing

task(s). Below, we detail the subdomains, alongside their experimental tasks and
paradigms and we include evidence of the different mechanisms reported in each
subdomain. Sub and suprasecond timing, also take place in the taxonomy. Al-
though we do not include subsecond and suprasecond timing in the figure, we
describe the scales of timing and their mechanisms in section (1.2).

1.1.1 Sensory and Motor Timing

The one common dimension of timing in the three aforementioned reviews is
sensory and motor timing. The sensory subdomain of timing is referred to as
temporal perception and concerns the perception and ’measurement’ of a duration
through our senses (which do not include a timing sense).
It is a rather tricky
concept, as it is dependent on a rather vast amount of external and internal factors,
including emotional state (stress, excitement, dread), spatial position, attention,
temperature, our actions etc. For instance, in the context of waiting for the bus
or running to catch it, two possibly identical durations can be perceived as very
different. However, more precise perceptions of time are also present, such as our
perception of a day (circadian clock) or that of specific intervals, when trained.
The latter has been shown by several studies across different species, which have
shown neural tuning to specific time intervals following training ((Bueti, 2011; Bueti
and D. V. Buonomano, 2014; D. V. Buonomano, Bramen, et al., 2009; Karmarkar and D. V.
Buonomano, 2003; Nagarajan et al., 1998) (electric fish (Carlson, 2009), rats (Zhou et al.,
2010), zebra finches (Margoliash, 1983)) (Paton and D. V. Buonomano, 2018)).

On the other hand, motor timing involves tasks where temporal control is nec-
essary to perform an action or anticipate it (Paton and D. V. Buonomano, 2018). In
the wild, this would mean escaping, starting to run instantly at the sight of a
predator, at a football court hitting the ball at the exact time that the goalkeeper is
distracted by someone else, in a piano class playing the right note at the right time
etc. Another intuitive example of motor timing is human speech, where words
are uttered in a sequence with small pauses in between. Longer pauses translate
to commas in the written language and even longer pauses to dots, thus affecting
the meaning of the sentence. For instance, a pause in the millisecond scale, can
significantly alter sentence meaning: ’Let’s eat grandma’, insinuating the grand-
mother should be eaten (?!), as compared to ’Let’s eat, grandma!’, where she is
being invited to join for dinner. Moreover, these speech pauses are affected by the
speech rate and vary in duration, number and position in the sentence (Matzinger
et al., 2020).

Although the description of sensory and motor timing above, may insinuate
they are discrete points in a line, that is not the case. They rather lie in a contin-
uum. However, tasks where one is more heavily present, are necessary to investi-
gate them and the involved circuitry in detail. In such tasks, imaging studies have
revealed they do not engage the same areas, with perceptual timing tasks, show-
ing mostly correlation with activity in the anterior portion of SMA (pre-SMA), the
right inferior frontal cortex and BG and motor timing tasks, with BG and a context-

19

1 Timing

dependent coactivation of the SMA (preSMA and/or SMA proper), inferior frontal
cortex or cerebellum (J. Coull and Nobre, 2008).

1.1.2 Implicit and Explicit Timing

Implicit timing, refers to tasks where timing develops implicitly from the task
in hand, as an automatic, unconscious processing of temporal information, often
integral to motor coordination, habituation, or rhythmic activities. On the other
hand, explicit timing necessitates a conscious awareness of timing, for instance
in estimating how long an event lasted, or how much time needs to pass before
It requires attentional resources focused on timing. As
performing an action.
such, explicit timing is crucial for tasks demanding active temporal judgments
and predictions.

Implicit and explicit timing have been shown through behavioral and imaging
studies to involve different mechanisms. In a review of fMRI studies (J. Coull and
Nobre, 2008), it was shown that during explicit timing there is an activation of the
basal ganglia, and a context-dependent co-activation of the prefrontal, premotor
and cerebellar areas, whereas during implicit timing, the inferior parietal and
premotor areas are active.

1.1.3 Retrospective and Prospective Timing

Another dimension important when designing experimental paradigms to study
timing is retrospective and prospective timing. The former is dedicated to time
that has passed and the latter to coming time. Retrospective timing, is associated
with memory (Block and Zakay, 1997) and to test it, in experimental settings, the
subject is asked after a particular interval has passed to report elapsed time. In
contrast, for prospective timing, the subject is informed beforehand that a timing
task is to take place and is asked to perform a timing-related judgement/action.

An example of retrospective timing in everyday life, could be reporting the
amount of time you were stuck in traffic that day, whereas examples of prospective
timing are estimating the amount of time before you enter an exam, or the time
it takes to finish a presentation. Both prospective and retrospective timing are
subject to a wide range of scales, even though retrospective timing studies are
known to explore more orders of time as compared to prospective timing (studied
mostly on brief intervals). In most taxa, prospective timing above a certain range,
i.e. hours, days may not possible, as this would involve more complex cognitive
mechanisms and elicit future planning.

1.1.4 Interval and Pattern Timing

Another dimension of timing entails its complexity, the two limits of which be-
ing interval (simple, ’absolute’) and pattern/dynamic (complex, ’relative’, ’beat-
based’) timing. The former refers to estimating/performing an action based on

20

1.2 Timing at Different Temporal Scales

the duration of a particular, isolated, event. The latter includes continuous time-
keeping as in the case of drawing a circle (Spencer and R. B. Ivry, 2013), where timing
is implicit and arises as a property of the performed action. It also includes tempo-
ral sequences, whereby time-keeping of the singular intervals, but also the overall
sequence structure is required.

Behavioral (Grube et al., 2010), imaging (Teki et al., 2011) and computational (Hardy
and D. V. Buonomano, 2016) approaches reveal that there are possibly different mech-
anisms involved in these two subdomains. An example is the presence of the cere-
bellar involvement only in interval timing (Breska and R. B. Ivry, 2016; Spencer and
R. B. Ivry, 2013), but not in dynamic timing. This has been shown both through
imaging studies and observed in impairments from cerebellar pathologies. How-
ever, there are exceptions as in the case of rhythmic finger tapping, which is associ-
ated with pattern timing, but is still affected by cerebellar pathologies, manifesting
with higher temporal variability.

1.2 Timing at Different Temporal Scales

Temporal processing can occur at different timescales (Buhusi and Meck, 2005), from
microseconds to a day, across at least 12 orders of magnitude (M. Mauk and D.
Buonomano, 2004). Broadly, M. Mauk and D. Buonomano (2004) split the timescales
into 4 main groups: circadian rhythms (King and Takahashi, 2000), seconds (Gibbon,
1977), milliseconds (Karmarkar and D. V. Buonomano, 2003) and microseconds (Carr,
1993). Upon observing the broad range of timescales illustrated in Fig.1.2, the
question of the underlying mechanisms and whether they are similar arises.

Figure 1.2: Temporal processing at different scales. At least 12 orders of magnitude are re-
ported in human temporal processing. Adapted from M. Mauk and D. Buono-
mano (2004).

As we have briefly mentioned above different mechanisms are engaged in each.
Evidence on the timescale of the circadian rhythm and the microsecond scale re-
veals their respective mechanisms. The former relies on a "period" gene (Reddy

21

10−3109Micro-seconds:10105107Milli-seconds:Seconds:1 milli-second1 second10−11031 minute1 hour1 dayCircadian rythm:SCALE:MECHANISMS:•appetite •sleep-wake•conscious time estimation•speech generation •speech recognition •motion detection •motor coordination•sound localization •echolocation•axonal cond. delays •variable inhibition??•translation/transcription •autoreg. feedback loops •suprachiasmatic nuclei1 Timing

et al., 1984), which encodes the transcription/ translation of a protein. The amount
of this protein serves as a hourglass clock- sandclock with a cycle of a bit more
than 24 hours (in humans). The suprachiasmatic nuclei are involved in this pro-
cess. The latter (microsecond scales) engages in sound localization (delay of sound
travel from one ear to the other) and echolocation (Covey and Casseday, 1999). Its
mechanism relies on axonal conduction delays and variable inhibition (M. Mauk
and D. Buonomano, 2004).

However, the sub- and suprasecond scale remain less clear, with evidence sug-
gesting the latter may be more related to conscious timing and cognitive capacities
(Buhusi and Meck, 2005). Time processing in this scale is often referred to as time
estimation and recruits the prefrontal and parietal cortices. This is thought to be a
very flexible timing mechanism. On the other hand, the tens to hundreds of mil-
lisecond scale, is considered ’automatic’ (Lewis et al., 2003) and proposed to rely on
more sophisticated and complex mechanisms (M. Mauk and D. Buonomano, 2004). It
is crucial for speech and fine motor coordination. Moreover, it is closely linked to
motor and premotor circuits and Lewis et al. (2003) suggest that it may ’keep time’
using a temporal pattern generator mechanism. The differences in mechanism be-
tween these two scales have been revealed by pharmacological (Rammsayer, 1999),
psychophysical (Karmarkar and D. V. Buonomano, 2007) and imaging studies (Lewis
et al., 2003).

1.3 Proposed Neural Mechanisms

The mechanisms underlying timing remain a fundamental and broadly researched
topic. There are several hypotheses, which are addressed by different computa-
tional models and experimental paradigms, and have their own supporting and
violating body of evidence. Since there is no evidence regarding the existence of a
dedicated organ or sense for time estimation, this means such estimation derives
from internal mechanisms, involving some form of computation (Clark, 1998). In
this regard, the two main hypotheses, comprising the two broader model classes
are the dedicated and intrinsic model of timing (R. Ivry and Schlerf, 2008).

Dedicated Model

The first hypothesis claims that there exist dedicated/specialized neural mecha-
nisms, involving one or several brain areas, that can perceive duration and execute
timely behaviour. The underlying mechanism is hypothesized to be ubiquitous
and invariant across conditions, modalities, task and scales (milliseconds to sec-
onds) (Karmarkar and D. V. Buonomano, 2003; Zelaznik et al., 2002). This hypothesis
was motivated by several reasons, including (i) its simple and intuitive nature, (ii)
the observation that our sense of passage of time is comparable across modalities
(visual, auditory) (Grondin and Rousseau, 1991) and (iii) the similarity in temporal
variability (ratio between variability and mean duration) between perception and

22

1.3 Proposed Neural Mechanisms

production tasks (R. B. Ivry and Hazeltine, 1995). Moreover, arguments associating
specific brain areas to dedicated timing systems are present. Notably, the cerebel-
lum, basal ganglia, supplementary motor area and the prefrontal cortex have been
proposed as candidate regions.

Dedicated models also include distributed time representations, where several
areas interact to give rise to timing. Each of these areas can have a particular
function, for instance, one being the pacemaker and the other the accumulator,
as in the case of the striatal beat frequency model (SBF). In this model, a set of
cortical neurons (timekeepers) that oscillate at regular, but distinct frequencies,
are followed by striatal integrators that combine the information received with
feedback and form the basis of interval timing (M. S. Matell and Meck, 2004; Meck
et al., 2008).

Dedicated systems (Bueti, 2011; R. Ivry and Schlerf, 2008) can be split in three
broad classes, the pacemaker-accumulator models, process-decay models, and
oscillator/coincidence-detection models (M. S. Matell and Meck, 2000). The most
commonly addressed models are clock based models, namely the pacemaker ac-
cumulator model (Creelman, 1962; Treisman, 1963), and the scalar expectancy theory
(Gibbon, 1977). The former relies on a pacemaker, which generates neural pulses
and an accumulator that assembles them, creating a linear measure of duration
based on the number of accumulated ticks. The latter contains an attentional
switch, a comparison step and a decision stage. A particular benefit of the scalar
expectancy theory, which is necessary in all timing models at this scale, is the
ability to reproduce the scalar property of timing. The scalar property of timing,
states according to Weber’s law, that the longer the duration, the higher the error
in timing estimation will be.

Intrinsic Model

Intrinsic models of timing suggest that temporal information is not specialized
It instead emerges from the instrinsic cellular
and associated with (a) clock(s).
and network dynamics of neural cirucuits and depends on the task demands (D. V.
Buonomano, 2000; D. V. Buonomano and Merzenich, 1995). This hypothesis is moti-
vated by (i) the importance and ubiquity of temporal computations, (ii) evidence
showing that timing is specific to modalities (Burr et al., 2007) and tasks and (iii)
the proposed analogy with spatial representations in the brain, which are vast
(Paton and D. V. Buonomano, 2018). In support of the second point, time-keeping in
different modalities (i.e. visual vs auditory) has been shown to recruit different
circuitry (i.e. visual neural mechanisms vs auditory) (Burr et al., 2007; R. Ivry and
Schlerf, 2008).

There exist several proposed mechanisms implementing the same conceptual
idea. A possible mechanism of intrinsic timing (Pariyadath and D. Eagleman, 2007)
suggests that duration may be encoded in the magnitude of neural activity and
the amount of energy spent over time. Similar to the SET, here the intensity of
the stimulus and attention affect temporal perception (D. M. Eagleman, 2008; Pariya-

23

1 Timing

dath and D. Eagleman, 2007). Other studies have proposed that timing is encoded
in beta oscillations (Fujioka et al., 2012) or in patterns of activity throughout the
neural network (D. V. Buonomano and Merzenich, 1995). An example of the latter
is the state dependent network (SDN) (D. V. Buonomano and M. D. Mauk, 1994; Kar-
markar and D. V. Buonomano, 2007), which proposes that any network could process
temporal information, and represent different durations through unique spatial
organizations. They propose that temporal selectivity is an intrinsic property of
local neural circuits that relies on time-varying synaptic and neuronal properties,
most notably short-term synaptic plasticity.

The applicability of either model (at least for perception) could map into the temporal
range, where intrinsic models can be more suited for the subsecond and dedicated timing
models for the suprasecond scale (R. Ivry and Schlerf, 2008).

Embodied Time

Embodiment of time refers to a tangible, physical structure, the observation of
which provides an (rough) estimation of time. In an isolated setting, with nothing
but one’s self to keep track of time, walking or drawing or any kind of action
can be used as a timing mechanism, especially when memory, reward signals or
a clock provide cues on how much time has passed at the end of the ’trial’. In-
deed, several studies have witnessed exactly this. They observe the appearance of
’superstitious’ (stereotypical) behaviors occurring when animals perform a timing
task pertaining a reward. These behaviors entail individually unique, repeated ac-
tions (or sequences of actions) that seem to be collateral and unrelated to the task.
Such actions are interpreted as a way to keep track of time through more easily
measurable metrics, i.e. the distance travelled (rats), or rotations/ turns (pigeons).
These actions are then likely reinforced upon reward delivery and an association
between them and the reward is created, making the animals repeat them in the
subsequent trials.

Similar stereotypical behaviors have been observed in humans.

In everyday
activities, we draw associations between the mean duration of certain tasks and
elapsed time, such as the time to drink a coffee, smoke, walk to work, or give a
well-rehearsed presentation. For instance in the latter, we know 45 minutes have
passed, probably not because we have an internal clock measuring each second
passing by, or because we have neurons tuned to this specific duration. Instead,
it is because after many rehearsals, we know approximately how long it generally
takes us to get to any point of the presentation, based on the speed of speech.
However, it is important to note the difference in the scale of time, as the mecha-
nisms described here are in the suprasecond scales. Conversely, in the subsecond
scale, evidence have shown that neural tuning to a certain duration occurs.

24

1.4 Neural Substrates of Motor Timing

1.4 Neural Substrates of Motor Timing

Investigation of motor timing and its proposed neural mechanisms can be per-
formed both in a physiological and pathological state, either experimentally in-
duced or clinically present. A loop of knowledge between the anatomical sub-
strates of timing and its clinical impairments emerges, as findings and observa-
tions from both symbiotically work to bring together a general picture of under-
standing, providing a clearer view of time in neuroscience. Based on the literature,
no neurological or psychiatric disorder has timing deficits in every scale and none
appears solely with timing deficits (J. T. Coull et al., 2011; Paton and D. V. Buono-
mano, 2018). This statement could suggest different timing mechanisms in differ-
ent scales, and either distributed or intrinsic mechanisms of timing. As briefly
mentioned above, several areas have been proposed as candidates for encoding
and/or generation of timing tasks (defined in section 1.1), in the framework of
each of the proposed neural mechanisms in section 1.3. These include the basal
ganglia, the cerebellum, the premotor cortex, supplementary motor (SMA), Brocca
and precentral gyrus (J. T. Coull et al., 2011). Some of these proposals originate from
the human literature, behavioral observations in certain tasks, conditions or in
lesions, presenting with disruptions in motor timing.

An example of a transfer of knowledge between clinics and neuroanatomy is
the observation of the behaviour of patients with Parkinson’s disease (PD), which
has become an incentive for the investigation of motor timing’s substrates in the
striatum and the dopaminergic system. Other disorders affecting the basal ganglia
and also presenting with altered perceptual or motor timing, include Huntington’s
disease and Tourette’s. The most studied basal ganglia dysfunction, Parkinson’s
disease is characterized by motor deficits, including bradykinesia (slowness of
movement). In PD, timing impairments are pronounced in explicit timing (section
1.1.2), both in the perceptual and motor subdomain. In the sensory domain they
are present in the subsecond and second timescale, across multiple modalities
(visual, auditory, tactile) and are correlated with disease severity (Artieda et al.,
1992).

In the motor domain, timing impairments manifest with bradykinesia, with ac-
curacy reduction in the sub- and suprasecond scale and higher timing variability
(inconsistent across studies) (J. T. Coull et al., 2011). Moreover, a prominent find-
ing is the overestimation of shorter duration and underestimation of longer ones,
hence bringing them closer in the estimation. This is referred to as a ’migratory’
effect and was present in the retrieval phase. Patients in the off-medicate state
overestimated a shorter duration (8 s) and underestimated a longer one (21 s)
(Malapani et al., 1998). Another study with nonmedicated patients showed overesti-
mation of both shorter and longer durations, suggesting a role of the basal ganglia
in determining the clock speed (Pastor et al., 1992). A very recent study supports
the clock-speed hypothesis, by cooling the striatum with a thermoelectric device
(Monteiro et al., 2023). They showed that cooler temperatures cause dilation, and
warmer temperatures contraction, of both neural activity and temporal judgement.

25

1 Timing

However, the speed of this activity does not affect continuous kinematics. Another
study revealed that the effects of striatum inactivation were greater for suprasec-
ond timing (Kunimatsu et al., 2018), while those in the cerebellum for subsecond
timing. Taken together, these studies suggest that the basal ganglia is a mid-level
controller, with no detailed control on the sequence, but control on selection, link
and modulation of actions (Graybiel, 1998; Monteiro et al., 2023; Park et al., 2020).

Cerebellum is another structure implicated in timing. Initially, it was associated
solely with motor timing, since in the case of cerebellar ataxia, difficulty in the
precise temporal control is observed. A number of studies claim a role for the
cerebellum in timing in the subsecond range, in the sensory and motor subdomain
(J. T. Coull et al., 2011), and in explicit and implicit timing (Breska and R. B. Ivry, 2016).
Examples of motor tasks used to test timing in cerebellar patients, include interval
reproduction, synchronization-continuation tapping task, circle production and
the best known task: eyeblink conditioning test. Several hypotheses are made
on the role of cerebellum. One hypothesis proposes a context- dependant role,
emerging in the case of malfunction of the corticostriatal pathway (Merchant et al.,
2013) or when processing at subsecond scale (Lewis et al., 2003) is needed. Another
hypothesis is built in a review, where Breska and R. B. Ivry (2016) first present a series
of studies highlighting the importance of the cerebellum in numerous timing tasks.
They then show the tasks not associated with the cerebellum, including circle
drawing, isochrony-based judgements and rhythm-based predictions. Such tasks
can be grouped as dynamic or continuous tasks, which leads to their proposal that
the cerebellum may be required when timing discrete intervals, but not when it is
intrinsic to rhythmic or continuous dynamics.

Cortical motor areas are also involved in timing, and as the intrinsic hypothe-
sis suggests, timing could be an intrinsic property of the cortical circuits. Studies
have revealed the engagement of the primary visual (Gavornik and Bear, 2014) and
auditory cortices (Brosch et al., 2005) in timing tasks including the respective modal-
ities. Moreover, motor cortical areas are shown to be implicated in timed actions,
such as controlling self initiated actions (Mushiake et al., 1991), and sequentially
organizing multiple actions (Tanji, 2001). Hence, it is suggested that, beyond just
representing features of motor output, motor regions may have intrinsic oscilla-
tory dynamics or sequential dynamics (Mita et al., 2009; Shenoy et al., 2013) to act as
their own pattern generators.

As briefly mentioned above, the aforementioned brain areas are likely linked
in a distributed system. For instance, the basal ganglia (McFarland and Haber,
2001) and cerebellum (Prevosto et al., 2010) send input through the thalamus to
the cortex. In rodents, these cortical areas are respectively the motor cortex and
deeper cortical layers (Kaneko, 2013) and they might be specifically involved in the
cortico-basal ganglia and the cortico-cerebellar loops. However, further research
in necessary.

The findings presented above, although mainly in humans, contain and were
supported by evidence found in other taxa. One such example are songbirds,
which have a somewhat simpler and clearer timing mechanism. In song-producing

26

1.4 Neural Substrates of Motor Timing

male zebra finches a premotor area, HVC, contains neurons firing in a time-locked
manner to the song (R. Hahnloser et al., 2002). Manipulations on this area, with a
cooling/heating paradigm, have shown, that both neural activity and song tim-
ing are a function of the temperature given to the nucleus, exhibiting constriction
when the nucleus is heated, and dilation otherwise (Long and M. S. Fee, 2008). This
effect is only seen in manipulations to this area and not on the subsequent motor
area, which is line with the hypothesis of a population clock model, suggesting
that the neuronal population of this area encodes the temporal dynamics of song
production at the scale of tens to hundreds of milliseconds.

27

2 Songbirds and Birdsong:
Vocalizations and Timing

.

2.1 Cognition and Anatomy in Birds . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . .
2.2 What do songbirds teach us about vocalizations?
. . . . . . . . . . . . . . . . . . . . . . . . .
2.2.1 Vocal production .
2.2.2 Vocal learning .
. . . . . . . . . . . . . . . . . . . . . . . . .
.
2.2.3 Parallels with Human Speech . . . . . . . . . . . . . . . . . . .
2.3 Neural Networks for Song Perception and Production . . . . . . . .
2.3.1 Auditory Pathway . . . . . . . . . . . . . . . . . . . . . . . . .
2.3.2 Anterior Forebrain Pathway (AFP) . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . . .
2.3.3 Motor Pathway .
2.4 Anatomical Substrates of Motor Timing In Songbirds . . . . . . . . .
2.4.1 A Local Motor Timing System: Premotor Nucleus HVC . . .
2.4.2 A Distributed Motor Timing System in Songbirds? . . . . . .
2.4.3 Plasticity of Motor Timing . . . . . . . . . . . . . . . . . . . . .

.

29
32
32
34
36
37
37
39
40
42
42
44
46

2.1 Cognition and Anatomy in Birds

Birds have been long studied across a variety of different fields and subjects. They
are particularly puzzling in the field of neuroscience due to their prominent cog-
nitive skills. Traditionally, the evolution of cognition and brain development is
represented as a function of telencephalic evolution and is thought to have oc-
curred in a progressive pattern, culminating with the human cerebrum (Edinger
et al., 1903). In this terminology, birds represented an earlier stage of evolution,
because most of the avian telencephalon was considered a hypertrophied basal
ganglia. However, the modern view of the vertebrate evolution is quite different
(Jarvis et al., 2005; Reiner et al., 2004), showing that birds do not represent an ear-
lier stage of evolution but rather an alternate one as shown in Fig. 2.1, all while
having/exhibiting similar cognitive function and abilities to mammals.

Sophisticated Cognitive Functions

Cognitive abilities of birds have been investigated in a different light since the
1950s and appreciated as more complex as previously assumed (Jarvis et al., 2005).

29

2 Songbirds and Birdsong: Vocalizations and Timing

Among these studies, Marler (1955) showed that chaffinches produce a range of
different sounds/calls, which are adapted to different scenarios and functions,
such as female attraction, rival male repelling, predator confusion and danger
communication. Other research in pigeons showed that they can form higher or-
der concepts to categorize objects (Lubow, 1974) and different styles of paintings
(Monet vs Picasso) (S. Watanabe et al., 1995). Moreover, they can communicate us-
ing visual symbols (Epstein et al., 1980), can learn and store up to several hundred
visual patterns over long periods of time (Fersen and Delius, 1989) and can lie (re-
port incorrectly) to increase reward (Lanza et al., 1982). The latter was also shown
in two species of flycatching birds, where they deceptively used alarm calls, i.e.
’cried wolf’ (Munn, 1986). Another cognitive skill observed in magpies is object
permanency, which they develop early on to use for food-storing purposes (Pollok
et al., 2000). Magpies are also reported to recognize themselves in the mirror (Prior
et al., 2008). Additionally, skills like sound localization in owls (Knudsen, 2002) and
vocal production and learning (Nottebohm, 1972) in songbirds, parrots and hum-
mingbirds are present. Parrots can even learn human words and communicate
through them.

A multitude of studies have focused on what is reported to be the family with
some of the most intelligent bird species, corvids (jays, crows). They exhibit sophis-
ticated cognitive skills, some of which were previously reported only in primates.
For instance, caledonian crows have an exceptional purpose-oriented (food re-
trieval) tool manipulation/modification capacity (bending wire into hooks) (Weir
et al., 2002). Rook, Eurasian jay, and New Caledonian crow show as good a perfor-
mance in a causal cognition task (Aesop fable), as seven-year-old children (Logan
et al., 2014). Moreover, corvids have good spatial memory (Balda and Kamil, 1992),
have episodic-like long term memory (spatiotemporal) (N. S. Clayton and Dickin-
son, 1998), adapt food-storing strategies (Emery and N. Clayton, 2001), generalize to
guide behavior (Smirnova et al., 2015; Veit and Nieder, 2013) and can plan for the
future (Raby et al., 2007).

Some of the cognitive skills reported above, such as self recognition in the mir-
ror, episodic memory or future planning were thought to be present sparsely in
mammals, or only in humans. However, not all birds, just like not all mammals
have such sophisticated abilities. Taken together, this section aims to present the
diverse and sophisticated cognitive skillset birds possess. Of particular importance
for this manuscript is song production and learning, but also temporal represen-
tation (past and future).

Anatomy

Although they exhibit comparable capabilities, the anatomical structures of mam-
mals and aves differ significantly. For instance, the architecture and organization
of the avian telencephalon is quite different, appearing mistakingly more primi-
tive, so much so that birds were previously though to only possess a hypertrophied
striatum (Edinger et al., 1903). However, more recent neurochemical, histological,

30

2.1 Cognition and Anatomy in Birds

Figure 2.1: Comparative evolution of the striatum and pallium in vertebrates. The col-
ormap on the left reflects the presence of each of the three domains, pallium,
striatum and pallidum. From the figure, it is clear that the ratio of the brain
mass devoted to the pallium increase in parallel in various vertebrates’ taxa.
This figure was taken to illustrate subsection 2.1 from Boraud et al. (2018)

embriological and genetic evidence (Reiner et al., 2004) have shown the presence of
pallium, which is not laminated, but instead organized in nuclei. Based on what is
observed behaviorally, it appears that a laminated, 6 layered cortex (as we humans
possess) with pallial-cortical folding is not necessary for higher cognition and a
simpler nuclear pallial organization (Güntürkün, 2011; Jarvis et al., 2005) could be
and is also sufficient. Despite the distinction in presence and absence of lamina-
tion, the microarchitecture (dopaminergic projections, neurochemical, functional
and electrophysiological similarities between prefrontal cortex and nidopallium
caudolateral) and the allometric (relative size of forebrain) properties of the mam-
malian and avian forebrains are remarkably similar (Güntürkün, 2011).

In the light of more information about the avian anatomy, a group of researchers
(Jarvis et al., 2005) presented a new nomenclature for the avian telencephalon. It
concludes that the avian telencephalon is organized into three main, developmen-
tally distinct domains: pallial, striatal (medial and lateral dorsal; ventral: nucleus
accumbens and the olfactory tubercle) and pallidal domains (Jarvis et al., 2005). The
pallium is organized into four subdivisions, hyperpallium, mesopallium, nidopal-
lium and arcopallium and as in mammals, it comprises up to 75 percent of the
telencephalic volume (measured on the sagittal series of pigeon and zebra finch
brain sections) (Jarvis et al., 2005). The presence of such structures and such inves-
tigations suggest a convergent evolution (Boraud et al., 2018; Güntürkün, 2011) (Fig.
2.1) and significant similarities between birds and mammals.

31

2 Songbirds and Birdsong: Vocalizations and Timing

While the evolution of these two classes has occurred independently (Jarvis et al., 2005) as
their evolutionary lines separated almost 300 million years ago (Güntürkün, 2011), there is
clear evidence of convergent evolution 1, both in cognition and neural architecture (Gün-
türkün, 2011).

2.2 What do songbirds teach us about vocalizations?

In the sections above we advocated for birds being a good model to study different
aspects of cognition. Here, we try to convey that some birds, in particular, provide
an invaluable model to study verbal social communication, vocal production and
vocal learning. As a general introduction, birds are categorized into nonpasserine
(chickens, ducks, eagles) and passerine (perching) birds. Passerines are futher
divided into oscines (songbirds) and suboscines (manakins, flycatchers), where
only oscines (sparrows, robins, finches, corvids, cowbirds, lyrebirds) are vocal
learners, making them particularly interesting in studying vocal learning. Oscines
can be open-ended or close-ended learners. This is defined, respectively, by the
absence or presence of a critical period of plasticity in these birds. For instance,
in closed-ended learners, such as zebra finches, learning can occur only within a
particular (critical/ sensitive) period. Beyond this period, close- ended learners
cannot learn any new song elements and continue to produce highly stereotyped
vocalizations throughout their lives. On the other hand, open-ended learners,
such as nightingales, European starlings and canaries, can learn new songs and
vocalizations throughout their lives. In the sections below, we will focus on oscine
birds, and more particularly, on zebra finches.

2.2.1 Vocal production

There are two main groups of vocalizations produced by oscine birds: calls and
birdsong. The first, are brief and thought to be mostly innate, although learn-
ing/modification is possible in some species (Marler, 2004). They are considered
means of social communication that convey a vast range of messages, includ-
ing maintenance of social group coherence (contact and separation calls, Stack and
Tet), flight, food, agression ( Wsst), alarm ( Thuck, mobbing and distress), breeding,
mate attraction, territory defense etc. (Marler, 2004). They can also be combined in
different ways and slightly modified to adapt different information.

On the other hand, birdsong is a set of ordered strings of sounds separated by
brief silent intervals and lasts from a few seconds to many tens of seconds (A. J.
Doupe and Kuhl, 1999). Like human speech, birdsong is a complex acoustic sig-
nal, produced by the flow of air during expiration through the tight coordination
of vocal muscles. It is composed of notes or ’elements’, which combine to form

1Convergent evolution describes the acquisition of the same biologic trait in unrelated lineages of

organisms due to a similar selection pressure. (Güntürkün, 2011)

32

2.2 What do songbirds teach us about vocalizations?

Figure 2.2: Spectrogram of a birdsong, showing also the motif organization.

syllables, further combining to build phrases or ’motifs’. A motif refers to a stereo-
typed sequence within a song (Fig. 2.2). The elements of birdsong rely on different
timescales, with notes and syllables on the order of tens of milliseconds and sylla-
bles and phrases on the order of hundreds of milliseconds. These definitions are
suitable for birds with highly stereotyped songs such as zebra finches.

However, they do not fully apply to other birds with more complex organiza-
tion, such as bengalese finches and canaries. For instance, bengalese finches songs’
are composed of notes, which organize in chunks that are not stereotypical, i.e. a
note can be found in different chunks and some notes can be repeated multiple
times. Furthermore, these chunks are sung in a probabilistic manner. On the other
hand, in canaries, songs are organized in phrases, composed of trilled repetitions
of single syllables. The transitions between different phrases relies on long-range
complex syntactic rules.

Despite the particularities of different species, taken together, the similarities
with speech production, temporal control, vocal muscle coordination and sen-
sorimotor learning indicate similar neural mechanisms involved in speech and
birdsong. While comparable to speech, stereotypical birdsong (zebra finch) is
likely not comparable to language (Brainard and A. J. Doupe, 2002) in terms of the
boundless, flexible and complex meaning language can convey. Birdsong typi-
cally conveys information regarding the bird’s species, ancestry, age, identity and
reproductive fitness. It is used in courtship and in intrasexual contexts, to repel
rival males (Searcy and Andersson, 1986).

As stated above and as it will be detailed below, due to the similarities with
speech, songbirds and in particular zebra finches with their simple syntax and
song stereotypy are the most studied laboratory model to study vocal production
and learning. The male zebra finch is a close-ended learner, with a highly stereo-
typical song, spanning 0.5 to 1 second, and consisting of repetitions of a single
motif (Immelmann, 1969), composed of 3-7 syllables. Whereas only males can sing,
both sexes engage in calling for communication.

33

2 Songbirds and Birdsong: Vocalizations and Timing

2.2.2 Vocal learning

Vocal learning is a rare trait among the taxa, but it is widely common in about 4000
species of songbirds. Moreover, birdsong has a vocal learning process bearing an
uncanny resemblance to speech acquisition in humans. These similarities lie on
the vital importance of learning for song production, the necessity of both sound
perception and production (sensory and sensorimotor period) during learning and
the presence of a critical period in some species, like zebra finches (A. J. Doupe and
Kuhl, 1999). Songbirds and humans learn how to sing and speak, respectively in a
simplified two-staged process, composed of a sensory and a sensorimotor phase.
The sensory phase is characterized by listening to the tutor’s song and building
a memory of the song template. It is restricted to a sensitive (critical) period that
spans a few weeks, it occurs quite quickly (with only a few minutes exposure
to the tutor’s song) and could result in a long- term memory of the tutor song.
Due to the presence of an innate predisposition toward certain songs, usually the
ones from the same species and closer relatives (Mooney, 2009a), there is certain
variability in how this phase evolves (how quickly and how accurately). In the
absence of tutor exposure, the critical period (Eales, 1985) is postponed. If the tutor
continues to be absent, abnormal, ’isolate’ songs emerge (Marler, 1970), but in 3-4
generations, these ’isolate songs’ turn to species specific songs (Fehér et al., 2009b),
implying a species- specific genetic predisposition and a possible innateness of the
song.

In the sensorimotor phase, the bird starts producing vocalizations and relies on
auditory feedback to match its own song to the tutor’s song template. In zebra
finches, as shown in Fig. 2.3, the sensory period, lasting until 60 days post hatch
(dph) and the sensorimotor (30 - 90 dph) one overlap and further exposure is
granted.
In the sensorimotor period, the bird goes through two substages, the
subsong and the plastic song, where the first resembles child babbling, with no
apparent structure and the latter is a highly variable, highly plastic vocalization,
comprised of phrases and becomes more and more similar to the tutor song every
passing day. If this learning stage is compromised, for instance by post-exposure
deafening, the bird is not able to learn the tutor song (Konishi, 1985). This is both
due to the need for tutor sensory input and due to the need of sensory input
coming in the form of a feedback from the bird itself.

If the first two stages remain uncompromised, song variability gradually re-
duces until vocal learning is finalized with the crystallized song, which is a stereo-
typical vocalization containing very little variability. The bird continues to re-
ceive auditory feedback to maintain the song similar to the template. When it
is deafened after learning, there is visible song deterioration (K. W. Nordeen and
E. J. Nordeen, 1992). Additionally, it has been shown that behavioral modifications,
targeting pitch (Andalman and M. S. Fee, 2009) and duration (Ali et al., 2013) can be
learned. Taken together, these evidence insinuate active maintenance of the song,
i.e. the bird always improves the proximity of his song to the template through a
continuous auditory feedback and that there is something in this auditory input

34

2.2 What do songbirds teach us about vocalizations?

perception that prevents it from learning new song elements (Vallentin, Kosche, et
al., 2016) and/or modifying existing ones. Moreover, in the context of chapter 1,
we would like to emphasize that song learning comprises learning a set of features
related to the tutor’s song, one of which is the precise timing within and between
syllables. This is what we referred to as pattern timing, in chapter 1.

Intrinsic constraints

If exposure to a tutor is what drives song learning, does this mean any song can
be learned? There appear to be certain species specific constraints, some of which
are related to respiratory circuits and some to genetic predisposition. A series
of experiments have investigated the two, and observed that when songbirds are
exposed to their parent’s song, a conspecific tutor’s song and a different species
song, there are differences in the learning outcome (Konishi, 1985; Marler, 1997;
Marler and S. Peters, 1977). Another important evidence is that isolate birds (birds
without tutors) living in a colony, after 3 or 4 generations can give rise to a species
typical song (Fehér et al., 2009b). Another study has shown that while syllable
coding is experience dependent, temporal gap coding is innate (Araki et al., 2016b).

Adult Plasticity

Although close-ended learners do not learn new song elements in adulthood, they
still have the ability to introduce slight modifications to their song (Tumer and
Brainard, 2007; Warren et al., 2011). Behavioral adaptation has been demonstrated
through a Conditional Auditory Feedback (CAF) paradigm in two song features,
namely pitch and duration. CAF aims to increase or decrease the duration (pitch)
of a target syllable. The targeted (pitch or durations) acoustic feature is computed
live while the bird is singing, and feedback is delivered accordingly, i.e. when
the bird sings outside a ’desired range’, white noise is given. More specifically,
white noise is presented as a perturbatory stimulus every time the target syllable’s
performance was lower (higher, depending on the protocol) than a dynamically
changing threshold.

The threshold is set by acquiring a set of baseline distributions prior to starting
the protocol and is changed based on the mean duration/pitch across trials. The
initial threshold is set at approximately a third of the distribution. When subjected
to such a protocol, the birds try to evade white noise by altering their songs and
after several trials across days, the bird shifts the duration (pitch) distribution by
about 2 to 3 standard deviations. In the duration protocol (Ali et al., 2013; Pehlevan
et al., 2018), a specificity to the target syllable in the acquired modification was
observed, i.e. no change was observed on any of the other syllables.

35

2 Songbirds and Birdsong: Vocalizations and Timing

Figure 2.3: Stages of vocal learning in zebra finches and humans, shown in a logarithmic

scale.

2.2.3 Parallels with Human Speech

As briefly stated above, there are similarities between birdsong and human speech.
Broadly, they are both complex acoustic signals, composed of three main dimen-
sions: time, frequency and intensity. During vocal production, speech and bird-
song rely on air expiration generating a complex waveform, through the vocal
cords in the larynx and the syrinx, respectively. In humans, the waveform is then
modified (filtered) by the rest of the vocal tract (Stevens, 1994), whereas in birds
there is evidence that the width of beak opening has a similar role and affects
sound frequency (Westneat et al., 1993). The basic vocalization units (phonetic unit
and note respectively) are grouped to form ’basic processing units’, the syllables
or phrases, which are then placed in order and separated by brief intervals (gaps).
Such order is referred to as song syntax in the songbird literature and remotely
corresponds to grammar. Lastly, they both rely on timing on different timescales,
the one of the building units and the one of the sequence (motif, phrase, sentence).
Vocal learning in both taxa also presents with a lot of similarities. For instance,
both taxa have critical periods, during which they learn through imitation of an
adult tutor. They heavily rely on auditory feedback and several stages of learning
(sensory, sensorimotor and motor) are present in both, as shown in Fig. 2.3. More-
over, the same gene, FoxP2, is linked to developmental vocal learning in humans
(Lai et al., 2001) and songbirds (Haesler et al., 2004).

Several intrinsic constrains and predispositions in vocal learning have been ob-
served in songbirds and humans (A. J. Doupe and Kuhl, 1999). Although some of
these are attributed to the physical apparatus, the repertoire of sounds is still
quite large, i.e. a wide range of vocalizations can be generated. Hence, other
mechanisms could also be involved, such as reported innate sensory recognition
and learning preferences (A. J. Doupe and Kuhl, 1999). Moreover, similar to isolate
songs produced by songbirds, children exposed ’pidgin’ languages and deaf chil-

36

Days101102103HatchBirthSensorySensori-motorSong is crystallizedFirst sounds startPlastic song startsNon-speech soundsBabbling soundsFirst wordsSensorySensori-motorFirst sentencesVocal-like sounds2.3 Neural Networks for Song Perception and Production

dren not exposed to sign language (Goldin-Meadow and Mylander, 1998), develop
some elements (words or gestures) and order them somewhat conforming to a
rudimentary grammar.

Lastly, a social factor is also present.

In the language literature, it has been
referred to as a social gating mechanism, driving children to only learn sounds
coming from human sources (Kuhl, 2004; Kuhl, 2007). Zebra finch, as a highly social
songbird, also relies on social features (who is feeding them) to choose their tutor.
Interestingly, they can override their innate conspecific song preferences and learn
the song of a bengalese finch, if they are the ones feeding them (Immelmann, 1969).

2.3 Neural Networks for Song Perception and

Production

Given the behavioral similarities detailed above, the birds present a good model to
investigate neural dynamics underlying different tasks, which may present with
seemingly more complex brain network in mammals and/or commonly used an-
imal models. In particular, in mammals, upon studying a sensorimotor skill, such
as speech production and its learning, complex interactions between cortical areas
(primary and secondary motor cortex in rodents, motor, premotor and supple-
mentary motor areas in primates) related to many different sensorimotor associ-
ations and motor skills are present (Dum and Strick, 2002). Conversely, in birds,
the sensorimotor skill of song production and its learning has a dedicated set of
interconnected brain nuclei known as the “song system”, coordinating patterned
breathing and vocal muscle activity necessary for vocalization. The simplicity of
this system makes them an outstanding model to study the neural mechanisms
of vocal learning and more generally, of sensorimotor learning (Brainard and A. J.
Doupe, 2002).

The neural circuitry underlying this mechanism has three main building blocks:
(i) the auditory pathway, responsible of the sensory acquisition of the song from
tutor exposure and of auditory feedback to the system to maintain the crystallized
song (Brainard and A. J. Doupe, 2002), (ii) the Anterior Forebrain Pathway (AFP)
entailing initial song learning, subsong generation, maintenance and variability in
adult song and (iii) the motor pathway responsible for the production of the adult
song. The last two constitute the ’song system’.

2.3.1 Auditory Pathway

The communication between the auditory system and song system is crucial for a
vocalization so heavily reliant on auditory feedback, such as birdsong. As shown
in Fig.2.4, auditory input enters the song system through nucleus interfaciallis of
the ndiopallium (NIf) and HVC. The anatomical connections, could help under-
stand the sensorimotor integration during song learning, and moreover during
maintenance and adaptation. For instance, area caudomedial nidopallium (NCM)

37

2 Songbirds and Birdsong: Vocalizations and Timing

Figure 2.4: Anatomy of the Auditory and Song System in Zebra Finches (A) Simplified
schema of the song system. (Luo and Perkel, 1999) (B) Summary of (most of)
the neural substrates of song perception and production (Sakata and Yazaki-
Sugiyama, 2020). Some parts of the ascending auditory pathway and the cere-
bellum; midbrain and hindbrain catecholaminergic areas are not included. The
abbreviations used are detailed in Table 2.1.

is hypothesized to be affiliated with the formation and storage of tutor song mem-
ories, providing a template for comparison during song learning. On the other
hand, nucleus avalanche (Av) transmits motor signals to the auditory system. Be-
low, we briefly explain the anatomy and the homologies with mammals. The
abbreviations used are detailed in Table 2.1.

Auditory information comes from the ascending auditory system (cochlea- hind-
brain cochlear nuclei - auditory nerve- auditory midbrain) through the auditory
thalamus nucleus Ov, which projects to Field L (analogous to the primary audi-
tory cortex) and then to the higher auditory areas CM (caudal mesopallium) and
NCM (caudo-medial nidopallium). It reaches the song system through NIf and
HVC. Moreover, in the ventral CM, nucleus Avalanche (Av) receives input through
the auditory thalamic nucleus uvaeformis (Uva) and has bidirectional connections
with both NIf and HVC (Akutagawa and Konishi, 2010). A loop between the auditory
and motor areas is formed. In this loop, HVCAv neurons, have an important role
in integrating motor-related signals with activity in the auditory system. Exper-
imental evidence with ablations have confirmed the existence of this link during
learning and adaptation of song timing (Roberts et al., 2017). The detailed pathways
and their respective intersection with the song system are illustrated in Fig. 2.4.

Several of these structures are homologous to auditory structures in mammal.
For instance, the ascending auditory pathway of songbirds is homologous to that
observed in other vertebrates: cochlea- hindbrain- midbrain-thalamus-cortex. The
avian auditory midbrain is homologous and functionally analogous to the mam-

38

Auditory SystemSong SystemA.B.2.3 Neural Networks for Song Perception and Production

malian central nucleus of the inferior colliculus (ICc). Moreover, the avian audi-
tory thalamus Ov is homologous to the ventral division of the mammalian medial
geniculate body. Field L2, which receives the most thalamic input in songbirds
is homologous to layer IV of the primary auditory cortex in mammals. Other
higher-order auditory areas included in the diagram are referred to as higher cor-
tex (Woolley and Portfors, 2013).

Abbreviation Structure name
Ad
AFP
Area X
Av
CLM
DLM
DTZ
HVC
HVCAv
HVCRA
HVCX
LC
LMAN
NCM
NIf
Ov
PAG
RA
Uva
VP
VTA

Dorsal arcopallium
Anterior forebrain pathway
vocal portion of the basal ganglia
Avalanche, a ventral region in CLM
Caudolateral mesopallium
Dorsal thalamic zone
Dorsal thalamic zone
Used as proper name
HVC cells that project to Av
HVC cells that project to RA
HVC cells that project to X
Locus coeruleus
Lateral magnocellular nucleus of anterior nidopallium
Caudomedial nidopallium
Nucleus interfacialis of the nidopallium
Nucleus ovoidalis
Avian periaqueductal gray
Robust nucleus of the arcopallium
Nucleus uvaeformis
Ventral pallidum
Ventral tegmental area

Table 2.1: Abbreviations used to refer to avian brain structures.

2.3.2 Anterior Forebrain Pathway (AFP)

The anterior forebrain pathway (AFP) is a basal ganglia-thalamic- cortical circuit
that indirectly connects HVC and RA. It contains the avian basal ganglia nucleus
Area X, the medial portion of the dorsolateral thalamic nucleus (DLM), and the
lateral magnocellular nucleus of the anterior nidopallium (LMAN). In oscine song-
birds, AFP is essential for vocal learning and plasticity (A. Doupe et al., 2005). The
hypothesized functions can be grouped into three, comparison with the song tem-
plate, generation of motor variability, and computation of error or instructive sig-
nal.

Area X could be involved in template memorization or matching. This is sup-
ported by evidence showing that suppression of FoxP2 in area X during tutor
exposure and sensorimotor learning, impairs imitation (Haesler et al., 2004). It also

39

2 Songbirds and Birdsong: Vocalizations and Timing

is at the receiving end of a lot of dopaminergic projections from VTA and substan-
tia nigra pars compacta (SNc), which implies a role for dopamine in song learning
(Doya and Sejnowski, 1998), consistent with its role in motor learning in mammals.
On the other hand, the function of LMAN mostly lies on variability generation
across the sensorimotor period and adulthood. It is considered the essential pre-
motor nucleus for babbling (Aronov et al., 2008), as the HVC RA pathway is not
strongly developed yet and exploration by LMAN drives its further consolidation.
In subsong, only 10 percent of HVCRA neurons burst rhythmically and they are
mostly aligned to syllable onset (Okubo et al., 2015).

The role of AFP in song production grows lesser as crystallization occurs and it
seems to be only important for the minimal variability present in adult song. For
instance, area X lesions during the sensorimotor period, cause a failure in song
stabilization and LMAN lesions cause the song to stabilize prematurely (Bottjer et
al., 1984; Ölveczky et al., 2005; Scharff and Nottebohm, 1991; Sohrabji et al., 1990). Con-
versely, AFP lesions in adulthood have less disruptive effects. Experiments using
a CAF paradigm, suggest that LMAN provides biased instructions, to avoid vocal
errors (Andalman and M. S. Fee, 2009), consistent with a role in auditory feedback-
dependent song plasticity. This is supported by the absence of song deterioration
in deafened birds with a lesioned LMAN (Bottjer et al., 1984; Scharff and Nottebohm,
1991).

In figure 2.4, the connections within the AFP and the reset of the song system
are illustrated. The initial projections come to the AFP from HVC through the X
projection neurons. Then, the GABAergic neurons in area X send excitatory and
inhibitory projections to the medial nucleus of the dorsolateral thalamus (DLM).
This then sends projections to the lateral portion of the magnocellular nucleus of
the anterior nidopallium (LMAN). LMAN send projections both to area X and RA.
The AFP is homologous to the basal ganglia-thalamic-cortical circuit in mam-
mals, where area X is homologous to the mammalian basal ganglia (A. Doupe et
al., 2005) and LMAN is functionally analogous to parts of the mammalian frontal
cortex (Pfenning et al., 2014; Reiner et al., 2004). Moreover, the thalamic DLM neu-
rons show thalamic properties and their projections to LMAN are glutamatergic,
corresponding to the mammalian thalamocortical projections.

2.3.3 Motor Pathway

The motor pathway is a direct pathway connecting HVC to Robust Nucleus of the
Arcopallium (RA). RA provides motor input to motor neurons in the tracheosy-
ringeal portion of the hypoglossal motor nucleus (XII). The syringeal muscles are
innervated and sound is produced. It also sends input to the respiratory premotor
neurons in the ventral respiratory group, which contains the expiratory nucleus
retroambigualis and the inspiratory nucleus parambigualis. These inputs, project
back to the thalamus and HVC (Brainard and A. J. Doupe, 2013; Schmidt et al., 2011).
The information transmission delay from HVC to RA is ∼5 ms (R. Hahnloser et al.,
2002) and the one from HVCRA to the output ∼ 15-20 ms (A. A. Kozhevnikov and

40

2.3 Neural Networks for Song Perception and Production

Figure 2.5: Brain pathways involved in birdsong and speech production In black arrows
the motor pathway, in white arrows, the AFP. In dashed black, the connections
between the AFP and motor pathway, and in red arrows the direct projection
from vocal motor cortex to vocal motor neurons. a indicates auditory, m motor
and m/a both auditory and motor neural activity. Some connections in the
human brain are proposed based on known connectivity of adjacent brain re-
gions in non-human primates. Taken from Pfenning et al. (2014). 2

M. S. Fee, 2007) or 35 ms (Ali et al., 2013). As briefly mentioned above, this pathway
develops later compared to the AFP and is not present during babbling and sub-
song. It only appears during plastic song. As its influence gets stronger and as
input from LMAN grows weaker, there is a decrease in song variability until song
crystallization is reached. The role of this pathway in song production is crucial,
as lesions either severely disrupt it, or abolish it (Nottebohm et al., 1976; Scharff, Kirn,
et al., 2000; Simpson and D. Vicario, 1990).

As we will detail below, HVCRA neurons burst only once during the ∼1 sec-
ond motif, with a brief duration of ∼10 ms.
In contrast RA neurons fire more
frequently, up to 10 times per motif, which suggests multiple HVC neurons send
converging input to multiple RA and single HVC neurons diverging input to mul-
tiple RA neurons (Mooney, 2009a). RA bursts are on average uncorrelated to spec-
tral features of the song (Leonardo and M. S. Fee, 2005). However, there is likely some
structure there as well, as birds exposed to the same tutor were shown to have sim-
ilar patterns of bursting activity (Mooney, 2009b). Also, an important feature of RA
is its position at the convergence of HVC and LMAN input, suggesting that this

2A1–L4: primary auditory cortex—layer 4, Am: nucleus ambiguous, aSt: anterior striatum, LMC:
laryngeal motor cortex, LSC: laryngealsomatosensory cortex, MN: motor neurons, MO: oval
nucleus of the anterior mesopallium, v: ventricle space.

41

2 Songbirds and Birdsong: Vocalizations and Timing

is the area where song variability and the biased exploration during learning is
induced.

HVC is functionally analogous to the premotor cortex in mammals and RA is
analogous to the vocal motor region of the primary motor cortex in mammals
(Fujimoto et al., 2011; Hara et al., 2012). An illustration of the homologies and analo-
gies in motor and anterior forebrain pathways between songbirds and humans is
presented in Fig.2.5.

2.4 Anatomical Substrates of Motor Timing In

Songbirds

2.4.1 A Local Motor Timing System: Premotor Nucleus HVC

HVC (proper name), formerly called the hyperstriatum ventrale, pars caudalis
and then the high vocal center, is an avian nucleus functionally analogous to the
premotor cortex in mammals. HVC receives auditory input and lies at the inter-
section of the motor and anterior forebrain pathway. Its position justifies its role in
song perception (Margoliash, 1997), production (Nottebohm et al., 1976) and learning
(Roberts et al., 2017). Interestingly, song perception (of the birds own song) and pro-
duction incite similar firing patterns in HVC (Mooney, 2000; J. Prather et al., 2008).
The implicated neurons (HVCX) are referred to as auditory-vocal mirror neurons
(J. Prather et al., 2008) and are similar to the visual- motor mirror neurons first in
the premotor cortex of macaque monkeys (Gallese et al., 1996). They are thought to
be important in social learning.

In the context of learning, in ’the AFP template comparison’ hypothesis, HVC
is proposed to be a source of live auditory input (Mooney, 2004; J. Prather et al.,
2008) sent to area X, where it is compared to the song template stored in AFP.
Other hypotheses of learning, suggest HVC provides a centrally generated effer-
ence copy that serves as an internal prediction of the feedback (Troyer and A. J.
Doupe, 2000), or gives a global time representation, as a timing generator (M. Fee
and Goldberg, 2011). HVC’s role in learning is supported by multiple experimental
studies, showing high dopamine concentrations in HVC while listening to a live
tutor and inhibition of song learning upon their manipulation (Tanaka et al., 2018).
The main hypothesis we address in the thesis is the one related to HVC as an
area important to song production and learning, in the temporal domain (Ali et
al., 2013; R. Hahnloser et al., 2002; Pehlevan et al., 2018). The first evidence of such a
role was provided by focal stimulation (E. Vu et al., 1994) in HVC, which disrupted
song sequencing. Moreover, brief neuronal bursts in a particular subpopulation
(HVCRA), time-locked to the song were reported (R. Hahnloser et al., 2002). To follow
the trail of HVC’s role in motor timing, a cooling study was performed and as
hypothesized, slowing down of both sequence and song was observed (Andalman,
Foerster, et al., 2011; Long and M. S. Fee, 2008). Hence, HVC was positioned as local
network encoding temporal control. However, other studies have hypothesized a

42

2.4 Anatomical Substrates of Motor Timing In Songbirds

Figure 2.6: The HVC Microcircuitry: The connections within HVC and their outside pro-

jections. Taken from (Murphy et al., 2020)

distributed network, where Uva, brainstem and RA could be organized (in a loop)
to control motor timing (Hamaguchi, Tanaka, et al., 2016).

HVC Microcircuitry

There are four main types of cells in HVC, HVCRA neurons, HVCX neurons,
HVCAv and interneurons (Fig. 2.6). As the name implies they project to RA, X
(analogous to basal ganglia) and nucleus Avalanche respectively. Below, we detail
important information for each of these subpopulations.

HVCAv neurons project to nucleus Avalanche, which provides feedforward and
feedback information between the auditory pathway and the song system, through
bidirectional connections with HVC. HVCAv cells exclusively receive input from
HVCRA cells, suggesting a possible role for them in song-timing. Ablation studies
in juveniles have revealed problems with imitation of the song as a sequence and
less visible problems in individual syllable learning. In deafened adults with Av
lesions, temporal features were not affected, in contrast with spectral ones. More-
over, HVCAv cell lesions interfere with the rate of learning and recovery (return)
of normal song timing in a CAF paradigm (Roberts et al., 2017). Together, these
findings reveal an important role of HVCAv neurons in learning and adaptive
modification of song timing.

HVCX neurons are another class of neurons in HVC, which project to area X
and furthermore activate the AFP, a basal ganglia pathway necessary for vocal
plasticity. They fire quite regularly with moderate spike-frequency adaptation
in response to a tonic input (Mooney and J. F. Prather, 2005). These neurons are
considered mirror neurons, showing similar responses to syllable perception and
production (J. Prather et al., 2008). During singing, multiple bursts of these neurons,
precede similar elements of the syllable patterns by ∼40ms, suggesting a relation
with temporal features. However, there seems to be no relation between their
activity and song spectral features. Moreover, no auditory responses were present

43

2 Songbirds and Birdsong: Vocalizations and Timing

in these neurons during singing (A. A. Kozhevnikov and M. S. Fee, 2007). Hence,
although previous hypotheses have implicated them in transmission of auditory
information (both spectral and temporal) to the AFP during singing, more recent
evidence suggests that it rather transmits information about sequence timing (A. A.
Kozhevnikov and M. S. Fee, 2007).

Possibly the only inhibitory source in HVC, interneurons fire densely and rel-
atively continually during the song. Together with X projection HVC neurons,
they fire in alternating phases of a local 30 Hz rhythm (Markowitz et al., 2015). In-
terneurons are connected to both RA and X projecting HVC neurons (Mooney and
J. F. Prather, 2005), suggesting an impact in song production, which has been shown
through pharmacological studies (blockade of GABAA conductances) (Kosche et
al., 2015). Vallentin, Kosche, et al. (2016) also showed that they are significantly cor-
related with song imitation accuracy and their maturation is performance rather
than age dependant. They futher hypothesize that their maturation has an effect
on the critical period, and its inhibition could allow continued (adult) learning,
like in open-ended learners.

HVCRA neurons are likely the most important class in HVC for song production,
since they project to the motor nucleus RA. However, as shown in Fig. 2.6 and
detailed above, they lie inside a circuitry, so their activity is related to the activity
of other neurons in HVC. HVCRA emit bursts of one to several action potentials
in response to a tonic input (Mooney and J. F. Prather, 2005) and burst only once
in a motif during singing. They fire time-locked to the song, always at the same
time across multiple renditions, with a jitter of less than a millisecond. The bursts
contain 3-6 spikes and a duration of 10 ms (R. Hahnloser et al., 2002). This is
illustrated in the experimental raster plot by R. Hahnloser et al., 2002, shown in Fig.
2.7. Moreover, their activity spans the whole song, creating a neuronal mapping
thereof (Lynch et al., 2016).

2.4.2 A Distributed Motor Timing System in Songbirds?

In the section above, we have presented several experimental findings suggesting
a role of HVC is song production and learning, focused on the temporal domain.
Moreover, we have detailed the roles of individual populations, which support
such a function. However, although HVC is mostly accepted as a timing-related
area, how much of this role (motor timing) can be attributed solely to this nucleus,
remains an open discussion. Other upstream areas, could be affecting HVC input
and be the ones actually ’driving’ time. Since during singing HVC is only affected
by motor input, the possible contributing areas are limited and the proposed dis-
tributed timing mechanisms focus on the roles of NIf or Uva on HVC.

NIf (nucleus interface of the nidopallium) is a significant source of auditory
input to HVC and also plays an important role during sleep (R. H. Hahnloser and
It is located in Field L, which is the avian homologous of the
M. S. Fee, 2007).
primary auditory cortex. NIf precedes introductory notes by several milliseconds
(McCasland, 1987) and hence may have a premotor role. A study, which pharma-

44

2.4 Anatomical Substrates of Motor Timing In Songbirds

Figure 2.7: HVCRA (N = 8) time-locked activity to the song and HVCI (N = 2) neurons.
Raster plots of several song renditions in a single bird. Each row is one ren-
dition and 10 renditions are shown for each neuron. The activity is aligned to
the onset of the nearest syllable. Taken from R. Hahnloser et al. (2002).

cologically inactivated NIf (Naie and R. Hahnloser, 2011) has shown that the effect
is different in juvenile birds singing subsong, those singing plastic song and adult
birds. In the latter, there is only a transitory effect, which decreases song stereo-
typy (by 10%) and destabilizes syllable sequences (Cardin et al., 2005; Naie and R.
Hahnloser, 2011). These results suggest that although present, NIf is not essential
for song production in adults.

On the other hand, several hypotheses have been proposed on the role of Uva in
motor timing during song production as a possible higher structure, guiding the
HVC sequence. More distinctively, Elmaleh et al. (2021) presented three hypotheses
of Uva generated input affecting sequence production, (i) in a continuous pattern,
(ii) in a more discrete pattern, i.e. at every syllable and (iii) not significantly, as lo-
cal HVC connections are able to maintain sequence generation independently. In
that study, in anesthetized birds, where sleep replay of the sequence is observed,
they lesion Uva and observe that the sequence remains unaffected, revealing im-
portant information of network connectivity, although only during sleep. In an-
other more recent study (Moll et al., 2023), Uva driven neurons were identified in
HVC during singing. They are always active at syllable initiation or/and ending
and constitute about 15% percent of the HVCRA neurons. This suggests that Uva
may be an upstream control of HVC. Due to its temporal pattern, it could likely
have a synchronizing activity on the two HVC. This is consistent with previous

45

2 Songbirds and Birdsong: Vocalizations and Timing

hypotheses, derived from Uva lesions (Coleman and E. T. Vu, 2005; H. Williams and
D. S. Vicario, 1993) and stimulations (E. Vu et al., 1994).

2.4.3 Plasticity of Motor Timing

Upon discussing the roles of different pathways, we have heavily relied on AFP
as a song learning pathway. As previous evidence have suggested, in a CAF ex-
perimental paradigm targeting syllable-level pitch adaptation, this pathway was
indeed involved. This was clearly demonstrated through lesions in LMAN and
area X, which compromised song plasticity. However, interestingly, this was not
the case when duration was targeted for modification (Ali et al., 2013). Lesions in
LMAN, MMAN and area X had very little to no effect on syllable modification,
suggesting a different learning mechanism is present in the temporal domain.

To investigate this further, the authors performed recordings in HVC during
the CAF protocol, which revealed that HVC activity reflects the temporal changes
observed in the song (but not the spectral ones). Their recordings show a local
stretching/shrinkage of the temporal structure at the level of a syllable targeted for
modification. The duration of the song segment and its modification is a function
of the speed of the activity propagation. Taken together with the very small effect
of AFP, these findings suggest that the synaptic changes driving the change in
activity propogation and furthemore interval length, are likely occurring at the
level of HVC itself.

Hence, the role of HVC in motor timing and its plasticity provides an excellent
framework to study the robustness and flexibility of motor timing. These features
are critical in the performance and refinement of many motor skills (including,
but not limited to vocal production), not only in songbirds, but also in humans.

46

3 Models of Subsecond Motor
Timing in Neuroscience

.
3.1 General Models .
3.2 Models of HVC .
.
3.3 Attractor Networks .

.
.

.
.
.

.
.
.

. . . . . . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . . . .

47
51
52

In the first two chapters, we motivated the broader question and illustrated the
characteristic properties of the biological model appropriate to address it. To
briefly summarize, in chapter 1, we highlighted the importance of motor timing
on the scale of tens to hundreds of milliseconds for a wide range of tasks, ranging
from simple eyelid conditioning to complex tasks like playing the piano or speech
production. Moreover, we defined timing tasks as those that require some sort
of timing device to solve, like interval/duration discrimination, production and
reproduction etc. Among those tasks, speech production is an example of pattern
timing, which involves two different scales, one at the level of the syllables and one
at the level of the sentence (sequence). Furthermore, in Chapter 2, we presented
a biological model, songbirds as an example of vocal production very similar to
humans’. As such, it highly depends on precise timing, encoded in the premo-
tor nucleus HVC, and it is studied by a number of experimental investigations.
Behavioral and electrophysiological studies have revealed important information
about the underlying circuitry, however, some questions remain unanswered. In
this setting, the benefit of computational modeling is significant. It can add sup-
plementary information, while being able to investigate time-consuming and/or
experimentally non-testable hypotheses. Moreover, it can guide future experi-
mental paradigms through predictions, and can help understand the underlying
mechanisms. In this chapter, we will first explore the general models of subsecond
motor timing and then we will focus on the ones used for HVC. Lastly, we include
a section on attractors as an alternative modeling approach.

3.1 General Models

As briefly discussed in Chapter 1, timing models can be split into two broad classes
(i) dedicated or (ii) intrinsic systems (R. Ivry and Schlerf, 2008). A series of models
pertaining to one or the other, have been designed. These include the pacemaker

47

3 Models of Subsecond Motor Timing in Neuroscience

accumulator models (Creelman, 1962), the scalar expectancy theory (Gibbon, 1977),
multiple oscillator models (Buhusi and Meck, 2005; Church and Broadbent, 1991; M. S.
Matell and Meck, 2004; Miall, 1989), multiple neuron models (Grossberg and Schmajuk,
1989; Moore et al., 1989; Staddon and Higa, 1999), ramping models (Gavornik, Shuler, et
al., 2009; Reutimann et al., 2004; Simen et al., 2011), population clocks (D. V. Buonomano
and M. D. Mauk, 1994; Liu and D. V. Buonomano, 2009) etc. Each of these classes
of models has one or few representatives. We have focused only on the ones
aiming to model motor timing (as opposed to perceptual timing), even though the
same principles and sometimes models can apply. Table 3.1 illustrates the main
representative(s) and characteristics of each of these model classes.

Pacemaker- Accumulator Model

The first models of timing on the scale of hundreds of milliseconds and seconds
were pacemaker-accumulator models (Creelman, 1962; Treisman, 1963). The prin-
ciple of these models is simple and similar to a man-made clock, with one pace-
maker generating neural pulses and an accumulator assembling them. Such mech-
anism creates a linear measure of duration based on the number of accumulated
ticks. The frequency of tick generation has been a subject of debate, pertaining the
mechanism with which it is determined. For instance, a constant frequency would
suggest a very objective/perfectly ’accurate’ timing mechanism, similar to having
an actual clock, which experiments and our personal experience demonstrate not
to be the case. This clock is likely affected by a number of factors.

Another model in this class and by far, the most influential is referred to as
the scalar-expectancy theory (Gibbon, 1977), containing (i) a clock compartment
with an attentional switch, (ii) a comparison compartment between (a) the work-
ing memory, where the representation of the duration is transferred and (b) the
reference standard in the long-term memory and (iii) a decision making compart-
ment. Regarding the frequency of neural ticks, throughout the years evidence has
shown that the rate of the pacemaker changes with respect to a multitude of exter-
nal (stimulus intensity, pharmacological manipulations (Meck, 1983)) and internal
factors (attention (Lejeune, 1998), fatigue, body temperature (Wearden and Penton-
Voak, 1995), excitement, boredom, switch latencies). The standard pacemaker-
accumulator models find little support in biology, because they are not very con-
sistent with experimental findings and imply a dedicated system through a mech-
anism, the anatomical correlates of which remain unknown (Buhusi and Meck, 2005;
M. Mauk and D. Buonomano, 2004).

Striatal Beat Frequency Model

The Striatal Beat Frequency (SBF) model, part of the multiple oscillator model
class, is comprised of cortical ’time-keeping’ neurons’ oscillating across varied fre-
quencies and striatal spiny neurons acting as coincidence detectors. This model

48

3.1 General Models

is designed to encompass the primary brain areas suggested to play a role in mo-
tor timing, specifically the frontal cortex and the basal ganglia (Buhusi and Meck,
2005; M. S. Matell and Meck, 2004). The SBF is reported to be consistent with record-
ings and behavioral findings (M. Matell et al., 2003) and it reproduces the scalar
property of timing. However, the sequential activity observed in striatal neurons
during timing tasks (Gouvêa et al., 2015) seems highly unlikely to play the role of a
coincidence detector.

Multiple Neuron Models: Spectral timing/ Labeled line

The spectral timing (Grossberg and Schmajuk, 1989) or labeled line model, assumes
a broad range of time constants distributed along a spectrum. This model was
initially developed based on the neural characteristics of the hippocampus. How-
ever, it has also been used to model conditional response timing in the cerebellum,
assuming different time constants for the granule cells (Bullock et al., 1994), or in a
later model, differently timed calcium responses in Purkinje cells (Fiala et al., 1996).
In this model, depending on the time interval between unconditional and condi-
tional stimulus, different synapses are reinforced, either the ones with fast or slow
membrane dynamics.

Ramping/ Climbing Model

Ramping models (Balci and Simen, 2016; Durstewitz, 2003; Simen et al., 2011) propose
that time is encoded in the monotonic changes in firing rate and that actions are
produced when the firing rates reach a threshold value.
It is resemblant of a
pacemaker-accumulator model, with tonic pulses (Paton and D. V. Buonomano, 2018).
The generated patterns are highly similar to the ones observed in different areas of
the brain during motor timing tasks. A large number of data shows such ramping
activity in the prefrontal cortex (Niki and M. Watanabe, 1979), premotor and motor
cortex (Mita et al., 2009; Murakami et al., 2014) and the parietal cortex (Jazayeri and
Shadlen, 2015), suggesting that this is a highly probable underlying mechanism for
motor timing. However, it is not clear whether ramping activity encodes time, or
it, instead reflects motor preparation, and whether it is the output of upstream
timing circuits.

Population Clock Model

Population clock models assume that time is both generated and represented (Kar-
markar and D. V. Buonomano, 2007) in the dynamically changing population of neu-
rons. First proposed in the context of the cerebellum (D. V. Buonomano and M. D.
Mauk, 1994), this model suggests specific patterns of activity encode specific in-
stances of time and trained output units recognise them to provide a readout (D. V.
Buonomano and Laje, 2010). Hence, the clock is an emergent property of the network
and the population clock speed covaries with the readout. This is consistent with

49

3 Models of Subsecond Motor Timing in Neuroscience

Class
Pacemaker Accumulator Pacemaker Accumulator Model

Models of Timing

(Creelman, 1962)

Mechanism
Clock (Pacemaker, Switch and Accumu-
lator)

D/I
D

Scalar Expectancy Theory (SET)
(Gibbon, 1977)

Clock (Pacemaker, Switch and Accumu-
lator), Memory, Comparison between the
two

Multiple Oscillators

Connectionist Model (Church and
Broadbent, 1991)

tracking the half phase of a series of oscil-
lators (clock stage) and continually com-
paring the phase of these oscillators to
a memory for the phases of these same
oscillators on previously reinforced trials
(memory stage)

Beat Frequency (BF) (Miall, 1989) Oscillations of Different Frequencies

Striatal Beat Frequency (SBF)
(Buhusi and Meck, 2005; M. S.
Matell and Meck, 2004)

Oscillations of Different Frequencies and
coincidence detectors: spiny neurons of
the striatum

Multiple Neuron

Memory Decay (Staddon and
Higa, 1999)

Multiple timescales, Gaussian activation
model, Temporal decay model, coupled
leaky integrators

Spectral
Schmajuk, 1989), Labeled Line

timing (Grossberg and

neurons can respond to the CS with
a broad range of time constants (hip-
pocampus)

Tapped delay line (Moore et al.,
1989)

time-varying activity by arranging neu-
rons in a chain so that each synapse adds
a discrete delay to the signal

Ramping/ Climbing

based

Models
Ramping
(Gavornik, Shuler,
et al., 2009;
Reutimann et al., 2004; Simen et al.,
2011)

monotonic changes in firing rate, and
that an actions are produced when the
firing rates reaches a threshold value

Population Clock

Mauk cerebellum (D. V. Buono-
mano and M. D. Mauk, 1994)

Unique spatial pattern of activity in a
neural network

Synfire Chain (Abeles, 1982; Liu
and D. V. Buonomano, 2009)

Sparse Population Clock, Feedforward
Network

D

D

D

D

D

D

D

D

I

I

Table 3.1: Computational Models of Timing. The first three classes of timing are based
on the review from (M. S. Matell and Meck, 2004). Further information included
information comes from different reviews on motor timing in the subsecond
scale, the main three being: (Addyman et al., 2016; M. S. Matell and Meck, 2004;
Medina and M. D. Mauk, 2000; Paton and D. V. Buonomano, 2018). D stands for
dedicated systems and I for intrinsic or distributed systems.

50

3.2 Models of HVC

experimental findings (Bakhurin et al., 2017; Gouvêa et al., 2015; Long and M. S. Fee,
2008; Monteiro et al., 2023), which demonstrate temporal scaling. Hence, slowing
or speeding up the temporal evolution of activity should translate to dilation or
contraction of the readout behaviour.A perfect example of this occurrence is the
effect of HVC cooling in songbirds (Long and M. S. Fee, 2008), which appears with
a dilated song. Another study with the same cooling paradigm in the striatum
(Monteiro et al., 2023) showed that cooler temperatures caused dilation, and warmer
temperatures contraction, of both neural activity and time perception, judging one
interval as longer (shorter) than it was when cooled (heated).

This property can also be captured by ramping models, through changing the
slope of neuronal activity. Ramping and population clock models both have their
advantages and shortcomings. However, due to the sequential nature of popu-
lation clocks, i.e. the reliance of the later patterns from earlier ones, population
clocks are considered better suited for pattern timing (Hardy and D. V. Buonomano,
2016), which also underlies speech and birdsong.

3.2 Models of HVC

One example of a sparse population clock, where each neuron is active only once
during each trajectory, is the synfire chain, which is also one of the most important
timing models in the songbird literature. Synfire chains were first introduced by
Abeles (1982). A synfire chain is a feed-forward network of neurons composed of
many layers (or pools), where each neuron in one pool excites the neurons of the
next pool, and each neuron in the receiving pool is excited by many neurons of
the previous pool. This generates a volley of spikes propagating synchronously
(Abeles, 1982; Diesmann et al., 1999) from pool to pool. The particular structure
with all-to-all connectivity between the pools/layers, referred to as a complete
transmission line, was suggested by Griffith (1963). It can guarantee a fixed level
of activity in a network of excitatory neurons. Similar structures were used to
learn and reproduce complicated space-time patterns (Grossberg, 1969), for cortical
(Ikegaya et al., 2004) and primary motor cortex (Prut et al., 1998) activity.

Upon investigating its properties and applicabilities, it soon became one of the
main models tackling motor timing in songbirds’ song production (R. Hahnloser
et al., 2002; D. Jin et al., 2007). In this system, synfire chains are able to explain ex-
perimental recordings and behavioral findings. They can generate sparse bursting
activity (R. Hahnloser et al., 2002) and upon tuning the noise, they can produce the
observed syllable duration variability (Glaze and Troyer, 2012). Moreover, they ac-
count for behavioral adaptation. As explained in Chapter 2, in a CAF paradigm
aiming to change the duration of a particular syllable in the song using white
noise, the bird can change the duration of the target syllable without affecting the
rest of the syllables’ duration. In Pehlevan et al. (2018), the authors tried to model
the learning specificity observed (Ali et al., 2013; Pehlevan et al., 2018), and compared
the results from three selected models: synfire chains, a dynamic attractor model

51

3 Models of Subsecond Motor Timing in Neuroscience

(Laje and D. V. Buonomano, 2013) and a feedback stabilized recurrent neural network
(Rajan et al., 2010; Sussillo and Abbott, 2009). They reported that only the synfire chain
was able to reproduce the behavior with specificity to the target, whereas in the
two other models an effect on other non target syllables (RNN) was present.

Another network architecture, similar to synaptic chains is proposed by Chang
and D. Z. Jin (2009). Here, neural activity is sustained by external inputs, guided by
strong global feedback inhibition and unidirectional excitation between groups
or neurons. The model belongs to the pulse-coupled oscillators class.
In the
simple implementation of this model, a race-to-spike occurs every time a neuron
spikes, during which global inhibition affects all neurons and excitation activates
the “closer” neuron in the network. Hence, spike propagation becomes an “at-
tractor” to which the dynamics flow from any initial conditions.
In contrast to
the synfire chains’ limited stable regime, this model is robust in the driven chain
regime for a large range of excitation and inhibition strengths. Moreover, in the
multiple-chain scenario, a winner-take-all mechanism emerges, where only one
chain is selected. Assuming each chain encodes one syllable of the zebra finch
song, this could be a potential action selection mechanism.

Moreover, other models of HVC have tried to address HVC as part of a dis-
tributed network. Although previous cooling and heating experiments had shown
that HVC could be in itself the timekeeper (local timing network) (Long and M. S.
Fee, 2008), other evidence based on the relatively small amount of dilation (shrink-
ing) after HVC heating (cooling), propose that a loop could be present, including
HVC, Uva, the brainstem and RA (Hamaguchi, Tanaka, et al., 2016). In a comparison
between the distributed and the local timing mechanism model simulations, they
show that although both generate sparse sequential activity, only the distributed
model through the temporal organization of active and silent phases of synap-
tic activity, generates detectable membrane potential correlations and coherence
peaks between HVC neurons. This view challenges the traditional local synfire
chain perspective, adding and emphasizing the role of collective, network-wide
dynamics and hemispheric connectivity in generating the precise temporal se-
quences required for song. Other models emphasizing the importance of different
structures of the loop have been proposed, such as the bilateral HVC synchroniza-
tion model by Pang et al. (2022), where Uva guarantees interhemispheric synchrony.

3.3 Attractor Networks

Having described the general models of subsecond motor timing and the main
ones used to model HVC, here we focus on an alternative model, attractor net-
works. In this section, we first briefly describe the dynamical systems theory and
attractor networks, their architectures and applicability. Then, we focus on the
ring model, its properties, applications and the reasons making it an alternative
model for HVC.

52

3.3 Attractor Networks

Dynamical System and Attractors

Dynamical systems theory describes systems, including particle(s) or variable(s),
the states of which change as a function of time while obeying a set of differential
equations (Strogatz, 1994). They can be deterministic or stochastic. The state of a
dynamical system is a point or vector in its state space and the set of states toward
which the system converges over time is considered an attractor (Milnor, 2006). The
central signatures of attractors, as summarized by Khona and I. Fiete (2022), include
the lower dimensional attractor manifold, the convergence to the attractor state
following perturbation and the long-time autonomous stability of the attractor
states. The latter refers to isolation, no external input or activity, i.e. a completely
self-sustained, autonomous system. However, in the context of a larger complex
and interconnected network such as the brain, a system with untuned inputs is
accepted as effectively autonomous.

In neuroscience, attractor networks can be used to describe and model a large
number of cognitive tasks, such as short term and long term memory representa-
tion (Compte et al., 2000; Funahashi et al., 1989; Sharma et al., 2022), sequence genera-
tion (Laje and D. V. Buonomano, 2013), integration (Stringer et al., 2002), classification
(Chaudhuri and I. Fiete, 2019) and decision making (X.-J. Wang, 2008). Different net-
work architectures can give rise to point attractors (Hopfield, 1982), line, ring (Ben-
Yishai et al., 1995b) and plane attractors (Burak and I. R. Fiete, 2009), cyclic attractors
and chaotic attractors (Sompolinsky et al., 1988). These are split into discrete and
continuous attractors, where the former consists of a set of discrete states where
the network could flow to and the latter a continuous one.

Discrete attractors are mainly represented by the Hopfield model (Hopfield,
1982), where each discrete attractor corresponds to a particular memory pattern
the network learns through a Hebbian-like learning rule and then can recall. As
the network with the learned weights has stabilized to form attractor states, even
when presented to a partial or noisy cue, the dynamics of the system drive it to-
ward the stored pattern, effectively performing pattern completion. Hence, the
network will converge to different attractor states (memories) depending on the
initial conditions. The connectivity matrix is a symmetric pattern across the diag-
onal. Discrete models have also been used to model cortical up and down states,
perceptual bistability (McWalter and McDermott, 2019; M. Wang et al., 2013), delay-
period dynamics during a binary decision task in rodents (Inagaki et al., 2019) and
recurrent dynamics in the olfactory system in flies (Lin et al., 2014).

On the other hand, continuous attractors neural networks (CANNs) refer to
manifolds in the state space where each point within the region is an attractor,
providing a continuum of stationary attractor states. In their recent review, Khona
and I. Fiete (2022) make a compilation of the sufficient conditions to allow it: (i) The
presence of nonlinear neurons with saturating responses or inhibition-dominated
recurrent interactions and a uniform excitatory drive is necessary to keep network
activity bounded (Amari, 1972; Ben-Yishai et al., 1995a; K. Zhang, 1996); (ii) strong
weights, local excitation and broader inhibition to drive pattern formation (K.

53

3 Models of Subsecond Motor Timing in Neuroscience

Zhang, 1996), which give rise to the attractor states and (iii) continuous symmetry
(translational or rotational invariance) in the weights. Examples of these models’
applications in the brain include using line attractors (infinite set of fixed points)
for oculomotor integration (Aksay et al., 2001; Arnold and Robinson, 1997), ring at-
tractors for head direction cells (Kim et al., 2017; Taube et al., 1990), two-dimensional
toroidal attractors in the grid cell system (Burak and I. R. Fiete, 2009; Trettel et al.,
2019).

Ring Attractor

Ring attractors are continuous attractors, and are referred to also as line attractors,
where ends meet or bump attractors (Ben-Yishai et al., 1995b; Compte et al., 2000;
Hansel and Sompolinsky, 1998; K. Zhang, 1996). They are structured attractor net-
works, where the neurons are arranged in a ring-like topology and each neuron
represents a particular (preferred) feature. The connectivity is characterized by
symmetric synaptic weights, strong local excitation and broader inhibition, which
helps maintain the localized bump and stabilizes it. Additionally, uniform exci-
tatory input is provided to all neurons. This gives rise to a bump-like activity
pattern centered in a particular location, and the totality of these locations in the
state space forms a ring. Since the mid 1990s, ring attractors have been proposed
to underlie the rodent’s head direction system (Ben-Yishai et al., 1995b; K. Zhang,
1996) and more recent evidence has identified network motifs and dynamics in the
Drosophila’s head direction system (anterodorsal thalamus) corresponding to ring
attractors (Kim et al., 2017). Supported by the suggestion that a possible underlying
mechanism for motor timing could rely on strong internal connections capable of
self-sustained activity (M. Mauk and D. Buonomano, 2004), the ring model can also
be considered for motor timing. However, the ring model has stationary states
and to be able to account for pattern motor timing, it would need to generate a
drifting bump of activity. That is possible through a moving external input, neu-
ronal adaptation (Hansel and Sompolinsky, 1998) or asymmetry in the weights. In
chapter 5, we will detail these three mechanisms and propose one as suitable for
modeling HVC dynamics.

54

4 Objectives and Overview of the

Thesis

In this manuscript we aim to address subsecond motor timing in the animal model
of songbirds using computational modeling. The preceding three chapters provide
an introduction to the key concepts necessary to understand the broader context,
songbirds and modeling approaches. In Chapter 1, we present the broader con-
cept of time, the taxonomy of timing in neuroscience, the different scales of timing
and the anatomical/neural substrates. Among the anatomical substrates, we sin-
gle out the premotor nucleus in songbirds as an outstanding biological model of
motor timing at the scale of tens to hundreds of milliseconds. In contrast to more
complex underlying mechanisms in mammals, songbirds have a dedicated set of
interconnected brain nuclei known as the song system, responsible for the acqui-
sition and performance of the sensorimotor task of song production. This entails
a simpler structure to study, both experimentally and computationally. More-
over, the processes of birdsong production and learning are resemblant to those of
human speech. With this motivation, in Chapter 2, we present the anatomy, phys-
iology and behavior of songbirds in the context of vocal production and learning.
We end the chapter by focusing only on motor timing, its plasticity and the nuclei
in songbirds hypothesized to be involved in its emergence.

Altogether, in Chapter 1 and 2, we have highlighted the relevance and benefits
of using the song-timing circuitry in songbirds to model subsecond motor timing.
The following chapter, chapter 3 presents a collection of hypotheses and compu-
tational approaches to subsecond motor timing, ranging from the main classes
of models used across different species (mainly mammals), to models specifically
dedicated to simulating the dynamics of song-timing. We position the latter to
one of the larger classes and provide a mapping from a specific model to a more
general one. Lastly, we include a section on dynamical systems and attractors, as
a class of robust models which can be proposed to model temporal dynamics in
HVC.

In brief, we consider the song timing circuitry in songbirds to be an example
of subsecond motor timing. The dynamics observed in songbirds could lead to
a wider understanding of temporal control in other taxa, including humans, par-
ticularly because the task at hand, birdsong, is so similar to human speech. To
address subsecond motor timing, we use a computational approach and formu-
late two main questions:

55

4 Objectives and Overview of the Thesis

• What are the underlying dynamics that give rise to the precise temporal

control of a learned sensorimotor task?

• What are the mechanisms, by which behavioral flexibility of motor timing is

possible?

Modeling The Underlying Mechanisms of Song Timing

Premotor nucleus HVC, has been modeled either as a standalone timing structure
(D. Jin et al., 2007) or as an element within a distributed system (Hamaguchi, Tanaka,
et al., 2016), from which timing emerges. In both cases, a chain-like structure, which
creates sequence generation is hypothesized. We start Chapter 5 by focusing on
the main example of a synaptic chain, the Synfire Chain model (Abeles, 1982; Dies-
mann et al., 1999), which is considered the golden standard in modeling HVC. Due
to its structure and previous reports, we expect limited robustness and aim to first
show that this is the case, before proceeding to another model. Hence, we propose
investigating its timing flexibility by exploring the possible synaptic weight range
that allows chain propagation and the model’s robustness to noise in the input and
synaptic weights. Furthermore we search for a more robust model, which should
mirror the reported structure of a cortical area and HVC, incorporating recurrent
connections and inhibition. At the same time, it should retain a chain-like con-
figuration to account for feedforwardness (chain propagation). These required
characteristics evoke the concept of a particular kind of a ring attractor model,
one that is capable of progressing through its fixed points or attractor states. This
would manifest with a moving bump of activity.

To explore this hypothesis, it is simpler to start with a rate based model and then
if necessary move to a spiking neural network, which can explain the underlying
dynamics more accurately. The rate based model provides results that up to a
certain limit, should be mappable and can guide investigation in models entailing
more neuronal complexities, such as spiking neurons. As the goal of exploring
a different model lies on its robustness, (i) we will first prove that the proposed
model is robust. Then (ii) we will explore the different mechanisms that can make
the activity propagate in the network, causing a sequential activity as reported
in HVC. As feedforwardness is hypothesized in the connections of the HVCRA
neurons, we add a β term, to make the connectivity pattern asymmetric. This
will, on its own, allow bump propagation. Lastly (iii) we will investigate if a
ring attractor architecture can capture even more specific features of HVCRA, i.e.
sparsity in activity and burst time duration (R. Hahnloser et al., 2002).

Following the implementation of a one population rate based model and ad-
dressing the above mentioned points, a more biologically realistic model may be
necessary to address the number of spikes per burst and burst time more ac-
curately. Moreover, the role of the neuronal dynamics in the network behavior
should also be explored. For instance, D. Z. Jin et al. (2007) have previously shown
that instrinsic bursting, with a conductance based model increases robustness in

56

a synfire chain model. An additional mechanism to achieve bursting dynamics is
with an adaptation current, through an AdEx neuronal model (Gerstner and Brette,
2009). Hence, we expect that adaptation would also increase robustness in the
ring model and investigate the relationship. Lastly, as the neurons responsible
for song timing are inside a microcircuitry in HVC, it is important to model the
other elements of the microcircuitry. Interneurons play an important role in motor
timing (Kosche et al., 2015; Vallentin, Kosche, et al., 2016) and hence, their effect will
be explored in an excitatory inhibitory (EI) network.

HVC may be a sole contributor to motor timing, or it could be guided by up-
stream brain areas: the auditory nucleus NIf (nucleus interfacialis of the nidopal-
lium) and/or the thalamic nucleus Uva (nucleus uvaeformis) (detailed in Chapter
2). Whereas lesion studies in NIf (Naie and R. Hahnloser, 2011) have revealed that
NIf is not necessary in adult song production, several studies have shown that
Uva is highly important in song production (Coleman and E. T. Vu, 2005) and a re-
cent study has shown that it drives a particular set of neurons in HVC, those firing
at syllable boundaries (Moll et al., 2023). Since there appears to be no lateralization
(Long and M. S. Fee, 2008) in song production, it is probable that Uva input has a
synchronizing effect. As such, it would resemble a sequential input reaching the
two HVCs at discrete times in the song and have no effect in the burst sequences,
which we still hypothesize to be generated within HVC. The effect of such an
input in the model and whether it synchronizes the activity of the 2 simulated
HVCs, is included in Section 5.4.

Plasticity in Motor Timing

The presence of behavioral plasticity in birdsong has been revealed initially through
pitch and duration shift experiments using a Conditional Auditory Feedback paradigm
(Ali et al., 2013; Andalman and M. S. Fee, 2009) (detailed in Chapter 2). In Chapter
6, we aim to numerically simulate the protocol in order to incite duration shift in
either direction, i.e. to lengthen and shorten the target syllable duration, using a
reward-covariance reinforcement learning rule. A key feature of this behavioral
experiment and a reported computational challenge, is the fact that only the tar-
geted segment (syllable) is affected (Pehlevan et al., 2018). In a simplified numerical
representation of this behavior, a set of neurons represents a syllable. Within a
synfire chain architecture, a set of neurons, and more specifically two layers of
connected neurons, represent the start and the end of the syllable and the weight
update occurs only in the connections between these two layers, making the neu-
rons of the two layers fire closer in time (duration shortening) or further in time
(duration lengthening). As the weights between the other layers are not updated,
there is no effect on any of the other syllables/segments. However, upon using
recurrently connected neural networks, a duration decrease could take place in
many different ways, and a neuron does not only project forward, making its
other synapses also update. This would show an effect on multiple ’sets’ of neu-

57

4 Objectives and Overview of the Thesis

rons, some of which not mapped to the target segment. Hence, an effect in other
syllables, referred to as interference, can be observed.

In Chapter 6, we first explore whether with the ring attractor architecture and
the chosen learning rule, a shift in duration is possible. Next, we check how the
weights are modified to acquire this shift. We first hypothesized a local posi-
tive weight change modification, similar to the one observed in the synfire chain,
in the case of duration shortening. Moreover, we hypothesized that this change
would have to be very narrowly focused at the level of the pre- and postsynaptic
neurons affiliated with the target syllable. In such a way, no effect on the other
syllables would be observed. Before starting the learning simulations, we tested
this hypothesis, by adding such a change to the weight matrix and confirmed our
hypothesis. However, this would not be a robust mechanisms and as we will show
in chapter 6, this is not the mechanism we observe.

Moreover, with the same reasoning as presented above, the effect of different
neuronal models to the learning is also to be addressed. For instance, does adap-
tation increase the rate of learning, or does it rather decrease it? What is the effect
in learning, of an inhibitory population as compared to global inhibition? Most
importantly, the question of whether the underlying mechanisms, i.e. the pattern
of change in weights, is significantly different based on the neuronal model used.
Lastly, the specificity of learning needs to be investigated, whether it is present
with a rate based model and if it is the same in different levels of neuronal com-
plexity. This then needs to be confronted with previously reported experimental
data and data collected in the lab. Hence, in chapter 6, we present the results of
learning at the level of the target syllable, the presence or absence of interference
and the analysis of experimental data, which have been acquired using a CAF
paradigm to change syllable duration. As the averaged results have been already
reported, the individual mechanisms each bird uses to change syllable duration,
are of particular interest to us.

Implications and Perspectives

In the last chapter (Chapter 7), a general discussion on the implications of our
results and their position in the literature takes place. From the wider timing
perspective, we present a ring attractor model, taking place in the population
clock model class, as a computational approach to subsecond motor timing. Like
population clocks, this model provides robust and flexible timing. In the song-
bird and computational perspective, we discuss the possible emergence of such a
structured model from initial learning and how we can numerically reproduce im-
itation learning from an adult tutor, during the sensory and sensorimotor period.
Furthermore, we propose that the synfire chains and ring attractors, may in fact
lie in a continuum. Lastly, we suggest an additional learning rule to account for
the return to baseline duration, observed after the CAF is stopped.

58

5 A Robust Model of Motor Timing

5.1 Robustness of the State of the Art Model: Synfire Chain . . . . . . .
5.2 The Rate-Based Ring Attractor Model of HVC . . . . . . . . . . . . .
5.2.1 Model and Methods . . . . . . . . . . . . . . . . . . . . . . . .
5.2.2 Conditions for a Stationary Bump . . . . . . . . . . . . . . . .
5.2.3 Mechanisms Generating a Drifting Bump . . . . . . . . . . . .
5.2.4 Asymmetric Connectivity Profile to Model HVC . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . . . .
5.2.5 Discussion .
5.3 A Spiking Neural Network Model of HVC . . . . . . . . . . . . . . .
5.3.1 Model and Methods . . . . . . . . . . . . . . . . . . . . . . . .
5.3.2
Symmetric Rectangular Connectivity Profile . . . . . . . . . .
5.3.3 Asymmetric Gaussian Connectivity Profile . . . . . . . . . . .
5.3.4 Conditions for a Drifting Bump . . . . . . . . . . . . . . . . .
5.3.5 Predictions from the Models . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . . . .
5.3.6 Discussion .
5.4 Extended model with thalamic (Uva) Input: Synchrony? . . . . . . .
5.5 An EI Network Model of HVC . . . . . . . . . . . . . . . . . . . . . .

.

.

.

.

.

.

60
66
66
69
71
75
76
79
79
82
83
83
86
89
90
92

Neural mechanisms of sub-second timing with millisecond precision can be in-
vestigated through the male zebra finch birdsong, where the premotor nucleus
HVC is responsible for the precise control of motor timing, leading a tight co-
ordination of vocal and respiratory muscles muscles that produce a stereotypical
song. Given that birdsong is a learned sensorimotor skill, the nucleus HVC pro-
vides an excellent environment to study motor timing in such skills. Thus, mod-
eling the observed dynamics of HVC can give further insights into the underlying
mechanisms and generate important predictions. To some extent, such predic-
tions might be useful not only for birdsong, but also for human speech and other
sensori-motor skills.

Traditionally, HVC has been described with a network of excitatory neurons or-
ganized in a sequentially connected chain of neuronal populations, often referred
to as the synfire chain, belonging to the class of population clock models. How-
ever, the purely feedforwad connectivity pattern of synfire chains does not appear
compatible with the connectivity patterns observed experimentally in cortical net-
works. More specifically, unidirectional connectivity between groups of neurons
is incompatible with: the high level of reciprocal connectivity typically observed

59

5 A Robust Model of Motor Timing

in the cortex (Perin et al., 2011), the strongly interconnected web (Kosche et al., 2015),
and with structured excitation and inhibition in HVC. Additionally, as it has been
previously shown (Pehlevan et al., 2018), synfire chain networks are sensitive to
noise and require fine tuned synaptic strengths to avoid runaway excitation or
decay.

In this chapter, we propose that the gradual propagation of an activity bump
in HVC is driven by attractor dynamics. In particular, a ring attractor can drive
a drifting activity bump with robust and resilient properties thanks to recurrent
connections (Ben-Yishai et al., 1995b; Compte et al., 2000; Hansel and Sompolinsky, 1998;
K. Zhang, 1996). However, it is unclear whether the ring attractor can account for
the properties of HVC neuronal dynamics and the behavioral adaptation of the
song timing.

The structure of this chapter is as follows. First, we review the caveats of synfire
chains. Second, we introduce the ring attractor model as an alternative and inves-
tigate its limitations. We then reproduce experimental observations and explore
the possible underlying timing mechanisms in HVC with our proposed model. We
do this in three levels of increasing complexity: with a rate-based model (Wilson
and Cowan, 1973), with a spiking neural network (SNN) model (Lapique, 1907) and
with a two population, excitatory inhibitory (EI) network. We also make predic-
tions about the effect of local inhibition (GABAA agonist and antagonist) in HVC.
Lastly, based on recent findings, we also discuss a SNN model with synchronizing
input coming from the thalamic nucleus, Uva.

5.1 Robustness of the State of the Art Model: Synfire

Chain

Here we assess the robustness of propagating localized activity profiles in synfire
chains. To do this, we implement a synfire chain model with adaptive exponential
integrate and fire (AdEx) neurons.

The neuron model: AdEx

We use an AdEx neuronal model, as a cost-effective choice that can generate differ-
ent types of spiking patterns: tonic activity, spike frequency adaptation, bursting
activity, etc. Since we try to model HVCRA neurons, shown to exhibit burst-like
spiking patterns, AdEx proves to be an ideal neuron model. It relies on two main
equations (Brette and Gerstner, 2005):

= −gL (Vi − EL) + gL ∆T e

( V−VT
∆
T

) − wi + Isyn + Iext +

√

τn σn ηi(t),

(5.1)

= a (Vi − EL) − wi + b τw δ(t − ti),

(5.2)

C

τw

dVi
dt
dwi
dt

60

5.1 Robustness of the State of the Art Model: Synfire Chain

which describe the dynamics of the membrane potential Vi and the adaptation
current wi of neuron i, respectively.

We first explain the membrane potential dynamics in Eq. (5.1), where C denotes
the membrane capacitance. The first right-hand-side (rhs) term describes the leak
term with gL and EL denoting the leak conductance and leak reversal potential,
respectively. The second rhs term describes the exponential activation, with ∆T
being the slope factor of the activation and VT the threshold potential. The third
term in Eq. (5.1) describes the coupling to the adaptation current. Moreover, Isyn
and Iext are generally time-dependent and describe the synaptic and external cur-
rents, respectively. Lastly, ηi(t) refers to the white noise, the amplitude of which
is determined by the corresponding time constant τn and standard deviation σn.

In the adaptation current dynamics, Eq. (5.2), τw denotes the adaptation timescale.

The first rhs term describes the coupling of adaptation current to the membrane
potential, with a coefficient a. The second term describes the leak of the current,
and the third term denotes an increase of the adaptation current by b at each
spike time ti of neuron i. More precisely, a spike time-point ti is one that satisfies
Vi(ti) > VT.

When the membrane potential crosses the threshold potential, Vi > VT, the

above parameters are updated:

Vi −→ VR,
wi −→ wi + b,

(5.3)

(5.4)

where the membrane potential V is reset to the reset potential VR, and the adap-
tation current w is updated according to Eq. (5.2). This system of equations tries
to reproduce the biological behavior of neurons. For instance, the sodium activa-
tion curve is simulated through the slope factor ∆T (sharpness of the spikes) and
the calcium-dependent potassium channels though the spike triggered adaptation
parameter b. The latter is under the assumption that calcium influx occurs mainly
during an action potential (Gerstner and Brette, 2009).

The Synfire Chain

We build a chain of 90 layers where each layer comprises n neurons. Each neuron
on layer l has an excitatory synaptic connection (weight) to every neuron of the
next layer l + 1 as illustrated in Fig.5.1. This is also known as an all-to-all feed-
forward connectivity. Following the assumptions previously presented for the
synfire chain, the mapping between network activity and time is layer specific,
such that a time-point t(l) is a function of only the activity of the neurons in layer
l. Hence, the activity in each layer encodes the start and end of the interval of two
consecutive layers, i.e. the first spike of the layer marks the beginning of the new
song interval (syllable + gap, inside a motif) and the end of the previous one. The

61

5 A Robust Model of Motor Timing

Figure 5.1: Architecture of the Synfire Chain Network. The Synfire Chain exhibits an all-
to-all feed-forward connectivity. For the flexibility protocol, only the weights
between the neurons of layer 4 and 5 are changed by δw. The flexibility is
defined by the range of values δw can take.

synaptic input is a function of the synaptic weights and the postsynaptic potential
(PSP), as presented below:

Isyn,i = ∑

Wij ∑

Θ(t − tk

j ) e

−(t−tk
j

)

τs

,

j

k

(5.5)

where Wij is the synaptic connectivity weight with i being the post-synaptic and
j the pre-synaptic neurons, respectively. ∑j denotes a summation over all pre-
synaptic neurons. Moreover, Θ(t − tk
j denoting the
kth spike of the jth neuron and ∑k denotes a summation over all the spike times
of neuron j. Lastly, τS denotes the synaptic time constant. For brevity, all the
parameters of Eqs.(5.1)–(5.5) are summarized in Table 5.1.

j ) is a step function with tk

Procedure of Simulations

Eqs. (5.1) (5.2) are integrated by using a forward time Euler scheme with a numer-
ical time-step ∆t = 0.01 ms for an overall duration of T = 150 ms. Optimization
runs were performed to verify that the chosen ∆t does not alter the outcome.
Parameter values for the simulations are detailed in Table 5.1.

Symbol Parameter
N
C
VT
∆t
τw
b
τn
τs

Symbol Parameter
Values
EL
3000
number of neurons
gL
281 pF
membrane capacitance
-50.4 mV ∆T
threshold
0.01 ms Wij
timestep
adaptation time constant
100 ms
spike triggered adaptation 0.5 nA
10 ms
time constant of the noise
5 ms
synaptic time constant

leak reversal potential
leak conductance
exponential slope factor
weight, pre-j to post-i
adaptation coupling parameter
initial external input
st. deviation of noise
simulation duration

a
Iext
σn
T

Values
-70.6 mV
30 nS
2 mV
1.4 mV
- 0.5 nS
12 nA
0.2 mV
150 ms

Table 5.1: Values of the parameters used in Eqs.(5.1) - (5.2) for the Synfire Chain.

62

Layer:356w0±δww0w0Weight:45.1 Robustness of the State of the Art Model: Synfire Chain

In the following subsections, we report simulation results of synfire chain net-
works for different number of neurons per layer, n. We initialize the system by
applying an external current of Iext = 12 nA only to the neurons of the layer l = 1
during the first 1 ms of each simulation. The feed-forward synaptic weights are
set equal to each other:

(cid:40)

Wij =

w0
0

if j ∈ l & i ∈ l + 1
otherwise,

(5.6)

where, l denotes the layer index and w0 is manually determined for each n in
order to allow for activity propagation in the chain. In other words, Eq. (5.6) tells
us that each neuron at the layer l + 1 receives synaptic input only from the neurons
of the previous layer l (Fig. 5.1).

In Fig. 5.2, the first two panels present the resultant activity. Moreover, in sub-
subsection 5.1 we test the flexibility of the network, i.e. the range of the synaptic
weight between two specific layers (see Fig. 5.1) which can sustain the uniform
activity propagation along the chain. Next, in section 5.1 we test the robustness of
the network. Namely, we investigate how far the synfire chain network can sus-
tain the activity propagation when it is under the influence of noisy perturbation.
Detailed descriptions are provided in the corresponding sections.

Flexibility of Chain Propagation

We examine the possible connectivity range that the weights can explore across
10 synfire chains of varying sizes, i.e. n = {15, 30, 45, 60, 75, 90, 105, 130, 135, 150}
number of neurons per layer. As mentioned above, w0 is determined separately for
each n such that it allows for a uniform activity propagation along the chain. We
find that w0 values which allow for propagation decrease as n increases. Moreover,
we numerically explore the behavior of the network when the weights between
neurons of the layers 4 and 5 alone are modified, i.e. Wij = w0 + δw, whereas
all weights of neurons from other layers l to l + 1 (with l ̸= 4) are kept at w0.
We focus on the limits of δw where the activity propagation stops/saturates in
order to determine the upper/lower limits of weight flexibility. This range was
previously referred to as timing flexibility (Pehlevan et al., 2018).

We find an absolute decrease in the flexibility range of the synaptic weights as
the number of neurons per layer increases, and an almost constant percentage wise
flexibility. Hence, in larger networks, the weights have to be fine-tuned within a
narrow interval in order to sustain an activity propagation (Fig. 5.2 (B)). The net-
work with largest n comprises a total of 13,500 neurons, a number that approaches
the ∼20,000 song-related HVCRA neurons reported (M. S. Fee et al., 2004; N. Wang
et al., 2002).

63

5 A Robust Model of Motor Timing

Figure 5.2: Synfire Chain and the Flexibility Range in Different Network Sizes Upper
two panels: Spiking dynamics of the Synfire Chain AdEx model. Third panel:
Timing flexibility range refers to the range of synaptic weight, which allow
proper activity propagation in the chain. It is expressed as the ∆W range, of
the synaptic weight W. The values of ∆W are computed for different number
of neurons per layer in the synfire chain.

Robustness protocols

Although several studies have investigated the robustness of synfire chains, here
we particularly study it in the context of perturbations to HVC dynamics. We
design two numerical protocols to evaluate the robustness of the synfire chain
model under possible noisy perturbations: (i) in the synaptic weights, Wij, and
(ii) in the external current, Iext. They are to the network with 30 neurons per
layer (N = 90). In both cases, binary noise is injected on a selected percentage of
synaptic weights and neurons, respectively. The magnitude of noise is set based
on a number of numerical explorations. For synaptic weights, it amounts to a
value of 30% of the synaptic weights and for external current to 10% of the initial
external input. We observe, in both protocols, that the activity propagation along
the chain stops when the percentage of perturbed weights or neurons reaches a
certain limit (shown in Fig. 5.3).

For investigation simplicity purposes, synaptic weight changes are set to be all
negative and upon affecting 10 % of the synapses, we show in Fig. 5.3 (A) that
in the synfire chain, propagation stops. The second protocol can also be taken as

64

Flexibility Range5.1 Robustness of the State of the Art Model: Synfire Chain

Figure 5.3: Robustness of the Synfire Chain. (A) Behavior of the synfire chain facing a
decrease in synaptic weights. At 10% weight involvement, there is a stop in
propagation. (B) Behavior of the synfire chain in face of a decrease in external
input. There is a stop in propagation when 5% of the population is affected.

a proxy for local inhibition, where neurons although selected randomly based on
their preferred timing (feature space), could be close in space. With a 10% decrease
in external input, to 5% of the neurons, propagation stops as shown in Fig. 5.3 (B).

Discussion

Above, we present a synfire chain model with AdEx neurons. Although it is a very
good model to explain the sequential activity in HVC and the neuronal dynamics,
the robustness of such a model is debatable. We have present 3 protocols, advocat-
ing for a lack of robustness. The first protocol on testing the flexibility range has
previously been shown in a chain of single integrate and fire neurons (Pehlevan
et al., 2018). In our simulations, upon adding adaptation to the neuron model and
multiple neurons per layer, we observe similar results, proving that only a limited
range of weights allows proper propagation in the chain. This is important as it
requires fine tuning of the weights and may be a limitation in learning, as the
weights cannot change below or above a certain limit. The two other protocols
show that the limit after which propagation in the chain breaks in response to a
small noisy perturbation, is relatively small (10% for weights and 5% for neurons).
These protocols can, however, be extended further, with different perturbation
patterns and can be implemented in synfire chains with heterogenous weights.

65

5 A Robust Model of Motor Timing

5.2 The Rate-Based Ring Attractor Model of HVC

In this section, we investigate how accurately a ring model can describe and fur-
thermore explain HVC network dynamics. In contrast to the synfire chain model
above, where the neuronal activity is described via the membrane potential, here
we describe the neuronal activity via the firing rate, i.e. a rate-based model. The
mean firing rate, m(x, t) is a variable averaged in space and time. The rate based
model has less parameters than the spiking model, is easier to investigate and can
provide valuable insights, which we use for the spiking neuron model in section
5.3. The structure of this section is presented in the following paragraphs.

In subsection 5.2.1 we introduce the rate-based model in a ring architecture,
which has been studied in detail in different contexts (Hansel and Sompolinsky,
1998; K. Zhang, 1996). We follow the established formalism and use a connectivity
profile with short-range excitation and long-range inhibition, allowing the sponta-
neous formation of a localized neuronal activity, i.e. a bump. Moreover, to acquire
a a very narrow bump, we propose using a gaussian profile (instead of a cosine as
in Hansel and Sompolinsky (1998)). Next, in section 5.2.2, we numerically investigate
the parameter space of the connectivity profile for which the ring model leads to
the bump formation. Then, in subsection 5.2.3, we focus on different mechanisms
that can generate an activity bump which drifts along the ring. We initially revise
cases where the external input Iext is present, and then focus on cases when ex-
ternal input is absent, Iext = 0. In the latter case, we discuss scenarios where the
system is subject to adaptation currents or asymmetries in the connectivity profile.
Both of these features can induce a drive in the system. Lastly, in subsection 5.2.4,
we focus on the scenario with an asymmetric connectivity pattern. Here, we use
similar techniques as in subsection 5.2.2 to study how the asymmetry of connec-
tivity affects the robustness of the system, i.e. parameter space for which a drifting
bump can exist. These results pave our way to proposing the ring attractor as a
robust model for describing HVC dynamics.

5.2.1 Model and Methods
The Ring Model

We consider a neural population whose mean firing rate is expressed as m(x, t),
with x ∈ [−π/2, π/2[ being the position over a closed one-dimensional ring with
period π, and t representing time. The firing rate m(x, t) represents the averaged
neuronal activity, and is governed by the following equation:

d
dt

τ

m(x, t) = −m(x, t) + G(cid:2) Iext(x, t) + Isyn(x, t) + Ia(x, t) − T +

τnσnη(x, t) (cid:3),
(5.7)
where τ is the neuronal membrane time constant. On the rhs of Eq. (5.7), Iext is
the external constant input, Isyn the synaptic input and T represents the threshold.
Ia is the adaptation current, and it is set to 0, unless otherwise stated. The last rhs

√

66

5.2 The Rate-Based Ring Attractor Model of HVC

term is a zero-mean white noise which, for numerical purposes, is correlated in x
with a Gaussian of standard deviation of π/500. For the nonlinear gain function
G[I] , the simple semi-linear form is adopted:

G[I] =






0
I

1

I < 0
0 ≤ I ≤ 1
I > 1.

(5.8)

In order to investigate the system numerically, we first discretize the position
x in N = 1000 neuronal units. Then, we use the following expression for the
synaptic input:

Isyn(x, t) = ∑
x′

1
N

W(x − x′) m(x′, t),

(5.9)

where W(x − x′) denotes the synaptic connectivity between the pre-x′, and the
post-x, synaptic neural positions. In other words, W is the weight matrix and ∑x′
denotes a summation over all the pre-synaptic position indices.

Note that all the previous equations are identical with the ones derived a previ-
ous study (Hansel and Sompolinsky, 1998). The modification we introduce is at the
level of W, which we choose of the following form:

W(x − x′) = W0 + W2 e

(cid:16) x−x′ +β
σ

− 1
2

(cid:17)2

,

(5.10)

where (x − x′ + β) is taken modulo π, W0 < 0 stands for the global inhibition,
W2 > 0 the excitation factor and σ the width of the gaussian excitatory connectivity
profile. We have also introduced a bias term, β, that makes the connectivity pattern
asymmetric. As a consequence, the activity can be pushed to dynamically drift
along the ring in one direction or the other, depending on the sign of β. A more
detailed discussion on the role of this parameter is reported in section 5.2.3.

In our model, x does not represent the neuronal position in a spatial topology,
as HVC micro-circuitry does not display spatio-temporal organization (see Fig.
5.4 (A)). Instead, x represents the neuronal position in the feature space, which is
defined based on the preferred timing of each neuron (see Fig. 5.4 (B)).

Simulation

Eq. 5.7 is integrated by using a forward Euler scheme with a numerical time-step
∆t = 0.25 ms. Multiple runs were performed to identify an appropriate value for
∆t that does not alter the outcome. Unless otherwise stated, parameter values for
the simulations are set as in Table 5.2.

67

5 A Robust Model of Motor Timing

Figure 5.4: Simplified illustration of the ring connectivity and consequences of local in-
hibition. (A) The connectivity represents the physical location of neurons. (B)
The same connectivity is represented using the preferred timing as a neigh-
bourhood proxy for the placement of neurons. (C) Injection of a local inhibi-
tion in nucleus HVC. (D) The same local inhibition shown when neurons are
ordered according to their preferred timing. In this spatial representation, the
effect is not local, but rather distributed, which makes the network more ro-
bust.

Center of Mass of Activity (COM) and Bump speed

In order to characterize the system’s dynamics, we define a “center of mass”
(COM) of activity. The peak position of the bump, C(t), is thus defined using
the COM of activity over the whole population. C(t) is computed based on equa-
tions of COM for systems with periodic boundary conditions (Bai and Breen, 2008).

We assume that the mapping between network activity and time is specific to
the bump such that, at the time-point t(x), the COM of the bump is at neuron
position x, which is maximally activated. Thus, as the bump of activity moves
across the ring, different neurons will be the most active at different time-points
(Fig. 5.8). To acquire this, C(t) is further discretized into ¯C(t) and maps to the
nearest discrete unit/neuron position:

¯C(t) = argmini|C(t) − xi|.

(5.11)

68

A.B.C.D.A.B.C.D.A.B.C.D.A.C.B.D.A.B.C.D.5.2 The Rate-Based Ring Attractor Model of HVC

Symbol Parameter
N
∆t
T
τ
Iext
τn

number of neurons
timestep
duration
membrane time constant
external constant input
time constant of the noise

Values
1000
0.25 ms W0
W2
2 s
β
10 ms
σ
1.1
σn
1 ms

Symbol Parameters
T

threshold
global inhibition
excitation strength
bias in the weight matrix
Eq. (5.10)
std. deviation of the noise

Values
0.9
-5
28
0.05
0.067
0.02

Table 5.2: Values of the parameters used in Eqs. (5.7) – (5.10).

The speed of the bump is then computed as the displacement (in the neuronal
feature space) of the center of mass over time.

Syllable definition and duration

s n, i+1

A syllable corresponds to a fixed segment of the ring. We divide, the discretized
space of the ring into equally sized segments such that for s syllables and n neu-
rons, syllable i is defined by [ i
s n]. The beginning and the end of syllable i are
respectively defined by the timepoint the center of the activity bump ¯C(t) crosses
the lower and upper limit of the segment. Mean syllable duration in zebra finches
has been reported to be 110 ± 56 ms (Glaze and Troye, 2006). We aim to simulate
an ’accurate’ syllable duration, which in our model, depends on the speed of the
bump. Hence, the magnitude of drifting mechanism, in our case the bias, needs
to be chosen accordingly (detailed in section 5.2.3).

5.2.2 Conditions for a Stationary Bump

Continuous attractor models require the fulfillment of a set of theoretical condi-
tions to be able to converge into different attractor states (Khona and I. Fiete, 2022):
nonlinear neurons, continuous symmetry in the weights and strong weights with
short-range excitation and long-range inhibition. Moreover, phase analyses to in-
vestigate when the network sets in the different stationary states are necessary.
In the ring model with a cosine symmetric connectivity profile, three main states
were shown (Hansel and Sompolinsky, 1998): (i) a homogeneous state, where there
is no activity in the network or it converges to a minimal homogeneous excitatory
state; (ii) an amplitude instability, where the whole population fires at the satura-
tion level; and (iii) the marginal state, where bump formation occurs. The activity
bump appears as a “balance” between strong & localized neuronal interactions
and the global inhibition. The different positions where the bump formation takes
place make out the low dimensional ring attractor.

Here we investigate the parameter space which allows for the spontaneous for-
mation of the bump in the rate-based model with a narrow Gaussian symmetric
(β = 0) connectivity profile.
In section 5.2.4 we also investigate the case of an
asymmetric profile, β > 0. We perform numerical analyses to investigate the

69

5 A Robust Model of Motor Timing

behavior of the network by tuning the global inhibition, W0, and the excitation pa-
rameters, namely the amplitude W2 (5.5 (A)) and the width σ of the connectivity
profile (5.5 (B)).

Figure 5.5: Two numerical phase diagrams for the rate based model with a Gaussian
symmetric connectivity profile. (A) The four distinct asymptotic states of the
system. Their corresponding regions are color coded in the phase diagrams.
(B) The rate based model’s phase diagram based on W0 and W2. (C) The rate
based model’s phase diagram based on σ and W2. Parameters as in Table 5.2,
except for Iext = 0.92, β = 0, τn = 0.

To identify the different asymptotic states and their regions in the parameter
space, we start from a quiescent state which has only two consecutive neurons
firing at the saturation level:

m(xi, t = 0) =

(cid:40)

1
0

if i = 499, 500
otherwise.

(5.12)

We let the system run for a duration of T = 5 s, a sufficient amount of time for
the system to reach its asymptotic state. Similar to previous works (Aussel et al.,
2017; Hansel and Sompolinsky, 1998), we observe the following 4 types of states (see
Figure 5.5 (C)):

70

46810-3-2-1016243240-3-2-10162432400.0250.0500.0750.1001. Homogeneous2. Bump3a. Bump instability3b. Amplitude instabilityNeuronNeuronNeuronNeuronActivity46810-3-2-10B.C.A.1.2.3a.3b.1.2.3a.5.2 The Rate-Based Ring Attractor Model of HVC

• In Region 1, the system converges to a homogeneous state.
• In Region 2, the system converges to a bump, i.e. the marginal state.
• In Region 3a, the system yields a saturated bump, i.e. bump instability.
• In Region 3b, the whole system saturates, i.e. amplitude instability. The ob-
served states are dependent on the parameters we investigate.
In Fig. 5.5 (A),
where bump width is kept constant, the transition out of the homogenous state
depends solely on W2’s magnitude. As the magnitude increases above a certain
limit, the marginal state appears. The rest of the states are dependent on the in-
teraction (ratio) of W0 and W2. In contrast in (B), where W0 is kept constant, the
transition out of the homogenous state relies on the interaction between the am-
plitude, W2 and width σ of the excitation. Moreover, region 3a is dependent on
the current activation function; if the activation function was changed to remove
the saturation (I ≤ 1), the peak of the bump would diverge to infinity.

5.2.3 Mechanisms Generating a Drifting Bump

In the presence of a symmetric (β = 0) connectivity and a constant and homoge-
neous input, upon stimulus presentation, the activity bump settles in one of the
stationary states and remains there until another localized input or a high enough
perturbation is exerted. However, since the purpose of this model is to gener-
ate sequential activity, we investigate how propagation across these states can be
achieved. There are at least three ways to ensure bump propagation. These in-
clude an external drive in the form of a moving input stimulus and internal drives
such as adaptation and asymmetric connections. The relationships between each
drive and the population activity are described below and illustrated in Fig. 5.6
and 5.7.

External drive: Moving Input

In a cosine ring model, several moving activity profiles in response to changing
stimulus feature, virtual rotation and locking to moving stimulus feature have
been analytically investigated (Hansel and Sompolinsky, 1998). Here, we focus on
the latter, where the stimulus feature changes with time. We simulate, in our
Gaussian ring model, three different types of velocity profiles, (i) constant veloc-
ity, (ii) with acceleration and (iii) with an oscillatory velocity profile. We show
that the population activity profile can lock to the given input and that in all the
three cases, there is a quasi-linear relationship between the bump speed and input
velocity. When modeling the effect of an external stimulus on the system, x0 repre-
sents the feature for which the external input is maximal, i.e. the stimulus feature.
We assume that the external input affects the system in the following general form
(Hansel and Sompolinsky, 1998):

Iext(x − x0) = C(1 − ϵ + 4ϵ e− 1

2 ( x−x0

σ )2

),

(5.13)

71

5 A Robust Model of Motor Timing

where C is the maximal amplitude of the external input and ϵ stands for the
stimulus tuning parameter. If ϵ = 0, the input is homogeneous and if 0.5, it is
tuned with a gaussian profile, to affect the nearby neurons and not those further
away. Hence, in the all the simulation below, we take ϵ = 0.5, in order to have an
activity tuned to the stimulus. The velocity profiles we investigate are described
below.

Constant Velocity: The input stimulus changes smoothly with time, with a con-

stant velocity (Fig.5.6 (A)).

x0(t) = v0t.

(5.14)

Acceleration: presents with a changing speed profile of finite initial velocity and

a constant acceleration (Fig.5.6 (B)), a0:

x0(t) = v0t + a0t2.

(5.15)

Oscillatory Velocity : In this case, the velocity is oscillating, hence both continuous
and changing (Fig.5.6 (C)). The peak position of the input current is thus of the
following form:

x0(t) =

cos(ωt).

(5.16)

π
2

The results show that the relationship between bump speed and input velocities
in the three profiles is quasilinear. However, as (cumulative) input velocity in each
profile increases it becomes harder for the bump to follow it. After a certain limit,
after which no movement is detected. An example of such an event, is in the
oscillating regime, where at a high frequency, the bump explores a much shorter
trajectory than the input.

Intrinsic drive: Adaptation

Adaptation can make the bump move by generating a local, strong, delayed neg-
ative feedback, which suppresses localized activity (Hansel and Sompolinsky, 1998).
This causes higher activity in the nearby unadapted region. Hence, adaptation not
only generates different spiking patterns in the spiking neuron model (described
above, AdEx), but also movement. The adaptation current obeys the dynamic
equation below:

τa

dIa(x, t)
dt

= −Ia(x, t) + Ja m(x, t),

(5.17)

where τa is the time constant of adaptation and Ja its strength. We test the effects
of changing Ja and observe that as it is increased, the bump moves faster. Also,
unlike the other drives which can define the direction of bump movement, in this
case, unless there is another asymmetry the bump can move in either direction
(i.e. clockwise or anticlockwise).

72

5.2 The Rate-Based Ring Attractor Model of HVC

Figure 5.6: Moving activity profile in response to different external inputs.

(A) The
higher the velocity of the stimulus, the higher the speed of the bump, which
follows it.
(right) A depiction of two selected input velocities (color coded
with left figure) and the population activity in time, represented by the center
of mass of the bump. In pink the stimulus feature for the red velocity profile.
(B) same as A but for accelerating velocity profile. (C) same as A and B, for the
oscillatory speed profile.

Intrinsic drive: Bias

The bias term β was briefly introduced above and is present in Eq. 5.10, in the
connectivity matrix. It provides asymmetry, ensuring network feed-forwardness
and bump propagation. The sign of the bias determines the direction of propaga-
tion and the bump speed exhibits a quasilinear relationship with β, such that the
higher the bias, the higher the speed of movement of the bump (Fig. 5.7 (B)). We
choose the magnitude of the bias to acquire a constant speed, which alongside our

73

A.B.C.External drive5 A Robust Model of Motor Timing

Figure 5.7: Moving activity profile in response to different internal drives (A) Response
of the bump speed to different adaptation strengths is a quasi linear one.
(right) A depiction of two selected input velocities (color coded with left fig-
ure) and the population activity in time, represented by the center of mass of
the bump. (B) An asymmetric connectivity pattern makes the bump of activity
move across the network. On the right, the population activity when β = 0
(blue) and when β = 0.05 are shown. In blue, there is no activity due to sym-
metric connections. (C) Connectivity profile for presynaptic neuron 0 with no
bias and bias (color coded with figure B). This bias is the one we use for the
rest of the results presented. Self-connections are set to 0 but not represented
on the figure.

network size, allows a syllable duration of approximately 120 ms. The rest of the
presented results are for an asymmetric connectivity profile and use a bias value
of β = 0.05 (Fig. 5.7 (C)).

74

A.B.C.Internal drive5.2 The Rate-Based Ring Attractor Model of HVC

5.2.4 Asymmetric Connectivity Profile to Model HVC

The ring attractor model with an asymmetric connectivity profile gives rise to an
activity bump, which propagates with a speed, defined by the bias β (as shown
in Fig. 5.6). The transient population activation can be investigated by the width
of the activity bump for one neuron. The width is affected by the neuronal model
(rate) used, the width of the connectivity profile (σ) and the membrane time con-
stant (τ). Regarding the second component σ, we have shown the possible values
it can take for the system to remain in the bump regime (Fig.5.5) and we take the
lowest of these values, for our chosen W0 and W2, to guarantee a narrow bump. To
address the last contributing factor, we explore two values for the membrane time
constant τ. With a τ = 1ms, we can observe a bump width of ∼10 ms. Conversely,
when τ = 1ms the bump duration is ∼100ms. Despite the activity in HVC being
much shorter than 100ms, we choose the latter value to stay consistent with previ-
ously reported membrane time constants. We illustrate the activity across time in
Fig. 5.8 and use a Poisson process to generate spikes based on the firing rate.

Figure 5.8: Activity propagation in the ring. The first two panels show the position of
the bump of activity in the network at a particular point in time. The third
panel serves to present the possible spiking pattern this rate network would be
compatible with. They were generated using a homogeneous Poisson process.

To investigate how the bias term affects the parameter space where the bump
is formed, we perform similar numerical analyses as in section 5.2.2. We obtain

75

5 A Robust Model of Motor Timing

four asymptotic states, and have two main observations, which help understand
the effect of the bias. First, we observe in Fig. 5.9 (A), where β = 0.05, that the
parameter space of the bump state is larger as compared to the system with β = 0
(Fig. 5.5). Second, in Fig. 5.9 (B), we see that as the magnitude of the bias increases,
so does the region where the bump occurs, i.e.
in regions where at a bias of 0,
there is bump instability, at a bias of 0.05, there is a bump. We think this is due to
the feedforwardness β induces, which constantly transfers the flux of activity to
the nearby population. Hence, it does not allow for saturation in regions where a
high enough W2 would otherwise lead to a bump instability when β = 0. Taken
together, these findings suggest that a β > 0, expands the parameter space where
the bump is formed and sustained.

Figure 5.9: Two numerical phase diagrams for the rate based model with an asymmetric
connectivity profile, β > 0. (A) The rate based model’s phase diagram based
on W0 and W2. (B) The rate based model’s phase diagram based on on β and
W2. For this phase diagram, W0 was chosen as a value of -3, correspondent to
the last row of the the matrix in (A).

5.2.5 Discussion

Attractor dynamics have been used to model a wide range of cognitive processes
including memory representation, sequence generation, decision making and inte-
gration. A group of criteria have been proposed to claim possible attractor dynam-
ics in different networks in the brain (Khona and I. Fiete, 2022). HVC activity abides
at least 4 out of 5 of these criteria, namely: (i) it possesses a low-dimensional set of
states, timing in the song (1D) (R. Hahnloser et al., 2002), that corresponds to attrac-
tors in the state space, (ii) it exhibits robustness to perturbation and returns to the
low-dimensional state after it. This was first shown by electrical stimulation (E. Vu

76

16243240-3-2-1016243240 00.020.040.060.080.146810-3-2-10A.B.1. Homogeneous2. Bump3a. Bump instability3b. Amplitude instability1.2.3a.3b.1.2.3a.5.2 The Rate-Based Ring Attractor Model of HVC

et al., 1994) in HVC. Although the stimulation perturbs song timing, once removed,
the activity is quickly restored. (iii) Moreover, the states are invariant and persis-
tent over time. In adult zebra finches, even in the absence of HVC main inputs (Nif
and Uva) (Elmaleh et al., 2021; Naie and R. Hahnloser, 2011), HVC neuronal activity
underlying song production persists. Also, HVC singing-related activity can be
evoked outside singing, e.g. during sleep (Elmaleh et al., 2021), but it is partial. (iv)
Lastly, the criterion of isometry, can be advocated by the neuronal activity of pro-
jection neurons and interneurons, being locked the song (Lynch et al., 2016). Song
timing is driven by HVARA neurons, active at a ∼ 29 − 35ms latency before fea-
ture (syllable onset/offset) appearance. As a continous activity spanning the song
duration, it can be mapped to different instances in the song. Moreover, changing
the distance in time between spikes, through heating and cooling experiments, has
shown a mappable effect on the speed of the produced sequence (Long and M. S.
Fee, 2008). The fifth condition, pertaining to anatomical and structural correlates,
remains to be studied and investigated further. However, there are three reasons
that make us speculate it may also apply to HVC. First, the neurons firing close
in time, will likely have their connections strengthened due to synaptic plasticity
and Hebbian learning. Hence, the underlying pattern of HVCRA neurons would
include reciprocal connectivity and rely on stronger connectivity between neurons
firing at the same time in song. Secondly, as a local circuit encoding motor tim-
ing, HVC is expected to rely on regimes with strong internal connections capable
of self-sustained activity (D. V. Buonomano and Laje, 2010). Thirdly, evidence from
mammalian visual cortex show that neurons with similar tuning, exhibit stronger
connections (Pattadkal et al., 2018). Moreover, in a recent model of the turtle’s visual
cortex, constrained by experimental data, the presence of rare strong synapses and
many weaker synapses was shown. The former has a role in sequence propagation
and the latter in its enhancement or disruption (Riquelme et al., 2023). These find-
ings in the mammalian and turtle visual cortex may be similar for the premotor
cortical area in songbirds.

In this section, we have shown the results of using a ring attractor to reproduce
HVC dynamics. We have presented a robust model, functioning for a wide range
of weights and have shown that we can generate a moving bump of activity. How-
ever, this model has the limitation of having a too long duration of the transient
population activity. In this model, the duration of the burst of activity observed in
HVC in zebra finches (∼10 ms) (R. Hahnloser et al., 2002), can only be reproduced
with artificially short neuronal time constants (1ms). Above, we have mentioned
the three factors affecting the ’burst’ duration: neuron model, width of the con-
nectivity profile and membrane time constant. As we cannot modify the later two
(section 5.2.4), it may be worth exploring a spiking neuronal model. Such model
also guarantees a more accurate representation of the spiking dynamics in the net-
work and the short-duration burst of activity spreading across the nucleus, which
can be achieved by adding adaptation.

Some observations in the ring attractor lead to important questions in the song-
bird literature. For instance, activity propagation is possible through external

77

5 A Robust Model of Motor Timing

inputs, adaptation and asymmetric weights. The first could insinuate a higher
structure driving the activity in HVC (Moll et al., 2023). The second, an intrinsic
neuronal property could insinuate an effect on song timing which is not based
on experience (Fehér et al., 2009a) (Araki et al., 2016a). It could also be a combina-
tion of intrinsic and experience based factors, presenting in the form of the bias
in our model. This could be learned during sensory (auditory) learning from the
tutor. Finally, songbirds are also known for being a good model for the neural
mechanisms of vocal production in humans (A. J. Doupe and Kuhl, 1999). Therefore,
similar neural mechanisms may underlie speech and song timing. The dynamics
of cortical neurons driving speech production may thus also be accurately repre-
sented by the present model.

78

5.3 A Spiking Neural Network Model of HVC

5.3 A Spiking Neural Network Model of HVC

As noted above, the use of a spiking neural networks (SNN) becomes indespens-
able when one aims towards a biologically plausible description of the HVC dy-
namics. Hence, in this section we investigate the conditions for which a ring
attractor can be sustained in a SNN model. First, in section 5.3.1, we describe
the neuronal dynamics with an adaptive and exponential (AdEx) model, as in the
synfire chain model, section 5.1. However, in contrast to the synfire chain, the
neurons here are placed in a periodic ring, exactly as in the rate model, section
5.2.

We investigate interactions with short-range excitation and long-range inhibi-
tion, where more specifically, we first focus on a simple rectangular connectivity
profile in section 5.3.2, and then on a Gaussian connectivity profile in section 5.3.3.
The Gaussian connectivity profile is the same as in the rate model in section 5.2.
In the first case, we start with an exponential integrate and fire neuron and test
the effects of adaptation, noise and synaptic delays on the system. In the second
case, we investigate the conditions for which the Gaussian connectivity profile can
allow for spontaneous bump formation in an AdEx neuronal model.

5.3.1 Model and Methods

We consider a ring population of N = 3000 AdEx integrate-and-fire neurons that
are able to display bursting activity as it has been observed in HVC. The dynam-
ics of each AdEx neuron i ∈ {1, 2, ..., N} were previously presented in the Synfire
Chain model (section 5.1). However, for completeness, we briefly review the cor-
responding equations below:

C

τw

dVi
dt
dwi
dt

= −gL (Vi − EL) + gL ∆T e

( V−VT
∆
T

) − wi + Isyn + Iext +

√

τn σn ηi(t),

(5.18)

= a (Vi − EL) − wi + b τw δ(t − ti),

(5.19)

where Vi and wi are, respectively, the membrane potential and adaptation current.
When the membrane potential crosses the threshold potential (V > VT), the above
parameters are updated:

Vi −→ VR = −45 mV,

wi −→ wi + b,

(5.20)

(5.21)

where VR is the reset potential. The update parameter in the adaptation current is
the spike triggered adaptation, here set to b = 0.01 nA.

79

5 A Robust Model of Motor Timing

The synaptic input is defined as a function of the synaptic weights and the

postsynaptic potential, and it reads:

Isyn = ∑

Wij ∑

Θ(t − tk

j ) e

−(t−tk
j

)

τs

,

j

k

(5.22)

where Wij represents the synaptic weight between the pre-j and the post-i synaptic
neurons. The single neuron dynamics are identical to those in the Synfire Chain
model, section 5.1, where we have explained in detail every variable, function and
parameter that is present in Eqs. (5.18)–(5.22).

In this section, we investigate the network dynamics of two types of connectivity
profiles with short-range excitation and long-range inhibition. First, in section
5.3.2 we discuss the case with a symmetric rectangular connectivity profile, which
reads:

Rectangular: Wij =






0
W2
W0

if i = j,
if 1 ≤ |i − j| ≤ 10,
otherwise.

(5.23)

In other words, Eq. (5.23) reflects that the neuron i will receive excitatory input,
W2 > 0, from its 20 nearest neighbors (in feature space) and an inhibitory input,
W0 < 0, from the rest of population. Autopses are set to 0.

Figure 5.10: (A) Rectangular connectivity profile. (B) Gaussian connectivity profile.

In section 5.3.3, we then focus on a network with an asymmetric Gaussian con-
nectivity profile, as in the rate-based ring model, section 5.2.4. More specifically,
the corresponding equation reads:

Gaussian: Wij =




0



W0 + W2 e

(cid:16) i−j+β
σ

− 1
2

(cid:17)2

if i = j,

otherwise,

(5.24)

where the bias, β, determines the asymmetry, and σ denotes the width of the
profile.

80

A.Rectangular ConnectivityB.Gaussian Connectivityi−jWijW2W010−10i−jWijW0−1010W2+W0β5.3 A Spiking Neural Network Model of HVC

Simulation

All simulations were run on macOS 13.2.1, with Python 3.9.7 and Brian2. The
equations were integrated using an Euler scheme with a timestep ∆t = 0.1ms.
Multiple runs were performed to identify an appropriate value for ∆t that does
not alter the outcome. Parameter values for the simulations are detailed in Table
5.3, unless otherwise stated in specific sections.

Symbol Parameter
N
C
VT
∆t
W2
σ
τw
b
τnoise

number of neurons
membrane capacitance
threshold
timestep
excitatory factor
width of connectivity profile
adaptation time constant
spike triggered adaptation
(time constant of the noise)

Symbol Parameter
Value
EL
3000
gL
281 pF
-50.4 mV ∆T
W0
0.1 ms
β
0.71 mV
Iext
0.023
a
200 ms
T
7 pA
σnoise
10 ms

leak reversal potential
leak conductance
slope factor
global inhibition
bias
external constant input
adaptation coupling parameter
duration of simulation
standard deviation of noise

Value
-70.6 mV
30 nS
2 mV
-0.49 mV
0.03
0.7 nA
-0.5 nS
300 ms
5 mV

Table 5.3: Values of the parameters used in Eqs.(5.18) - (5.22) and (5.24).

Center of Mass (COM) and Bump speed

Due to the architecture, size of the network and noise, several neurons may fire
(∼1-6) simultaneously. Hence, to acquire a one dimensional position vector of
the neural activity across time, the firing rate of the population is needed. The
position C(t) (center of mass) of the bump can be computed as the maximum
value of the population’s mean firing rate. From the spike indices and times
(extracted from Brian2), we compute a binary matrix (spike/ no spike), which is
convolved in time and space using a two-dimensional filter with a Gaussian kernel
of standard deviation 5 ms and 50 neurons respectively. The peak of the activity
bump encodes time such that at time t(x), neuron x is maximally activated. As the
bump of activity moves across the network different neurons become more active
progressively (Fig. 5.8). The center of mass C(t), is further discretized into ¯C(t)
such as to coincide with the nearest unit position:

¯C(t) = argmini|C(t) − xi|.

(5.25)

The speed of the bump is then computed as the displacement (in the neuronal
feature space) of the center of mass over time. Alternatively, the speed can be
calculated using the amount of time between two neurons’ first spikes and their
distance in feature space.

Syllable definition and duration

A syllable corresponds to a fixed segment of the ring. We choose to simulate a
syllable duration of 50 ms and for simplification, we chose equal size segments

81

5 A Robust Model of Motor Timing

such that for s syllables and n neurons, syllable i is defined by [ i
s n]. Syllable
duration boundaries are defined based on the timepoints when the peak of the
spike-computed activity bump ˆC(t) crosses the lower and the upper limit of the
segment.

s n, i+1

5.3.2 Symmetric Rectangular Connectivity Profile

Figure 5.11: Activity Propagation in a Symmetric Ring Model with a Rectangular Con-
nectivity Profile and AdEx Neurons (A,C,E) Network of a size of 100 neurons,
across 3 different conditions: with no delays, with equal delays and with dis-
tance based delays. (B,D,F) same as the previous panels for a larger network
(1000 neurons).

In this part, we describe an exploration conducted in the spiking model, using
the symmetric rectangular connectivity profile as defined in Eq. (5.23). We investi-
gate the system in the absence of noise. Due to the effect of adaptation (Hansel and
Sompolinsky, 1998), we expect the formation of an activity bump that propagates in
one direction in the ring. Instead, we observe two bumps of activity being formed
and evolving in two different directions (Fig. 5.11). We illustrate the bump genera-
tion described in networks of two different sizes, with 100 and 1000 neurons. This
effect may be a result of the mechanism of adaptation, making a local inhibition
at the neuron level and a relative heightened activity in the adjacent non-adapted
areas. Given that the neighboring regions in both directions are equivalent due
to the network’s architecture, it’s likely that both have comparable activity levels,
leading to the creation of two distinct bumps. However in the presence of slight
asymmetry, i.e. through noise, we would instead observe only one propagating
bump.

82

A.B.E.C.F.D.5.3 A Spiking Neural Network Model of HVC

Next, we explore the effect of synaptic delays in the model. Constant delays
show very similar results (Fig. 5.11 (C,D)), with a delay between spikes. However,
there is still no asymmetry. In contrast, adding distance dependent delays would
guarantee that. To be able to do that, we first need to map our one dimensional
ring to a three dimensional space, which has the shape of a sphere and a radius of
π/2. We make no assumptions about how the feature space relates to the actual
space, other than it being random. Hence, each neuron {0, ..., N} in the feature
space is randomly assigned to one in the 3D space. We then calculate the Euclidean
distance between all pairs of neurons and multiply the result by a factor of 2.5ms,
to achieve a maximum delay of 7.9ms as reported previously. This adjustment
aligns with experimental data that indicates conduction delays varying between 0
to 7.9ms (Egger et al., 2020). As expected, upon adding distance dependent delays a
single bump, propagating in one direction, is formed. Distance dependent delays
provide asymmetricity as undoubtedly one neuron will be closer in space than the
other. The direction is determined by the closest neuron (Fig. 5.11 (E, F)).

5.3.3 Asymmetric Gaussian Connectivity Profile

In this part, we investigate an asymmetric gaussian connectivity profile as defined
in Eq. (5.24). Although there could be similarities in behaviour between a rect-
angular and gaussian profile, it is important to investigate the latter as well. A
reason for this is to be consistent with the connectivity profile in the rate model.
Moreover, it is likely that the synaptic weights are ’graded’ rather than binary,
and lastly because of the central limit theorem, stating that the distribution of a
random variable converges to a normal distribution as the number of samples
increases.

We first report and illustrate the neural dynamics and then investigate the con-
ditions where such dynamics are possible. When using parameters inspired from
biological systems, we observe the formation of an activity profile that drifts along
the ring where every active neuron bursts in 3-6 spikes for a typical duration of
≈ 10 ms (see Fig. 5.12). This matches experimentally-observed neuronal dynamics
(R. Hahnloser et al., 2002).

5.3.4 Conditions for a Drifting Bump

In this part, we perform numerical analyses of the SNN model to investigate the
parameter space for which a drifting bump forms due to neuronal interactions.
Similar to the analysis of the rate-based model, we identify the distinct asymptotic
states and their corresponding regions in the W0 – W2 space.

We run simulations of exponential integrate and fire neurons by combining Eqs.
(5.18) (5.20) (5.22) & (5.24). Adaptation current dynamics, Eqs. (5.21) (5.21) is ex-
cluded here in order to allow easier translation/mapping to the rate model phase
diagrams. However, inclusion of adaptation likely does not affect the phase dia-

83

5 A Robust Model of Motor Timing

Figure 5.12: Activity Propagation in an Asymmetric Ring Model with a Gaussian Con-
nectivity Profile and AdEx Neurons The first two panels show the position
of the bump of activity (the computation of which is present in 5.3.1) in the
network at a particular point in time. The third panel is the raster plot, show-
ing the brief bursts of activity and the propagation in the network.

grams significantly; it would possibly only broaden the area of the stable regime
(D. Jin et al., 2007).

The model was initialized with a constant input and a “pinch” input applied to
only one neuron (neuron index, 500) for 15ms. Then it was run for a long enough
time; a time after the initial transient formation has passed and the stable state is
present. At the last time-step, we observed where the system settled and identified
four distinct regimes:

• In Region 1 , the system converges to a homogeneous regime (Fig. 5.13 (A) in
gray dots).
• In Region 2 , the system converges to a stable/stationary bump (Fig. 5.13 (A), in
light blue dots).
• In Region 3, the system converges to a moving bump. Two different moving
bumps are observed,

• a “hopping” bump (purple triangles in Fig. 5.13 (A)) and
• a continuously moving bump (blue triangles).

84

t=15msneuron index01t=40msneuron index01t=65msneuron index01t=90msneuron index0115406590Time (ms)Neuron index5.3 A Spiking Neural Network Model of HVC

• In Region 4, the system diverges to bump or amplitude instability (orange and
red).

Determining the boundary of the fourth region was challenging, so we decided
to call anything above a certain maximum spike number a bump instability. How-
ever, while this is acceptable for our particular model, where the spike number
should be below 10, it would need another criterion for a more general model.
Perhaps as shown in the last panel of Fig. 5.13 (B) in red, the amplitude instability
can be determined when the mean firing rate of the last timestep appears as sat-
urated, with a flat top. This is also similar to the criterion used for the rate based
model.

Moreover, the presence of a stationary bump and “hopping” bump state are
interesting. The first, is likely dependent on a interaction between bias and exci-
tation (W2). Although the center of mass of the activity settles in one place, the
bias seems to keep driving neuronal movement within the region itself. As excita-
tion increases, the “hopping” bump appears. It is a state between stationary and
bump state, and has characteristics of both. The center of mass moves in time,
but it stays in one centered location for a prolonged time and a large number
of neurons are involved (∼ 100). Here, the interaction between bias and recur-
rent excitation, allows activity propagation. However, these profiles have not been
further investigated in this manuscript.

The parameters are chosen from region 3b, where a continuously moving bump

emerges.

Figure 5.13: Phase diagram of an Exponential Integrate-and-Fire neuron model in an
asymmetric (with bias) Ring Attractor Architecture. (A) The phase diagram
of the five possible regimes. (B) The raster plots of each of the observed states
and their respective activity profile in the last timestep of each simulation.
The plots in (B) are color coded to the phase diagram.

85

051015-10-9-8-7-6-5A.B.5 A Robust Model of Motor Timing

Figure 5.14: Robustness of the Ring Model. (A) Behavior of the synfire chain in face of a
change in synaptic weights, i.e. 30% decrease. There is no stop in propagation,
even when all connections are affected. (B) Behavior of the synfire chain in
face of an external inhibition, amounting to 10% of Iext. There is no stop in
propagation when 50 percent of the population is affected.

Robustness

In addition, we use the same two robustness protocols reported in the Section 5.1
in order to also be able to make a comparison of the robustness of the model with
the Synfire Chain. As it was illustrated in Fig. 5.3, with the administered binary
noise magnitude in the synaptic weights and input, the Synfire Chain stops activ-
ity propagation even when a small proportion of synaptic weights and neurons
are affected. In the case of the Ring Attractor, using the same amplitude as used
in the synfire chain, even at an 100% synaptic and neuronal involvement, there is
almost no effect (Fig. 5.14).

This can be expected from the recurrent architecture present in the ring, as com-
pared to the purely feed-forward one in the synfire chain. Moreover, as the input
affects randomly neurons in the network, their absence can easily be compensated.
Lastly, unlike in the Synfire Chain, the weights can be pulled from a wide parame-
ter range of inhibitory (W0) and excitatory (W2) values to bring forward the bump
state (Fig. 5.13).
In the case of a perturbation, such as one caused by noise or
a robustness paradigm as we described, the network ’drowns’ it across time and
goes back to its marginal state.

5.3.5 Predictions from the Models

We designed an additional protocol to evaluate the robustness of the network
under possible biological perturbations and the effect of inhibition administered
directly at the HVC nucleus level. We simulate the local injection of a drug in-
ducing the inhibition of neuronal activity (e.g. Muscimol), optogenetic stimula-
tion/cholinergic agonist, or Gabazine injection, with effects that spread with a
Gaussian spatial distribution into the network, as shown in Fig. 5.4 (C, D). We
assume this external perturbation is constant in time and we add it to the main
equation (5.18). For the simulations of Muscimol injection and optogenetic stimu-
lation, the equation reads:

− 1

2 ( x−µ
σi

)2

.,

(5.26)

Ii = α e

86

5.3 A Spiking Neural Network Model of HVC

where α is the amplitude and σi the width of distribution in space. In contrast,
in the Gabazine simulation, as an antagonist of gabaergic receptors, the global
inhibition parameter W0 is affected.
In this protocol, the additional input is a
function of the neurons’ location in the three dimensional space. To simulate a
lateral inhibition/activation to HVC, we randomly choose a neuron from those
most distant from the center of the sphere, and use it as the peak of the gaussian
(input). Then, we compute the Euclidean distance between this neuron and each
neuron in the sphere, which constitutes the x − µ line in Eq. (5.26). The outcome
is a one dimensional array, which is then added to the main voltage equation.

We test different distribution widths (σ) and input amplitudes (α). Moreover, by
changing the sign of α in Eq. (5.26), we are able to model two possible effects at the
level of GABAA receptors; with a negative sign that of the GABAA Agonist, Mus-
cimol, which enforces inhibition and with optogenetic stimulation, which serves
to minimize the inhibition.

Inhbition: GABAA Agonist (Muscimol)

Muscimol is a drug that acts as an agonist at the GABAA receptors and it is
widely used in experimental studies. We simulate its effects in the rate based
model and in the spiking model and observe a visible effect in bump formation.
Due to the high level of disruption, there is a delay in sequence initiation (Fig.
5.16 (A)). The amount of delay is linearly related to the amplitude and width of
the inhibition. Moreover, although the sequence absorbs the perturbation and is
maintained for the rest of the simulation, a decrease in the speed of propagation
is present. Speed has a quasi linear relationship (shown in Fig. 5.15) with the
amplitude and standard derivation, such as when one of the two increases, the
speed of the bump decreases. The standard deviations in Fig. 5.15 are expressed
as a function of the size of the system. The limit above which the bump does
not recover is defined at σ = 0.9 (in a sphere with radius equal to π/2) and an
amplitude α = −14 nA.

Overall, these findings suggest potential predictions regarding HVC behavior
in the face of such inhibition. The effect might be a delay in the initiation of the
sequence (song), without any subsequent disruption in the propagation of the se-
quence, as depicted in Fig. 5.16. Nonetheless, bump speed propagation decreases
(Fig. 5.15, middle), leading to a compromised timing, i.e. slightly stretched time.
It is particularly difficult to test the first hypothesis/ prediction of the model,
as a song initiation time would need to be defined, from which the delay is to
be computed. A possibility is to compute an average reaction or singing time in
response to female presentation (directed singing) or with respect to the introduc-
tory notes. Subsequent changes in this reaction time, in the context of Muscimol
inhibition, could then be studied.

Our second finding is easier to test, although a mapping of our amplitude values
to drug dosages, is necessary. It could be possible that the allowed dosage maps to
a very low amplitude in our simulation, reflecting in a very small speed decrease,

87

5 A Robust Model of Motor Timing

Figure 5.15: Effect of Inhibition on the Speed of the Bump. On the right, an illustra-
tion of the distribution of the inhibitory input in the 3D space is shown. In
the middle and on the left, respectively, Muscimol’s and Gabazine’s effect on
the bump speed are investigated, for different amplitudes and distributions
(width). The amplitude is expressed in nA and is the coefficient of the gaus-
sian, whereas the SD is expressed based on the size of the system (π). The
colors represent the change in speed as a percentage of the inital (uninhibited)
propagation speed.

i.e. very high doses could completely degrade the song (Isola et al., 2020).
It is
possible that a stretching effect similar to the one reported (Isola et al., 2020) in
Bengalese finches upon muscimol injections is present.

Optogenetic activation

there is a delay in sequence initiation.

In our model (rate, SNN), in terms of the initial response to this input, we observe
the same effect as with Muscimol- mimicking simulations. The bump takes longer
In the spiking model, the
to form, i.e.
network is more sensitive to higher amplitudes of excitation as compared to the
rate model. Moreover, the speed profile has a nonlinear relationship to the input’s
size and/or magnitude. When the amplitude is kept constant and we explore
different σi, there is a linear relationship (increase in speed) up to a certain limit,
after which there is no bump formation. Upon crossing a second limit, the linear
relationship reverts. This suggests that the excitation of such kind should be fine
tuned and can at different distributions, provide different results. However, this
remains to be further investigated.

Inhbition: GABAA Antagonist (Gabazine)

Gabazine is a drug that acts as an antagonist at the GABAA receptors, and re-
sults in a reduction of GABA-mediated synaptic inhibition, namely W0. Our find-
ings with the gabazine mimicking simulation (Fig. 5.17), show an effect in speed,
which is quasi-linear and in the opposite direction, compared to the effect with
Muscimol. Hence, when the amplitude or standard deviation of this inhibition is
increased, the speed increases (Fig. 5.15, left).

88

0.40.50.60.70.8SD151050Amplitude 010205.3 A Spiking Neural Network Model of HVC

Figure 5.16: How does inhibition affect bump propagation? Here we present two exam-
ple cases of the effect of moderate inhibition in the rate and SNN model. In
(A,B) we illustrate a Muscimol-mimicking simulation, both in the rate model
(A) and in the SNN (B). We observe a disruption in the beginning, but similar
to a noisy perturbation, the model is able to recover after a while, although
the inhibition is constant.
(C,D) In these panels, we illustrate optogenetic
stimulation-mimicking simulation, both in the rate model (C) and in the SNN
(D). In both cases we observe only a disruption in the beginning.

5.3.6 Discussion

HVC neuronal recordings reveal a sparse network activity with bursts of 3-6 spikes
lasting 6-10 ms, time-locked to the song. In this section, we have introduced a ring
attractor model that captures the sequential neuronal activity of HVC while pre-
serving the individual neuronal properties. We use spiking neurons and since
previous evidence (Long, D. Z. Jin, et al., 2010) has shown that HVC bursts are me-
diated by calcium spikes, we add neuronal adaptation as a possible mechanism
to capture this. More specifically, adaptation, modeled by a differential equation
first presented in Brette and Gerstner (2005), can account for ionic channel activity,
depolarizing currents (captured by parameter a in Eq.5.19) and calcium dependent
potassium channels (captured by parameter b).

Our results provide evidence that an asymmetric ring attractor model with
adaptive exponential integrate and fire neurons can explain the underlying mech-
anisms motor timing in songbirds. The model is robust, able to generate the same
In terms of
spiking/bursting activity and activity propagation in the network.

89

SNNB.RateSNND.C.A.5 A Robust Model of Motor Timing

Figure 5.17: How does inhibition affect bump propagation?
Gabazine-mimicking simulation in the SNN model.

Illustration of a case of

robustness, we first compare our model with a traditional synfire chain, where
weights have to be fine tuned to support propagation. We perform numerical sim-
ulations to compile phase diagrams, and show that the regime where the bump
is formed, the marginal state, is quite broad. Hence, the weights do not need fine
tuning. Moreover, we investigate their robustness with two protocols, described
in Subsection 5.1. We show that while the synfire chain shows a high sensitivity to
random partial decreases in external input and synaptic weights, the ring attractor
remains mostly unaffected and is robust to noise, even at high levels of neuronal
and synaptic involvement. We only witness a slight delay in activity initiation.
This is consistent with the literature on attractors where noise is absorbed by the
system, although it may slightly disrupt it in the beginning (Khona and I. Fiete,
2022).

A possible further exploration of our model is investigating behavioral adapta-
tion, which entails learning to modify the duration of a syllable, without affecting
the other syllables. This has been shown to be the case in songbirds (Ali et al., 2013).
In chapter 6, we will simulate such a behavioral learning paradigm, and present
the results.

5.4 Extended model with thalamic (Uva) Input:

Synchrony?

A number of studies have investigated and focused on providing a better under-
standing of the role of Uva in song production. Several models of its function have

90

5.4 Extended model with thalamic (Uva) Input: Synchrony?

been proposed as a: (i) a synchronizing center for the two hemispheres (Ashmore,
Renk, et al., 2008; Gibb et al., 2009; Schmidt, 2003; E. Vu et al., 1994), (ii) an intermediary
transmitting important song-related information or feedback from the brainstem
(Ashmore, Renk, et al., 2008; Hamaguchi, Tanaka, et al., 2016), and (iii) an initiation hub
(Alonso et al., 2015) at discrete times. According to recent evidence (Moll et al., 2023),
a percentage of HVC neurons are Uva-driven and fire at particular times during
the song, namely at the beginning and/or end of the syllable. However, the exact
role and significance of these neurons and the incoming input is still a topic of
discussion.

Figure 5.18: Uva as a possible synchronizing nucleus between the HVCs of the two
hemispheres. In (A) HVCs of the two hemispheres are not connected. When
the sequences of each are initiated at different times, they evolve in parallel,
with the same speed and no convergence. In (B) the two HVCs receive input
from Uva, which is able to make their respective sequences converge, making
one’s speed go faster and the other’s slower, until they fire synchronously.

A prominent hypothesis is that Uva plays a synchronizing role between the two
HVCs. Cooling studies have shown that the effect of such manipulation in ei-
ther HVC manifest with song stretching. This suggests both HVCs are equally
important and/or complementary in controlling song timing (Long and M. S. Fee,
2008). However, synaptic noise or other physiological factors could drive the two

91

A.Not connectedConnectedHVC 1HVC 2HVC 1HVC 2UvaB.5 A Robust Model of Motor Timing

HVCs to present with slightly different activity, which could affect timing accu-
racy. Hence, the information coming from the two HVCs could be, synchronized
through a higher level structure, the thalamic nucleus Uva. The presence of such
input at the syllable level (Moll et al., 2023) could be affected by respiration.

We simulate 2 spiking neural networks, with the same properties as described
above, and add a sequential input representing the input originating from Uva.
To reproduce experimental findings, only 15 % of neurons receive input from Uva
(Moll et al., 2023) and these are the neurons firing at the beginning and end of each
syllable. We first, investigate the behavior of the system in a high noise regime
and observe synchronization. However, to be able to illustrate this effect better,
we run a dedicated simulation where the starting input is different in the two
HVCs, similar to what has been shown in Pang et al. (2022). As one sequence starts
from neuron index 200, instead of neuron index 0, the signal is ahead of the other
HVC’s signal. Whereas in the case of no external intervention, these two signals
would always be separate from one another, evolving in parallel (Fig. 5.18(A)),
here, due to the presence of a synchronizing unit, after a short while the signals
converge (Fig. 5.18(B)), proving a consistent input to RA.

5.5 An EI Network Model of HVC

In the previous sections, we investigated the behavior of the model in a one pop-
ulation model, in the presence of global inhibition and excitatory and inhibitory
synaptic connections. However, interneurons likely have a significant importance
on the produced dynamics. To investigate the effect of inhibition of a more com-
plex form, we expand our model to a 2-population model. We consider an exci-
tatory (E ) and an inhibitory (I) population, both with single neuronal dynamics
described by Eqs. (5.18) (5.20) (5.22) & (5.24), without adaptation currents. The
only difference is that the inhibitory populations membrane time constant is twice
that of the E population. The size of the (E ) and (I) populations are 3000 and
600 neurons respectively, with a ratio of 5:1 (Fig. 5.19 (A)). The connections be-
tween the neurons in the excitatory population are guided by a ring attractor with
a Gaussian connectivity profile, same as in the models presented above (Eq.(5.10).
However, W0, global inhibition is absent, as inhibition is now in a loop with the
excitatory neurons.

All parameter values are same as in Table 5.3. Moreover, among themselves, the
inhibitory neurons are not connected. The synaptic weights from the (E ) to I popu-
lation are set 0.015 mV and a connection probability of 0.79. The synaptic weights
from I to E are set to 0.49 mV, with a connection probability of 0.67. Connection
probabilities were set based on previous findings (Kosche et al., 2015). The magni-
tude of synaptic weights (EI, IE) is set to enable proper activity propagation in the
excitatory population and allow burst of ∼ 10ms duration, 4-6 spikes. Although,
in the presented model, we do not explicitly propose a structure for the inhibition,
there is an emergent structure originating from its interactions with the excitatory

92

5.5 An EI Network Model of HVC

Figure 5.19: Activity propagation in the EI model. (A) Illustration of the network archi-
tecture. (B) Raster plot of the excitatory population. (C) Raster plot of the
inhibitory population.

population. We see a spiking pattern in both populations (Fig. 5.19) consistent
with recordings. Whereas we had set the parameters to acquire the spiking pat-
tern of the E population, we presented no additional constrains for I. The mean
firing rate of the inhibitory population is oscillating at ∼30Hz, matching the one
reported from experiments (Markowitz et al., 2015).

93

A.- Excitatory neuron (E): NE=3000- Inhibitory neuron (N): NI=600- E excites E: Gaussian weights- E inhibits I: - I inhibits E: WE,I=0.015mVWI,E=0.490mVB.C.6 A Flexible Model of Motor

Timing: Behavioral Adaptation

.

.

.

.

.

perimental Paradigm .

6.2 Learning in the Rate-Based Model

6.2.1 Results .
.
6.3 Learning in the SNN .
.
6.3.1 Results .

6.1 Reinforcement Learning: Numerical Implementation of the CAF ex-
96
. . . . . . . . . . . . . . . . . . . . . . . . .
98
. . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . . . .
98
. . . . . . . . . . . . . . . . . . . . . . . . . . 103
. . . . . . . . . . . . . . . . . . . . . . . . . . 104
6.4 Learning in the EI Network Model . . . . . . . . . . . . . . . . . . . . 109
6.5 Comparing Model Results to Experimental Data . . . . . . . . . . . . 112
. . . . . . . . . . . . . . . . . . . . . . . . . . 113
. . . . . . . . . . . . . . . . . . . . . . . . . . 114
. . . . . . . . . . . . . . . . . . . . . . . . . . 115

6.5.1 Methods .
.
6.5.2 Results .
.
.

6.6 Discussion .

.
.
.

.
.
.

.
.
.

.
.
.

.
.
.

.

.

.

.

Behavioral findings using the Conditional Auditory Feedback (CAF) paradigm
(described in Ch. 2) have shown that when an interval (syllable + gap) in a song-
bird’s song is targeted for lengthening (shortening), this occurs with specificity
(Ali et al., 2013; Pehlevan et al., 2018). The songbird is able to change the duration of
that target interval, without significantly affecting other interval durations. Hence,
song length increases/decreases as an effect of the change in one interval. This
supports one of the three previously proposed hypotheses. The other two are:
(i) global modification, where all the elements of the sequence change (they all
lengthen, when one lengthens) and (ii) interference, where the duration modifica-
tion affects the other syllables, such as to keep the song length constant (i.e. when
one syllable lengthens, the others shorten).

How the reported specificity in behavioral adaptation can be captured from a
computational perspective poses an interesting question, which can provide in-
sight on the underlying mechanisms. In a recent article (Pehlevan et al., 2018), three
different models were explored: synfire chains, dynamic attractors (Laje and D. V.
Buonomano, 2013) and feedback-stabilized RNNs (fsRNN) (Rajan et al., 2010; Sussillo
and Abbott, 2009). It was shown that only synfire chains are able to conduct in-
terval modification in both directions (shortening, lengthening), without causing
any interference (effect on the other intervals). In contrast, with fsRNNs there is

95

6 A Flexible Model of Motor Timing: Behavioral Adaptation

interference in all the other intervals and in the attractor model there is interfer-
ence in the adjacent ones. However, since our proposed attractor model, the ring
model is able to capture and provide explanations for HVCRA neuron behavior,
we decide to further explore its behavior when presented with a simulated version
of this learning paradigm. We use a reward covariance learning rule (R. Williams,
1992) and adapt the simulation to the experimental conditions presented (Ali et
al., 2013). The used formalisms and adaptations are consistent with the computa-
tional methodology used in a previous study (Pehlevan et al., 2018). In this chapter,
we present our findings at four levels of increasing complexity using first, a one
population network with (i) rate-based neurons, (ii) exponential integrate and fire
neurons (eIF), (iii) adaptive exponential integrate and fire (AdEx) neurons and (iv)
a two population network (EI) with exponential integrate and fire neurons. Lastly,
we make a comparison between our numerical findings and recent behavioral data
collected in our lab.

6.1 Reinforcement Learning: Numerical Implementation

of the CAF experimental Paradigm

We use a reward covariance learning rule (R. Williams, 1992) to simulate the CAF
paradigm. The equations reads:

∆Wij = γ R eij
dt′
τe

eij =

(cid:90) t

0

with

e−(t−t′)/τe ηi(t′)mj(t′),

(6.1)

(6.2)

where ∆Wij denotes the learning-induced change in the synaptic weight between
the pre- (j), and postsynaptic neurons (i). γ denotes the learning rate, R the reward
value and eij the eligibility trace. The eligibility trace (Eq.
(6.2)) controls the
synaptic change amplitude and flags whether a synapse is eligible for modification,
based on recent activation of the plastic synapse. The eligibility trace used in our
model is computed based on the target syllable 1, where (Eq. (6.2)) 0 is the start
and t the end of the syllable. Moreover, it relies on a time constant τe, the noise of
the postsynaptic neuron ηi and mj the firing rate of the presynaptic neuron.

In our reinforcement learning simulations we set the learning rate to γ = 0.0002,
and the eligibility time constant to τe = 35 ms. γ was chosen to match learning
rates observed in songbirds experiments and taue to match the delay between HVC
signal and motor action (Ali et al., 2013). The reward R takes a value of 0 or 1 when
the syllable is targeted for modification, and 0 when it is not targeted.

1In the rest of this chapter, we use the term syllable instead of interval to maintain consistency
with the terminology used in Chapter 5. Moreover, we have defined no gaps in the model, so
what we refer to as syllable, encompasses them.

96

6.1 Reinforcement Learning: Numerical Implementation of the CAF experimental
Paradigm

If targeted for modification, the syllable duration at the end of each trial is
compared to the running average of the target syllable duration. This is updated
in each trial as shown in (6.3):

¯I(tar) ← 0.995 ¯I(tar) + 0.005I(tar),

(6.3)

where I(tar) denotes the current syllable duration and ¯I(tar) the running average
of the target syllable duration. When the syllable is targeted for lengthening, if
I(tar) > ¯I(tar), a reward is given (R = 1), and the weights are updated according to
the learning rule (6.1). If I(tar) < ¯I(tar), no reward is given, R = 0, and the synaptic
weights remain unchanged.

The RL pseudoalgorithm when the syllable is targeted for lengthening

1: for i = 1 to 50 do
run(model)
2:
duration ← find\_syllable\_duration()
baseline[i] ← duration

3:

4:
5: end for

6: for i = 1 to 1000 do
run(model)
7:
duration ← find\_syllable\_duration()
duration\_target← duration\_target × 0.995 + duration × 0.005
if duration > duration\_target then

9:

8:

10:

11:

12:

13:

∆W ← R × γ × e

else

∆W ← 0

end if

14:
15: W ← W + ∆W
16: end for

17: for i = 1 to 50 do
run(model)
18:
duration ← find\_syllable\_duration()
postrl[i] ← duration

19:

20:
21: end for

Simulations

All other simulation parameters unrelated to the learning for each of the models
(rate, eIF, AdEx), remain consistent with those detailed in their respective sessions
in Chapter 5. Prior to implementing the learning rule, 50 trials are run to deter-
mine the baseline distribution of the syllables. Then, the learning trials are run. In

97

6 A Flexible Model of Motor Timing: Behavioral Adaptation

the rewarded trials, the weight matrix, W is updated by ∆Wij. Lastly, 50 more trials
are run to determine the distribution of durations with the new weight matrix W
(Winitial + ∆W). A simplified representation of the followed protocol is presented
in the pseudoalgorithm. Lastly, the baseline and post-reinforcement (postrl) sylla-
ble distributions are compared using independent t-tests. Significance is reported
when p < 0.01.

6.2 Learning in the Rate-Based Model

We first explore the effects of our learning rule and paradigm, with a one popu-
lation model of rate based neurons (5.2). Rate based neurons models require less
computational power as compared to spiking neurons, can give valuable intuition,
and guide explorations in the spiking model. In this section we report the results
of the presented reinforcement learning (’simulated’ CAF) protocol.

6.2.1 Results

As explained above, we run 50 trials prior to and following learning, to determine
duration distribution with the initial weights, and with the weights modified by
the learning rule. With the used noise magnitude, we acquire a mean baseline
duration of 118.6 ms, with a standard deviation of 0.75 ms.

Figure 6.1: Target syllable duration distribution before and after reinforcement learning
(for shortening, lengthening) of the targeted syllable. Effects of reinforcement
learning in single run simulations of 1000 trials, aiming to change the duration
of the syllable in the direction of lengthening (blue) or shortening (red). Base-
line duration distribution in gray represent 50 trials prior to RL, and each of the
two other distributions represents post-RL duration distributed (color coded).

Following the learning protocol for syllable shortening and lengthening, the re-
spective mean syllable durations become 117.33 ms and 119.59 ms, with standard
deviations of 0.7 and 0.75 ms. Hence, for a run consisting of 1000 learning trials,
the difference between mean durations (pre and post learning) amounts to 1.27
ms in the case of syllable shortening and 0.98 ms for syllable lengthening. In other

98

11611711811912012105101520CountBefore LearningTarget: LengthenTarget: Shorten6.2 Learning in the Rate-Based Model

words, the temporal shift is ∼1.3 and ∼1.7 standard deviations from the baseline
distribution (Fig. 6.1).

To make the analysis more complete, we investigate the averaged results as
well. We make the assumption that each run, executed with a distinct seed, sim-
ulates a different behavior and consider them as ”simulated birds“. Therefore, 10
runs are viewed as 10 simulated birds, and the mean results offer a measurement
akin to those employed in behavioral studies. The mean value of the distribution
from each run is taken for all the syllables, providing a 10 (runs) by 5 (syllables)
matrix. Then, this distribution of means is compared with the average baseline
distribution (10 x 5 matrix). We report that the single run results are similar to the
averaged ones. In the latter, the averaged change for shortening and lengthening
are respectively 0.98 and 1.17 ms. Upon increasing the number of trials from 1000
to 3000, we obtain a mean change of ∼1.6 ms for syllable lengthening and 1.79 ms
for shortening. A slight difference between the magnitudes of learning in the two
cases (shorten/lengthen) can be observed. It may indicate that syllable shortening
is easier to perform as compared to lengthening.

To what extent is the modification specific to the target syllable?

To investigate the specificity of such a temporal shift, we analyzed the durations of
the non-target syllables before and after learning, considering both individual runs
and the averaged outcomes of the 10 runs. With the single runs, we conducted
independent t-tests comparing syllable distributions before and after the learning
and observed, in every seed, a temporal shift at the level of the target syllable (p
< 0.001). In few seeds (10%), we observe an effect in the subsequent syllable, with
a significance level of p < 0.05 and a smaller ( ∼ 1
2 x) t-value compared to one of
the target syllable (x). In terms of change in mean duration, in this example case
with interference, the target syllable changes by 0.94 ms and the following syllable
by 0.4 ms. In the averaged results, no significant (p < 0.05) change in any other
syllable, except for the targeted one is present. Taken together, these results show
an effect at the target syllable level, but no discernible effect on the other syllables
(Fig. 6.2).

Underlying Mechanisms of Behavioral Adaptation

The change in synaptic weights (∆W) drives a change in population activity and
bump speed, causing the temporal shift. Hence, the patterns of this change
(∆W) reveal important information about the underlying mechanisms of behav-
ioral adaptation. Upon looking at the matrices of the ∆W at the end of learning,
we observe the change is localized on a portion of the presynaptic neurons, but
it is diffused across all postsynaptic neurons. However, even in the postsynaptic
neurons, the main effect (in terms of magnitude) can be observed in the same lo-
calized population. These affected neurons are in fact the neurons correlated with
the target syllable.

99

6 A Flexible Model of Motor Timing: Behavioral Adaptation

Figure 6.2: Learning is specific to the targeted syllable. 10 runs (of 1000 trials) of learning,
aiming to achieve syllable duration shortening (red)/ lengthening (blue) are
run. For each of the 10 runs in the three conditions (baseline/increase/decrease
duration), a mean duration is computed from the respective duration distribu-
tions (10 mean values per condition) and these are shown as points in the bar
plot. Baseline mean durations are displayed in gray. \* stands for p < 0.001.

As it was described in Chapter 5 we have a network of 1000 neurons, equally
split into 5 equal segments of 200 neurons, which each define the duration of one
of the 5 syllable. The start and the end of the syllable is defined by the moment
the center of mass of the bump crosses the ’start’ neuron and the ’end’ neuron.
As the bump approaches the ’end’ neuron, a bigger and bigger portion of it en-
gages neurons associated with the following syllable. The amount of the neurons
affected depends on the width of the bump. In rewarded trials, the connections
emerging from these presynaptic neurons will be likewise strengthened. Based
on these observations and for illustration (clarity) purposes, in Fig. 6.3(A,C), we
show only these 250 neurons, where 0 and 200, are respectively, the neurons at the
start and end of the target syllable.

In Fig. 6.3 (A,C), we show that, both when the syllable is targeted for shorten-
ing and lengthening, we observe an effect centered at the diagonal, with almost
the same magnitude, but of different signs. For instance, in the single run, in
the ∆W in Fig. 6.3 A, where the target is to shorten the syllable, we observe a
decrease in the synaptic connections in the upper half of the diagonal and an in-
crease in the lower half. It translates to a weakening of the connections from the
presynaptic neuron 100 to the postsynaptic neurons prior (neuron 0 to 100) and a
strengthening of the ones ahead (neuron 100 to 200). These changes modify the
connectivity profile at the level of the involved presynaptic neurons (but not of the
other presynaptic neurons), making the bump move faster in that area.

100

12Target Syllable45117118119120Duration in msnsns\*nsnsnsns\*nsnsTarget: ShortenBefore LearningTarget: Lengthen6.2 Learning in the Rate-Based Model

Figure 6.3: Localized changes in synaptic weights, following learning. A) ∆W of a sin-
gle run (target: decrease syllable duration), zoomed in at the area of pre and
post-synaptic neurons (n=200) encoding the target syllable and 50 neurons af-
ter. B) ∆W are rotated by 90 degrees, to see the synaptic weight change with
respect to the diagonal. The mean of the ∆W across the presynaptic neurons
encoding the target syllable, averaged across 10 runs. The thicker line repre-
sents the mean and the filled in area the standard deviations of each of the
10 runs’ averaged ∆W(across the presynaptic neurons). C, D) Same as A and
B for syllable duration lengthening. Note: The pre-learning W is scaled for
illustration purposes.

Moreover, we investigate ∆W across different runs and present an average. First,
since we saw in panel A and B, that the changes occurring are with respect to the
diagonal, we rotate the ∆W matrix by 90 degrees to get a representation based
on the diagonal. Then, we average across the columns (presynaptic neurons), to
investigate the averaged effect of all involved presynaptic synaptic to the postsy-
naptic neurons. Lastly, we average the effects on the postsynaptic neurons across
10 runs. The results are illustrated in Fig. 6.3 (B,D). Consistent with what we re-
ported at the single run level, in the case of syllable shortening, we can clearly see
a synaptic weight decrease to the preceding postsynaptic neurons and an increase
to the following ones. The flipped version with respect to the y axis, is seen in the
other protocol (lengthening). Hence, the mechanisms involved are very similar.

The reported modification pattern is in fact a modification of the bias β, i.e. an
increase. As described in the previous chapter, β grants feedforwardness to the

101

D.C.A.B.6 A Flexible Model of Motor Timing: Behavioral Adaptation

network, by defining a bump centered further ahead from the diagonal. It hence
affects the speed of bump movement. We also showed that this relationship is
quasilinear, i.e. an increase in bias, increases bump speed. The presented ∆W in
Fig. 6.3 (B) shows an example of increasing the bias by two different mechanisms,
during learning. If the synaptic weights to the neurons ahead of the ones defined
by the bias are strengthened and the ones prior to it are weakened, an increase in
bias occurs.

To better interpret and put into context the results of our learning rule in the
synaptic weight change, we would like to summarize some important contribut-
ing factors, originating from the learning rule:

(i) The learning rule dictates an eligibility trace spanning from the start to the
end of each syllable (Eq. (6.2)) and only the target syllable can be given a reward
of 1.

(ii) Based on equation 6.2, the mean firing rate of only the presynaptic neurons
active at the time of the target syllable, is taken to compute the eligibility trace.
This corresponds to the positions, where the dynamic COM’s discretized form
(neuron) falls in the segment [α i
s n] and a few following neurons, which are
active due to the shape/width of the bump.

s n, α i+1

(iii) The reinforced synaptic weights can be with any of the postsynaptic neu-
rons. However, even in this case, the effect is more pronounced in the regions
corresponding to the target syllable encoding neurons. Other effects are averaged
out.

102

6.3 Learning in the SNN

6.3 Learning in the SNN

In this section, we present the results of the application of the same learning for-
malism (R. Williams, 1992) in the spiking neural network (6.1),(6.2). We will show
our results with an exponential integrate and fire neuronal model, with an AdEx
neuron model and in a two population (EI) network of exponential integrate and
fire neurons. As already mentioned in Chapter 5, in Table 3.1, the size of the net-
work used for the SNN is 3000 neurons, about 7 times less than the song-related
HVCRA population (20,000). With the current model, we get at most 10 neurons
active at the same time (timestep), as compared to 100-200 reported in HVC.

Only three syllables are investigated, the one prior to the target, the target and
the following syllable. This choice was guided by the results from our work in
the previous section with the rate based model, which showed that when there
is an effect in the other syllables, it is always in the following one. Everything in
the learning rule is identical with the one presented in the rate model, except the
mean firing rate, the learning rate γ, which equals 0.04 and the number of trials
(200). Since no mean firing rate is present, it will either have to be computed based
on the generated spikes or replaced by another parameter. We choose to do the
former and explain below how it is computed.

Syllable Duration and Learning Signal

We compute the ’mean firing rate’ by first generating a binary matrix from the
spikes, and then convolving this matrix in time and space2, with a Gaussian kernel
of standard deviation 5 ms and 50 neurons respectively. This provides a narrow
bump of activity in both dimensions, the center of mass of which indicates the
activity peak. Just like in the rate model, the timepoints at which the center of
mass of the bump crosses the boundary neurons, define the syllable duration. The
same bump-like signal is also fed into the learning algorithm.

This choice was made considering this signal as similar to the neuronal activity
in the presence of a larger network (20,000 neurons). As briefly mentioned above,
with our current network size and propagation speed, about 5- 10 neurons are ac-
tive at the same time-step (∆t), compared to ∼ 100- 200 active in HVC. Hence, the
activity is less continuous than in HVC and reflects the stochasticity of the noise
(with a spatial convolution, σ = 2 neurons), which was chosen to reproduce the
duration variability reported from experiments. To compute syllable duration, a
center of mass of activity is necessary. Assigning one of the 5- 10 neurons active as
the most active or as the center of mass would not be precise enough in capturing
the whole dynamics. In this context, a small- windowed convolution in space is
necessary. Moreover, as the neurons have bursts of spikes, a temporal correlation
with a 5 ms standard deviation (σ) in a 10 ms burst is useful. In the context of
learning, due to stochasticity, the mean over only 10 active synapses, reflecting our

2In this chapter, the space we refer to is feature space, unless otherwise stated.

103

6 A Flexible Model of Motor Timing: Behavioral Adaptation

10 active neurons at one ∆t, is less reliable than the total ∆W computed from 100
-200 synapses underging synaptic plasticity in HVC. One way to account for this
is by smoothing the activity as described above.

6.3.1 Results
Shortening: Exponential Integrate-and-Fire Neuron

As explained above, we first run 50 trials prior to and following learning. We
acquire a mean baseline duration of 50.5 ms, with a standard deviation of 1.1 ms.
Following 200 trials of learning, targeting syllable shortening the mean syllable
duration becomes 47.2 ms, with standard deviation of 0.95 ms (Fig. 6.4a). The
difference is 3.29 ms, corresponding to a temporal shift of ∼3 standard deviations
from the baseline distribution. Moreover, the mean change across 8 runs amounts
to 3.14 ms, with the lowest run difference at 2.01 ms and the highest at 3.6 ms.

(a) Effect of reinforcement learning on duration distribution shift on a single run.

(b) Averaged effect of RL across runs.

Figure 6.4: Representation of the effect of learning in a behavioral adaptation paradigm
as modeled by an Exponential Integrate and Fire Neuron Model (a) Target
syllable duration distribution before and after reinforcement learning. Dura-
tion distributions are computed as explained in section 6.1. (b) Adaptation is
specific to the target syllable and no effects are observed in the adjacent and
non-adjacent syllables on the averaged results of 10 runs. \* stands for p <
0.001.

104

4647484950515253Duration in ms0.00.10.20.30.4ProbabilityBefore LearningTarget: Shorten1Target Syllable346485052Change in duration in msns\*nsTarget: ShortenBefore Learning6.3 Learning in the SNN

We follow the same protocol explained in section 6.2.1 to investigate the pres-
ence of interference. The results of 8 averaged runs show no interference in the
adjacent syllables. However, at the level of individual runs, 3 out of 8 (37.5 %) have
a significant interference (p < 0.01). In these three cases, the target syllable mean
changes respectively by 3, 2 and 2 ms, whereas the following syllable changes by
0.97, -1.2 and 1.2 ms. The ratio of change is not constant in the three cases and
it is not always in the same direction, i.e. the following syllable is increased or
decreased. Such bidirectional change of the following syllable is likely the cause
of averaging out, i.e. of no interference in the averaged results.

Figure 6.5: Four simulated birds across learning (Exponential IF): Change in dura-
tion across 200 trials of learning in the Exponential Integrate-and-Fire neuron
model. The results from 4 seeds are shown, where the first and last bars re-
spectively represent, the 50 baseline (B) trials and the 50 post RL (P-RL) trials.
The 200 trials in the middle show the progression of learning in time. They are
binned in 4, each containing 50 trials. In the first row the change in duration
of the target syllable is shown, and in the second that of the following syllable.
That is because, whenever we see an effect in the other syllables it is always in
the next syllable. In black, baseline and post-RL distributions.

Upon looking at the ∆W, we observe a weight modification, quite different
In the single run ∆W, we do
from the one witnessed in the rate-based model.
not see a clear effect centered on the diagonal and it becomes harder to interpret
the effect by looking solely at the connectivity matrix in Fig.6.6. An observation
of the averaged results provides more insight. The postsynaptic neurons affected

105

B1234P-RL64202Target Syllable Duration change in msSimulated Bird 1B1234P-RLSimulated Bird 2B1234P-RLSimulated Bird 3B1234P-RLSimulated Bird 4B1234P-RL432101234Next Syllable Duration change in msB1234P-RLB1234P-RLB1234P-RL6 A Flexible Model of Motor Timing: Behavioral Adaptation

are rather distributed, with the largest effect observed at the level of the (i) self-
connections of the bump and (ii) following it (up to 700 neurons after) (Fig.6.6,
right). (i) The first observation is that of an increase in synaptic weights at the level
of the diagonal, i.e. all connections to neighbouring neurons are strengthened.
Neighbouring neurons are defined by the width of the activity bump in space.
The increase in synaptic weights at this level likely reflects a Hebbian-like learning
mechanism, and serves as a mechanism to conserve the bump’s stationary state.
Hence, it could slow down the bump slightly.
It is a particularity of the effect
of the learning rule in the spiking neural network and it is present in the AdEx
model as well. It was not present in the rate based neuron model.

Figure 6.6: How do the weights change? Change of ∆W weights in a single run. Only
the neurons affiliated with the target syllable are plotted (n = 450). (Right) The
average mean across the 10 runs. The target is to decrease the duration of the
syllable. In red the averaged change in synaptic weights, based on the distance
from the presynaptic neurons, affiliated with the target syllable. In gray, the
Gaussian connectivity profile of the presynaptic neurons to the postsynaptics.

(ii) On the other hand, the increase in the weights after the bias, provides an
addition to the bias, and thus, increases it. Such an increase in the bias conse-
quently increases the speed of the bump/activity in the location defined by the
presynaptic neurons involved. Just like we described in the rate, only the presy-
naptic neurons correlated with the target syllable are affected. However, there
is quite a high variability in the weight changes, as compared to our previous
results. This observation, taken together with the behavioral outcome revealing
bidirectional interference in the single runs, drives us to speculate that the simu-
lated ’birds’ incorporate different mechanisms in adapting syllable duration to an
external reward.

106

-1000-30003001000Neuron index difference (pre-post)W pre-learningTarget: ShortenBias0200400Presynaptic neurons0200400Postsynaptic neurons0.150.15W6.3 Learning in the SNN

AdEx

In chapter 5, we state our reasons for choosing an AdEx neuron model. These rea-
sons are mostly to reproduce biologically realistic dynamics and more specifically
the burst like activity in HVC, driven by the calcium channel dynamics. In this
chapter, we started with a simple exponential IF model and showed the effects of
learning. Here, we explore whether adding an adaptation current to the neuron
makes a difference in the learning rate or in the ∆W. A recent study (Kubo et al.,
2023) has revealed additional implications of neural adaptation to learning in an
artificial neural network, i.e. a facilitation of learning. This may or may not be the
case in the ring attractor model. An important contributing factor is the role of
adaptation in bump propagation, and furthermore its speed. There is an interplay
between the speed caused by adaptation and the one by the bias.

Here, we investigate the experiment both in the direction of shortening and
In the case of the latter, the learning rate, has to be adapted and
lengthening.
lowered in order to avoid interference. The underlying reasons of this difference
between the two paradigms remain to be further investigated.

(a) Effect of reinforcement learning on duration distribution shift at a single run level.

(b) Averaged effect of reinforcement learning in 10 runs.

Figure 6.7: Representation of the effect of learning in a behavioral adaptation in
paradigm as modeled by an Adaptive Exponential Integrate and Fire Neu-
ronal Model (a) Target syllable duration before and after reinforcement learn-
ing. Duration distributions are computed as explained above in subsubsection
6.1. (b) In the case of syllable shortening, adaptation is specific to the target
syllable and no effects are observed in the adjacent and non-adjacent syllables
on the averaged results of 10 runs. In the case of lengthening, there is a sig-
nificant effect also at the level of the following syllable. In the individual runs,
this effect is observed in 50- 60% of the cases.

For the case presented in Fig. 6.7a (right), we acquire a mean baseline duration
of 50.48 ms, with a standard deviation of 0.96 ms. Following the learning pro-
tocol with 200 trials for syllable shortening the mean syllable duration becomes
47.07 ms, with standard deviation of 0.96 ms. The change is 3.4 ms (Fig. 6.7),

107

6 A Flexible Model of Motor Timing: Behavioral Adaptation

corresponding to a temporal shift of ∼3 standard deviations from the baseline
distribution. Moreover, the mean change across 10 runs amounts to 3.1 ms, with
the lowest run difference at 1.8 ms and the highest at 5.6 ms.

No interference is observed in the averaged results, in case of syllable shorten-
ing. However, two of the 10 runs present with interference in the next syllable.
The significance is p < 0.01, whereas the magnitude of change is in relation to the
one of the target syllable is as follows. The target syllable mean change, in the
two cases, is 3.29 ms and 5.6 ms and on the following syllable 0.8 ms and -2.9ms,
respectively. A bidirectional effect on the next syllable’s shift is also observed here,
i.e. both lengthening and shortening alongside the shortening in the target sylla-
ble. We show 4 different runs across the learning trials in Fig. 6.8, to illustrate
the effects at the level of the target and following syllable. In contrast, in the case
of lengthening, interference is present at the level of the following syllable, in the
opposite direction.

Figure 6.8: Four simulated birds across learning (AdEx) to shorten the duration of a
target syllable. Change in duration across 200 trials of learning. Just like in
Fig. 6.5 the results from 4 seeds. In the first row the change in duration of the
target syllable is shown, and in the second that of the following syllable.

Moreover, an illustration of the final ∆W for a single run and the average across
10 runs are shown in Fig. 6.9. Notably, it is dissimilar from the rate ∆W and quite
similar the Exponential IF. The postsynaptic neurons affected are relatively more
localized, although they are still not at the level of the neurons encoding the target

108

B1234P-RL864202Target Syllable Duration change in msSimulated Bird 1B1234P-RLSimulated Bird 2B1234P-RLSimulated Bird 3B1234P-RLSimulated Bird 4B1234P-RL42024Next Syllable Duration change in msB1234P-RLB1234P-RLB1234P-RL6.4 Learning in the EI Network Model

syllable ([−200 : 250]). The same ’conservation’ reinforcement at the level of the
self-connections (bump), as in the eIF, is present. As in eIF, the mechanism driving
the bump faster, is the increase in the area following the bias.

Figure 6.9: How do the weights change in the AdEx neuronal model? Change of ∆W
weights in a single case and the average mean across the 10 runs. In the upper
panel, the target is to decrease the duration of the syllable and in the lower
panel, to increase it.

6.4 Learning in the EI Network Model

Furthermore, we investigate learning in the EI Network with eIF neurons.
In
contrast to the model presented in Chapter 5, here the connection probabilities
between the two populations are set to 1. We use the same learning rule in the
EI network first presented in the beginning of this chapter. The plasticity rule
only affects the E-E synaptic weights. However, the changes in weights, do not
only affect the excitatory population, but as they are in a loop, the inhibitory
population as well.

For the case presented in Fig. 6.10a (right), we acquire a mean baseline duration
of 61.5 ms, with a standard deviation of 2.5 ms. Following the learning protocol of
300 trials for syllable shortening the mean syllable duration becomes 58.4 ms, with
standard deviation of 2.5 ms. The change is 3.1 ms, corresponding to a temporal

109

6 A Flexible Model of Motor Timing: Behavioral Adaptation

shift of ∼ 1 standard deviations from the baseline distribution. Using the same
protocol for syllable lengthening, the results are similar, as shown in Fig.6.10a
(left).

Moreover, in the shortening experiment. the mean change across 12 runs amounts

to 2.1 ms, with the lowest run difference at 1.1 ms and the highest at 3.1 ms. When
the number of trials per run is increased to 500, we see a mean change of 3.4
ms, with a lowest run value at 2.76 and the highest at 4.3 ms. No interference
is observed in either cases in the averaged results (Fig. 6.10b). However, in the
500 trials runs, one of the 5 runs presents with interference in the next syllable.
The significance is p < 0.01, whereas the magnitude of change is half of the one
observed in the target syllable. The target syllable change in mean is by 2.81 ms
and the one on the following syllable at 1.4 ms.

On the left, the results of the lengthening experiment are shown. In terms of
effect at the level of the target syllable, they are very similar. However, there is
visible interference in the opposite direction of the target syllable change in the
the following syllable’s duration decreases, as the target
following syllable, i.e.
syllable’s increases. The reason for such a difference between the two experiments
remains unclear and is not further investigated in this manuscript.

(a) Effect of reinforcement learning on duration distribution shift at a single run level.

(b) Total effect of reinforcement learning across 10 runs.

Figure 6.10: Representation of the effect of learning in a behavioral adaptation in
paradigm as modeled by an EI network of Exponential Integrate and Fire
Neuronal Model (a) Target syllable duration before and after reinforcement
learning. Duration distributions are computed as explained above in subsub-
section 6.1. (b) Adaptation is specific to the target syllable and no effects are
observed in the adjacent and non-adjacent syllables on the averaged results of
10 runs.

110

6.4 Learning in the EI Network Model

Figure 6.11: How do the weights change in the EI network model? Change of ∆W
weights in a single case and the averaged mean across the 10 runs.
In the
upper panel, the target is to decrease the duration of the syllable and in the
lower panel, to increase it..

The synaptic weights are altered with a different pattern (Fig. 6.11, upper pan-
els). When compared to the one population eIF model, which is the same neu-
ronal model, but does not include inhibition, the difference is clear. While the
effect on the further away neurons is very noisy, the main effect is at the postsy-
naptic neurons preceding the diagonal. There is a clear minimum right before the
diagonal/self-connections and a slight increase in weights following the it, with a
peak (similar to the two previous ∆W) between the diagonal and the bias. The dip
in activity, which can also be seen from the single run weights, slightly changes
the connectivity shape. It is an alternative way of a relative bias increase (similar
to one of the mechanisms in the rate model). Hence, it increases the speed of the
bump at the location determined by the presynaptic neurons involved.

111

6 A Flexible Model of Motor Timing: Behavioral Adaptation

Figure 6.12: Four simulated birds across learning to decrease syllable duration in an EI
network (Exponential IF): Change in duration across 300 trials of learning
in the Exponential Integrate-and-Fire neuron model. The results from 4 seeds
are shown. They are binned in 4, each containing 50 trials. In the first row the
change in duration of the target syllable is shown, and in the second that of
the following syllable.

6.5 Comparing Model Results to Experimental Data

There is significant evidence from the literature, that a Conditional Auditory
Paradigm makes the bird shift its duration in both directions, left and right, i.e.
to decrease or increase mean syllable duration (Ali et al., 2013; Pehlevan et al., 2018).
Moreover, the effect of the CAF on the other syllables is investigated and an ab-
sence of interference in any of the syllables is reported. Our averaged results in
all the models support this finding, but we do notice interference in a small per-
centage of the runs (10% for rate, 37.5 % for eIf and 20% AdEx and EI). They are
always in the syllable following the target and the magnitude of change is smaller.
As this effect is actually averaged out when we look at 10 different seeds, we won-
der if that was also the case with the experimental data and what the magnitude
of change in the next syllable for each bird across days is. Moreover, interference
is present even in the averaged results when the syllable is targeted for lengthen-
ing. To address these questions, we use data previously collected in the lab in a
CAF paradigm. The methodology and most of the results are reported in the the

112

B123456P-RL10.07.55.02.50.02.55.07.5Target Syllable Duration change in msSimulated Bird 1B123456P-RLSimulated Bird 2B123456P-RLSimulated Bird 3B123456P-RLSimulated Bird 4B123456P-RL1086420246Next Syllable Duration change in msB123456P-RLB123456P-RLB123456P-RL6.5 Comparing Model Results to Experimental Data

thesis of Ursu (2023). However, the findings on the effect on the next syllable are a
preliminary finding from the data and have previously not been reported.

6.5.1 Methods

Behavioral Paradigm

Adult zebra finches (aged >90) were used in the following experiments. They were
housed in a 12h light/ dark cycle and provided food and water ad libidum. For
the first three days the bird was singing without any reward. Based on the first
song spectrograms, a syllable in each bird was chosen for modification (length-
ening). In the fourth day, the conditional auditory feedback protocol was begun.
A microphone captures the sound of the bird’s song, which is then transferred to
the amplifier and then to the software, through which the duration is computed
based on the envelope of the song (Skocik and A. Kozhevnikov, 2013).

Whenever the duration of the chosen syllable does not cross a set threshold
(set at the mean of the baseline distribution, which was computed from the first 3
baseline days), real-time audio feedback, in the form of a white noise is given with
a latency of ∼5 ms for 100 ms. Moreover, the threshold is updated dynamically,
based on the bird’s performance in the last 200 renditions. If the fraction of dura-
tions that have not received white noise is ≥ 70%, then the threshold is updated
(Ali et al., 2013; Ursu, 2023). This update is only made in the direction of learning.
For instance, if the syllable is targeted for lengthening and the threshold is at a
value x, it will be increased to x + ∆x if ≥ 70% of the durations where higher
than x. However, it will never decrease, as such an update would not permit
lengthening.

The CAF protocol was continued for a variable number of days (4-10), depend-
ing on how quickly/slowly the bird shifted the target duration distribution. A
minimum of 4-5 days was set for each bird, but if the shift was less than 2 stan-
dard deviations at the end of 5 days, the CAF was continued until it reached
that value. Moreover, we would like to specify that although in the rest of the
manuscript we have referred to the duration as a syllable, in the experimental pro-
tocol the targeted element in the song is actually an interval encompassing both
the syllable and the following gap.

Data analysis

Among the different birds undergoing the CAF protocol, we selected only the
ones that had a interval following the target interval.
In the cases, where the
interval was at the end of the motif, the bird was excluded from the analysis.
This is because we would like to see the adaptation both at the level of the target
interval, and the following one. Moreover, as it was previously reported (Ursu,
2023) some birds did not achieve the temporal shift and some birds presented with
an amplitude increase (N = 7) in the envelope, which was interpreted as a duration

113

6 A Flexible Model of Motor Timing: Behavioral Adaptation

change. However, as this is no pure temporal shift, these birds were also excluded
from the analysis. Hence in the analysis presented below, a total of 8 birds (N = 8)
were evaluated.

The extracted audio files were band-pass filtered at cutoff frequencies of 500
and 8000 Hz, then squared and low-pass filtered with a box car window of 10 ms
(Ursu, 2023), providing the envelope. For each bird, we manually select a thresh-
old, based on which the interval is segmented. Then, we manually label 100 -
200 motifs per bird, and use them as training data for the HVC (Nicholson, 2018)
software, a supervised machine learning software used to perform automatic in-
terval labelling. It then predicts the annotations for the rest of the motifs. After
the prediction is complete, a text file for each song is exported, with the onset and
offset of each interval and the respective label.3

6.5.2 Results

Behavioral data reveal interesting findings. The duration of the target interval and
the following interval of the 8 birds presented was variable. We use the durations
in the third day of baseline (Fig. 6.13) and compute the mean baseline duration for
each bird and then average them across birds. The mean across birds is 123 ms for
the target interval, with a mean standard deviation of 3.4 ms and 169 ms with a
standard deviation of 4.4 ms for the following interval.4 We present the durations
with respect to the difference from the baseline duration’s mean. The duration
variability (1.5-4 % of mean durations) discussed above is also visible from these
plots (Fig. 6.13).

In the last day of CAF the overall mean target interval duration is 145 ms (stan-
dard deviation of 5.7 ms) and that of the following interval 163 ms (standard
deviation 3.8 ms). The difference (δduration) is 22 ms (18%, 4.4σ) at the level of the
target interval and 6 ms (3.5%, < 2σ) on the next interval. Upon looking at the
individual effects from baseline to the last day of CAF, as a mean duration, we
observe changes in interval lengthening, from 7 to 30% the interval duration and
an effect in the following intervals from 1 to 8%.5

The mean change per day across birds for the target syllable is 3.46 ms and for
the next syllable 0.84 ms. Using a one-sample t-test to compare the difference per

3A detailed description of the analysis steps and pipeline used in the lab, compiled by Remya

Sankar: https://github.com/rsankar9/HVCHackathon/tree/main/HVC.

4Following the order in Fig.6.13, the birds had mean target intervals of 137, 163, 97, 142, 79, 165,

103 and 125 ms. Respective standard deviations are 3.3, 2.6, 4.1, 4.4 , 5.4, 2.5, 1.9, 3.2 ms.
The following intervals’ mean durations were 194, 178, 136, 206, 145, 228, 187 and 75 ms. Re-
spective standard deviations are 2.9, 3.5, 2.9, 4, 9.7, 5, 4 and 2.7 ms.

5Following the order in Fig.6.13, after learning, the birds had mean target intervals of 146.34,
180.55, 120.69, 162.8 , 103.55, 168.78, 118.95 and 161.78 ms. Respective standard deviations are
2.8, 4.9, 5.1, 7.2, 10.9, 4.2, 3.7 and 7.2 ms.
The following intervals’ mean durations were 190.19, 176.1 , 125.15, 202.08, 140.1 , 215.14, 184.47,
72.16 ms. Respective standard deviations are 3.6, 3.6, 2.9, 4.8, 5.6, 3.5, 3.4 and 2.7 ms.

114

6.6 Discussion

day with 0, we show a significant change for the target syllable, with a p value of
p = 0.009 and for the next syllable with p = 0.018.

Moreover, in some of the birds, such as bird 2, 3, 6 the change in the following
interval is very clear and in the opposite direction, whereas other birds such as 4
and 5 show more diverse effects (Fig. 6.13) across days. For instance, bird 5 shows
an increase followed by a decrease during the CAF paradigm. The changes are
considerably smaller in magnitude as compared to the ones in the target interval
(∼5 times less), but they are present, they are not always in the same direction
across days and need to be explored more.

6.6 Discussion

In this chapter, we show the results after we have implemented a reinforcement
learning rule into our models with the goal of simulating the CAF behavioral
paradigm. Although the same parameters are used in the three spiking models,
there are differences in mean and standard deviation. The mean is likely affected
by the addition of the adaptation current (increases bump speed and decreases
duration) and the addition of an inhibitory population, which appears to slow
down the bump and increase duration. On the other hand, the variability (σ) is
similar in eIF and AdEx (∼1ms), but increases significantly in the EI network,
amounting to ∼2.5ms. These variabilities correspond to a coefficient of variation
of ∼2% (eIf, AdEx) and ∼4% (EI), similar to ∼1-10% CV range reported in young
adult zebra finches (Glaze and Troyer, 2013; Glaze and Troyer, 2012). The increase of
variability in the EI model could be related both to an effect of the I population,
but also due to the increase in duration (61.5ms as compared to 50.5ms in the
other two models). The latter could represent with the scalar property of timing,
which states that a longer duration has a higher variability. However, no change in
standard deviation was seen when the duration changed to 58 ms. It is probable
that a bigger difference in mean (within model) is necessary to acquire a change
in variability. This remains to be tested.

With respect to learning, in the 4 used models, we acquire a temporal shift of
the distribution of the target interval, with an average of 1.8 ms (rate), 3.1 ms
(eIF), 3.1 ms (AdEx) and 3.4 ms (EI) respectively. In the averaged results, no effect
on the adjacent interval is present. However, at the single run level, we report
interference in some of the runs (10- 38%, depending on the model used), with a
temporal shift lesser than in the target interval.

In the rate based model, we implement learning in both directions, to shorten
and lengthen the interval duration. We observe that the magnitude of change
in interval duration, is higher when it is targeted for shortening as compared to
lengthening. This could suggest that in such a protocol, it is easier to decrease
It appears to be the case in the behavioral paradigm as well
interval duration.
In the three spiking models, we focus on
(Ali et al., 2013; Pehlevan et al., 2018).
explaining the mechanisms of interval shortening. However, for the AdEx and

115

6 A Flexible Model of Motor Timing: Behavioral Adaptation

EI network model, syllable lengthening is presented in the figures as well. Using
the same parameters for syllable lengthening, we observed that in order to not
get a very high interference at the next interval (in the lengthening experiment),
the learning rate had to be decreased to γ = 0.004. Following this modification,
less interference was observed, but it was still present, always at the level of the
next syllable and in the opposite direction. These reasons drove us to look at the
experimental data and investigate whether there is an observable change at the
level of the syllable following the target one.

Hence, we confront the present results with experimental data, and observe
slight interference present in most birds. At the end of learning, all the birds
had a significant temporal shift of more than 2.8 standard deviations in the target
interval.
In the following interval, only two birds had a shift of more than 2
standard deviations. Based on the criteria put by the experimenter (Ursu, 2023),
we could say 25% of the birds presented with interference in the next interval. As
in previous reports (Pehlevan et al., 2018) and as in our simulations, the averaged
effects on the following interval are not significant, accounting to about 1.4σ on
average (affected by a 4σ change in Bird 3), whereas the effect in the other interval
is on average 6.8σ.

At the end of the CAF, the effect on the next interval is at the opposite direc-
tion with that of the target, i.e.
if the target interval is increasing, the following
interval is decreasing. However, on a day by day basis, we observe changes in the
same direction as well. These observations might hint at the existence of diverse
learning mechanisms across birds and the influence of specific training days on in-
terference. While the simulations seem to echo these findings, the limited sample
of just eight birds restricts the strength of our analysis. As such, a more extensive
sample would be beneficial.

116

6.6 Discussion

Figure 6.13: Interval duration change across days of 8 birds undergoing CAF. Each bin
represents a day, each point the change in duration of one interval from the
In black, the baseline and return
mean interval duration during baseline.
durations are represented. The durations of the other days are in colors, and
the mean duration is shown by a black line. The x axes are aligned at the first
day when CAF was started (day 0).

117

7 Discussion and Conclusions

.

7.1 A Robust and Flexible Model of Motor Timing using Attractors . . . 119
7.1.1 Rate and SNN Model
. . . . . . . . . . . . . . . . . . . . . . . 120
7.1.2 Relating the EI model with the Literature . . . . . . . . . . . . 121
7.2 Biological Relevance and Interpretation . . . . . . . . . . . . . . . . . 121
. . . . . . . . . . . . . . . . . . . . . . . . . . 121
7.2.1 Motor Timing .
7.2.2 Learning Rule for Behavioral Adaptation . . . . . . . . . . . . 124
. . . . . . . . . . . . . . . . . . . . . . . . . . 128
7.3.1 Cellular and Network Properties . . . . . . . . . . . . . . . . . 128
7.3.2 HVC in Bengalese Finches and Canaries . . . . . . . . . . . . 129
. . . . . . . . . . . . . . . . . . . . . . . . . 130
7.4.1 A Continuum? Synaptic Chains to Asymmetric Ring Models 130
Initial Learning in Unstructured Networks . . . . . . . . . . . 130
7.4.2
7.4.3 Return to Baseline Duration . . . . . . . . . . . . . . . . . . . . 131

7.4 Perspectives .

7.3 Limitations .

.

.

.

.

.

.

.

.

.

.

.

.

.

.

In this chapter, we discuss the implications of our previously presented results
and suggest their position in the literature of timing and songbirds. Although
each individual results chapter is followed by its own discussion section, here, a
more general insight on the implication of our proposal as a whole is compiled.
Moreover, we rediscuss limitations and some methodological choices, the support
in the literature that drove them, and the possible effect they may have had in our
results. Several impromtu findings were acquired during the work, which could
drive further experimental and numerical work. We try to formulate possible
proposals in both directions. Lastly, we include a section on future perspectives.

7.1 A Robust and Flexible Model of Motor Timing using

Attractors

In Chapter 5, we have presented a robust model of timing. We claim the robust-
ness of our model based on the extensive literature on ring attractors, numerical
analysis to find the parameter space allowing bump formation and perturbation
protocols. We show that a ring architecture, with a gaussian connectivity profile,
can give rise to neuronal dynamics consistent with those observed from electro-
physiological recordings. Each neuron fires a burst of 3-6 spikes, with an approx-

119

7 Discussion and Conclusions

imate duration of 10ms and activity propagation is guaranteed by a feedforward
term, the bias. The speed of propagation can be adjusted by changing the bias
term, demostrating temporal scaling.

Moreover, in Chapter 6, we focused on the flexibility of our model. We numeri-
cally implemented a well known behavioral paradigm, CAF, and showed that our
model is flexible and can change the duration of a target syllable in response to a
reward profile, implemented with reinforcement learning. Previous work has sug-
gested that flexible time keeping requires a one to one mapping between synapses
and the interval duration (Pehlevan et al., 2018). Our weight profiles present a
widespread effect on multiple synapses, but by default due to the learning rule, it
is concentrated on the synapses projecting from the presynaptic neurons affiliated
to the target syllable. Moreover, we see that although a minimal effect is observed
in the extremities, the synapses most reinforced are the ones with the postsynaptic
neurons, also affiliated with the target syllable. This is mostly consistent with the
suggestion of a one to one mapping.

It is challenging to construct a model that is both robust and flexible, as these
two properties tend to be in opposite ends of the spectrum (Khona and I. Fiete,
2022). However, not only is this necessary in a general computational model, but it
is even more in our specific model which aims to simulate a very particular area,
with very clear dynamics, exhibiting both robustness and flexibility.

7.1.1 Rate and SNN Model

We started our numerical simulations with a coarse grained approach, using a
rate based model. The first results on robustness, duration distribution and rein-
forcement learning are presented in this model. This helped us acquire an under-
standing of whether such an architecture would be able to able to simulate HVC
dynamics and furthermore behavioral adaptation. However, although we used a
very narrow Gaussian for the connectivity profile, the time constant of our rate
model constrained the emergent bump width (narrowness), not allowing us to
reach the observed 10 ms burst activity in HVCRA neurons.

Alongside the motivation to investigate the effect of single neuron dynamics
inside this architecture, this drove us to expand our simulations to a spiking neural
network. Moreover, we added adaptation, to ensure the bursts observed in HVC.
This provides a more biologically plausible model, constrained by experimental
observations. Our results with the SNN are equivalent to the readout from the
rate based model, both for robustness and flexibility. Moreover in the SNN, at the
single run level, more nuanced results are observed, with slight interference at the
following syllable after learning. This is consistent with previous experimental
results (Ursu, 2023). However, the underlying learning mechanisms in the SNN are
much harder to interpret and possibly require more investigations.

120

7.2 Biological Relevance and Interpretation

7.1.2 Relating the EI model with the Literature

Additionally, a model with two populations of excitatory and inhibitory neurons
was investigated. At the microcircuitry level, there is a loop between HVCRA
and interneurons (Mooney and J. F. Prather, 2005), and moreover, a number of recent
studies have highlighted the importance of inhibition in HVC sequence generation
(Kosche et al., 2015). We used unstructured, non recurrently connected inhibition
and studied at a very basic level the effects of such a population to our results.
We tested the model with different parameters for excitation and inhibition, and
fit those to experimental findings (Kosche et al., 2015). Our results are in line with
the suggestion that HVCRA activity is sufficient to drive structured activity in the
interneuron network (30 Hz, as shown by Markowitz et al. (2015)). However, we did
not investigate recurrent connections within the inhibitory neurons themselves
and the differences appearing in the model in the case of a previously set struc-
tured inhibition. This could provide an interesting perspective for a more detailed
computational model.

7.2 Biological Relevance and Interpretation

7.2.1 Motor Timing

A brief overview of the timing literature and the main proposed neural mecha-
nisms and models were presented in chapter 1 and 3. Here, we would like to
restate the role of songbirds in the motor timing literature, in the order of tens to
hundreds of milliseconds and discuss the role and contribution of our study. Bird-
song is characterized by a temporal structure, similar to human speech (A. J. Doupe
and Kuhl, 1999), with both a syllable and sequence/song level temporal structure.
In the taxonomy of timing (section 1.1), it would be referred to as belonging to
subsecond, explicit, prospective, pattern motor timing. This temporal structure
has been associated with premotor nucleus HVC through different experiments,
including stimulation studies (E. Vu et al., 1994), extracellular recordings (R. Hahn-
loser et al., 2002) and cooling experiments in HVC (Long and M. S. Fee, 2008). HVC
RA projecting neurons fire ∼ 10 ms bursts of 3-6 spikes, time-locked to the song
that span the whole duration of the song. HVC is considered either as the main
timing structure or as a crucial element of a distributed timing system.

Dedicated or Intrinsic Model of Motor Timing

In the light of the two broad classes of conceptual models of timing, the question
arises whether HVC is a dedicated or an intrinsic model of timing. Numerous
studies have shown temporal selectivity in nucleus HVC, either to specific inter-
vals (Margoliash, 1983) or to more complex temporal features of song (like order and
song, bird’s own song) (Gentner and Margoliash, 2003; Lewicki and Konishi, 1995; Mar-
goliash and Fortune, 1992; Mooney, 2000). With respect to motor timing, R. Hahnloser

121

7 Discussion and Conclusions

et al. (2002) first showed the chain-like sequence in HVC during song production
and cooling experiments in HVC revealed a causal link between sequence speed
and song (Long and M. S. Fee, 2008). Taken together, these two aspects of HVC in
sensory and motor timing, could show a more general role of HVC in temporal
processing. This could drive us to consider it as a dedicated model of timing,
however HVC is also crucial in other aspects song learning and song production
(syntax (Y. S. Zhang et al., 2017)), not only with respect timing. Moreover, in terms
of timing, we clearly see a role of HVC in song timing but no such role has been
reported in other sequential motor behavior.

Hence, attributing HVC to intrinsic models of timing would be more intuitive.
In this theoretical framework, time is encoded in the population activity, and is
affected by intrinsic properties of the neurons and network such as time constants,
ionic channels, neuronal adaptation, synapses etc. Population clocks are a subclass
of intrinsic timing models, where time is encoded in dynamic changes of neural
populations (D. V. Buonomano and M. D. Mauk, 1994; Medina and M. D. Mauk, 2000).
The experimental studies in songbirds (R. Hahnloser et al., 2002; Long, D. Z. Jin, et
al., 2010) support the position of HVC as a population clock, as HVCRA neurons
manifest with time-varying activity time-locked to the song. The model used in
this manuscript, the ring model takes part in the population clock subclass of
intrinsic models of motor timing. In the ring model, the dynamic changes in the
population and more specifically in the bump encode timing.

Contribution of the Attractor Model

Our ring attractor model stands as a type of population clock models (Paton and
D. V. Buonomano, 2018), with each attractor state representing a particular time in
the song. In the emergence of each of these states, the individual neuronal and cir-
cuit dynamics are crucial, and the travel in the state space implies time. A previous
model of the same class has been introduced by Laje and D. V. Buonomano (2013),
called dynamic attractor. However, although this model accounts for robustness,
the scalar property of timing and is an embodiment of the theoretical viewpoint
of population clocks, another study (Pehlevan et al., 2018) has presented concerns
regarding its flexibility to behavioral change. As an attractor, we show our model
preserves the same robustness properties, while being flexible. Moreover, this is
supported by a suggestion in the same study that flexibility could as well be a
feature of effective feedforward networks, and an asymmetric Hopfield networks
or other attractor models could provide similar results to a synfire chain. Taken
together, our results show that this is possible with a ring model.

Localized Model of Motor Timing

HVC can be conceptually modeled as a local or distributed timing area. The first
hypothesis considers HVC as the sole driving force of timing, and the second pro-
poses that timing emerges from the interaction between multiple areas including

122

7.2 Biological Relevance and Interpretation

HVC (Elmaleh et al., 2021; Hamaguchi, Tanaka, et al., 2016). In our model, the external
inputs reaching HVC, were considered to be on average homogenous and con-
stant, which would make HVC a localized and effectively autonomous system. We
focus only on modeling the sequential activation observed there. This activity is
likely due to a functionally feedforward network and is generally modeled with
synaptic chains. However, while being functionally feedforward, the underlying
connectivity in HVC is recurrent (R. Hahnloser et al., 2002; Hamaguchi, Tanaka, et al.,
2016; Yamashita et al., 2008).

A connection probability of 0.11 (Mooney and J. F. Prather, 2005) was reported be-
tween HVCRA neurons. With a ring attractor model, we approach the suggested
recurrent architecture with a narrow connectivity profile and through an asym-
metric connectivity pattern, by adding a bias (β), we generate feedforwardness
within it. The narrow connectivity profile is a Gaussian, the width of which is set
based on the reported connection probabilities and the assumption that the con-
nectivity must represent the sparse dynamics observed. Moreover, the added bias
term makes the activity propagate in time, generating a sequence. The bias am-
plitude determines the speed and it is adapted to the sequence propagation speed
in HVC. This is also set to simulate syllable durations in birdsong. Lastly, to our
knowledge no autopses have been reported in HVC so we assign self-connections
to 0 (as in Drew and Abbott (2003)).

We have also explored in Chapter 5 (section 5.3.2) rectangular connectivity pat-
tern. We observe no reportably different dynamics. Hence, we assume that the
chosen profile of a gaussian can be more biologically plausible, with the neurons
sending variable (graded) synaptic weights to other neurons, rather than binary
ones.
In our proposed model, the rectangular profile could instead reflect an
intermediary state between the random connections, prior to learning, and the
final adult HVC network. This could map to observations in mammalian litera-
ture where sparsening (Komiyama et al., 2010) and temporal sharpening (Masamizu
et al., 2014; A. J. Peters et al., 2014) of the neural activity occurs as motor learning
progresses. Another connectivity profile to be considered, since the system is de-
fined in a periodic ring is a von Misses (periodic normal distribution) connectivity
profile. This can mostly be beneficial in exploring the system analytically.

Lastly, in the main models, inhibition is modeled as a non specific, global ef-
fect. Although experimental exploration have revealed patterns in inhibition, it is
unclear whether it is a readout of the existing loop with HVCRA neurons. This is
explored with the EI network, both in terms of model dynamics and its flexibility.

Distributed Model of Motor Timing

Due to the highly connected position of HVC (projections from Uva, nucleus,
Avalanche, CM, NIf and Field L) in the auditory pathway and the song system,
it is important to consider the distributed hypothesis, investigate each of these
structures and discuss their possible role in driving time. As we are focused on
the temporal control of song, the question is whether these projections are present

123

7 Discussion and Conclusions

during song production and to answer it, Vallentin and Long (2015) has shown that
only motor inputs to HVC are present, possibly from Uva, NIf and other HVCRA
neurons. (i) We are already including the connections between HVCRA neurons in
the model. (ii) NIf has been shown not to be crucial in adult song production (Naie
and R. Hahnloser, 2011), but numerous studies have shown Uva is and it is specif-
ically involved in temporal control as well.
(iii) Uva receives bilateral feedback
projections from the brainstem nuclei and stimulation studies have revealed that
focal stimulation in the brainstem inspiratory-related nucleus paraambigualis, can
disrupt song timing (Ashmore, Wild, et al., 2005). Moreover, when Uva is lesioned
bilaterally, permanent song disruption is observed (Coleman and E. T. Vu, 2005; H.
Williams and D. S. Vicario, 1993). Recently, it has also been shown that the projec-
tions from thalamic nucleus Uva to HVC have a spatiotemporal structure (Moll
et al., 2023). Altogether, these findings could suggest a role of Uva in interhemi-
spheric synchronization (Coleman and E. T. Vu, 2005; Schmidt, 2003) .

In the light of these evidence, we add a model where Uva input is present to
illustrate the effect that such an instructive signal would have on the dynamics.
The parameters and model we create are based on recent experimental reports
(Moll et al., 2023), where it was shown that 15% of HVCRA neurons are Uva-driven
neurons. The observed activity of Uva driven neurons at syllable onset/offset is
in line with the observation of periods of interhemispheric synchronization time
locked to syllable onset. In the model, the scalar input Uva is given only to the
neurons present at syllable onset/offset. In a very noisy ’environment’, or in the
case of a delay in propagation in one of the HVCs, we observe that Uva input
is able to quickly synchronize the activity. This shows the ability of our model
to adapt to such an external input and that the model would be a biologically
plausible explanation, even in the case of a distributed timing system.

However, in the learning mechanism, adding Uva would create significant chal-
lenges if the synaptic weights to the Uva driven neurons are plastic. If that is not
the case, then Uva would just present some constrains in terms of how much the
duration can be modified. This remains to be further explored, both computation-
ally and experimentally.

7.2.2 Learning Rule for Behavioral Adaptation

Several models of reinforcement learning involving basal ganglia have been pro-
posed in songbirds. The RL framework is also proposed for vertebrates’ basal
ganglia function. Although evidence has shown that learning in the temporal do-
main does not involve basal ganglia (Ali et al., 2013) and hence it is not modeled in
this work, a general overview of the framework gives insight on the mechanisms
involved.

The aforementioned models include template comparison (Doya and Sejnowski,
1998; M. Fee and Goldberg, 2011; I. R. Fiete, M. S. Fee, et al., 2007), efference copy (Troyer
and A. J. Doupe, 2000) and inverse models (Hanuschkin et al., 2013) (review: Leblois
and Darshan (2014)). The ’AFP comparison’ hypothesis assumes that the song tem-

124

7.2 Biological Relevance and Interpretation

plate is stored in AFP and is compared in area X (Mooney, 2004; J. F. Prather et
al., 2008; Sakata and Brainard, 2008) to the auditory information coming from HVC
about the ongoing song. The result can then be directly transmitted through the
AFP to the motor pathway (Doya and Sejnowski, 1998; Troyer and A. J. Doupe, 2000).
However, this hypothesis assumes auditory feedback activity in the AFP, possi-
bly coming from HVC, which is inconsistent with evidence showing no response
to distorted auditory feedback in area X originating from HVC projections (A. A.
Kozhevnikov and M. S. Fee, 2007; J. Prather et al., 2008) and LMAN (Leonardo, 2004), or
within the basal ganglia (M. Fee and Goldberg, 2011).

An alternative hypothesis presented by (M. Fee and Goldberg, 2011), suggests
that the song-quality evaluation signal, computed after comparison between the
song template or tutor’s memory and ongoing song (auditory cortex), is transmit-
ted through neuromodulatory inputs such as dopamine, from the VTA to area X
(Gale, Person, et al., 2008) as a reward prediction error (Gale and Perkel, 2010). More-
over, area X receives input from LMAN, accounting for variability and from HVC,
which provides a global (fixed) representation of time. If activity in LMAN is cor-
related with good feedback, reward is provided and strengthening of the synaptic
weights between HVC and X occurs. This then drives a temporal pattern of bias in
LMAN in favor of improved song performance, through projections to DLM (loop:
LMAN-X-DLM-LMAN). Their proposed learning rule reads: ∆WHVCX = βLHR,
where R represents the reward reaching the MSNs in area X from the VTA, and the
eligibility trace is defined by H the activity of HVC neurons and L the activity of
LMAN neurons. This hypothesis is in the same line with the computational model
of I. R. Fiete, M. S. Fee, et al. (2007). It assumes the same actor-critic-experimenter RL
scheme (Doya and Sejnowski, 1998), where LMAN is the experimenter, RA the actor
and there is a scalar evaluation signal as a critic. Here, HVC sequence is assumed
to be fixed, and only its mapping to RA is malleable, i.e. HVC RA synapses are
plastic, whereas the synapses from LMAN to RA are considered empiric synapses,
i.e. specialized for experimentation.

In both hypotheses, the role of area X as a critical area in learning is emphasized.
This is consistent with behavioral adaptation in pitch change, where exploratory
variability is provided by the thalamo-cortical circuit and area X is a key area of
reinforcement learning. However, learning in the temporal domain is not well
represented by this hypothesis, as it was shown that the AFP and the song-related
basal ganglia circuits are not needed for temporal plasticity (Ali et al., 2013). More-
over, the findings of the study by Ali et al. (2013) suggest that the learning of these
two features, namely pitch and timing, rely on two different circuitry and more
specifically, learning in the time domain is expressed within the HVC itself. This
suggests that the duration of the song segment is a function of the speed of the
activity propagation and is supported by their recordings, which show a local
stretching/shrinkage of the temporal structure at the level of a syllable targeted
for modification. Below, we explain the interpretation of the RL rule in the context
of learning in the temporal domain.

125

7 Discussion and Conclusions

Biological Interpretation of the Learning Rule

In the light of these results, it is reasonable to assume that variability and the
reward signal project to HVC, either directly or indirectly. In our approach, we
use a reinforcement learning rule, first proposed by R. Williams (1992) and then
used in the context of songbirds by I. R. Fiete and Seung (2006). This all is adapted
to the ring model architecture. Our learning rule can be written as:

∆WHVCRA = γReHVCRA

, with :

eHVCRA =

(cid:90) t

0

dt′
τe

e−(t−t′)/τe ηHVCRA (t′)mHVCRA (t′),

(7.1)

(7.2)

where R is a reward value of 0 and 1 and the weight changes are dependent on
the eligibility trace eHVCRA. The eligibility trace controls the synaptic change am-
plitude and flags whether a synapse is eligible for modification, based on recent
activation of the plastic synapse. Its value is increased during the coactivation of
pre and postsynaptic activity, and decays exponentially with a time constant (τe),
which should roughly match the maximum delay of the reinforcers and hence,
link synaptic processes to behavior. Since HVC signal precedes motor (timing)
activity and thus reward (white noise in CAF) by 35 ms (Ali et al., 2013), τe was
chosen of this value (Pehlevan et al., 2018). Evidence of the presence of an eligibility
trace is supported by several experimental studies in the striatum (Yagishita et al.,
2014), cortex (He et al., 2015), and hippocampus (Brzosko et al., 2015) (review: (Gerst-
ner, Lehmann, et al., 2018)). Taken together, theoretical and experimental evidence
suggest that the eligibility trace is representative of neuromodulatory effect.

In the context of reward and/or surprise, and in the case of songbird learning,
it could be provided to HVC through midbrain (A11: mesencephalic central gray)
(Appeltants et al., 2000; Hamaguchi and Mooney, 2012) and/or PAG (Tanaka et al., 2018)
dopaminergic projection neurons and/or norepinephrine from noradrenergic nu-
cleus subceruleus (A6) (Appeltants et al., 2000).

The experimenter, is considered to be the noise reaching HVC, ηHVCRA and could
biologically map to the noisy synaptic activity within HVC itself or LMAN, which
could reach HVC indirectly through A11 (Hamaguchi and Mooney, 2012) and/or Ad
(Gale, Person, et al., 2008) . However, A11 cannot project to HVC both as a reward
and as the experimenter, as likely they are mutually exclusive. The hypothesis
of possible indirect projections through LMAN driving noise, is supported by the
finding that a lesion in LMAN reduces learning rate and variability. Hence, LMAN
may be a source of variability but possibly not be the only one.

The actor is the activity of the HVCRA neurons, represented by mHVCRA (in the
rate based model).The threshold used to determine the presence or absence of
white noise (negative reward) was updated on every trial, based on the average
syllable duration, as it was done experimentally (Ali et al., 2013; Ursu, 2023).

Altogether, the learning rule reflects a biologically plausible mechanism of how
the synapses in HVC are updated to modify syllable duration in response to a

126

7.2 Biological Relevance and Interpretation

reward profile, coming in the form of an perturbatory auditory feedback. It is in
accordance with the proposed conceptual mechanism proposed and allows us to
investigate timing adaptation as a separate process, independent of other behav-
ioral components.

Confrontation of Simulation Results to Behavioral Data

When the findings following this learning approach are confronted to experimen-
tal data, we get interesting results.

(i) First, previous results (Ali et al., 2013; Pehlevan et al., 2018), have shown that
the bird is able to adaptively modify motor timing of a particular interval, without
showing any effects on the other intervals. This is a critical finding of behavioral
flexibility and could translate to human speech and other kind of motor sequence
production involved in pattern timing. It suggests that one “syllable” in a behav-
ioral sequence can be modified independently of the rest of the sequence.

Our results with the rate based model support this finding. The model is able
to learn to change the duration of a syllable in either direction (shortening, length-
ening), without any interference on adjacent or nonadjacent syllables. However,
these results was more nuanced when implemented in a SNN. In the case of short-
ening, the general averaged effect remained consistent, i.e. no interference was
observed on other syllables. However, upon looking at single runs, in all the three
models (exponential IF, AdEx and EI), we observed an effect at the level of the
next syllable. This effect was averaged out across runs, which could also be the
case in the presented experimental findings. Moreover, in the case of lengthening,
interference was present at the level of the next syllable.

(ii) To test whether this is the case, and investigate if at any point during the
learning process, there is an effect (either a daily effect or a small effect) in the
following syllable, we analyzed data previously collected in the lab. As in our
simulations, the averaged results show no significant interference in the other
syllables. The change in magnitude is too small (<2σ) in comparison to that of the
target syllable.

However, individual birds show different cases of interference present in the
following syllable. Across the birds who have such effects (25%), the effect is con-
sistently in the opposite direction. The presence of interference in some birds, and
not in others could be due to different learning mechanisms, as different birds
present variability (individuality) during learning. An example of such variability
is the different learning rates. Previously presented results showing no interfer-
ence, could be due to averaging effects or it might indicate that we need a larger
sample size. Moreover, as in our simulations, an asymmetry in duration shift
could also be possible. As in the original study both duration shortening and
lengthening are grouped, this asymmetry is hard to assess. On the other hand,
our data comprises of only duration lengthening, so a comparison between the
two protocols is at this time, not possible.

127

7 Discussion and Conclusions

7.3 Limitations

In this work, we start with a rate based model to test our hypothesis, we explore
different kinds of neuronal complexity, while aiming for a low-level representa-
tion and biological plausibility. We do not use conductance based or a Hodgkin
Huxley model, but we believe our assumptions are cost effective and biologically
sufficient. Moreover, we notice that the observed mechanisms are conserved across
the different complexity levels of our models. However, there are certain limita-
tions to our model, that have not been captured by the model and could incite
future work and/or could have affected our results.

7.3.1 Cellular and Network Properties

Primarily, we are modeling only one cell type, the HVCRA neuron. This is based
on evidence that these cells are associated with motor timing, shown both from
recordings of time-locked activity to the song (R. Hahnloser et al., 2002) and from
cooling/heating manipulations which have an effect on their burst time in the
sequence, and consequently to the song too (Hamaguchi, Tanaka, et al., 2016; Long
and M. S. Fee, 2008). However, interneurons and HVCX neurons could also have a
role in song production.

(i) For instance, bilateral inhibition in HVC of interneurons through Gabazine
(Kosche et al., 2015) leads to a degradation in song structure, highlighting their im-
portance in maintenance of activity. We tested this effect in our one population
SNN model, where inhibition is modeled as a global variable. Upon administra-
tion of certain (detailed in Chapter 5) levels of inhibition, the sequence production
degrades. Moreover, we show that the model is much more sensitive to removal of
inhibition, in comparison to addition. This is because inhibition allows a localized
bump formation and its removal could drive it to amplitude instability, which may
map to what is occurring experimentally. Additionally, in one of the models we
also added interneurons (Subsection 7.1.2).

(ii) HVCX neurons are connected to both HVCRA and interneurons, and could
potentially have an effect on the resultant sequence. However, in our model, this
effect was assumed negligible due to experimental findings showing that selective
ablation of X projecting neurons had no effect on song production (Scharff, Kirn,
et al., 2000).

In modeling HVCRA neurons, an important factor is the burst activity observed,
and whether this is driven by network dynamics and input or whether it is rather
an intrinsic property of the neurons. From an experimental perspective, Long, D. Z.
Jin, et al. (2010) have identified L-type calcium channels to have a role in generating
or initiating bursting activity in HVCRA neurons and have suggested that bursts
are calcium-mediated. From a computational perspective, D. Z. Jin et al. (2007) have
shown that an intrinsic burst mechanism increases the robustness of the synaptic
chains used to model HVC.

128

7.3 Limitations

In two different models (D. Z. Jin et al., 2007; Long, D. Z. Jin, et al., 2010), bursting
neurons were simulated with two compartment model, a somatic and dendritic
compartment, containing conductances for generating calcium spikes. However,
these spikes were longer in duration than the HVCRA burst, so D. Jin et al. (2007)
propose that burst duration could be defined by either a shorter dendritic spike or
by the contribution of strong somatic spike frequency adaptation. Another single
compartment approach (Daou et al., 2013), constructed detailed Hodgkin-Huxley
models of the three main model groups in HVC, and showed through experiments
the importance of each conductance, highlighting the effect of calcium-activated
potassium currents and an A-type potassium current for HVCRA. Although our
model does not use conductance based synapses, we use adaptation in the frame-
work of an AdEx model, where the b parameter is assumed to account for the the
effect of calcium dependent potassium channels.

Another important component driving network dynamics are synaptic delays.
In our model with rectangular connectivity profile, we tested the effect of adding
delays as a function of distance, taken from the distibution provided by Egger et
al. (2020). Although in their model, the effect of delays is significant in activity
propagation, it does not seem to convey the same importance in ours. However,
further explorations in the Gaussian connectivity profile could be done, but we do
not expect any changes. In the light of neural field theory, delays have shown to
provide a travelling wave (Palkar et al., 2023), which translated to our model could
have an effect on bump propagation speed. This has not been tested in this work.

7.3.2 HVC in Bengalese Finches and Canaries

Our findings are representative of a stereotypical, linear syntax, such as the courtship
song of the male zebra finch. However, in the presence of branching, or transition
probabilities, where the motif could either be ABCE or ABDE (where A, B, C, D
and E stand for syllables) as observed in Bengalese finches and canaries, they may
not be applicable at the same extent. That does not solely depend on the chosen
computational approach, but more on the role of HVC. For instance, alongside its
role in timing, experiments have shown that cooling HVC also affects transition
probabilities (Y. S. Zhang et al., 2017) in Bengalese finches, suggesting that the pre-
cise burst time encodes transitions. How a ring attractor model could account for
branching, based on spike-times is still unclear. We could imagine two or more
rings sharing part of the same trajectory and then branching to one or the other
ring. The branching mechanism could be probabilistic, and the transition marko-
vian as in a previous model by D. Z. Jin (2009), where the synaptic chains would be
replaced by rings.

129

7 Discussion and Conclusions

7.4 Perspectives

7.4.1 A Continuum? Synaptic Chains to Asymmetric Ring Models

An interesting proposal is that the synaptic chains represented by synfire chains
in HVC models, form a continuum with the asymmetric ring model. We compute
phase diagrams by investigating the network’s evolution after a high perturbation
is provided. In the spiking model (exponential IF) with bias, alongside the three
main states reported in the rate model, we observe a ’hopping’ bump state, where
spike propagation is not continuous but rather jump-like. It manifests as popu-
lations of neurons active at approximately the same time with some jitter due to
noise. This pattern of activation is reminiscent of the synfire chain, where neurons
are organized in layers.

This propagation/chain pattern is present at lower levels of excitation (W2) and
when the ratio between excitation and inhibition is low. We also observe the same
hopping bump phase when the ratio between the bias and width of the connec-
tivity profile is high. Although these observations have not been quantified, they
show that a feedforward network with recurrence, displays similarity in different
regimes with a purely feedforward architecture. A systematic investigation of the
effect of connectivity width, could reveal that in fact synfire chains and attractors
lie at two different ends of the same continuum.

7.4.2 Initial Learning in Unstructured Networks

In this study, we assume a gaussian connectivity profile within HVC neurons.
This is based on experimental findings, showing the percentage of HVCRA con-
nections (Mooney and J. F. Prather, 2005) and the reported strongly interconnected
web (Kosche et al., 2015), with structured excitation and inhibition. We also add
a bias term in the connectivity matrix, which accounts for an effectively feedfor-
ward network. However, whether this structure emerges, or is learned during
sensorimotor learning is a question we have not addressed. Based on the behav-
ior observed in the chosen animal model (zebra finch), the connectivity pattern
and bias could be learned during the sensorimotor phase with exposure to the
tutor’s song. Part of the observed sequential dynamics is also encoded in intrinsic
properties (adaptation) of the neurons or relies on influence from the brainstem
areas (respiratory-related information) and likely has a genetic component (Fehér
et al., 2009b). These three factors can be interconnected and possibly pose con-
strains on the produced song and interact with the connectivity, so they should be
considered as well.

Learning could drive the development of the neural sequences, through an ex-
ternal source, in this case the tutor, which repeats the same sequence and entrains
the neurons in HVC to spike in a certain order (Amari, 1972; Nowotny et al., 2003).
Another hypothesis suggests that the timing mechanism in HVC develops before
In this work, they use spike time de-
song acquisition (Jun and D. Z. Jin, 2007).

130

7.4 Perspectives

pendent plasticity (STDP), axon remodeling and synaptic decay to induce a self-
organization process leading to a long synfire chain. A similar approach (I. R. Fiete,
M. S. Fee, et al., 2007) uses STDP and heterosynaptic competition, which guarantees
spatiotemporal distribution of the activity and consequently the unary sequential
code in HVC. Moreover, in this study when giving temporally structured input,
the learning is rapid. We would like to pursue a similar approach and observe
whether with a similar learning rule the model can learn a simplified asymmetric
ring architecture. In line with Jun and D. Z. Jin (2007)’s proposal, it could be that the
recurrent architecture in HVC is learned before tutor exposure, and it is only the
bias (speed) that is learned through supervised learning. It could also be that the
initial structure is binary, as in the rectangle connectivity profile, and the gaussian
and bias are both learned.

7.4.3 Return to Baseline Duration

Experimental evidence (Ali et al., 2013; Pehlevan et al., 2018; Ursu, 2023) have shown
that following the CAF paradigm, the bird’s syllable duration returns to baseline.
This suggests a possible conservation mechanism, or as previously called template
reinforcement mechanism, which rewards duration changes toward the baseline du-
ration. The area responsible for such a return has been identified to be Av and its
lesion prevents the bird to return to baseline. In the model we have presented, we
could say we simulate a case where there is such a lesion and to account for its
presence we would need to add another learning rule (Roberts et al., 2017).

The learning rule would be effective at the level of each syllable and would be
added to the CAF learning rule. It reinforces the synapses based on where in the
baseline normal distribution the current duration is. Hence, the further away from
the mean it goes, the more the reward approaches 0. In the case of the addition of
the reinforcement learning rule (CAF), the latter would overcome the conservation
reward (due to its size) and minimize its effect, thus still allowing duration shift
to occur. Once the reward from CAF is taken out, the conservation learning rule
should be able to take the syllable duration to the baseline duration.

In a previous study, a template reinforcer learning rule was implemented (Pehle-
van et al., 2018) in addition to the learning rule. No effect was observed in terms of
increase in specificity, but an effect was observed in the return. There, the template
reinforcer rule provides reward only after the mean of the duration distribution
exceeds the mean of the baseline by 0.1ms, in the opposite direction of this excess.
For instance, if mean duration distribution is higher than mean baseline distribu-
tion by at least 0.1ms, all duration values less then the mean duration distribution
are awarded. This resembles a bimodal reward, drifting the syllable distribution
to the mean every time it ’escapes’ it. Although such a mechanism works, a sce-
nario when the bird is rewarded every time the duration is within the baseline
distribution, as we propose, can also be applicable.

131

List of Figures

1.1 Taxonomy of Timing. A representation of the taxonomy of timing,
compiled based the evidence provided throughout the years (Breska
and R. B. Ivry, 2016; J. Coull and Nobre, 2008; Grondin, 2010; M. Mauk
and D. Buonomano, 2004): namely sensory/motor, implicit/explicit,
prospective/retrospective and interval/pattern timing. Each of the
limits of these dimensions is shown to engage different mechanisms,
hence bringing the necessity of separating it into subdomains when
studying timing. Whereas the other domains represent separate di-
mensions, prospective/retrospective timing is a subdivision of ex-
plicit timing. On the side, different tasks, where different aspects of
. . . . . . . . . . . . . . . . . .
timing can be studied, are illustrated.

1.2 Temporal processing at different scales. At least 12 orders of mag-
nitude are reported in human temporal processing. Adapted from
M. Mauk and D. Buonomano (2004). . . . . . . . . . . . . . . . . . . . . .

2.1 Comparative evolution of the striatum and pallium in vertebrates.
The colormap on the left reflects the presence of each of the three
domains, pallium, striatum and pallidum. From the figure, it is
clear that the ratio of the brain mass devoted to the pallium increase
in parallel in various vertebrates’ taxa. This figure was taken to
. . . . . . . . . . . .
illustrate subsection 2.1 from Boraud et al. (2018)

2.2 Spectrogram of a birdsong, showing also the motif organization.

.

2.3 Stages of vocal learning in zebra finches and humans, shown in a
. . . . . . . . . . . . . . . . . . . . . . . . . .

logarithmic scale. .

.

.

.

2.4 Anatomy of the Auditory and Song System in Zebra Finches (A)
Simplified schema of the song system.
(Luo and Perkel, 1999) (B)
Summary of (most of) the neural substrates of song perception and
production (Sakata and Yazaki-Sugiyama, 2020). Some parts of the as-
cending auditory pathway and the cerebellum; midbrain and hind-
brain catecholaminergic areas are not included. The abbreviations
used are detailed in Table 2.1. . . . . . . . . . . . . . . . . . . . . . . .

18

21

31

33

36

38

133

List of Figures

2.5 Brain pathways involved in birdsong and speech production In
black arrows the motor pathway, in white arrows, the AFP. In dashed
black, the connections between the AFP and motor pathway, and in
red arrows the direct projection from vocal motor cortex to vocal
motor neurons. a indicates auditory, m motor and m/a both au-
ditory and motor neural activity. Some connections in the human
brain are proposed based on known connectivity of adjacent brain
regions in non-human primates. Taken from Pfenning et al. (2014). 1

2.6 The HVC Microcircuitry: The connections within HVC and their
outside projections. Taken from (Murphy et al., 2020) . . . . . . . . . .

2.7 HVCRA (N = 8) time-locked activity to the song and HVCI (N =
2) neurons. Raster plots of several song renditions in a single bird.
Each row is one rendition and 10 renditions are shown for each
neuron. The activity is aligned to the onset of the nearest syllable.
. . . . . . . . . . . . . . . . . . .
Taken from R. Hahnloser et al. (2002).

5.1 Architecture of the Synfire Chain Network. The Synfire Chain ex-
hibits an all-to-all feed-forward connectivity. For the flexibility pro-
tocol, only the weights between the neurons of layer 4 and 5 are
changed by δw. The flexibility is defined by the range of values δw
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
can take.

.

.

.

.

.

5.2 Synfire Chain and the Flexibility Range in Different Network
Sizes Upper two panels: Spiking dynamics of the Synfire Chain
AdEx model. Third panel: Timing flexibility range refers to the
range of synaptic weight, which allow proper activity propagation
in the chain. It is expressed as the ∆W range, of the synaptic weight
W. The values of ∆W are computed for different number of neurons
. . . . . . . . . . . . . . . . . . . . . . .
per layer in the synfire chain.

5.3 Robustness of the Synfire Chain. (A) Behavior of the synfire chain
facing a decrease in synaptic weights. At 10% weight involvement,
there is a stop in propagation. (B) Behavior of the synfire chain in
face of a decrease in external input. There is a stop in propagation
when 5% of the population is affected. . . . . . . . . . . . . . . . . . .

5.4 Simplified illustration of the ring connectivity and consequences
of local inhibition.
(A) The connectivity represents the physical
location of neurons. (B) The same connectivity is represented using
the preferred timing as a neighbourhood proxy for the placement of
neurons. (C) Injection of a local inhibition in nucleus HVC. (D) The
same local inhibition shown when neurons are ordered according
to their preferred timing.
In this spatial representation, the effect
is not local, but rather distributed, which makes the network more
. . . . . . . . . . . . . . . . . . . . . . . . . . . . .
robust.

.

.

.

.

.

.

.

41

43

45

62

64

65

68

134

List of Figures

5.5 Two numerical phase diagrams for the rate based model with a
Gaussian symmetric connectivity profile.
(A) The four distinct
asymptotic states of the system. Their corresponding regions are
(B) The rate based model’s
color coded in the phase diagrams.
phase diagram based on W0 and W2.
(C) The rate based model’s
phase diagram based on σ and W2. Parameters as in Table 5.2, ex-
cept for Iext = 0.92, β = 0, τn = 0. . . . . . . . . . . . . . . . . . . . . .

5.6 Moving activity profile in response to different external inputs.
(A) The higher the velocity of the stimulus, the higher the speed of
the bump, which follows it. (right) A depiction of two selected input
velocities (color coded with left figure) and the population activity
in time, represented by the center of mass of the bump. In pink the
stimulus feature for the red velocity profile. (B) same as A but for
accelerating velocity profile. (C) same as A and B, for the oscillatory
. . . . . . . . . . . . . . . . . . . . . . . . . .
speed profile.

.

.

.

.

.

.

5.7 Moving activity profile in response to different internal drives (A)
Response of the bump speed to different adaptation strengths is a
quasi linear one. (right) A depiction of two selected input velocities
(color coded with left figure) and the population activity in time,
represented by the center of mass of the bump. (B) An asymmetric
connectivity pattern makes the bump of activity move across the
network. On the right, the population activity when β = 0 (blue)
and when β = 0.05 are shown.
In blue, there is no activity due
to symmetric connections. (C) Connectivity profile for presynaptic
neuron 0 with no bias and bias (color coded with figure B). This
bias is the one we use for the rest of the results presented. Self-
. . . . . .
connections are set to 0 but not represented on the figure.

5.8 Activity propagation in the ring. The first two panels show the po-
sition of the bump of activity in the network at a particular point in
time. The third panel serves to present the possible spiking pattern
this rate network would be compatible with. They were generated
. . . . . . . . . . . . . . . . .
using a homogeneous Poisson process.

5.9 Two numerical phase diagrams for the rate based model with an
asymmetric connectivity profile, β > 0. (A) The rate based model’s
phase diagram based on W0 and W2.
(B) The rate based model’s
phase diagram based on on β and W2. For this phase diagram, W0
was chosen as a value of -3, correspondent to the last row of the the
. . . . . . . . . . . . . . . . . . . . . . . . . .
matrix in (A).

.

.

.

.

.

.

5.10 (A) Rectangular connectivity profile. (B) Gaussian connectivity pro-
. . . . . . . . . . . . . . . . . . . . . . . . . .

file.

.

.

.

.

.

.

.

.

.

.

.

.

70

73

74

75

76

80

135

List of Figures

5.14 Robustness of the Ring Model.

5.11 Activity Propagation in a Symmetric Ring Model with a Rectan-
gular Connectivity Profile and AdEx Neurons (A,C,E) Network of
a size of 100 neurons, across 3 different conditions: with no delays,
with equal delays and with distance based delays. (B,D,F) same as
. . . . . . .
the previous panels for a larger network (1000 neurons).
5.12 Activity Propagation in an Asymmetric Ring Model with a Gaus-
sian Connectivity Profile and AdEx Neurons The first two panels
show the position of the bump of activity (the computation of which
is present in 5.3.1) in the network at a particular point in time. The
third panel is the raster plot, showing the brief bursts of activity and
the propagation in the network. . . . . . . . . . . . . . . . . . . . . . .
5.13 Phase diagram of an Exponential Integrate-and-Fire neuron model
in an asymmetric (with bias) Ring Attractor Architecture. (A) The
phase diagram of the five possible regimes. (B) The raster plots of
each of the observed states and their respective activity profile in the
last timestep of each simulation. The plots in (B) are color coded to
. . . . . . . . . . . . . . . . . . . . . . . . . . . . .
the phase diagram.
(A) Behavior of the synfire chain
in face of a change in synaptic weights, i.e. 30% decrease. There
is no stop in propagation, even when all connections are affected.
(B) Behavior of the synfire chain in face of an external inhibition,
amounting to 10% of Iext. There is no stop in propagation when 50
percent of the population is affected. . . . . . . . . . . . . . . . . . . .
5.15 Effect of Inhibition on the Speed of the Bump. On the right, an il-
lustration of the distribution of the inhibitory input in the 3D space
is shown. In the middle and on the left, respectively, Muscimol’s
and Gabazine’s effect on the bump speed are investigated, for dif-
ferent amplitudes and distributions (width). The amplitude is ex-
pressed in nA and is the coefficient of the gaussian, whereas the SD
is expressed based on the size of the system (π). The colors repre-
sent the change in speed as a percentage of the inital (uninhibited)
. . . . . . . . . . . . . . . . . . . . . . . . . . . .
propagation speed.
5.16 How does inhibition affect bump propagation? Here we present
two example cases of the effect of moderate inhibition in the rate
and SNN model. In (A,B) we illustrate a Muscimol-mimicking sim-
ulation, both in the rate model (A) and in the SNN (B). We observe a
disruption in the beginning, but similar to a noisy perturbation, the
model is able to recover after a while, although the inhibition is con-
stant. (C,D) In these panels, we illustrate optogenetic stimulation-
mimicking simulation, both in the rate model (C) and in the SNN
. .
(D). In both cases we observe only a disruption in the beginning.
5.17 How does inhibition affect bump propagation? Illustration of a
. . . . .

case of Gabazine-mimicking simulation in the SNN model.

.

82

84

85

86

88

89

90

136

List of Figures

5.18 Uva as a possible synchronizing nucleus between the HVCs of the
two hemispheres. In (A) HVCs of the two hemispheres are not con-
nected. When the sequences of each are initiated at different times,
they evolve in parallel, with the same speed and no convergence.
In (B) the two HVCs receive input from Uva, which is able to make
their respective sequences converge, making one’s speed go faster
. . . . . . . . .
and the other’s slower, until they fire synchronously.
5.19 Activity propagation in the EI model. (A) Illustration of the net-
work architecture. (B) Raster plot of the excitatory population. (C)
. . . . . . . . . . . . . . . .
Raster plot of the inhibitory population.

91

93

6.1 Target syllable duration distribution before and after reinforce-
ment learning (for shortening, lengthening) of the targeted syl-
lable. Effects of reinforcement learning in single run simulations
of 1000 trials, aiming to change the duration of the syllable in the
direction of lengthening (blue) or shortening (red). Baseline dura-
tion distribution in gray represent 50 trials prior to RL, and each of
the two other distributions represents post-RL duration distributed
. . . . . . . . . . . . . . . . . . . . . . . . .
(color coded).
6.2 Learning is specific to the targeted syllable. 10 runs (of 1000 trials)
of learning, aiming to achieve syllable duration shortening (red)/
lengthening (blue) are run. For each of the 10 runs in the three
conditions (baseline/increase/decrease duration), a mean duration
is computed from the respective duration distributions (10 mean
values per condition) and these are shown as points in the bar plot.
Baseline mean durations are displayed in gray. \* stands for p < 0.001.100

98

.

.

.

.

.

.

.

6.3 Localized changes in synaptic weights, following learning. A) ∆W
of a single run (target: decrease syllable duration), zoomed in at the
area of pre and post-synaptic neurons (n=200) encoding the target
syllable and 50 neurons after. B) ∆W are rotated by 90 degrees, to
see the synaptic weight change with respect to the diagonal. The
mean of the ∆W across the presynaptic neurons encoding the target
syllable, averaged across 10 runs. The thicker line represents the
mean and the filled in area the standard deviations of each of the 10
runs’ averaged ∆W(across the presynaptic neurons). C, D) Same as
A and B for syllable duration lengthening. Note: The pre-learning
W is scaled for illustration purposes.

. . . . . . . . . . . . . . . . . . 101

6.4 Representation of the effect of learning in a behavioral adapta-
tion paradigm as modeled by an Exponential Integrate and Fire
Neuron Model (a) Target syllable duration distribution before and
after reinforcement learning. Duration distributions are computed
as explained in section 6.1. (b) Adaptation is specific to the target
syllable and no effects are observed in the adjacent and non-adjacent
syllables on the averaged results of 10 runs. \* stands for p < 0.001. . 104

137

List of Figures

6.5 Four simulated birds across learning (Exponential IF): Change in
duration across 200 trials of learning in the Exponential Integrate-
and-Fire neuron model. The results from 4 seeds are shown, where
the first and last bars respectively represent, the 50 baseline (B) trials
and the 50 post RL (P-RL) trials. The 200 trials in the middle show
the progression of learning in time. They are binned in 4, each
containing 50 trials. In the first row the change in duration of the
target syllable is shown, and in the second that of the following
syllable. That is because, whenever we see an effect in the other
syllables it is always in the next syllable.
In black, baseline and
post-RL distributions.

. . . . . . . . . . . . . . . . . . . . . . . . . . . 105

6.6 How do the weights change? Change of ∆W weights in a single
run. Only the neurons affiliated with the target syllable are plot-
ted (n = 450).
(Right) The average mean across the 10 runs. The
target is to decrease the duration of the syllable. In red the aver-
aged change in synaptic weights, based on the distance from the
presynaptic neurons, affiliated with the target syllable. In gray, the
Gaussian connectivity profile of the presynaptic neurons to the post-
synaptics. .

.

.

.

.

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 106

6.7 Representation of the effect of learning in a behavioral adapta-
tion in paradigm as modeled by an Adaptive Exponential Inte-
grate and Fire Neuronal Model (a) Target syllable duration before
and after reinforcement learning. Duration distributions are com-
puted as explained above in subsubsection 6.1.
(b) In the case of
syllable shortening, adaptation is specific to the target syllable and
no effects are observed in the adjacent and non-adjacent syllables
on the averaged results of 10 runs. In the case of lengthening, there
is a significant effect also at the level of the following syllable. In
the individual runs, this effect is observed in 50- 60% of the cases.

. 107

6.8 Four simulated birds across learning (AdEx) to shorten the dura-
tion of a target syllable. Change in duration across 200 trials of
learning. Just like in Fig. 6.5 the results from 4 seeds. In the first
row the change in duration of the target syllable is shown, and in
the second that of the following syllable.

. . . . . . . . . . . . . . . . 108

6.9 How do the weights change in the AdEx neuronal model? Change
of ∆W weights in a single case and the average mean across the 10
runs. In the upper panel, the target is to decrease the duration of
the syllable and in the lower panel, to increase it.

. . . . . . . . . . . 109

138

List of Figures

6.10 Representation of the effect of learning in a behavioral adapta-
tion in paradigm as modeled by an EI network of Exponential
Integrate and Fire Neuronal Model (a) Target syllable duration be-
fore and after reinforcement learning. Duration distributions are
computed as explained above in subsubsection 6.1. (b) Adaptation
is specific to the target syllable and no effects are observed in the
adjacent and non-adjacent syllables on the averaged results of 10 runs.110

6.11 How do the weights change in the EI network model? Change of
∆W weights in a single case and the averaged mean across the 10
runs. In the upper panel, the target is to decrease the duration of
the syllable and in the lower panel, to increase it..

. . . . . . . . . . . 111

6.12 Four simulated birds across learning to decrease syllable dura-
tion in an EI network (Exponential IF): Change in duration across
300 trials of learning in the Exponential Integrate-and-Fire neuron
model. The results from 4 seeds are shown. They are binned in 4,
each containing 50 trials. In the first row the change in duration of
the target syllable is shown, and in the second that of the following
syllable.

.

.

.

.

.

.

.

.

.

.

. . . . . . . . . . . . . . . . . . . . . . . . . 112

6.13 Interval duration change across days of 8 birds undergoing CAF.
Each bin represents a day, each point the change in duration of one
interval from the mean interval duration during baseline. In black,
the baseline and return durations are represented. The durations of
the other days are in colors, and the mean duration is shown by a
black line. The x axes are aligned at the first day when CAF was
started (day 0). .

.

.

.

.

.

.

. . . . . . . . . . . . . . . . . . . . . . . . . 117

139

List of Tables

2.1 Abbreviations used to refer to avian brain structures.

. . . . . . . . .

39

3.1 Computational Models of Timing. The first three classes of timing
are based on the review from (M. S. Matell and Meck, 2004). Further
information included information comes from different reviews on
motor timing in the subsecond scale, the main three being: (Addy-
man et al., 2016; M. S. Matell and Meck, 2004; Medina and M. D. Mauk,
2000; Paton and D. V. Buonomano, 2018). D stands for dedicated sys-
. . . . . . . . . . . . .
tems and I for intrinsic or distributed systems.

50

5.1 Values of the parameters used in Eqs.(5.1) - (5.2) for the Synfire Chain. 62
69
5.2 Values of the parameters used in Eqs. (5.7) – (5.10).
81
5.3 Values of the parameters used in Eqs.(5.18) - (5.22) and (5.24).

. . . . . . . . . .
. . . .

141

Bibliography

1. M. Abeles. “Local Cortical Circuits: An Electrophysiological study.” Springer

Berlin., 1982.

2. C. Addyman, R. M. French, and E. Thomas. “Computational models of in-
terval timing”. Current Opinion in Behavioral Sciences 8, 2016, pp. 140–146.
doi: 10.1016/j.cobeha.2016.01.004. url: https://doi.org/10.1016/j.cobeha.2016.
01.004.

3. E. Aksay, G. Gamkrelidze, H. S. Seung, R. Baker, and D. W. Tank. “In vivo
intracellular recording and perturbation of persistent activity in a neural
integrator”. Nature neuroscience 4:2, 2001, pp. 184–193.

4. E. Akutagawa and M. Konishi. “New brain pathways found in the vocal
control system of a songbird”. The Journal of Comparative Neurology 518:15,
2010, pp. 3086–3100. doi: 10.1002/cne.22383. url: https://doi.org/10.1002/cne.
22383.

5. F. Ali, T. M. Otchy, C. Pehlevan, A. L. Fantana, Y. Burak, and B. P. Ölveczky.
“The Basal Ganglia Is Necessary for Learning Spectral, but Not Temporal,
Features of Birdsong”. Neuron 80:2, 2013, pp. 494–506. doi: 10.1016/j.neuron.
2013.07.049. url: https://doi.org/10.1016/j.neuron.2013.07.049.

6. R. G. Alonso, M. A. Trevisan, A. Amador, F. Goller, and G. B. Mindlin. “A
circular model for song motor control in Serinus canaria”. Frontiers in Com-
putational Neuroscience 9, 2015. doi: 10 . 3389 / fncom . 2015 . 00041. url: https :
//doi.org/10.3389/fncom.2015.00041.

7. S. Amari. “Learning patterns and pattern sequences by self-organizing”,

1972.

8. A. S. Andalman and M. S. Fee. “A basal ganglia-forebrain circuit in the
songbird biases motor output to avoid vocal errors”. Proceedings of the Na-
tional Academy of Sciences 106:30, 2009, pp. 12518–12523. doi: 10 . 1073 / pnas .
0903214106. url: https://doi.org/10.1073/pnas.0903214106.

9. A. S. Andalman, J. N. Foerster, and M. S. Fee. “Control of Vocal and Respi-
ratory Patterns in Birdsong: Dissection of Forebrain and Brainstem Mecha-
nisms Using Temperature”. PLoS ONE 6:9, 2011. Ed. by S. J. Kiebel, e25461.
doi: 10.1371/journal.pone.0025461. url: https://doi.org/10.1371/journal.pone.
0025461.

143

Bibliography

10. D. Appeltants, P. Absil, J. Balthazart, and G. F. Ball. “Identification of the
origin of catecholaminergic inputs to HVc in canaries by retrograde tract
tracing combined with tyrosine hydroxylase immunocytochemistry”. Jour-
nal of chemical neuroanatomy 18:3, 2000, pp. 117–133.

11. M. Araki, M. M. Bandi, and Y. Yazaki-Sugiyama. “Mind the gap: Neural
coding of species identity in birdsong prosody.” Science, 2016. doi: 10.1126/
science.aah6799.

12. M. Araki, M. M. Bandi, and Y. Yazaki-Sugiyama. “Mind the gap: Neural cod-
ing of species identity in birdsong prosody”. Science 354:6317, 2016, pp. 1282–
1287. doi: 10.1126/science.aah6799. url: https://doi.org/10.1126/science.aah6799.

13. D. Arnold and D. Robinson. “The oculomotor integrator: testing of a neural

network model”. Experimental brain research 113, 1997, pp. 57–74.

14. D. Aronov, A. S. Andalman, and M. S. Fee. “A Specialized Forebrain Circuit
for Vocal Babbling in the Juvenile Songbird”. Science 320:5876, 2008, pp. 630–
634. doi: 10.1126/science.1155140. url: https://doi.org/10.1126/science.1155140.

15.

J. Artieda, M. A. Pastor, F. Lacruz, and J. A. Obeso. “Temporal discrimination
is abnormal in Parkinson’s disease”. Brain 115:1, 1992, pp. 199–210.

16. R. C. Ashmore, J. A. Renk, and M. F. Schmidt. “Bottom-Up Activation of the
Vocal Motor Forebrain by the Respiratory Brainstem”. The Journal of Neuro-
science 28:10, 2008, pp. 2613–2623. doi: 10.1523 /jneurosci.4547- 07.2008. url:
https://doi.org/10.1523/jneurosci.4547-07.2008.

17. R. C. Ashmore, J. M. Wild, and M. F. Schmidt. “Brainstem and Forebrain
Contributions to the Generation of Learned Motor Behaviors for Song”. The
Journal of Neuroscience 25:37, 2005, pp. 8543–8554. doi: 10.1523/jneurosci.1668-
05.2005. url: https://doi.org/10.1523/jneurosci.1668-05.2005.

18. A. Aussel, L. Buhry, and R. Ranta. “Stability conditions of Hopfield ring
networks with discontinuous piecewise-affine activation functions”. In: 2017
IEEE 56th Annual Conference on Decision and Control (CDC). IEEE. 2017, pp. 3350–
3355.

19. L. Bai and D. Breen. “Calculating center of mass in an unbounded 2D envi-

ronment”. Journal of Graphics Tools 13:4, 2008, pp. 53–60.

20. K. I. Bakhurin, V. Goudar, J. L. Shobe, L. D. Claar, D. V. Buonomano, and
S. C. Masmanidis. “Differential encoding of time by prefrontal and striatal
network dynamics”. Journal of Neuroscience 37:4, 2017, pp. 854–870.

21. F. Balci and P. Simen. “A Decision Model of Timing.” Current Opinion in

Behavioral Sciences 8, 2016. doi: 10.1016/j.cobeha.2016.02.002.

22. R. P. Balda and A. C. Kamil. “Long-term spatial memory in Clark’s nutcracker,

Nucifraga columbiana”. Animal Behaviour 44:4, 1992, pp. 761–769.

144

Bibliography

23. R. Ben-Yishai, R. L. Bar-Or, and H. Sompolinsky. “Theory of orientation tun-
ing in visual cortex.” Proceedings of the National Academy of Sciences 92:9, 1995,
pp. 3844–3848. doi: 10.1073/pnas.92.9.3844. url: https://doi.org/10.1073/pnas.
92.9.3844.

24. R. Ben-Yishai, R. L. Bar-Or, and H. Sompolinsky. “Theory of orientation tun-
ing in visual cortex.” Proceedings of the National Academy of Sciences 92:9, 1995,
pp. 3844–3848.

25. H. Bergson. Essai sur les données immédiates de la conscience, Paris, PUF, coll.«

1889.

26. R. A. Block and D. Zakay. “Prospective and retrospective duration judg-
ments: A meta-analytic review”. Psychonomic bulletin & review 4:2, 1997,
pp. 184–197.

27. T. Boraud, A. Leblois, and N. P. Rougier. “A natural history of skills”. Progress

in Neurobiology 171, 2018, pp. 114–124.

28. L. Boroditsky. “Language and the construction of time through space”. Trends

in neurosciences 41:10, 2018, pp. 651–653.

29. L. Boroditsky, O. Fuhrman, and K. McCormick. “Do English and Mandarin

speakers think about time differently?” Cognition 118:1, 2011, pp. 123–129.

30. L. Boroditsky and A. Gaby. “Remembrances of times East: absolute spatial
representations of time in an Australian aboriginal community”. Psychologi-
cal science 21:11, 2010, pp. 1635–1639.

31. S. W. Bottjer, E. A. Miesner, and A. P. Arnold. “Forebrain Lesions Disrupt
Development But Not Maintenance of Song in Passerine Birds”. Science
224:4651, 1984, pp. 901–903. doi: 10.1126/science.6719123. url: https://doi.org/
10.1126/science.6719123.

32. M. S. Brainard and A. J. Doupe. “Translating Birdsong: Songbirds as a Model
for Basic and Applied Medical Research”. Annual Review of Neuroscience 36:1,
2013, pp. 489–517. doi: 10.1146/annurev- neuro- 060909- 152826. url: https://doi.
org/10.1146/annurev-neuro-060909-152826.

33. M. S. Brainard and A. J. Doupe. “What songbirds teach us about learning”.
Nature 417:6886, 2002, pp. 351–358. doi: 10.1038/417351a. url: https://doi.org/
10.1038/417351a.

34. A. Breska and R. B. Ivry. “Taxonomies of timing: where does the cerebellum
fit in?” Current Opinion in Behavioral Sciences 8, 2016, pp. 282–288. doi: 10 .
1016/j.cobeha.2016.02.034. url: https://doi.org/10.1016/j.cobeha.2016.02.034.
35. R. Brette and W. Gerstner. “Adaptive Exponential Integrate-and-Fire Model

as an Effective Description of Neuronal Activity.” J. Neurophysiol. 94, 2005.

36. M. Brosch, E. Selezneva, and H. Scheich. “Nonauditory events of a behav-
ioral procedure activate auditory cortex of highly trained monkeys”. Journal
of Neuroscience 25:29, 2005, pp. 6797–6806.

145

Bibliography

37. Z. Brzosko, W. Schultz, and O. Paulsen. “Retroactive modulation of spike
timing-dependent plasticity by dopamine”. eLife 4, 2015. doi: 10.7554/elife.
09685. url: https://doi.org/10.7554/elife.09685.

38. D. Bueti. “The Sensory Representation of Time”. Frontiers in Integrative Neu-
roscience 5, 2011. doi: 10.3389/fnint.2011.00034. url: https://doi.org/10.3389/
fnint.2011.00034.

39. D. Bueti and D. V. Buonomano. “Temporal Perceptual Learning”. Timing and
Time Perception 2:3, 2014, pp. 261–289. doi: 10 . 1163 / 22134468 - 00002023. url:
https://doi.org/10.1163/22134468-00002023.

40. C. V. Buhusi and W. H. Meck. “What makes us tick? Functional and neu-
ral mechanisms of interval timing”. Nature Reviews Neuroscience 6:10, 2005,
pp. 755–765. doi: 10.1038/nrn1764. url: https://doi.org/10.1038/nrn1764.

41. D. Bullock, J. C. Fiala, and S. Grossberg. “A neural model of timed response
learning in the cerebellum”. Neural Networks 7:6-7, 1994, pp. 1101–1114.
doi: 10 . 1016 / s0893 - 6080(05 ) 80161 - 3. url: https : / / doi . org / 10 . 1016 / s0893 -
6080(05)80161-3.

42. D. Buonomano. Your brain is a time machine: The neuroscience and physics of

time. WW Norton & Company, 2017.

43. D. Buonomano and C. Rovelli. “Bridging the neuroscience and physics of

time”. arXiv preprint arXiv:2110.01976, 2021.

44. D. V. Buonomano. “Decoding temporal information: a model based on short-

term synaptic plasticity”. Journal of Neuroscience 20:3, 2000, pp. 1129–1141.

45. D. V. Buonomano and M. M. Merzenich. “Temporal information transformed
into a spatial code by a neural network with realistic properties”. Science
267:5200, 1995, pp. 1028–1030.

46. D. V. Buonomano, J. Bramen, and M. Khodadadifar. “Influence of the in-
terstimulus interval on temporal processing and learning: testing the state-
dependent network model”. Philosophical Transactions of the Royal Society B:
Biological Sciences 364:1525, 2009, pp. 1865–1873. doi: 10.1098/rstb.2009.0019.

47. D. V. Buonomano and R. Laje. “Population clocks: motor timing with neural
dynamics”. Trends in Cognitive Sciences 14:12, 2010, pp. 520–527. doi: 10.1016/
j.tics.2010.09.002.

48. D. V. Buonomano and M. D. Mauk. “Neural Network Model of the Cerebel-
lum: Temporal Discrimination and the Timing of Motor Responses”. Neural
Computation 6:1, 1994, pp. 38–55. doi: 10.1162/neco.1994.6.1.38. url: https:
//doi.org/10.1162/neco.1994.6.1.38.

49. Y. Burak and I. R. Fiete. “Accurate path integration in continuous attractor
network models of grid cells”. PLoS computational biology 5:2, 2009, e1000291.

146

Bibliography

50. D. Burr, A. Tozzi, and M. C. Morrone. “Neural mechanisms for timing visual
events are spatially selective in real-world coordinates”. Nature neuroscience
10:4, 2007, pp. 423–425.

51.

J. A. Cardin, J. N. Raksin, and M. F. Schmidt. “Sensorimotor Nucleus NIf
Is Necessary for Auditory Processing But Not Vocal Motor Output in the
Avian Song System”. Journal of Neurophysiology 93:4, 2005, pp. 2157–2166.
doi: 10.1152/jn.01001.2004. url: https://doi.org/10.1152/jn.01001.2004.

52. B. A. Carlson. “Temporal-Pattern Recognition by Single Neurons in a Sen-
sory Pathway Devoted to Social Communication Behavior”. The Journal of
Neuroscience 29:30, 2009, pp. 9417–9428. doi: 10.1523/jneurosci.1980- 09.2009.
url: https://doi.org/10.1523/jneurosci.1980-09.2009.

53. C. E. Carr. “Processing of Temporal Information in the Brain”. Annual Review
of Neuroscience 16:1, 1993, pp. 223–243. doi: 10 . 1146 / annurev . ne . 16 . 030193 .
001255. url: https://doi.org/10.1146/annurev.ne.16.030193.001255.

54. D. Casasanto and L. Boroditsky. “Time in the mind: Using space to think
about time”. Cognition 106:2, 2008, pp. 579–593. doi: 10.1016/j.cognition.2007.
03.004.

55. W. Chang and D. Z. Jin. “Spike propagation in driven chain networks with
dominant global inhibition”. Physical Review E 79:5, 2009. doi: 10 . 1103 /
physreve.79.051917. url: https://doi.org/10.1103/physreve.79.051917.

56. R. Chaudhuri and I. Fiete. “Bipartite expander Hopfield networks as self-
decoding high-capacity error correcting codes”. Advances in neural informa-
tion processing systems 32, 2019.

57. R. M. Church and H. A. Broadbent. “A connectionist model of timing.” Neu-

ral network models of conditioning and action, 1991, pp. 225–240.

58. A. Clark. “Time and mind”. The Journal of Philosophy 95:7, 1998, pp. 354–376.

59. N. S. Clayton and A. Dickinson. “Episodic-like memory during cache recov-

ery by scrub jays”. Nature 395:6699, 1998, pp. 272–274.

60. M. J. Coleman and E. T. Vu. “Recovery of impaired songs following unilat-
eral but not bilateral lesions of nucleus uvaeformis of adult zebra finches”.
Journal of Neurobiology 63:1, 2005, pp. 70–89. doi: 10 . 1002 / neu . 20122. url:
https://doi.org/10.1002/neu.20122.

61. A. Compte, N. Brunel, P. S. Goldman-Rakic, and X.-J. Wang. “Synaptic mech-
anisms and network dynamics underlying spatial working memory in a cor-
tical network model”. Cerebral cortex 10:9, 2000, pp. 910–923.

62.

63.

J. T. Coull, R.-K. Cheng, and W. H. Meck. “Neuroanatomical and neurochem-
ical substrates of timing”. Neuropsychopharmacology 36:1, 2011, pp. 3–25.

J. Coull and A. Nobre. “Dissociating explicit timing from temporal expec-
tation with fMRI”. Current Opinion in Neurobiology 18:2, 2008, pp. 137–144.
doi: 10.1016/j.conb.2008.07.011. url: https://doi.org/10.1016/j.conb.2008.07.011.

147

Bibliography

64. E. Covey and J. H. Casseday. “TIMING IN THE AUDITORY SYSTEM OF
THE BAT”. Annual Review of Physiology 61:1, 1999, pp. 457–476. doi: 10.1146/
annurev.physiol.61.1.457. url: https://doi.org/10.1146/annurev.physiol.61.1.457.
65. C. Creelman. “Human discrimination of auditory duration.” Journal of the

Acoustical Society of America,34, 582–593, 1962.

66. A. Daou, M. T. Ross, F. Johnson, R. L. Hyson, and R. Bertram. “Electrophysi-
ological characterization and computational models of HVC neurons in the
zebra finch”. Journal of Neurophysiology 110:5, 2013, pp. 1227–1245. doi: 10.
1152/jn.00162.2013. url: https://doi.org/10.1152/jn.00162.2013.

67. M. Diesmann, G. M.-O., and A. A. “Stable propagation of synchronous spik-

ing in cortical neural networks.” Nature, 1999.

68. A. Doupe, D. Perkel, A. Reiner, and E. Stern. “Birdbrains could teach basal
ganglia research a new song”. Trends in Neurosciences 28:7, 2005, pp. 353–363.
doi: 10.1016/j.tins.2005.05.005. url: https://doi.org/10.1016/j.tins.2005.05.005.

69. A. J. Doupe and P. K. Kuhl. “BIRDSONG AND HUMAN SPEECH: Common
Themes and Mechanisms”. Annual Review of Neuroscience 22:1, 1999, pp. 567–
631. doi: 10.1146/annurev.neuro.22.1.567. url: https://doi.org/10.1146/annurev.
neuro.22.1.567.

70. K. Doya and T. J. Sejnowski. “A computational model of birdsong learning

by auditory experience and auditory feedback”, 1998, pp. 77–88.

71. P. J. Drew and L. F. Abbott. “Model of Song Selectivity and Sequence Gen-
eration in Area HVc of the Songbird”. Journal of Neurophysiology 89:5, 2003,
pp. 2697–2706. doi: 10. 1152 /jn. 00801. 2002. url: https : / /doi . org / 10 . 1152 / jn .
00801.2002.

72. R. Dum and P. Strick. “Motor areas in the frontal lobe of the primate”. Physi-
ology and Behavior 77:4-5, 2002, pp. 677–682. doi: 10.1016/s0031-9384(02)00929-0.
url: https://doi.org/10.1016/s0031-9384(02)00929-0.

73. D. Durstewitz. “Self-Organizing Neural Integrator Predicts Interval Times

through Climbing Activity.” Journal of Neuroscience, 2003. doi: 10.1523/JNEUROSCI.
23-12-05342.

74. D. M. Eagleman. “Human time perception and its illusions”. Current opinion

in neurobiology 18:2, 2008, pp. 131–136.

75. L. A. Eales. “Song learning in zebra finches: some effects of song model

availability on what is learnt and when”. Animal Behaviour 33:4, 1985, pp. 1293–
1300. doi: 10.1016/s0003- 3472(85)80189- 5. url: https://doi.org/10.1016/s0003-
3472(85)80189-5.

76. L. Edinger, A. Wallenberg, and G. M. Holmes. “Das Vorderhirn der Vögel.”
Untersuchungen uber die vergleichende Anatomie des Gehirnes. 20, 1903, pp. 343–
426.

148

Bibliography

77. R. Egger, R. Tupikov, and M. E. et al. “Local Axonal Conduction Shapes the

Spatiotemporal Properties of Neural Sequences.” Cell., 2020.

78. A. Einstein. “Die Feldgleichungen der Gravitation”. Sitzungsberichte der Königlich

Preussischen Akademie der Wissenschaften, 1915, pp. 844–847.

79. M. Elmaleh, D. Kranz, A. Asensio, F. Moll, and M. Long. “Sleep replay re-
veals premotor circuit structure for a skilled behavior.” Neuron, 2021. doi: 10.
1016/j.neuron.2021.09.021.

80. N. Emery and N. Clayton. “Effects of experience and social context on
prospective caching strategies by scrub jays”. Nature 416, 2001, pp. 443–446.

81. R. Epstein, R. P. Lanza, and B. F. Skinner. “Symbolic communication between
two pigeons,(Columba livia domestica)”. Science 207:4430, 1980, pp. 543–545.

82. M. Fee and J. Goldberg. “A hypothesis for basal ganglia-dependent rein-
forcement learning in the songbird”. Neuroscience 198, 2011, pp. 152–170.
doi: 10 . 1016 / j . neuroscience . 2011 . 09 . 069. url: https : / / doi . org / 10 . 1016 / j .
neuroscience.2011.09.069.

83. M. S. Fee, A. A. Kozhevnikov, and R. H. Hahnloser. “Neural mechanisms of
vocal sequence generation in the songbird”. Annals of the New York Academy
of Sciences 1016:1, 2004, pp. 153–170.

84. O. Fehér, H. Wang, S. Saar, P. P. Mitra, and O. Tchernichovski. “De novo
establishment of wild-type song culture in the zebra finch.” Nature, 2009.
doi: 10.1038/nature07994.

85. O. Fehér, H. Wang, S. Saar, P. P. Mitra, and O. Tchernichovski. “De novo
establishment of wild-type song culture in the zebra finch”. Nature 459:7246,
2009, pp. 564–568. doi: 10 . 1038 / nature07994. url: https : / / doi . org / 10 . 1038 /
nature07994.

86. L. von Fersen and J. D. Delius. “Long-term retention of many visual patterns

by pigeons”. Ethology 82:2, 1989, pp. 141–155.

87.

88.

89.

J. C. Fiala, S. Grossberg, and D. Bullock. “Metabotropic Glutamate Receptor
Activation in Cerebellar Purkinje Cells as Substrate for Adaptive Timing of
the Classically Conditioned Eye-Blink Response”. The Journal of Neuroscience
16:11, 1996, pp. 3760–3774. doi: 10 . 1523 / jneurosci . 16 - 11 - 03760 . 1996. url:
https://doi.org/10.1523/jneurosci.16-11-03760.1996.

I. R. Fiete, M. S. Fee, and H. S. Seung. “Model of Birdsong Learning Based
on Gradient Estimation by Dynamic Perturbation of Neural Conductances”.
Journal of Neurophysiology 98:4, 2007, pp. 2038–2057. doi: 10 . 1152 / jn . 01311 .
2006. url: https://doi.org/10.1152/jn.01311.2006.

I. R. Fiete and H. S. Seung. “Gradient Learning in Spiking Neural Networks
by Dynamic Perturbation of Conductances”. Physical Review Letters 97:4,
2006. doi: 10 . 1103 / physrevlett . 97 . 048104. url: https : / / doi . org / 10 . 1103 /
physrevlett.97.048104.

149

Bibliography

90. H. Fujimoto, T. Hasegawa, and D. Watanabe. “Neural coding of syntactic
structure in learned vocalizations in the songbird”. Journal of Neuroscience
31:27, 2011, pp. 10023–10033.

91. T. Fujioka, L. J. Trainor, E. W. Large, and B. Ross. “Internalized timing of
isochronous sounds is represented in neuromagnetic beta oscillations”. Jour-
nal of Neuroscience 32:5, 2012, pp. 1791–1802.

92. S. Funahashi, C. J. Bruce, and P. S. Goldman-Rakic. “Mnemonic coding of
visual space in the monkey’s dorsolateral prefrontal cortex”. Journal of neu-
rophysiology 61:2, 1989, pp. 331–349.

93. S. D. Gale and D. J. Perkel. “A Basal Ganglia Pathway Drives Selective Audi-
tory Responses in Songbird Dopaminergic Neurons via Disinhibition”. The
Journal of Neuroscience 30:3, 2010, pp. 1027–1037. doi: 10.1523/jneurosci.3585-
09.2010. url: https://doi.org/10.1523/jneurosci.3585-09.2010.

94. S. D. Gale, A. L. Person, and D. J. Perkel. “A novel basal ganglia pathway
forms a loop linking a vocal learning circuit with its dopaminergic input”.
The Journal of Comparative Neurology 508:5, 2008, pp. 824–839. doi: 10 . 1002 /
cne.21700. url: https://doi.org/10.1002/cne.21700.

95. V. Gallese, L. Fadiga, L. Fogassi, and G. Rizzolatti. “Action recognition in

the premotor cortex”. Brain 119:2, 1996, pp. 593–609.

96.

97.

J. P. Gavornik and M. F. Bear. “Higher brain functions served by the lowly
rodent primary visual cortex”. Learning & Memory 21:10, 2014, pp. 527–533.

J. P. Gavornik, M. G. H. Shuler, Y. Loewenstein, M. F. Bear, and H. Z. Shouval.
“Learning reward timing in cortex through reward dependent expression of
synaptic plasticity”. Proceedings of the National Academy of Sciences 106:16,
2009, pp. 6826–6831. doi: 10 . 1073 / pnas . 0901835106. url: https : / / doi . org / 10 .
1073/pnas.0901835106.

98. T. Q. Gentner and D. Margoliash. “Neuronal populations and single cells
representing learned auditory objects”. Nature 424:6949, 2003, pp. 669–674.
doi: 10.1038/nature01731. url: https://doi.org/10.1038/nature01731.

99. W. Gerstner and R. Brette. “Adaptive exponential integrate-and-fire model”.

Scholarpedia 4:6, 2009, p. 8427.

100. W. Gerstner, M. Lehmann, V. Liakoni, D. Corneil, and J. Brea. “Eligibility
Traces and Plasticity on Behavioral Time Scales: Experimental Support of
NeoHebbian Three-Factor Learning Rules”. Frontiers in Neural Circuits 12,
2018. doi: 10.3389/fncir.2018.00053. url: https://doi.org/10.3389/fncir.2018.
00053.

101. L. Gibb, T. Q. Gentner, and H. D. I. Abarbanel. “Brain Stem Feedback in a
Computational Model of Birdsong Sequencing”. Journal of Neurophysiology
102:3, 2009, pp. 1763–1778. doi: 10.1152/jn.91154.2008. url: https://doi.org/10.
1152/jn.91154.2008.

150

Bibliography

102.

J. Gibbon. “Scalar Expectancy Theory and Weber’s Law in Animal Timing.”
Psychological Review, 84, 279-325., 1977. doi: 10.1037/0033-295X.84.3.279.
103. C. M. Glaze and T. W. Troyer. “Development of temporal structure in zebra

finch song”. Journal of neurophysiology 109:4, 2013, pp. 1025–1035.

104. C. M. Glaze and T. W. Troye. “Temporal Structure in Zebra Finch Song: Im-
plications for Motor Coding.” Journal of Neuroscience, 2006. doi: 10 . 1523 /
JNEUROSCI.3387-05.2006.

105. C. M. Glaze and T. W. Troyer. “A Generative Model for Measuring Latent
Timing Structure in Motor Sequences”. PLoS ONE 7:7, 2012. Ed. by M. J.
Coleman, e37616. doi: 10.1371/journal.pone.0037616. url: https://doi.org/10.
1371/journal.pone.0037616.

106. S. Goldin-Meadow and C. Mylander. “Spontaneous sign systems created by

deaf children in two cultures”. Nature 391:6664, 1998, pp. 279–281.

107. T. S. Gouvêa, T. Monteiro, A. Motiwala, S. Soares, C. Machens, and J. J. Paton.
“Striatal dynamics explain duration judgments”. eLife 4, 2015. doi: 10.7554/
elife.11386. url: https://doi.org/10.7554/elife.11386.

108. A. M. Graybiel. “The basal ganglia and chunking of action repertoires”. Neu-

robiology of learning and memory 70:1-2, 1998, pp. 119–136.

109.

J. Griffith. “On the stability of brain-like structures.” Biophys. J. 3:299-308.,
1963.

110. S. Grondin. “Timing and time perception: A review of recent behavioral
and neuroscience findings and theoretical directions”. Attention, Perception,
and Psychophysics 72:3, 2010, pp. 561–582. doi: 10 . 3758 / app . 72 . 3 . 561. url:
https://doi.org/10.3758/app.72.3.561.

111. S. Grondin and R. Rousseau. “Judging the relative duration of multimodal
short empty time intervals”. Perception & psychophysics 49:3, 1991, pp. 245–
256.

112. S. Grossberg. “Some networks that can learn, remember, and reproduce any
number of complicated space-time patterns.” I. J. Math. Mech., 19:53-91, 1969.

113. S. Grossberg and N. A. Schmajuk. “Neural dynamics of adaptive timing and
temporal discrimination during associative learning”. Neural Networks 2:2,
1989, pp. 79–102. doi: 10.1016/0893- 6080(89)90026- 9. url: https://doi.org/10.
1016/0893-6080(89)90026-9.

114. M. Grube, F. E. Cooper, P. F. Chinnery, and T. D. Griffiths. “Dissociation of
duration-based and beat-based auditory timing in cerebellar degeneration”.
Proceedings of the National Academy of Sciences 107:25, 2010, pp. 11597–11601.
doi: 10.1073/pnas.0910473107. url: https://doi.org/10.1073/pnas.0910473107.
115. O. Güntürkün. “The convergent evolution of neural substrates for cogni-
tion”. Psychological Research 76:2, 2011, pp. 212–219. doi: 10.1007/s00426- 011-
0377-9.

151

Bibliography

116. S. Haesler, K. Wada, A. Nshdejan, E. E. Morrisey, T. Lints, E. D. Jarvis, and C.
Scharff. “FoxP2 expression in avian vocal learners and non-learners”. Journal
of Neuroscience 24:13, 2004, pp. 3164–3175.

117. R. Hahnloser, A. Kozhevnikov, and M. Fee. “An ultra-sparse code underlies
the generation of neural sequences in a songbird.” Nature, 2002. doi: 10.1038/
nature00974.

118. R. H. Hahnloser and M. S. Fee. “Sleep-related spike bursts in HVC are driven
by the nucleus interface of the nidopallium”. Journal of neurophysiology 97:1,
2007, pp. 423–435.

119. K. Hamaguchi and R. Mooney. “Recurrent Interactions between the In-
put and Output of a Songbird Cortico-Basal Ganglia Pathway Are Impli-
cated in Vocal Sequence Variability”. The Journal of Neuroscience 32:34, 2012,
pp. 11671–11687. doi: 10.1523/jneurosci.1666-12.2012. url: https://doi.org/10.
1523/jneurosci.1666-12.2012.

120. K. Hamaguchi, M. Tanaka, and R. Mooney. “A Distributed Recurrent Net-
work Contributes to Temporally Precise Vocalizations”. Neuron 91:3, 2016,
pp. 680–693. doi: 10.1016/j.neuron.2016.06.019. url: https://doi.org/10.1016/j.
neuron.2016.06.019.

121. D. Hansel and H. Sompolinsky. “Modeling feature selectivity in local corti-

cal circuits.” Book Chapter, 1998.

122. A. Hanuschkin, S. Ganguli, and R. H. R. Hahnloser. “A Hebbian learning
rule gives rise to mirror neurons and links them to control theoretic inverse
models”. Frontiers in Neural Circuits 7, 2013. doi: 10 . 3389 / fncir . 2013 . 00106.
url: https://doi.org/10.3389/fncir.2013.00106.

123. E. Hara, M. V. Rivas, J. M. Ward, K. Okanoya, and E. D. Jarvis. “Convergent
differential regulation of parvalbumin in the brains of vocal learners”. PloS
one 7:1, 2012, e29457.

124. N. F. Hardy and D. V. Buonomano. “Neurocomputational models of interval
and pattern timing”. Current Opinion in Behavioral Sciences 8, 2016, pp. 250–
257.

125. K. He, M. Huertas, S. Z. Hong, X. Tie, J. W. Hell, H. Shouval, and A. Kirk-
wood. “Distinct Eligibility Traces for LTP and LTD in Cortical Synapses”.
Neuron 88:3, 2015, pp. 528–538. doi: 10.1016/j.neuron.2015.09.037. url: https:
//doi.org/10.1016/j.neuron.2015.09.037.

126.

J. J. Hopfield. “Neural networks and physical systems with emergent col-
lective computational abilities.” Proceedings of the National Academy of Sci-
ences 79:8, 1982, pp. 2554–2558. doi: 10 . 1073 / pnas . 79 . 8 . 2554. url: https :
//doi.org/10.1073/pnas.79.8.2554.

127. F. Hyseni, N. Rougier, and A. Leblois. “A model of Sequence Timing in
Songbird’s Premotor Nucleus.” In: Student Conference on Biological Sciences
(SCBS). Tirana, Albania, 2021. url: 10.5281/zenodo.5877414.

152

Bibliography

128. F. Hyseni, N. Rougier, and A. Leblois. “An Attractor Model of the Temporal
Dynamics of the Songbird’s Premotor Nucleus.” In: 32nd Annual Computa-
tional Neuroscience Meeting (CNS). Leipzig, Germany, 2023.

129. F. Hyseni, N. Rougier, and A. Leblois. “Comparative study of the synfire
chain and ring attractor model for timing in the premotor nucleus in male
Zebra Finches.” In: ESANN 2023-European Symposium on Artificial Neural
Networks, Computational Intelligence and Machine Learning. 2023, pp. 647–652.
doi: 10.14428/esann/2023.ES2023-120.

130. F. Hyseni, N. Rougier, and A. Leblois. “Temporal Dynamics in an Attractor
Model of the Songbird’s Premotor Nucleus.” In: Computational and Systems
Neuroscience (COSYNE). Lisbon, Portugal, 2022. url: https://www.world- wide.
org/cosyne-22/temporal-dynamics-attractor-model-songbirds-b261b11a/.

131. F. Hyseni, N. P. Rougier, and A. Leblois. “Attractor dynamics drive flexible
timing in birdsong.” In: International Conference on Artificial Neural Networks.
Springer. 2023, pp. 112–123. doi: 10.1007/978-3-031-44198-1\_10.

132. Y. Ikegaya, G. Aaron, R. Cossart, D. Aronov, I. Lampl, D. Ferster, and R.
Yuste. “Synfire Chains and Cortical Songs: Temporal Modules of Cortical
Activity”. Science 304:5670, 2004, pp. 559–564. doi: 10 . 1126 / science . 1093173.
url: https://doi.org/10.1126/science.1093173.

133. K. Immelmann. “Song development in the zebra finch and other estrildid

finches.” (No Title), 1969, p. 61.

134. H. K. Inagaki, L. Fontolan, S. Romani, and K. Svoboda. “Discrete attractor
dynamics underlies persistent activity in the frontal cortex”. Nature 566:7743,
2019, pp. 212–217.

135. G. R. Isola, A. Vochin, and J. T. Sakata. “Manipulations of inhibition in corti-
cal circuitry differentially affect spectral and temporal features of Bengalese
finch song”. Journal of Neurophysiology 123:2, 2020, pp. 815–830. doi: 10.1152/
jn.00142.2019. url: https://doi.org/10.1152/jn.00142.2019.

136. R. Ivry and J. Schlerf. “Dedicated and intrinsic models of time perception.”
Trends Cogn Sci. 12(7), 2008, pp. 273–80. doi: 10.1016/j.tics.2008.04.002.

137. R. B. Ivry and R. E. Hazeltine. “Perception and production of temporal in-
tervals across a range of durations: evidence for a common timing mecha-
nism.” Journal of Experimental Psychology: Human Perception and Performance
21:1, 1995, p. 3.

138. E. D. Jarvis et al. “Avian brains and a new understanding of vertebrate brain
evolution”. Nature Reviews Neuroscience 6:2, 2005, pp. 151–159. doi: 10.1038/
nrn1606.

139. M. Jazayeri and M. N. Shadlen. “A neural mechanism for sensing and re-
producing a time interval”. Current Biology 25:20, 2015, pp. 2599–2609.

153

Bibliography

140. D. Jin, F. Ramazano ˘glu, and H. Seung. “Intrinsic bursting enhances the ro-
bustness of a neural network model of sequence generation by avian brain
area HVC.” J Comput Neurosci, 2007.

141. D. Z. Jin. “Generating variable birdsong syllable sequences with branching
chain networks in avian premotor nucleus HVC”. Physical Review E 80:5,
2009. doi: 10.1103/physreve.80.051902. url: https://doi.org/10.1103/physreve.80.
051902.

142. D. Z. Jin, F. M. Ramazano ˘glu, and H. S. Seung. “Intrinsic bursting enhances
the robustness of a neural network model of sequence generation by avian
brain area HVC”. Journal of Computational Neuroscience 23:3, 2007, pp. 283–
299. doi: 10.1007/s10827- 007- 0032- z. url: https://doi.org/10.1007/s10827- 007-
0032-z.

143.

J. K. Jun and D. Z. Jin. “Development of Neural Circuitry for Precise Tempo-
ral Sequences through Spontaneous Activity, Axon Remodeling, and Synap-
tic Plasticity”. PLoS ONE 2:8, 2007. Ed. by S. Akbarian, e723. doi: 10.1371/
journal.pone.0000723. url: https://doi.org/10.1371/journal.pone.0000723.

144. T. Kaneko. “Local connections of excitatory neurons in motor-associated cor-

tical areas of the rat”. Frontiers in neural circuits 7, 2013, p. 75.

145. U. R. Karmarkar and D. V. Buonomano. “Timing in the absence of clocks:

encoding time in neural network states”. Neuron 53:3, 2007, pp. 427–438.

146. U. R. Karmarkar and D. V. Buonomano. “Temporal Specificity of Perceptual
Learning in an Auditory Discrimination Task”. Learning and Memory 10:2,
2003, pp. 141–147. doi: 10.1101/lm.55503.

147. R. Kawai, T. Markman, R. Poddar, R. Ko, A. L. Fantana, A. K. Dhawale, A. R.
Kampff, and B. P. Ölveczky. “Motor Cortex Is Required for Learning but Not
for Executing a Motor Skill”. Neuron 86:3, 2015, pp. 800–812. doi: 10.1016/j.
neuron.2015.03.024. url: https://doi.org/10.1016/j.neuron.2015.03.024.

148. M. Khona and I. Fiete. “Attractor and integrator networks in the brain.” Nat

Rev Neurosci 23, 2022, pp. 744–766. doi: 10.1038/s41583-022-00642-0.

149. S. S. Kim, H. Rouault, S. Druckmann, and V. Jayaraman. “Ring attractor dy-
namics in the Drosophila central brain”. Science 356:6340, 2017, pp. 849–853.
doi: 10.1126/science.aal4835. url: https://doi.org/10.1126/science.aal4835.

150. D. P. King and J. S. Takahashi. “Molecular Genetics of Circadian Rhythms in
Mammals”. Annual Review of Neuroscience 23:1, 2000, pp. 713–742. doi: 10 .
1146/annurev.neuro.23.1.713. url: https://doi.org/10.1146/annurev.neuro.23.1.713.

151. E. I. Knudsen. “Instructed learning in the auditory localization pathway of

the barn owl”. Nature 417:6886, 2002, pp. 322–328.

152. T. Komiyama, T. R. Sato, and . K. Svoboda. “Learning-related fine-scale speci-
ficity imaged in motor cortex circuits of behaving mice”. Nature 464:7292,
2010, pp. 1182–1186. doi: 10.1038/nature08897.

154

Bibliography

153. M. Konishi. “Birdsong: From Behavior to Neuron”. Annual Review of Neuro-
science 8:1, 1985, pp. 125–170. doi: 10.1146/annurev.ne.08.030185.001013. url:
https://doi.org/10.1146/annurev.ne.08.030185.001013.

154. G. Kosche, D. Vallentin, and M. A. Long. “Interplay of Inhibition and Ex-
citation Shapes a Premotor Neural Sequence”. The Journal of Neuroscience
35:3, 2015, pp. 1217–1227. doi: 10 . 1523 / jneurosci . 4346 - 14 . 2015. url: https :
//doi.org/10.1523/jneurosci.4346-14.2015.

155. A. A. Kozhevnikov and M. S. Fee. “Singing-related activity of identified HVC
neurons in the zebra finch”. Journal of neurophysiology 97:6, 2007, pp. 4271–
4283.

156. Y. Kubo, E. Chalmers, and A. Luczak. “Biologically-inspired neuronal adap-
tation improves learning in neural networks”. Communicative and Integrative
Biology 16:1, 2023. doi: 10.1080/19420889.2022.2163131. url: https://doi.org/10.
1080/19420889.2022.2163131.

157. P. K. Kuhl. “Early language acquisition: cracking the speech code”. Nature

reviews neuroscience 5:11, 2004, pp. 831–843.

158. P. K. Kuhl. “Is speech learning ‘gated’by the social brain?” Developmental

science 10:1, 2007, pp. 110–120.

159.

J. Kunimatsu, T. W. Suzuki, S. Ohmae, and M. Tanaka. “Different contribu-
tions of preparatory activity in the basal ganglia and cerebellum for self-
timing”. Elife 7, 2018, e35676.

160. C. S. Lai, S. E. Fisher, J. A. Hurst, F. Vargha-Khadem, and A. P. Monaco. “A
forkhead-domain gene is mutated in a severe speech and language disor-
der”. Nature 413:6855, 2001, pp. 519–523.

161. R. Laje and D. V. Buonomano. “Robust timing and motor patterns by taming
chaos in recurrent neural networks”. Nature Neuroscience 16:7, 2013, pp. 925–
933. doi: 10.1038/nn.3405. url: https://doi.org/10.1038/nn.3405.

162. R. P. Lanza, J. Starr, and B. Skinner. ““Lying” in the pigeon”. Journal of the

Experimental Analysis of Behavior 38:2, 1982, pp. 201–203.

163. L. Lapique. “Researches quantatives sur l’excitation electrique des nerfs
traitee comme une polarization”. Journal of Physiology, Pathology and Genetics
9, 1907, pp. 620–635.

164. A. Leblois and R. Darshan. “Basal Ganglia: Songbird Models”. In: Ency-
clopedia of Computational Neuroscience. Springer New York, 2014, pp. 1–6.
doi: 10 . 1007 / 978 - 1 - 4614 - 7320 - 6 \_ 84 - 1. url: https : / / doi . org / 10 . 1007 / 978 - 1 -
4614-7320-6\_84-1.

165. H. Lejeune. “Switching or gating? The attentional challenge in cognitive
models of psychological time”. Behavioural Processes 44:2, 1998, pp. 127–145.
doi: 10 . 1016 / s0376 - 6357(98 ) 00045 - x. url: https : / / doi . org / 10 . 1016 / s0376 -
6357(98)00045-x.

155

Bibliography

166. A. Leonardo. “Experimental test of the birdsong error-correction model”.
Proceedings of the National Academy of Sciences 101:48, 2004, pp. 16935–16940.

167. A. Leonardo and M. S. Fee. “Ensemble coding of vocal control in birdsong”.

Journal of Neuroscience 25:3, 2005, pp. 652–661.

168. M. S. Lewicki and M. Konishi. “Mechanisms underlying the sensitivity of
songbird forebrain neurons to temporal order.” Proceedings of the National
Academy of Sciences 92:12, 1995, pp. 5582–5586. doi: 10.1073/pnas.92.12.5582.
url: https://doi.org/10.1073/pnas.92.12.5582.

169. P. A. Lewis, R. Miall, S. Daan, and A. Kacelnik. “Interval timing in mice
does not rely upon the circadian pacemaker”. Neuroscience letters 348:3, 2003,
pp. 131–134.

170. A. C. Lin, A. M. Bygrave, A. De Calignon, T. Lee, and G. Miesenböck. “Sparse,
decorrelated odor coding in the mushroom body enhances learned odor dis-
crimination”. Nature neuroscience 17:4, 2014, pp. 559–568.

171.

J. K. Liu and D. V. Buonomano. “Embedding Multiple Trajectories in Simu-
lated Recurrent Neural Networks in a Self-Organizing Manner”. The Journal
of Neuroscience 29:42, 2009, pp. 13172–13181. doi: 10 . 1523 / jneurosci . 2358 -
09.2009. url: https://doi.org/10.1523/jneurosci.2358-09.2009.

172. C. J. Logan, S. A. Jelbert, A. J. Breen, R. D. Gray, and A. H. Taylor. “Modifica-
tions to the Aesop’s Fable paradigm change New Caledonian crow perfor-
mances”. PLoS One 9:7, 2014, e103049.

173. M. A. Long and M. S. Fee. “Using temperature to analyse temporal dynamics
in the songbird motor pathway”. Nature 456:7219, 2008, pp. 189–194. doi: 10.
1038/nature07448. url: https://doi.org/10.1038/nature07448.

174. M. A. Long, D. Z. Jin, and M. S. Fee. “Support for a synaptic chain model of
neuronal sequence generation”. Nature 468:7322, 2010, pp. 394–399. doi: 10.
1038/nature09514. url: https://doi.org/10.1038/nature09514.

175. R. E. Lubow. “HIGH-ORDER CONCEPT FORMATION IN THE PIGEON

1”. Journal of the Experimental Analysis of Behavior 21:3, 1974, pp. 475–483.

176. M. Luo and D. J. Perkel. “A GABAergic, strongly inhibitory projection to
a thalamic nucleus in the zebra finch song system”. Journal of Neuroscience
19:15, 1999, pp. 6700–6711.

177. G. Lynch, T. Okubo, A. Hanuschkin, R. Hahnloser, and M. Fee. “Rhythmic
Continuous-Time Coding in the Songbird Analog of Vocal Motor Cortex.”
Neuron, 2016. doi: 10.1016/j.neuron.2016.04.021.

178. C. Malapani, B. Rakitin, R. Levy, W. H. Meck, B. Deweer, B. Dubois, and J.
Gibbon. “Coupled Temporal Memories in Parkinson’s Disease: A Dopamine-
Related Dysfunction”. Journal of Cognitive Neuroscience 10:3, 1998, pp. 316–
331. doi: 10.1162/089892998562762. url: https://doi.org/10.1162/089892998562762.

156

Bibliography

179. D. Margoliash. “Acoustic parameters underlying the responses of song-
specific neurons in the white-crowned sparrow”. The Journal of Neuroscience
3:5, 1983, pp. 1039–1057. doi: 10.1523/jneurosci.03- 05- 01039.1983. url: https:
//doi.org/10.1523/jneurosci.03-05-01039.1983.

180. D. Margoliash and E. Fortune. “Temporal and harmonic combination-sensitive

neurons in the zebra finch’s HVc”. The Journal of Neuroscience 12:11, 1992,
pp. 4309–4326. doi: 10.1523/jneurosci.12- 11- 04309.1992. url: https://doi.org/
10.1523/jneurosci.12-11-04309.1992.

181. D. Margoliash. “Functional organization of forebrain pathways for song pro-
duction and perception”. Journal of neurobiology 33:5, 1997, pp. 671–693.

182.

J. E. Markowitz, W. A. Liberti, G. Guitchounts, T. Velho, C. Lois, and T. J.
Gardner. “Mesoscopic Patterns of Neural Activity Support Songbird Corti-
cal Sequences”. PLOS Biology 13:6, 2015. Ed. by J. Ashe, e1002158. doi: 10.
1371/journal.pbio.1002158. url: https://doi.org/10.1371/journal.pbio.1002158.

183. P. Marler. “A comparative approach to vocal learning: Song development in
white-crowned sparrows.” Journal of Comparative and Physiological Psychology
71:2, Pt.2, 1970, pp. 1–25. doi: 10.1037/h0029144. url: https://doi.org/10.1037/
h0029144.

184. P. Marler. “Bird Calls: Their Potential for Behavioral Neurobiology”. Annals
of the New York Academy of Sciences 1016:1, 2004, pp. 31–44. doi: 10 . 1196 /
annals.1298.034. url: https://doi.org/10.1196/annals.1298.034.

185. P. Marler. “Characteristics of some animal calls”. Nature 176:4470, 1955, pp. 6–

8.

186. P. Marler. “Three models of song learning: evidence from behavior”. Journal

of neurobiology 33:5, 1997, pp. 501–516.

187. P. Marler and S. Peters. “Selective vocal learning in a sparrow”. Science

198:4316, 1977, pp. 519–521.

188. Y. Masamizu, Y. R. Tanaka, Y. H. Tanaka, R. Hira, F. Ohkubo, K. Kitamura, Y.
Isomura, T. Okada, and M. Matsuzaki. “Two distinct layer-specific dynamics
of cortical ensembles during learning of a motor task”. Nature Neuroscience
17:7, 2014, pp. 987–994. doi: 10.1038/nn.3739. url: https://doi.org/10.1038/nn.
3739.

189. M. Matell, W. Meck, and M. Nicolelis. “Integration of Behavior and Tim-
ing”. In: Functional and Neural Mechanisms of Interval Timing. CRC Press, 2003.
doi: 10.1201/9780203009574.ch15. url: https://doi.org/10.1201/9780203009574.ch15.

190. M. S. Matell and W. H. Meck. “Cortico-striatal circuits and interval timing:
coincidence detection of oscillatory processes”. Cognitive Brain Research 21:2,
2004, pp. 139–170. doi: 10.1016/j.cogbrainres.2004.06.012. url: https://doi.org/
10.1016/j.cogbrainres.2004.06.012.

157

Bibliography

191. M. S. Matell and W. H. Meck. “Neuropsychological mechanisms of interval
timing behavior”. BioEssays 22:1, 2000, pp. 94–103. doi: 10.1002/(sici)1521-
1878(200001)22:1<94::aid-bies14>3.0.co;2-e. url: https://doi.org/10.1002/(sici)
1521-1878(200001)22:1%3C94::aid-bies14%3E3.0.co;2-e.

192. T. Matzinger, N. Ritt, and W. T. Fitch. “Non-native speaker pause patterns
closely correspond to those of native speakers at different speech rates”.
PLOS ONE 15:4, 2020. Ed. by K. Miwa, e0230710. doi: 10.1371/journal.pone.
0230710. url: https://doi.org/10.1371/journal.pone.0230710.

193. M. Mauk and D. Buonomano. “The Neural Basis of Temporal Processing.”
Annual review of neuroscience 27, 2004, pp. 307–40. doi: 10.1146/annurev.neuro.
27.070203.144247.

194.

J. McCasland. “Neuronal control of bird song production”. The Journal of
Neuroscience 7:1, 1987, pp. 23–39. doi: 10.1523/jneurosci.07-01-00023.1987. url:
https://doi.org/10.1523/jneurosci.07-01-00023.1987.

195. N. R. McFarland and S. N. Haber. “Organization of thalamostriatal termi-
nals from the ventral motor nuclei in the macaque”. Journal of Comparative
Neurology 429:2, 2001, pp. 321–336.

196. R. McWalter and J. H. McDermott. “Illusory sound texture reveals multi-
second statistical completion in auditory scene analysis”. Nature communica-
tions 10:1, 2019, p. 5096.

197. W. H. Meck, T. B. Penney, and V. Pouthas. “Cortico-striatal representation
of time in animals and humans”. Current opinion in neurobiology 18:2, 2008,
pp. 145–152.

198. W. H. Meck. “Selective adjustment of the speed of internal clock and mem-
ory processes.” Journal of Experimental Psychology: Animal Behavior Processes
9:2, 1983, pp. 171–201. doi: 10.1037/0097-7403.9.2.171. url: https://doi.org/10.
1037/0097-7403.9.2.171.

199.

J. F. Medina and M. D. Mauk. “Computer simulation of cerebellar informa-
tion processing”. Nature Neuroscience 3:S11, 2000, pp. 1205–1211. doi: 10 .
1038/81486. url: https://doi.org/10.1038/81486.

200. H. Merchant, D. L. Harrington, and W. H. Meck. “Neural basis of the percep-
tion and estimation of time”. Annual review of neuroscience 36, 2013, pp. 313–
336.

201. D. S. Miall. “Beyond the schema given: Affective comprehension of liter-
ary narratives”. Cognition and Emotion 3:1, 1989, pp. 55–78. doi: 10 . 1080 /
02699938908415236. url: https://doi.org/10.1080/02699938908415236.
J. W. Milnor. “Attractor”. Scholarpedia 1:11, 2006, p. 1815.

202.

203. A. Mita, H. Mushiake, K. Shima, Y. Matsuzaka, and J. Tanji. “Interval time
coding by neurons in the presupplementary and supplementary motor ar-
eas”. Nature neuroscience 12:4, 2009, pp. 502–507.

158

Bibliography

204. F. W. Moll, D. Kranz, A. C. Asensio, M. Elmaleh, L. A. Ackert-Smith, and
M. A. Long. “Thalamus drives vocal onsets in the zebra finch courtship
song”. Nature 616:7955, 2023, pp. 132–136. doi: 10 . 1038 / s41586 - 023 - 05818 - x.
url: https://doi.org/10.1038/s41586-023-05818-x.

205. T. Monteiro, F. S. Rodrigues, M. Pexirra, B. F. Cruz, A. I. Gonçalves, P. E.
Rueda-Orozco, and J. J. Paton. “Using temperature to analyze the neural ba-
sis of a time-based decision”. Nature Neuroscience 26:8, 2023, pp. 1407–1416.
doi: 10.1038/s41593-023-01378-5. url: https://doi.org/10.1038/s41593-023-01378-
5.

206. R. Mooney. “Different Subthreshold Mechanisms Underlie Song Selectivity
in Identified HVc Neurons of the Zebra Finch”. The Journal of Neuroscience
20:14, 2000, pp. 5420–5436. doi: 10 . 1523 / jneurosci . 20 - 14 - 05420 . 2000. url:
https://doi.org/10.1523/jneurosci.20-14-05420.2000.

207. R. Mooney. “Neural mechanisms for learned birdsong”. Learning and Mem-
ory 16:11, 2009, pp. 655–669. doi: 10.1101/lm.1065209. url: https://doi.org/10.
1101/lm.1065209.

208. R. Mooney. “Neurobiology of song learning”. Current opinion in neurobiology

19:6, 2009, pp. 654–660.

209. R. Mooney. “Synaptic Mechanisms for Auditory-Vocal Integration and the
Correction of Vocal Errors”. Annals of the New York Academy of Sciences 1016:1,
2004, pp. 476–494.

210. R. Mooney and J. F. Prather. “The HVC Microcircuit: The Synaptic Basis for
Interactions between Song Motor and Vocal Plasticity Pathways”. The Journal
of Neuroscience 25:8, 2005, pp. 1952–1964. doi: 10.1523/jneurosci.3726-04.2005.
url: https://doi.org/10.1523/jneurosci.3726-04.2005.

211.

J. W. Moore, J. E. Desmond, and N. E. Berthier. “Adaptively timed condi-
tioned responses and the cerebellum: A neural network approach”. Biolog-
ical Cybernetics 62:1, 1989, pp. 17–28. doi: 10 . 1007 / bf00217657. url: https :
//doi.org/10.1007/bf00217657.

212. C. A. Munn. “Birds that ‘cry wolf’”. Nature 319:6049, 1986, pp. 143–145.

213. M. Murakami, M. I. Vicente, G. M. Costa, and Z. F. Mainen. “Neural an-
tecedents of self-initiated actions in secondary motor cortex”. Nature neu-
roscience 17:11, 2014, pp. 1574–1582.

214. K. Murphy, K. S. Lawley, P. Smith, and J. F. Prather. “New insights into the
avian song system and neuronal control of learned vocalizations”. The neu-
roethology of birdsong, 2020, pp. 65–92.

215. H. Mushiake, M. Inase, and J. Tanji. “Neuronal activity in the primate pre-
motor, supplementary, and precentral motor cortex during visually guided
and internally determined sequential movements”. Journal of neurophysiology
66:3, 1991, pp. 705–718.

159

Bibliography

216. S. S. Nagarajan, D. T. Blake, B. A. Wright, N. Byl, and M. M. Merzenich.
“Practice-Related Improvements in Somatosensory Interval Discrimination
Are Temporally Specific But Generalize across Skin Location, Hemisphere,
and Modality”. The Journal of Neuroscience 18:4, 1998, pp. 1559–1570. doi: 10.
1523/jneurosci.18-04-01559.1998.

217. K. Naie and R. Hahnloser. “Regulation of learned vocal behavior by an audi-
tory motor cortical nucleus in juvenile zebra finches.” J. Neurophysiol., 2011.
doi: 10.1152/jn.01035.2010.

218. D. Nicholson. NickleDave/hybrid-vocal-classifier: annotated-high-level-finch. 2018.

doi: 10.5281/ZENODO.1475481. url: https://zenodo.org/record/1475481.

219. H. Niki and M. Watanabe. “Prefrontal and cingulate unit activity during
timing behavior in the monkey”. Brain research 171:2, 1979, pp. 213–224.

220. K. W. Nordeen and E. J. Nordeen. “Auditory feedback is necessary for the
maintenance of stereotyped song in adult zebra finches”. Behavioral and Neu-
ral Biology 57:1, 1992, pp. 58–66. doi: 10.1016/0163-1047(92)90757-u. url: https:
//doi.org/10.1016/0163-1047(92)90757-u.

221. F. Nottebohm. “The Origins of Vocal Learning”. The American Naturalist
106:947, 1972, pp. 116–140. doi: 10 . 1086 / 282756. url: https : / / doi . org / 10 .
1086/282756.

222. F. Nottebohm, T. M. Stokes, and C. M. Leonard. “Central control of song
in the canary, Serinus canarius”. The Journal of Comparative Neurology 165:4,
1976, pp. 457–486. doi: 10.1002/cne.901650405. url: https://doi.org/10.1002/cne.
901650405.

223. T. Nowotny, M. I. Rabinovich, and H. D. Abarbanel. “Spatial representation
of temporal information through spike-timing-dependent plasticity”. Physi-
cal Review E 68:1, 2003, p. 011908.

224. R. E. Núñez and E. Sweetser. “With the future behind them: Convergent evi-
dence from Aymara language and gesture in the crosslinguistic comparison
of spatial construals of time”. Cognitive science 30:3, 2006, pp. 401–450.

225. T. S. Okubo, E. L. Mackevicius, H. L. Payne, G. F. Lynch, and M. S. Fee. “Growth

and splitting of neural sequences in songbird vocal development”. Nature
528:7582, 2015, pp. 352–357. doi: 10.1038/nature15741. url: https://doi.org/10.
1038/nature15741.

226. B. P. Ölveczky, A. S. Andalman, and M. S. Fee. “Vocal Experimentation in
the Juvenile Songbird Requires a Basal Ganglia Circuit”. PLoS Biology 3:5,
2005. Ed. by W. Schultz, e153. doi: 10.1371/journal.pbio.0030153. url: https:
//doi.org/10.1371/journal.pbio.0030153.

227. G. Palkar, J.-y. Wu, and B. Ermentrout. “The inhibitory control of trav-
eling waves in cortical networks”. PLOS Computational Biology 19:9, 2023,
e1010697.

160

Bibliography

228. R. Pang, A. Duffy, D. Bell, Z. Torok, and A. Fairhall. “Precision motor timing
via scalar input fluctuations”, 2022. doi: 10.1101/2022.05.18.492498. url: https:
//doi.org/10.1101/2022.05.18.492498.

229. V. Pariyadath and D. Eagleman. “The effect of predictability on subjective

duration”. PloS one 2:11, 2007, e1264.

230.

J. Park, L. T. Coddington, and J. T. Dudman. “Basal ganglia circuits for action
specification”. Annual review of neuroscience 43, 2020, pp. 485–507.

231. M. Pastor, J. Artieda, M. Jahanshahi, and J. Obeso. “Time estimation and
reproduction is abnormal in Parkinson’s disease”. Brain 115:1, 1992, pp. 211–
225.

232.

233.

J. J. Paton and D. V. Buonomano. “The Neural Basis of Timing: Distributed
Mechanisms for Diverse Functions”. Neuron 98:4, 2018, pp. 687–705. doi: 10.
1016/j.neuron.2018.03.045. url: https://doi.org/10.1016/j.neuron.2018.03.045.
J. J. Pattadkal, G. Mato, C. van Vreeswijk, N. J. Priebe, and D. Hansel. “Emer-
gent orientation selectivity from random networks in mouse visual cortex”.
Cell reports 24:8, 2018, pp. 2042–2050.

234. C. Pehlevan, F. Ali, and B. Ölveczky. “Flexibility in motor timing constrains
the topology and dynamics of pattern generator circuits.” Nat Commun 9,
977, 2018. doi: 10.1038/s41467-018-03261-5.

235. R. Perin, T. K. Berger, and H. Markram. “A synaptic organizing principle for
cortical neuronal groups”. PNAS, 2011. doi: 10.1073/pnas.1016051108.
236. A. J. Peters, S. X. Chen, and T. Komiyama. “Emergence of reproducible spa-
tiotemporal activity during motor learning”. Nature 510:7504, 2014, pp. 263–
267. doi: 10.1038/nature13235.

237. A. R. Pfenning et al. “Convergent transcriptional specializations in the brains
of humans and song-learning birds”. Science 346:6215, 2014. doi: 10 . 1126 /
science.1256846. url: https://doi.org/10.1126/science.1256846.

238. B. Pollok, H. Prior, and O. Güntürkün. “Development of object permanence
in food-storing magpies (Pica pica).” Journal of Comparative Psychology 114:2,
2000, pp. 148–157. doi: 10.1037/0735-7036.114.2.148.
J. Prather, S. Peters, S. Nowicki, and R. Mooney. “Precise auditory-vocal mir-
roring in neurons for learned vocal communication.” Nature, 2008. doi: 10.
1038/nature06492.

239.

240.

J. F. Prather, S. Peters, S. Nowicki, and R. Mooney. “Precise auditory–vocal
mirroring in neurons for learned vocal communication”. Nature 451:7176,
2008, pp. 305–310.

241. V. Prevosto, W. Graf, and G. Ugolini. “Cerebellar inputs to intraparietal cor-
tex areas LIP and MIP: functional frameworks for adaptive control of eye
movements, reaching, and arm/eye/head movement coordination”. Cere-
bral Cortex 20:1, 2010, pp. 214–228.

161

Bibliography

242. H. Prior, A. Schwarz, and O. Güntürkün. “Mirror-induced behavior in the
magpie (Pica pica): evidence of self-recognition”. PLoS biology 6:8, 2008, e202.

243. Y. Prut, E. Vaadia, H. Bergman, I. Haalman, H. Slovin, and M. Abeles. “Spa-
tiotemporal Structure of Cortical Activity: Properties and Behavioral Rele-
vance”. Journal of Neurophysiology 79:6, 1998, pp. 2857–2874. doi: 10.1152/jn.
1998.79.6.2857. url: https://doi.org/10.1152/jn.1998.79.6.2857.

244. C. R. Raby, D. M. Alexis, A. Dickinson, and N. S. Clayton. “Planning for the

future by western scrub-jays”. Nature 445:7130, 2007, pp. 919–921.

245. K. Rajan, L. Abbott, and H. Sompolinsky. “Stimulus-dependent suppression
of chaos in recurrent neural networks”. Physical review e 82:1, 2010, p. 011903.

246. T. H. Rammsayer. “Neuropharmacological evidence for different timing mech-

anisms in humans”. The Quarterly Journal of Experimental Psychology: Section
B 52:3, 1999, pp. 273–286.

247. P. Reddy, W. Zehring, D. Wheeler, V. Pirrotta, C. Hadfield, J. Hall, and M.
Rosbash. “Molecular analysis of the period locus in Drosophila melanogaster
and identification of a transcript involved in biological rhythms.” Cell., 1984.
doi: 10.1016/0092-8674(84)90265-4.

248. A. Reiner et al. “Revised nomenclature for avian telencephalon and some
related brainstem nuclei”. The Journal of Comparative Neurology 473:3, 2004,
pp. 377–414. doi: 10.1002/cne.20118.

249.

250.

J. Reutimann, V. Yakovlev, S. Fusi, and W. Senn. “Climbing Neuronal Ac-
tivity as an Event-Based Cortical Representation of Time”. The Journal of
Neuroscience 24:13, 2004, pp. 3295–3303. doi: 10.1523/jneurosci.4098- 03.2004.
url: https://doi.org/10.1523/jneurosci.4098-03.2004.

J. L. Riquelme, M. Hemberger, G. Laurent, and J. Gjorgjieva. “Single spikes
drive sequential propagation and routing of activity in a cortical network”.
Elife 12, 2023, e79928.

251. T. F. Roberts, E. Hisey, M. Tanaka, M. G. Kearney, G. Chattree, C. F. Yang,
N. M. Shah, and R. Mooney. “Identification of a motor-to-auditory pathway
important for vocal learning”. Nature Neuroscience 20:7, 2017, pp. 978–986.
doi: 10.1038/nn.4563. url: https://doi.org/10.1038/nn.4563.

252. C. Rovelli. The order of time. Penguin, 2019.

253.

J. T. Sakata and M. S. Brainard. “Online contributions of auditory feedback to
neural activity in avian song control circuitry”. Journal of Neuroscience 28:44,
2008, pp. 11378–11390.

254.

J. T. Sakata and Y. Yazaki-Sugiyama. “Neural circuits underlying vocal learn-
ing in songbirds”. The neuroethology of birdsong, 2020, pp. 29–63.

162

Bibliography

255. C. Scharff and F. Nottebohm. “A comparative study of the behavioral deficits
following lesions of various parts of the zebra finch song system: implica-
tions for vocal learning”. The Journal of Neuroscience 11:9, 1991, pp. 2896–
2913. doi: 10.1523/jneurosci.11- 09- 02896.1991. url: https://doi.org/10.1523/
jneurosci.11-09-02896.1991.

256. C. Scharff, J. R. Kirn, M. Grossman, J. D. Macklis, and F. Nottebohm. “Tar-
geted Neuronal Death Affects Neuronal Replacement and Vocal Behavior
in Adult Songbirds”. Neuron 25:2, 2000, pp. 481–492. doi: 10 . 1016 / s0896 -
6273(00)80910-1. url: https://doi.org/10.1016/s0896-6273(00)80910-1.

257. M. F. Schmidt. “Pattern of Interhemispheric Synchronization in HVc Dur-
ing Singing Correlates With Key Transitions in the Song Pattern”. Journal of
Neurophysiology 90:6, 2003, pp. 3931–3949. doi: 10 . 1152 / jn . 00003 . 2003. url:
https://doi.org/10.1152/jn.00003.2003.

258. M. F. Schmidt, J. McLean, and F. Goller. “Breathing and vocal control: the
respiratory system as both a driver and a target of telencephalic vocal mo-
tor circuits in songbirds”. Experimental Physiology 97:4, 2011, pp. 455–461.
doi: 10.1113/expphysiol.2011.058669. url: https://doi.org/10.1113/expphysiol.
2011.058669.

259. W. A. Searcy and M. Andersson. “Sexual selection and the evolution of
song”. Annual Review of Ecology and Systematics 17:1, 1986, pp. 507–533.

260. S. Sharma, S. Chandra, and I. Fiete. “Content addressable memory with-
out catastrophic forgetting by heteroassociation with a fixed scaffold”. In:
International Conference on Machine Learning. PMLR. 2022, pp. 19658–19682.

261. K. V. Shenoy, M. Sahani, and M. M. Churchland. “Cortical control of arm
movements: a dynamical systems perspective”. Annual review of neuroscience
36, 2013, pp. 337–359.

262. P. Simen, F. Balci, L. Souza, J. Cohen, and P. Holmes. “A Model of Interval
Timing by Neural Integration.” The Journal of neuroscience : the official journal
of the Society for Neuroscience 31, 2011, pp. 9238–53. doi: 10 . 1523 / JNEUROSCI .
3121-10.2011.

263. H. Simpson and D. Vicario. “Brain pathways for learned and unlearned
vocalizations differ in zebra finches”. The Journal of Neuroscience 10:5, 1990,
pp. 1541–1556. doi: 10.1523/jneurosci.10- 05- 01541.1990. url: https://doi.org/
10.1523/jneurosci.10-05-01541.1990.

264. M. Skocik and A. Kozhevnikov. “Real-time system for studies of the effects
of acoustic feedback on animal vocalizations”. Frontiers in Neural Circuits 6,
2013, p. 111.

265. A. Smirnova, Z. Zorina, T. Obozova, and E. Wasserman. “Crows sponta-
neously exhibit analogical reasoning”. Current Biology 25:2, 2015, pp. 256–
260.

163

Bibliography

266. F. Sohrabji, E. J. Nordeen, and K. W. Nordeen. “Selective impairment of song
learning following lesions of a forebrain nucleus in the juvenile zebra finch”.
Behavioral and Neural Biology 53:1, 1990, pp. 51–63. doi: 10.1016/0163-1047(90)
90797-a. url: https://doi.org/10.1016/0163-1047(90)90797-a.

267. H. Sompolinsky, A. Crisanti, and H.-J. Sommers. “Chaos in random neural

networks”. Physical review letters 61:3, 1988, p. 259.

268. R. M. C. Spencer and R. B. Ivry. “Cerebellum and Timing”. In: Handbook of
the Cerebellum and Cerebellar Disorders. Springer Netherlands, 2013, pp. 1201–
1219. doi: 10.1007/978- 94- 007- 1333- 8\_52. url: https://doi.org/10.1007/978- 94-
007-1333-8\_52.

269.

J. E. R. Staddon and J. J. Higa. “TIME AND MEMORY: TOWARDS A PACEMAKER-
FREE THEORY OF INTERVAL TIMING”. Journal of the Experimental Analysis
of Behavior 71:2, 1999, pp. 215–251. doi: 10.1901/jeab.1999.71- 215. url: https:
//doi.org/10.1901/jeab.1999.71-215.

270. K. Stevens. “Scientific substrates of speech production”. Introduction to com-

munication sciences and disorders, 1994, pp. 399–437.

271. S. Stringer, T. Trappenberg, E. Rolls, and I. Araujo. “Self-organizing con-
tinuous attractor networks and path integration: one-dimensional models
of head direction cells”. Network: Computation in Neural Systems 13:2, 2002,
pp. 217–242.

272. S. H. Strogatz. Nonlinear dynamics and chaos: with applications to physics, biol-

ogy, chemistry, and engineering. Westview Press., 1994.

273. D. Sussillo and L. F. Abbott. “Generating coherent patterns of activity from

chaotic neural networks”. Neuron 63:4, 2009, pp. 544–557.

274. M. Tanaka, F. Sun, Y. Li, and R. Mooney. “A mesocortical dopamine circuit
enables the cultural transmission of vocal behaviour”. Nature 563:7729, 2018,
pp. 117–120.

275.

276.

J. Tanji. “Sequential organization of multiple movements: involvement of
cortical motor areas”. Annual review of neuroscience 24:1, 2001, pp. 631–651.

J. S. Taube, R. U. Muller, and J. B. Ranck. “Head-direction cells recorded from
the postsubiculum in freely moving rats. I. Description and quantitative
analysis”. Journal of Neuroscience 10:2, 1990, pp. 420–435.

277. S. Teki, M. Grube, S. Kumar, and T. D. Griffiths. “Distinct Neural Substrates
of Duration-Based and Beat-Based Auditory Timing”. The Journal of Neuro-
science 31:10, 2011, pp. 3805–3812. doi: 10.1523 /jneurosci.5561- 10.2011. url:
https://doi.org/10.1523/jneurosci.5561-10.2011.

278. E. C. Traugott. “On the expression of spatio-temporal relations in language”.

Universals of Human Language III, 1978.

164

Bibliography

279. M. Treisman. “Temporal discrimination and the indifference interval: Impli-
cations for a model of the "internal clock".” Psychological Monographs: General
and Applied, 77(13), 1–31., 1963. doi: 10.1037/h0093864.

280. S. G. Trettel, J. B. Trimper, E. Hwaun, I. R. Fiete, and L. L. Colgin. “Grid cell
co-activity patterns during sleep reflect spatial overlap of grid fields during
active behaviors”. Nature neuroscience 22:4, 2019, pp. 609–617.

281. T. W. Troyer and A. J. Doupe. “An Associational Model of Birdsong Sensori-
motor Learning I. Efference Copy and the Learning of Song Syllables”. Jour-
nal of Neurophysiology 84:3, 2000, pp. 1204–1223. doi: 10.1152/jn.2000.84.3.1204.
url: https://doi.org/10.1152/jn.2000.84.3.1204.

282. E. C. Tumer and M. S. Brainard. “Performance variability enables adaptive
plasticity of ‘crystallized’adult birdsong”. Nature 450:7173, 2007, pp. 1240–
1244.

283. R. Ursu. “Role of the cerebellum in avian song learning”. Thesis, 2023.

284. D. Vallentin, G. Kosche, D. Lipkind, and M. A. Long. “Inhibition protects
acquired song segments during vocal learning in zebra finches”. Science
351:6270, 2016, pp. 267–271. doi: 10.1126/science.aad3023. url: https://doi.org/
10.1126/science.aad3023.

285. D. Vallentin and M. A. Long. “Motor Origin of Precise Synaptic Inputs onto
Forebrain Neurons Driving a Skilled Behavior”. The Journal of Neuroscience
35:1, 2015, pp. 299–307. doi: 10 . 1523 / jneurosci . 3698 - 14 . 2015. url: https :
//doi.org/10.1523/jneurosci.3698-14.2015.

286. L. Veit and A. Nieder. “Abstract rule neurons in the endbrain support in-
telligent behaviour in corvid songbirds”. Nature communications 4:1, 2013,
p. 2878.

287. E. Vu, M. Mazurek, and Y. Kuo. “Identification of a forebrain motor pro-
gramming network for the learned song of zebra finches.” Journal of Neuro-
science, 1994. doi: 10.1523/JNEUROSCI.14-11-06924.1994.

288. M. Wang, D. Arteaga, and B. J. He. “Brain mechanisms for simple percep-
tion and bistable perception”. Proceedings of the National Academy of Sciences
110:35, 2013, E3350–E3359.

289. N. Wang, P. Hurley, C. Pytte, and J. R. Kirn. “Vocal control neuron incorpo-
ration decreases with age in the adult zebra finch”. Journal of Neuroscience
22:24, 2002, pp. 10864–10870.

290. X.-J. Wang. “Decision making in recurrent neuronal circuits”. Neuron 60:2,

2008, pp. 215–234.

291. T. L. Warren, E. C. Tumer, J. D. Charlesworth, and M. S. Brainard. “Mech-
anisms and time course of vocal learning and consolidation in the adult
songbird”. Journal of neurophysiology 106:4, 2011, pp. 1806–1821.

165

Bibliography

292. S. Watanabe, J. Sakamoto, and M. Wakita. “PIGEONS’DISCRIMINATION
OF PAINTINGS BY MONET AND PICASSO”. Journal of the experimental
analysis of behavior 63:2, 1995, pp. 165–174.

293.

J. H. Wearden and I. S. Penton-Voak. “Feeling the heat: body temperature
and the rate of subjective time, revisited.” he Quarterly journal of experimental
psychology. B, Comparative and physiological psychology 48:2, 1995, pp. 129–141.
url: https://doi.org/10.1080/14640749508401443.

294. A. A. Weir, J. Chappell, and A. Kacelnik. “Shaping of hooks in New Caledo-

nian crows”. Science 297:5583, 2002, pp. 981–981.

295. M. W. Westneat, J. H. Long Jr, W. Hoese, and S. Nowicki. “Kinematics of
birdsong: functional correlation of cranial movements and acoustic features
in sparrows”. Journal of Experimental Biology 182:1, 1993, pp. 147–171.

296. H. Williams and D. S. Vicario. “Temporal patterning of song production:
Participation of nucleus uvaeformis of the thalamus”. Journal of Neurobiology
24:7, 1993, pp. 903–912. doi: 10.1002/neu.480240704. url: https://doi.org/10.
1002/neu.480240704.

297. R. Williams. “Simple statistical gradient-following algorithms for connec-

tionist reinforcement learning.” Mach Learn, 1992.

298. H. R. Wilson and J. D. Cowan. “A mathematical theory of the functional
dynamics of cortical and thalamic nervous tissue”. Kybernetik 13:2, 1973,
pp. 55–80.

299. S. M. Woolley and C. V. Portfors. “Conserved mechanisms of vocalization
coding in mammalian and songbird auditory midbrain”. Hearing research
305, 2013, pp. 45–56.

300. S. Yagishita, A. Hayashi-Takagi, G. C. Ellis-Davies, H. Urakubo, S. Ishii, and
H. Kasai. “A critical time window for dopamine actions on the structural
plasticity of dendritic spines”. Science 345:6204, 2014, pp. 1616–1620. doi: 10.
1126/science.1255514. url: https://doi.org/10.1126/science.1255514.

301. Y. Yamashita, M. Takahasi, T. Okumura, M. Ikebuchi, H. Yamada, M. Suzuki,
K. Okanoya, and J. Tani. “Developmental learning of complex syntactical
song in the Bengalese finch: A neural network model”. Neural Networks 21:9,
2008, pp. 1224–1231. doi: 10.1016/j.neunet.2008.03.003. url: https://doi.org/
10.1016/j.neunet.2008.03.003.

302. H. N. Zelaznik, R. M. C. Spencer, and R. B. Ivry. “Dissociation of explicit and
implicit timing in repetitive tapping and drawing movements.” Journal of Ex-
perimental Psychology: Human Perception and Performance 28:3, 2002, pp. 575–
588. doi: 10 . 1037 / 0096 - 1523 . 28 . 3 . 575. url: https : / / doi . org / 10 . 1037 / 0096 -
1523.28.3.575.

303. K. Zhang. “Representation of spatial orientation by the intrinsic dynamics
of the head-direction cell ensemble: A theory.” Journal of Neuroscience, 1996.

166

Bibliography

304. Y. S. Zhang, J. D. Wittenbach, D. Z. Jin, and A. A. Kozhevnikov. “Tempera-
ture Manipulation in Songbird Brain Implicates the Premotor Nucleus HVC
in Birdsong Syntax”. The Journal of Neuroscience 37:10, 2017, pp. 2600–2611.
doi: 10 . 1523 / jneurosci . 1827 - 16 . 2017. url: https : / / doi . org / 10 . 1523 / jneurosci .
1827-16.2017.

305. X. Zhou, É. de Villers-Sidani, R. Panizzutti, and M. M. Merzenich. “Successive-

signal biasing for a learned sound sequence”. Proceedings of the National
Academy of Sciences 107:33, 2010, pp. 14839–14844. doi: 10.1073/pnas.1009433107.
url: https://doi.org/10.1073/pnas.1009433107.

167

