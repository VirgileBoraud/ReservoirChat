Learning an inverse model for vocal production: toward
a bio-inspired model
Silvia Pagliarini, Xavier Hinaut, Arthur Leblois

To cite this version:

Silvia Pagliarini, Xavier Hinaut, Arthur Leblois. Learning an inverse model for vocal production: to-
ward a bio-inspired model. European Birdsong Meeting, Apr 2018, Odense, Denmark. ￿hal-01963115￿

HAL Id: hal-01963115

https://inria.hal.science/hal-01963115

Submitted on 21 Dec 2018

HAL is a multi-disciplinary open access
archive for the deposit and dissemination of sci-
entific research documents, whether they are pub-
lished or not. The documents may come from
teaching and research institutions in France or
abroad, or from public or private research centers.

L’archive ouverte pluridisciplinaire HAL, est
destinée au dépôt et à la diffusion de documents
scientifiques de niveau recherche, publiés ou non,
émanant des établissements d’enseignement et de
recherche français ou étrangers, des laboratoires
publics ou privés.

Learning an inverse model for vocal 
production: toward a bio-inspired model

6th European Birdsong Meeting, April 12-13, 2018, Odense, Denmark

Silvia Pagliarini 
(with Xavier Hinaut and Arthur Leblois)
INRIA Bordeaux Sud-Ouest, Institut des Maladies Neurodégénératives, Université de Bordeaux, FR

WHAT IS SENSORIMOTOR LEARNING?

Control problem which maps a sensory input into a motor output

Basic components:

● Input: sensory stimulus

● Output: reproduction of the stimulus

Da Cunha et al., 2010

LEARNING BY IMITATION AND INVERSE MODEL

Imitation: learning from a tutor using a feedback guided error

Sensory area

Motor area

Motor production

LEARNING BY IMITATION AND INVERSE MODEL

Imitation: learning from a tutor using a feedback guided error

Inverse model: the aim is to transform a sensory stimulus into the corresponding 
motor command 

Inverse model

Sensory area

Motor area

Motor production

A BIOLOGICAL EXAMPLE: SONG LEARNING IN 
BIRDS

● Comparable learning mechanisms and behavior

Sensory

Subsong (Babbling)

Plastic song

Crystallization

Brainard and Doupe, 2002

A BIOLOGICAL EXAMPLE: SONG LEARNING IN 
BIRDS

● Comparable learning mechanisms and behavior

Sensory

Subsong (Babbling)

Plastic song

Crystallization

Brainard and Doupe, 2002

A BIOLOGICAL EXAMPLE: SONG LEARNING IN 
BIRDS

● Comparable learning mechanisms and behavior

Sensory

Subsong (Babbling)

Plastic song

Crystallization

Brainard and Doupe, 2002

LEARNING AN INVERSE MODEL

Synaptic weights initially weak

…

Sensory 
Area

…

Motor Area

 
 
 
 
 
 
 
 
LEARNING AN INVERSE MODEL

Synaptic weights initially weak

At each time : 

●

…

Sensory 
Area

…

Motor Area

 
 
 
 
 
 
 
 
LEARNING AN INVERSE MODEL

Synaptic weights initially weak

At each time : 

●

●

Hebbian learning 
rule

 : learning rate

…

Sensory 
Area

…

Motor Area

 
 
 
 
 
 
 
 
LEARNING AN INVERSE MODEL

Synaptic weights initially weak

Hebbian learning 
rule

At each time : 

●

●

●

 : learning rate

…

Sensory 
Area

…

Motor Area

 
 
 
 
 
 
 
 
HAHNLOSER-GANGULI THEORETICAL MODEL

i

l

s
n
o
i
t
a
u
m
s
0
5
r
e
v
o
e
c
n
a
t
s
d
e
g
a
r
e
v
A

i

Time (in number of time steps)

 
 
 
 
 
NONLINEAR MODEL INTRODUCTION

 : target motor pattern

 : tuning selectivity width

 represents the distance 
between the target and the random 
exploration

GANGULI-HAHNLOSER MODEL

l

i

s
n
o
i
t
a
u
m
s
0
5
r
e
v
o
e
c
n
a
t
s
d
e
g
a
r
e
v
A

i

Time (in number of time steps)

 
 
 
 
NORMALIZATION

Synaptic weights have a maximal value, related to the number of synaptic receptors 
one neuron is able to produce. 

NORMALIZATION

Synaptic weights have a maximal value, related to the number of synaptic receptors 
one neuron is able to produce. 

● Maximal weights normalization

● Supremum weights normalization

NORMALIZATION

Synaptic weights have a maximal value, related to the number of synaptic receptors 
one neuron is able to produce. 

● Maximal weights normalization

● Supremum weights normalization

● Decreasing factor normalization 

NORMALIZED INVERSE MODEL

Maximum weights

Supremum weights

Decreasing factor

e
c
n
a
t
s
d
e
h
t

i

f

o
n
o
i
t
u
o
v
E

l

Time (in number of time steps)

Normalization applied over the auditory neurons

 
 
 
NORMALIZED INVERSE MODEL

e
c
n
a
t
s
d
e
h
t

i

f

o
n
o
i
t
u
o
v
E

l

Mean

Norm

Time (in number of time steps)

 
 
 
 
AUDITORY SELECTIVITY EFFECT

)
s
p
e
t
s
e
m

i
t

f

o
r
e
b
m
u
n
n

i
(

e
m

i
t
e
c
n
e
g
r
e
v
n
o
C

t
e
g
r
a
t
e
h
t

m
o
r
f
e
c
n
a
t
s
D

i

Tuning selectivity width

 
 
 
 
 
 
 
 
 
VARYING INPUT/OUTPUT DIMENSION

t
e
g
r
a
t
e
h
t

m
o
r
f
e
c
n
a
t
s
D

i

Distance from the motor target at convergence

Number of neurons in the network

 
 
 
VARYING INPUT/OUTPUT DIMENSION

)
s
p
e
t
s
e
m

i
t

f

o
r
e
b
m
u
n
n

i
(

e
m

i
t
e
c
n
e
g
r
e
v
n
o
C

Convergence time

Number of neurons in the network

 
 
 
 
 
 
SUMMARY

● Simple normalization schema are successful in the nonlinear model

● Decreasing tuning selectivity width: 
○ convergence time explosion 
○ accuracy of learning increases 

● Auditory VS motor dimension 

WHAT’S NEXT?

● Duration of syllable and feedback delay

WHAT’S NEXT?

● Duration of syllable and feedback delay

● Production of sound 

WHAT’S NEXT?

● Duration of syllable and feedback delay

● Production of sound 

Enjoy the poster from 
Xavier Hinaut

WHAT’S NEXT?

● Duration of syllable and feedback delay

● Production of sound 

Enjoy the poster from 
Xavier Hinaut

● Make prediction on experimental data

Thanks for the attention.

