A bio-inspired model towards vocal gesture learning in songbird Silvia
Pagliarini, Xavier Hinaut, Arthur Leblois

To cite this version:

Silvia Pagliarini, Xavier Hinaut, Arthur Leblois. A bio-inspired model
towards vocal gesture learning in songbird. 2018 Joint IEEE
International Conference on Development and Learning and Epigenetic
Robotics (ICDL-EpiRob), Sep 2018, Tokyo, Japan. ￿hal-01906459v2￿

HAL Id: hal-01906459

https://inria.hal.science/hal-01906459v2

Submitted on 22 Apr 2021

HAL is a multi-disciplinary open access archive for the deposit and
dissemination of sci- entific research documents, whether they are pub-
lished or not. The documents may come from teaching and research
institutions in France or abroad, or from public or private research
centers.

L’archive ouverte pluridisciplinaire HAL, est destinée au dépôt et à la
diffusion de documents scientifiques de niveau recherche, publiés ou
non, émanant des établissements d’enseignement et de recherche français
ou étrangers, des laboratoires publics ou privés.

A bio-inspired model towards vocal gesture learning in songbird

Silvia Pagliarini Inria Bordeaux Sud-Ouest, Talence, France. LaBRI, UMR
5800, CNRS, Bordeaux INP, IMN, UMR 5293, CNRS, Universit´e de Bordeaux,
France. silvia.pagliarini@inria.fr

Xavier Hinaut* Inria Bordeaux Sud-Ouest, Talence, France. LaBRI, UMR
5800, CNRS, Bordeaux INP, IMN, UMR 5293, CNRS, Universit´e de Bordeaux,
France. xavier.hinaut@inria.fr

Arthur Leblois* IMN, UMR 5293, CNRS, Universit´e de Bordeaux, France.
arthur.leblois@u-bordeaux.fr

Abstract—The paper proposes a bio-inspired model for an imitative
sensorimotor learning, which aims at building a map between the sensory
representations of gestures (sensory targets) and their underlying motor
pattern through random exploration of the motor space. An example of
such learning process occurs during vocal learning in humans or birds,
when young subjects babble and learn to copy previously heard adult
vocalizations. Previous work has suggested that a simple Hebbian
learning rule allows perfect imitation when sensory feedback is a purely
linear function of the motor pattern underlying movement production. We
aim at generalizing this model to the more realistic case where sensory
responses are sparse and non-linear. To this end, we explore the
performance of various learning rules and nor- malizations and discuss
their biological relevance. Importantly, the proposed model is robust
whatever normalization is chosen. We show that both the imitation
quality and the convergence time are highly dependent on the sensory
selectivity and dimension of the motor representation.

I. INTRODUCTION

in a sensorimotor phase,

Imitative sensorimotor learning can be though as a control problem
aiming to map the sensory input into a motor output. For example, humans
and songbirds learn to produce species- speciﬁc vocalizations as
juveniles by imitating surrounding adults. The vocal learning process
displays distinct (although partially overlapping) processes. First,
during a sensory learn- ing phase, young subjects memorize adult
vocalizations, and build neuronal representations of their species vocal
gestures. they start vocalizing and Then, progressively converge to a
good imitation of previously exprienced vocalizations. It is believed
that during the early phase of this sensorimotor process, called
babbling, the sub- ject maps representation of sensory (auditory)
targets to the corresponding motor commands. In other words, the subject
learns an inverse model. In this study, we assume the auditory selective
responses to be already in place and investigate biological plausible
mechanisms to learn an inverse model enabling this sensorimotor mapping.

An interesting property of some neurons in the brain is the ability to
respond similarly during the production or observa- tion (or listening
for vocal gestures) of a given movement. This property has been linked
with imitative sensorimotor learning

* Corresponding authors that co-supervised the study.

and internal models (inverse or forward model). These neurons are
referred to as mirror neuron [1], [2], [3]. While forward models
describe a causal relationship between the sensory input and the motor
system, inverse models have the aim to provide an appropriate motor
command to a given state of the motor system. Although building an
inverse model is easier when a forward model is available as proposed in
[4], [5], inverse models could be enough to bootstrap the development of
a simple computational mechanism, describing a memory system composed by
the motor plan and the sensory stim- ulus [6]. The importance of
computational models involving mirrors systems and learning processes
has been stressed by Oztop et al. [1], [6], and the ”Mirror-system
hypothesis” stated by Arbib in [7] links mirror neurons with the
emergence of human language during evolution. Songbirds learn their
vocalization by imitation through a vocal learning process that very
much resembles speech learning in human babies [8]. In the brain of
songbirds, a part of the basal ganglia-thalamo- cortical circuitry is
devoted to song learning in juveniles and plasticity in adults. This
circuit is homologuous to the basal ganglia circuits responsible for
motor learning in mammals, and involved in speech learning in humans
[9], [10]. Moreover, this song-related BG-thalamo-cortical circuit in
birds receives input from mirror neurons [2]. Therefore, the brain
circuits re- sponsible for avian song learning represent an ideal
framework to study the neural mechanisms underlying imitative learning.
A theoretical model describing the implementation of an inverse model
between auditive and motor areas through associative learning has been
proposed recently [11], [12]. The model is based on a simple Hebbian
learning rule driven through random motor exploration and auditory
feedback responses to this motor exploration. The proposed model assumes
linearity for mathematical simplicity. As auditory responses in the
brain are rather sparse and nonlinear we aim to extent the theoretical
framework to a more realistic scenario [13].

We used an inverse model inspired by Hahnloser and Gan- guli [11] to
describe the interaction between two populations of neurons, one formed
by motor neurons and another formed by sensory neurons. We ﬁrst show
that replacing the learning rule by a simple normalized Hebbian learning
rule allows

rapid convergence in a simple non-linear model. We apply different
normalizations in the learning rule. We then explore the inﬂuence of the
sharpness of auditory selectivity in relation with the learning error
after convergence and convergence time of the learning. Finally, we show
how changing the number of sensory or motor dimensions modiﬁes learning.

A. Network and goal

II. METHOD

The model includes two neural populations as shown in Fig. 1. The ﬁrst
layer is composed by afferent neurons and represents the sensory area.
The second layer is composed by motor neurons, which represent the
starting point for muscle activation, and thereby for movement
production. The synaptic weights describing the strength of the
connection between neurons are deﬁned by matrix W .

Fig. 1. Neural network schema. The network includes two neural popu-
lations: the ﬁrst layer is composed by na afferent neurons and
represents the sensory area, the second layer is composed by nm motor
neurons and represents the motor area. Wi,j represents the synaptic
connections between sensory and motor neurons. Below the network schema
we highlight how we deﬁne the sensory response. At each time step t, the
sensory response is a function of the motor output, that is At = f (Mt).

A model describing sensorimotor phase of learning based on a network as
in Fig. 1 has been previously proposed by Hahnloser and Ganguli [11].
Neurons are linear units and at each time t motor and auditory activity
are deﬁned as a nm- dimensional vector Mt and a na-dimensional vector
At, where nm and na represent respectively the number of motor and
auditory neurons in the network.

B. Auditory response

At each time t the auditory activity At is deﬁned as a function of the
motor pattern Mt at that particular time, that is At = f (Mt). Hahnloser
and Ganguli in [11] deﬁne the auditory activity as a linear function of
Mt, that is

At = QMt,

(1) 

where Mt represents the motor pattern at time t and Q the linear map
deﬁning the auditory activity due to the auditory feedback driven by
current motor activity.

We then introduce non-linearity in the sensory response to auditory
feedback. To represent selective responses as observed in various high
sensory brain areas (e.g. auditory

regions of the pallium in birds display responses selective to tutor
syllables or to the bird’s own syllables), we deﬁne the auditory
activity At for each j = 1, .., na neurons as a bell- shaped function
around a target motor pattern:

Ajt = exp

(cid:18) −||M ∗

j − Mt||2 2σ2nm

(cid:19) ,

(2) 

where σ represents the selectivity tuning width, nm the number of motor
neurons belonging to the network, Mt the motor pattern at time t and M ∗
the center of the auditory activity.

C. Learning process

Learning is driven by the Hebbian learning rule

∆Wt ∝ ηMtAt,

(3) 

where Wt represents the synaptic weights between sensory and motor
neurons, η the learning rate, Mt the motor pattern at time t and At the
auditory activity at time t.

Synaptic weights Wt=t0 between sensory and motor neu- rons are initially
weak and increase according with (3) during learning until a certain
time t = tf , as

Wt = Wt−1 + ∆Wt,

(4) 

where Wt represents the synaptic connections between sensory and motor
neurons and ∆Wt is deﬁned by (3).

However, synaptic weights have an upper boundary due to biological
limitations (maximal number of synaptic receptors or neurotransmitters
released). This can be introduced by a normalization either on the
synaptic weights Wi,j or on their variation ∆Wi,j.

Hahnloser and Ganguli in [11] proposed a postdictive Heb-

bian learning rule given by

∆Wt = η(Mt − Wt−1At)AT t ,

(5) 

where Wt represents the synaptic weights between sensory and motor
neurons, η the learning rate, Mt the motor pattern and At is deﬁned by
Eq. (1). Here the apex T indicates the transpose of the vector At.

In our model, we kept the basic Hebbian rule and we tested three
normalizations in two different cases: a normalization over motor
neurons (over all targets of one postsynaptic neuron) and a
normalization over auditory neurons (over all inputs of one presynaptic
neuron).

In practice, the two types of normalization are respectively implemented
by normalizing over the lines or columns of the weights matrix W . The
aim of the normalization is to bound either the mean of each column or
line of Wi,j or the euclidean norm of each column or line of Wi,j to a
maximum of 1. Considering the case of normalizing with respect to
auditory neurons and pushing the mean of every column of W to a maximum
of 1, the applied normalizations are the following:

• Maximum weights normalization

Wi,j =

nmWi,j ΣiWi,j

,

(6) 

• Supremum weights normalization

(cid:40)

Wi,j =

Wi,j nmWi,j ΣiWi,j

ΣiWi,j < 1, nm otherwise,

• Decreasing factor normalization

∆Wi,j = ηMtAt

1 −

(cid:18)

(cid:19)

.

ΣiWi,j nm

(7) 
(8) 

Here Wi,j represents the synaptic connections between sen- sory neuron j
and motor neurons i = 1, .., nm, where nm is the number of motor
neurons.

To obtain the normalization over the motor neurons and pushing the mean
of each line of W to a maximum of 1, it is enough to change the index i
for the index j and use the auditory dimension na. In order to use the
norm instead of the mean in the deﬁniton of the normalizations it is
enough to introduce the norm on the column or the norm on the line of W
in place of the mean.

At the same time, normalizing synaptic weights forces us to also
normalize the motor target M ∗, which represents what the model would
learn at t = tf . This is equivalent to a reduction of the target motor
space (as it introduces a constraint on the ﬁnal output of the model).

D. Simulation details

Each sensory neuron contains the response to a motor performance, and
this is represented by the motor target M ∗. We did not consider any
strategy for the exploration. That is, at each time step t we simply
considered the case of a random motor exploration Mt on which the
auditory selectivity depends.

In the Hahnloser-Ganguli model there exist a direct map which deﬁnes the
motor activity from the auditory activity as Mt = QdAt. For the inverse
model we need to deﬁne At in dependence on Mt as in Eq. (1). That is the
inverse matrix of Q, i.e Qd represents the motor target M ∗, that is the
ideal motor activity which the model should have learned once learning
phase has ended. The goal then is to activate each sensory neuron can
drive M ∗

j through W , such that

W A∗ −→ M ∗,

(9) 

where A∗ = A0I deﬁnes the ideal auditory activity. We ﬁxed A0 = 1.

Given the motor targets M ∗, at each time step t, the distance between
what the model actually learned and what it should have learned is
deﬁned as

dt =

||M ∗ − WtA∗|| nm

,

(10) 

where M ∗ represents the motor target, Wt the synaptic weights matrix,
A∗ the ideal auditory activity and nm the number of motor neurons.

We deﬁned the convergence time τ as the number of time steps at which
the updates of the weights are small enough. That is, the distance
between what the model targets should have learned and what he
effectively learned reaches a plateau.

After have chosen (cid:15) = 1 at t = t0, given an interval of time ∆t =
[k, k + 2N ] of measure 2N , we deﬁned

(cid:15) =

1 2N

(cid:18)

Σk+2N

k+N dt − Σk+N

k

(cid:19) ,

dt

(11) 

and we used it as threshold, in a way that a particular experiment stops
either if (cid:15) reaches the value (cid:15)∗ = 10−9 either if it goes
until a ﬁxed time t = tf . We tested i.e. σ = several values for the
tuning selectivity width, [0.02, 0.05, 0.1, 0.2, 0.3, 0.5, 0.7], varying
in this way the au- ditory selectivity. We used for almost every value
an interval of length N = 400. However, since the distance evolves very
slowly, for small values of σ this interval is not large enough. For
instance, an interval with N = 500000 has been used for σ = 0.02.

III. RESULTS

A. Simple model with linear auditory responses

Fig. 2 shows the evolution in time of the smooth average distance
between W A∗ and the target motor pattern M ∗, deﬁned by Eq. (10) for
each simulation. In the linear version of the model (blue line) , the
auditory activity is a linear function of the motor production, as in
Eq. (1), and the postdictive Hebbian rule deﬁned by Eq. (5) guides
learning. As expected by the theory [11], the distance between W A∗ and
the target motor pattern M ∗ (which is the inverse of Q) converges
exponentially to zero. The learning rule therefore ensures proper
learning of the inverse model. In contrast, when auditory feedback is
non-linear (orange line in Fig. 2), where the auditory activity is
deﬁned by Eq. (2), the postdictive Hebbian learning rule does not allow
convergence, and the distance between W A∗ and the target motor pattern
M ∗ rather diverges.

Fig. 2. Ganguli-Hahnloser linear and nonlinear model. Evolution in time
of the smooth average distance between W A∗ and the target motor pattern
M ∗, computed over 50 simulations. Comparison between the
Hahnloser-Ganguli linear model (in blue) where the auditory response is
deﬁned by Eq. (1) and the nonlinear version of Hahnloser-Ganguli model
(in orange) where the auditory response is deﬁned by Eq. (2). In both
cases learning is driven by the postidictive Hebbian learning rule in
Eq. (5) and weights are updated following Eq. (4). To highlight the
behavior of the linear model, the same comparison using a log scale is
shown in the box. Parameters value: tf = 1.5 ∗ 104, nm = na = 3, η =
0.01, σ = 0.1, C = 20.

020004000600080001000012000140000.00.51.01.52.0Linear ModelNonlinear
Model010000104100Time (in number of time steps)Evolution of the
distanceDeﬁne the auditory activity as in Eq. (1) means that the matrix
Q needs to be invertible to reach convergence. We also don’t know how to
deﬁne the exploration space starting from the map Q. We assumed as given
the space of the inverse of Q, which means that we solved at each time
step t the linear system Q−1At = Mt, where Q−1 = M ∗. At the same time
to solve a linear system means to face the problem of invertibility of
matrix M ∗. Indeed, if the matrix M ∗ is singular or close to be
singular, then the numerical algorithm is not longer working. To avoid
an ill-posed problem we added a condition by computing the condition
number1 of the matrix M ∗, forcing it to be such that

k(M ∗) < C,

(12) 

where M ∗ represents the motor target and C is a positive constant
belonging to [1, +∞]. In this way we simulated all the simulations in
Fig. 2 without having ill-posed problems. Without the application of
this condition, simulations were of- ten diverging because of the
divergence of M ∗−1 . A nonlinear auditory response deﬁned by Eq. (2)
enables to avoid ill-posed problems. At the same time (as underlined in
the small box with logarithmic scale in Fig. 2) it leads to a divergence
in the distance between the target motor pattern M ∗ and W A∗. That is,
the model does not learn anymore after the introduction of nonlinearity.
So far, instead of keeping the postdictive Hebbian rule proposed by
Ganguli and Hahnloser in [11], we used a traditional Hebbian rule to
drive learning and tried to face the problem by applying other types of
normalization.

B. A nonlinear auditory response

Fig. 3 shows the evolution of the distance between W A∗ and the target
motor pattern M ∗ for one example neuron. The initially weak synaptic
connections evolves following the Hebbian learning rule given by Eq. (3)
and ﬁnally approaches M ∗. To obtain these results we applied the
normalization deﬁned by Eq. (8). By introducing nonlinearity, as shown
by Fig. 2, the Ganguli-Hahnloser model does not converge anymore.

We tested three different normalizations, given by Eq. (6), Eq. (7) and
Eq. (8). The upper panel of Fig. 4 shows the comparison between the
three normalizations with respect to auditory neurons. That is, with
respect to the columns of W . Normalizations given by Eq. (6) and Eq.
(7) are applied di- rectly to the weights matrix, which gives a faster
convergence but a lost in smoothness. Normalization given by Eq. (8) is
applied to the variation of the weights, by multiplying its classical
deﬁnition by a decreasing factor. This means that the variation is
smaller and smaller as the weights approaches the target, which results
in a smooth trend of the distance curve. To highlight better the
difference between normalization

1Given a general linear system Ax = b, its condition number is deﬁned as
k(A) = ξmax(A)/ξmin(A), where ξmax(A and ξmin(A) are respectively the
maximal and minimal singular values of A. The value k(A) represents the
variability of the solution, so how much the solution x changes
consequently to a change in b. The lower bound for the condition number
is k(A) = 1, whereas it can reaches the value k(A) = ∞ if the matrix A
is singular.

Fig. 3. Evolution of synaptic weights in time relative to a single
auditory neuron and distance from the target motor pattern (three
neurons example). Evolution in time of the synaptic weights W
(continuous blue line) and the target motor pattern M ∗ (dashed blue
line) for one example neuron. Each auditory neuron is composed by three
components represented by the three lines. Here the auditory activity is
deﬁned by Eq. (2) and learning is driven by the Hebbian learning rule in
Eq. (3). At each time steps weights are updated following Eq. (4) and
the normalization deﬁned by Eq. (8) has been applied. Parameters value:
tf = 1 ∗ 105, nm = 3, na = 1, η = 0.01, σ = 0.1.

over auditory and motor neurons, the bottom panel of Fig. 4 shows the
comparison between the normalization given by Eq. (8) applied in its
mean and norm version. As it is shown, a normalization over auditory
neurons works better than the same normalization over motor neurons in
the sense that the distance between W A∗ and M ∗ is lower if the
normalization is applied over the auditory neurons than if the
normalization is applied over the motor neurons.

C. Auditory selectivity effect

Auditory selectivity impact on the learning can be observed by varying
its value and by observing both the convergence time τ both the distance
at t = τ between W A∗ and M ∗. Fig. 5 shows how the mean convergence
time τ and the mean distance dt at t = τ depends on the auditory
selectivity. As the tuning selectivity width σ increases, a decreasing
in the mean convergence time and an increasing in the mean distance can
be observed. In particular, for the value σ = 0.02 convergence time is
not fully correct because many simulation reached a ﬁxed time tf = 2 ∗
107 before having reached convergence. This is displayed on the plot by
the ﬁrst dashed part of the red line.

D. Varying network dimensions

The quality of learning in terms of the distance at the convergence time
t = τ and how slow learning develops can be investigated by varying the
network dimension. Firstly, the number of auditory neurons has been kept
ﬁxed at the value na = 3, and the number of motor neurons varied as nm =
[2, 3, 4, 5, 6, 7]. Then, viceversa, the number of motor neurons has
been kept ﬁxed at nm = 3 and the number of the auditory neurons varied
using the same values as before. Fig. 6 shows the effect of changes in
the network dimension respectively on the mean convergence time τ and on
the mean distance at t = τ , computed over 50 simulations. The upper
panel shows how, keeping ﬁxed the motor dimension,

0500001000000.00.20.40.60.81.01.2Time (in number of time steps)Evolution
of the distanceFig. 5. Effect of the auditory selectivity on
convergence time and distance. Auditory selectivity impact on the
convergence time (in red) and on the distance between W A∗ at the
convergence time τ and the target motor pattern M ∗ (in blue), computed
over 50 simulations. The ﬁrst dashed part of the red line underlines the
fact that for σ = 0.02 not all the simulations converges before having
reach a ﬁxed simulation exit time tf = 2 ∗ 107. Here the auditory
activity is deﬁned by Eq. (2) and learning is driven by the Hebbian
learning rule in Eq. (3). At each time steps weights are updated
following Eq. (4). Parameters value: σ = [0.02, 0.05, 0.1, 0.2, 0.3,
0.5, 0.7], nm = na = 3, η = 0.01, (cid:15)∗ = 10−9. We applied the
decreasing factor normalization given by Eq. (8). To exit the
simulations we compute (cid:15) as in Eq. (11). We used for almost every
value an interval with N = 400. However, since the distance evolves very
slowly, for small values of σ this interval is not large enough. For
instance, an interval with N = 500000 has been used for σ = 0.02.

Fig. 6. Effect of network dimension on the convergence time and the
distance. (Left) Network dimensions effect on the mean convergence time
τ and (Right) on the mean distance between W A∗ at time t = τ and the
target motor pattern M ∗, computed over 50 simulations. The dark red
line refers to a network where the number of auditory neurons has been
kept ﬁxed at na = 3, whereas the light red line refers to a network
where the number of motor neurons has been kept ﬁxed at nm = 3. In both
cases, the second dimension has been varied as [2, 3, 4, 5, 6, 7].
Parameters value: η = 0.01, σ = 0.1. Here we applied the decreasing
factor normalization given by Eq. (8). To exit the simulations we
compute (cid:15) as in Eq. (11) with N = 400.

and motor dimensions have to be equal. Moreover, numer- ical
implementation of the learning algorithm proposed by Hahnloser and
Ganguli requires to invert the auditory response matrix (Q) to determine
the range of motor output required for proper exploration and learning.
As there is no general method to invert a random matrix Q, a numerical
implementation of the model requires to set a speciﬁc Q that can be
inverted. Finally, the postdictive learning rule only works for the
linear model and it is not clear whether biologically realistic learning
rules can still lead to convergence or near-convergence in the case of
non-linear auditory feedback.

As Hebbian or associative learning rules are imple-

Fig. 4. Comparison between different types of normalization: evolution
in time of the distance. Evolution in time of the smooth average
distance be- tween W A∗ and the target motor pattern M ∗, computed over
50 simulations. (Top) Comparison between the model normalized by the
maximum weights normalization in Eq. (6) and the corresponding norm
version (respectively the continuous blue line and the dashed blue
line), the model normalized by the supremum weights normalization in Eq.
(7) and the corresponding norm version (respectively the continuous
green line and the dashed green line), the model normalized by the
decreasing factor normalization in Eq. (8) and the corresponding norm
version (respectively the continuous red line and the dashed red line).
All the normalizations have been taken with respect to auditory neurons.
(Bottom) Comparison between the model normalized by the decreasing
factor normalization in Eq. (8) with respect to auditory neurons (red
lines) and with respect to motor neurons (dark red lines). Comparison
between the normalization applied using the mean of W (continuous lines)
and the norm of W (dashed lines). Here the auditory activity is deﬁned
by Eq. (2) and learning is driven by the Hebbian learning rule in Eq.
(3). At each time steps weights are updated following Eq. (4).
Parameters value: tf = 1 ∗ 105, nm = na = 3, η = 0.01, σ = 0.1.

there is not an evidence of network dimension effect on the mean
convergence time. Viceversa, keeping ﬁxed the auditory dimension the
learning slows down as the motor dimension increases. However, the mean
distance at t = τ is not affected by any change in the neural network
dimensions, as shown in the bottom panel of Fig. 6. More details are
available at https://github.com/spagliarini/2018-ICDL-EPIROB.

IV. DISCUSSION

Hahnloser and Ganguli [11] proposed a simple mathemati- cal framework to
approach the sensorimotor learning problem in songbirds. It is based on
a linear auditory activity and a postdictive Hebbian learning rule.
Linearity in the auditory activity makes the theoretical is not
biologically realistic. To be invertible, the matrix Q for auditory
response must be squared, which means that auditory

investigation possible but

0.020.050.10.20.30.50.7104105106107102101Convergence time (in number of
time steps)Final distance from the targetTuning sparameterConvergence
time (time steps)Distane from the target234567102101Motor dim=3,
Auditory dim=2:7Auditory dim=3, Motor
dim=2:72345671.1×1041.1×1051.01×106Motor dim=3, Auditory dim=2:7Auditory
dim=3, Motor dim=2:7Distane from the targetConvergence time (time
steps)Number of neuronsNumber of neurons mented through
activity-dependent synapse-speciﬁc increases in synaptic weights
(synaptic potentiation), that must be aug- mented by global processes
that regulate overall levels of neuronal and network activity to prevent
explosion of synaptic weights [14]. Regulatory processes are often as
important as the more intensively studied Hebbian processes in
determining the consequences of synaptic plasticity for network
function. Setting an upper bound on the total synaptic weights to or
from a given neuron may also reﬂect the biological limitation of
synaptic connections: limits are imposed on their growth due to the
limited quantity of available material (receptors, neurotransmitters,
…). The introduction of normalization on the weights or on their
variations is a simple solution to this problem. Several forms of
normalization were considered here to take into account this biological
limitation. While the linear model of Hahnloser and Ganguli [11]
converges for the postdictive learning rule described there, we show
that near- convergence can be achieved with multiple normalization rules
added to a simple and typical associative learning rule given by Eq.
(3). Convergence time, ﬁnal distance from motor output to target, and
smoothness of the distance evolution through time all depend on the
speciﬁc normalization used. However, it is important to notice that the
ﬁnal ”error” (distance from motor ﬁnal weights to target motor pattern)
does not vary much with normalization, assuming it is applied on all
synaptic outputs from a given presynaptic (auditory) neuron.

In most of the simulations we focused on normalization given by the
decreasing factor normalization in Eq. (8). We kept this normalization
for all our analyses because it gives better performance (i.e. low
”error”). We noticed that when this normalization is applied, it gives
better performances over auditory neurons (presynaptic) than over motor
neurons (post- synaptic), despite the fact that a normalization with
respect to motor neurons (regulated at the level of the post-synaptic
neuron) may be more biologically plausible. Although other forms of
plasticity exist, including presynaptic modulation of synaptic strength,
classic long-term potentiation/depression (LTP/LTD) mechanisms mostly
involve postsynaptic receptor reorganization.

A remaining open question is related to the ﬁnal value (after
convergence) of the distance between the target motor pattern and what
the model actually learned. Future work is needed to determine the
factors that determine this ﬁnal error and how it can be reduced. One
possibility is that various motor targets (one for each auditory neuron)
may interfere during learning, leading to imperfect copies. However, our
preliminary experiments didn’t show that interference had an inﬂuence on
the ﬁnal error.

We investigated how learning depends on the auditory selec- tivity
observing that as the tuning selectivity width σ increases as the ﬁnal
distance between weight matrix and motor target (error) increases while
convergence time decreases. There is therefore a trade-off between
learning speed and accuracy that can be balanced through the selectivity
of auditory neurons. One way to make learning both fast and accurate
could be to start the learning process with a large tuning width (low

selectivity) and to decrease it progressively as learning goes on.
Interestingly, in many songbird species (including the well-studied
zebra ﬁnches), sensory learning overlaps with sensorimotor learning, and
the auditory selectivity therefore develops during the early
sensorimotor phase.

Finally, taking into account the inﬂuence of the dimensions (i.e. number
of units) of the sensory and motor layers we noticed that motor
dimension has a strong inﬂuence on con- vergence time. This strong
inﬂuence comes from the fact that for lower values of σ the distance
between the target and W A∗ tents to decrease much more slowly. In our
network we are considering a motor output that does not distinguishes
muscle control and sound production. It is not clear which of these two
components is responsible for the high increase in convergence time. A
model displaying a motor output and a sound gener- ating system is
needed to resolve this question. Future work could include (1) the
addition of an artiﬁcial syrinx model as motor output and more auditive
like feature selectivity in the auditory layer, and (2) the inﬂuence of
different exploration methods such as goal-directed exploration.

ACKNOWLEDGMENT

We would like to thank Camille Soetaert and Jean-Baptiste Zacchello for
preliminary work done. We also thank Inria for the CORDI-S PhD
fellowship grant.

REFERENCES

[1] E. Oztop, M. Kawato, and M. Arbib. Mirror neurons and imitation: A
computationally guided review. Neural Networks, 19(3):254–271, 2006. [2]
J. F. Prather, S. Peters, S. Nowicki, and R. Mooney. Precise auditory–
vocal mirroring in neurons for learned vocal communication. Nature,
451(7176):305, 2008.

[3] N. Giret, J. Kornfeld, S. Ganguli, and R. HR Hahnloser. Evidence for
a causal inverse model in an avian cortico-basal ganglia circuit. PNAS,
111(16):6063–6068, 2014.

[4] M. I. Jordan and D. E. Rumelhart. Forward models: Supervised
learning

with a distal teacher. Cognitive science, 16(3):307–354, 1992.

[5] A. K. Philippsen, R. F. Reinhart, and B. Wrede. Learning how to
speak: Imitation-based reﬁnement of syllable production in an
articulatory- acoustic model. In ICDL-Epirob, 2014, pages 195–200. IEEE,
2014. [6] E. Oztop, M. Kawato, and M. A. Arbib. Mirror neurons:
functions, mechanisms and models. Neuroscience letters, 540:43–55, 2013.

[7] M. A. Arbib.

fo the mirror system, imitation, and the evolution of

language. Imitation in animals and artifacts, 229, 2002.

[8] A. J. Doupe and P. K. Kuhl. Birdsong and human speech: common themes
and mechanisms. Annual review of neuroscience, 22(1):567– 631, 1999.

[9] A. J. Doupe, D. J. Perkel, A. Reiner, and E. A. Stern. Birdbrains
could teach basal ganglia research a new song. Trends in neurosciences,
28(7):353–363, 2005.

[10] R. Mooney. Neural mechanisms for learned birdsong. Learning &

Memory, 16(11):655–669, 2009.

[11] R. Hahnloser and S. Ganguli. Vocal learning with inverse models.

Principles of Neural Coding, pages 547–564, 2013.

[12] A. Hanuschkin, S. Ganguli, and R. Hahnloser. A hebbian learning
rule gives rise to mirror neurons and links them to control theoretic
inverse models. Frontiers in neural circuits, 7:106, 2013.

[13] R. HR Hahnloser and A. Kotowicz. Auditory representations and mem-
ory in birdsong learning. Current opinion in neurobiology, 20(3):332–
339, 2010.

[14] L. F. Abbott and S. B. Nelson. Synaptic plasticity: taming the
beast.

Nature neuroscience, 3(11s):1178, 2000.


