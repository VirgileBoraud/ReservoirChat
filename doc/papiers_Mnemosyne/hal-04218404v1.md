Comparative study of synﬁre chain and ring
attractor model for timing in the premotor
nucleus in male Zebra Finches

Fjola Hyseni

1,2

and Nicolas P. Rougier

2,3,∗ and Arthur Leblois

1, ∗

1- CNRS, IMN, UMR 5293, F-33000, Bordeaux, France

2- LaBRI, Universite de Bordeaux, Talence, France

3- Inria Bordeaux Sud-Ouest, Talence, France

Abstract. Timing is crucial for the generation of a wide range of sen-
sorimotor tasks. However, the underlying mechanisms remain unclear. In
the order of milliseconds, premotor nucleus HV C (proper name) in male
zebra ﬁnches is an outstanding model in studying the sequential neuronal
activity encoding action timing. Current computational models of HV C
rely on the synﬁre chains, which are not robust to noise and function for a
narrow range of weights. An alternative with robust functional properties
[11][5] are attractors. Here, we compare the two models and show that not
only the ring attractor is more robust, but can also reproduce the brief
activity bursts of HV C neurons.

1

Introduction

Timing is crucial for a wide range of sensorimotor tasks, including speech and
birdsong production, which require precise temporal control at the scale of tens
to hundreds of milliseconds for the essential tight coordination of vocal mus-
cles. In songbirds, temporal precision is managed by a localized timing area, the
premotor nucleus HV C (proper name), which projects to a downstream mo-
tor nucleus, RA (robust nucleus of the acropallidum) responsible of controlling
syringeal and respiratory muscles. The projection neurons HV CRA, ﬁre in a
time-locked manner during singing, producing a single
10 ms long burst of
3-6 spikes [4]. To simulate neuronal dynamics giving rise to motor timing at
this scale, several computational models have been proposed i.e. ramping mod-
els, internal clocks, population clocks, labeled-line models and multiple-oscillator
models [3, 2]. Among these, population clocks and in particular synﬁre chains
are most commonly used to model the particular dynamics of the aforementioned
nucleus HV C.

≈

A synﬁre chain [8] is a feedforward network of excitatory neurons organized
in sequentially connected layers (or pools), with neurons in the same layer ﬁr-
ing in an almost synchronous manner [8, 6]. However, the purely feedforwad
connection pattern of synﬁre chains does not appear compatible with the con-
nectivity patterns revealed experimentally in cortical networks, which typically
entail high levels of reciprocal connectivity [10]. Additionally, synﬁre chain net-
works are sensitive to noise and not very robust to weight variability, requiring

∗These authors contributed equally.

647ESANN 2023 proceedings, European Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning. Bruges (Belgium) and online event, 4-6 October 2023, i6doc.com publ., ISBN 978-2-87587-088-9. Available from http://www.i6doc.com/en/.precisely tuned synaptic strengths to avoid runaway excitation (saturation) or
decay.

We propose attractor models as an alternative since their dynamics provide
both robustness to noise and high accuracy. Linear attractors, also referred to
as ring attractors [11][5], in the case of asymmetric connections, can drive a
drifting activity bump, with robust and resilient properties thanks to recurrent
connections [5]. However, it remains unclear whether attractors with structured
connectivity can accurately represent HV C dynamics underlying song timing as
HV C song-related activity is very sparse and the underlying activity bump is
very narrow; the timescale of neuronal dynamics may impose a limit on bump
width in this model. We propose that this narrow bump of activity could be
the result of sparse, strong excitatory connections, organised as a function of
the neurons’ preferred timing. In the present work, we compare synﬁre chains
and the ring attractor model, their output and robustness and propose a Ring
Attractor model with a narrow Gaussian pattern of connectivity to model HV C
neuronal dynamics.

2 Methods

2.1 Synﬁre Chain

To investigate synﬁre chains and assess their properties, we implement a synﬁre
chain model with adaptive exponential integrate and ﬁre (AdEx) neurons (eq.
(1)). We build a network of 3000 neurons, consisting of 120 layers and 25 neu-
rons per layer. Every neuron on one layer has an excitatory synaptic connection
(weight) to each neuron of the next layer (all to all connectivity). All synaptic
weights are identical and the value is such as to ensure proper activity proga-
gation. The parameter values are the same as the ones reported in [9] and the
adaptation parameters were adjusted to generate bursts of 4 spikes. The AdEx
model is described as below:

C

dVi
dt

τw

dw
dt

gL(Vi

=

−

−

EL) + gL∆T e

( V −VT
∆T

)

−

= a(V

EL)

−

−

w + bτwδ(t

tf ), ,

−

w + Isyn + Iext,i(t) + √τnσηi(t), ,

(1)

(2)

where C is the membrane capacitance and V is the membrane potential. On the
right hand side (rhs) of Eq. (1), gL is the leak conductance, EL the leak reversal
potential, VT the threshold, ∆T the slope factor, Iext the external input, Isyn
the synaptic input and w the adaptation variable. The last rhs term is a zero-
mean Gaussian white noise. In Eq. (2), τw equals 100 ms, a is -0.5 nS and b 0.5
nA. When the membrane potential crosses the threshold potential (V > VT ),
the above parameters are updated: V
w + b, where Vr is the reset
−→
potential and the update parameter b (0.01 nA) is the spike triggered adaptation.

Vr, w

−→

648ESANN 2023 proceedings, European Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning. Bruges (Belgium) and online event, 4-6 October 2023, i6doc.com publ., ISBN 978-2-87587-088-9. Available from http://www.i6doc.com/en/.Synaptic input is a function of synaptic weights and post-synaptic potential:

Isyn = X
j

Wij X
k

Θ(t

−

−(t−tk
j )
τs

,

tk
j ) e

(3)

where Θ(t

−

j ) is a step function and tk
tk

j denotes the kth spike of the jth neuron.

2.2 Ring Attractor with a Spiking Neural Network

We consider a discrete population of N = 3000 adaptive exponential integrate-
and-ﬁre neurons that are able to display a burst activity as it has been observed
in HV C. The dynamics of each AdEx neuron i
in the network
are given by Eq. (1). The equations governing adaptation and synaptic input
are as in the synﬁre chain model, respectively described in Eq. (2) and Eq. (3).
The weight matrix W is chosen of the following form:

1, 2, ..., N

∈ {

}

Wij = W0 + W2

1
σ√2π

e−( i−j+β

2σ )2

.

(4)

As HV C microcircuitry does not display spatio-temporal organization, W is
deﬁned based on the neurons’ preferred timing and not their spatial position. W0
represents global inhibition, W2 the excitation factor and σ the standard devia-
tion of excitation. The β (bias) term makes the connectivity pattern asymmetric.

2.3 Simulations

In both models, the simulation time and network size are identical, 350 ms and
3000 neurons respectively. We also adjust the parameters and layer size to get
a similar propagation speed in both. All simulations were performed with Euler
integration and a timestep (dt) of 0.01 ms for the synﬁre chain and 0.1 ms for the
ring. In the synﬁre chain we inject a current only to the ﬁrst layer (12 nA for 1
ms) and in the ring attractor only to one neuron (1.9 nA for 15 ms). Additionally,
a constant input is needed in the ring to preserve the bump activity (0.7 nA).
Parameter values for the simulations are detailed in the code in Github.

2.4 Robustness protocols

We design two test protocols, compatible with both models, to evaluate the
robustness of the network under possible perturbations. One test corresponds
to noise injection in the synaptic weights while the second corresponds to an
inhibitory input injected on random neurons in the population. In the ﬁrst test,
random synaptic weights, with a total of at least 10 percent are aﬀected. The
amount of noise is set to be a function of the weights (30 percent). In the second
test, we start by aﬀecting only 5 percent of the population with an inhibitory
input of an amplitude equal to 10 percent of the excitatory starting input.

649ESANN 2023 proceedings, European Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning. Bruges (Belgium) and online event, 4-6 October 2023, i6doc.com publ., ISBN 978-2-87587-088-9. Available from http://www.i6doc.com/en/. A. 10% of the synaptic weights have been scaled down 

 C. 100% of the synaptic weights have been scaled down 

Synfire Chain 

Ring Model 

 by 30%

 by 30%

400

200

0

2000

0

0.00

0.02

0.04

0.06

0.08

0.10

0.00

0.05

0.10

0.15

0.20

0.25

0.30

0.35

 B. 5% of neurons input has been scaled down 

D. 50% of neurons' input has been scaled down 

 by 10%

 by 10%

400

200

0

2000

0

x
e
d
n

i

n
o
r
u
e
N

x
e
d
n

i

n
o
r
u
e
N

0.00

0.02

0.04

0.06

0.08

0.10

0.00

0.05

0.10

0.15

0.20

0.25

0.30

0.35

Time in seconds

Fig. 1: Synﬁre Chain and Ring Attractor models. Representation of
spiking dynamics of both models and their robustness.(A) Behavior of the synﬁre
chain facing a decrease in synaptic weights. There is a stop in propagation.
(B) Behavior of the synﬁre chain facing external inhibition. There is a stop
in propagation when 5 percent of the population is aﬀected.
(C,D) same as
(A,B) but for the Ring Attractor. Neurons inhibited in both models are not
functionally clustered; they are randomly chosen in the network. Note: In panels
A and B, we show a zoomed in version to illustrate where propagation stops.

3 Results

In the ring attractor model, recurrent connections allow for the formation of an
activity bump that remains stable across a wide range of weights [5]. To ensure
propagation across stable states and consequently generate sequential activity,
several approaches have been identiﬁed [5], including using a moving stimulus
as an external drive, an asymmetric connectivity proﬁle and adaptation. The
ﬁrst two have, respectively, a linear and quasi-linear relationship with the speed
of the bump. Adaptation can ensure bump propagation through delayed, local
inhibition [5].

3.1 Robustness

With the ﬁrst robustness check protocol, we show in Fig. 1 (A) that in the synﬁre
chain with a 10 percent involvement of the population, propagation stops. In
contrast, in the ring 1 (C), we can go up to 100 percent and there is only a slight
delay in initiation of the activity, but no eﬀect in the propagation. Results are
similar in the second protocol, which is taken as a proxy for local inhibition,
as neurons are chosen randomly based on their preferred timing, but could be
considered as spatially correlated. Here, the synﬁre chain shows a cease in
propagation 1 (B) at a 5 percent involvement, in contrast to up to 50 percent
with the ring model 1 (D).

650ESANN 2023 proceedings, European Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning. Bruges (Belgium) and online event, 4-6 October 2023, i6doc.com publ., ISBN 978-2-87587-088-9. Available from http://www.i6doc.com/en/. 
 
x
e
d
n

I

n
o
r
u
e
N

700

600

500

400

1000

800

600

60

70

80

90

100

110

60

70

80

90

100

110

Time (ms)

Time (ms)

Fig. 2: Spiking dynamics in the Synﬁre Chain (left) and Ring Model
(right). In the four panels a speciﬁc time in the sequence is chosen (60 -110
ms) and the activity (voltage traces, above) and raster plots (below) for each
model are shown. A typical burst generated by the synﬁre chain lasts 4 ms and
contains 4 spikes, whereas the one generated by the ring model 6- 10ms, with
3- 6 spikes. The diﬀerent colors represent diﬀerent neurons and in both models,
every 50 neurons, a neurons voltage trace is plotted (i.e, neuron 50, 100 etc.).

3.2 Reproducing HV C spiking dynamics

We show that the two models are able to reproduce HV C dynamics as shown
in Fig. 2. The ring model shows a continuous propagating activity across the
population, whereas the synﬁre chain is more discrete due to its layered structure.
We also show the burst patterns, duration and number of spikes per burst, which
in the ring seem closer to experimental observations ([4], Fig.2).

4 Discussion

HV C neuronal recordings reveal bursts of 3-6 spikes lasting 6-10 ms, time-locked
to the song. In this study, we implement two models, aiming to capture the se-
quential neuronal activity of HV C, while preserving these individual neuronal
properties. We use a spiking model and as previous evidence [7] has shown
that HV C bursts are mediated by calcium spikes, we add adaptation[1], which
can account for ionic channel activity, depolarizing currents (parameter a in
Eq.2) and calcium dependent potassium channels (parameter b). Our ﬁndings
provide clear evidence with two robustness protocols that the ring attractor
model is more robust in modelling HV C dynamics, compared to a synﬁre chain.
Thereby, in the synﬁre chain, it emphasizes the ﬁne tuning necessary for the
weights, which does not support possible weight modiﬁcations possibly occuring
due to developmental, seasonal, experiential factors. It also shows high sensi-
tivity to a local inhibition with small size and low magnitude. Since HVC is
not topologically organized, the neurons aﬀected by this inhibition would not be

651ESANN 2023 proceedings, European Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning. Bruges (Belgium) and online event, 4-6 October 2023, i6doc.com publ., ISBN 978-2-87587-088-9. Available from http://www.i6doc.com/en/. 
functionally correlated and a preservation of timing is expected, especially with
a small size and low magnitude. However, in both cases the ring model is robust
and only displays a delay in activity initiation, even at higher perturbation size
and magnitude. Furthermore, we compared the spiking dynamics produced from
the synﬁre chain model and the ring attractor with an asymmetric connectivity
proﬁle. With both models, we generate sequential activity and spiking dynamics
similar to the ones shown in HVC recordings [4]. A possible limitation of our
model could be adaptive learning, which entails learning to modify the duration
of a syllable, without aﬀecting the other syllables. This has been shown to be
the case in songbirds and it has also [9] been shown that only the synﬁre chain,
and not attractors, can accomplish adaptive learning. However, as a structured
attractor, the ring model could perform diﬀerently, which remains yet to be
explored.

References

[1] R. Brette and W. Gerstner. Adaptive exponential integrate-and-ﬁre model as an eﬀective

description of neuronal activity. J. Neurophysiol., 94(5):3637–3642, 2005.

[2] D.V. Buonomano and R. Laje. Population clocks: motor timing with neural dynamics.

Trends in Cognitive Sciences, 14(12):520–527, 2010.

[3] A. Goel and D.V. Buonomano. Timing as an intrinsic property of neural networks:
evidence from in vivo and in vitro experiments. Philosophical Transactions of the Royal
Society B: Biological Sciences, 369(1637):20120460, 2014.

[4] R. Hahnloser, A. Kozhevnikov, and M. Fee. An ultra-sparse code underlies the generation

of neural sequences in a songbird. Nature, 419:65–70, 2002.

[5] David Hansel and Haim Sompolinsky. Modeling feature selectivity in local cortical circuits.

Book Chapter, 1998.

[6] D.Z Jin, F.M. Ramazanoglu, and H.S. Seung. Intrinsic bursting enhances the robustness
of a neural network model of sequence generation by avian brain area hvc. J Comput
Neurosci, 23(3):283–299, 2007.

[7] M. A. Long, D. Z. Jin, and M. S. Fee. Support for a synaptic chain model of neuronal

sequence generation. Nature., 468(7322):394–399, 2010.

[8] Abeles M. Local Cortical Circuits: An Electrophysiological study., Springer Berlin, 1982.

[9] C. Pehlevan, F. Ali, and B. Olveczky. Flexibility in motor timing constrains the topology

and dynamics of pattern generator circuits. Nat Commun, 9,977, 2018.

[10] R. Perin, T. K. Berger, and H. Markram. A synaptic organizing principle for cortical

neuronal groups. PNAS, 108(13):5419–5424, 2011.

[11] K. Zhang. Representation of spatial orientation by the intrinsic dynamics of the head-
direction cell ensemble: A theory. Journal of Neuroscience, 16(6):2112–2126, 1996.

652ESANN 2023 proceedings, European Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning. Bruges (Belgium) and online event, 4-6 October 2023, i6doc.com publ., ISBN 978-2-87587-088-9. Available from http://www.i6doc.com/en/.