Models of Hippocampus for pavlovian learning
Roman Gorojosky, Frédéric Alexandre

To cite this version:

Roman Gorojosky, Frédéric Alexandre. Models of Hippocampus for pavlovian learning.
Report] RR-8377, INRIA. 2013, pp.77. ￿hal-00870700￿

[Research

HAL Id: hal-00870700

https://inria.hal.science/hal-00870700

Submitted on 7 Oct 2013

HAL is a multi-disciplinary open access
archive for the deposit and dissemination of sci-
entific research documents, whether they are pub-
lished or not. The documents may come from
teaching and research institutions in France or
abroad, or from public or private research centers.

L’archive ouverte pluridisciplinaire HAL, est
destinée au dépôt et à la diffusion de documents
scientifiques de niveau recherche, publiés ou non,
émanant des établissements d’enseignement et de
recherche français ou étrangers, des laboratoires
publics ou privés.

Models of Hippocampus
for pavlovian learning

Román Gorojovsky, Frederic Alexandre

G
N
E
+
R
F
-
-
7
7
3
8
-
-

/

R
R
A
R
N

I

I

RESEARCH
REPORT
N° 8377
Octobre 2013

Project-Teams MNEMOSYNE

N
R
S

I

9
9
3
6
-
9
4
2
0
N
S
S

I

Models of Hippocampus for pavlovian learning

RomÆn Gorojovsky∗, Frederic Alexandre†

Project-Teams MNEMOSYNE

Research Report n(cid:176) 8377 (cid:22) Octobre 2013 (cid:22) 77 pages

Abstract:
Amygdala and hippocampus are key structures in pavlovian conditioning. From
existing models of these cerebral structures, we test them on corpus, to assess their capacities and
also their performances in critical situation. From these results, we propose adaptations to these
models together with an early study on forgetting.

Key-words:

hippocampus, pavlovian learning, amygdala, learning, cortex

∗ Facultad de Ciencias Exactas y Naturales, Universidad de Buenos Aires.
† INRIA Bordeaux (cid:21) frederic.alexandre@inria.fr

RESEARCH CENTRE
BORDEAUX – SUD-OUEST

200 avenue de la Vieille Tour
33405 Talence Cedex

ModŁles de l’hippocampe pour le conditionnement
pavlovien

RØsumØ :
L’amygdale et l’hippocampe sont des structures clØ en conditionnement pavlovien.
A partir de modŁles existants de ces structures, nous les testons sur des corpus, a(cid:28)n d’Øvaluer
leurs capacits et leurs performances dans des situations critiques. A partir de ces rØsultats, nous
proposons des adaptations de ces modŁles, ainsi qu’une Øtude prØliminaire sur l’oubli.

Mots-clØs :

hippocampe, aprentissage pavlovien, amygdale, apprentissage, cortex

Models of Hippocampus for pavlovian learning

3

1

Introduction

This text documents the ideas developed during an internship for the team1, their implemen-
tations, tests and results. The (cid:28)rst section describes the model as it existed when this work
started, and the basic names and ideas used all along the document2. The following sections
present the di(cid:27)erent ideas we worked on, the scenarios used to test them, present the results and
discuss them.

The research documented here is divided on three main areas: Normal working mode of
the model, Forgetting on the Hippocampus and the Splitted Amygdala. We de(cid:28)ne and
explain these ideas on the sections 3 to 5. The next section describes the scenarios used to test
each of these three features, and the results of those tests, if any, appear on the following section.
A discussion of those results (or lack thereof) is on the following section.

Finally we discuss what remains open for further work and document some ideas and intuitions
on the di(cid:27)erent problems that are (cid:16)on the air(cid:17) in di(cid:27)erent lines of investigation of the group and
how this work and its components relate to them.

After that, on a series of appendices, we mention a few lateral developments from these days
that aren’t particularly relevant to any of the main ideas and document the tools, scripts and
con(cid:28)guration (cid:28)les used during these months. All the code can be found on the forge, on the
group’s repository.

A note on nomenclature: To di(cid:27)erentiate between the biological subsections of the brain
and the modules on our computational model, we’ll be using the following convention: italicized
words refer to the biological ones, while monospaced words refer to the module/s.

1Between april and october 2013, under the INRIA program of international internships
2Including this introduction, bit of a circular problem here

(cid:176)
RR n

8377

4

RomÆn Gorojovsky, Frederic Alexandre

Contents

1 Introduction

2 Starting model

2.1 Objective and general ideas . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

2.2 The model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

2.2.1

Hippocampus . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

2.3 The brains . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

2.4 Base scenario, tests and results . . . . . . . . . . . . . . . . . . . . . . . . . . . .

2.4.1 The Simple XOR scenario . . . . . . . . . . . . . . . . . . . . . . . . . . .

2.4.2 Results

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

3 Normal working mode

3.1

Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

3.1.1 Capacity . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

3.1.2

Scaling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

3.1.3 Learning by heart

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

3.2 Testing of capacity and scaling . . . . . . . . . . . . . . . . . . . . . . . . . . . .

3.2.1 Results

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

3.2.2 Discussion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

3.3 Testing for Learning by heart . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

3.3.1 Results

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

3.3.2 Discussion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

4 Forgetting on the Hippocampus

4.1 Detailed model of CA3 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

4.2 Mechanics of forgetting . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

4.2.1 Global (systematic) forgetting . . . . . . . . . . . . . . . . . . . . . . . . .

4.2.2 Dynamic forgetting . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

4.3 Modi(cid:28)cations to the recall mode

. . . . . . . . . . . . . . . . . . . . . . . . . . .

4.4 Testing and results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

4.5 Discussion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

3

7

7

7

7

8

8

8

9

12

12

12

12

12

12

13

15

16

18

34

39

39

40

40

41

42

42

49

Inria

Models of Hippocampus for pavlovian learning

5 Splitted Amygdala

5.1

Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

5.2 Architecture . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

5.2.1 Deciders . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

5.3

Implementation details . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

5.3.1 Fine tuning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

5.4 Testing scenarios . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

5.5 Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

5.5.1

Simple XOR . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

5.5.2 Double map XOR . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

5.6 Discussion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

5.6.1

Simple XOR . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

5.6.2 Double Map XOR . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

5.6.3 Problems with the Amygdala . . . . . . . . . . . . . . . . . . . . . . . . .

6 Further work

6.1 Dynamic forgetting . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

6.2 Consolidation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

6.3 Decider

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

6.4 Binary vs. Real Computation . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

6.5 Continuous use . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

6.6 CA1, the weak link . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

6.7 Probes and better test tools . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

A Other implementations

A.1 Corpus . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

A.2 Random Recall

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

B main\_bis

C Con(cid:28)guration (cid:28)les for the Scenarios

D Scripts

D.1 Requirements . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

D.2 plot\_amygdala.sh . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

D.3 Plotting scripts . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

(cid:176)
RR n

8377

5

50

50

50

50

51

52

52

54

54

56

65

65

65

65

68

68

68

68

69

69

70

70

71

71

71

72

73

74

74

74

74

6

E Unit tests

RomÆn Gorojovsky, Frederic Alexandre

76

Inria

Models of Hippocampus for pavlovian learning

7

2 Starting model

2.1 Objective and general ideas

The objective of our modeled brain is to associate unconditional stimuli to neutral stimuli pre-
dicting them (pavlovian conditioning). Given some non-learned stimuli or CS, which can be
external or internal it learns to predict an outcome from them. We call these outcomes US.

We have three components for the learning: the Amygdala, the Cortex and the Hippocampus.
The (cid:28)rst one is a simple neuronal network that takes an input and learns to build a prediction.
It also sends an error signal that can be used to modulate the learning and/or unlearning of the
other two components.

The Cortex one slowly learns associations of these elements to extract minimal cues describing
them, while the Hippocampus one learns by heart some associations, and is able to recall the
recorded ones with only a part of them, which is particularly useful to quickly get the US given
an input.

2.2 The model

This model is better described on [2] and [1], two publications by its developers. The focus of
this work was on the Hippocampus, so we’ll only give a brief description of the Amygdala and
the Cortex, and refer to those publications for details. For this same reason, we’ll only present
very broad intuitions of the whys behind some of our results.

The Amygdala is a simple neural network with one input level of as many neurons as bits on
the inputs, all connected to the output level, which has as many neurons as bits on the output or
prediction. The network learns by adjusting its weights to adjust the prediction to the US, once
it arrives. The Cortex has the same sensory input layer as the amygdala and several additional
layers that can be used to extract, by learning, conjunction of activities in layers below, as a
model of semantic memory.

2.2.1 Hippocampus

Modes of working We map some of the functionalities of the Hippocampus to what we call
modes of work of the Hippocampus. These modes aren’t mutually exclusive, and part of the work
is deciding when each mode is to be used. The modes implemented are Learn and Recall.

In both modes Hippocampus receives an input, which comes from the Cortex to be processed.
On learning mode, the Hippocampus will try to store it, regardless of whether it has already seen
it or not. Learning mode is usually enabled after the US has arrived, and that will be part of
the stimulus stored. This is important because in recall mode, if the input is already stored,
the component will try to complete it with its US. In the current implementation, recall mode is
always enabled.

The Hippocampus has to decide whether the stimulus is new or if it already knows it. This is
the problem of separation and completion: if two semantically di(cid:27)erent inputs are syntactically
too close, the second to arrive will be considered the same as the (cid:28)rst and it will be completed
to the (cid:28)rst one, with its US.

(cid:176)
RR n

8377

8

RomÆn Gorojovsky, Frederic Alexandre

Architecture The Hippocampus is a set of components, each of which represents and models
a di(cid:27)erent part or area of the Hippocampus. These parts are, in order of (cid:16)data (cid:29)ow(cid:17):

Entorhinal Cortex Acts as an entry point/interface with the Cortex. Right now is just
a pair of bu(cid:27)ers, one for the input from Cortex and another for the output. The input is the
Cortex activity plus the US.

Dentate Gyrus or DG transforms the input received by the Entorhinal Cortex to the

input used by the following module, CA3. This transformation should make the input sparser.
The DG’s output is wider than its input. For an input of size ni the output’s size is no = n2
,
i.e. the number of possible pairs of elements of the vector. Each cell of the output converges to
the product of two cells of the input. In some models, the original input is also appended to DG’s
output, but that’s not the case in our implementation.

i −ni
2

CA3 (Cornu Armonis 3) This is the actual data storage, the module that actually learns
and remembers data. As said before, it has it’s own (cid:16)language(cid:17), i.e. the data stored is represented
di(cid:27)erently than in the rest of the model. The details of the implementation of this module can
be seen in the section 4.1.

CA1 Is the module that receives the output from CA3, translates it back to the format the
rest of the model understands, and sends this to the Entorhinal Cortex. Unlike the translation
on DG this one is learned using an array of perceptrons.

2.3 The brains

There are three di(cid:27)erent (cid:16)brains(cid:17) implemented to test di(cid:27)erent things at various moments of the
development of the model:

(cid:136) BrainCA Only has a Cortex, which takes the sensorial input and an Amygdala for the (cid:28)nal

prediction.

(cid:136) BrainHA Only has a Hippocampus, which also takes only the CS as input and an Amygdala.

(cid:136) BrainCHA Has both Cortex and Hippocampus, which here takes all the Cortex’s activity

as input, plus the Amygdala

2.4 Base scenario, tests and results

2.4.1 The Simple XOR scenario

All of the scenarios used to test the di(cid:27)erent features of the system are modi(cid:28)cations of this
one that we used as a baseline, as something used for comparison. Is a simple non linear prob-
lem with two possible inputs, A and B that, on their own, are associated with a positive US,
and when presented together (AB) with a negative one. Although two bits on the input are
enough to represent this, for this implementation we need to use two bits for each, and add an

Inria

Models of Hippocampus for pavlovian learning

9

extra input Z, also associated with a negative US, where neither A nor B are present. So we have:

Input
A
B
AB
Z

CS
[1 0 0 1]
[0 1 1 0]
[1 0 1 0]
[0 1 0 1]

US
[1]
[1]
[0]
[0]

This scenario was presented to a Cortex with an input map of four units, a middle map of

two units and the output map, with a single unit.

Figure 1: Cortex used to run the Simple XOR scenario

The standard or (cid:16)all equal(cid:17) version of this scenario presents all four inputs on all the iterations,
always on the same order. One variation ((cid:16)proba(cid:17)) is to give to some of the inputs, typically
AB and Z, a probability to appear in any iteration. After trying a few di(cid:27)erent proportions we
settled on a probability of 0.2, i.e., these inputs will appear on 1/5th of the iterations, which was
enough to show in a practical time the results we needed. The other variation is randomizing
the order of the inputs using a (cid:16)corpus(cid:17) (see appendix A.1). Both variations can be combined
resulting in a randomized corpus where some of the inputs appear on 20% of the iterations.

The (cid:28)rst of these variations was our (cid:28)rst test for Learning by heart, with the idea that
the inputs that appear only on 1/5th of the iterations will be easier to learn by heart by the
Hippocampus than for the Cortex.

2.4.2 Results

The Graphs The simple XOR, the base or control scenario, was tested with the three brains
mentioned on 2.3. These graphs show the output, but before presenting them, we need to clarify
what they show.

When we run tests we are limited on what we can (cid:16)see(cid:17) of the behaviour of the system, the
only output we have is the Amygdala’s predictions on each iteration of the simulation. All of our
observations of the Cortex or the Hippocampus are indirect since we don’t have an easy way to
see what’s happening on them. We implemented some probes on the Hippocampus, that dump

(cid:176)
RR n

8377

10

RomÆn Gorojovsky, Frederic Alexandre

the state of both CA3 and CA1 to text (cid:28)les, but they slow the system too much to use them on
long simulations like those needed to (cid:28)nish these scenarios.

On each graph, the X-axis shows the iterations and the Y-axis shows the predictions for
each iteration, normally between 0 and 1. There’ll be a note whenever any of this is changed.
What we want to see is the evolution of the predictions, from the random values on the (cid:28)rst few
iterations to the convergence to a (cid:28)nal prediction.3 In many cases, there’s an intermediate state,
while the information received by the Amygdala is not enough for a prediction and it (cid:29)atlines,
i.e. outputs an useless prediction around 0.5.

Each simulation was run (cid:28)rst for a large number of iterations, to make sure we capture all of
these states and transitions. Once we have an idea of when these transitions happen, we reduced
the number of iterations to a few hundred iterations above that, so all the information is clearly
presented and the simulation time is reasonable to run them many times. The graphs presented
are for those shorter runs.

So here are the graphs for the Simple XOR, for all three brains. All other experiments will

be compared to this one, and these (cid:28)gures will be repeated when needed.

Figure 2: Outputs of Brain CA for the simple XOR showing the (cid:29)atline until around the
2500th iteration and then the transition to the (cid:28)nal convergence.
Top row: A and B (US 1), low row: AB and Z (US 0)

3There’ll be a di(cid:27)erence between this prediction and the US determined by the con(cid:28)guration de(cid:28)ned threshold

for learning

Inria

Models of Hippocampus for pavlovian learning

11

Figure 3: Outputs of Brain HA for the simple XOR showing the almost immediate convergence.
Top row: A and B (US 1), low row: AB and Z (US 0)

Figure 4: Outputs of Brain CHA for the simple XOR showing the even faster convergence.
Top row: A and B (US 1), low row: AB and Z (US 0)

(cid:176)
RR n

8377

12

RomÆn Gorojovsky, Frederic Alexandre

3 Normal working mode

3.1

Introduction

The earlier developments of the Hippocampus (as well as the Cortex) were focused on some
special problems, but the system should be able to work on (cid:16)normal occasions(cid:17), and so some
properties needed to be tested. We’d like to know what’s the capacity of the Hippocampus and
how that capacity scales with the size of the component.

3.1.1 Capacity

The capacity of the Hippocampus is how many inputs can be learned without making mistakes
on the recall mode. As the number of stimulus stored increases, so does the chance of completing
a new one to another already stored. Of course, this limit depends on the overlap of the inputs,
so when designing a test for this we have to be careful with the randomization and order we use.

3.1.2 Scaling

Once we know the capacity of the Hippocampus for inputs of a given size, we would like to know
what’s the relation between that capacity and that size, whether the former grows linearly with
the latter or quadratically or something else.

3.1.3 Learning by heart

One of the functions of the Hippocampus is learning by heart some inputs, as opposed to by
association and generalization the way the Cortex works. We ran some scenarios to see how well
the Hippocampus implements this behaviour.

3.2 Testing of capacity and scaling

In general, we want to know for an Hippocampus of size n, the capacity k of inputs that can be
stored before the output is what we call a mistake, according to a given criteria. These inputs
will have a number M of bits (cid:16)on(cid:17).

M

For our tests we generate all the (cid:0) n

(cid:1) possible inputs of size n with M bits on, randomize
the order. For these tests we choose M = n × 0.15, based on the work presented on [3] that
estimates the normal Cortex activity at 15%. Then we start sending them for the Hippocampus
to learn. After each one is supposedly learned, we test the recall of what’s already there. Once
the number of stored inputs passes an arbitrary number we start testing the recall of a random
sample of them, otherwise it’d take too much time to (cid:28)nish. Since the order of the inputs can
change the k obtained, we run this process 50 times, each time with the outputs in di(cid:27)erent
orders, and our results are the statistics of these 50 runs.

Many di(cid:27)erent criteria for what’s a mistake were used:

Inria

Models of Hippocampus for pavlovian learning

13

Ruthless To make comparisions easier, we want to compare binary vectors, and, since the
output vector is not binary, (cid:28)rst we normalize every element as

Ni =

(cid:40)

Ei
¬Ei

if |Ei − Ri| <= ε
if |Ei − Ri| > ε

where
R is the received (output) vector
E is the expected (input) vector
N is R normalized
i is the position on the vector
ε is the precision threshold (for these tests we used ε = 0.01)

and then we check if any element of N di(cid:27)ers from the corresponding position on the expected
result

Number of di(cid:27)erent bits Here we use the same normalization, count how many bits are
di(cid:27)erent and we call the output a mistake if it has over a given number of di(cid:27)erent bits from the
input (for these tests, M /2)

Accumulated sum of failures This criteria takes

acc =

size(E)
(cid:88)

i=0

|Ei − Ri|

and calls R a mistake if acc is over a threshold, in this case, 0.4.

To check whether the mistake is made by what’s stored on CA3 or by the transformation
learned by CA1 to return to the Entorhinal Cortex, we implemented some probes or dumps
of the modules’ states. These probes write to a (cid:28)le the inner status of the components, what’s
stored on CA3, what was the last input and what’s the current output. With this tool we can
(cid:16)see(cid:17) where the output diverged from the input (and expected output) and infer what is the
problem. Although none of those dumps are included in this document, for they are large and
confusing even if you know exactly what you are trying to see, whenever we state that the mistake
was made by CA1 or CA3, we are basing that on an observation of these dumps.

3.2.1 Results

This is the output from the tests for n from 10 to 35, with M = n × 0.15, rounded up, using as
an error criteria the accumulated sum of failures with an error threshold of 0.4. For each n and
its corresponding M , we show the statistics after 50 runs of the experiment, i.e., after obtaining
50 values of k

(cid:176)
RR n

8377

14

RomÆn Gorojovsky, Frederic Alexandre

Step 2: n = 10, M = 2
Statistics for the Hippocampus’ capacity (k):
3
average:
min:
3
first\_quartil: 3
median:
3
third\_quartil: 3
max:
3
All samples, sorted for clarity:
[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,

3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]

Step 2: n = 15, M = 3
Statistics for the Hippocampus’ capacity (k):
3
average:
min:
1
first\_quartil: 3
4
median:
third\_quartil: 4
max:
4
All samples, sorted for clarity:
[1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4,

4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]

Step 3: n = 20, M = 3
Statistics for the Hippocampus’ capacity (k):
3
average:
min:
1
first\_quartil: 4
median:
4
third\_quartil: 4
max:
4
All samples, sorted for clarity:
[1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,

4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]

Step 4: n = 25, M = 4
Statistics for the Hippocampus’ capacity (k):
3
average:
min:
1
first\_quartil: 2
median:
4
third\_quartil: 4
max:
4
All samples, sorted for clarity:
[1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4,

4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]

Step 5: n = 30, M = 5

Inria

Models of Hippocampus for pavlovian learning

15

Statistics for the Hippocampus’ capacity (k):
2
average:
min:
1
first\_quartil: 2
3
median:
third\_quartil: 4
max:
4
All samples, sorted for clarity:
[1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3,

3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]

Step 6: n = 35, M = 6
Statistics for the Hippocampus’ capacity (k):
2
average:
min:
1
first\_quartil: 1
median:
2
third\_quartil: 3
max:
5
All samples, sorted for clarity:
[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,

2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5]

Step 7: n = 40, M = 6
Statistics for the Hippocampus’ capacity (k):
2
average:
min:
1
first\_quartil: 1
median:
3
third\_quartil: 3
5
max:
All samples, sorted for clarity:
[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3,

3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5]

3.2.2 Discussion

Our experience with the model shows that it and, more precisely, the Hippocampus + Amygdala
can handle more inputs that what these tests show. The scenarios that we used for the rest of
our tests, as we’ll show below, store 4, 8 and 16 di(cid:27)erent stimuli with n = 4 on the (cid:28)rst case and
n = 8 on the other two, while these tests show from 3 inputs for n = 10 to at most 5 elements
for n = 40. The problem with the tests is that the criteria used to decide what’s a mistake are
arti(cid:28)cial and too strict compared to the complete system. Since the latter is dynamic, it adapts
to those mistakes or di(cid:27)erences with the theoretical binary values which makes the capacity
higher.

Using probes, i.e. dumping the states to (cid:28)les as mentioned on 3.2, we could see that when the
tests report an error, the output from CA3 would be considered valid for any of the criteria. The
di(cid:27)erences appear when CA1 tries to reconvert CA3’s output to the original input. Apparently

(cid:176)
RR n

8377

16

RomÆn Gorojovsky, Frederic Alexandre

learning and unlearning the conversions fast and precisely enough it’s hard for CA1.

We didn’t test with bigger values of n because that starts to excede the computer’s capacity,
since the matrix on CA3 store O(n4) elements (the DG translates from n to n2
∈ O(n2) and
that is the width and height of the matrix), so testing with higher values of n becomes too slow
and impractical. Since the matrix stores mostly 0s, a better implementation can help with this
problem, but the main issue of the de(cid:28)nition of (cid:16)mistake(cid:17) remains.

i −ni
2

Also the numbers themselves start to be intractable. For example, calculating the number of
inputs that will be generated (which we do to reserve all memory at once, i.e. faster than one
portion at a time) for which we need to calculate n!, can’t be done for n ≥ 34 because 34! is
larger than 64 bits.

3.3 Testing for Learning by heart

This scenario consists of two simple XORs adjacent to one another, with the idea of presenting
one of them less than the other and expecting that the less frequent is learned by heart but not
by the Cortex. The inputs for this scenario are:

Input
A1
B1
AB1
Z1
A2
B2
AB2
Z2

CS
[1 0 0 1 0 0 0 0]
[0 1 1 0 0 0 0 0]
[1 0 1 0 0 0 0 0]
[0 1 0 1 0 0 0 0]
[0 0 0 0 1 0 0 1]
[0 0 0 0 0 1 1 0]
[0 0 0 0 1 0 1 0]
[0 0 0 0 0 1 0 1]

US
[1]
[1]
[0]
[0]
[1]
[1]
[0]
[0]

The Cortex for this has eight units on the input map, two middle maps of two units each
and (cid:28)nally the out level with a single unit. We tried this scenario (cid:28)rst with all inputs on each
iteration, to see how the system behaves with it. Then we ran simulations giving the second half
(A2, B2, AB2 and Z2) a probability of 0.2 to appear and (cid:28)nally we run this again, but this time
randomizing the order of the stimuli.

Inria

Models of Hippocampus for pavlovian learning

17

Figure 5: Cortex used to run the Double XOR scenario

(cid:176)
RR n

8377

18

RomÆn Gorojovsky, Frederic Alexandre

3.3.1 Results

Simple XOR, using probabilities This is the same scenario, but while the inputs A and
B are presented on every iteration, AB and Z have only a probability of 0.2 of being presented
on each one. The scale for the X axis on those two graphs is in a way di(cid:27)erent and in another
the same. It shows the number of the iterations where each stimulus was presented, so where
the last datapoint for AB or Z is 200 this means that that stimulus appeared 200 times, not
that it appeared last on the 200th iteration. In this sense of the absolute iteration numbers is
di(cid:27)erent, but considering the real time of the simulation, the values to the right of the graphs
where computed roughly at the same time for each one. There are a few additional arti(cid:28)ces
produced by the autoscaling from gnuplot, the program used to generate these graphs.

Figure 6: Outputs of Brain CA for the simple XOR where AB and Z have 20% chance of
appearing on each iteration, showing a faster convergence, without (cid:29)atline for all inputs.
Top row: A and B (US 1), low row: AB and Z (US 0)

Inria

Models of Hippocampus for pavlovian learning

19

Figure 7: Outputs of Brain HA for the simple XOR where AB and Z have 20% chance of
appearing on each iteration, showing a little interference on the (cid:28)rst iterations of A and B,
and, thanks to the lower number of iterations, more detail on the convergence for the other two
inputs.
Top row: A and B (US 1), low row: AB and Z (US 0)

Figure 8: Outputs of Brain CHA for the simple XOR where AB and Z have 20% chance of
appearing on each iteration, showing again that the convergence is faster.
Top row: A and B (US 1), low row: AB and Z (US 0)

(cid:176)
RR n

8377

20

RomÆn Gorojovsky, Frederic Alexandre

Simple XOR, randomized Again the same simple scenario, but this time we feed the stimuli
in random orders, (cid:28)rst with equal probabilities for all of them:

Figure 9: Outputs of Brain CA for the simple XOR, with the inputs randomized. The
randomization changes the (cid:29)atline state by random noise, until the Cortex’s activity is strong
enough to generate a convergence.
Top row: A and B (US 1), low row: AB and Z (US 0)

Figure 10: Outputs of Brain HA for the simple XOR, with the inputs randomized. This graph
is practically identical to 3, the randomization doesn’t a(cid:27)ect the Hippocampus
Top row: A and B (US 1), low row: AB and Z (US 0)

Inria

Models of Hippocampus for pavlovian learning

21

Figure 11: Outputs of Brain CHA for the simple XOR, with the inputs randomized. This
graph is also identical to 4.
Top row: A and B (US 1), low row: AB and Z (US 0)

(cid:176)
RR n

8377

22

RomÆn Gorojovsky, Frederic Alexandre

and then with the same disproportion (5:1) as before

Figure 12: Outputs of Brain CA for the simple XOR, with the inputs disproportionate and
randomized. This removes the noise shown in the (cid:28)gure 9, but the evolution to the convergence
is noiser than in 6 for all four inputs.
Top row: A and B (US 1), low row: AB and Z (US 0)

Figure 13: Outputs of Brain HA for the simple XOR, with the inputs disproportionate and
randomized. It’s basically a noisier version of (cid:28)g. 7
Top row: A and B (US 1), low row: AB and Z (US 0)

Inria

Models of Hippocampus for pavlovian learning

23

Figure 14: Outputs of Brain CHA for the simple XOR, with the inputs disproportionate and
randomized. It’s noisier than the (cid:28)gures 8 and 13, the cortex’s in(cid:29)uence is (cid:16)negative(cid:17) here.
Top row: A and B (US 1), low row: AB and Z (US 0)

(cid:176)
RR n

8377

24

RomÆn Gorojovsky, Frederic Alexandre

Double XOR As mentioned on the previous section, we (cid:28)rst ran this scenario with all stimuli
in every iteration

Figure 15: Outputs of Brain CA for the double XOR, showing that both (cid:16)halves(cid:17) behave
independently as two simple XORs for this brain, since the (cid:28)rst four graphs are equal to (cid:28)gure
2 as are the second four.
First row: A1 and B1 (US 1), second row: AB1 and Z1 (US 0), third row: A2 and B2 (US 1),
last row: AB2 and Z2 (US 0)

Inria

Models of Hippocampus for pavlovian learning

25

Figure 16: Outputs of Brain HA for the double XOR, also showing that both (cid:16)halves(cid:17) behave
independently as two simple XORs for this brain.
First row: A1 and B1 (US 1), second row: AB1 and Z1 (US 0), third row: A2 and B2 (US 1),
last row: AB2 and Z2 (US 0)

(cid:176)
RR n

8377

26

RomÆn Gorojovsky, Frederic Alexandre

Figure 17: Outputs of Brain CHA for the double XOR, also showing that both (cid:16)halves(cid:17) behave
independently as two simple XORs for this brain.
First row: A1 and B1 (US 1), second row: AB1 and Z1 (US 0), third row: A2 and B2 (US 1),
last row: AB2 and Z2 (US 0)

Inria

Models of Hippocampus for pavlovian learning

27

And then with the second half appearing around 1/5th of the iterations.

Figure 18: Outputs of Brain CA for the double XOR, where A2, B2, AB2 and Z2 have 20%
chance of appearing on each iteration. This generates a di(cid:27)erent kind of noise, as if the inputs
were randomized.
First row: A1 and B1 (US 1), second row: AB1 and Z1 (US 0), third row: A2 and B2 (US 1),
last row: AB2 and Z2 (US 0)

(cid:176)
RR n

8377

28

RomÆn Gorojovsky, Frederic Alexandre

Figure 19: Outputs of Brain HA for the double XOR, where A2, B2, AB2 and Z2 have 20%
chance of appearing on each iteration. These show little di(cid:27)erence with the previous results
((cid:28)g. 16).
First row: A1 and B1 (US 1), second row: AB1 and Z1 (US 0), third row: A2 and B2 (US 1),
last row: AB2 and Z2 (US 0)

Inria

Models of Hippocampus for pavlovian learning

29

Figure 20: Outputs of Brain CHA for the double XOR, where A2, B2, AB2 and Z2 have 20%
chance of appearing on each iteration. Again, no di(cid:27)erence with the previous results).
First row: A1 and B1 (US 1), second row: AB1 and Z1 (US 0), third row: A2 and B2 (US 1),
last row: AB2 and Z2 (US 0)

(cid:176)
RR n

8377

30

RomÆn Gorojovsky, Frederic Alexandre

Double XOR with randomness Running the same scenario but randomizing the inputs can
generate very di(cid:27)erent outputs in di(cid:27)erent simulations using the Brain without Hippocampus,
some of which we present here. This has no relation with learning by heart, the results from this
scenario on the brains HA and CHA don’t show anything new and we won’t even present them
here. However, the e(cid:27)ect of this randomness on the CA might be interesting to someone working
on the Cortex, so we present that as data, without too much analisys.

Figure 21: Outputs of Brain CA for the double XOR randomized, in a simulation that didn’t
converge. Notice the large number of iterations.
First row: A1 and B1 (US 1), second row: AB1 and Z1 (US 0), third row: A2 and B2 (US 1),
last row: AB2 and Z2 (US 0)

Inria

Models of Hippocampus for pavlovian learning

31

Figure 22: Outputs of Brain CA for the double XOR randomized, in a simulation that
converged in about 3500 iterations. This is similar to 18
First row: A1 and B1 (US 1), second row: AB1 and Z1 (US 0), third row: A2 and B2 (US 1),
last row: AB2 and Z2 (US 0)

(cid:176)
RR n

8377

32

RomÆn Gorojovsky, Frederic Alexandre

Figure 23: Outputs of Brain CA for the double XOR randomized, in a simulation that
converged very fast.
First row: A1 and B1 (US 1), second row: AB1 and Z1 (US 0), third row: A2 and B2 (US 1),
last row: AB2 and Z2 (US 0)

Inria

Models of Hippocampus for pavlovian learning

33

Figure 24: Outputs of Brain CA outputs for the double XOR randomized. These graphs aren’t
similar to any other, except for the one corresponding to B2.
First row: A1 and B1 (US 1), second row: AB1 and Z1 (US 0), third row: A2 and B2 (US 1),
last row: AB2 and Z2 (US 0)

(cid:176)
RR n

8377

34

RomÆn Gorojovsky, Frederic Alexandre

3.3.2 Discussion

The results of these tests don’t really say much about the behaviour of the Hippocampus. It does
what it’s supposed to do, learns things fast and helps the Amygdala to converge to a solution in
only a few iterations, two orders of magnitude faster than the Cortex alone. But this quickness
doesn’t help testing how it behaves with regards to learning by heart. All of the graphs for the
brains with Hippocampus have the same general form: 40 to 70 iterations of convergence and
then the predictions stay at the same value for the rest of the simulation.

That being said, these tests show some interesting behaviours from the brain CA, the one
with only a Cortex and a Amygdala, on cases that the previous work didn’t cover cases like these,
so we’ll discuss them here.

Cortex behaviour on disproportionate scenarios As shown on the (cid:28)gure 6, when AB and
Z appear 1/5th of the time the Cortex is able to converge to a solution much faster, near to 5
times faster. We believe that the disproportion allows the component to generate a representation
for A and B faster, since AB and Z interfere less with the process. To compare, we inverted the
disproportion, presenting AB and Z on all iterations and A and B with probability 0.2. The
brains with an Hippocampus can solve this without problems, but for brain CA we got these
results which again we present mostly as data to be analized somewhere else:

Figure 25: Outputs of Brain CA for the simple XOR, with the A and B appearing 1/5th of the
iterations instead of AB and Z. After 20000 iterations, no convergence was reached.
Top row: A and B (US 1), low row: AB and Z (US 0)

Inria

Models of Hippocampus for pavlovian learning

35

Figure 26: Outputs of Brain CA for the simple XOR, with only AB having probability 0.2 of
appearing. This reaches a convergence, after much noise
Top row: A and B (US 1), low row: AB and Z (US 0)

(cid:176)
RR n

8377

36

RomÆn Gorojovsky, Frederic Alexandre

Simple XOR, randomized On the (cid:28)gure 9 is clear that the order on which the stimuli
appear matter for the Cortex. Here, where A, B, AB and Z are presented randomly (but the
same amount of times each one) there’s just noise until the convergence. The presence of an
Hippocampus on the brain smoothes that randomness and the predictions are again fast.

Using both the randomization and the disproportion we remove most of the noise and the
results presented on the (cid:28)gure 12 are similar to 6. This again implies that the least the contra-
dictory stimuli appear (AB and Z contradict what can be learned from the presence of A and
B), the least it interferes with the Cortex’s (and/or the Amygdala’s) convergence. This idea is
further supported by the next two graphs, where the disproportion is applied only to AB and
not Z:

Figure 27: Brain without Hippocampus’ outputs for the simple XOR with di(cid:27)erent
probabilities on AB only Top row: A and B (US 1), low row: AB and Z (US 0)

Inria

Models of Hippocampus for pavlovian learning

37

Figure 28: Brain without Hippocampus’ outputs for the simple XOR with di(cid:27)erent
probabilities on AB only and presented randomly
Top row: A and B (US 1), low row: AB and Z (US 0)

(cid:176)
RR n

8377

38

RomÆn Gorojovsky, Frederic Alexandre

Double XOR Presenting this scenario straight to the di(cid:27)erent brains produces outputs no
di(cid:27)erent from presenting simple XORs we’ve seen before. However, once we start modifying the
simulation’s parameters, the output from the brain with Cortex only changes substantially. If
we present the second half fewer times the brain takes from two to three times as many iterations
to converge4; the predictions for the (cid:28)rst half (the one that always appears) are noisy and don’t
even converge at the same time; and for the second half there’s lots of noise until it starts slowly
converging.5

When we add randomness to the (cid:16)mix(cid:17), the variations on the behaviour increase. Using
only randomness (i.e. all stimuli presented on all iterations) It can either generate pure noise
even after 15000 iterations ((cid:28)g. 21), converge in a (cid:16)reasonable(cid:17) number of iterations ((cid:28)g. 22),
converge quickly and almost without noise ((cid:28)g. 23 and even generate results that are just plain
strange ((cid:28)g. 24). This variety of results is a constant, we didn’t have to run lots of simulations
to (cid:28)nd them. Most simulations generate results with some noise and then a convergence, in any
given number of iterations, but about one in ten generate strange results or just noise. Using
randomness with not equiprobable stimuli generated no new results, so we don’t present those
graphs here.

Again we don’t have any theory, nor even an intuition of why the Cortex + Amygdala give any
of these results, since most of our work was on the Hippocampus. Speaking of which, the brains
with Hippocampus, again, ignore this randomness and converge to predicting correct results in
only a few hundred iterations.

4The graph on the (cid:28)gure 18 shows a run that took about 15000 iterations, but due to the randomness of the

starting weights on the Cortex other runs have taken under 8000

5This is second half is aesthetically the most beautiful graph of them all.

Inria

Models of Hippocampus for pavlovian learning

39

4 Forgetting on the Hippocampus

The Hippocampus acts as a storage space that keeps stimuli (CS) and reactions (US) as they
come, without building associations the way the Cortex does. It sounds reasonable that, given
that its capacity is limited, it should have some mechanic to forget, to empty the data stored
that it has stored to make room for new inputs. It’s not clear that the Hippocampus does indeed
forget, and if it does, is de(cid:28)nitely not clear how.

We decided to implement and test some mechanics to model this new mode of work on the
Hippocampus, without trying to decide when they should run, how strongly, etc. This section
will introduce these mechanics in the order they were created, starting with the simplest and
growing in complexity, until we reach the (cid:16)(cid:28)nal(cid:17) model.

4.1 Detailed model of CA3

The data storage of the Hippocampus is CA3, so this is what we needed to modify to implement
forgetting. To better explain the new model let’s detail how this component works in the modes
already implemented:

Learning The input to CA3 is a vector input ∈ {0, 1}n, for a given size n. The system is
implemented with real numbers, and the outputs are usually real numbers. However, accepting
real numbers for inputs increases the di(cid:30)culty of deciding if an input is new or just a version of
what we already new. We’ll discuss more about this issue latter, but for now we need to clarify
that some of the equations that govern this module assume that the inputs are either 0 or 1.

When along with the input comes the signal to store that input, this is stored in a matrix

W ∈ Rn×n:

∆Wij = inputi × inputj

Therefore, inputs are redundantly stored, so for example:

is stored as

i = (cid:2) 0

1

0

1 (cid:3)

W =







0
0
0
0

0
1
0
1

0
0
0
0







0
1
0
1

Recall The output vector is a function of both the input and the contents of the matrix W ,
created from the memories stored. This process happens (cid:16)always(cid:17), i.e.: all inputs create an
output, regardless of whether the input is learned or not.

Before the implementation of forgetting the equation for the output was:

(cid:176)
RR n

8377

40

where

RomÆn Gorojovsky, Frederic Alexandre

∆outputj =

−outputj + h((cid:80)

i Wij ∗ inputi − (cid:80)

i inputi)

τ

(1)

h(x) =

(cid:40)

1 if x ≥ 0
0 if x < 0

Continuing with the previous example, and ignoring the dynamic nature of the computatin,

we get for the same i = [0 1 0 1].

output1 = −0 + h(0 − 0) = 0
output2 = −0 + h(2 − 2) = 1
output3 = −0 + h(0 − 0) = 0
output4 = −0 + h(2 − 2) = 1

and if we used i = [0 1 0 0] we’d get

output1 = −0 + h(0 − 0) = 0
output2 = −0 + h(2 − 2) = 1
output3 = −0 + h(0 − 0) = 0
output4 = −0 + h(1 − 1) = 1

completing the original input stored.

This output could be compared with the input and use that di(cid:27)erence as an indicator of the
novelty of an input for the separation/completion problem, with a higher di(cid:27)erence showing that
the stimulus is likely to be new.

4.2 Mechanics of forgetting

4.2.1 Global (systematic) forgetting

With the (cid:28)rst and simplest mechanic implemented, all the memories stored are gradually for-
gotten over time. On CA3, for each unit on the matrix Wij that stores data (i.e. has a non-zero
value) we’ll have

∆Wij =

f (Wij)
τ

< 0

The simplest f is applying a constant forgetting rate ϕ:

∆Wij =

−Wij × ϕ
τ

(notice that even though in the previous examples we were using binary values, the implemen-
tation of W uses doubles)

Inria

Models of Hippocampus for pavlovian learning

41

4.2.2 Dynamic forgetting

However, discussing what would be needed to implement other features missing from the model
(notably consolidation, described on 6.2), it became clear that a global mechanic might not
be enough. We’ll need to be able to forget a particular example, whether as the only way of
forgetting or alongside the global leak. For this model we decided to go with the latter option,
and use the global forgetting as a general mechanic, modulated by selective forgetting.

At the same time we realized that memories aren’t all equal and so it would be interesting
to model the strength of the memories. In our current model all inputs are stored on the
Hippocampus and with the same intensity. But when the error in the prediction for a stimulus is
large (for whatever value of large), or perhaps larger than the errors produced for the rest of the
problem, it is more important that the Hippocampus learns them by heart. The memory should
be stronger. This strength can be modeled as another modulation of the general forgetting:
stronger stimuli will have lower forgetting rate.

So now instead of a global rate ϕ we need to have a di(cid:27)erent rate for each input, stored in
a new matrix F where, for each Wij that has a value (i.e.
is part of a remembered input), we
have an associated forgetting rate ϕij that will go up with selective forgetting, and down with
the reappearance of the stimuli. In this latter case, the reduction of the corresponding ϕij will
be dependent on the required strength of the memory while for the former we used a constant
value for the increment, which will make ϕij fall exponentially over time. If we plot Wij over
time, ϕij would be the absolute value of the slope of that plot. Since we’ll never want the Wij
to grow on its own, that slope is always < 0.

The mechanic for forgetting in any cell is

∆Wij =

−Wij × ϕij
τ

< 0

Recalling an input inhibits forgetting it, and once an output starts to converge due to com-
pletion, forgetting is also inhibited for those cells. Each ϕij will go up and down as just described
with the following operations:

(cid:136) Forget all Reduces all memories according to their corresponding rates.

∆Wij =

−Wij × ϕij
τ

(cid:136) Forget all except input runs the same operation, but the reduction of the Wij cor-
responding to the input is inhibited. More precisely, the previous item is not applied if
inputi × inputj (cid:54)= 0

(cid:136) Forget input increases the forgetting rate for the input and applies the mechanic for it.

I.e., if inputi × inputj (cid:54)= 0:

∆ϕij =

ϕ0
τ

∆Wij =

−Wij × ϕij
τ

where ϕ0 is the base forgetting rate, which is a con(cid:28)gurable constant.

(cid:176)
RR n

8377

42

RomÆn Gorojovsky, Frederic Alexandre

(cid:136) Learn input, s increases the value of the memory (the corresponding Wij) by the given

strength s and modi(cid:28)es the ϕij accordingly.

∆Wij =

Wij × s
τ

The (cid:28)rst time an input is presented (i.e. Wij = 0), a value of 1 is used instead of Wij × s.
At the same time, ϕij is set or initialized:

ϕij =

(cid:40) ϕ0
s
min(ϕij, ϕij
s )

if ϕij = 0
if ϕij > 0

Again, this is only applied where inputi × inputj (cid:54)= 0

4.3 Modi(cid:28)cations to the recall mode

The equations for recall assume that the contents of W are integer numbers, usually 0 or 1.
As soon as you add a leak, that’s no longer true, and so, since the inputs are still binaries,
(cid:80)
i inputi, h() always returns 0 and there’s no output. To avoid this, we

i Wij ∗ inputi < (cid:80)

changed the recall equation 1 to

∆outputj =

−outputj + (cid:80)
τ

i Wij ∗ inputi

But now the outputs stop being around 1 and 0, so to (cid:16)normalize(cid:17) the output we add back the
(cid:80)

i inputi term.

∆outputj =

−outputj +

(cid:80)

i Wij ∗inputi
(cid:80)
i inputi

τ

Now the output is no longer a vector in {0, 1}n but an approximation, so someone should
make a decision about when a number is (cid:16)1(cid:17) or not. Right now that component is CA1 without
modi(cid:28)cations. CA1 learns to translate from the (cid:16)language(cid:17) used in CA3 to the one used on the rest
of the brain, and does that by comparing CA3’s output with the input to the Hippocampus. Since
this process is learned, it doesn’t actually matter if the output is binary or real. In fact the input
to the Hippocampus is not necessarily binary either. CA1 has a large learning rate, so it adjust
to the variations quicly, and the output re(cid:29)ects the memory losses with lower activities. We also
tried implementing a leak on its neurons, but it didn’t add to the model. This component also
has some potential problems that we’ll dicuss in the section 6.6

The testing protocols for this portion of the research are described on the section 4.4, the results
are on 4.4 and discussed on 4.5

4.4 Testing and results

This is more a proof of concept than a complete test of the behaviour of the system for a given
scenario. We just want to show how our mechanics work compared to the earlier model, so we

Inria

Models of Hippocampus for pavlovian learning

43

ran the simple XOR with an instance of the system with forgetting enabled, and with various
forgetting rates (ϕ0) looking for a behaviour we’d like for this feature. Although all of the system
is implemented, in our tests only the global forgetting is used, since there’s still no point where
selective forgetting nor strengthed learning are used, so this con(cid:28)gured rate is used only as the
global leak rate.

Before showing the results with di(cid:27)erent values of ϕ0, we present again the outputs from
the three brains for the Simple XOR ((cid:28)gures 3 and 4), as a reference, since thats the (cid:16)original(cid:17)
behaviour we are comparing to. The output from Brain CA are omitted since these modi(cid:28)cations
don’t afect it.

Figure 29: Outputs of Brain HA for the simple XOR
Top row: A and B (US 1), low row: AB and Z (US 0)

(cid:176)
RR n

8377

44

RomÆn Gorojovsky, Frederic Alexandre

Figure 30: Outputs of Brain CHA for the simple XOR
Top row: A and B (US 1), low row: AB and Z (US 0)

Inria

Models of Hippocampus for pavlovian learning

45

And now the results sorted by ascendent ϕ, (cid:28)rst the results for Brain HA:

Figure 31: Outputs of Brain HA for the simple XOR, with a forgetting rate of 0.00002, not
enough to show more than a little noise.
Top row: A and B (US 1), low row: AB and Z (US 0)

Figure 32: Outputs of Brain HA for the simple XOR, with a forgetting rate of 0.00005, which
produces a gentle return to the (cid:29)atline of the predictions.
Top row: A and B (US 1), low row: AB and Z (US 0)

(cid:176)
RR n

8377

46

RomÆn Gorojovsky, Frederic Alexandre

Figure 33: Outputs of Brain HA for the simple XOR, with a forgetting rate of 0.00008, which
produces a faster return to predictions around 0.5, still useful.
Top row: A and B (US 1), low row: AB and Z (US 0)

Figure 34: Outputs of Brain HA for the simple XOR, with a forgetting rate of 0.0002, which
makes the predictions fall too fast, it could be said that there’s no convergence.
Top row: A and B (US 1), low row: AB and Z (US 0)

Inria

Models of Hippocampus for pavlovian learning

47

And now for Brain CHA:

Figure 35: Outputs of Brain CHA for the simple XOR, with a forgetting rate of 0.00002
Top row: A and B (US 1), low row: AB and Z (US 0)

Figure 36: Outputs of Brain CHA for the simple XOR, with a forgetting rate of 0.00005
Top row: A and B (US 1), low row: AB and Z (US 0)

(cid:176)
RR n

8377

48

RomÆn Gorojovsky, Frederic Alexandre

Figure 37: Outputs of Brain CHA for the simple XOR, with a forgetting rate of 0.00008
Top row: A and B (US 1), low row: AB and Z (US 0)

Figure 38: Outputs of Brain CHA for the simple XOR, with a forgetting rate of 0.0002
Top row: A and B (US 1), low row: AB and Z (US 0)

Inria

Models of Hippocampus for pavlovian learning

49

All four of these graphs are similar to the earlier four (for Brain HA), but in all cases the

convergence is somehow noisier and lasts a few iterations more before decaying.

4.5 Discussion

Is clear that the forgetting rate ϕ, a(cid:27)ects the behaviour of the Hippocampus. The behaviour
we’d like from this mechanic is that of the (cid:28)gures 32 and 33, where the system gives a good
prediction at the beginning of the simulation, and then this prediction starts to weaken where
the Cortex would start to converge to a solution. With a lower rate there’s no forgetting ((cid:28)g.
31) and a higher rate drops the solution almost immediately ((cid:28)g. 34).

On the brain that does have an Cortex, the output of this component delays the beginning
of the downslope of the predictions, and interferes with the predictions before this slope starts.
However, even though the Cortex will solve the problem at some point, the output from the
Hippocampus dominates the behaviour of the Amygdala so the predictions (cid:29)at towards 0.5, the
(cid:16)(cid:29)atline(cid:17) prediction. We believe that this domination comes from the fact that the Hippocampus
output keeps changing, and the Amygdala is more a(cid:27)ected by rapidly changing information
that the slower change of the Cortex’s output. This dominations gives another reason to use
something like the Splitted Amygdala.

There is no guarantee that these forgetting rates are useful for other problems, but that might
be a moot point since this is only a part of the model. Maybe the (cid:16)correct(cid:17) ϕ0 is lower than
0.00005 and modulation with signals from the rest of the model should be the main factor on
forgetting. Maybe forgetting is not even needed at all. This is only a proof of concept of a part of
the model, and there’s lots of further work on this area, which we’ll discuss on the next section.

(cid:176)
RR n

8377

50

RomÆn Gorojovsky, Frederic Alexandre

5 Splitted Amygdala

5.1

Introduction

In the real brain, the Hippocampus is used to learn new and important things fast, then gradually
teach them to the Cortex , and (maybe) gradually forget those things it has already taught. The
output from both the Hippocampus and the Cortex is then used by the Amygdala to make
a prediction based on those inputs. Our model’s Amygdala, receives the output of both the
Cortex and the Hippocampus to make that prediction. When the prediction (cid:16)fails(cid:17), we know
that both the Hippocampus and the Cortex are failing to help the Amygdala. But when the
prediction is successful, we don’t know if any of them is still failing. In practice, what’ll happen
is that, since the Hippocampus learns faster than the Cortex, by design, its output will mask
the Cortex’s. Without that information we can’t dynamically adjust the learning and forgetting
rates we de(cid:28)ned and implemented at the end of section 4 as a function of the success of the
predictions based only on the Cortex output.

We decided to create a new component that can take the CS and the outputs from both the
Cortex and the Hippocampus, make a prediction and also di(cid:27)erentiate between the predictions
generated only from either of those components. This idea isn’t just a computational patch
for a problem. In the real brain, the activity from the Cortex arrives earlier than that of the
Hippocampus, and the Amygdala is always working, so two di(cid:27)erent predictions are computed in
parallel. Our implementation, however is strictly sequential: the Cortex gives an output, then
the Hippocampus processes that, and then both outputs are used by the Amygdala to give the
(cid:28)nal prediction. Instead of introducing threading, which is never an easy task, we created a new
component: the Splitted Amygdala.

As a black box, the Splitted Amygdala will take four inputs: the non-learned inputs, the
output from the Cortex and the Hippocampus and subsequently the US. The outputs will be a
prediction for the US (which is ready before the actual US arrives), and two error signals, i.e. the
absolute error between the US and the predictions due to the Cortex and the Hippocampus.

5.2 Architecture

Internally we have two amygdalas, one takes only the output from the Cortex and the other
only the output from the Hippocampus. Then we have a Decider component that selects which
one of their predictions will be the prediction of the Splitted Amygdala. We tried two di(cid:27)erent
approaches to this component, which will be described in the following section.

The output from the Cortex and Hippocampus are sent as inputs to the three components
(two Amygdala and the Decider) and the operations for processing and learning relayed as
necessary. The predictions from the two Amygdalas are used to calculate the errors once the
actual US arrives and by the Decider to choose which one is a (cid:16)better(cid:17) prediction of the US,
before it arrives.

5.2.1 Deciders

The idea of the Decider is to make a decision based on the previous behaviour of both Amygdalas.
The original idea was making statistics with regards to the reliability of the predictions of each
one, which we’ll call Scores.

Inria

Models of Hippocampus for pavlovian learning

51

Scores When the US arrives, we can compute, for each Amygdala and for each bit of the US,
the error δ of the prediction as δ = |Pi − U Si|, from these values, (δC and δH ) we can keep
average errors6 (¯δC and ¯δH ), and from these average errors, we can compute normalized scores
SC and SH as

and

where

and

SC =

ScoreC
ScoreC + ScoreH

SH =

ScoreH
ScoreC + ScoreH

ScoreC = |δC − ¯δC|

ScoreH = |δH − ¯δH |

Averaging these scores7, we have a measure of how reliable are the predictions from each

Amygdala for each bit of the US.

Initially we made the decision of which prediction to use based only on this score, but during
testing we found that the Amygdala that worked with the Cortex produced more stable results
than the one that worked with the Hippocampus, i.e., with better scores, even when the absolute
and the average errors were lower for the latter Amygdala during most of the process (until
the Cortex output moves the Amygdala’s predictions and it converges to a better solution).
Likely these betters scores are related to the lower learning rates on the Cortex, which makes its
outputs more stable. We then tried to make a decision based on both the score and the actual
error (multiplying them), and found that it’s not too hard to (cid:28)nd examples where even this will
produce erroneous predictions, specially at the beginning of the process.

Instead of searching for a better performing but more complex function of the scores and
errors to make the decision we discarded this idea and implemented a di(cid:27)erent decider. The
implementation of the calculation of scores is still there, but with optional compilation, and by
default disabled.

Decider Amygdala The Decider Amygdala is (obviously) an Amygdala that takes the non-
learned inputs (CS) and learns to predict the errors δC and δH , with a faster learning rate than
the one used in the other two Amygdalas (which both use the same rate). The decision between
both predictions is then based on the predicted error, the one that’s expected to be closer to the
correct answer wins. It’s a simpler and more robust solution.

We found a di(cid:27)erent implementation issue here, related to the Amygdala’s behaviour when

the inputs are static over time, discussed on 5.6

5.3

Implementation details

The interface of the Splitted Amygdala is as close as possible to the interface of the Amygdala,
but no closer. The Amygdala takes an input vector for processing (which can be the CS, the

6Average over a window, not over the whole process
7Again, over a window, not necessarily the same than the one used for ¯δ

(cid:176)
RR n

8377

52

RomÆn Gorojovsky, Frederic Alexandre

Cortex’s output, the Hippocampus’s, all together, etc.), outputs a prediction and then takes
another vector to learn from (the US). The Splitted Amygdala is less generic, since it takes
takes three di(cid:27)erent inputs that it knows are the CS, the Cortex’s output and the Hippocampus’s
plus the US for learning and outputs a prediction plus two error signals. Therefore, this new
component is not a drop-in replacement for the Amygdala, and a new brain, BrainCHAS had to
be implemented. It copies most of the behaviour of BrainCHA, with the necessary modi(cid:28)cations
to send the di(cid:27)erent outputs to the Splitted Amygdala. The methods process(), learn() and
lastOutput() remain on the interface, with the same semantics8

Since this component is not a drop-in replacement for the Amygdala, we created a new brain,

BrainCHAS, that implements the information transfer between all the components.

5.3.1 Fine tuning

To get these results we adjusted two of the system’s knob trying to balance how fast the system
processes, i.e. converges and stabilizes on a solution; with the (cid:16)smoothness(cid:17) of that convergence.
If the learning rates are too high, the learning on the Amygdalas appear as sudden jumps instead
of transitions. If the rates are too low, the process will take too long.

The other knob is the randomness on the starting weights of the Cortex’s neurons. These
are selected at random around a given central weight, with a con(cid:28)gured delta. This randomness
factor impacts the variance of the iterations it takes the system to converge. If this delta is too
high, then the convergence times can vary by thousands of iterations, but the delta can’t be 0
since that wouldn’t be a good model of the Cortex .

For these tests we settled on these values:

(cid:136) Learning rate for the Amygdalas: 0.005

(cid:136) Learning rate for the Decider Amygdala: 0.03

(cid:136) Learning rate for the Cortex: 0.002

(cid:136) Deltas for the weights of the Cortex’s neurons: 0.01

The testing protocols for this portion of the research are described on the section 5.4, the results
are on 5.5 and discussed on 5.6

5.4 Testing scenarios

With the Splitted Amygdala we wanted a scenario where the Hippocampus worked better for
some inputs and the Cortex better for others. What we decided to try is a version of the Double
XOR with a di(cid:27)erent Cortex. Instead of having a single input map we used two, each one of four
units and connected to a middle map of two units. This two middle units are both connected
to the single unit output map. This scenario is called Double mapped XOR, and was tested
presenting all stimuli in all iterations, without any variation.

8Although for some reason the latter method is called output()

Inria

Models of Hippocampus for pavlovian learning

53

Figure 39: Cortex used to run the Double mapped XOR scenario

The inputs are a XOR in one of the maps and either 0s or 1s on the other one, so we have:

Set

XOR 0

XOR 1

0 XOR

1 XOR

Input
A
B
AB
Z
A
B
AB
Z
A
B
AB
Z
A
B
AB
Z

Left map
[1 0 0 1]
[0 1 1 0]
[1 0 1 0]
[0 1 0 1]
[1 0 0 1]
[0 1 1 0]
[1 0 1 0]
[0 1 0 1]
[0 0 0 0]
[0 0 0 0]
[0 0 0 0]
[0 0 0 0]
[1 1 1 1]
[1 1 1 1]
[1 1 1 1]
[1 1 1 1]

Right map US
[1]
[0 0 0 0]
[1]
[0 0 0 0]
[0]
[0 0 0 0]
[0]
[0 0 0 0]
[1]
[1 1 1 1]
[1]
[1 1 1 1]
[0]
[1 1 1 1]
[0]
[1 1 1 1]
[1]
[1 0 0 1]
[1]
[0 1 1 0]
[0]
[1 0 1 0]
[0]
[0 1 0 1]
[1]
[1 0 0 1]
[1]
[0 1 1 0]
[0]
[1 0 1 0]
[0]
[0 1 0 1]

A variation on this scenario, called Double mapped crossed XOR, was brie(cid:29)y tested, but
the Cortex described can’t solve any of these inputs. In this scenario half of the XOR is in the
left side map and the other half on the right side one. For example:

Set

XOR 0 / XOR 0

Input
A
B
AB
Z

Left map
[1 0 0 0]
[0 1 0 0]
[1 0 0 0]
[0 1 0 0]

Right map US
[1]
[0 1 0 0]
[1]
[1 0 0 0]
[0]
[1 0 0 0]
[0]
[0 1 0 0]

(cid:176)
RR n

8377

54

RomÆn Gorojovsky, Frederic Alexandre

5.5 Results

5.5.1 Simple XOR

For the Splitted Amygdala we show the output of the two inner Amygdalas, the Decider
Amygdala and the chosen predictions. First, as a base case to show that the idea works, we ran
the Simple XOR on it.

Figure 40: Predictions by the Cortex’s Amygdala, very similar to (cid:28)gure 2.
Top row: A and B (US 1), low row: AB and Z (US 0)

Figure 41: Predictions by the Hippocampus’s Amygdala, very similar to (cid:28)gure 3.
Top row: A and B (US 1), low row: AB and Z (US 0)

Inria

Models of Hippocampus for pavlovian learning

55

Figure 42: Decider Amygdala predictions, on red the predicted error for for the Cortex’s
Amygdala, on green, the predicted error for the Hippocampus’ Amygdala.
Top row: A and B (US 1), low row: AB and Z (US 0)

Figure 43: Splitted Amygdala predictions: the output selected based on the Decider
Amygdala’s predictions. the output selected based on the Decider Amygdala’s predictions. The
only di(cid:27)erence is for A, where the output changes for the last few hundred iterations.
Top row: A and B (US 1), low row: AB and Z (US 0)

(cid:176)
RR n

8377

56

RomÆn Gorojovsky, Frederic Alexandre

5.5.2 Double map XOR

Then, as explained before, we ran the double map scenario. Its important to remember that
all 16 di(cid:27)erent stimuli are presented to the system together, as part of a single simulation. To
simplify the presentations we’ll present them in groups of 4, as subproblems, but these aren’t
independent.

XOR - 0 XOR on the left hand map, 0s on the right one:

Figure 44: Predictions by the Cortex’s Amygdala. For AB the predictions go below 0, likely
converging near -0.1. Otherwise the graphs are similar to (cid:28)gure 2.
Top row: A and B (US 1), low row: AB and Z (US 0)

Inria

Models of Hippocampus for pavlovian learning

57

Figure 45: Predictions by the Hippocampus’s Amygdala, similar to 3.
Top row: A and B (US 1), low row: AB and Z (US 0)

Figure 46: Decider Amygdala predictions, on red the predicted error for for the Cortex’s
Amygdala, on green, the predicted error for the Hippocampus’ Amygdala. For some of the
inputs it fails to correctly predict the error of the Cortex’s, by a large margin in the case of A.
For the Hippocampus’ it cycles around a few values.
Top row: A and B (US 1), low row: AB and Z (US 0)

(cid:176)
RR n

8377

58

RomÆn Gorojovsky, Frederic Alexandre

Figure 47: Splitted Amygdala predictions: the output selected based on the Decider
Amygdala’s predictions. Due to the failure on the predictions for A and B, the component
chooses the Cortex’s Amygdala prediction, even when the Hippocampus’s is better. Also, since
for AB the predicted error for the Hippocampus’ Amygdala cycles, there’s a period where the
output oscilates between both predictions.
Top row: A and B (US 1), low row: AB and Z (US 0)

Inria

Models of Hippocampus for pavlovian learning

59

XOR - 1 XOR on the left hand map, 1s on the right one:

Figure 48: Predictions by the Cortex’s Amygdala. Very similar to (cid:28)gure ??.
Top row: A and B (US 1), low row: AB and Z (US 0)

Figure 49: Predictions by the Hippocampus’s Amygdala, which apparently can’t solve this
subproblem so it (cid:29)atlines.
Top row: A and B (US 1), low row: AB and Z (US 0)

(cid:176)
RR n

8377

60

RomÆn Gorojovsky, Frederic Alexandre

Figure 50: Decider Amygdala predictions, on red the predicted error for for the Cortex’s
Amygdala, on green, the predicted error for the Hippocampus’ Amygdala. Again, large errors for
A and B on red, but here the Decider Amygdala predicts worst behaviour than the real. Also,
for Z the cycle of predicted values for the Hippocampus’ Amygdala’s error is wider.
Top row: A and B (US 1), low row: AB and Z (US 0)

Figure 51: Splitted Amygdala predictions: the output selected based on the Decider
Amygdala’s predictions. Again, since the predictions are wrong, the selections are too, only this
time it’s picking the output from the Hippocampus instead of the Cortex.
Top row: A and B (US 1), low row: AB and Z (US 0)

Inria

Models of Hippocampus for pavlovian learning

61

0 - XOR XOR on the right hand map, 0s on the left one:

Figure 52: Predictions by the Cortex’s Amygdala. Also very similar to (cid:28)gure ??.
Top row: A and B (US 1), low row: AB and Z (US 0)

Figure 53: Predictions by the Hippocampus’s Amygdala. Similar to (cid:28)gure 4, but with a better
prediction for A.
Top row: A and B (US 1), low row: AB and Z (US 0)

(cid:176)
RR n

8377

62

RomÆn Gorojovsky, Frederic Alexandre

Figure 54: Decider Amygdala predictions, on red the predicted error for for the Cortex’s
Amygdala, on green, the predicted error for the Hippocampus’ Amygdala. Similar problems than
on (cid:28)gure 46
Top row: A and B (US 1), low row: AB and Z (US 0)

Figure 55: Splitted Amygdala predictions: the output selected based on the Decider
Amygdala’s predictions. Something very strange happens for A, it doesn’t seem to be a product
of the previous (cid:28)gure, unless the cycle of predicted errors for the Hippocampus’ Amygdala has a
value below 0 which wouldn’t appear on the graph but closer to 0, which would be better than
the predicted error for the Cortex’s Amygdala.
Top row: A and B (US 1), low row: AB and Z (US 0)

Inria

Models of Hippocampus for pavlovian learning

63

1 - XOR XOR on the right hand map, 1s on the left one:

Figure 56: Predictions by the Cortex’s Amygdala. Very similar to (cid:28)gure ?? as well.
Top row: A and B (US 1), low row: AB and Z (US 0)

Figure 57: Predictions by the Hippocampus’s Amygdala. As for the XOR - 1, this can’t be
solved by this part of the system.
Top row: A and B (US 1), low row: AB and Z (US 0)

(cid:176)
RR n

8377

64

RomÆn Gorojovsky, Frederic Alexandre

Figure 58: Decider Amygdala predictions, on red the predicted error for for the Cortex’s
Amygdala, on green, the predicted error for the Hippocampus’ Amygdala. Generally the same
problems than those shown in the (cid:28)gure 50
Top row: A and B (US 1), low row: AB and Z (US 0)

Figure 59: Splitted Amygdala predictions: the output selected based on the Decider
Amygdala’s predictions. Again, same problems than those shown in the (cid:28)gure 51
Top row: A and B (US 1), low row: AB and Z (US 0)

Inria

Models of Hippocampus for pavlovian learning

65

5.6 Discussion

5.6.1 Simple XOR

The (cid:28)rst tests show that the idea seems to work. On this use case, the Hippocampus gives a
pretty good answer, and the Cortex only gets better on a few occasions once it converges, and
the prediction generated by the Splitted Amygdala only changes then (which wasn’t happening
with the scoring system).

Of special note are the jumps or staircase that appear on the Decider Amygdala’s graph.
These are due to the higher learning rate that the Decider Amygdala uses, which induces these
jumps instead of the smoother transitions seen on the other graphs.

5.6.2 Double Map XOR

With this scenario we get more interesting results. On one hand, setting the (cid:16)unused(cid:17) map to
ones makes Amygdala assigned to the Hippocampus’ output predicts useless values, which is what
we designed this part of the scenario for. This would have been an example of a subproblem
where the Splitted Amygdala would choose the Cortex + Amygdala’s output. Notice that since
this is a subproblem, i.e. it runs alongside the rest of the examples which are correctly solved by
Hippocampus + Amygdala, we cannot say whether it is the Hippocampus that’s overwhelmed by
so many 1s and outputs useless information, or if it’s the Amygdala that doesn’t know what to
do with this information. We also don’t know if in the former case the problem is on CA3 or CA1.

On the other hand, the graphs showing the behaviour of the Decider Amygdala ilustrate
the next problem of this component. Figures like 46 and 47, show that the decider often makes
bad predictions for the error of the Cortex + Amygdala and stays there until the Cortex starts
a(cid:27)ecting the Amygdala’s predictions. But before that the Splitted Amygdala will have chosen
the Cortex’s prediction as its (cid:28)nal prediction, which is wrong. The opposite problem can happen
too, like on the XOR - 1 subproblem.

5.6.3 Problems with the Amygdala

To explain the problem, we need to explain with some detail how the Amygdala learns. On each
iteration of a problem, each neuron of the amygdala will learn (i.e. have its weight W modi(cid:28)ed)
according to:

Wij = Wi(j−1) + λ × Ii × δj

where

i is the position on the input and the neuron number.

j is the stimulus number (0 ≤ j <≤ # stimuli on the problem).

λ is the learning rate.

I is the input vector, i.e. the stimulus.

δj is the error: U Sj − predictionj

(cid:176)
RR n

8377

66

RomÆn Gorojovsky, Frederic Alexandre

Ii can be either 0 or 1. In the (cid:28)rst case, clearly, W remains unchanged. Since λ is a constant,
we can de(cid:28)ne k = λ × Ii. Now, for a complete iteration of the problem, for a given neuron
(i.e., (cid:28)xing i), calling the starting weight Ws and considering that that particular neuron will be
a(cid:27)ected by n stimuli (i.e., there are n inputs for which Ii = 1), we’ll have:

W0 = Ws + k × δ0

W1 = W0 + k × δ1

W2 = W1 + k × δ2

. . .

Wn = Wn−1 + k × δn

Replacing one equation on the following:

W0 = Ws + k × δ0

W1 = Ws + k × δ0 + k × δ1

W2 = Ws + k × δ0 + k × δ1 + k × δ2

. . .

Wn = Ws + k × δ0 + k × δ1 + · · · + k × δn−1 + k × δn

So (cid:28)nally:

Wn = Ws + k

And when the amygdala reaches a stable state,





n
(cid:88)



δj



j=0

n
(cid:88)

j=0

δj ≈ 0, so Wn = Ws

This is both a bug and a feature. It’s a feature because it means that yes, the amygdala
does reach a stable state. It’s a bug because that stability does not depend on each |δj|, it’s not
a(cid:27)ected by how large the error of the prediction is. This is why the (cid:16)(cid:29)atline(cid:17) of the Amygdala is
around 0.5.

The actual problem is the use we are giving this neural network. A di(cid:27)erent one might be
better for the role of Decider. So far we were using the Amygdalas with two inputs: on one
side, the activities used as input, whether from the Cortex, the Hippocampus, both, etc. and on
the other side, the actual US, once it arrives. These inputs came from the sensorial input, the
Cortex and the Hippocampus. The (cid:28)rst one is constant (for each stimulus). The input from the

Inria

Models of Hippocampus for pavlovian learning

67

Cortex varies over time as it learns and so the input to the amygdala varies. The Hippocampus
includes the Cortex’s input, so it varies too.

The new examples tested on this period use these inputs di(cid:27)erently: For the decider amygdala,
the inputs are constant, what changes is the (cid:16)US(cid:17), in this case, the actual predictions from
the Cortex and the Hippocampus’ amygdala. For the Cortex +Amygdala’s error prediction it
converges to a (cid:16)wrong(cid:17) result early on and then it stays there until the Cortex starts converging
and the prediction changes.

(cid:176)
RR n

8377

68

RomÆn Gorojovsky, Frederic Alexandre

6 Further work

There are many ideas hanging from this work, regarding further development on the Hippocampus
itself, on combining it with the rest of the model and improving testing.

6.1 Dynamic forgetting

Although we implemented small unit tests for the dynamic model of forgetting, we haven’t
tested it together with the rest of the system and simulations of scenarios. To fully integrate this
Hippocampus with the other components we needed to implement two features.

One is a measure of the errors commited by the Cortex, which we now have as a signal
from the Splitted Amygdala. We could use this signal as part of the strength of the memories
stored on the Hippocampus, and/or to decide if we can start forgetting or at least increasing the
forgetting rate for a stimulus.

6.2 Consolidation

The other feature is the process called Consolidation. This is a process by which the Hippocampus
(cid:16)teaches(cid:17) the Cortex what the former has stored, to help the latter create its representations.
There are many reports of how this system might work from a biological perspective, but no
computational models. We believe that a model for this process, no matter how rudimentary, is
needed to complete the information loop between the Cortex, the Hippocampus and the Amygdala
and control how and when the information can be forgotten. Every time we discussed the more
advanced features of forgetting we came back to the interaction between the Cortex and the
Hippocampus which right now is one way (the ouput of the Cortex feeds the Hippocampus via
the ERC) and consolidation is the other, still missing way. Right now, without consolidation the
Hippocampus would be forgetting inputs hoping that the Cortex is learning them, and taking
no active part on that process.

The problem of modeling consolidation is very complex, but we believe that implementing
the simplest model we can think of and start running simulations to see what we are missing can
be a successful (cid:28)rst step. We propose implementing a (cid:16)sleep period(cid:17) feature on the brains and
scenarios, since most of the biological data indicates that consolidation (cid:16)runs(cid:17) during periods of
low to no activity like sleep, and on those periods feed the contents of the Hippocampus back to
the Cortex, to train it with the data stored and not the outside stimuli. The random\_recall()
feature (see section A.2) can be a good enough starting point for (cid:16)selecting(cid:17) which inputs to send,
so the only problem remaining is exactly how to feed it back to the Cortex, since what it sends
to the Hippocampus is all of its activity and right now there’s no way to input that activity back.

6.3 Decider

This is an obvious dangling thread, we haven’t found yet the right decider. We need something
similar to the amygdala, but that cares more about the errors of it’s predictions to avoid the
current behaviour where it settles on a prediction too far from reality, and stays there until the
US (the predictions from the other Amygdalas) change.

Inria

Models of Hippocampus for pavlovian learning

69

6.4 Binary vs. Real Computation

As mentioned many times, the current system takes binary inputs and tries to generate binary
outputs. This is what we call binary computation, as opposed to real computation, where the
inputs are real (double) numbers and so are the outputs. The di(cid:30)culty with this mode of
computation is more semantic than syntactic, since the system internally works with doubles.
In fact the inputs to Hippocampus tend to be real numbers since they arrive while they consolidate
to 0 or 1 on the Cortex.

The biggest problem is with separation/completion: it’s easy to distinguish [1 0 0 1] from
[0 1 0 1] but it’s harder to distinguish [0.8 0 0 1] from [0.3 0 0 1]. Right now we can’t
decide whether the second input is a di(cid:27)erent one or the (cid:28)rst one that hasn’t (cid:28)nished consoli-
dating. A similar problem can be found with forgetting: a value of 0.42, is a recall of a previous
storage of that value or is it a di(cid:27)erent value that is being forgotten?

When we considered these problems we decided that using real numbers was too much of a
problem without adding bene(cid:28)ts and, if it came to that, we could always modify DG to convert
real numbers to a binary representation.

Other points of the system that expect the inputs to be between 0 and 1:

(cid:136) The Amygdala’s neurons cap their outputs to that range.
(cid:136) The values stored on CA3 are also capped to 1. Additionaly, when the value is input for
the (cid:28)rst time is set to 1 ×s /τ (where s is the strength of the memory (1 by default) and τ
is the time constant).
(cid:136) Forgetting is capped to 0.
(cid:136) random\_recall() (see section A.2) assumes that CA3 tries to store 1s.

6.5 Continuous use

All of our simulations are restricted on time and scope. We run the system for a number of
iterations and for a certain number of stimuli. Another line of investigation involves releasing
the system on the wild, or at least on Minecraft, and letting it act and react on the environment.
The question then is, what problems could this new operation mode cause on the system.

The (cid:28)rst problem we see is that right now it takes too long for the Cortex to learn the
associations it needs, due to the low learning rates.
Increasing this rates can cause sudden
(cid:16)jumps(cid:17) on the predictions instead of smooth(er) transitions from one answer to another. So if
a fast reaction is needed, the Hippocampus becomes essential.

With this component the representation of the inputs becomes particularly important, they
have to be sparse. The scenario (cid:16)Double mapped XOR(cid:17) used to test the Splitted Amygdala
(section 5.4, results on 5.5) shows that too many inputs set to one overwhelm the component
and its outputs become useless to the Amygdala. Whatever representation is chosen to interpret
the environment, it has to be careful with this, but it should also be careful with the size of the
inputs, because that may exceed the capacity of the machine in both memory and processing
speed.

Then there’s the issue of capacity of the Hippocampus, how many di(cid:27)erent inputs can be
stored until they start to overlap and generate unexpected results. As stated on section ??, we

(cid:176)
RR n

8377

70

RomÆn Gorojovsky, Frederic Alexandre

didn’t get conclusive results for that problem, so while it’s clear that the number of di(cid:27)erent
inputs the component can store is limited, we don’t know if this is below the number of di(cid:27)erent
inputs the environment can and/or will generate while the system runs. Exceeding that capacity
could either be a case for the implementation of forgetting or to modify the representation and
make it sparser, with the caveats already stated.

6.6

CA1, the weak link

As a general observation, while the model seems solid for the current and immediately foreseeable
uses, we have the intuition that, when something breaks, it will probably be CA1. The behaviour
shown during the tests for capacity and scale indicates that it’s somehow fragile. The implemen-
tation looks a bit na(cid:239)f and has not been stress tested. If the function used on DG changes, this
implementation might simply not be enough to translate for it’s purpose.

It’s also tempting to use this component to redistribute the stored inputs from the Hippocampus
back to the di(cid:27)erent levels of the Cortex during consolidation. We advice against this model,
unless it has strong biological evidence to back it up, and recommend instead to move this func-
tionality to the ERC or another intermetdiate component. Giving CA1 more functionality than
translating from one (cid:16)language(cid:17) to the other would add unnecesary complexity and probably get
us nowhere.

6.7 Probes and better test tools

Some of the tests we ran didn’t produce results not because the tests itself are wrong, but because
we can’t get enough data of the behaviour of the system. Here’s a brief list of tools and outoputs
that we think would be useful to improve this situation:

(cid:136) Either better criteria for what’s a (cid:16)mistake(cid:17) or

(cid:136) a way to run the capacity tests with at least the brain without Cortex (BrainHA) and

de(cid:28)ne (cid:16)mistake(cid:17) as the point where the predictions start to fail.

(cid:136) Easier ways to look into the behaviour of the Amygdala, Cortex and Hippocampus than
dumping the states to (cid:28)les or printing debug lines. Ideally these probes should be pre-
sentable in some sort of graph.

(cid:136) Better scenarios to test learning by heart, where a subset of inputs appear sporadically and

need to be learned by the Hippocampus for the brain to be (cid:16)succesful(cid:17)

Inria

Models of Hippocampus for pavlovian learning

71

Appendix A Other implementations

A.1 Corpus

The scenarios are described on json (cid:28)les which de(cid:28)ne the stimuli (inputs), the USs and their
relations. Then the program creates the stimuli on runtime and presents it to the selected brain.

One problem with this is that this (cid:28)les de(cid:28)ne implicitly an order in which the stimuli are
presented, and in these problems the order matters. We wanted to try presenting the stimuli
randomly, and to do so, we needed to have all the stimuli created and mixed before running the
simulation. We call this (cid:16)precompiled(cid:17) list of stimuli a corpus.

Implementation

The implementation of the corpus input has two halves, the script to create the corpus (cid:28)le from
a scenario (cid:28)le (described below) and a new scenario class (ScenarioCorpus) to read the inputs
from those (cid:28)les instead of creating them. We also modi(cid:28)ed the Loader class to check for the
parameter USE\_CORPUS on the scenario’s con(cid:28)g (cid:28)le and create the corresponding Scenario class.

create\_corpus.py This is a (relatively) simple script written in python that takes a scenario
(cid:28)le (and an optional -r parameter to enable randomizing) and creates a corpus (corpus.txt)
with the dimensions of the problem on the (cid:28)rst line (input size, US size) and then a stimulus on
each line on the format    (the latter is the amount of iterations until the
US is presented, that is de(cid:28)ned on the scenarios)

A.2 Random Recall

This is a method of the Hippocampus to recall a stored input. It has two forms: random\_recall()
obtains an input on a single call, while build\_random\_recall(), builds one over time (which
can be obtained with the method output(), as usual).

Implementation

These methods of the Hippocampus call random\_recall() on CA3 to (cid:28)nd a stored stimulus and
then feed that recalled input to CA1 to build the de(cid:28)nitive output either over time or in the single
call.

CA3’s random\_recall() randomly selects cells on the storage matrix until it (cid:28)nds a non-zero
cell (i.e., a cell with a value above a certain threshold). Once it found that Wij, it walks all of
the row i and the column j, and copies all of the values from both to the output. The random
recall on CA3 is always done fully on one call.

(cid:176)
RR n

8377

72

RomÆn Gorojovsky, Frederic Alexandre

Appendix B main\_bis

To ensure backwards compatibility with the work that was being done earlier and in paralel with
this one, we used a di(cid:27)erent main() on main\_bis.cpp built using Makefile\_bis, with these
modi(cid:28)cations.

Con(cid:28)guration by parameter We used the library getopt to be able to de(cid:28)ne which brain
and scenario will be simulated on run-time. Here is the help output:

$ ./Cortex\_bis --help
./Cortex\_bis ([ -b  ] [ -c  ] [ -a  ] [ -s  ]

| -h )

-b arg, --brain=arg:

One of:

Brain to use
ac
ha
ach (All together).

(Amygdala and Cortex).
(Hippocampus and Amygdala).

-c arg, --cortex=arg:
-a arg, --amygdala=arg:
-i arg, --hippo=arg:
-s arg, --scenario=arg:

Cortex definition filename
Amygdala definition filename
Hippocampus definition filename
Scenario definition filename

This is implemented with a new scenario() function and the class Options

scenario\_chas is a new method to use the BrainCHAS, since building it is di(cid:27)erent that
building all of the other brains.

We strongly recommend that all this functionality is merged back with the (cid:16)standard(cid:17) main.cpp.

Inria

Models of Hippocampus for pavlovian learning

73

Appendix C Con(cid:28)guration (cid:28)les for the Scenarios

The con(cid:28)guration of the scenarions described in section ?? are on the directory cortex-learning/scenarios/Learn\_by\_heart.
Each scenario is described by a (cid:28)le named Scenario\*.json and the Cortex and Amygdala used
are described on the corresponding AmygdalaConfig\*.json and CortexConfig\*.json. The few
con(cid:28)gurable values of the Hippocampus are on the (cid:28)les Hippiocampus.json and Hippocampus\_forgets.json,
and are common for all scenarios.

The Simple XOR scenario (sec. 2.4) and it’s variations are de(cid:28)ned on these (cid:28)les:

Scenario\_Simple-XOR-all\_equal.json
Scenario-Simple\_XOR-corpus.json
Scenario-Simple\_XOR.json
Scenario-Simple\_XOR-proba-corpus.json
Scenario-Simple\_XOR-proba.json

AmygdalaConfig\_Simple-XOR-SimpleCortex.json

CortexConfig\_Simple-XOR-SimpleCortex.json

For the Double XOR (sec. 3.3) we have

Scenario-Double\_XOR.json
Scenario-Double\_XOR-proba.json

AmygdalaConfig-Double\_XOR.json

CortexConfig-Double\_XOR.json

And (cid:28)nally for the Double Mapped XOR and Double mapped crossed XOR (sec. 5.4),

Scenario-Double\_map.json
Scenario-Double\_map\_crossed.json

AmygdalaConfig\_Double\_map.json

CortexConfig\_Double\_map.json

Notice that the Splitted Amygdala uses only the behaviour constants for the Amygdalas and
de(cid:28)nes (cid:16)manually(cid:17) the sizes of its component Amygdalas based on the de(cid:28)nition of the problem
to solve.

(cid:176)
RR n

8377

74

RomÆn Gorojovsky, Frederic Alexandre

Appendix D Scripts

At cortex-learning/plot\_scripts/ there are a few scripts to quickly run and plot these ex-
amples. There’s also a script to create corpuses, written in python, on the (cid:16)home(cid:17) directory.

D.1 Requirements

The plotting scripts use gnuplot to plot the data and imagemagick to stitch the plots for the
di(cid:27)erent stimuli together into a single image. They also rely on a certain folder organization
of the repository and the paths of the (cid:28)les where the main program outputs the predictions
and other data. Some of the directories are created by the scripts themselves, and all of these
directories are presetted as variables at the beginning of the scripts.

D.2

plot\_amygdala.sh

This is the core script for plotting the output of the simulations. It was designed to plot the
predictions of the Amygdala, hence the name, but now it’s mostly used by the rest of the scripts
to plot a series of values which might be predictions, errors etc.

$ ./plot\_amygdala.sh -h
Use: ./plot\_amygdala.sh    [input offset (zero based)]

where

 [yrange]

filename:
number of inputs: Number of different inputs on the problem.
US size:

Path of the file with the data to plot.

input offset:
output file:
yrange:

Bits on the US.
A different line will be plotted for each input, for each US.
Use to skip inputs from the problem.
Path of the file to write (png).
Top and bottom value on the plot written as [top:bottom].
The default is [0:1].

The parameters between angles (< >) are mandatory and those between brackets ([ ]) are
optional. The order of the parameters is important, and not all of the combinations of optional
and mandatory parameters are guaranteed to work.

D.3 Plotting scripts

There is a script for each of the problems, plus the variations for the (cid:28)rst one:

plots-simple-all\_equal.sh
Runs the simple XOR with all stimuli presented equally, using al three (cid:16)original(cid:17) brains (CA,
HA and CHA) and plots the results.

Inria

Models of Hippocampus for pavlovian learning

75

plots-simple-all\_equal-corpus.sh
Same as before, but uses a corpus randomizing the inputs.

plots-simple-proba.sh
This runs the same XOR, but the stimuli for AB and Z have a probability of 0.2 to appear.

plots-simple-proba-corpus.sh
Uses the corpus created against the scenario with the lower probability for AB and Z to present
the stimuli randomized.

plots-double-all\_equal.sh
Runs the double XOR with all stimuli presented equally, using al three (cid:16)original(cid:17) brains (CA,
HA and CHA).

plots-double-proba.sh
Runs the double XOR using al three (cid:16)original(cid:17) brains (CA, HA and CHA), but the stimuli for
the (cid:16)second(cid:17) XOR have a probability of 0.2 to appear.

plots-simple-brain-chas.sh
This runs the simple XOR against the brain with the Splitted Amygdala, which has a di(cid:27)erent
output so the creation of the graphs is di(cid:27)erent. A few parameters on the (cid:28)rst lines that control
whether to use a corpus and whether that corpus is randomized. Notice that enabling corpus on
the script doesn’t enable it on the Scenario.

plots-double\_map-brain-chas.sh
This runs the double mapped XOR against the brain with Splitted Amygdala (BrainCHAS).
It also has the parameters to control whether to use a corpus and its randomization.

plots-double\_map\_crossed-brain-chas.sh
This runs a version of the double mapped crossed XOR against brain CHAS, again with the
parameters to control corpus use and its randomization.

(cid:176)
RR n

8377

76

RomÆn Gorojovsky, Frederic Alexandre

Appendix E Unit tests

A set of reduced and arti(cid:28)cial tests were implemented to keep track of the functionality and the
modi(cid:28)cations of the Hippocampus and to easily test the new functionality. As usual, each test
is a single function, and then there’s a function that runs each one, and another that calls all of
them and prints the results. Three sets of tests were implemented, and all of them are on the
directory test/. There’s a main.cpp that may run all of them and a Makefile to compile them
and link them to the model implemented on the home folder.

CA3 tests These live on MemDyn\_test.cpp. There are tests for recalling (remember), completing
inputs, overlapping (two inputs that share a few bits), random recall, remembering with di(cid:27)erent
strengths, forgetting in general and forgetting a particular entry.

Hippocampus tests For the top level component there are a few tests for remembering and
forgetting, plus a test of the random\_recall() method on the (cid:28)le Hippocampus\_test.cpp

Capacity and scaling tests The implementation tests described on 3.2 are also stored here,
on the (cid:28)le Capacity\_test.cpp. This (cid:28)le contains all the classes used to generate the datasets
and run the tests.

Inria

Models of Hippocampus for pavlovian learning

77

References

[1] Beati, Thomas; Carrere, Maxime; Alexandre, Frederic. Which reinforcing signals in au-
tonomous systems? Third International Symposium on Biology of Decision Making. 2013

[2] Carrere, Maxime; Alexandre, Frederic, (cid:201)mergence de catØgories par interaction entre sys-
tŁmes d’apprentissage, ConfØrence Francophone sur l’Apprentissage Automatique (CAP)
Philippe Preux and Marc Tommasi eds. 2013

[3] O’Reilly, R. C. and Rudy, J. W. Conjunctive representations in learning and memory: Prin-
ciples of cortical and hippocampal function. Psychological Review, 108(2):311-345. 2001

[4] Joseph LeDoux. The amygdala Current Biology, 17(20) :R868(cid:21)R874. October 2007

[5] J. L. McClelland, B. L. McNaughton, and R. C. O’Reilly. Why there are complementary
learning systems in the hippocampus and neocortex: insights from the successes and failures
of connectionist models of learning and memory. Psychological review, 102(3). July 1995

[6] B.L. McNaughton and L. Nadel. Hebb-marr networks and the neurobiological representation
of action in space. Neuroscience and Connectionist Theory, pages 1(cid:21)63. Hillsdale, NJ : L.
Erlbaum. 1990.

[7] R.A. Rescorla and A.R. Wagner. A theory of pavlovian conditioning: Variations in the
e(cid:27)ectiveness of reinforcement and nonreinforcement. Classical Conditioning II : Current
Research and Theory, pages 64(cid:21)99. Appleton Century Crofts. 1972.

[8] N. Schmajuk and J. DiCarlo. Stimulus con(cid:28)guration, classical conditioning and the hip-

pocampus. Psychological Review, 99 :268(cid:21) 305. 1992.

[9] L. R. Squire. Memory and the hippocampus: a synthesis from (cid:28)ndings with rats, monkeys,

and humans. Psychological Review, 99 :195(cid:21)231. 1992.

[10] Joao Sacramento and Andreas Wichert. Tree-like hierarchical associative memory structures.

Neural Networks, 24(2) :143(cid:21)147. 2011.

(cid:176)
RR n

8377

RESEARCH CENTRE
BORDEAUX – SUD-OUEST

200 avenue de la Vieille Tour
33405 Talence Cedex

Publisher
Inria
Domaine de Voluceau - Rocquencourt
BP 105 - 78153 Le Chesnay Cedex
inria.fr

ISSN 0249-6399

