Learning to Parse Sentences with Cross-Situational
Learning using Different Word Embeddings Towards
Robot Grounding
Subba Reddy Oota, Frédéric Alexandre, Xavier Hinaut

To cite this version:

Subba Reddy Oota, Frédéric Alexandre, Xavier Hinaut. Learning to Parse Sentences with Cross-
Situational Learning using Different Word Embeddings Towards Robot Grounding. Spatial Language
Understanding and Grounded Communication for Robotics Workshop, ACL-IJCNLP 2021, Aug 2021,
Bangkok, Thailand. . ￿hal-03533730￿

HAL Id: hal-03533730

https://inria.hal.science/hal-03533730

Submitted on 19 Jan 2022

HAL is a multi-disciplinary open access
archive for the deposit and dissemination of sci-
entific research documents, whether they are pub-
lished or not. The documents may come from
teaching and research institutions in France or
abroad, or from public or private research centers.

L’archive ouverte pluridisciplinaire HAL, est
destinée au dépôt et à la diffusion de documents
scientifiques de niveau recherche, publiés ou non,
émanant des établissements d’enseignement et de
recherche français ou étrangers, des laboratoires
publics ou privés.

Learning to Parse Sentences with Cross-Situational Learning using
Different Word Embeddings Towards Robot Grounding
Spatial Language Understanding and Grounded Communication for Robotics Workshop, ACL-IJCNLP 2021

Subba Reddy Oota1, Frédéric Alexandre1, Xavier Hinaut1
1INRIA Bordeaux Sud-Ouest, France
{subba-reddy.oota, frederic.alexandre, xavier.hinaut}@inria.fr

Introduction

• Grounded Language Acquisition:
1. it is the process of learning a language
2. how children can learn language by observing their environments, interacting with others, under-
standing the concepts of a language (i.e., word-to-meaning) as it relates to the physical world.
• Cross-situational Learning (CSL): Understanding the mechanism enabling children to learn rapidly

word-to-meaning mapping in uncertain conditions.

Why to perform grounded language acquisition through CSL?

• Acquiring language is not a supervised task: e.g. before one year of age, children can segment

words from speech based on statistical learning mechanisms.

• What children observe while hearing the ”the red cup is on the right” and how they map these

sounds to multi-modal features, learning the concept as it refers to a red or blue cup.

• It is still not understood how meaning concepts are captured from complex sentences, along with

learning language-based interactions.

• Also, how pre-trained transformer models perform grounded language acquisition through cross-

situational learning (CSL) remains unclear.

• Such systems could beneﬁt the ﬁeld of human-robot interactions and help understand how children

learn and ground language.

Main Contributions

• We introduce a ﬁne-tuned BERT using the masked-language modeling objective trained on a lan-

guage corpus (i.e. Juven’s CSL + GoLD).

• We showcase that One-Hot and BERT ﬁne-tuned representations signiﬁcantly improve the stimu-

lated vision’s prediction than pre-trained Google BERT.

• We interpret the inner working details of both models and plot the evolution of the output activation

during the processing of a sentence.

Approach

To build the grounded language acquisition models to employ a CSL task using two sequence models:
• Echo State Networks (i.e Reservoir Computing) – ESN
1. ESN with Final Learning: the online algorithm is applied to the reservoir state after the last word

of the sentence.

2. ESN with Continual Learning: the reservoir states are updated after each word of a sentence

using the online method

• Long Short-Term Memory Networks (LSTM)

Experimental Results

Baseline Results Comparison

Model
ESN FL + One-Hot
ESN FL + BERT CSL
ESN FL + Google BERT
ESN CL + One-Hot
ESN CL + BERT CSL
ESN CL + Google BERT
LSTM + One-Hot
LSTM + BERT CSL
LSTM + Google BERT

Juven’s CSL Data

GoLD Data

Valid Error Exact Error Valid Error Exact Error

0.28 5.64
0 6.28
0.2 7.72
2.32 12.1
2.41 13.7
2.78 14.6
0.1 3.5
0.2 1.3
0 4.56

20.05 49.7
25.22 47.4
26.8 51.48
20.16 49.5
18.19 45.2
22.92 49.01
30.65 34.65
22.72 27.11
31.9 36.35

Table 1: Accuracy for wound attribute prediction using Xception CNN classiﬁers. The precision and recall for both single
and multi-task experiments are listed in the table.
Juven’s CSL: Quantitative Analysis

Figure 3: Juven’s data Fine-Tuned BERT CSL

Figure 4: Juven’s data: One-Hot Encoding

Juven’s CSL: Qualitative Analysis

Figure 5: Juven’s Data: Output activation of theLSTM + Fine-Tuned BERT CSL

Figure 1: Echo State Networks are an instance of the Reservoir Computing paradigm using units with continuous states

Evaluation Metrics

Figure 2: Evaluations of different imagined scenes: Valid and Exact Errors.

Discussion

Dataset

• Juven’s CSL Dataset: It is composed of 1000 training sentences, 1000 testing sentences, where

each sentence is describing one or two objects.

• Grounded language dataset (GoLD): There are 8250 textual descriptions consists of 47 object

classes spread across ﬁve different groups, 7 actions, and 8 colors.

• We compare the ability of ESNs and LSTMs to learn to parse sentences via imperfect supervision

(cross-situational learning)

• These experiments yield the following insights: (i) ESNs generalize better than LSTMs when the
vocabulary size increases (for a comparable number of trained parameters); (ii) ﬁne-tuned BERT
representation (i.e. BERT CSL) is the best representation among all models;

• In future work, we will investigate how to transfer this surprisingly good ESN generalizing perfor-

mance by adding gating mechanisms to ESNs and attention mechanisms.

Figure 6: Juven’s Data: Output activation of theESN + BERT CSL.

Random weightsLearned weightsActivation through timeInputsOutputs5101520253035404550−5%0%5%10%15%20%25%30%35%40%45%50%55%60%65%70%75%80%85%90%95%100%Fine-Tuned BERT CSLValid Error ESN CLExact Error ESN CLValid Error ESN FLExact Error ESN FLValid Error LSTM (20)Exact Error LSTM (20)Valid Error LSTM (40)Exact Error LSTM (40)Valid Error LSTM (80)Exact Error LSTM (80)Error vs number of objects in the vocabularyNumber of objects in the vocabularyError on Test5101520253035404550−5%0%5%10%15%20%25%30%35%40%45%50%55%60%65%70%75%80%85%90%95%100%105%One-Hot EncodingValid Error ESN CLExact Error ESN CLValid Error ESN FLExact Error ESN FLValid Error LSTM (20)Exact Error LSTM (20)Valid Error LSTM (40)Exact Error LSTM (40)Valid Error LSTM (80)Exact Error LSTM (80)Error vs number of objects in the vocabularyNumber of objects in the vocabularyError on Test