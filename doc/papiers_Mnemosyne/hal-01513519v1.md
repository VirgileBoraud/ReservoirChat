Motivated Self-Organization
Nicolas P. Rougier, Yann Boniface

To cite this version:

Nicolas P. Rougier, Yann Boniface. Motivated Self-Organization. 12th International Workshop on
Self-Organizing Maps and Learning Vector Quantization, , Jun 2017, Nancy, France. ￿hal-01513519￿

HAL Id: hal-01513519

https://inria.hal.science/hal-01513519

Submitted on 25 Apr 2017

HAL is a multi-disciplinary open access
archive for the deposit and dissemination of sci-
entific research documents, whether they are pub-
lished or not. The documents may come from
teaching and research institutions in France or
abroad, or from public or private research centers.

L’archive ouverte pluridisciplinaire HAL, est
destinée au dépôt et à la diffusion de documents
scientifiques de niveau recherche, publiés ou non,
émanant des établissements d’enseignement et de
recherche français ou étrangers, des laboratoires
publics ou privés.

Distributed under a Creative Commons Attribution 4.0 International License

Motivated Self-Organization

Nicolas P. Rougier
Inria Bordeaux Sud-Ouest
33405 Talence, France
Email: http://www.labri.fr/perso/nrougier/

Yann Boniface
Loria - Campus Scientiﬁque
54506 Vandoeuvre-ls-Nancy, France
Email: yann.boniface@loria.fr

Abstract—We present in this paper a variation of the self-
organizing map algorithm where the original time-dependent
(learning rate and neighborhood) learning function is replaced
by a time-invariant one. The resulting self-organization does not
ﬁt the magniﬁcation law and the ﬁnal vector density is not
directly proportional to the density of the distribution. This lead
us to introduce the notion of motivated self-organization where
the self-organization is biased toward some data thanks to a
supplementary signal. From a behavioral point of view, this signal
may be understood as a motivational signal allowing a ﬁner tuning
of the ﬁnal self-organization where needed. We illustrate this
behavior through a simple robotic arm setup.

II. MODEL

We’ll use here the deﬁnitions that we ﬁrst proposed in [1].

A. Deﬁnitions

Let us consider a probability density function f (x) on a
compact manifold Ω ∈ Rd. A vector quantization (VQ) is a
function Φ from Ω to a ﬁnite subset of n code words {wi ∈
Rd}1≤i≤n that form the code book. A cluster is deﬁned as
def= {x ∈ Ω|Φ(x) = wi}, which forms a partition of Ω and
Ci
the distortion of the VQ is measured by the mean quadratic
error

I.

INTRODUCTION

ξ =

(cid:107)x − wi(cid:107)2f (x)dx.

(1)

n
(cid:88)

(cid:90)

i=1

Ci

We introduced in [1] the Dynamic Self-Organized Map
(DSOM) architecture that is a variation of the self-organizing
map algorithm [2] where the original time-dependent (learning
rate and neighborhood) learning function has been replaced by
a time-invariant learning rule. This modiﬁcation of the learn-
ing rule yields several interesting new properties. First, and
because of the time invariance, it is possible for the network
to support life-long learning. This means that the network can
be fed continuously with new input and the network is able
to self-organize itself around the whole set of data (using
a set of hypothesis detailed in [1]). This kind of property
cannot be easily achieved using SOM-like algorithms because
they generally and explicitly depend on a time decreasing
learning rate and/or neighborhood function (SOM, NG, GNG)
that requires to know beforehand the number of data to be
processed. The second property deals with the magniﬁcation
law as introduced by [3]. Most vector quantization (VQ)
algorithms try to match the density through the density of
their code book: high density regions of the distribution tend
to have more associated prototypes than low density regions.
This generally allows to minimize the loss of information (or
distortion) as measured by the mean quadratic error. However,
in the case of DSOM, the magniﬁcation law is not ﬁt and the
density of the code book is uncorrelated with the density of the
data, hence leading to a regular quantiﬁcation a priori of the
underlying probability density function. This second property
could be easily considered as a serious drawback for vector
quantization if one wants, for example, to estimate data density
function. However, from a more behavioral point of view,
we argue in this paper that this may be a desirable property
provided that we can modulate learning using a dedicated
signal, i.e. a motivation to concentrate learning on what is
relevant to the task in order to have ﬁnely tune representations
where necessary.

If the function f is unknown and a ﬁnite set {xi} of p non
biased observations is available, the distortion error may be
empirically estimated by

ˆξ =

1
p

n
(cid:88)

(cid:88)

i=1

xj ∈Ci

(cid:107)xj − wi(cid:107)2.

(2)

In the following, we will use deﬁnitions and notations intro-
duced by [3] where a neural map is deﬁned as the projection
from a manifold Ω ⊂ Rd onto a set N of n neurons which is
formally written as Φ : Ω → N . Each neuron i is associated
with a code word wi ∈ Rd, all of which established the set
{wi}i∈N that is referred as the code book. The mapping from
Ω to N is a closest-neighbor winner-take-all rule such that any
vector v ∈ Ω is mapped to a neuron i with the code wv being
closest to the actual presented stimulus vector v,

Φ : v (cid:55)→ arg min

((cid:107)v − wi(cid:107)).

i∈N

(3)

The neuron wv is called the winning element and the set Ci =
{x ∈ Ω|Φ(x) = wi} is called the receptive ﬁeld of the neuron
i. The geometry corresponds to a Vorono¨ı diagram of the space
with wi as the center.

B. Self-Organizing Maps (SOM)

SOM is a neural map equipped with a structure (usually a
hypercube or hexagonal lattice) and each element i is assigned
a ﬁxed position pi in Rq where q is the dimension of the lattice
(usually 1 or 2). The learning process is an iterative process
between time t = 0 and time t = tf ∈ N+ where vectors
v ∈ Ω are sequentially presented to the map with respect to
the probability density function f . For each presented vector v
at time t, a winner s ∈ N is determined according to equation

(3). All codes wi from the code book are shifted towards v
according to

∆wi = ε(t) hσ(t, i, s) (v − wi)

(4)

with hσ(t, i, j) being a neighborhood function of the form

hσ(t, i, j) = e−

(5)
where ε(t) ∈ R is the learning rate and σ(t) ∈ R is the width
of the neighborhood deﬁned as

.

(cid:107)pi−pj (cid:107)2
2σ(t)2

σ(t) = σi

(cid:19)t/tf

(cid:18) σf
σi

, with ε(t) = εi

(cid:19)t/tf

(cid:18) εf
εi

,

(6)

while σi and σf are respectively the initial and ﬁnal neighbor-
hood width and εi and εf are respectively the initial and ﬁnal
learning rate. We usually have σf (cid:28) σi and εf (cid:28) εi.

C. Dynamic Self-Organizing Map (DSOM)

DSOM is a neural map equipped with a structure (a
hypercube or hexagonal lattice) and each neuron i is assigned
a ﬁxed position pi in Rq where q is the dimension of the
lattice (usually 1 or 2). The learning process is an iterative
process where vectors v ∈ Ω are sequentially presented to
the map with respect to the probability density function f .
For each presented vector v, a winner s ∈ N is determined
according to equation (3). All codes wi from the code book
W are shifted towards v according to

∆wi = ε(cid:107)v − wi(cid:107)Ω hη(i, s, v) (v − wi)
with ε being a constant learning rate and hη(i, s, v) being a
neighborhood function of the form

(7)

hη(i, s, v) = e

− 1
η2

(cid:107)pi−ps(cid:107)2
(cid:107)v−ws(cid:107)2
Ω

(8)

where η is the elasticity or plasticity parameter. If v = ws,
then hη(i, s, v) = 0

D. Standard distributions

The DSOM algorithm reﬂects two main ideas:

•

•

If a neuron is close enough to the data, there is no need
for others to learn anything: the winner can represent
the data.

If there is no neuron close enough to the data, any
neuron learns the data according to its own distance
to the data.

The closeness of the winner to the data is controlled using the
elasticity parameter as illustrated on ﬁgure 1. and for uniform
distributions, DSOM with proper elasticity is comparable to
SOM as illustrated on ﬁgure 2 and detailed in [1].

III. EXPERIMENTAL RESULTS

As we explained in the introduction, the dynamic nature
of the DSOM algorithm leads to a regular self-organization,
that is, a self organization that does not ﬁt the magniﬁcation
law and consequently, code-vectors are evenly spread on the
distribution support. Even from a behavioral point of view,
this may not be satisfactory since we may want to have ﬁner
representations in some region of the input space that are of
some interest and more generic representations in some other
parts of the input space.

Fig. 1. Three DSOM with respective elasticity equal to 1, 1.5 and 2 have
been trained for 20 000 iterations on a normal distribution using a regular grid
covering the [0, 1]2 segment as initialization. Low elasticity leads to loose
coupling between neurons while higher elasticity results in a tight coupling
between neurons.

Fig. 2. Side by side comparison of the SOM and DSOM algorithms on very
simple and uniform distributions. For each ﬁgure, network of size 8 × 8 has
been trained for 20 000 epochs using 10 000 samples. Initialization has been
done by placing initial code vectors randomly over the [0, 1]2 area.

θ2

L2

L1

θ1

The robotic arm is made of two segments of respective size L1
Fig. 3.
and L2 whose positions are given by angles θ1 and θ2. The gray area
represents reachable positions in the case L1 = L2 and the dotted disc area
corresponding to the region of interest (arbitrary deﬁned) .

A. Experimental setup

Let us consider the case of a simple robotic arm made of
two linked segments L1 and L2. Segment L1 can rotate freely
around its base in the range [−π/2, +π/2] and segment L2
can rotate around L1 endpoint in the range [−π/2, +π/2] (see
ﬁgure 3). The goal of the experiment is to learn the correspon-
dence between {θ1, θ2} and the Cartesian coordinates {x, y} of
the end point of the arm with ﬁner representations in the dotted
disc area. Since we do not want to use the inverse model of
the arm, the only way to generate data is then to draw {θ1, θ2}
from their respective domain and to compute the corresponding
{x, y} end position of the arm.

B. Results

The mapping from {θ1, θ2} to {x, y} is not linear and
leads to a larger density on the frontier of the domain. If we
use such a distribution, we obtain the self-organization drawn
on left part of ﬁgure 4. This self-organization spreads almost
evenly on the whole reachable region with some noticeable
and useless representations outside the region. However, as we
explained we would like to have ﬁner representations within
the dotted gray area and consequently, we built a modulation
signal deﬁned as the distance of the end-point to the center
of the disc area. This modulation is associated to any sample
given to the model and this allow us to modify the original
neighborhood equation (8) as follows:

hη(i, s, v) = e

− α
η2

(cid:107)pi−ps(cid:107)2
(cid:107)v−ws(cid:107)2
Ω

(9)

with α being the modulation. This α modulation modiﬁes
the overall elasticity on a per sample basis and allows to
have a ﬁner tuning of the self-organization. This is illustrated
on the left part of the ﬁgure 4 where self-organization has
concentrated code vectors in the region of interest.

IV. CONCLUSION

Since the early work of [4], [5], the idea of a critical
period in the early years of development, where most sensory

Sample data are generated by drawing uniformly θ1 and θ2 in
Fig. 4.
[−π/2, +π/2] and computing the end point position. This leads to a non-
uniform distribution where higher density is found on the periphery of the
distribution support. The left ﬁgure displays resulting self-organization of a
DSOM with an elasticity of 2.5 and no modulation while the right ﬁgure
displays the same DSOM algorithm where each sample is modulated according
to its distance to the center of the ﬁgure.

or motor properties are acquired and stabilized have been
widely accepted. In such context, the original SOM algorithm
gives a fair account of such development. However, cortical
representations are not ﬁxed entities, but rather, are dynamic
and are continuously modiﬁed by experience as explained
by [6] and the capacity of the cortex to re-organize itself in
face of lesions, deﬁcits or change in the environment [7], [8]
cannot be easily explained using SOM-like algorithm since
after learning period, the resulting self-organization is frozen
and cannot be easily changed.

Thanks to its dynamic nature, the DSOM algorithm may
help to solve this dilemma by ensuring a tight coupling
between representations and the environment with a code
book that does not ﬁt data density and cover the whole
data support evenly. Since we may need nonetheless to have
more representations in some region of the input space, we
proposed to modulate learning by providing the algorithm
with an explicit signal giving the importance of the data.
In a more general framework, we could expect a cerebral
structure (e.g. basal ganglia, amygdala) to compute such signal:
if some regions of the perceptive space is judged behaviorally
relevant, model could develop precise representations in this
region. This has been illustrated through a very simple robotic
experiment where the motivation signal is computed according
to the distance of the arm end-point to the center of the
distribution. If learning was to be driven solely by data density
(like in most VQ), such modulation would certainly be strongly
attenuated or not possible at all.

Without modulationelasticity = 2.00, L1=0.35, L2=0.15With modulationelasticity = 2.00, L1=0.35, L2=0.15Without modulationelasticity = 2.00, L1=0.25, L2=0.25With modulationelasticity = 2.00, L1=0.25, L2=0.25APPENDIX

: a compact manifold of Rd where d ∈ N+
Ω
: a probability density function (pdf) Ω → R
f (x)
: a set of p non-biased observations of f .
{xi}
: a set of n elements, n ∈ N+.
N
Φ
: a function deﬁned from Ω → N
wi ∈ Rd : code word associated to an element i of N
{wi}
Ci

: code book associated to N
: cluster associated to element i such that Ci =
{x ∈ Ω|Φ(x) = wi}
: euclidean norm deﬁned over Rd
: normalized euclidean norm deﬁned over Ω as
x (cid:55)→
: distortion error deﬁned as (cid:80)n
wi(cid:107)2f (x)dx
estimated
:
(cid:80)
1
p
ε(t)
: learning rate at time t
λ(t) or σ(t): neighborhood width at time t
η
: elasticity or plasticity

distortion
(cid:107)xj − wi(cid:107)2

(cid:107)x(cid:107)
maxy,z∈Ω((cid:107)y−z(cid:107))

(cid:107)x(cid:107)
(cid:107)x(cid:107)Ω

deﬁned

(cid:107)x −

error

xj ∈Ci

(cid:80)n

i=1

i=1

as

ˆξ

Ci

(cid:82)

ξ

%

REFERENCES

[1] N. Rougier and Y. Boniface, “Dynamic self-organizing map,” Neurocom-

puting, 2011, to appear.

[2] T. Kohonen, “Self-organized formation of topologically correct feature

maps,” Biological Cybernetics, vol. 43, pp. 59–69, 1982.

[3] T. Villman and J. Claussen, “Magniﬁcation control in self-organizing
maps and neural gas,” Neural Computation, vol. 18, pp. 446–449, 2006.
[4] D. Hubel and T. Wiesel, “The period of susceptibility to the physiological
effects of unilateral eye closure in kittens.” Journal of Physiology, vol.
206, pp. 419–436, 1970.

[5] N. Daw, “Mechanisms of plasticity in the visual cortex,” Investigative

Ophthalmology, vol. 35, pp. 4168–4179, 1994.

[6] D. Buonomano and M. Merzenich, “Cortical plasticity: From synapses
to maps,” Annual Review of Neuroscience, vol. 21, pp. 149–186, 1998.
[7] P. B. y Rita, Brain Mechanisms in Sensory Substitution. Academic Press

New York, 1972.

[8] V. Ramachandran, D. Rogers-Ramachandran, and M. Stewart, “Percep-
tual correlates of massive cortical reorganization,” Science, vol. 258, pp.
1159–1160, 1992.

