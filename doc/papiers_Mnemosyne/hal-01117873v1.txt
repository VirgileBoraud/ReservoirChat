A Long Journey into Reproducible Computational Neuroscience Meropi
Topalidou, Arthur Leblois, Thomas Boraud, Nicolas P. Rougier

To cite this version:

Meropi Topalidou, Arthur Leblois, Thomas Boraud, Nicolas P. Rougier. A
Long Journey into Reproducible Computational Neuroscience. Frontiers in
Computational Neuroscience, 2015, pp.2. ￿10.3389/fncom.2015.00030￿.
￿hal-01117873￿

HAL Id: hal-01117873

https://inria.hal.science/hal-01117873

Submitted on 5 Mar 2015

HAL is a multi-disciplinary open access archive for the deposit and
dissemination of sci- entific research documents, whether they are pub-
lished or not. The documents may come from teaching and research
institutions in France or abroad, or from public or private research
centers.

L’archive ouverte pluridisciplinaire HAL, est destinée au dépôt et à la
diffusion de documents scientifiques de niveau recherche, publiés ou
non, émanant des établissements d’enseignement et de recherche français
ou étrangers, des laboratoires publics ou privés.

Distributed under a Creative Commons Attribution 4.0 International
License

A Long Journey into Reproducible Computational Neuroscience Meropi
Topalidou1,2,3,4, Arthur Leblois5, Thomas Boraud2,3, and Nicolas P.
Rougier1,2,3,4,*

1 INRIA Bordeaux Sud-Ouest, Bordeaux, France 2 Institut des Maladies
Neurodégénératives, Université de Bordeaux, UMR 5293, Bordeaux, France 3
Institut des Maladies Neurodégénératives, Centre National de la
Recherche Scientiﬁque, UMR 5293, Bordeaux, France 4 LaBRI, Université de
Bordeaux, Institut Polytechnique de Bordeaux, Centre National de la
Recherche Scientiﬁque, UMR 5800, Talence, France 5 Centre de
Neurophysique, Physiologie et Pathologies, Université Paris Descartes,
Centre National de la Recherche Scientiﬁque, UMR 8119, Paris, France *
Corresponding author.

Computational neuroscience is a powerful ally in our quest to understand
the brain. Even the most simple model can shed light on the role of this
or that structure and propose new hypothesis concerning the overall
brain organization. However, any model in Science is doomed to be proved
wrong or incomplete and replaced by a more accurate one. In the
meantime, for such replacement to happen, we have ﬁrst to make sure that
models are actually reproducible such that they can be tested,
evaluated, criticized and ultimately modiﬁed, replaced or even rejected.
This is where the shoe pinches. If we cannot reproduce a model in the
ﬁrst place, we’re doomed to re-invent the wheel again and again,
preventing us from building an incremental computational knowledge of
the brain.

We have been recently confronted to the problem when we tried to
reproduce a model of the literature (Guthrie et al., 2013) concerning a
computational model of the basal ganglia. This model was based on a
previous modelling study by (Leblois et al., 2006) where authors
proposed an action selection mechanism based on a competition between
the positive feedback, direct pathway through the striatum and the
negative feedback, hyperdirect pathway through the subthalamic nucleus.
Guthrie et al. (2013) further investigated how multiple level action
selection could be performed, and the model has been extended in a
manner consistent with known anatomy and electrophysiology of the basal
ganglia in the monkey. The model is quite complex, but such is the basal
ganglia. We asked authors for the sources of the model only to realize
it has been implemented using 6000 lines of Delphi (Pascal language). We
were unable to compile it (due to missing packages that we couldn’t
locate in any repository) and we thus decided to recode it from scratch.
Unfortunately, the information provided in the article was not sufﬁcient
to allow for the direct reproduction of the model, mainly because there
were factual errors in the manuscript and some information was ambiguous
or missing. Ultimately, we were able to reach two of the original
authors,T. Boraud and A. Leblois (who are also authors of this
commentary) in order to ask them about the details of the model. We
joined efforts and proceeded with a complete rewrite, using the Python
language (Perkel, 2015), a dedicated library (DANA), a versioning system
(git), a public repository (github) and the IPython notebook, merely
following the principles of reproducible computational science as
proposed in (Peng, 2011; Sandve et al., 2013; Stodden et al., 2014). We
also established the tabular description of the model as proposed in
(Nordlie et al., 2009). We contend this revamped model now allows any
researcher in computational neuroscience to run it and to obtain the
exact same results as the ones described in the original article (see
https://hal.inria.fr/hal-01109483 for complete description and
https://github.com/rougier/
Neurosciences/tree/master/basal-ganglia/guthrie-et-al-2013 for source
code). Furthermore, the new description, as well as the new ﬁgures,
allow anyone to rewrite the model using a different language, tools or
software.

However, the whole process took us approximately three months. This is
hardly acceptable for the reproduction of a computational model that
should be straightforward.

Unfortunately, this is not an isolated case. If computer science offers
a large set of tools for prototyping, writing, running, testing,
validating, sharing and reproducing results, computational neuroscience
still lags behind. In the best case, authors may provide the sources of
their model as a compressed archive and feel conﬁdent their model is
reproducible. But this is not exactly true. Buckheit and Donoho (1995)
explained almost 20 years ago that, “an article about computational
result is advertising, not scholarship. The actual scholarship is the
full software environment, code and data that produced the result”. The
computational part in computational sciences implies the use of
computers, operating systems, tools, frameworks, libraries and data.
This  leads to such a large

number of combinations (taking into account the version for each
components) that the chances to have the exact same conﬁguration as one
of your colleague are nearly zero. This draws consequences in our 
respective computational approaches in order to make sure models and
simulations can be actually and faithfully reproduced. We have to
enforce the rules proposed in the literature and editors have to make
sure this actually happens. From a broader perspective, this singular
experience raises also some questions about the whole publication
process. If articles remain the best media to publish a research and to
introduce a model, why can’t we have associated resources for the actual
code just like we can have supplementary material as a separate
document? For example, it is quite surprising that there is still no
ofﬁcial code repository associated with journals. Even a dedicated
public account on github (or any similar website) would really help on
this matter. 

But more importantly, given the quality of the new tools available
today, it may be time to envisage new formats for communicating
computational researches. For example, interactive documents could allow
to replay a simulation and to modify parameters while reading the
description of a model or a simulation. The IPython notebook is a
serious candidate in that direction and could soon become a new way to
exchange knowledge. It has been recently highlighted on Nature (Shen,
2014) and it is already widely used for teaching and writing books. Such
new formats would deﬁnitely help authors, reviewers, readers and
ultimately, Science.

References

1.  M. Guthrie, A. Leblois, A. Garenne, and T. Boraud. Interaction
    between cognitive and motor cortico-basal ganglia loops during
    decision making: a computational study. Journal of Neurophysiology,
    109:3025–3040,

2.  

3.  A. Leblois, T. Boraud, W. Meissner, H. Bergman, and D. Hansel.
    Competition between feedback loops underlies normal and pathological
    dynamics in the basal ganglia. Journal of Neurosciences,
    26:3567–3583,

4.  

5.  R.D. Peng. Reproducible research in computational science. Science,
    334(6060):1226–1227, 2011.

6.  G.K. Sandve, A. Nekrutenko, J. Taylor, and E. Hovig. Ten simple
    rules for reproducible computational research. PLoS Computational
    Biology, 9(10):e1003285, 2013. doi:
    doi:10.1371/journal.pcbi.1003285.

7.  V. Stodden, F. Leisch, and R.D. Peng, editors. Implementing
    Reproducible Research. Chapman & Hall/CRC,

8.  

9.  Jeffrey M. Perkel. Programming: Pick-Up Python. Nature 518,
    125–126, 2015.

10. E. Nordlie, M. Gewaltig, and H.E. Plesser. Towards reproducible
    descriptions of neuronal network models.

PLoS Computational Biology, 5(8):e1000456, 2009. doi:
10.1371/journal.pcbi.1000456.

8.  J. Buckheit and D.L. Donoho. Wavelets and Statistics, chapter
    Wavelab and reproducible research.

Antoniadis, A., 1995.

9.  Helen Shen. Interactive notebooks: Sharing the code. Nature,
    (515):151–152, 2014.


