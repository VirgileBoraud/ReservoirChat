A Long Journey into Reproducible Computational
Neuroscience
Meropi Topalidou, Arthur Leblois, Thomas Boraud, Nicolas P. Rougier

To cite this version:

Meropi Topalidou, Arthur Leblois, Thomas Boraud, Nicolas P. Rougier. A Long Journey into Repro-
ducible Computational Neuroscience. 2014. ￿hal-01109483￿

HAL Id: hal-01109483

https://inria.hal.science/hal-01109483

Preprint submitted on 26 Jan 2015

HAL is a multi-disciplinary open access
archive for the deposit and dissemination of sci-
entific research documents, whether they are pub-
lished or not. The documents may come from
teaching and research institutions in France or
abroad, or from public or private research centers.

L’archive ouverte pluridisciplinaire HAL, est
destinée au dépôt et à la diffusion de documents
scientifiques de niveau recherche, publiés ou non,
émanant des établissements d’enseignement et de
recherche français ou étrangers, des laboratoires
publics ou privés.

A Long Journey into Reproducible Computational Neuroscience

Meropi Topalidou1,2,3,4, Arthur Leblois5, Thomas Boraud2,3, and Nicolas P. Rougier1,2,3,4,\*

1

INRIA Bordeaux Sud-Ouest, Bordeaux, France
2Institut des Maladies Neurod´eg´en´eratives,
Universit´e Bordeaux-Segalen, UMR 5293, Bordeaux, France
3Institut des Maladies Neurod´eg´en´eratives,
Centre National de la Recherche Scientiﬁque, UMR 5293, Bordeaux, France
4LaBRI, Universit´e de Bordeaux, Institut Polytechnique de Bordeaux,
Centre National de la Recherche Scientiﬁque, UMR 5800, Talence, France
5Centre de Neurophysique, Physiologie et Pathologies, Universit´e Paris Descartes,
Centre National de la Recherche Scientiﬁque, UMR 8119, Paris, France
\*Corresponding author: Nicolas.Rougier@inria.fr

Abstract Computational neuroscience, a relatively recent ﬁeld, has gained fast ground and modelling is now widely
used to better understand individual and collective neuronal dynamics, and to propose new functions relying on
neural substrate. While the development of a model is initially tightly linked to the speciﬁc question asked by a given
group of researchers, further development of the model in diﬀerent contexts is often possible and desired. When such
further development relies on new players, the continuity of the work requires proper validation, reproduction and
sharing of the models original equations and code. However, as they are published today, computational neuroscience
papers rarely include the suﬃcient material for the reproduction and sharing of the underlying model as a whole.
Here, we aim at showing the full extent of the problem, as well as state-of-the-art solutions, through the detailed story
of the reproduction of a computational modelling study by Guthrie et al. (2013) investigating the dynamics of basal
ganglia circuits and their function in multiple level action selection. In collaboration with the authors of the original
work, we ﬁrst explain the diﬃculties encountered during the reproduction and validation of the initial model and
results. These diﬃculties led us to completely rewrite the model enforcing best software practices, relying on previous
attempts to provide a common framework for reproducible computational science and software sustainability. We
hereby detail these practices in the face of our practical example: the reproduction of the results from Guthrie et al.
(2013). In particular, these practices include: (i) a template for formal description of the model in a single table,
(ii) a public repository for shared software a proper version control, and (iii) an easy interface to run the underlying
code and reproduce ﬁgures. We ﬁnally propose new formats for communicating results allowing the replay of a code
while reading a computational study, in order to get a deeper understanding of the concepts being introduced.

Author Summary Computational sciences, such as bioinformatics, computational biology or computational neuro-
science, are gaining fast ground in modern Life Sciences and new discoveries can be made thanks to computational
models or numerical simulations and analysis. The picture is not all bright however. The computational part in
computational sciences implies the use of computers, operating systems, tools, frameworks, libraries and data. This
leads to such a large number of combinations (taking into account the version for each components) that the chances
to have the exact same conﬁguration as one of your colleague are nearly zero. This draws consequences in our
respective computational approaches in order to make sure models and simulations can be actually and faithfully
reproduced. If reproducibility is the hallmark of Science, computational sciences seems to be still in their infancy
in this domain, even though things have started to improve. This article highlights the extent of the problem based
on the reproduction of a model in computational neuroscience and show how to circumvent it using recommended
practices.

1

1

2

3

4

5

6

7

8

9

10

11

12

13

14

15

16

17

18

19

20

21

22

23

24

25

26

27

28

29

30

31

32

33

34

35

36

37

38

39

40

41

42

43

44

45

46

47

48

49

50

51

52

53

54

55

56

57

58

59

60

61

62

63

64

65

66

67

68

69

70

71

72

73

74

75

76

Introduction

During the last few years, there has been an increased interest in reproducible computational science as
shown by the ﬂourishing literature on the topic (Peng, 2011; Sandve et al., 2013; Osborne et al., 2014;
Stodden et al., 2014), on good software practices (Nordlie et al., 2009; Donoho, 2011; Delescluse et al.,
2012; Wilson et al., 2014; Goble, 2014) and the newly created websites to ensure software sustainability
(recomputation.org, runmycode.org, etc.). These both illustrate the extent of the problem and the para-
doxical nature of the situation. While computer science oﬀers a large set of tools for prototyping, writing,
running, testing, validating, sharing and reproducing results, computational neuroscience still lags behind.
In the best case, authors may provide sources of their model as a compressed archive and feel conﬁdent
they contributed to reproducible computational neuroscience. But this is not exactly true. Buckheit and
Donoho (1995) explained almost 20 years ago that, an article about computational result is advertising, not
scholarship. The actual scholarship is the full software environment, code and data, that produced the result.
Anyone that ever open such compressed archive will plainly agree with this quote. How things went so bad ?
Part of the answer may be the ever growing place of software in modern Science, up to the point where new
research domains have emerged, mirroring their traditional counterpart with the computational adjective
(computational biology, computational neuroscience, computational geometry, etc.). Does this mean all of
a sudden everybody can write software ? Unfortunately no. If more than 50% of scientists admit to write
software according to a survey by Hannay et al. (2009), it is very unlikely that all of these people received
proper training to do so. This results in software of very diﬀerent quality and accessibility, but more impor-
tantly, this may also result in incorrect software. And if your software is incorrect, so will be your science
(Merali, 2010). This article aims at showing the full extent of the problem through the detailed story of
the reproduction of a computational model. It has been written in collaboration with the authors of the
original work, that allowed a full access to their archives and code and provides all the missing information
that grounded the research.

In a previous modeling study, Leblois et al. (2006) demonstrated an action selection mechanism in
cortico-basal ganglia loops based on a competition between the positive feedback, direct pathway through
the striatum and the negative feedback, hyperdirect pathway through the subthalamic nucleus. In Guthrie
et al. (2013), authors investigated further how multiple level action selection could be performed by the basal
ganglia, and the model has been extended in a manner consistent with known anatomy and electro-physiology
of the basal ganglia in the monkey. The model is quite complex, but such is the basal ganglia. Unfortunately,
the information provided by the latter article was not suﬃcient to allow for the direct reproduction of the
model. We explained in this article the precise diﬃculties we encountered and the reasons that lead us
to a complete rewrite of the model, trying to enforce best software practices. Following good software
practices, we were ultimately able to reproduce original results, conﬁrming the correctness of the original
implementation of the model. But we lost nearly three months in the process, while this should have been
a routine task.

Models

Original model

The initial version of the model (Leblois et al., 2006) was studied through analytical calculation (in a
reduced model of the network) and through numerical simulations (for the complete model including random
connectivity, heterogeneities and synaptic noise). The simulation programs were written in C code (by A.
Leblois), and, for some exploratory simulations, in Fortran (by D. Hansel). All the code used to run
simulations for the results and ﬁgures of (Leblois et al., 2006) was written in C. At that stage, analytical
calculation and simulations of the model could be reproduced simply from the equation and parameters
provided in the paper. The task would be relatively easy for the reduced model, but may take quite some
time for the extended model given the large number of parameters required to deﬁne network connectivity,

2

77

78

79

80

81

82

83

84

85

86

87

88

89

90

91

92

93

94

95

96

97

98

99

100

101

102

103

104

105

neuronal properties and inputs. The C code underlying the simulations of this complete model was not
written to be easily shared (no versioning, no public repository), and providing the raw code would therefore
be of partial help only. The later version of the model Guthrie et al. (2013) was developed in a collaboration
between authors of the original version (A. Leblois and T. Boraud) and a new post-doc (M. Guthrie).
The latter decided to use a graphical user interface (Delphi) to develop further the model, most likely due
to his speciﬁc coding history. This methodological decision had a rather negative impact on the further
development of the model: it was not possible for A. Leblois, who developed the initial version of the model,
to run the code and therefore he had limited access to the behavior of the new model as the architecture
complexity was incremented. It now turns out that this approach also impedes the reproducibility of the
model by other scientist. This was precisely the case for M. Topalidou and N. Rougier when they decided
to reproduce results of the article and soon realized that the information provided by the article was not
suﬃcient to reproduce the results.

Literal description

The literal description of the model is primarily addressed to a neuroscientist audience (it was published
in Journal of Neurophysiology) and assumes implicitly that readers are familiar with both neurophysiology
and neuroanatomy of the basal ganglia. For example, the detailed description of the nuclei is absent and
well know facts, such as the nature (excitatory or inhibitory) of this or that projection, are not mentioned.
While this might be obvious for experts, such absence makes the reproduction task more diﬃcult for non
experts, even if it is possible to somehow deduce this knowledge from various hints in the article. Overall,
the model is described quite precisely, with a lot of important information, but still, some information are
ambiguous or erroneous and some others are just missing. We report in this section the description of the
model as it has been proposed in the original article. We use gray boxes to indicate in extenso citation of
the original material.

Direction

e
u
C

Cortex

Thalamus

STN

Striatum

Cognitive

Motor

Associative

GPi

Figure 1: Architecture of basal ganglia model (left) and partial architecture of action selection model (right). Re-
produced with authors permission.

Ambiguous and erroneous information Throughout the whole article, the diﬀerent parts of the model
are described using neuron, ensemble or unit. This ambiguity is related to the fact that there are two pos-
sible interpretations of the rate model. Either it is used to represent a neuronal population, each ﬁring rate
variable being associated to the average activity over a large pool of neurons. Or it can be used to represent
the output (formally, the slow synaptic output) of a given neuron. In the case where connectivity between
populations is all-to-all, all neurons behave the same in one population, and the single variable represent

3

106

107

108

109

110

111

112

113

114

115

116

117

118

119

120

121

122

123

124

125

126

127

128

129

130

131

132

133

134

135

136

137

138

139

140

141

142

143

either the average ﬁring of the population or the activity of any of these neurons. In the original article,
ensemble is deﬁned as a set of co-activated neurons but units seems to be reserved for striatal units which
suggest striatal elements might be represented by a single neuron while other elements may need several
neurons. From the various ﬁgure describing the architecture of the model, it happens eventually an ensem-
ble is a represented by a single equation.

No units are given for the diﬀerent constants and reader has to guess the unit from the nature of the
variable. While this poses no problem for most variables and constants, there are some ambiguous situations.
For example, time constant tau has been set to a value of 10. Since this is a time constant used for synaptic
decay, we can deduce the actual value is 10 milliseconds or 0.01 second. However, this is far from evident
by looking at the sources because the actual dt variable has been set to 1ms and removed from equations
(implicit use of the forward Euler method).

The initialization of weights are deﬁned in two diﬀerent parts of the paper. First on page 3030 (second

column):

Weights were initialized to a Gaussian distribution with a mean of 0.5 and a SD of 0.005 at the start of each
simulation...

then on page 3031 in the caption of ﬁgure 4.

All synaptic weights were initialized to 0.5.

In fact, both deﬁnitions are right but do not address the same projections. Cortico-striatal synaptic

weights use Gaussian distribution while all other weights are set to 1.0.

Finally, the Boltzmann equation according to the paper is:

mout = Vmin ·







Vmax − Vmin
Vh − min
V c

1 + e







This deﬁnition is wrong according to the proper Bolzmann equation that use a + instead of a · . The
problem is even worse, because the article equation, when used with parameters given in table 3 of the
original article, is quite similar to the actual Bolzmann equation. This makes even more diﬃcult to spot the
error and only the change of parameters clearly indicate the equation is wrong.

Undisclosed information As explained previously, the model refers to two pathways, one direct and one
hyperdirect, but authors never explained what nuclei are involved or how they interact. For example, it is
not mentioned if GPi sends inhibitory or excitatory inputs to thalamus. The only reference exists in the
caption of the ﬁrst ﬁgure. Furthermore, the last sentence of the same caption and table 2 indicate that
cortex sends input to the thalamus but the gains used in the source code, are diﬀerent from the article.

The learning rule includes a Vi term which refers to the value of cue i. Knowing that each cue is associated
with a reward probability, it is legitimate at this stage to assimilate the two of them. However, it appears this
value is actually referring to the state value as deﬁned in reinforcement learning Sutton and Barto (1998).
This was far from obvious since these values were not deﬁned beforehand and their initial state is reported
nowhere. Only the knowledge of reinforcment learning methods helped us setting their initial state to 0.5.

4

144

145

146

147

148

149

150

151

152

153

154

155

156

157

158

159

160

161

162

163

164

165

166

Source description

Because we were unable to reproduce the model using article description, we proceeded with studying the
sources of the model that we requested from the authors. These sources are not available elsewhere and
we were lucky enough that authors still have a copy around. However, studying these sources, to try to
undersand how the model works, has been a very demanding task. The main reason is that the main project
ﬁle is 6000 lines long (using Pascal programming language) and mix the graphical user code with the actual
model simulation. Furthermore, in order to compile the model, we needed a Windows system, the Delphi 7
personal edition compiler suite (which is no more available from the editor) and various extra components
that were used for the graphical user interface. Even if we were able to gather most of these components, we
were not able to ﬁnd all of them and consequently, we did not manage to compile the model. However, having
these sources was still very useful because they allowed us to check for the implementation of this or that
equation. This is, for example, how we spotted the error on the Bolztmann equation and the initialization of
weights. It also helped us to ﬁnd out which set of parameters were used since the sources are accompanied
by several conﬁguration ﬁles (quite ill-named default.ini, default2.ini, etc.).

Executable

We had to turn to the actual executable and run it on a combination of Virtual Box and a 32 bits Windows
7 even though the original model has been developped using Windows XP, but we did not encounter any
compatibility issue. This binary executable came as a great help in understanding how the model actually
works (see ﬁgure 2) and allowed us to check for the activity of other structures and to compare the respective
implementations (original and our version). Unfortunately, such executable is quite limited in what you can
actually experiment, because it is dedicated to the main experimental paradigm. If we were able to tweak the
various parameters to check for the activity of this or that structure, we could not, for example, experience
lesion or new connectivity patterns. In other words, we could not escape the main experimental paradigm
that is hard-coded through the interface.

Figure 2: The executable of the original model provides a graphical user interface that allow to re-run the article
experiment and allows to tweak diﬀerent parameters.

5

167

168

169

170

171

172

173

174

175

176

177

178

179

180

181

182

183

184

185

186

187

188

189

190

191

192

193

194

195

196

197

198

199

200

201

202

203

204

205

206

207

208

Author’s interview

Ultimately, we were able to reach one of the original author (T. Boraud) in order to talk with him about the
model. This took the form of an interview and we had prepared a series of questions to be answered such
that we could reproduce the model. This was the ﬁnal stage of our journey. We ﬁnally had enough material
to start the reproduction of the model.

Revamped model

Before diving in the redesign of the model, we needed ﬁrst to gather relevant information into a formal
description following guidance of Nordlie et al. (2009) and to redesign ﬁgures of the model following rules
described in Rougier et al. (2014). All the sources (python scripts and notebooks) are available from https:
//github.com/rougier/Neurosciences/tree/master/basal-ganglia/guthrie-et-al-2013.

Description

The complete description of the model (architecture, connectivity and neuron model) is spread throuhghout
the whole article in a variety of forms (prose, equations, and ﬁgure). This has been identiﬁed as a source of
problems by Nordlie et al. (2009) and detrimental to the computational neuroscience ﬁeld. Authors suggests
instead good model description practices in order for a model to be reproduced easily. Most notably, they
propose a general guideline and checklist for a model description, but also propose templates for tables
describing the model. These tables allow both a precise and concise description of the model that are really
useful if one wants to reproduce the model or check the actual implementation (provided model sources has
been given) of the model. We gathered all available information (article & source) into a tabular description
given in appendix A.

Figures

There are mainly two ﬁgures describing the model in the original article. One is oﬀering a global view of the
model, emphasizing the cognitive and motor loops with an artistic style (see left part of ﬁgure 1). The other
one rather aims at specifying precisely what are the projections between the diﬀerent nuclei and makes use
of the model graphical user interface to do so. Since there is a lot of projections, this ﬁgure is actually split
into 6 sub-ﬁgures using a semantic that is not described but can be guessed (parallel/divergent/convergent
connections). We took a diﬀerent approach for this latter ﬁgure and used standard boxes and arrows
(circle/red/inhibitory, arrow/blue/excitatory) to indicate the existence and the nature of a projection while
the exact parameters of each projection are given in the appendix A.

Language

The ﬁrst step in the redesign of a model is to choose the proper modeling approach. Namely, one can
use a simulator (e.g. Neuron Carnevale and Hines (2006), Emergent O’Reilly and Y.Munakata (2000)), a
toolbox (e.g. Matlab, Mathematica), a library (e.g. Brian Goodman and Brette (2008), DANA Rougier and
Fix (2012)) or a programming language (e.g. C, Python). Each approach has its pros and cons and the
choice depends mainly on the expertise of the modeler and the modeling history of the team/lab. While a
simulator oﬀers many advantages (rapid prototyping, correctness of the model), a new model might not ﬁt
exactly the modeling paradigm. Toolboxes are more ﬂexibles since they oﬀer basic components that can be
assembled together to make the model, but correctness of the model is no longer guaranteed and depends on
the interaction of the diﬀerent components. At a lower level, modeling libraries are very similar to toolboxes
but oﬀer a uniﬁed approach that might save a lot of troubles. For example, the unit checking system of
Brian ensures that any equation is physically menaningful and hence saves a lot of time during the design
of new models. Last, but not least, one can choose to directly program the model from scratch, beneﬁting

6

External current

External current

External current

1:1

Cortex
motor

Cortex
associative

1:1

Cortex
cognitive

1:1

1:\*

1:1

1:\*

1:1

1:1

Striatum
motor

Striatum
associative

Striatum
cognitive

1:1

1:1

\*:1

\*:1

1:1

1:1

STN
motor

GPi
motor

1:1

GPi
cognitive

STN
cognitive

1:1

1:1

1:1

Thalamus
motor

Thalamus
cognitive

1:1

Figure 3: The ﬁgure describing the model architecture has been redesigned from the ground up in order to have
a unique ﬁgure showing all excitatory and inhibitory connections at once as well as the external current insertion
points. The color of a connection indicates its excitatory (blue) or inhibitory (red) nature and a label indicates if it
is a parallel (1:1), convergent (1:\*) or divergent (1:\*). All these informations are also given in the tabular description
of the model (Appendix A).

209

210

211

212

213

from a total freedom. Depending on the level of expertise of the designer, this can be a viable approach
but is prone to many errors (e.g. inconsistent variable type, use of the default random generator, improper
integration scheme, etc.). For the redesign of the model, we choose the DANA library (Rougier and Fix
(2012), https://github.com/rougier/dana) which is a Python library heavily inspired from Brian but
slanted towards mean-rate models. The main reason for such a choice is that last author is an expert in

7

214

215

216

217

218

219

220

221

222

223

224

225

226

227

228

229

230

231

232

233

234

235

236

237

238

239

240

241

242

243

244

245

246

247

248

249

250

251

252

253

254

255

256

257

Python and developed the DANA library which is open source, documented, tested and maintained. The
use of this library allowed us to reduce the model to a 200 lines Python script.

Version control

In any experimental laboratory, notebooks help to keep track of the daily activity. Such notebooks are
typically permanently bound (no ﬂying pages) with page numbered (one can notice if a page is missing)
and entries are timestamped and signed and such that an entry cannot be physically deleted. Even if such
notebook are scarcely shared, they are used by the experimentalist who wrote them to get back some info they
forgot. Legally, the notebook may attest that you did the experiment ﬁrst, and it is used to attest that you use
the right medications (for animale welfare). The digital equivalent for computational neuroscience is version
control using tools such as subversion (http://subversion.apache.org) or git (http://www.github.com).
These tools allow to keep track of changes, to know who did what/when, and to test new hypothesis very
easily by, for example, creating branches. In the end, one can read the logs to know what were the diﬀerent
steps to build the model or what were the errors. However, such tools are restricted to sources. If your
model is based on an external simulation software, you’ll dependent on whether the software oﬀers version
control or not.

Public repository

As explained earlier, we managed to contact the original authors and they were able to send us the original
source code. This was somehow expected since the model is barely two years old. However, for older models,
it might be very unlikely that authors can still be contacted or that they still have a copy of the model, if this
one has not be made public in the ﬁrst place. There are many ways to do that, a simple compressed archive
bundled with the supplementary materials on the journal website, a dedicated repository like, for example,
the Neuron database available at http://senselab.med.yale.edu/modeldb/. For our revamped model, we
decided from the start to make it available on github which oﬀer a web-based framework for collaboration,
code review, and code management and yields several advantages. First, all the repositories are public by
default and anyone can look directly at a speciﬁc project as well as its commit history (however, this public
nature is not always desirable). Furthermore, anyone can fork the project by hitting a single button and
starts working on his own personal version of the model. Also, if some changes or bug ﬁxed are worth to be
added to the main repository, it is possible to issue a pull request that tell the original authors what is the
purpose of this pull request and what would be changed (see ﬁgure 4). At this point, it is possible to discuss
the pros and cons of this or that change before merging it into the main repositoty. Once this is done, the
contribution will be recorded inside logs.

Interface

The IPython notebook (P´erez and Granger, 2007) is a web-based interactive computational environment
where you can combine code execution, text, mathematics, plots and rich media into a single document. This
allows easy collaroration with colleagues since the notebook can be exported to various formats (HTML, pdf,
etc.) or directly shared online using a static version. One of the strength of the notebook is that it allows
to mix code, ﬁgures and elaborated comments into a single document. For example, the equation governing
a potential can be inserted in extenso (using LATEX language) and the result is a self-contained document
with code, results and explanations. The model has been made also available as a notebook such that it is
a self-contained interactive document, mixing model deﬁnition and explanation.

Results

The ﬁnal step in our journey has been to check if results could be reproduced faithfully. Due to the diﬃculty
in the redesign of the model, this has been split in two phases. First, we checked if a single trial could
be qualitatively reproduced in terms of dynamic (oscillations during settling) and decision (does a decision

8

Figure 4: Screenshot of the github interface showing a discussion on a pull request (https://github.com/rougier/
Neurosciences/pull/1). Before merging modiﬁcations into the model, it is possible to discuss and comment to
improve the proposed modiﬁcation.

258

259

260

261

262

263

264

265

actually occurs in the cognitive and motor structures). We then proceeded to the learning task in order to
reach asymptotic performances.

Single trial

A trial lasts for exactly three seconds, including a settling phase of 500ms with no external input. During
this settling phase, there appear some characteristic damped oscillations that stabilizes just before the actual
start of the trial (see ﬁgure 5). At time t=500ms, cues are presented to the model in the form of external
activity that feed the cognitive and motor areas. The activity of the associative cortex receives proper
external activity in order to disambiguate correspondence between shape and position (no binding problem).

9

Figure 5: Activity in the cortical populations (blue for motor, red for cognitive) during a single trial.

266

267

268

269

270

271

272

273

274

275

276

277

278

279

280

281

282

283

284

285

286

287

288

Cognitive and motor neurons that are not fed by the external input decrease their activity to the resting
potential while the fed ones increases their activity. After 750ms, the activity of the active neurons start to
diverge in both cognitive and motor groups. For a decision to be considered to have occurred, there must
be a signiﬁcant diﬀerence (40Hz) which happens around 1250ms for both cognitive and motor groups. The
trial stops at 2500ms and the model can return to the resting state in 500 ms. The original article provided
a single ﬁgure with the activity of both cortical cognitive and motor structures, although it was essential for
us to check the activity of other structures during a single trial as shown on ﬁgure 7 in the appendix.

Learning

According to the original protocol, learning has been tested over 120 consecutive trials. However, there was
missing information about the exact protocol and we assumed the following elements:

• We assumed an exact uniform target distribution (each target appears exactly 60 times). This has

been implemented by shuﬄing an array holding all the targets pairs.

• We implemented an explicit resetting phase between trials to ensure we have no trailing activities from

previous trial.

• Learning occurs at the end of the trial, if and only if a motor decision has been made by the model.

• Trials where no motor decision has occurred (diﬀerence of activity is less than 40Hz) have been dis-

carded.

The learning protocol has been averaged over 250 simulations of 120 trials. Performance has been calculated
as the ratio of correct motor decisions, independently of the cognitive decision. This means that if the model
chose the wrong shape (cognitive decision) but the right move (motor decision), this results in reaching the
right target. Since there is no way to disambiguate such double errors in the monkey, we assumed this should
be counted as a correct answer. The asymptotic performance of the revamped model is approximately 97%,
to be compared with the 96% performance of the original model.

10

289

290

291

292

293

294

295

296

297

298

299

300

301

302

303

304

305

306

307

308

309

310

311

312

313

314

315

316

317

318

319

320

321

322

323

324

325

326

327

328

329

330

331

332

333

334

335

336

337

Discussion

Computational neuroscience is a powerful ally in our quest to understand the brain. Even the most simple
model can shed light on the role of this or that structure and propose new hypothesis concerning the overall
brain organization. The model we studied and reproduced in this paper, while simple, is able to explain to
some extents how the motor and the cognitive cortico-basal ganglia loops interact during decision making.
However, any model in Science is doomed to be proved wrong or incomplete and replaced by a more accurate
one (Box and Draper, 1987). In the meantime, for such replacement to happen, we have ﬁrst to make sure
it is actually reproducible such that it can be tested, evaluated, criticized and ultimately modiﬁed, replaced
or even rejected. This is where the shoe pinches. If we cannot reproduce a model in the ﬁrst place, we’re
doomed to re-invent the wheel again and again and we won’t be able to build an incremental computational
knowledge of the brain. In this short article, we tried to show the extent of the problem and the precise
diﬃculties that arise when one want to reproduce a computational model using a singular example. However,
from our own experience, this is not an isolated case, even though there are few cases where the model can be
reproduced in a straightforward way as we did for Gurney et al. (2001) and Girard et al. (2008). We believe
the revamped model we proposed allows any researcher in computational neuroscience to run it and obtain
the exact same results as the ones introduced in this article. Some colleagues already have shown interest in
the revamped model because they failed at reproducing the original one. Furthermore, the new description,
as well as the new ﬁgures, allow anyone to rewrite the model using diﬀerent language, tools or software.
To obtain such reproducible results, we merely applied precepts that are now widely available in the litter-
ature Nordlie et al. (2009); Peng (2011); Osborne et al. (2014); Delescluse et al. (2012); Stodden et al. (2014).

From a broader perspective, this singular experience into reproducible neuroscience raises some questions
about the whole publication process. While it has been true for a long time that article were actually printed,
it is more and more common to download and read articles in electronic form only. In such context, does it
really make sense any more to have supplementary materials as a separate document while they may carry
critical information for the reproduction of the result ? We think instead, any supplementary materials car-
rying important information for the reproduction of the model should be attached with the main document.
Furthemore, for the computational part, it is quite surprising that there is still no oﬃcial journal source
repository. A simple dedicated account on github (or any similar website such as sourceforge, gitlab, etc.)
would be an extremely valuable resources for researchers as it would provide a unique entry point for any
published model. It could even be hosted on the journal website since most repository oﬀers deployment of
enterprise edition. The next step in that direction would be to have online repository of virtual machines
where model could be directly ran and modiﬁed from within a web browser. This is what is currently ex-
perienced on the recomputation.org website where the ﬁrst recomputable experiments from ECAI 2014
have been made available using a combination of downloadable virtual machines (www.virtualbox.org) and
vagrant environments (www.vagrantup.com). Of course, such virtual machines solution would prohibit the
use of non free software and this could penalize a lot of authors. But such non-free software equally penalizes
reviewers and readers, when it is necessary, for example, to buy several 500$ toolboxes to run a single model.

Finally and given the quality of the new tools available today, it may be time to envisage new formats
for communicating results. For example, interactive documents could allow to replay a simulation and mod-
ify parameters while reading the description of a model or simulation. The IPython notebook is a serious
candidate in that direction and could soon become a new way to exchange knowledge. It has been recently
highlighted on Nature (Shen, 2014) and it is already widely used for teaching. Furthermore, interactive books
are now available at nbviewer.ipython.org that allow to tweak the parameters of a simulation in order
to get a deeper understanding of the concepts being introduced. It is probably a matter of months before
no one can tell the diﬀerence between a regular document (PDF) and an interactive one living in the browser.

Such new formats would deﬁnitely help authors, reviewers, readers and ultimately, Science as a whole.

11

Figure 6: Screenshot of the IPython notebook implementing the model. Title and abstract are part of the notebook
and have been written using markdown cell type.

338

339

340

341

Supporting Information

Model description

Notebook

Additional results

References

G.E.P. Box and N.R. Draper. Empirical Model Building and Response Surfaces. John Wiley & Sons, New York, 1987.

12

A Model Summary
Populations

Topology
Connectivity
Neuron model
Channel model
Synapse model
Plasticity
Input
Measurements

Twelve: Cortex (motor, associative & cognitive), Striatum (motor, associative & cogni-
tive), GPi (motor & cognitive), STN (motor & cognitive), Thalamus (motor & cognitive)
–
one to one, one to many (divergent), many to one (convergent)
Dynamic rate model
–
Linear synapse
Reinforcement learning rule
External current in cortical areas (motor, associative & cognitive)
Firing rate

B Populations
Name
Cortex motor
Cortex cognitive
Cortex associative
Striatum motor
Striatum cognitive
Striatum associative
GPi motor
GPi cognitive
STN motor
STN cognitive
Thalamus motor
Thalamus cognitive
Values (Vi)

Elements
Linear neuron
Linear neuron
Linear neuron
Sigmoidal neuron
Sigmoidal neuron
Sigmoidal neuron
Linear neuron
Linear neuron
Linear neuron
Linear neuron
Linear neuron
Linear neuron
Scalar

-3
-3
-3
0
0
0

Size Threshold (h) Noise
1 × 4
4 × 1
4 × 4
1 × 4
4 × 1
4 × 4
1 × 4 +10
4 × 1 +10
-10
1 × 4
-10
4 × 1
-40
1 × 4
-40
4 × 1
–
4

1.0%
1.0%
1.0%
0.1%
0.1%
0.1%
3.0%
3.0%
0.1%
0.1%
0.1%
0.1%
–

Initial state
0.0
0.0
0.0
0.0
0.0
0.0
0.0
0.0
0.0
0.0
0.0
0.0
0.5

C Connectivity
Target
Source
Thalamus motor
Cortex motor
Thalamus cognitive
Cortex cognitive
STN motor
Cortex motor
STN cognitive
Cortex cognitive
Striatum motor
Cortex motor
Striatum cognitive
Cortex cognitive
Striatum associative
Cortex motor
Striatum associative
Cortex cognitive
Striatum associative
Cortex associative
Cortex motor
Thalamus motor
Cortex cognitive
Thalamus cognitive
Thalamus motor
GPi motor
Thalamus cognitive
GPi cognitive
GPi motor
STN motor
GPi cognitive
STN cognitive
GPi cognitive
Striatum cognitive
Striatum motor
GPi motor
Striatum associative GPi motor
Striatum associative GPi cognitive

Pattern
(1, i) → (1, i)
(i, 1) → (i, 1)
(1, i) → (1, i)
(i, 1) → (i, 1)
(1, i) → (1, i) N (0.5, 0.005)
(i, 1) → (i, 1) N (0.5, 0.005)
(1, i) → (∗, i) N (0.5, 0.005)
(i, 1) → (i, ∗) N (0.5, 0.005)
(i, j) → (i, j) N (0.5, 0.005)
(1, i) → (1, i)
(i, 1) → (i, 1)
(1, i) → (1, i)
(i, 1) → (i, 1)
(1, i) → (1, i)
(i, 1) → (i, 1)
(i, 1) → (i, 1)
(i, 1) → (i, 1)
(∗, i) → (1, i)
(i, ∗) → (i, 1)

Weight (W) Gain (G) Plastic
0.4
1.0
0.4
1.0
1.0
1.0
1.0
1.0
1.0
1.0
0.2
0.2
1.0
1.0
1.0
-0.5
-0.5
1.0
1.0
-2.0
-2.0
-2.0
-2.0

No
No
No
No
No
Yes
No
No
No
No
No
No
No
No
No
No
No
No
No

1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0

13

D1 Neuron Model
Name
Type
Membrane Potential

D2 Neuron Model
Name
Type
Membrane Potential

Linear neuron
Rate model
τ dV /dt = −V + Isyn + Iext − h
U = max(V, 0)

Sigmoidal neuron
Rate model
τ dV /dt = −V + Isyn + Iext − h
U = Vmin − (Vmax − Vmin)/ (cid:16)1 + e

Vh−V
Vc (cid:17)

E Synapse
Name
Type
Output

Linear synapse
Weighted sum
I B
syn =

PA∈sources(GA→BWA→BUA)

F Plasticity
Name Reinforcement learning
Type
Delta ∆WA→B = α × P E × UB

Delta rule

P E = Reward − Vi
α = 0.01 if P E < 0 (LTD), α = 0.02 if P E > 0 (LTP)

Cortical input

G Input
Type
Description A trial is preceded by a settling period (500ms) and followed by a reset period. At time
t = 0, two shapes are presented in cortical cognitive area (Iext = 7 at {i1, i2}) at two
diﬀerent locations in cortical motor area (Iext = 7 at {j1, j2}) and the cortical associate
area is updated accordingly (Iext = 7 at {i1, i2} × {j1, j2}).
Trial start

Stimulus oﬀset

Stimulus onset

Reset

Timing

-500ms

0

2500 ms

3000 ms

H Measurements
Site
Data Activity in cognitive and motor cortex

Cortical areas

Cortico-striatal weights

I Environment
OS
Language Python 2.7.6 (brew installation)
Libraries

OSX 10.9 (maverick)

Numpy 1.8.1 (pip installation)
SciPy 0.13.3 (pip installation)
IPython 1.2.1 (pip installation)
Matplotlib 1.3.0 (pip installation)
DANA 0.5.1 (pip installation)
Safari browser (native)

Tools

Table 1: A tabular description of the model following the prescription of Nordlie et al. (2009).

14

Figure 7: The activities of the non-cortical groups during a single trial were not provided in the original manuscript.
However, we found these activitites to be extremely useful for understanding the dynamic of the model. Knowing the
overall shape of the diﬀerent activities in the model, even without precise details, allows to quickly spot problems.
For example, using these acivities, we know what are the bounds for the activities in each area and as soon as one of
our activity is out of bounds, we’ll know something is wrong.

J. Buckheit and D.L. Donoho. Wavelets and Statistics, chapter Wavelab and reproducible research. Antoniadis, A.,

1995.

N.T. Carnevale and M.L. Hines. The NEURON Book. Cambridge University Press, 2006.

Matthieu Delescluse, Romain Franconville, S´ebastien Joucla, Tiﬀany Lieury, and Christophe Pouzat. Making neuro-
physiological data analysis reproducible. why and how ? Journal of Physiology (Paris), 106(3–4):159–170, 2012.

D.L. Donoho. An invitation to reproducible computational research. Biostatistics, 11(3):385388, 2011. doi: 10.1093/

biostatistics/kxq028.

B. Girard, N. Tabareau, Q. Pham, A. Berthoz, and J. Slotine. Where neuroscience and dynamic system theory meet
autonomous robotics : a contracting basal ganglia model for action selection. Neural Networks, 21(4):628–641,
2008.

C. Goble. Better software, better research. IEEE Internet Computing, 2014.

D. Goodman and R. Brette. Brian: a simulator for spiking neural networks in python. Frontiers in Neuroinformatics,

2(5):1–10, 2008. ISSN 1662-5196.

K. Gurney, T. Prescott, and P. Redgrave. A computational model of action selection in the basal ganglia. i. a new

functional anatomy. Biological cybernetics, 84(6):401–410, 2001.

15

010203040506070STNMOTOR010203040506070COGNITIVEASSOCIATIVE0102030405060CORTEX010203040506002468101205101520STRIATUM051015200246810020406080100120GPi020406080100120051015202530354045THALAMUS051015202530354045M. Guthrie, A. Leblois, A. Garenne, and T. Boraud. Interaction between cognitive and motor cortico-basal ganglia

loops during decision making: a computational study. Journal of Neurophysiology, 109:3025–3040, 2013.

J.E. Hannay, H.P. Langtangen, C. MacLeod, D. Pfahl, J. Singer, and G. Wilson. How do scientists develop and use
scientiﬁc software? In MIT Press, editor, Software Engineering for Computational Science and Engineering, 2009.

A. Leblois, T. Boraud, W. Meissner, H. Bergman, and D. Hansel. Competition between feedback loops underlies

normal and pathological dynamics in the basal ganglia. Journal of Neurosciences, 26:3567–3583, 2006.

Z. Merali. Computational science: ... error ... why scientiﬁc programming does not compute. Nature, 467:775–777,

2010.

E. Nordlie, M. Gewaltig, and H.E. Plesser. Towards reproducible descriptions of neuronal network models. PLoS

Computational Biology, 5(8):e1000456, 2009. doi: 10.1371/journal.pcbi.1000456.

R.C. O’Reilly and Y.Munakata. Computational Explorations in Cognitive Neuroscience: Understanding the Mind by

Simulating the Brain. MIT Press, Cambridge, MA, USA, 2000.

J.M. Osborne, M.O. Bernabeu, M. Bruna, B. Calderhead, J. Cooper, N. Dalchau, S. Dunn, A.G. Fletcher, R. Freeman,
D. Groen, B. Knapp, G.J. McInerny, G.R. Mirams, J. Pitt-Francis, B. Sengupta, D.W. Wright, C.A. Yates, D.J.
Gavaghan, S. Emmott, and C. Deane. Ten simple rules for eﬀective computational research. PLoS Computational
Biology, 10(3):e1003506, 2014. doi: 10.1371/journal.pcbi.1003506.

R.D. Peng. Reproducible research in computational science. Science, 334(6060):1226–1227, 2011.

Fernando P´erez and Brian E. Granger. IPython: a system for interactive scientiﬁc computing. Computing in Science

and Engineering, 9(3):21–29, 2007. ISSN 1521-9615. doi: 10.1109/MCSE.2007.53.

N.P. Rougier and J. Fix. Dana: Distributed numerical and adaptive modelling framework. Network: Computation

in Neural Systems, 23(4), 2012.

N.P. Rougier, M. Droettboom, and P.E. Bourne. Ten simple rules for better ﬁgure. PLOS Computational Biology,

10(9), 2014.

G.K. Sandve, A. Nekrutenko, J. Taylor, and E. Hovig. Ten simple rules for reproducible computational research.

PLoS Computational Biology, 9(10):e1003285, 2013. doi: doi:10.1371/journal.pcbi.1003285.

Helen Shen. Interactive notebooks: Sharing the code. Nature, (515):151–152, 2014.

V. Stodden, F. Leisch, and R.D. Peng, editors. Implementing Reproducible Research. Chapman & Hall/CRC, 2014.

Richard S. Sutton and Andrew G. Barto. Reinforcement Learning: An Introduction. MIT Press, Cambridge, MA,

1998.

G. Wilson, D. A. Aruliah, C.T. Brown, N.P. Chue Hong, M. Davis, R.T. Guy, S.H.D. Haddock, K.D. Huﬀ, I.M.
Mitchell, M.D. Plumbley, B. Waugh, E.P. White, and P. Wilson. Best practices for scientiﬁc computing. PLOS
Biology, 12(1), 2014.

16

