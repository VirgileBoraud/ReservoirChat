Formation à l’IA -épisode 3 : Class’Code / Inria IAI Frédéric Alexandre,
Marie-Hélène Comte, Martine Courbin-Coulaud, Bastien

Masse

To cite this version:

Frédéric Alexandre, Marie-Hélène Comte, Martine Courbin-Coulaud, Bastien
Masse. Formation à l’IA -épisode 3 : Class’Code / Inria IAI. 2021.
￿hal-03120951v2￿

HAL Id: hal-03120951

https://inria.hal.science/hal-03120951v2

Submitted on 26 Jan 2021

HAL is a multi-disciplinary open access archive for the deposit and
dissemination of sci- entific research documents, whether they are pub-
lished or not. The documents may come from teaching and research
institutions in France or abroad, or from public or private research
centers.

L’archive ouverte pluridisciplinaire HAL, est destinée au dépôt et à la
diffusion de documents scientifiques de niveau recherche, publiés ou
non, émanant des établissements d’enseignement et de recherche français
ou étrangers, des laboratoires publics ou privés.

Distributed under a Creative Commons Attribution 4.0 International
License

Formation à l’IA - épisode 3 : Class’Code / Inria IAI

Publié sur
https://www.lemonde.fr/blog/binaire/2021/01/26/formation-a-lia-episode-3-
classcode-iai/

Nous vous l’avions annoncé ici, Victor Storchan termine la série
d’articles sur les initiatives de formation à l’intelligence
artificielle (IA). Après “Elements Of AI”, et “Objectif IA”, il donne la
parole à Frédéric Alexandre, Marie-Hélène Comte, Martine Courbin-Coulaud
et Bastien Masse sur Class´Code IAI. Serge Abiteboul et Thierry
Viéville.

La formation/certification à l’IA Victor Storchan (VS): Quelles ont été
vos motivations initiales et vos objectifs pour l’élaboration de votre
cours en ligne ?

L’équipe de Class´Code (CC): Il s’agit d’offrir une initiation à
l’Intelligence Artificielle via une formation citoyenne, gratuite et
attestée https://classcode.fr/iai, dans le cadre d’une perspective «
d’Université Citoyenne et Populaire en Sciences et Culture du Numérique
» où chacune et chacun de la chercheuse au politique en passant par
l’ingénieure ou l’étudiant venons avec nos questionnements, nos savoirs
et savoir-faire à partager.

Très concrètement on y explique ce qu’est l’IA et ce qu’elle

n’est pas, comment ça marche, et quoi faire ou pas avec. On découvre les
concepts de l’IA en pratiquant des activités concrètes, on y joue par
exemple avec un réseau de neurones pour en démystifier le
fonctionnement. On réfléchit aussi, ensemble, à ce que le développement
de l’IA peut soulever comme questions vis-à-vis de l’intelligence
humaine.

Ce MOOC a été développé sur la plateforme FUN par le Learning Lab Inria
qui en assure l’animation.

VS: Quel est le public que vous visez ?

CC: La cible primaire est l’ensemble des personnes en situation
d’éducation : enseignant·e, animateur·e

et parents, qui doivent comprendre pour re-partager ce qu’est l’IA.
C’est —par exemple— abordé au

lycée dans les cours de sciences de 1ère et terminale, c’est abordé de
manière transversale dans les

enseignements d’informatique et présent dans de nombreux ateliers
extra-scolaires.

Par extension, toutes les personnes qui veulent découvrir ce qu’est
l’IA et se faire une vision claire des défis et enjeux posés, ceci en
“soulevant le capot”, c’est-à-dire en comprenant comment ça marche, sont
bienvenues. Et c’est de fait une vraie formation citoyenne.

VS: Quels sont les apports de votre cours pour ce public ?

Ce qui rend ce cours attrayant est une approche ludique et pratique avec
une diversité de ses supports – vidéos conçues avec humour, tutos et
activités pour manipuler (y compris avec des objets du quotidien) les
mécanismes sous-jacents, des ressources textuelles pour aller plus loin,
et des exercices pour s’évaluer. Toutes ces ressources sont
réutilisables.

Ce qui rend ce cours unique, par rapport aux autres offres connues, est
un forum pour échanger et des webinaires et rencontres en ligne ou en
présentiel sur ces sujets, à la demande des personnes participantes : la
formation sert de support pour des rencontres avec le monde de la
recherche. Cette possibilité de dialogue direct entre personnes
participantes, de proposer des ressources ou des liens en fonction des
besoins est vécu comme un point majeur de cette formation.

VS: Pouvez-vous partager les premiers résultats à ce stade et quelles
sont vos perspectives futures ?

CC: Ouvert en avril 2020, le MOOC Class’Code IAI “Intelligence
Artificielle avec Intelligence” a attiré jusqu’à présent (mi-novembre)
plus de 18800 personnes, dont beaucoup ont effectivement profité d’au
moins un élément de la formation et délivré 1038 attestations de suivi.
Il y a plus de 5300 personnes sur le forum et près de 600 messages
échangés, beaucoup entre l’équipe pédagogique et les personnes
participantes, mais aussi entre elles. Nos mooqueurs et mooqueuses se
disent satisfaits à plus de 94%. Les rencontres en ligne attirent entre
50 et 100 personnes et sont vues par plusieurs centaines en replay.

Les vidéos sont réutilisées au sein de plusieurs ressources numériques
en lien avec les manuels d’apprentissage des sciences en première et
terminale qui inclut le sujet de l’IA ou sur le site lumni.fr de France
Télévision (qq milliers de vues, mais pas de comptage précis).

Au niveau des perspectives, nous invitons les personnes à suivre ensuite
par exemple Elements Of AI course.elementsofai.com/fr-be dans sa version
francophone, pour se renforcer sur des éléments plus techniques, tandis
que notre action s’inscrit dans la perspective de cette université
citoyenne déjà citée.

VS: Comment vos ressources participent-elles à la création d’une
confiance dans le développement de ces innovations, et aident-elles à
développer un esprit critique constructif à ces sujets ?

Nous avons deux leviers principaux.

Le premier est de dépasser les idées reçues (les “pourquoi-pas”) sur ce
sujet et d’inviter à distinguer les croyances, les hypothèses
scientifiques (qui pourront être infirmées, contrairement aux croyances
qui ne seront jamais ni fausses, ni vraies), des faits avérés. Pour
développer l’esprit scientifique il est particulièrement intéressant de
montrer que, à l’instar de l’astrologie par exemple, il y a dans le
domaine de l’IA l’émergence d’une pseudo-science qu’il faut expliciter
et dépasser.

Le second est de “comprendre pour pouvoir en juger”. Nous voulons aider
les personnes à avoir une vision opérationnelle de ce qu’est l’IA, pas
uniquement des mots pour en parler, de façon à réfléchir en profondeur
sur ce qu’elle peut apporter.

Motivé par la déclaration commune artificielle juste, solidaire et
centrée sur l’humain” nous pensons que la première étape est d’instruire
et donner les moyens de s’éduquer.

franco-finlandaise de “promouvoir une vision de l’intelligence

Une analyse plus précise est donnée ici expliquant la démarche d’ « Open
Educational Resources and MOOC for Citizen Understanding of Artificial
Intelligence »

Le projet entrepreneurial VS: Quelles difficultés surmonte-t-on pour
déployer un projet comme celui-ci ?

 CC: Au niveau des moyens, forts de la réussite du projet Class ´Code
nous avons été soutenus sans souci par des fonds publics et avons eu les
moyens des objectifs choisis.

Au niveau de la diffusion, il est moins facile de faire connaître notre
offre qui est peu relayée médiatiquement, car le message est moins
“sensationnel” que d’autres, nous construisons notre notoriété
principalement sur les retours des personnes qui ont pu en bénéficier.

Au niveau des personnes, le principal défi est d’apaiser les peurs et
d’aider à dépasser les idées reçues, parfois les fantasmes sur ces
sujets : l’idée d’une intelligence qui émergerait d’un dispositif
inanimé de la légende de Pinocchioau mythe du Golem est ancrée dans nos
inconscients et c’est un obstacle à lever.

VS: Quels sont les bénéfices de la coopération entre partenaires de
votre initiative, en particulier pour la réalisation d’un cours sur l’IA
par nature interdisciplinaire ?

CC: Ils sont triples.

D’une part en associant des compétences académiques en sciences du
numérique, neurosciences cognitives et sciences de l’éducation on se
donne vraiment les moyens de bien faire comprendre les liens entre
intelligence artificielle et naturelle, et d’avoir les bons leviers pour
permettre d’apprendre à apprendre.

Par ailleurs, à travers Class´Code et plus de 70 de ses partenaires, on
donne les moyens aux initiatives locales, associatives ou structurelles
de disposer de ressources de qualité et de les co-construire avec elles
et eux, pour être au plus près du terrain. Notre collaboration avec des
entreprises d’éducation populaire de droit public comme La Ligue de
l’Enseignement ou de droit privé comme Magic Maker, ou des clusters
d’entreprise EdTech comme celles d’EducAzur montre aussi que les
différents modèles économiques ne s’excluent pas mais se renforcent sur
un sujet qui est l’affaire de toutes et tous.

La collaboration avec la Direction du Numérique pour l’Education et
l’Université Numérique d’Ingéniérie et de Technologie permet de se
positionner comme fournisseur de ressources pour l’apprentissage à
grande échelle de ces sujets, en mettant en partage un bien commun.

Les modèles d’écosystèmes français VS: Au-delà de la formation, quels
sont les atouts et les faiblesses de l’Europe pour peser dans la
compétition technologique mondiale ?

CC: Il y a de multiples facteurs qui dépassent notre action. Mais
relevons en un qui nous concerne directement : celui d’éduquer au
numérique et ses fondements, que nous discutons ci-dessous.

VS: Votre initiative crée donc un lien éducation et IA, quels sont les
liens à renforcer entre IA et éducation (par exemple apprentissage de
l’IA dans le secondaire) et éducation et IA (par exemple des assistants
algorithmiques), et quels sont les impacts socio-économiques visés ?

CC: Les liens entre IA et éducation sont doubles : éduquer par et au
numérique comme on le discute ici en explicitant les liens entre IA et
éducation au-delà des idées reçues qui sont bien décryptées montrant les
limites de l’idée que le numérique va révolutionner l’éducation. Nous
nous donnons avec ce MOOC IAI les moyens pour que nos forces citoyennes
soient vraiment prêtes à relever ces défis. L’apprentissage scolaire de
l’informatique est un vrai levier et un immense investissement pour
notre avenir, et la France a fait ce choix d’enseigner les fondements du
numérique pour maîtriser le numérique.

À ce sujet Inria publie un livre blanc « Éducation et numérique, Défis
et enjeux » qui discute de ces aspects tout particulièrement en lien
avec l’IA, tandis que l’Éducation Nationale met en place des groupes
thématiques numériques (GTnum) animés conjointement par des équipes de
recherche et des pédagogues, par exemple sur le « renouvellement des
pratiques numériques et usages créatifs du numérique en lien avec l’IA
».

VS: Confier à des algorithmes des tâches qui mènent à des décisions
cruciales, par exemple en matière de justice, d’embauche, ou d’autres
décisions à forte conséquence humaine, questionne, quel est votre
positionnement sur ce sujet ? Quelle place pensez-vous que l’éthique
doit prendre dans votre enseignement ?

CC: Pouvoir se construire une éthique, c’est-à-dire se forger un
jugement moral sur ce qu’il convient de faire ou pas avec l’IA, est en
quelque sorte l’aboutissement de cette formation. Là encore cela passe
par la compréhension de notions fines comme interprétabilité et
explicabilité ou les causes des biais dans les mécanismes d’IA venant
des données ou des algorithmes pour ne pas juste émettre des opinions
superficielles à ce sujet. Aucun sujet technique n’est abordé sans que
ces aspects éthiques ou sociétaux le soient comme c’est le cas en
robotique.

D’un point de vue éthique, la responsabilité est toujours “humaine”, par
exemple si on laisse l’algorithme décider, c’est notre décision de le
faire : de déléguer la décision à un algorithme au lieu de la prendre
soi-même, c’est un choix et c’est un humain qui doit faire ce choix. Si
vous choisissez de “faire confiance” à une machine avec un algorithme
d’IA, vous faites surtout confiance en votre propre jugement quant aux
performances de ce mécanisme.

VS: Le fait que des tâches cognitives de plus en plus complexes soient
réalisées par des programmes nous amène-t-il à reconsidérer
l’intelligence humaine ? Est-ce que cela a des impacts sur notre vision
de l’IA ? Sur son enseignement ?

CC: C’est tout à fait le cas. On se pose souvent la question
“symétrique” de savoir si une machine peut être ou devenir intelligente
: le débat est interminable, car -en gros- il suffit de changer la
définition de ce que l’on appelle intelligence pour répondre “oui,
pourquoi-pas” ou au contraire “non, jamais”. La vraie définition de l’IA
est de “faire faire à une machine ce qui aurait été intelligent si
réalisé par un humain”, ce qui évite de considérer cette question mal
posée.

[caption id=“attachment_11836” align=“alignright” width=“293”]
©cointre[/caption]

En revanche, avec la mécanisation de processus cognitifs, ce qui
paraissait “intelligent” il y a des années par exemple, le calcul mental
devient moins intéressant avec l’apparition -dans ce cas- de
calculettes. De même l’intelligence artificielle soulage les humains de
travaux intellectuels que l’on peut rendre automatiques. Du coup, cela
oblige à réfléchir à l’intelligence humaine en fonction et au- delà de
ce que nous appelons la pensée informatique.

Par exemple, nous savons que plus le problème à résoudre est spécifique,
plus une méthode algorithmique sera efficace, possiblement plus que la
cognition humaine, tandis qu’à l’inverse plus le problème à résoudre est
général, moins un algorithme ne pourra intrinsèquement être performant,
quelle que soit la solution (no free lunch theorem). Il se trouve que
les systèmes biologiques eux aussi ont cette restriction, l’intelligence
humaine n’est donc peut-être pas aussi “générale” qu’on ne le pense.

VS: Nous vivons au temps des algorithmes. Quelle place voulons-nous
accorder aux algorithmes dans la “cité” ? Est-ce que cela nous conduit à
repenser cette cité ? Comment mieux nous préparer au monde de demain ?

CC: En formant en profondeur les citoyennes et citoyens, nous nous
donnerons « les moyens de construire un outil qui rend possible la
construction d’un monde meilleur, d’un monde plus libre, d’un monde plus
juste … » écrivent Gilles Dowek et Serge Abiteboul en conclusion du
“temps des algorithmes”.

Que des robots assistent des personnes âgées pour reprendre leur
exemple, sera un progrès, permettant de les maintenir chez eux, à leur
domicile et dans l’intimité de leur dignité, mais si cela est vu
uniquement comme un levier de réduction des coûts de prise en charge, ou
un moyen de nous désengager d’une tâche parmi les plus humaines qui soit
à savoir s’occuper des autres, alors la machine nous déshumanisera.

Cet exemple nous montre surtout, comme la crise sanitaire le fait aussi
depuis quelques mois, que des circonstances exceptionnelles nous
obligent à revoir en profondeur les équilibres que nous pensions acquis
pour notre société. Quand, et cela est en train d’advenir, nous aurons
mécanisé la plupart des tâches professionnelles qui sont les nôtres
aujourd’hui, nous allons devoir organiser autrement la société.

Frédéric Alexandre, Équipe Mnemosyne Inria

Marie-Hélène Comte, Learning-Lab Inria

Martine Courbin-Coulaud Mission de Médiation Scientifique Inria

Bastien Masse Université de Nantes.

Grand merci à Inria Learning Lab pour avoir porté et adapté le MOOC sur
FUN ainsi que pour le forum.


