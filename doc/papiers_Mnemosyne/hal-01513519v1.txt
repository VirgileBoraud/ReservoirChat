Motivated Self-Organization Nicolas P. Rougier, Yann Boniface

To cite this version:

Nicolas P. Rougier, Yann Boniface. Motivated Self-Organization. 12th
International Workshop on Self-Organizing Maps and Learning Vector
Quantization, , Jun 2017, Nancy, France. ￿hal-01513519￿

HAL Id: hal-01513519

https://inria.hal.science/hal-01513519

Submitted on 25 Apr 2017

HAL is a multi-disciplinary open access archive for the deposit and
dissemination of sci- entific research documents, whether they are pub-
lished or not. The documents may come from teaching and research
institutions in France or abroad, or from public or private research
centers.

L’archive ouverte pluridisciplinaire HAL, est destinée au dépôt et à la
diffusion de documents scientifiques de niveau recherche, publiés ou
non, émanant des établissements d’enseignement et de recherche français
ou étrangers, des laboratoires publics ou privés.

Distributed under a Creative Commons Attribution 4.0 International
License

Motivated Self-Organization

Nicolas P. Rougier Inria Bordeaux Sud-Ouest 33405 Talence, France Email:
http://www.labri.fr/perso/nrougier/

Yann Boniface Loria - Campus Scientiﬁque 54506 Vandoeuvre-ls-Nancy,
France Email: yann.boniface@loria.fr

Abstract—We present in this paper a variation of the self- organizing
map algorithm where the original time-dependent (learning rate and
neighborhood) learning function is replaced by a time-invariant one. The
resulting self-organization does not ﬁt the magniﬁcation law and the
ﬁnal vector density is not directly proportional to the density of the
distribution. This lead us to introduce the notion of motivated
self-organization where the self-organization is biased toward some data
thanks to a supplementary signal. From a behavioral point of view, this
signal may be understood as a motivational signal allowing a ﬁner tuning
of the ﬁnal self-organization where needed. We illustrate this behavior
through a simple robotic arm setup.

II. MODEL

We’ll use here the deﬁnitions that we ﬁrst proposed in [1].

A. Deﬁnitions

Let us consider a probability density function f (x) on a compact
manifold Ω ∈ Rd. A vector quantization (VQ) is a function Φ from Ω to a
ﬁnite subset of n code words {wi ∈ Rd}1≤i≤n that form the code book. A
cluster is deﬁned as def= {x ∈ Ω|Φ(x) = wi}, which forms a partition of
Ω and Ci the distortion of the VQ is measured by the mean quadratic
error

I.  

INTRODUCTION

ξ =

(cid:107)x − wi(cid:107)2f (x)dx.

(1) 

n (cid:88)

(cid:90)

i=1

Ci

We introduced in [1] the Dynamic Self-Organized Map (DSOM) architecture
that is a variation of the self-organizing map algorithm [2] where the
original time-dependent (learning rate and neighborhood) learning
function has been replaced by a time-invariant learning rule. This
modiﬁcation of the learn- ing rule yields several interesting new
properties. First, and because of the time invariance, it is possible
for the network to support life-long learning. This means that the
network can be fed continuously with new input and the network is able
to self-organize itself around the whole set of data (using a set of
hypothesis detailed in [1]). This kind of property cannot be easily
achieved using SOM-like algorithms because they generally and explicitly
depend on a time decreasing learning rate and/or neighborhood function
(SOM, NG, GNG) that requires to know beforehand the number of data to be
processed. The second property deals with the magniﬁcation law as
introduced by [3]. Most vector quantization (VQ) algorithms try to match
the density through the density of their code book: high density regions
of the distribution tend to have more associated prototypes than low
density regions. This generally allows to minimize the loss of
information (or distortion) as measured by the mean quadratic error.
However, in the case of DSOM, the magniﬁcation law is not ﬁt and the
density of the code book is uncorrelated with the density of the data,
hence leading to a regular quantiﬁcation a priori of the underlying
probability density function. This second property could be easily
considered as a serious drawback for vector quantization if one wants,
for example, to estimate data density function. However, from a more
behavioral point of view, we argue in this paper that this may be a
desirable property provided that we can modulate learning using a
dedicated signal, i.e. a motivation to concentrate learning on what is
relevant to the task in order to have ﬁnely tune representations where
necessary.

If the function f is unknown and a ﬁnite set {xi} of p non biased
observations is available, the distortion error may be empirically
estimated by

ˆξ =

1 p

n (cid:88)

(cid:88)

i=1

xj ∈Ci

(cid:107)xj − wi(cid:107)2.

(2) 

In the following, we will use deﬁnitions and notations intro- duced by
[3] where a neural map is deﬁned as the projection from a manifold Ω ⊂
Rd onto a set N of n neurons which is formally written as Φ : Ω → N .
Each neuron i is associated with a code word wi ∈ Rd, all of which
established the set {wi}i∈N that is referred as the code book. The
mapping from Ω to N is a closest-neighbor winner-take-all rule such that
any vector v ∈ Ω is mapped to a neuron i with the code wv being closest
to the actual presented stimulus vector v,

Φ : v (cid:55)→ arg min

((cid:107)v − wi(cid:107)).

i∈N

(3) 

The neuron wv is called the winning element and the set Ci = {x ∈ Ω|Φ(x)
= wi} is called the receptive ﬁeld of the neuron i. The geometry
corresponds to a Vorono¨ı diagram of the space with wi as the center.

B. Self-Organizing Maps (SOM)

SOM is a neural map equipped with a structure (usually a hypercube or
hexagonal lattice) and each element i is assigned a ﬁxed position pi in
Rq where q is the dimension of the lattice (usually 1 or 2). The
learning process is an iterative process between time t = 0 and time t =
tf ∈ N+ where vectors v ∈ Ω are sequentially presented to the map with
respect to the probability density function f . For each presented
vector v at time t, a winner s ∈ N is determined according to equation

(3). All codes wi from the code book are shifted towards v according to

∆wi = ε(t) hσ(t, i, s) (v − wi)

(4) 

with hσ(t, i, j) being a neighborhood function of the form

hσ(t, i, j) = e−

(5) where ε(t) ∈ R is the learning rate and σ(t) ∈ R is the width of the
    neighborhood deﬁned as

.

(cid:107)pi−pj (cid:107)2 2σ(t)2

σ(t) = σi

(cid:19)t/tf

(cid:18) σf σi

, with ε(t) = εi

(cid:19)t/tf

(cid:18) εf εi

,

(6) 

while σi and σf are respectively the initial and ﬁnal neighbor- hood
width and εi and εf are respectively the initial and ﬁnal learning rate.
We usually have σf (cid:28) σi and εf (cid:28) εi.

C. Dynamic Self-Organizing Map (DSOM)

DSOM is a neural map equipped with a structure (a hypercube or hexagonal
lattice) and each neuron i is assigned a ﬁxed position pi in Rq where q
is the dimension of the lattice (usually 1 or 2). The learning process
is an iterative process where vectors v ∈ Ω are sequentially presented
to the map with respect to the probability density function f . For each
presented vector v, a winner s ∈ N is determined according to equation
(3). All codes wi from the code book W are shifted towards v according
to

∆wi = ε(cid:107)v − wi(cid:107)Ω hη(i, s, v) (v − wi) with ε being a
constant learning rate and hη(i, s, v) being a neighborhood function of
the form

(7) 

hη(i, s, v) = e

− 1 η2

(cid:107)pi−ps(cid:107)2 (cid:107)v−ws(cid:107)2 Ω

(8) 

where η is the elasticity or plasticity parameter. If v = ws, then hη(i,
s, v) = 0

D. Standard distributions

The DSOM algorithm reﬂects two main ideas:

•

•

If a neuron is close enough to the data, there is no need for others to
learn anything: the winner can represent the data.

If there is no neuron close enough to the data, any neuron learns the
data according to its own distance to the data.

The closeness of the winner to the data is controlled using the
elasticity parameter as illustrated on ﬁgure 1. and for uniform
distributions, DSOM with proper elasticity is comparable to SOM as
illustrated on ﬁgure 2 and detailed in [1].

III. EXPERIMENTAL RESULTS

As we explained in the introduction, the dynamic nature of the DSOM
algorithm leads to a regular self-organization, that is, a self
organization that does not ﬁt the magniﬁcation law and consequently,
code-vectors are evenly spread on the distribution support. Even from a
behavioral point of view, this may not be satisfactory since we may want
to have ﬁner representations in some region of the input space that are
of some interest and more generic representations in some other parts of
the input space.

Fig. 1. Three DSOM with respective elasticity equal to 1, 1.5 and 2 have
been trained for 20 000 iterations on a normal distribution using a
regular grid covering the [0, 1]2 segment as initialization. Low
elasticity leads to loose coupling between neurons while higher
elasticity results in a tight coupling between neurons.

Fig. 2. Side by side comparison of the SOM and DSOM algorithms on very
simple and uniform distributions. For each ﬁgure, network of size 8 × 8
has been trained for 20 000 epochs using 10 000 samples. Initialization
has been done by placing initial code vectors randomly over the [0, 1]2
area.

θ2

L2

L1

θ1

The robotic arm is made of two segments of respective size L1 Fig. 3.
and L2 whose positions are given by angles θ1 and θ2. The gray area
represents reachable positions in the case L1 = L2 and the dotted disc
area corresponding to the region of interest (arbitrary deﬁned) .

A. Experimental setup

Let us consider the case of a simple robotic arm made of two linked
segments L1 and L2. Segment L1 can rotate freely around its base in the
range [−π/2, +π/2] and segment L2 can rotate around L1 endpoint in the
range [−π/2, +π/2] (see ﬁgure 3). The goal of the experiment is to learn
the correspon- dence between {θ1, θ2} and the Cartesian coordinates {x,
y} of the end point of the arm with ﬁner representations in the dotted
disc area. Since we do not want to use the inverse model of the arm, the
only way to generate data is then to draw {θ1, θ2} from their respective
domain and to compute the corresponding {x, y} end position of the arm.

B. Results

The mapping from {θ1, θ2} to {x, y} is not linear and leads to a larger
density on the frontier of the domain. If we use such a distribution, we
obtain the self-organization drawn on left part of ﬁgure 4. This
self-organization spreads almost evenly on the whole reachable region
with some noticeable and useless representations outside the region.
However, as we explained we would like to have ﬁner representations
within the dotted gray area and consequently, we built a modulation
signal deﬁned as the distance of the end-point to the center of the disc
area. This modulation is associated to any sample given to the model and
this allow us to modify the original neighborhood equation (8) as
follows:

hη(i, s, v) = e

− α η2

(cid:107)pi−ps(cid:107)2 (cid:107)v−ws(cid:107)2 Ω

(9) 

with α being the modulation. This α modulation modiﬁes the overall
elasticity on a per sample basis and allows to have a ﬁner tuning of the
self-organization. This is illustrated on the left part of the ﬁgure 4
where self-organization has concentrated code vectors in the region of
interest.

IV. CONCLUSION

Since the early work of [4], [5], the idea of a critical period in the
early years of development, where most sensory

Sample data are generated by drawing uniformly θ1 and θ2 in Fig. 4.
[−π/2, +π/2] and computing the end point position. This leads to a non-
uniform distribution where higher density is found on the periphery of
the distribution support. The left ﬁgure displays resulting
self-organization of a DSOM with an elasticity of 2.5 and no modulation
while the right ﬁgure displays the same DSOM algorithm where each sample
is modulated according to its distance to the center of the ﬁgure.

or motor properties are acquired and stabilized have been widely
accepted. In such context, the original SOM algorithm gives a fair
account of such development. However, cortical representations are not
ﬁxed entities, but rather, are dynamic and are continuously modiﬁed by
experience as explained by [6] and the capacity of the cortex to
re-organize itself in face of lesions, deﬁcits or change in the
environment [7], [8] cannot be easily explained using SOM-like algorithm
since after learning period, the resulting self-organization is frozen
and cannot be easily changed.

Thanks to its dynamic nature, the DSOM algorithm may help to solve this
dilemma by ensuring a tight coupling between representations and the
environment with a code book that does not ﬁt data density and cover the
whole data support evenly. Since we may need nonetheless to have more
representations in some region of the input space, we proposed to
modulate learning by providing the algorithm with an explicit signal
giving the importance of the data. In a more general framework, we could
expect a cerebral structure (e.g. basal ganglia, amygdala) to compute
such signal: if some regions of the perceptive space is judged
behaviorally relevant, model could develop precise representations in
this region. This has been illustrated through a very simple robotic
experiment where the motivation signal is computed according to the
distance of the arm end-point to the center of the distribution. If
learning was to be driven solely by data density (like in most VQ), such
modulation would certainly be strongly attenuated or not possible at
all.

Without modulationelasticity = 2.00, L1=0.35, L2=0.15With modulationelasticity = 2.00, L1=0.35, L2=0.15Without modulationelasticity = 2.00, L1=0.25, L2=0.25With modulationelasticity = 2.00, L1=0.25, L2=0.25APPENDIX

    a compact manifold of Rd where d ∈ N+ Ω

    a probability density function (pdf) Ω → R f (x)

    a set of p non-biased observations of f . {xi}

    a set of n elements, n ∈ N+. N Φ

    a function deﬁned from Ω → N wi ∈ Rd : code word associated to an
    element i of N {wi} Ci

    code book associated to N

    cluster associated to element i such that Ci = {x ∈ Ω|Φ(x) = wi}

    euclidean norm deﬁned over Rd

    normalized euclidean norm deﬁned over Ω as x (cid:55)→

    distortion error deﬁned as (cid:80)n wi(cid:107)2f (x)dx estimated :
    (cid:80) 1 p ε(t)

    learning rate at time t λ(t) or σ(t): neighborhood width at time t η

    elasticity or plasticity

distortion (cid:107)xj − wi(cid:107)2

(cid:107)x(cid:107) maxy,z∈Ω((cid:107)y−z(cid:107))

(cid:107)x(cid:107) (cid:107)x(cid:107)Ω

deﬁned

(cid:107)x −

error

xj ∈Ci

(cid:80)n

i=1

i=1

as

ˆξ

Ci

(cid:82)

ξ

%

REFERENCES

[1] N. Rougier and Y. Boniface, “Dynamic self-organizing map,” Neurocom-

puting, 2011, to appear.

[2] T. Kohonen, “Self-organized formation of topologically correct
feature

maps,” Biological Cybernetics, vol. 43, pp. 59–69, 1982.

[3] T. Villman and J. Claussen, “Magniﬁcation control in self-organizing
maps and neural gas,” Neural Computation, vol. 18, pp. 446–449, 2006.
[4] D. Hubel and T. Wiesel, “The period of susceptibility to the
physiological effects of unilateral eye closure in kittens.” Journal of
Physiology, vol. 206, pp. 419–436, 1970.

[5] N. Daw, “Mechanisms of plasticity in the visual cortex,”
Investigative

Ophthalmology, vol. 35, pp. 4168–4179, 1994.

[6] D. Buonomano and M. Merzenich, “Cortical plasticity: From synapses
to maps,” Annual Review of Neuroscience, vol. 21, pp. 149–186, 1998. [7]
P. B. y Rita, Brain Mechanisms in Sensory Substitution. Academic Press

New York, 1972.

[8] V. Ramachandran, D. Rogers-Ramachandran, and M. Stewart, “Percep-
tual correlates of massive cortical reorganization,” Science, vol. 258,
pp. 1159–1160, 1992.


