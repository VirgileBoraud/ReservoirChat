When Artificial Intelligence and Computational Neuroscience meet
Frédéric Alexandre, Peter Ford Dominey, Philippe Gaussier, Benoît
Girard,

Mehdi Khamassi, Nicolas P. Rougier

To cite this version:

Frédéric Alexandre, Peter Ford Dominey, Philippe Gaussier, Benoît
Girard, Mehdi Khamassi, et al.. When Artificial Intelligence and
Computational Neuroscience meet. Springer. A guided tour of artificial
intelligence research, Interfaces and applications of artificial
intelligence, 3, 2020, Interfaces and Applications of Artificial
Intelligence, 978-3-030-06170-8. ￿hal-01735123￿

HAL Id: hal-01735123

https://hal.science/hal-01735123

Submitted on 13 May 2020

HAL is a multi-disciplinary open access archive for the deposit and
dissemination of sci- entific research documents, whether they are pub-
lished or not. The documents may come from teaching and research
institutions in France or abroad, or from public or private research
centers.

L’archive ouverte pluridisciplinaire HAL, est destinée au dépôt et à la
diffusion de documents scientifiques de niveau recherche, publiés ou
non, émanant des établissements d’enseignement et de recherche français
ou étrangers, des laboratoires publics ou privés.

When Artiﬁcial Intelligence and Computational Neuroscience meet

Fr´ed´eric Alexandre, Peter F. Dominey, Philippe Gaussier, Benoˆıt
Girard, Mehdi Khamassi, and Nicolas P. Rougier

Abstract Computational Intelligence and Artiﬁcial Intelligence are both
aiming at building machines and softwares capable of intelligent
behavior. They are conse- quently prone to interactions, even if the
latter is not necessarily interested in un- derstanding how cognition
emerges from the brain substrate. In this chapter, we enumerate,
describe and discuss the most important ﬁelds of interactions. Some are
methodological and are concerned with information representation,
processing and learning. At the functional level, the focus is set on
major cognitive functions like perception, navigation, decision making
and language. Among the salient charac- teristics of the critical
contributions of Computational Neuroscience to the develop- ment of
intelligent systems, its systemic view of the cerebral functioning is
particu- larly precious to model highly multimodal cognitive functions
like decision making

Fr´ed´eric Alexandre Inria Bordeaux Sud-Ouest; LaBRI UMR 5800; IMN UMR
5293; CNRS; Universit´e de Bordeaux; Bordeaux INP; France. e-mail:
Frederic.Alexandre@inria.fr

Peter F. Dominey Inserm 1208 Stem Cell and Brain Research Institute,
Human and Robot Cognitive Systems, 18, avenue du doyen Jean L´epine
69675 Bron cedex, e-mail: peter.dominey@inserm.fr

Philippe Gaussier ETIS (ENSEA, University of Cergy Pontoise CNRS UMR
8051), 2, avenue Adolphe-Chauvin B.P. 222, 95302 Cergy-Pontoise Cedex,
France, e-mail: gaussier@ensea.fr

Benoˆıt Girard Sorbonne Universit´es, UPMC Univ Paris 06, CNRS,
Institute of Intelligent Systems and Robotics (ISIR), F-75005 Paris,
France, e-mail: benoit.girard@isir.upmc.fr

Mehdi Khamassi Sorbonne Universit´es, UPMC Univ Paris 06, CNRS,
Institute of Intelligent Systems and Robotics (ISIR), F-75005 Paris,
France, e-mail: mehdi.khamassi@upmc.fr

Nicolas P. Rougier Inria Bordeaux Sud-Ouest; LaBRI UMR 5800; IMN UMR
5293; CNRS; Universit´e de Bordeaux; Bordeaux INP; France. e-mail:
Nicolas.Rougier@inria.fr

1

2

F. Alexandre, P.F. Dominey, P. Gaussier, B. Girard, M. Khamassi and N.P.
Rougier

and language and to design cognitive architectures for the autonomous
behavior of robots.

1 Introduction

The goal of Computational Neuroscience (CN) is to study relations
between brain structures and functions by the means of information
processing techniques [Marr, 1982; Schwartz, 1990; Churchland and
Sejnowski, 1992; Dayan and Abbott, 2001]. This scientiﬁc domain has to
deal more speciﬁcally with three major topics, neu- ronal processing,
learning and brain functions and aims at establishing its achieve- ments
by the design of hardware and software systems to be compared with brain
performances. It has consequently large overlaps with connectionism,
machine learning and cognitive science but it is also different because
it is speciﬁcally in- terested in understanding how these topics are
implemented in real brains, with pos- sible effects in neuroscience and
in psychology.

Artiﬁcial Intelligence (AI) is another scientiﬁc domain overlapping CN.
Though AI is not directly interested in understanding the brain, it is
also a computational science aiming at building machines and softwares
capable of intelligent behavior. There are consequently many ﬁelds where
these two domains could cross-fertilize but others are more
confrontational because each of the two domains relies on spe- ciﬁc
bases not to say dogmas.

In this Chapter, we propose to visit several ﬁelds of interest to better
understand the rich relations betwen AI and CN. Some ﬁelds are directly
related to some cog- nitive functions that have been deeply studied in
AI and where CN has investigated and modeled the cerebral structures
generally reported to be mainly involved in this cognitive function.
This is the case with decision making and related processes of action
selection and reinforcement learning involving basal ganglia (section 5)
and also with language and the central role of the prefrontal cortex
(section 6). Other ﬁelds are more methodological since CN can be also
useful to propose to AI orig- inal, efﬁcient and robust mechanisms for
information representation. We begin to evoke here the problem of the
level of description in computational models, from neurons to symbols
(section 2), and turn to the representation of sensory informa- tion in
the cortex (section 3) and to their multimodal integration in the
hippocampus (section 4). Having mentioned these points of inﬂuence in
computational mecha- nisms and in cognitive functions will be a good
basis for discussion proposed in section 7.

2 From Neurons to Symbols

Initial modeling approaches of neuronal functioning [McCulloch and
Pitts, 1943] and learning [Hebb, 1949] in the middle of the XX th
century are often considered

AI and Computational Neuroscience

3

to be at the root of the development of both CN and connectionism
(artiﬁcial neural networks without biological inspiration, presented in
Chapter 12 of Volume 2), even if oldest efforts exist (as discussed by
[Brunel and van Rossum, 2007]), particularly related to neuron
excitability, in the context of CN.

At more microscopic levels of description, CN is also interested in
understanding the behavior of single neurons through the dynamic
evolution of their membrane po- tential, as it is the case for example
in another seminal model by Hodgkin & Huxley [Nelson and Rinzel, 1995]
or in other models dedicated to lower levels of descrip- tion like
dendrites, axons or even ion channels. Building such biophysical models
is important to understand how neurons process information - how they
compute - and some bottom up approaches propose to build on them up to
the brain level and high level cognitive functions. This is speciﬁcally
the case with huge simulation projects like the Blue Brain Project
[Markram et al., 2015] and more recently the Human Brain Project, but
many researchers wonder if such ascending projects are constrained
enough to drive directly from sub-neuronal levels to cognition [Fr´egnac
and Laurent, 2014; Chi, 2016]. In some way, the reciprocal criticism is
sometimes given to cognitive psychology, stating that a descending
approach, purely driven with functional consideration, is too vague to
anchor in biological reality.

This is reminiscent of the duality in AI between the difﬁculty of making
symbols emerge from numerical computation and the reciprocal Symbol
Grounding Problem [Harnard, 1990]. This duality has been nicely
addressed by D. Marr considering the visual brain as an information
processing system, with the Tri-Level Hypothesis [Marr, 1982]. He
proposes to deﬁne the computational level, describing the (vi- sual)
functions of the brain, the implementational level describing the
underlying neuronal circuitry and, in-between, argues for an algorithmic
level including the representations and processes employed by the
implementational level to create the computational level.

Another property of this intermediate level is that it can be partly
disconnected from the other two levels. At some moment, it can be
interesting to wonder how cognitive functions are implemented by lower
level mechanisms or to wonder how some mechanisms can result from a
precise neuronal circuitry without having all the three levels of
analysis in mind. Beyond the domain of vision, this fruitful anal- ysis
is often used by researchers exploiting a certain formalism of
computation, like bayesian statisticians describing the brain [Friston,
2012] or theoreticians deﬁn- ing neuronal operations at the level of the
population of neurons [Coombes, 2005] in reference to biological data
about arrangements of neurons in repetitive circuits [Hubel et al.,
1978]. Apart from the huge bottom-up projects mentioned above, most of
the research in CN aiming at studying cognitive functions exploit such
interme- diate algorithmic levels with intermediate processing units
(representing circuits or populations of neurons) and intermediate
mechanisms (representing connectivity or learning rules).

Connectionism (artiﬁcial neural networks without biological inspiration)
has also been used to encode, combine and manipulate symbols
(Connectionist Symbol Pro- cessing [Sun and Alexandre, 1997]) and has
been confronted to similar problems as AI and particularly to the Frame
Problem, related to the difﬁculty of adequate

4

F. Alexandre, P.F. Dominey, P. Gaussier, B. Girard, M. Khamassi and N.P.
Rougier

knowledge representation. This is also illustrated in the Searle’s
Chinese Room [Searle, 1980], where an agent can appear as intelligent by
manipulating syntactic rules but turns out to have no knowledge about
the meaning of its responses. This has been studied in Embodied AI
[Pfeifer et al., 2007] by creating loops between the agent and its
environment, through sensors and actuators, to create circular low-
level sensorimotor relations, instead of elaborating complex high level
formal rules [Brooks, 1990]. This approach is also frequently used in
CN, often concerned by perception and action, with the brain seen as a
way to associate them, as we are going to describe in the next sections.

3 Sensory Perception, Cortex and Unsupervised Learning

In the brain, the representation of information begins at the lower
level by the rep- resentation of perceptual information received by
sensors and has been primarily studied in the somatosensory system. The
primary somatosensory cortex (S1 or SI) is a part of the cerebral cortex
that is situated in the lateral postcentral gyrus, pos- terior to the
central sulcus. It is, together with the primary motor cortex (anterior
to the central sulcus), one of the ﬁrst cortex to develop and certainly
one of the most important. SI is innervated by sensory receptors
(thermoreceptors, mechanorecep- tors, chemoreceptors and nociceptors)
that originate from both the surface of the body (e.g. skin) and from
inside the body (e.g. bones and joints).

Even though the somatotopic organization of the cortex has been
hypothesized more than a century ago by John Hughlings Jackson (1886)
while studying epileptic patients, its existence was really demonstrated
in the forties [Penﬁeld and Boldrey, 1937; Marshall et al., 1937;
Adrian, 1941]. This has been since then illustrated with the so-called
sensory homunculus representation based on the work of Wilder Pen- ﬁeld
using electrical stimulations on epileptic patients (even though this
homuncu- lus does not make justice to the amazing work of Wilder
Penﬁeld). These studies highlighted the somatotopic organization of the
cortex and demonstrated a point-to- point correspondence between the
surface of the body and the somatosensory cortex. However, such orderly
representations are not restricted to the somatosensory cortex and,
using similar approaches in the auditory, visual and motor domain
[Diamond and Neff, 1957; Hubel and Wiesel, 1969; Merzenich and Kaas,
1980; Gould et al., 1986; Kaas, 1994], a large number of topographic
maps have been described all over the cortex for different modalities
(tonotopic maps, retinotopic maps, motor maps). But they have different
properties. Early observations of [Leyton and Sherring- ton, 1917] (as
reported in [Lemon, 2008]) on the adult anthropoid apes demonstrated the
ability of the motor cortex to recover from extensive cortical lesions.
The authors hypothesized consequently the existence of a neural
substrate and/or a mechanism for such extensive recovery. However, about
forty years later, Hubel and Wiesel published a very inﬂuential paper
[Hubel and Wiesel, 1959] that promoted the idea of ﬁxed cortical
representations following the post-natal developmental period (the
so-called critical period). This hypothesis has prevailed for a long
time until the

AI and Computational Neuroscience

5

studies of [Merzenich and Kaas, 1982; Kaas et al., 1983; Kaas, 1991]
provided ex- perimental evidence for the somatosensory cortex
reorganization after a peripheral nerve injury or amputation in the
adult monkey.

The initial formation of these maps depends on a number of mechanisms
occur- ing at the different stages in the development of the brain and
the body and relies essentially on a complex molecular axon guidance
[Tessier-Lavigne and Goodman, 1996] and a local selection of synapses
and connections, based on temporal cor- relations [Katz and Shatz,
1996]. However, the exact mechanisms behind such or- ganization has
puzzled researchers for quite a long time. How can you preserve
neighboorhood relationships during the course of development such that
ultimately, two neighbor skin patches tend to activate two neighbor
cortical patches? Either you have to consider a genetic encoding where
each cell “knows” where to connect or you have to consider an autonomous
process that results in such orderly organiza- tion.

This latter hypothesis has been proposed in the seventies by Willshaw
and von der Malsburg [Willshaw and von der Malsburg, 1976] with the idea
of a self- organization. They proposed a model of the retina considering
a set of cells that have short-range excitation (cooperation) and long
range inhibition (competition). The distance between cells is provided
by their actual position onto the cortical sheet, hence providing an
explicit topology. They used this model to explain the for- mation of
representation in V1 using a model of the retina that already possessed
a topography. This model had a great inﬂuence and provided a very
elegant explana- tion to the aforementionned question. Some years later,
Kohonen [Kohonen, 1982] proposed an alternative model where he got rid
of the lateral connectivity in favor of a winner takes all algorithm as
well as an explicit lateral connectivity function. This model has become
popular far beyond the computational neuroscience domain since it also
provided an elegant solution to any vector quantization problem (see
Chapter 12 of Volume 2).

Vector quantization (VQ) refers to the modelling of a probability
density func- tion into a discrete set (codebook) of prototype vectors
(a.k.a. centroids) such that any point drawn from the associated
distribution can be associated to a prototype vector. Most VQ algorithms
try to match the density through the density of their codebook: high
density regions of the distribution tend to have more associated pro-
totypes than low density region. This generally allows to minimize the
distortion as measured by the mean quadratic error. For a more complete
picture, it is to be noted that there also exist some cases where only a
partition of the space occupied by the data (regardless of their
density) is necessary. In this case, one wants to achieve a regular
quantiﬁcation a priori of the probability density function. For example,
in some classiﬁcation problems, one wants to achieve a discrimination of
data in terms of classes and thus needs only to draw frontiers between
data regardless of their respective density. Such vector quantization
can be achieved using several methods such as variations of the k-means
method [Macqueen, 1967], Linde–Buzo–Gray (LBG) algorithm [Linde et al.,
1980] or neural network models such as the self- organizing map (SOM, a
priori topology) [Kohonen, 1982], neural gas (NG, no topology)
[Martinetz et al., 1993] and growing neural gas (GNG, a posteriori
topol-

6

F. Alexandre, P.F. Dominey, P. Gaussier, B. Girard, M. Khamassi and N.P.
Rougier

ogy) [Fritzke, 1995]. Nonetheless, the SOM algorithm remains the most
popular in the ﬁeld of computational neurosciences since it gives a
plausible account on the or- ganization of receptive ﬁelds in sensory
areas where adjacent neurons share similar representations as explained
previously.

However, the stability and the quality of this self-organization depends
heavily on a decreasing learning rate as well as a decreasing
neighbourhood function. This is a major drawback of most neural map
algorithms because it is thus necessary to have a ﬁnite set of
observations to perform adaptive learning starting from a set of initial
parameters (learning rate, neighbourhood or temperature) at time ti down
to a set of ﬁnal parameters at time t f . In the framework of signal
processing or data analysis, this may be acceptable as long as we can
generate a ﬁnite set of samples in order to learn it off-line. However,
from a more general point of view, it is not always possible to have
access to a ﬁnite set and we must face on-line learning as for example
during a robotic task. The question is thus how to achieve both
stability and plasticity.

To answer this question, variants of the original SOM learning algorithm
have been proposed where the time dependency has been removed (see
[Rougier and Boniface, 2011] for example). Based on several experiments
in both two-dimensional, high-dimensional and dynamic cases, these
variants allow for on-line and continu- ous learning ensuring a tight
coupling with the environment. Following up on these ideas, [Detorakis
and Rougier, 2012, 2014] investigated the formation and main- tenance of
ordered topographic maps in the primary somatosensory cortex and the
reorganization of representations after sensory deprivation or cortical
lesion. Their model is based on neural ﬁeld theory using plastic
feed-forward thalamocortical connections while cortico-cortical
connections drive the competition mechanism.

Beyond these limitations, the original self-organizing map by Kohonen
has be- come ubiquitous in the artiﬁcial intelligence landscape for
learning and representing simple sensory information. SOM has been and
is still used in a huge number of works in both image and signal
processing, pattern recognition, speech processing, artiﬁcial
intelligence, etc. Hundreds of variants of the original algorithm exist
today [Kaski S. and Kohonen, 1998; Oja et al., 2003] such that it is
literally impossible to review all of them here. Being both simple to
implement and fast to compute, it is used in a wide variety of tasks
ranging from navigation, compression, encoding, feature selection, and
many others.

However, for the representation of more complex multimodal information
(of “objects”), some other cerebral structures are necessary, namely,
the hippocampus. This structure plays a central and critical role in the
integration of various sources of information as well as in the encoding
of multimodal regions such as the associative cortex. We now evoke the
main ingredients of these complex processes.

AI and Computational Neuroscience

7

4 The Hippocampus for Multimodal Binding

4.1 Functional Organization of the Hippocampus: Implication for

Learning

The hippocampal system (HS) seems to participate in a lot of cognitive
functions. In humans and animals, the HS plays an important role in
spatial cognition but also in more general memorization processes. One
important fact is that the hippocampus (Hip), a part of the HS with a
seahorse shape, is connected through the entorhinal cortex (EC) to all
the cortical associative areas. This makes the HS a very special
convergence point to integrate multimodal information [McClelland et
al., 1995]. The bilateral ressection of the hippocampi in human causes a
severe anterograde amnesia while the ability to learn new skills remains
intact [Scoville and Milner, 1957]. Moreover, Alzheimer disease targets
ﬁrst the hippocampus and induces the same kind of memory issues. All
these researches suggest the HS plays a major role in the formation of
new memories and more speciﬁcally in episodic and autobio- graphic
memories. Most of these memories would next be recoded at the cortical
level by mechanisms which are still not well understood.

The HS can be seen as a generic tool to index or to build hash codes of
the cor- tical activity [Teyler and DiScenna, 1986] in order to detect
and learn in a fast way new events that cannot be easily detected by
cortical neurons [Cohen and Eichen- baum, 1993; Eichenbaum et al., 1994;
Bunsey and Eichenbaum, 1996; Buzs´aki, 2013; Buzs´aki and Moser, 2013]
because of the practical limitation of the neurons connectivity. As a
matter of fact, ”typical” neurons are connected to around 10 000 other
neurons limiting the capability of one neuron to detect complex events
re- lated to the co-occurence of signals present in different sensory
cortical areas for in- stance1. Using the ”small world” connectivity
found in the brain allows any neuron in the cortex to contact any other
neuron with a quite limited number of intermedi- ate neurons. Yet,
building such a network cannot be done in one shot. The neocortex is
characterized by a slow learning rate and overlapping distributed
representations allowing the extraction of the general statistical
structure of the environment, while the hippocampus learns rapidly,
using separated representations to encode the de- tails of speciﬁc
events while suffering minimal interference [O’Reilly and Rudy, 2000]
providing both structures a quite complementary role in learning. This
dual system for learning and memorization could be used in AI to limit
the learning to the statistic of ”important” events.

This fast learning capability of the Hip is supported by the properties
of the Long Term Potentiation (LTP) found in the granular cells of the
dentate gyrus (DG) and in the pyramidal cell of the Cornu Ammonia areas
(CA). The speciﬁc organization of the recurrent connections in the CA3
region has been exploited in numerous models of auto associative
memories [Marr et al., 1971; Hopﬁeld, 1982; McNaughton and

1 We can imagine this limitation is due to wiring issues: if some
neurons were connected to all the neurons in other cortical areas, the
size and weight of the brain would increase dramatically due to the
space need for the dendritic trees of these neurons.

8

F. Alexandre, P.F. Dominey, P. Gaussier, B. Girard, M. Khamassi and N.P.
Rougier

Morris, 1987] in order to explain pattern completion or pattern
retrieval and even for the learning of sequences of events. In these
models, the dentate gyrus (DG), one of the major inputs to CA3 is
supposed to perform pattern separation or pattern orthogonalization of
the activities coming from and through EC [Marr et al., 1971; McNaughton
and Morris, 1987; Treves and Rolls, 1994]. More recent theories pro-
pose that the hippocampus is a predictive auto-encoder [Gluck and Myers,
1993] playing a major role in detecting new complex events and allowing
their learning thanks to its reciprocal connections with the septal
nuclei which controls the acetyl- choline (ACh) neuromodulation
[Hasselmo et al., 1995, 1996]. The ACh provided by the medial septum
seems to mediate the learning and memory capabilities in the rest of the
brain. For instance, it has been shown that lesions of the HS disrupt
the acquisition of long-latency conditioned responses [Berger and
Thompson, 1978] such as the eyeblink conditioning learned in the
cerebellum [Thompson, 1986; Kim et al., 1995].

Hence, the neurobiological results teach us the brain uses at least two
memory systems: the cortex learns on the long term but slowly the
statistical structures of our interactions with the environment while
the HS learns quickly (but for a maximum of few weeks) some compressed
codes allowing to detect novelty and to control cortical learning.

4.2 The Hippocampus in Navigation Tasks: an Example of

Multimodal Integration

The discovery of place cells in the hippocampus [O’Keefe and Dostrovsky,
1971; Morris et al., 1982] and later the discovery of grid cells [Fyhn
et al., 2004] in the dorso median entorhinal cortex (dMEC) has
emphasized the role of the hippocam- pus in spatial cognition. In this
framework, the HS is supposed to play a speciﬁc role in spatial
cognition and even to constitute a ”cognitive map” [O’Keefe and Nadel,
1978]. A lot of works have focused on explaining how neurons in Hip can
become speciﬁc to a given place. Some of the models start from visual
information and show that a code built from the concatenation of several
visual inputs is sufﬁcient to rec- ognize one place [Arleo and Gerstner,
2000; Milford et al., 2004; Krichmar et al., 2005]. The use of more
speciﬁc codes to recognize one place as a constellation of landmark x
azimuth couples (using conjunctive cells) is also used to improve gen-
eralization capabilities [Zipser, 1985; Bachelder and Waxman, 1994;
Gaussier and Zrehen, 1995] when the animal is moving. Other models are
using the distance in- stead of the azimuth [Burgess et al., 1997] or
can use both since the elevation can be seen as a distance measure
[Giovannangeli et al., 2006]. Yet, most of these models suppose that
some place-action associations can be learned presumably thanks to the
output of the Hip in the direction of the basal ganglia to control the
direction of the action to be performed in a given place (see next
section for more details on the basal ganglia).

AI and Computational Neuroscience

9

The nature of the inputs and their coding can have very important impact
on how place recognition can be used. For instance, if the azimuth
information is coded thanks to a 1 dimension neural ﬁeld (a bubble of
activity centered on the neuron as- sociated to a given azimuth) then
the landmark-azimuth conjunctions are sensitive to the azimuth variation
between the learned place and the actual place. The result- ing place
cells exhibit very large and reliable place ﬁelds [Gaussier et al.,
2000; Giovannangeli et al., 2006]. In a room of 10x10m, the place ﬁeld
can easily be 2x2 m and can scale with the size of the environment. It
is really an interesting property since after the learning of few
place-action associations in the vicinity of a ”goal” location, the
competition between actions allows reaching the goal place from never
visited places and from locations far away from the learned places2. In
this case, the capability of one neuron to recognize one place is no
more important. It is only the rank of the place cells activity level
(their ﬁring rate) that matters: the action is chosen according to the
winning place (competitive process). This is an important change from
classical place cells models since the issue is no more to recognize one
place but to be able to reach that place. In real world conditions,
being sure of recognizing one place can be quite difﬁcult when landmarks
are moved or occluded (the effect of these changes on the cells
activities can be higher than when mov- ing away from the learned
place). Yet, the rank of the place cells will remain the same: all the
neurons are usually impacted in the same way if landmarks are ran- domly
hidden or displaced. For instance, using 40 visual landmarks while
learning places allows maintaining a good homing behavior even if more
than half of the landmarks are hidden (basically 2 to 3 well recognized
landmarks are sufﬁcient). This generalization capability can also be
very interesting to ﬁnd a shortcut or to perform a detour according to
the experimental situation. Moreover, if the landmark x azimuths
conjunctions are selected in a 180 degrees image instead of a 270 de-
grees panorama then the cell activities are no more place cells but view
cells and could explain the recording of ”view cells” in the monkey
hippocampus [Rolls and O’Mara, 1995] as opposed to the place cells in
the rat. Yet, the place ﬁelds found in the CA region of the Hip look
like really small (size about 20 cm) as compared to the large place
ﬁelds described here. One hypothesis could be that those place cells
would be located before the Hip in the ventromedial part of EC and that
they would not be considered as place cells because of their broad
receptive ﬁeld [Quirk et al., 1992]. The small place ﬁelds in the Hip
would be explained by the result of a competition layer allowing to
obtain place ﬁeld with a size equal to the mean dis- tance between the
learned places. In a new environment these cells will continue to react
and provide some activities allowing to recognize the new places as a
com- pound code. However, these visual place cells cannot explain how
place cells can be maintained in the dark.

This approach is sometimes opposed to models supposing place cells are
primar- ily built from path integration information [McNaughton et al.,
1996; Touretzky and Redish, 1996; Redish and Touretzky, 1997] and that
the HS is dedicated to spatial cognition. These models suppose path
integration is computed in a discrete way

2 to the extend that these places still belong to the same visual
environment i.e. that they are in the area surrounded by the visual
landmarks used for learning.

10

F. Alexandre, P.F. Dominey, P. Gaussier, B. Girard, M. Khamassi and N.P.
Rougier

using a pre-existing two dimensional grid of neurons to store successive
positions [Wan et al., 1994; Touretzky and Redish, 1996; Samsonovich and
McNaughton, 1997; Redish and Touretzky, 1997; Clark and Taube, 2012].
Starting from a given place, the integration of velocity signal and
direction of movement (supported by head direction cells) allows
predicting a new position and then an update from place to place.

Hence, event if these different models differs in the way they suppose
the place cells are built, all of them emphasize the role of the
hippocampus in merging mul- timodal information: i.e exteroceptive
information (vision, tactile, odor…) and pro- prioceptive information
(speed, orientation,…). Robotics experiments provide an in- teresting
way to test the limitations and the emergent properties of these
different models.

4.3 Grid Cells in the Entorhinal Cortex : Information

Compression and Coding

The seminal ﬁnding of grid cells3 in EC [Hafting et al., 2005] has
reinforced the idea of the HS as a cartesian map. The models based on a
direct computation of place recognition from the association of the
dynamical memory of the departure place and a speed vector have been
transformed to use the grid cells instead of the place cells [McNaughton
et al., 2006; Fuhs and Touretzky, 2006; Burak and Fiete, 2009]. In these
attractor models, grid activity is explained by the folding of a
2-dimensional Cartesian map representing the physical environment (a
torus which has the advan- tage that it avoids the side effects related
to the borders of the map). As pointed out by [Burak and Fiete, 2006],
the ﬁrst continuous attractor models [Fuhs and Touret- zky, 2006;
McNaughton et al., 2006; Samsonovich and McNaughton, 1997] work
correctly only if the activity bubble moves exactly in register with the
rat position. In other words, the network must precisely integrate rat
velocity (which, in turn, must ﬁt the environment discretization used in
the simulation). If speed or movement di- rection does not correspond
exactly to the parameters used for the discretization of the grid (in
terms of angle and distance4), there is an accumulation of errors induc-
ing a rapid blurring of the grid activity [Burak and Fiete, 2006].
[Burak and Fiete, 2009] proposed a solution for this issue. Yet, this
model has still a lot of constraints on the network connectivity to work
correctly. But above all, these models suppose that the entorhinal
cortex and/or the hippocampus are devoted to navigation (see ”the
hippocampus as a cognitive map” [O’Keefe and Nadel, 1978]) and still
need visual information for the (re)calibration of the path integration
system.

However, if the hippocampus is not dedicated to spatial computation how
to ex- plain grid cell activities in the EC [Hafting et al., 2005]?
[Gaussier et al., 2007;

3 grid cells: cells with a spatial ﬁring frequency related to the
wandered distance and direction of the animal movements. 4 distance =
speed (cid:63) time constant of the computation time in the hippocampal
loop

AI and Computational Neuroscience

11

Jauffret et al., 2015] propose that grid cell activity results from a
special case of the compression of the cortical activity projected onto
the EC in order to build a hash code usable by the HS to recover
information and detect complex novel states. Hence, grid cell activity
would result from the simple projection and merging of a long-distance
path integration onto the dorso medial entorhinal cortex (dMEC). Using a
kind of modulo projection such that the same cell is activated from
neurons associated to different distances allows the building of a very
compact code with grid activity able to differentiate correctly
different locations if the modulo factors are prime.

Recent studies on the lateral entorhinal cortex (LEC) and the way it can
merge vi- sual information for instance could reconcile both approaches.
However, it is a mat- ter of debate whether the hippocampus performs the
path integration by itself or is just a generic structure to build a
compact code of some path integration performed outside the hippocampus
[Gaussier et al., 2007]. Anyhow, these works have led to efﬁcient
bio-inspired architectures [Gaussier and Zrehen, 1995; Gaussier et al.,
1998; Krichmar et al., 2005; Milford and Wyeth, 2008] merging path
integration and visual information in order to build robust place cells
and to recalibrate path integration [Arleo and Gerstner, 2000; Gaussier
et al., 2007; Jauffret et al., 2015].

4.4 Implication of the Hippocampus in Planning and Transition

Recognition

Using direct place-action associations either with a strict recognition
of place (need of learning a large number of places to pave regularly
the environment) or with a competition mechanism (allowing to build a
Voronoi tessellation of the environment and playing with the
generalization properties of place cells) allows obtaining good
performances in repetitive tasks (learning an habitual behavior).

When the goals can change, the place-action associations need to be
relearnt (long procedure) or need to be duplicated for each potential
context or goal (with as many motor mappings as the number of goals).
Reinforcement learning lacks some plasticity to explain speciﬁc learning
capabilities such as latent learning [Tolman, 1948]. In this case, it is
useful to learn independently the graph or the cognitive map connecting
the known places so as to use them for planning the route in the
direction of any known place without the need for more learning
[Mataric, 1991; Schmajuk and Thieme, 1992; Guazzelli et al., 1998]. If
we suppose a fronto-parietal cognitive map is ultimately built from the
known places using Hebbian learning (neighbor places are connected to
each other), several update rules allow to see the shortest path to
reach a given goal location. For instance, if the connection weights are
constant (or inversely proportional to the distance or to the difﬁculty
to reach a place) and if the neuron activity for one node on the
cognitive map is the maximum of the incoming activities then after the
diffusion of the goal activity onto the map,

12

F. Alexandre, P.F. Dominey, P. Gaussier, B. Girard, M. Khamassi and N.P.
Rougier

following the maximum gradient of activity allows taking the shortest
path to reach that goal location.

Yet, there is a need for introducing an algorithm to read this gradient
information since at a given place, the rat has not access to the
activity in future places (until it reaches one of them). This problem
is usually solved by using an ad hoc algorithm having a global view of
the cognitive map to select the next place to be reached 5 but as far as
we suppose the neurons are only performing local computations there is a
clear homonculus issue. One solution is to use a vicarious trial and
error approach [Schmajuk and Thieme, 1992], where the animal is checking
the different alternative directions before choosing the most active
one. This solution is correct if important changes can be perceived from
the decision point (i.e. the jonction where the choice has to be made).

Unfortunately, in a real size environment, it is more likely that
corridors or paths will look like quite identical for over long
distances making this approach inefﬁ- cient. One solution is to suppose
the hippocampus role might be to predict transi- tions of multimodal
events [Schmajuk, 1991; Grossberg and Merrill, 1996; Banquet et al.,
1997]. Working with ”transition cells” instead of classical steady state
place cells solves the issue of the cognitive map readout by building a
graph of transition cells and allowing a given transition cell to be
connected to a single action [Revel et al., 1998; Gaussier et al., 2002;
Banquet et al., 2005; Hirel et al., 2013]. As a matter of fact, building
a cognitive map is no longer learning to connect for instance place ”A”
to place ”B” then next to place ”C” but is learning instead that
transition ”AB” is connected to transition ”BC”. If the current
recognized place is ”A” and ”A” is connected to ”B” and ”D” for instance
then the transitions ”AB” and ”AD” will have the same activity when
being in A (both transition are predicted at the same level). If a
diffusion activity from the goal to the different transitions on the map
adds a little more activity to ”AB” than ”AD” then the action associated
to ”AB” will win and the agent can move in the correct direction since
one transition is always associated to one unique direction of movement.

Coming back to the hippocampus, learning temporal transitions implies to
have access both to the previous and the current places and in parallel
to be able to in- tegrate the movement from A to B (i.e. the heading
direction of the animal [Sharp, 1999] when going from ”A” to ”B”). In
our case, we consider two kinds of short term memories inside the HS.
First, the recurrent connections in the dentate gyrus (DG) between the
granular cells and the mossy cells could allow building a tem- poral
trace that the CA3 pyramidal cells can use to learn when a new place
will be reached (let’s say when ”B” will be reached from the memory
trace of the previous place ”A”). Next, CA1 neurons could use a more
rustic short term memory relying on EC3 pyramidal cells (and built from
EC2 activities) to build transition cells in CA1. Then, CA1 activity
could be propagated to the fronto-parietal network to build long term
cognitive maps and also to the nucleus accumbens (ACC) to learn and pro-
pose the different possible transitions. Finally, the neurons in the ACC
receiving the activities from the fronto-parietal network and the
activity from EC1 could decide

5 yet selecting the correct action can be tricky when the place ﬁelds
are not regular enough

AI and Computational Neuroscience

13

about the transition to be selected. Interestingly, recent results on
”time cells” in the hippocampus [Naya and Suzuki, 2011; Kraus et al.,
2013; Pfeiffer and Foster, 2013; Eichenbaum, 2014] are coherent with
this view of the hippocampus as a system to predict temporal transitions
[Hirel et al., 2013].

In conclusion, the HS is mainly known and studied in rodents for its
implication in navigation tasks while in primates and humans it is known
to participate also in higher cognitive functions such as the building
of autobiographical memories. The speciﬁc architecture and connectivity
of the hippocampal system makes it important for the building of
declarative (or explicit) memories as opposed to the procedural (or
implicit) memories directly stored in the cortical and subcortical
structures. The HS capability to build a spatio-temporal code and to
perform fast or even one shot learning is a crucial element to build
place codes for navigation tasks, to predict transitions between multi
modal states and even to implement some timing proper- ties for
sequences learning and recognition. The complementary role of the HS and
cortex in the building of different kind of memories is certainly a key
element for the understanding of the human intelligence and our
capability to ﬁlter the huge amount of data our brain faces during real
life interactions. It is clear that mimicking the way the hippocampus is
interacting with the cortical areas and the basas ganglia could be
helpful in AI when facing the management of big data in real time
conditions. Moreover, neurobiological data and robotics experiments show
that at least for nav- igation tasks, recognizing perfectly a place is
not necessary to reach that place in a robust way. Hence recognizing a
place or an object is much more being able to come back to that place or
to grasp and act on that object. As opposed to a purely passive
recognition scheme, a sensory-motor approach of cognition has strong
impact on the way information has to be coded and emphasizes the
importance of taking into account the action selection in all the stages
of the cognitive processes (i.e. even in the design of a pattern
recognition system).

5 Action selection, reinforcement learning and the basal ganglia

5.1 The Basal Ganglia as a Central Action Selection Device in the

Brain

The basal ganglia are a group of inter-connected subcortical nuclei,
which receive massive convergent input from most regions of cortex,
hippocampus and amyg- dala and output to targets in the thalamus and
brainstem. It is thus considered as a priviledged region in the brain
having access to diverse information (from sensori- motor, emotional,
motivational and reward information to associative memory and episodic
memory) and directly inﬂuencing motor regions [Alexander et al., 1990;
Voorn et al., 2004]. It has even been hypothesized to implement some
sort of di- mensionality reduction – formalized as a similar process to
a Principal Component

14

F. Alexandre, P.F. Dominey, P. Gaussier, B. Girard, M. Khamassi and N.P.
Rougier

Analysis – in order to sort out the most important and relevant features
among the large amount of information to which an individual is
confronted in order to de- cide which motor response should be performed
at a given moment [Bar-Gad et al., 2000].

One of the main theories of the role of the basal ganglia is that it
constitutes a neural substrate of a central action selection device
within the brain [Mink, 1996; Redgrave et al., 1999; Gurney et al.,
2001a,b]. The theory explicitly makes interest- ing links with the
problem of module selection within distributed, modular control
architectures in the ﬁeld of Engineering. It argues that a central
selection device minimizes the number of connections as well as human
prior knowledge. While a distributed selection architecture requires
inhibitory interconnections between all modules, a central selection
device only requires connections between each mod- ule and itself. While
a subsumption architecture [Brooks, 1986] requires a prepro- grammed,
ﬁxed priority scheme, a central selection device can compare modules
with a common currency (thus enabling learning mechanisms as described
below). These features have attracted the attention of several
researchers in Artiﬁcial In- telligence and Robotics, who wanted to
study the potential beneﬁts of neuro-inspired basal ganglia action
selection models for artefacts compared to Engineering meth- ods
[Prescott et al., 1999; Girard et al., 2003; Khamassi et al., 2005;
Girard et al., 2005; Khamassi et al., 2006; Girard et al., 2008]. In
particular, Girard and colleagues have shown that such basal ganglia
models have some persistance properties which enable a robot to save
more energy than a classical winner-takes-all mechanism [Gi- rard et
al., 2003]. The anatomical loops that the basal ganglia form with the
cortex and the thalamus provide a feedback mechanism to the action
selection mechanism, enabling a selected channel (or action) to have a
slight bonus over competing chan- nels during the competition at the
next time step. Hence the persistance in action selection. Such a
feedback is particularly relevant to avoid ”hesitations” in the sys- tem
when two channels have the same saliency and are thus oscillatorily
selected one after the other, resulting in the absence of any
displacement by the robot. In other words, such a persistance mechanism
can help solving the Buridan donkey paradox, which in extension to a
discussion raised by Aristotle suggests that a don- key having to choose
between food and water, and being as hungry as thirsty, would remain
unable to decide, immobile and would die from starvation.

Another interesting property of action selection mechanisms in the basal
gan- glia is that they operate through disinhibition rather than
excitation of the selected action [Chevalier and Deniau, 1990]. Basal
ganglia output nuclei are indeed toni- cally inhibiting their motor
targets, so that the selection of an action results in the suppression
of the inhibition of the corresponding channel (hence a disinhibition).
This results in a faster action initiation compared to alternative
mechanisms where action selection would result in the initiation of a
motor command. Moreover, it has been shown in the occulomotor domain
that such inhibition mechanisms enable to prevent the blocking of
voluntary sight orientation movements by compensatory eye movements due
to the vestibulo-occular reﬂex [Berthoz, 2002].

The basal ganglia is not only fed with cortical input information
(i.e. neurotrans- mission) but is also strongly modulated by
neuromodulators such as dopamine, no-

AI and Computational Neuroscience

15

radrenaline, serotonin and acetylcholine. These neuromodulators have
been hypoth- esized to perform a meta-control or meta-learning process
on top of basal ganglia ac- tion section mechanisms [Doya, 2002]. They
have been shown to both affect neural plasticity and instantaneous gain
modulations of information transmission [Servan- Schreiber et al., 1990;
Reynolds et al., 2001]. One of the advantages of such neu- romodulation
mechanisms is that they enable to reduce the combinatorial explosion in
the number of required channels to represent different variations of the
same ac- tion. For instance, rather than representing a different
channel for the same action performed with different response vigors,
with different speeds of movements, or in relation to different contexts
and goals, the neuromodulatory system can learn to perform different
levels of modulations on the same action channel [Niv et al., 2007;
Humphries et al., 2012].

Finally, the basal ganglia are anatomically organized into different
territories which form different parallel loops with different cortical
and thalamic territories [Alexander et al., 1990; Voorn et al., 2004].
Such organization is well conserved through evolution [Redgrave et al.,
1999; Prescott et al., 1999; Stephenson-Jones et al., 2011]. Since each
basal ganglia territory and group of nuclei is seen as roughly organized
in the same manner as other territories [Gerfen and Wilson, 1996], such
a parallelism permits a reuse of the same selection mechanisms applied
to different ac- tion domains (locomotor, oculomotor, etc.), different
levels of selection (movement selection, action selection, action plan
selection, strategy selection, goal selection). These parallel loops are
thus considered as engaged in different cognitive functions such as
motor, associative, limbic and oculomotor [Alexander et al., 1990; Haber
et al., 2000; Uylings et al., 2003]. An architecture with two simulated
basal ganglia loops has for example been successfully used in a robotic
task to select among both appetitive actions (directions of movement)
and consumatory ones (stops at differ- ent reloading stations) and to
coordinate them [Girard et al., 2005]. Furthermore, the limbic loop
having a privileged access to reward as well as other emotional infor-
mation from the amygdala, hypothalamus and brainstem, and being in a
position of inﬂuence over other loops through neuromodulatory
projections, this suggests that the limbic loop of the basal ganglia may
play a central role in learning [Graybiel, 1998; Bornstein and Daw,
2011; Ito and Doya, 2011; Khamassi and Humphries, 2012; van der Meer et
al., 2012].

5.2 The Basal Ganglia as a Center for Reinforcement Learning

Animals’ ability to learn from their own experience and errors, in
particular in the context of sparse reward and punishment signals, is
considered to rely on reinforce- ment learning processes [Doya, 2000;
Foster et al., 2000; Balleine and O’Doherty, 2010; Khamassi and
Humphries, 2012; van der Meer et al., 2012; Palminteri et al., 2015].
The most central theory, developed in the ﬁeld of Artiﬁcial
Intelligence, cur- rently considers that such learning relies on: 1) the
competition between actions, resulting in action selection as a function
of the actions’ relative probabilities; 2) the

16

F. Alexandre, P.F. Dominey, P. Gaussier, B. Girard, M. Khamassi and N.P.
Rougier

anticipation of the value of rewards and punishments that could follow
the execu- tion of the action; 3) the computation of a reward prediction
error comparing what was expected with what is actually obtained; 4) the
use of such a reward prediction error as a feedback (i.e. positive,
negative or null reinforcement signal) to update either the probability
of the performed action or the predictive value associated to the action
and to the stimuli present in this context [Sutton and Barto, 1998].

This formalism can be seen as an extension of the Rescorla-Wagner model
[Rescorla and Wagner, 1972] developed in Psychology, in which learning
requires prediction errors to explain various properties of associative
learning during ani- mals classical conditioning. Prediction errors can
indeed explain the blocking phe- nomenon – when a stimulus B cannot be
associated with a reward if it is presented together with a stimulus A
which is already fully predictive of the reward –, and cases of
overexpectation – when the concomittant presentation of two reward pre-
dictive stimuli inﬂuences behavior as if they were adding up, to form a
stronger prediction.

A particular subgroup of RL algorithms implementing what is called
Temporal- Difference (TD) learning extends the Rescorla-Wagner model in
that prediction er- ror signals contain three terms rather than two. The
Rescorla-Wagner indeed com- pares past expectation with present outcome
(e.g. reward). The TD learning rule adds to this comparison a term
representing future expectations of reward. As a consequence, a
reinforcement signal can be computed even before the reward is attained
by comparing temporally consecutive expectations of reward – hence the
term Temporal-Difference: e.g. when an action leads to a situation or
state where reward expectations are higher than previous ones, this
action should be reinforced. Since nearly twenty years, this theory has
provided Neuroscientists with formal tools which contributed to
important breakthroughs in the understanding of neural correlates of
learning. Reinforcement Learning models turned out to be able to ex-
plain a wide range of adaptive behaviors experimentally observed both in
humans (e.g. [Frank et al., 2009; Balleine and O’Doherty, 2010]) and in
non-human animals (e.g. [Yin and Knowlton, 2006; Khamassi and Humphries,
2012]). This formalism also enabled to explain a variety of neural
correlates of learning [Schultz et al., 1997; Khamassi et al., 2008].
The most striking example and probably the most central in the ﬁeld is
the observation that phasic responses of dopaminergic neurons (which
send massive neuromodulatory projections to the basal ganglia [Haber et
al., 2000]) follow the proﬁle of reward prediction errors as they are
formalized by the RL the- ory: an increase in activity when the outcome
of action is better than expected; a decrease in activity when it is
worse than expected; an absence of response when it meets the
expectations [Schultz et al., 1997]. In addition, the third term of the
learn- ing rule mentioned above enables TDRL models to account for
reward anticipation signals in the rat ventral striatum (the main
nucleus in the limbic part of the basal ganglia) [Khamassi et al., 2008]
as well as in some dopaminergic neurons [Bellot et al., 2012].

The accumulation of neurophysiological results corroborated by this
computa- tional theory has also enabled to establish that the learning
of reward values and action values depends on plasticity in projections
from the cortex to the basal gan-

AI and Computational Neuroscience

17

glia (in particular to the striatum, the main input structure of the
basal ganglia), and that these adjusments depend on dopaminergic signals
sent from the substan- tia nigra pars compacta and the ventral tegmental
area [Barto, 1995; Houk et al., 1995; Schultz et al., 1997; Reynolds et
al., 2001]. Numerous computational mod- els of the basal ganglia were
derived from these experimental results [Houk et al., 1995; Schultz et
al., 1997; Doya, 2000; Joel et al., 2002; Khamassi et al., 2005; Frank,
2005; Guthrie et al., 2013; N’Guyen et al., 2014], and were built on the
cen- tral assumption mentioned above that the basal ganglia play a
critical role in action selection [Redgrave et al., 1999; Gurney et al.,
2001a,b].

Strikingly, this ﬁeld of investigation has entertained an important
dialog between AI and Neuroscience. One of the main recent examples is
the interest that neuro- scientists have gained for the distinction
between different types of TDRL algo- rithms in the ﬁeld of AI, namely:
Actor-Critic, Q-learning, SARSA. These three al- gorithms use different
information in their learning rule, which is respectively based on state
value (independent from the action), the maximal action value in the
current state, the value of the action chosen to be performed in the
current state at the next timestep. These three variations of TDRL thus
lead to different proﬁles of reward prediction error signals. As a
consequence, several neuroscience groups have de- signed experiments to
speciﬁcally investigate whether reinforcement signals in the brain are
consistent with either Actor-Critic, Q-learning or SARSA. Contradictory
results have been obtained by different groups so far [Morris et al.,
2006; Roesch et al., 2007; Bellot et al., 2012]. There could exist
differences between species (mon- keys and rats) or between experimental
conﬁgurations (presentation of single versus pairs of reward predicting
stimuli). Future dialogs between Neuroscience and AI thus promise
fertile exchanges along this line of research.

Finally, in the last decade computational neuroscientists have
discovered that the classical distinction between learning strategies
considered in AI and Machine Learning, namely model-based and model-free
RL, also applies to Neuroscience by capturing different experimentally
observed behavioral strategies in mammals, and related brain activities
in different networks involving different basal ganglia territories [Daw
et al., 2005; Khamassi and Humphries, 2012; Doll´e et al., 2018]. More
precisely, it turns out that mammals often start learning a task by
trying to build an internal model of the task states, actions and
transitions between them. This enables initial ﬂexible behavior – which
in particular enables to quickly adapt to task changes – in parallel to
the slower acquisition of model-free local action values in the
background. Once the latter learning process has converged – if the
stability and familiarity of the task permit this long convergence – it
starts expressing its learned behavioral sequences. This permits to free
the parts of the brain which are responsible for model-based decisions
(including the prefrontal cortex), thus enabling quicker but at the same
time more rigid action selection. If the task changes after a long
period of stability, it is more difﬁcult for mammals to break their
habits and adapt to the new task contingencies.

Nevertheless, this line of Neuroscience research promises interesting
future in- spiration for AI by investigating how the brain efﬁciently
coordinates these different types of learning. For instance, Daw and
colleagues have suggested that the relative

18

F. Alexandre, P.F. Dominey, P. Gaussier, B. Girard, M. Khamassi and N.P.
Rougier

uncertainty within each learning system could help the brain decide
which system should control behavior at any given moment [Daw et al.,
2005]. In addition, more recent models can explain a variety of animal
behavior in different tasks by em- ploying a meta-controller which
meta-learns which learning system was the most efﬁcient in each state of
each task [Doll´e et al., 2018]. This suggests principles for the
coordination of multiple learning systems which could inspire Artiﬁcial
Intelli- gence in return. Recent applications of these principles to
Robotics suggest that this can work on real robots in a variety of tasks
[Caluwaerts et al., 2012; Renaudo et al., 2014]. While classical
AI-based robots usually try to solve a given problem with a single
algorithm (either planning or reinforcement learning), trying to make
this al- gorithm the best possible on the considered solution, it turns
out that different prob- lems require different algorithms [Kober et
al., 2013]. Here the neuro-inspired solu- tion suggests that a system or
cognitive architecture coordinating multiple learning processes (as it
is the case in the basal ganglia) may beneﬁt from the advantages of each
process/algorithm, and may learn by itself which one is the most
appropriate in each given situation [Caluwaerts et al., 2012; Renaudo et
al., 2015; Khamassi et al., 2016]. While this may lead to good but
suboptimal performance in a given problem (at is the case for mammals),
this may enable the agent to adapt to many different situations, which
could be of great potential interest for Artiﬁcial Intelligence re-
search. In return, more recent developments in AI and Robot learning
permitting to efﬁciently and dynamically tune the
exploration-exploitation trade-off in reinforce- ment learning [Wang et
al., 2016; Khamassi et al., 2018] as well as to bootstrap learning with
prioritized experience replay [Schaul et al., 2015] could greatly in-
spire future improvements of reinforcement learning models in
Neuroscience [Caze et al., 2018].

6 Language and the prefrontal cortex

As the most recent arrival in the long evolution of the primate cortex,
the prefrontal cortex (PFC) is considered to one of the pillars of
higher cognitive function [Fuster, 1991; Goldman-Rakic, 1987; Miller and
Cohen, 2001; Wang et al., 2015]. Gener- ally speaking, there is a
transition in the posterior to anterior extent of the cortex from
sensory-motor functions posteriorly to progressively more integrated and
ab- stract functions as we move more anterior in cortex, culminating in
prefrontal cortex [Fuster, 1991]. Thus, PFC has been a candidate for
numerous computational mod- els [Bastos et al., 2012; Dominey et al.,
1995; Duncan, 2001; O’Reilly and Frank, 2006]. Complimentary to its
place as a highly associative area, one of the princi- pal
neurophysiological characteristics of prefrontal cortex is the density
of local recurrent connections [Goldman-Rakic, 1987]. A second
neurophysiological char- acteristic of the prefrontal cortex is its
privileged relation with the basal ganglia and thalamus. We will see how
these characteristics can lead to impressive computa- tional
capabilities.

AI and Computational Neuroscience

19

The computational power of recurrent networks has traditionally been
demon- strated in a number of domains [Douglas et al., 1995; Hermans and
Schrauwen, 2012; Pearlmutter, 1995]. One of the great challenges in
modeling recurrent net- works concerns how to adapt the recurrent
connection weights, as it is difﬁcult to assign credit to recurrent
connections [Pearlmutter, 1995]. When an input excites the network,
activation can circulate through the recurrent connections numerous
times before the output is generated. If the output is incorrect, and
one wants to modify a recurrent connection in order to reduce the error,
one must keep in memory the different roles of this connection
throughout the numerous cycles of activation. A number of technical
solutions that can involve cutting of the recurrent history to sim-
plify the credit assignment, or unrolling the recurrent cycles, have
been employed [Elman, 1990; Jordan, 1986; Pearlmutter, 1995]. The
resulting recurrent neural net- work (RNN) models have a long and rich
history in cognitive science [Cleeremans and McClelland, 1991; Elman,
1991].

An alternative approach is to retain the rich temporal dynamics within
recurrent network, with no cutoff, by maintaining the recurrent
connections ﬁxed, and mod- ifying connections between the recurrent
units and the output units. This approach was ﬁrst invented by Dominey
and colleagues [Dominey, 1995; Dominey et al., 1995]. Later it was again
independently developed by Maass as the liquid state ma- chine [Maass et
al., 2002], and by Jaeger as the echo state network [Jaeger, 2001;
Jaeger and Haas, 2004]. These three approaches have been integrated
under the title of reservoir computing [Lukosevicius and Jaeger, 2009].

The initial motivation for these recurrent networks was to understand
how the prefrontal cortex encodes sequential structure. Barone and
Joseph [Barone and Joseph, 1989] studied neural activity in the
prefrontal cortex of monkeys that had been trained to perform a sequence
learning task that involved watching the presen- tation of a visual
sequence on a response button board, and then after a short delay,
reproducing the sequence by touching the buttons on the board in the
same order that they were presented. They observed that neurons in the
dorsolateral prefrontal cortex (DLPFC) displayed two characteristic
responses to stimuli in the sequence task. First, as had previously been
observed, the neurons were spatially selective, with preferences for
stimuli in particular locations in the retinal image. The second
characteristic was new, and revolutionary: many of these neurons also
displayed a “sequence rank” effect, that is, they had preferences for
stimuli that had appeared ﬁrst, second or last in the input sequence.
Thus, the spatial selectivity in many neu- rons was modulated by the
rank or order of the element in the sequence. This indi- cated that
DLPFC embodies a mechanism for discriminating the order of items in a
perceptual sequence.

These observations motivated us to develop a recurrent network that
received retinotopic (spatially organized) inputs, and combined these
inputs with mixed ex- citatory and inhibitory connections. We reasoned
that this would lead to a form of mixed selectivity combining spatial
location and sequence rank, as observed in the primate. This is indeed
what we observed, thus demonstrating that such recurrent networks have
signiﬁcant sequence learning capability, and that their coding corre-
sponds to that seen in the prefrontal cortex [Dominey et al., 1995].

20

F. Alexandre, P.F. Dominey, P. Gaussier, B. Girard, M. Khamassi and N.P.
Rougier

More recently we have used this same type of reservoir model to solve a
rather complex task where the system should search for the one rewarded
target amongst four possibilities, then repeat that response for several
rewards, before starting anew with the search for the new rewarded
target. Model neurons showed a remarkable similarity to neurons recorded
in the primate anterior cingulate cortex, including the non-linear
mixture of task relevant parameters [Enel et al., 2016]. It is now
consid- ered that these recurrent networks with feedback have universal
computing prop- erties [Maass et al., 2007, 2002]. Intuitively, the
recurrent connections project the inputs into an inﬁnitely high
dimensional space that incorporates past history. Mod- iﬁable readout
neurons can then be trained to select the appropriate representation for
the task at hand.

Such universal computing should be appropriate for language learning.
Language learning can be characterized as learning from paired
sentence-meaning examples how to generate the corresponding meaning for
a new sentence. In order to have a simpliﬁed version of such a task, we
looked to neurolinguistic tasks used to mea- sure human language
comprehension. Caplan and colleagues developed a task that exploited
nine different sentence types, and measured patients ability to perform
thematic role assignment, or to determine who did what to whom [Caplan
et al., 1985]. Typical sentences tested included

1.  Dative passive: The elephant was given to the monkey by the rabbit.
2.  Subject-Object relative: The elephant that the monkey hit hugged the
    rabbit.

Patients were asked to read such sentences, and then by pointing to
pictures, indicate in order the agent, the object and the recipient of
the described actions. Patients with lesions in the left hemisphere, in
the region surrounding the sylvian ﬁssure, displayed deﬁcits in using
these grammatical cues to determine who did what to whom. Instead, they
relied on the so called canonical order and indicating that the ﬁrst
mentioned noun was the agent, second object, third recipient [Caplan et
al., 1985].

We reasoned that this thematic role assignment problem could be
considered as a sequence processing problem, where the system should
take the input sentence and reorder the nouns (if necessary) into the
agent, object, recipient order, based on the grammatical function words
like “was”, “to” and “by”. In this context, meaning can be represented
in a predicate-argument form such as “predicate(agent, object,
recipient)”, and sentences are represented as sequences of words. As
illustrated in ﬁgure 1, these grammatical words are processing the
recurrent network (that we posit to be in BA47 PFC region), and the open
class words (nouns and verbs) are held in a working memory (that we
posit to be in prefrontal cortex BA44). Through learning, the system
associates different states of activity in the recurrent network with
selection of different elements in the working memory, thus linking
different sentence forms with different re-ordering of the open class
elements into the agent, object, recipient order, as required for
Caplan’s task [Dominey et al., 2003].

For example, “It was the cat1 that the dog2 chased3” becomes “The dog2
chased3 the cat1”. From an abstract perspective, this corresponds to an
abstract structure ABC-BAC which is a sequence of six elements where the
second triplet is a system-

AI and Computational Neuroscience

21

atically transformed version of the ﬁrst [Dominey et al., 1998].
Interestingly this model made a strong prediction about the equivalent
processing of linguistic se- quences (i.e. sentences) and non-linguistic
abstract sequences in the brain: both sen- tences, and non-linguistic
abstract sequences that required a systematic re-ordering of certain
elements should recruit a common brain network for structure processing,
while language should require additional processing to integrate
semantic contents.

Fig. 1 A. Neural network model of fronto-striatal system for sentence
and non-linguistic abstract sequence processing (from [Dominey et al.,
2009]). B. Neural activity for sentence and abstract sequence processing
(from [Hoen et al., 2006]). Common activity for sentences and sequences
in red (corresponding to recurrent network and structure mapping), and
language speciﬁc activity in green (corresponding to integration of
semantic content into grammatical structure via ventral pathway and
BA45).

One of the remarkable features of language processing, and thus a key
property for any model of language processing is the ability to learn
grammatical structure from a limited number of examples, and to
generalize this learning to new grammati- cal sentences. By using more
optimized learning techniques to learn the associations between activity
in the recurrent network and the corresponding responses, we have
demonstrated such generalization. Figure 2 illustrates the updated
reservoir model for language comprehension, and generalization
performance on untrained sentence types in a parameter exploration where
network parameters are systematically var- ied.

An interesting property of the behavior of the network can be seen in
Figure 3. The two panels illustrate activity in the readout neurons that
code for the semantic role of the ﬁrst noun in two different grammatical
types. In the second sentence, this noun is the agent or subject of the
main (second) verb and the object of the relative (ﬁrst) verb. The two
sentences are identical up to the arrival of the fourth word. In the
subject-subject sentence depicted in A, the model accurately predicts
what happens and there is little change in the output indicated at the
arrow. In the less frequent subject-object sentence in B, the model’s
prediction must be updated at the arrival of the fourth word causing a
large visible change in activity. This is

22

F. Alexandre, P.F. Dominey, P. Gaussier, B. Girard, M. Khamassi and N.P.
Rougier

Fig. 2 Simpliﬁed reservoir model for sentence comprehension. A.
Grammatical words are input to the reservoir. Through learning,
connections from reservoir to the readout can associate patterns of
activity in the reservoir with activation of neurons that represent the
semantic role (predicate, agent, object or recipient) for each semantic
word in the sentence. B. Performance error in comprehension in a test of
generalization to new untrained constructions. Note an extended
parameter space with good generalization.

precisely the kind of activity change that is seen in the human brain in
response to lower frequency grammatical structures, referred to as the
syntactic positive shift or P600 (a positivity that comes 600ms after
the offending word) [Frisch et al., 2002; Hagoort and Brown, 2000].

We have seen that recurrent network models of PFC can perform complex
tasks like language comprehension. Recent work at the forefront between
computational neuroscience and machine learning has contributed to the
concept that the prefrontal cortex is a recurrent network that has
universal coding properties. Rigotti and col- leagues have shown that
recurrent reservoir networks inherently display mixed se- lectivity in
their single units, and that this mixed selectivity is precisely the
high dimensional coding required for solving complex cognitive tasks
[Fusi et al., 2016; Rigotti et al., 2013]. Interestingly this is the
same kind of mixed selectivity that we modeled (mixing spatial location
and sequence rank) in our ﬁrst instantiation of the reservoir concept
[Dominey et al., 1995], where a network of neurons connected by ﬁxed
recurrent connections provides a universal high dimensional encoding,
and modiﬁable connections allow the system to learn to associate these
representations with the desired output. Future research should attempt
to further understand these neurocomputational systems, and address
questions concerning how the encoding of task related context can render
these systems even more powerful.

7 Conclusion

AI and CN are two scientiﬁc domains developing their own formalisms but
they are both interested in understanding how cognitive functions can
emerge from com-

AI and Computational Neuroscience

23

Fig. 3 Processing of Subject-Relative and Object-Relative sentences in
corpus where subject- relatives are more frequent than object-relatives.
A. Subject-relative. For the word “V” following “that”, there is
relatively small change in the readout neurons, indicating that the
predictions of the model were essentially conﬁrmed. B. Object-relative.
For the “the” following “that”, there is a signiﬁcant shift in activity,
corresponding to a reassignment of the most probable coded meaning. From
[Hinaut and Dominey, 2013].

putational mechanisms. Speciﬁcally, CN takes a strong inspiration from
the brain circuitry, which is undoubtly a choice source of information
to study the emergence of cognitive functions. Accordingly, CN can
provide AI with original and ﬁrst-hand mechanisms related to cognition.
In addition, Neuroscience is a very dynamical do- main extracting more
and more information from the mysterious brain, and CN is perpetually
renewed by following these progresses and sometimes contributing to
them. In this Chapter, we have proposed some illustrations on important
questions on which the domains can interact.

The problem of representation of information is a central issue in AI,
from the Physical Symbol System hypothesis to more recent questions
evoked in most Chap- ters of Volume 1, about the representation of
complex objects or events [Russell and Norvig, 2003]. Whereas the
existence in the cortex of topographic maps of neu- rons responding each
to preferential stimuli (cf. section 3) can give arguments for localized
representations at the symbolic and subsymbolic levels, the dynamics of
recurrent networks in the PFC (cf. section 6) and the hippocampus
(cf. section 4) is rather reminiscent of distributed encoding. It is
also important to mention that the corresponding neuronal models are
associated to well explored learning rules that allow to build both
kinds of representation from sampling in the environment. Concerning the
elaboration of information representation, a related topic is about the
opposition between top down and botton up approaches in AI (cf. section
2). Pieces of evidence have been proposed here that Marr’s algorithmic
level could be fed with sensory information in an ascending way and
controled in the opposite way by structures like the PFC (cf. section
6).

Whereas learning is a central mechanism in cognition, it has a
particular status in AI. Sometimes it is not directly addressed and it
is believed that information can be efﬁciently injected in a cognitive
system as formalized knowledge. Sometimes

24

F. Alexandre, P.F. Dominey, P. Gaussier, B. Girard, M. Khamassi and N.P.
Rougier

it is the central topic of an algorithm in Machine Learning that is
intended to solve the considered cognitive task by processing
iteratively data received in experimen- tal cases. From this duality
between adaptation by integration of knowledge or data [Sun and
Alexandre, 1997], CN argues that knowledge injected into a cognitive
sys- tem can correspond to the very slow learning, at the scale of
species evolution, of the structures and characteristics of the neuronal
circuitry and proposes, for adaptation at shorter time constants, a
large variety of biologically inspired learning algorithms that we have
evoked throughout this Chapter, particularly mentioning their strong
links to classical algorithms in Machine Learning presented in Chapter
12 of Volume 1 and Chapter 12 of Volume 2, and their
cross-fertilization. It is thus notable that the recently developed Deep
Learning approach evoked in Chapter 12 of Volume 2, which offers among
the most efﬁcient artiﬁcial learning systems, makes strong ref- erences
to neuroscience and in particular to the visual system [Yamins and
DiCarlo, 2016], although we must also relativize this type of analogy.
Speciﬁcally, the effec- tiveness of these systems is based largely on
their training from very large corpus of examples, whereas natural
learning generally has fewer trials to adapt.

Furthermore, as it can be observed in behaving animals (or robots !), an
intelli- gent behavior often corresponds to the capacity to adapt to a
variety of tasks and not to be a specialist for only one task. This is
clearly one domain where AI is only starting out (but consider the
domains of Lifelong Machine Learning and of Arti- ﬁcial General
Intelligence) and where CN is more mature, allowing to coordinate
multiple ways of learning in modular networks, as it has been evoked
several times above.

A related characteristic of central interest in intelligent behavior is
autonomy, also too poorly dealt with in AI. Here also, CN is some steps
beyond because its systemic view is more adapted to implement a
versatile agent able to adapt by itself to changing and unknown
conditions and also because recent models of the loops between the basal
ganglia and the PFC [Koechlin et al., 2003; O’Reilly et al., 2010] are
begining to address the functions of self-evaluation of performances and
cogni- tive control, not to mention consciousness, which are also
fundamental ingredients to autonomous behavior. Nevertheless, these
approaches are still far from proposing an architecture of control
making the agent fully autonomous and able to exploit previously
elaborated knowledge in new circumstances, and to identify these cir-
cumstances, particularly in the case of unstationary environment and a
lot of work remains to be done in that direction.

Our capacity to adapt to completly unexpected situations is certainly a
central explanation to the fact that our brain today spends most of its
time making sym- bolic manipulations (with natural language, with
mathematics, but also with digital devices) it was not necessarily
designed for at the origin. Understanding how the systemic arrangement
of cerebral structures presented here produces this general purpose
information processing system specially interested in symbolic analysis
is certainly another rich domain of interaction between AI and CN.
Particularly, inspi- ration from natural sciences can bring to AI an
original understanding of this prob- lem, focusing for example on
developmental issues (how skills can be installed one after the other to
produce an increasingly mature system) and also on the importance

AI and Computational Neuroscience

25

of social interactions (imitation, teaching) and their impact on the
development of the cerebral system.

Whereas general intelligence is clearly an important goal of CN-AI
interactions but remains on a long-term perspective, we have also shown
in this Chapter that very concrete interactions are already existing for
cognitive functions corresponding to more classical goals of AI, like
perception, navigation, decision making (including action selection,
reasoning, planning) and language. We have explained here that CN can
provide AI with useful mechanisms and principles of information
represen- tation, by deciphering the brain circuitry involved in these
functions. In addition, CN can offer another decisive contribution for
helping computational models to master more widely these functions.
Their development is certainly linked to the better in- tegration of
multimodal sensorimotor ﬂows and to their interconnections, one with the
others. The systemic approach of CN in clearly an asset in that
direction.

In conclusion, CN has already demonstrated interesting contributions to
AI at the methodological level, for information representation,
processing and learning and also at the functional level for the
implementation of a variety of cognitive functions [Hassabis et al.,
2017]. Other types of contribution are particularly precious because
they exploit the unique capability of CN to develop an integrated
approach of brain modeling, in a systemic view. They should be
encouraged for the development of AI in domains like autonomous
robotics, for multimodal cognitive functions like decision making and
language and also for general intelligence.

References

Adrian, E. D. (1941). Afferent discharges to the cerebral cortex from
peripheral

sense organs. Journal of Physiology London, 100.

Alexander, G., Crutcher, M., and DeLong, M. (1990). Basal
ganglia-thalamocortical circuits: parallel substrates for motor,
oculomotor, ”prefrontal” and ”limbic” func- tions. Prog Brain Res,
85:119–146.

Arleo, A. and Gerstner, W. (2000). Spatial cognition and neuro-mimetic
navigation: a model of hippocampal place cell activity. Biological
Cybernetics, 83(3):287– 299.

Bachelder, I. A. and Waxman, A. M. (1994). Mobile robot visual mapping
and localization: A view-based neurocomputational architecture that
emulates hip- pocampal place learning. Neural networks, 7(6):1083–1099.

Balleine, B. W. and O’Doherty, J. P. (2010). Human and rodent homologies
in action control: corticostriatal determinants of goal-directed and
habitual action. Neuropsychopharmacology, 35(1):48–69.

Banquet, J., Gaussier, P., Dreher, J. C., Joulain, C., Revel, A., and
G¨unther, W. (1997). Space-time, order, and hierarchy in
fronto-hippocampal system: A neural basis of personality. In Matthews,
G., editor, Cognitive Science Perspectives on Personality and Emotion,
volume 124, pages 123–189, Amsterdam. North Hol- land.

26

F. Alexandre, P.F. Dominey, P. Gaussier, B. Girard, M. Khamassi and N.P.
Rougier

Banquet, J.-P., Gaussier, P., Quoy, M., Revel, A., and Burnod, Y.
(2005). A hierarchy of associations in hippocampo-cortical systems:
Cognitive maps and navigation strategies. Neural Computation,
17(6):1339–1384.

Barone, P. and Joseph, J. P. (1989). Prefrontal cortex and spatial
sequencing in

macaque monkey. Experimental Brain Research, 78(3):447–464.

Barto, A. (1995). Adaptive critics and the basal ganglia.

In Houk, J., Davis, J., and Beiser, D., editors, Models of Information
Processing in the Basal Ganglia, chapter 11, pages 215–232. MIT Press,
Cambridge, MA.

Bar-Gad, I., Havazelet-Heimer, G., Goldberg, J. A., Ruppin, E., and
Bergman, H. (2000). Reinforcement-driven dimensionality reduction – a
model for informa- tion processing in the basal ganglia. J Basic Clin
Physiol Pharmacol, 11:30520. Bastos, A. M., Usrey, W. M., Adams, R. A.,
Mangun, G. R., Fries, P., and Friston, K. J. (2012). Canonical
microcircuits for predictive coding. Neuron, 76(4):695 – 711.

Bellot, J., Sigaud, O., and Khamassi, M. (2012). Which temporal
difference learning algorithm best reproduces dopamine activity in a
multi-choice task? In Ziemke, T., Balkenius, C., and Hallam, J.,
editors, From Animals to Animats 12, volume 7426 of Lecture Notes in
Computer Science, pages 289–298. Springer Berlin / Heidelberg.

Berger, T. W. and Thompson, R. F. (1978). Neuronal plasticity in the
limbic system during classical conditioning of the rabbit nictitating
membrane response. i. the hippocampus. Brain research, 145(2):323–346.

Berthoz, A. (2002). Le Mouvement. Odile Jacob, Paris, France. Bornstein,
A. M. and Daw, N. D. (2011). Multiplicity of control in the basal gan-
glia: computational roles of striatal subregions. Current opinion in
neurobiology, 21(3):374–380.

Brooks, R. A. (1986). A robust layered control system for a mobile
robot. IEEE

Journal of Robotics and Automation, R.A-2:14–23.

Brooks, R. A. (1990). Elephants don’t play chess. Robotics and
Autonomous Sys-

tems, 6(1):3 – 15.

Brunel, N. and van Rossum, M. C. W. (2007). Lapicque’s 1907 paper: from
frogs

to integrate-and-ﬁre. Biological Cybernetics, 97(5):337–339.

Bunsey, M. and Eichenbaum, H. (1996). Conservation of hippocampal memory

function in rats and humans. Nature, 379:255–257.

Burak, Y. and Fiete, I. (2006). Do we understand the emergent dynamics
of grid cell

activity? J Neurosci, 26(37):9352–4; discussion 9354.

Burak, Y. and Fiete, I. R. (2009). Accurate path integration in
continuous attractor

network models of grid cells. PLoS Comput Biol, 5(2):e1000291.

Burgess, N., Donnett, J. G., Jeffery, K. J., John, O., et al. (1997).
Robotic and neuronal simulation of the hippocampus and rat navigation.
Philosophical Trans- actions of the Royal Society of London B:
Biological Sciences, 352(1360):1535– 1543.

Buzs´aki, G. (2013). Cognitive neuroscience: time, space and memory.
Nature,

497(7451):568–569.

AI and Computational Neuroscience

27

Buzs´aki, G. and Moser, E. I. (2013). Memory, navigation and theta
rhythm in the

hippocampal-entorhinal system. Nature neuroscience, 16(2):130–138.

Caluwaerts, K., Staffa, M., S., N., Grand, C., Doll´e, L., Favre-F´elix,
A., Girard, B., and Khamassi, M. (2012). A biologically inspired
meta-control navigation system for the psikharpax rat robot.
Bioinspiration and Biomimetics, 7(2):025009.

Caplan, D., Baker, C., and Dehaut, F. (1985). Syntactic determinants of
sentence

comprehension in aphasia. Cognition, 21(2):117 – 175.

Caze, R., Khamassi, M., Aubin, L., and Girard, B. (2018). Hippocampal
replays under the scrutiny of reinforcement learning models. Journal of
Neurophysiology, page in revision.

Chevalier, G. and Deniau, J. (1990). Disinhibition as a basic process in
the expres-

sion of striatal functions. Trends Neurosci, 13(7):277–280.

Chi, K. R. (2016). Neural modelling: abstractions of the mind. Nature,
531. Churchland, P. and Sejnowski, T. J. (1992). The Computational
Brain. Cambridge,

MA: MIT Press.

Clark, B. J. and Taube, J. S. (2012). Vestibular and attractor network
basis of the head direction cell signal in subcortical circuits. Front.
Neural Circuits, 6(7):10– 3389.

Cleeremans, A. and McClelland, J. L. (1991). Learning the structure of
event se-

quences. Journal of experimental psychology. General, 120(3):235–253.

Cohen, N. and Eichenbaum, H. (1993). Memory, amnesia, and the
hippocampal

system. MA:MIT.

Coombes, S. (2005). Waves, bumps and patterns in neural ﬁeld theories.
Biol.

Cybern., 93:91–108.

Daw, N., Niv, Y., and Dayan, P. (2005). Uncertainty-based competition
between prefrontal and dorsolateral striatal systems for behavioral
control. Nat Neurosci, 8(12):1704–1711.

Dayan, P. and Abbott, L. F. (2001). Theoretical neuroscience:
computational and

mathematical modeling of neural systems. Cambridge, MA: MIT Press.

Detorakis, G. and Rougier, Nicolas, P. (2012). A Neural Field Model of
the So- matosensory Cortex: Formation, Maintenance and Reorganization of
Ordered To- pographic Maps. PLoS ONE, 7(7):e40257.

Detorakis, G. I. and Rougier, N. P. (2014). Structure of receptive ﬁelds
in a compu- tational model of area 3b of primary sensory cortex.
Frontiers in Computational Neuroscience, 8:26.

Diamond, I. T. and Neff, W. D. (1957). Ablation of temporal cortex and
discrimina-

tion of auditory patterns. Journal fo Neurophysiology, 20.

Doll´e, L., Chavarriaga, R., Guillot, A., and Khamassi, M. (2018).
Interactions of spatial strategies producing generalization gradient and
blocking: A computa- tional approach. PLoS computational biology,
14(4):e1006092.

Dominey, P. F. (1995). Complex sensory-motor sequence learning based on
re- current state representation and reinforcement learning. Biological
Cybernetics, 73(3):265–74.

28

F. Alexandre, P.F. Dominey, P. Gaussier, B. Girard, M. Khamassi and N.P.
Rougier

Dominey, P. F., Arbib, M. A., and Joseph, J.-P. (1995). A Model of
Cortico-Striatal Plasticity for Learning Oculomotor Associations and
Sequences. Journal of Cog- nitive Neuroscience, 7(3):311–336.

Dominey, P. F., Hoen, M., Blanc, J.-M., and Lelekov-Boissard, T. (2003).
Neu- rological basis of language and sequential cognition: Evidence from
simulation, aphasia, and {ERP} studies. Brain and Language, 86(2):207 –
225.

Dominey, P. F., Inui, T., and Hoen, M. (2009). Neural network processing
of nat- ural language: Ii. towards a uniﬁed model of corticostriatal
function in learning sentence comprehension and non-linguistic
sequencing. Brain and Language, 109(2-3):80–92.

Dominey, P. F., Lelekov, T., Ventre-Dominey, J., and Jeannerod, M.
(1998). Disso- ciable processes for learning the surface structure and
abstract structure of senso- rimotor sequences. Journal of Cognitive
Neuroscience, 10(6):734–51.

Douglas, R., Koch, C., Mahowald, M., Martin, K., and Suarez, H. (1995).
Recurrent

excitation in neocortical circuits. Science, 269(5226):981–985.

Doya, K. (2000). Complementary roles of basal ganglia and cerebellum in
learning

and motor control. Curr Opin Neurobiol, 10(6):732–739.

Doya, K. (2002). Metalearning and neuromodulation. Neural Netw,
15(4-6):495–

506. 

Duncan, J. (2001). An adaptive coding model of neural function in
prefrontal cortex.

Nature Reviews Neuroscience 2, 2(11):820–829.

Eichenbaum, H. (2014). Time cells in the hippocampus: a new dimension
for map-

ping memories. Nature Reviews Neuroscience, 15(11):732–744.

Eichenbaum, H., Otto, T., and Cohen, N. (1994). Two functional
components of the

hippocampal memory system. Behav. Brain Sci., 17.

Elman, J. L. (1990). Finding structure in time. Cognitive Science,
14(2):179–211. Elman, J. L. (1991). Distributed representations, simple
recurrent networks, and

grammatical structure. Machine Learning, 7:195–225.

Enel, P., Procyk, E., Quilodran, R., and Dominey, P. F. (2016).
Reservoir computing properties of neural dynamics in prefrontal cortex.
PLoS Comput Biol, 12(6):1– 35.

Foster, D., Morris, R., and Dayan, P. (2000). A model of hippocampally
dependent navigation, using the temporal difference learning rule.
Hippocampus, 10(1):1– 16.

Frank, M. J. (2005). Dynamic dopamine modulation in the basal ganglia: a
neu- rocomputational account of cognitive deﬁcits in medicated and
nonmedicated parkinsonism. Journal of Cognitive Neuroscience,
17(1):51–72.

Frank, M. J., Doll, B. B., Oas-Terpstra, J., and Moreno, F. (2009).
Prefrontal and striatal dopaminergic genes predict individual
differences in exploration and ex- ploitation. Nature neuroscience,
12(8):1062–1068.

Fr´egnac, Y. and Laurent, G. (2014). Where is the brain in the human
brain project?

Nature, 513.

Frisch, S., Schlesewsky, M., Saddy, D., and Alpermann, A. (2002). The
{P600} as

an indicator of syntactic ambiguity. Cognition, 85(3):B83 – B92.

AI and Computational Neuroscience

29

Friston, K. (2012). A Free Energy Principle for Biological Systems.
Entropy (Basel,

Switzerland), 14(11):2100–2121.

Fritzke, B. (1995). A growing neural gas network learns topologies. In
Tesauro, G., Touretzky, D., and Leen, T., editors, Advances in Neural
Information Processing Systems 7, pages 625–632. MIT Press, Cambridge
MA.

Fuhs, M. C. and Touretzky, D. S. (2006). A spin glass model of path
integration in

rat medial entorhinal cortex. Journal of Neuroscience.

Fusi, S., Miller, E. K., and Rigotti, M. (2016). Why neurons mix: high
dimen- sionality for higher cognition. Current Opinion in Neurobiology,
37:66 – 74. Neurobiology of cognitive behavior.

Fuster, J. M. (1991). Chapter 10 the prefrontal cortex and its relation
to behavior. In Holstege, G., editor, Role of The Forebrain in Sensation
and Behavior, volume 87 of Progress in Brain Research, pages 201 – 211.
Elsevier.

Fyhn, M., Molden, S., Witter, M. P., Moser, E. I., and Moser, M.-B.
(2004). Spatial

representation in the entorhinal cortex. Science, 305(5688):1258–1264.

Gaussier, P., Banquet, J., Sargolini, F., Giovannangeli, C., Save, E.,
and Poucet, B. (2007). A model of grid cells involving extra hippocampal
path integration, and the hippocampal loop. Journal of integrative
neuroscience, 6(03):447–476.

Gaussier, P., Joulain, C., Banquet, J.-P., Leprˆetre, S., and Revel, A.
(2000). The vi- sual homing problem: an example of robotics/biology
cross fertilization. Robotics and autonomous systems, 30(1):155–180.

Gaussier, P., Moga, S., Quoy, M., and Banquet, J.-P. (1998). From
perception-action loops to imitation processes: A bottom-up approach of
learning by imitation. Ap- plied Artiﬁcial Intelligence,
12(7-8):701–727.

Gaussier, P., Revel, A., Banquet, J.-P., and Babeau, V. (2002). From
view cells and place cells to cognitive map learning: processing stages
of the hippocampal system. Biological Cybernetics, 86:15–28.

Gaussier, P. and Zrehen, S. (1995). Perac: A neural architecture to
control artiﬁcial

animals. Robotics and Autonomous Systems, 16(2):291–320.

Gerfen, C. and Wilson, C. (1996). The basal ganglia. In Swanson, L.,
Bj¨orklund, A., and H¨okfelt, T., editors, Handbook of chemical
neuroanatomy, volume Vol 12: Integrated Systems of the CNS, Part III,
chapter Chapter II, pages 371–468. Elsevier Science B.V.

Giovannangeli, C., Gaussier, P., and Banquet, J. (2006). Robustness of
visual place cells in dynamic indoor and outdoor environment.
International Journal of Ad- vanced Robotic Systems, 3(2):115–124.

Girard, B., Cuzin, V., Guillot, A., Gurney, K., and Prescott, T. (2003).
A basal ganglia inspired model of action selection evaluated in a
robotic survival task. Journal of Integrative Neuroscience,
2(2):179–200.

Girard, B., Filliat, D., Meyer, J.-A., Berthoz, A., and Guillot, A.
(2005). Integration of navigation and action selection functionalities
in a computational model of cortico-basal ganglia-thalamo-cortical
loops. Adaptive Behavior, 13(2):115–130. Girard, B., Tabareau, N., Pham,
Q., Berthoz, A., and Slotine, J.-J. (2008). Where neuroscience and
dynamic system theory meet autonomous robotics: a contract- ing basal
ganglia model for action selection. Neural Networks, 21(4):628–641.

30

F. Alexandre, P.F. Dominey, P. Gaussier, B. Girard, M. Khamassi and N.P.
Rougier

Gluck, M. A. and Myers, C. E. (1993). Hippocampal mediation of stimulus
repre-

sentation: A computational theory. Hippocampus, 3(4):491–516.

Goldman-Rakic, P. S. (1987). Circuitry of primate prefrontal cortex and
regulation

of behavior by representational memory. Comprehensive Physiology.

Gould, J. H. I., Cusick, C. G., Pons, T. P., and Kaas, J. H. (1986). The
relationship of corpus callosum connections to electrical stimulation
maps of motor, supple- mentary motor, and frontal eye ﬁelds in owl
monkeys. Journal of Comparative Neurology, 247.

Graybiel, A. (1998). The basal ganglia and chunking of action
repertoires. Neuro-

biol Learn Mem, 70(1-2):119–136.

Grossberg, S. and Merrill, J. (1996). The hippocampus and cerebellum in
adaptively timed learning, recognition, and movement. Journal of
Cognitive Neuroscience, 8:257–277.

Guazzelli, A., Bota, M., Corbacho, F. J., and Arbib, M. A. (1998).
Affordances. motivations, and the world graph theory. Adaptive Behavior,
6(3-4):435–471. Gurney, K., Prescott, T., and Redgrave, P. (2001a). A
computational model of action selection in the basal ganglia. I. A new
functional anatomy. Biological Cyber- netic, 84(6):401–410.

Gurney, K., Prescott, T., and Redgrave, P. (2001b). A computational
model of action selection in the basal ganglia. II. Analysis and
simulation of behaviour. Biol Cybern, 84(6):411–423.

Guthrie, M., Leblois, A., Garenne, A., and Boraud, T. (2013).
Interaction between cognitive and motor cortico-basal ganglia loops
during decision making: a com- putational study. Journal of
neurophysiology, 109(12):3025–3040.

Haber, S., Fudge, J., and McFarland, N. (2000). Striatonigrostriatal
pathways in primates form an ascending spiral from the shell to the
dorsolateral striatum. J Neurosci, 20(6):2369–2382.

Hafting, T., Fyhn, M., Molden, S., Moser, M.-B., and Moser, E. (2005).
Microstruc-

ture of a spatial map in the entorhinal cortex. Nature, 436:801–806.

Hagoort, P. and Brown, C. M. (2000). {ERP} effects of listening to
speech compared to reading: the p600/sps to syntactic violations in
spoken sentences and rapid serial visual presentation. Neuropsychologia,
38(11):1531 – 1549.

Harnard, S. (1990). The symbol grounding problem. Physica D: Nonlinear
Phe-

nomena, 42:335–346.

Hassabis, D., Kumaran, D., Summerﬁeld, C., and Botvinick, M.
Neuroscience-inspired artiﬁcial intelligence. Neuron, 95(2):245–258.

(2017).

Hasselmo, M. E., Schnell, E., and Barkai, E. (1995). Dynamics of
learning and recall at excitatory recurrent synapses and cholinergic
modulation in rat hippocampal region ca3. The Journal of neuroscience,
15(7):5249–5262.

Hasselmo, M. E., Wyble, B. P., and Wallenstein, G. V. (1996). Encoding
and re- trieval of episodic memories: role of cholinergic and gabaergic
modulation in the hippocampus. Hippocampus, 6(6):693–708.

Hebb, D. (1949). The Organization of Behavior : A Neuropsychological
Theory.

Wiley, New York.

AI and Computational Neuroscience

31

Hermans, M. and Schrauwen, B. (2012). Recurrent kernel machines:
Computing

with inﬁnite echo state networks. Neural Comput., 24(1):104–133.

Hinaut, X. and Dominey, P. F. (2013). Real-time parallel processing of
grammatical structure in the fronto-striatal system: a recurrent network
simulation study using reservoir computing. PLoS ONE, 8(2):e52946.

Hirel, J., Gaussier, P., Quoy, M., Banquet, J.-P., Save, E., and Poucet,
B. (2013). The hippocampo-cortical loop: spatio-temporal learning and
goal-oriented planning in navigation. Neural Networks, 43:8–21.

Hoen, M., Pachot-Clouard, M., Segebarth, C., and Dominey, P. F. (2006).
When Broca experiences the Janus syndrome: an ER-fMRI study comparing
sentence comprehension and cognitive sequence processing. Cortex,
42(4):605–623.

Hopﬁeld, J. J. (1982). Neural networks and physical systems with
emergent col- lective computational abilities. Proceedings of the
national academy of sciences, 79(8):2554–2558.

Houk, J., Adams, J., and Barto, A. (1995). A model of how the basal
ganglia gen- In Houk, J., Davis, J., erate and use neural signals that
predict reinforcement. and Beiser, D., editors, Models of Information
Processing in the Basal Ganglia, chapter 13, pages 249–270. MIT Press,
Cambridge, MA.

Hubel, D. and Wiesel, T. (1959). Receptive ﬁelds of single neurones in
the cat’s

striate cortex. The Journal of physiology, 148(3):574–591.

Hubel, D. and Wiesel, T. (1969). Anatomical demonstration of columns in
the mon-

key striate cortex. Nature, 221.

Hubel, D. H., Wiesel, T. N., and Stryker, M. P. (1978). Anatomical
demonstration

of orientation columns in macaque monkey. J. Comp. Neur., 177:361–380.

Humphries, M., Khamassi, M., and Gurney, K. (2012). Dopaminergic control
of the exploration-exploitation trade-off via the basal ganglia.
Frontiers in Neuro- science, 6:9.

Ito, M. and Doya, K. (2011). Multiple representations and algorithms for
reinforce- ment learning in the cortico-basal ganglia circuit. Current
opinion in neurobiol- ogy, 21(3):368–373.

Jaeger, H. (2001). The ”echo state” approach to analysing and training
recurrent neural networks-with an erratum note. Bonn, Germany: German
National Re- search Center for Information Technology GMD Technical
Report, 148:34.

Jaeger, H. and Haas, H. (2004). Harnessing nonlinearity: Predicting
chaotic systems

and saving energy in wireless communication. science, 304(5667):78–80.

Jauffret, A., Cuperlier, N., and Gaussier, P. (2015). From grid cells
and visual place cells to multimodal place cell: a new robotic
architecture. Frontiers in Neuro- robotics, 9(1).

Joel, D., Niv, Y., and Ruppin, E. (2002). Actor-critic models of the
basal ganglia: new anatomical and computational perspectives. Neural
Netw, 15(4-6):535–547. Jordan, M. I. (1986). Serial order: A parallel,
distributed processing approach. Tech- nical Report 8604, Institute for
Cognitive Science, University of California, San Diego.

Kaas, J. (1991). Plasticity of sensory and motor maps in adult mammals.
Annual

review of neuroscience, 14(1).

32

F. Alexandre, P.F. Dominey, P. Gaussier, B. Girard, M. Khamassi and N.P.
Rougier

Kaas, J., Merzenich, M., and Killackey, H. (1983). The reorganization of
somatosen- sory cortex following peripheral nerve damage in adult and
developing mammals. Annual Review of Neuroscience, 6:325–356.

Kaas, J. H. (1994). Aotus: The owl monkey, chapter The organization of
sensory and

motor cortex in owl monkeys. Baer, J. F. and Weller, R. E. and Kakoma,
I.

Kaski S., Jangas, J. and Kohonen, T. (1998). Bibliography of
self-organizing map

papers: 1981-1997. Neural Computing Surveys.

Katz, L. C. and Shatz, C. J. (1996). Synaptic activity and the
construction of cortical

circuits. Science, 274.

Khamassi, M., Girard, B., Clodic, A., Devin, S., Renaudo, E., Pacherie,
E., Alami, R., and Chatila, R. (2016). Integraton of action, joint
action and learning in robot cognitive architectures. Intellectica,
2016/1:169–203.

Khamassi, M. and Humphries, M. (2012).

Integrating cortico-limbic-basal gan- glia architectures for learning
model-based and model-free navigation strategies. Frontiers in
Behavioral Neuroscience, 6:79.

Khamassi, M., Lacheze, L., Girard, B., Berthoz, A., and Guillot, A.
(2005). Actor- critic models of reinforcement learning in the basal
ganglia: from natural to ariﬁ- cial rats. Adaptive Behavior, 13:131–148.

Khamassi, M., Martinet, L.-E., and Guillot, A. (2006). Combining
self-organizing maps with mixtures of experts: application to an
actor-critic model of reinforce- ment learning in the basal ganglia. In
From Animals to Animats 9, LNAI 4095, pages 394–405. Berlin, Heidelberg:
Springer-Verlag.

Khamassi, M., Mulder, A., Tabuchi, E., Douchamps, V., and Wiener, S.
(2008). Anticipatory reward signals in ventral striatal neurons of
behaving rats. European Journal of Neuroscience, 28:1849–1866.

Khamassi, M., Velentzas, G., Tsitsimis, T., and Tzafestas, C. (2018).
Robot fast adaptation to changes in human engagement during simulated
dynamic social interaction with active exploration in parameterized
reinforcement learning. IEEE Transactions on Cognitive and Developmental
Systems, page in revision.

Kim, J. J., Clark, R. E., and Thompson, R. F. (1995). Hippocampectomy
impairs the memory of recently, but not remotely, acquired trace
eyeblink conditioned responses. Behavioral neuroscience, 109(2):195.

Kober, J., Bagnell, J. A., and Peters, J. (2013). Reinforcement learning
in robotics: A survey. The International Journal of Robotics Research,
pages 1238–1274. Koechlin, E., Ody, C., and Kouneiher, F. (2003). The
Architecture of Cognitive

Control in the Human Prefrontal Cortex. Science, 302(5648):1181–1185.

Kohonen, T. (1982). Self-organized formation of topologically correct
feature maps.

Biological Cybernetics, 43.

Kraus, B. J., Robinson, R. J., White, J. A., Eichenbaum, H., and
Hasselmo, M. E. (2013). Hippocampal ”time cells”: time versus path
integration. Neuron, 78(6):1090–1101.

Krichmar, J. L., Seth, A. K., Nitz, D. A., Fleischer, J. G., and
Edelman, G. M. (2005). Spatial navigation and causal analysis in a
brain-based device modeling cortical- hippocampal interactions.
Neuroinformatics, 3(3):197–221.

AI and Computational Neuroscience

33

Lemon, R. (2008). An enduring map of the motor cortex. Experimental
Physiology,

93:798–802.

Leyton, S. and Sherrington, C. (1917). Observations on the excitable
cortex of the chimpanzee, orang-utan and gorilla. Quaterly Journal of
Experimntal Physiology, 11:135–222.

Linde, Y., Buzo, A., and Gray, R. (1980). An algorithm for vector
quantization

design. IEEE Trans. on Communications.

Lukosevicius, M. and Jaeger, H. (2009). Survey: Reservoir computing
approaches

to recurrent neural network training. Comput. Sci. Rev., 3(3):127–149.

Maass, W., Joshi, P., and Sontag, E. D. (2007). Computational aspects of
feedback

in neural circuits. PLoS Comput Biol, 3(1):1–20.

Maass, W., Natschl¨ager, T., and Markram, H. (2002). Real-time computing
without stable states: A new framework for neural computation based on
perturbations. Neural Comput., 14(11):2531–2560.

Macqueen, J. B. (1967). Some methods of classiﬁcation and analysis of
multivariate observations. In Proceedings of the Fifth Berkeley
Symposium on Mathematical Statistics and Probability, pages 281–297.

Markram, H., Muller, E., Ramaswamy, S., Reimann, M. W., Abdellah, M.,
Sanchez, C. A., Ailamaki, A., Alonso-Nanclares, L., Antille, N.,
Arsever, S., Kahou, G. A., Berger, T. K., Bilgili, A., Buncic, N.,
Chalimourda, A., Chindemi, G., Courcol, J.-D., Delalondre, F., Delattre,
V., Druckmann, S., Dumusc, R., Dynes, J., Eile- mann, S., Gal, E.,
Gevaert, M. E., Ghobril, J.-P., Gidon, A., Graham, J. W., Gupta, A.,
Haenel, V., Hay, E., Heinis, T., Hernando, J. B., Hines, M., Kanari, L.,
Keller, D., Kenyon, J., Khazen, G., Kim, Y., King, J. G., Kisvarday, Z.,
Kumbhar, P., Lasserre, S., Le B´e, J.-V., Magalh˜aes, B. R. C.,
Merch´an-P´erez, A., Meystre, J., Morrice, B. R., Muller, J., Mu˜noz
C´espedes, A., Muralidhar, S., Muthurasa, K., Nachbaur, D., Newton, T.
H., Nolte, M., Ovcharenko, A., Palacios, J., Pastor, L., Perin, R.,
Ranjan, R., Riachi, I., Rodr´ıguez, J.-R., Riquelme, J. L., R¨ossert,
C., Sfyrakis, K., Shi, Y., Shillcock, J. C., Silberberg, G., Silva, R.,
Tauheed, F., Tele- font, M., Toledo-Rodriguez, M., Tr¨ankler, T., Van
Geit, W., D´ıaz, J. V., Walker, R., Wang, Y., Zaninetta, S. M.,
DeFelipe, J., Hill, S. L., Segev, I., and Sch¨urmann, F. (2015).
Reconstruction and Simulation of Neocortical Microcircuitry. Cell,
163(2):456–492.

Marr, D. (1982). Vision: A Computational Investigation into the Human
Represen- tation and Processing of Visual Information. Henry Holt and
Co., Inc., New York, NY, USA.

Marr, D., Willshaw, D., and McNaughton, B. (1971). Simple memory: a
theory for archicortex. Philosophical Transactions of the Royal Society
of London. Series B, Biological Sciences, 262(841):23–81.

Marshall, W. H., Woolsey, C. N., and Bard, R. (1937). Cortical
representation of

tactile sensibility as indicated by cortical potentials. Science, 85.

Martinetz, T. M., Berkovich, S. G., and Schulten, K. J. (1993).
Neural-gas network for vector quantization and its application to
time-series prediction. IEEE Trans. on Neural Networks, 4(4):558–569.

34

F. Alexandre, P.F. Dominey, P. Gaussier, B. Girard, M. Khamassi and N.P.
Rougier

Mataric, M. J. (1991). Navigating with a rat brain: a neurobiologically
inspired model. In From Animals to Animats; Proceedings of the First
International Con- ference on Simulation of Adaptive Behavior. MIT
Press, Cambridge, Mass.

McClelland, J. L., McNaughton, B. L., and O’Reilly, R. C. (1995). Why
there are complementary learning systems in the hippocampus and
neocortex: insights from the successes and failures of connectionist
models of learning and memory. Psychological review, 102(3):419.

McCulloch, W. and Pitts, W. (1943). A logical calculus of the ideas
immanent in

nervous activity. Bulletin of Mathematical Biophysics, 5:115–133.

McNaughton, B., Barnes, C., Gerrard, J., Gothard, K., Jung, M., Knierim,
J., Ku- drimoti, H., Qin, Y., Skaggs, W., Suster, M., et al. (1996).
Deciphering the hip- pocampal polyglot: the hippocampus as a path
integration system. The Journal of Experimental Biology, 199(1):173–185.

McNaughton, B., Battaglia, F. P., Jensen, O., Moser, E. I., and Moser,
M.-B. (2006). Path integration and the neural basis of the ’cognitive
map’. Nat Rev Neurosci, 7:663–678.

McNaughton, B. L. and Morris, R. G. (1987). Hippocampal synaptic
enhancement and information storage within a distributed memory system.
Trends in neuro- sciences, 10(10):408–415.

Merzenich, M. and Kaas, J. (1982). Reorganization of mammalian
somatosensory cortex following peripheral nerve injury. Trends in
Neurosciences, 5:434–436. Merzenich, M. M. and Kaas, J. H. (1980).
Progress in psychobiology and physiolog- ical psychology, chapter
Principles of organization of sensory-perceptual systems in mammals.
Sprague, J. M. and Epstein, A. N.

Milford, M. J. and Wyeth, G. F. (2008). Mapping a suburb with a single
cam- era using a biologically inspired slam system. IEEE Transactions on
Robotics, 24(5):1038–1053.

Milford, M. J., Wyeth, G. F., and Rasser, D. (2004). Ratslam: a
hippocampal model for simultaneous localization and mapping. In Robotics
and Automation, 2004. Proceedings. ICRA’04. 2004 IEEE International
Conference on, volume 1, pages 403–408. IEEE.

Miller, E. K. and Cohen, J. D. (2001). An integrative theory of
prefrontal cortex

function. Annu. Rev. Neurosci., 24:167–202.

Mink, J. W. (1996). The basal ganglia: focused selection and inhibition
of competing

motor programs. Progress in neurobiology, 50(4):381–425.

Morris, G., Nevet, A., Arkadir, D., Vaadia, E., and Bergman, H. (2006).
Midbrain dopamine neurons encode decisions for future action. Nat
Neurosci, 9(8):1057– 1063.

Morris, R., Garrud, P., Rawlins, J., and O’Keefe, J. (1982). Place
navigation im-

paired in rats with hippocampal lesions. Nature, 297:24.

Naya, Y. and Suzuki, W. A. (2011). Integrating what and when across the
primate

medial temporal lobe. Science, 333(6043):773–776.

Nelson, M. and Rinzel, J. (1995). The Hodgkin-Huxley model., chapter 4,
pages

27–51. Bower and Beeman. The book of Genesis. Springer, New York.

AI and Computational Neuroscience

35

N’Guyen, S., Thurat, C., and Girard, B. (2014). Saccade learning with
concurrent cortical and subcortical basal ganglia loops. Frontiers in
Computational Neuro- science, 8:48.

Niv, Y., Daw, N., Joel, D., and Dayan, P. (2007). Tonic dopamine:
opportunity costs and the control of response vigor. Psychopharmacology
(Berl), 191(3):507–520. Oja, M., Kaski, S., and Kohonen, T. (2003).
Bibliography of self-organizing map

papers: 1998-2001 addendum. Neural Computing Surveys.

O’Keefe, J. and Dostrovsky, J. (1971). The hippocampus as a spatial map.
pre- liminary evidence from unit activity in the freely-moving rat.
Brain research, 34(1):171–175.

O’Keefe, J. and Nadel, N. (1978). The hippocampus as a cognitive map.
Clarendon

Press, Oxford.

O’Reilly, R. C. and Frank, M. J. (2006). Making Working Memory Work: A
Com- putational Model of Learning in the Prefrontal Cortex and Basal
Ganglia. Neural Comp., 18(2):283–328.

O’Reilly, R. C., Herd, S. A., and Pauli, W. M. (2010). Computational
models of

cognitive control. Current Opinion in Neurobiology, 20(2).

O’Reilly, R. C. and Rudy, J. W. (2000). Computational principles of
learning in the

neocortex and hippocampus. Hippocampus, 10(4):389–397.

Palminteri, S., Khamassi, M., Jofﬁly, M., and Coricelli, G. (2015).
Medial prefrontal cortex and the adaptive regulation of reinforcement
learning parameters. Nature Communications, 6:8096.

Pearlmutter, B. A. (1995). Gradient calculations for dynamic recurrent
neural net-

works: a survey. IEEE Trans Neural Netw, 6(5):1212–1228.

Penﬁeld, W. and Boldrey, E. (1937). Somatic motor and sensory
representation in

the cerebral cortex as studied by electrical stimulation. Brain, 60.

Pfeifer, R., Bongard, J., and Grand, S. (2007). How the body shapes the
way we

think: a new view of intelligence. Bradford Books. MIT Press.

Pfeiffer, B. E. and Foster, D. J. (2013). Hippocampal place-cell
sequences depict

future paths to remembered goals. Nature, 497(7447):74–79.

Prescott, T., Redgrave, P., and Gurney, K. (1999). Layered control
architectures in

robots and vertebrates. Adaptive Behavior, 7:99–127.

Quirk, G. J., Muller, R. U., Kubie, J. L., and Ranck, J. (1992). The
positional ﬁring properties of medial entorhinal neurons: description
and comparison with hippocampal place cells. The Journal of
Neuroscience, 12(5):1945–1963.

Redgrave, P., Prescott, T., and Gurney, K. (1999). The basal ganglia: a
vertebrate

solution to the selection problem? Neuroscience, 89(4):1009–1023.

Redish, A. D. and Touretzky, D. S. (1997). Cognitive maps beyond the
hippocam-

pus. Hippocampus, 7(1):15–35.

Renaudo, E., Girard, B., Chatila, R., and Khamassi, M. (2014). Design of
a con- trol architecture for habit learning in robots. In Duff, A.,
Lepora, N., Mura, A., Prescott, T., and Verschure, P., editors,
Biomimetic and Biohybrid Systems, Third International Conference, Living
Machines 2014, pages 249–260.

Renaudo, E., Girard, B., Chatila, R., and Khamassi, M. (2015).
Respective advan- tages and disadvantages of model-based and model-free
reinforcement learning

36

F. Alexandre, P.F. Dominey, P. Gaussier, B. Girard, M. Khamassi and N.P.
Rougier

in a robotics neuro-inspired cognitive architecture. Procedia Computer
Science, 71:178–184.

Rescorla, R. and Wagner, A. (1972). A theory of pavlovian conditioning:
variations in the effectiveness of reinforcement and nonreinforcement.
In Black, A. and Prokasy, W., editors, Classical Conditioning II:
Current Research and Theory, pages 64–99. Appleton-Century-Crofts,
New-York.

Revel, A., Gaussier, P., Lepretre, S., and Banquet, J. (1998).
Planiﬁcation versus sensory-motor conditioning: what are the issues ? In
SAB’98: From animals to animats 5, pages 129–138.

Reynolds, J., Hyland, B., and Wickens, J. (2001). A cellular mechanism
of reward-

related learning. Nature, 413(6851):67–70.

Rigotti, M., Barak, O., Warden, M. R., Wang, X. J., Daw, N. D., Miller,
E. K., and Fusi, S. (2013). The importance of mixed selectivity in
complex cognitive tasks. Nature, 497(7451):585–590.

Roesch, M., Calu, D., and Schoenbaum, G. (2007). Dopamine neurons encode
the better option in rats deciding between differently delayed or sized
rewards. Nat Neurosci, 10(12):1615–1624.

Rolls, E. T. and O’Mara, S. M. (1995). View-responsive neurons in the
primate

hippocampal complex. Hippocampus, 5(5):409–424.

Rougier, N. P. and Boniface, Y. (2011). Dynamic Self-Organising Map.
Neurocom-

puting, 74(11):1840–1847.

Russell, S. and Norvig, P. (2003). Artiﬁcial Intelligence - A Modern
Approach.

Prentice-Hall, Upper Saddle River, New Jersey.

Samsonovich, A. and McNaughton, B. L. (1997). Path integration and
cognitive Journal of Neuro-

mapping in a continuous attractor neural network model. science.

Schaul, T., Quan, J., Antonoglou, I., and Silver, D. (2015). Prioritized
experience

replay. arXiv preprint arXiv:1511.05952.

Schmajuk, N. (1991). A neural network approach to hippocampal function
in clas-

sical conditioning. Behavioral Neuroscience, 105(1):82–110.

Schmajuk, N. and Thieme, A. (1992). Purposive behavior and cognitive
mapping:

a neural network model. Biological Cybernetic, 67:165–174.

Schultz, W., Dayan, P., and Montague, P. (1997). A neural substrate of
prediction

and reward. Science, 275(5306):1593–1599.

Schwartz, E. L. (1990). Computational Neuroscience. MIT Press,
Cambridge, MA,

USA.

Scoville, W. B. and Milner, B. (1957). Loss of recent memory after
bilateral hip- pocampal lesions. Journal of neurology, neurosurgery, and
psychiatry, 20(1):11. Searle, J. R. (1980). Minds, brains, and programs.
Behavioral and Brain Sciences,

3:417–457.

Servan-Schreiber, D., Printz, H., and Cohen, J. (1990). A network model
Science,

of catecholamine effects: gain, signal-to-noise ratio, and behavior.
249(4971):892–895.

Sharp, P. E. (1999). Comparison of the timing of hippocampal and
subicular spatial

signals: implications for path integration. Hippocampus, 9(2):158–172.

AI and Computational Neuroscience

37

Stephenson-Jones, M., Samuelsson, E., Ericsson, J., Robertson, B., and
Grillner, S. (2011). Evolutionary conservation of the basal ganglia as a
common vertebrate mechanism for action selection. Current Biology,,
21(13):1081–1091.

Sun, R. and Alexandre, F. (1997). Connectionist-Symbolic Integration :
From Uni-

ﬁed to Hybrid Approaches. Lawrence Erlbaum Associates.

Sutton, R. and Barto, A. (1998). Reinforcement Learning: An
Introduction. Cam-

bridge, MA: MIT Press.

Tessier-Lavigne, M. and Goodman, C. S. (1996). The molecular biology of
axon

guidance. Science, 274.

Teyler, T. J. and DiScenna, P. (1986). The hippocampal memory indexing
theory.

Behavioral neuroscience, 100(2):147.

Thompson, R. F. (1986). The neurobiology of learning and memory.
Science,

233(4767):941–947.

Tolman, E. (1948). Cognitive maps in rats and men. The Psychological
Review,

55(4):189–208.

Touretzky, D. S. and Redish, A. D. (1996). Theory of rodent navigation
based on

interacting representations of space. Hippocampus, 6(3):247–270.

Treves, A. and Rolls, E. (1994). Computational analysis of the role of
the hippocam-

pus in memory. Hippocampus, 4(3):374–391.

Uylings, H., Groenewegen, H., and Kolb, B. (2003). Do rats have a
prefrontal cor-

tex? Behav Brain Res, 146(1-2):3–17.

van der Meer, M., Kurth-Nelson, Z., and Redish, A. D. (2012).
Information pro-

cessing in decision-making systems. The Neuroscientist, 18(4):342–359.

Voorn, P., Vanderschuren, L., Groenewegen, H., Robbins, T., and
Pennartz, C. (2004). Putting a spin on the dorsal-ventral divide of the
striatum. Trends Neu- rosci, 27(8):468–474.

Wan, H., Touretzky, D., and Redish, A. (1994). Towards a computational
theory In Mozer, M., Smolensky, P., Touretzky, D., Elman, J., and of rat
navigation. Weigend, A., editors, Proc. of the 1993 Connectionist Models
Summer School, pages 11–19. Lawrence Erlbaum Associates.

Wang, J. X., Kurth-Nelson, Z., Tirumala, D., Soyer, H., Leibo, J. Z.,
Munos, R., Blundell, C., Kumaran, D., and Botvinick, M. (2016). Learning
to reinforcement learn. arXiv preprint arXiv:1611.05763.

Wang, L., Li, X., Hsiao, S. S., Lenz, F. A., Bodner, M., Zhou, Y. D.,
and Fuster, J. M. (2015). Differential roles of delay-period neural
activity in the monkey dorsolateral prefrontal cortex in visual-haptic
crossmodal working memory. Proc. Natl. Acad. Sci. U.S.A.,
112(2):E214–219.

Willshaw, D. J. and von der Malsburg, C. (1976). How patterned neural
connections can be set up by self-organization. Proceedings of the Royal
Society London B, 194.

Yamins, D. L. K. and DiCarlo, J. J. (2016). Using goal-driven deep
learning models

to understand sensory cortex. Nature Neuroscience, 19(3):356–365.

Yin, H. and Knowlton, B. (2006). The role of the basal ganglia in habit
formation.

Nat Rev Neurosci, 7(6):464–476.

38

F. Alexandre, P.F. Dominey, P. Gaussier, B. Girard, M. Khamassi and N.P.
Rougier

Zipser, D. (1985). A computational model of hippocampal place ﬁelds.
Behavioral

neuroscience, 99(5):1006–1018.


