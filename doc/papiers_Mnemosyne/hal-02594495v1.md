Hierarchical-Task Reservoir for Anytime POS Tagging
from Continuous Speech
Luca Pedrelli, Xavier Hinaut

To cite this version:

Luca Pedrelli, Xavier Hinaut. Hierarchical-Task Reservoir for Anytime POS Tagging from Continuous
Speech. 2020 International Joint Conference on Neural Networks (IJCNN 2020), Jul 2020, Glasgow,
Scotland, United Kingdom. ￿hal-02594495￿

HAL Id: hal-02594495

https://inria.hal.science/hal-02594495

Submitted on 15 May 2020

HAL is a multi-disciplinary open access
archive for the deposit and dissemination of sci-
entific research documents, whether they are pub-
lished or not. The documents may come from
teaching and research institutions in France or
abroad, or from public or private research centers.

L’archive ouverte pluridisciplinaire HAL, est
destinée au dépôt et à la diffusion de documents
scientifiques de niveau recherche, publiés ou non,
émanant des établissements d’enseignement et de
recherche français ou étrangers, des laboratoires
publics ou privés.

Hierarchical-Task Reservoir for
Anytime POS Tagging from Continuous Speech

Luca Pedrelli
1. INRIA Bordeaux Sud-Ouest.
2. LaBRI, Bordeaux INP, CNRS, UMR 5800.
3. Institut des Maladies Neurod´eg´en´eratives,
Universit´e de Bordeaux, CNRS, UMR 5293.
Bordeaux, France.
orcid.org/0000-0002-4752-7622

Xavier Hinaut
1. INRIA Bordeaux Sud-Ouest.
2. LaBRI, Bordeaux INP, CNRS, UMR 5800.
3. Institut des Maladies Neurod´eg´en´eratives,
Universit´e de Bordeaux, CNRS, UMR 5293.
Bordeaux, France.
orcid.org/0000-0002-1924-1184

Abstract—We propose a novel architecture called Hierarchical-
Task Reservoir (HTR) suitable for real-time sentence parsing
from continuous speech. Accordingly, we introduce a novel task
that consists in performing anytime Part-of-Speech (POS) tagging
from continuous speech. This HTR architecture is designed to
address three sub-tasks (phone, word and POS tag estimation)
with increasing levels of abstraction. These tasks are performed
by the consecutive layers of the HTR architecture. Interestingly,
the qualitative results show that the learning of sub-tasks en-
forces low frequency dynamics (i.e. with longer timescales) in
the more abstract layers. We compared HTR with a baseline
hierarchical reservoir architecture (in which each layer is an
ESN that addresses the same POS tag estimation). Moreover,
we also performed a thorough experimental comparison with
several architectural variants. Finally, the HTR obtained the
best performance in all experimental comparisons. Overall, the
proposed approach will be a useful tool for further studies
regarding both the modeling of language comprehension in
a neuroscience context and for real-time implementations in
Human-Robot Interaction (HRI) context.

Index Terms—Recurrent Neural Networks, Hierarchical Reser-
voir Computing, Natural Language Processing, Speech Recogni-
tion, Part-of-Speech, POS tagging, Anytime Process, Hierarchical
Processing.

I. INTRODUCTION

Language unfolds in time. Both the brains of the speaker
and the hearer need to produce/process complex acoustic
streams. We easily forget the complexity at hand when we
speak our native language. However, when one hears an
unknown foreign language, little or no information could be
extracted from the acoustic stream. Another crucial property
of spoken language is the short availability of the signal
(compared to written text): the brain needs to process it as
quickly as possible because the phonological memory buffer
is very limited [1].

Natural Language Processing (NLP) tools (e.g., CoreNLP,
NLTK, Gensim and SpaCy) are quite different from how our
brains work. One example is the typical use of bag-of-words
(i.e. considering a sentence as unordered words instead of
considering the timing of the sequence of words). Most of the
recent NLP tools based on deep learning approaches [2]–[4]
are focused on encoder/decoder mechanisms and bidirectional

architectures to address temporal and more complex depen-
dencies between words. However, these implementations need
to parse the whole sentence before producing an output. On
the contrary, brains process sentences online in an anytime
fashion (i.e. ability to have a partial understanding before the
end of the sentence).

For instance, in the case of human-robot interaction through
spoken language [5]–[7], a common approach is still to per-
form parsing of sentences based on a restricted grammar parser
written by hand, with speech preprocessing done with Google
Speech API. It seems that even with Deep Learning based ar-
chitecture that try to integrate NLP and vision processing, there
is still the need for ad-hoc word correction from the speech
API [8]. Overall, these steps are performed by different mod-
ules instead of being a fully integrated architecture. Typically
the speech recognition module is implemented through a deep
learning approach based on sequence transduction approaches
[9]–[11]. In these approaches there are two main limitations:
1) one need to know in advance the maximal length of the
sentences in the test phase and 2) the speech module needs
to read the whole sentence in order to produce the phone
recognition of the input signal. Therefore, these approaches
are not suitable for a real-time human-robot interaction system
or for biologically plausible cognitive models.

Since another important characteristic of the brain is the
presence of hierarchical structures the deep learning (DL)
paradigm took inspiration from this fact: for example for
the vision areas hierarchy (cortical areas V1, V2, V3, V4,
etc.). However, this is only a shallow inspiration, because
the brain is processing information in a much more dynamic
way: exempliﬁed for instance by the presence of feedforward
and feedback connections [12] (e.g. there are strong feedback
connections from area V4 to area V2). In particular, deep
Recurrent Neural Networks (RNNs) [13]–[15] are a class
of neural networks suitable for time series processing able
to intrinsically develop hierarchical and distributed temporal
features [16], [17]. However, from the learning mechanisms
point of view the use of back-propagation in deep neural
networks makes these approaches not biologically plausible.
A good solution based on RNNs that avoids the use of back

propagation is the Reservoir Computing (RC) paradigm [18],
[19]. Indeed, RC is widely used to model brain processes with
RC instances such as Echo State Networks (ESNs) and Liquid
State Machines [19]. In this case, we focus on the ESN model
that represents a discrete-time system.

More recent works introduce hierarchically organized mod-
els [9], [20] and deep recurrent architectures [16], [17] in the
context of RC. In particular, Hierarchical Reservoir Computing
(HRC) obtained results competitive with the state-of-the-art on
continuous speech recognition [9].

Following these aspects, the aim of this paper is to in-
troduce a novel model called Hierarchical-Task Reservoir
(HTR) for anytime sentence parsing from continuous speech
which combines the following aspects: i) suitable for real-time
implementations of sentence parsing from continuous speech,
ii) learning different levels of abstraction through a hierarchy
of sub-tasks, iii) ability to learn a hierarchical representation of
temporal features, iv) a suitable tool for neuroscience linguistic
studies.

Based on such considerations, we construct a novel sentence
parsing dataset for Anytime POS tagging basing on the TIMIT
continuous speech recognition corpus [21]. TIMIT is one of
the most used dataset for studies and analyses on continuous
speech recognition in the context of neural networks [9],
[10]. With the SpaCy library we computed the POS labels
starting from the sentences of the corpus. We quantitatively
and qualitatively compare HTR and HRC architectures on the
Anytime POS task. Then, we qualitatively study the dynamics
developed in the layers of the HTR architecture. Finally,
we quantitatively compare architectural variants of HTR to
empirically study the effect of the hierarchy of sub-tasks on
the model performance.

II. RESERVOIR COMPUTING

Reservoir Computing (RC) [22] is a paradigm for the design
in which the
and training of Recurrent Neural Networks,
recurrent
layer is non-linear, randomly initialized and left
untrained. Within RC networks, in this work we are focused
on Leaky Integrator Echo State Networks (LI-ESNs) [23]. As
shown in Figure 1, the architecture of LI-ESN is composed by
a non-linear recurrent layer called the reservoir and a linear
output layer called readout. Omitting the bias in the following

Fig. 1. An example of Echo State Network architecture.

formulas for the ease of notation, the state transition function
of the LI-ESN is computed as follows:

x(t) = (1 − a)x(t − 1) + a tanh(Winu(t) + Wx(t − 1)), (1)
where u(t) ∈ RNU is the input at
time t, x(t) ∈ RNR
is the reservoir state, Win ∈ RNR×NU is the input matrix,
W ∈ RNR×NR is the recurrent matrix, a ∈ [0, 1] is the leaky
parameter and tanh is the element-wise hyperbolic tangent.
The reservoir is initialized considering the echo state property
the values of matrix W are randomly
[24]. Accordingly,
initialized from a uniform distribution and then rescaled in
order to have a spectral radius ρ (i.e., the maximum absolute
eigenvalue of W) less than 1. However, in practical cases the
ESP can be satisﬁed also with values of ρ ≥ 1 [25]. The
values in matrix Win are randomly initialized from a uniform
distribution and then rescaled in order to have a norm σ. The
output of LI-ESN is computed as follows:

y(t) = Woutx(t),
where y(t) ∈ RNY is the output at time t and Wout is
the output matrix. The values in Wout represent the free-
parameters of the model which are trained to solve the task
by computing typical approaches for linear optimization such
as ridge regression. In the following, we use the term ESN to
refer to LI-ESN model.

(2)

Hierarchical Reservoir Computing (HRC) [9] is a RC ap-
proach that obtained promising results in Acoustic Modeling.
HRC networks are composed by a cascade of ESNs in which
each network is individually trained on the basis of the output
of the previous ESN. In this way the higher models can correct
the errors produced by the previous models. As shown by
recent studies regarding Deep Reservoir Computing [16], [17],
a main advantage offered by the layering in recurrent archi-
tectures is the ability to develop a hierarchical organization of
temporal features independently by the learning algorithm.

III. HIERARCHICAL-TASK RESERVOIR

The

source

code of

available
the
on our Github repository: https://github.com/lucapedrelli/
PedrelliHinaut2020 IJCNN

experiments

is

In this paper, we introduce a novel architecture based on
HRC that we call Hierarchical-Task Reservoir (HTR). The
architecture is composed by a hierarchy of layers in which
each layer is an ESN optimized on a different task. Each ESN
is fed by the previous ESN in the hierarchy and the pipeline
is progressively optimized from the ﬁrst layer to the last layer.
The main differences between HTR and the approach proposed
in [9] are two: (i) instead of addressing only phone recognition
tasks, HTR architectures deal with a different kind of task for
each layer with a progressively increased level of abstraction
(corresponding to a decreased frequency of labels). In this
way, the learning process inﬂuences progressively the level of
abstraction of the representation in higher layers; (ii) instead
of controlling by hand the internal dynamics of the higher
layers with ﬁxed input scales and ﬁxed leaky integrators, in
HTR we optimize all the hyper-parameters in each layer. In

this way, the hyper-parameters are optimized depending on the
task addressed by the layer.

The Figure 2 shows an example of the maximal size HTR
architecture used in this paper. The state computation of the
HTR architecture for the layer l = 1, ..., NL is deﬁned by
following equations:

x(l)(t) = (1 − a(l))x(l)(t − 1) + a(l) f (W(l)

in i(l)(t) + W(l)x(l)(t − 1))
(3)

in which the input i(l) of layer l is deﬁned as follow:

i(l)(t) =






u(t)

if

l = 1

y(l−1)(t)

if

l > 1.

(4)

Algorithm 1 HTR Training
1: procedure TRAINHTR(i(1), NT rials)
for l in 1, ..., NL do
2:

3:

4:
5:
6:
7:
8:

9:

θ(l) = generateTrials(NT rials)

HTR(l) = modelSelection(θ(l), l)

(cid:46) generate NT rials models

(cid:46) select the best model on task l

i(l+1) = computeOutput(HTR(l), i(l))

(cid:46) compute the output as input for the next layer

return HTR

(cid:46) return the whole trained architecture

U

where u(1) ∈ RN (1)
input with an input
is the external
and y(l−1)(t) ∈ RN (l)
dimension of N (1)
is the output of
U
layer l − 1 where N (l)
U is the dimension of the output of layer
l − 1 which coincides with the dimension of the input of layer
l. The output of layer l is computed as follows:

U

y(l)(t) = W(l)

outx(l)(t),

(5)

where x(l)(t) ∈ RNR is the reservoir state of layer l, W(l)
in ∈
RNR×N (l)
U is the input matrix of layer l with a input dimension
of N (l)
U , W(l) ∈ RNR×NR is the recurrent matrix of layer l,
W(l)
out is the output matrix, a(l) ∈ [0, 1] is the leaky parameter
and f (l) is the activation function of layer l. In this work we
consider f (l) = tanh for each l. The values of matrices W(l)
in
and W(l) are randomly initialized from uniform distribution
and then rescaled such that the euclidean norm of W(l)
in is
equal to σ(l) and the spectral radius of W(l) is equal to ρ(l). It
deserves to be mentioned that the values ρ(l) and a(l) have an
important role in controlling stability of deep recurrent neural
networks [26].

In HTR architecture, each ESN is individually optimized
on a different task by performing random search (for hyper-
parameter tuning) and ridge regression (for readout learning)
following the pipeline from the layer 1 to the layer NL. The
main architecture that we consider is composed by 3 layers:
(i) the ﬁrst layer is optimized to estimate phones from speech
SP→PH, (ii) the second layer is optimized to estimate words
from phones PH→WD and (iii) the third layer is optimized
to estimate POS tagging from words WD→POS. Overall, we
denote the whole HTR architecture as SP→PH→WD→POS.
The Algorithm 1 describes the optimization procedure for
HTR considering NL layers, NT rials trials and external input
i(1). In the following section we provide the description of the
considered tasks.

IV. ANYTIME POS TAGGING FROM SPEECH RECOGNITION

In this section, we introduce a novel grammatical analysis
task for anytime part-of-speech (POS) tagging from continu-
ous speech recognition. It consists in a supervised classiﬁca-
tion task in which the aim is to continuously provide the POS
Tagging estimation for each 10 ms frame of speech signal.

Fig. 2. HTR architecture: the main model we propose to address
the hierarchical task SP→PH→WD →POS. The architecture receive the
features extracted from the speech signal with MFCC algorithm each 10 ms.
The ﬁrst layer is optimized for SP→PH (Task 1), the second layer is optimized
for PH→WD (Task 2) and, ﬁnally, the third layer is optimized for WD→POS
(Task 3).

Accordingly, the approaches evaluated on this task must be
suitable for real-time implementations.

For this purposes, we focus on the TIMIT [21] corpus which
is widely used in the ﬁeld of continuous speech recognition.
The dataset contains recordings from 630 American speakers
and each speaker read 10 phonetically rich sentences. Each
frame of 10 ms is labelled with a phone and a word class with
a total of 61 phones and 6012 words. We divided the dataset in
a training set containing 540 speaker and a test set containing
90 speaker. We use the last 135 speaker for the validation set.

As in [9], we reduce the number of phones from 61 to 51
merging similar sounds. In order to keep efﬁciency in training
processes, we considered only the 50 most frequent words of
the corpus, each having one output label, and merging the
others in a single out-of-vocabolary (OOV) label.

We extended the dataset by computing the POS tagging
by using SpaCy tools for each sentence with a total of 17
grammatical elements. The POS labelling is performed by
computing a POS tag for each word. Then, the POS tag is
associated with a class label for each frame that belongs to the
duration of the word in the speech signal. Finally, a silence
label is considered as an additional class in correspondence
with silence frames in the speech signal. For each 10ms the
Mel Frequency Cepstral Coefﬁcients (MFCC) [9] algorithm
computes the 39 components used as input for the architectures
(see [9] for the setup of MFCC).

In order to form the whole hierarchical task for POS tagging
and to deﬁne the different architectures for the experiments,
we consider 10 sub-tasks listed in the following: SP→PH
(predict phones from speech), PH→WD (words from phones),
WD→POS (POS from words), SP→WD (words from speech),
SP→POS (POS from speech), PH→POS (POS from phones),
WD→POS (POS from words), WD(lb)→POS (POS from
words labels), PH(lb)→WD (words from phones labels) and
PH(lb)→POS (POS from phones labels). In all
the
evaluation is performed by computing the frame error rate
(FER) which is the ratio between the number of correctly
classiﬁed time steps and the total number of time steps.

tasks,

For each task, the model selection is performed with a
random search evaluating the performance on the validation
set. For each trial, we sample the hyper-parameters spectral
radius in the following way: ρ(l) and input norm σ(l) from a
logarithmic distribution in [0.1, 10], leak-rate a(l) from a uni-
form distribution in [0.1, 1] and ridge (regularisation) λ(l) from
a discrete uniform distribution in [100, 10−1, ..., 10−7, 10−8].
In training phase a search grid is performed on λ(l) consid-
ering values reported above. As in standard RC, each hyper-
parametrization (i.e. ρ(l), σ(l), a(l) and λ(l)) is evaluated aver-
aging the results obtained by randomly initialized architectures
(that we call guesses). In this work we consider 5 guesses.

In order to keep the execution of the hyper-parameter search
in a reasonable time, we did not optimize the input scaling of
each MFCC input component individually. Triefenbach et al.
[9] optimized inputs scaling by clusters: optimizing the scaling
for signals, signal derivative (delta), and signal acceleration
(i.e. delta-delta). Moreover, since we have several experiments
to perform (due to a thorough architectural comparison) on a
signiﬁcantly big corpus we performed preliminary experiments
to ﬁx a proper number of units. We ﬁnd that 1000 units are
a good tradeoff between accuracy and efﬁciency, considering
also that the proposed approach must be efﬁciently executable
in real-time. Accordingly, in the following all experiments are
performed by using NR = 1000 for each ESN layer.

The 3 main architectures that we consider in this paper are
listed in Table I. Therefore, in HTR ﬁrst the layer ESN 1 (see
Figure 2) is optimized to estimate phones (PH) from speech

TABLE I
THE TASK STRUCTURE OF THE ARCHITECTURES HTR, HRC AND ESN.

Name
HTR
HRC
ESN

Architecture
SP→PH →WD→POS
SP→POS→POS→POS
SP→POS

(SP) then ESN 2 is optimized to recognize words (WD) from
phones and ﬁnally ESN 3 is optimized to estimate POS tagging
from words. Differently, in HRC case, ESN 1 is optimized to
estimate POS from HRC while ESN 2 and ESN 3 are both
optimized to estimate POS tagging from POS tagging. The
ESN in I is optimize to estimate POS tagging from speech
implementing 3000 units (the same total number of units of
HTR and HRC).

V. EXPERIMENTAL RESULTS

A. Architecture Comparison on the Anytime POS Task

Here, we present the results obtained by HTR, HRC and
ESN on the Anytime POS Task. Table II shows the test FERs
achieved by HTR, HRC and ESN. The HTR obtained the
best result with a test FER of 45.51% followed by HRC and
ESN that achieved 49.55% and 53.40% test FER, respectively.
First, we can note that HRC achieve 4.08 FER points less

TABLE II
TEST FERS: HTR, HRC AND ESN ON THE ANYTIME POS TASK.

Architecture
HTR
HRC
ESN

Test
45.51(0.04)%
49.32(0.12)%
53.40(0.15)%

than ESN. This highlights that solving the Anytime POS task
with a pipeline of ESN modules, as performed in HRC, allows
us to improve the results with respect to the use of a single
ESN module (containing a total equivalent number of reservoir
units). Moreover, the hierarchical-task approach implemented
by HTR (i.e. considering progressively more abstract sub-tasks
in higher layers) allows us to have a further improvement on
the Anytime POS task outperforming HRC architecture by
4.04 FER points.

B. Improving HRC Perf. by increasing the number of layers

In this section, we show the experimental results obtained
by HRC on the Anytime POS Task by varying the number
of layers. Table III shows the test FERs achieved by HRC
considering progressively more layers in the architecture (i.e.,
1, 2 and 3 layers). The HRC architecture obtained 50.35%,
49.55% and 49.32% test FER for 1, 2 and 3 layers, re-
spectively. We can note that the error obtained by the HRC
architecture decreases when the number of layers increases.
This conﬁrms the ability of the next layers to correct the errors
made by the previous layers as achieved in [9]. This aspect
is also interesting in relation to results obtained by the ESN
with 3000 units (see Table II). This suggests that, in terms of

TABLE III
TEST FERS OBTAINED ON THE ANYTIME POS TASK BY PROGRESSIVELY
ADDING LAYERS IN THE HRC ARCHITECTURE.

HRC
SP→POS
SP→POS→POS
SP→POS→POS→POS

FER
50.35(0.19)%
49.55(0.14)%
49.32(0.12)%

number of layers increases. The sentence considered is ”don’t
ask me to carry an oily rag like that” with the associated
the POS tags ”AUX VERB PRON PART VERB DET ADJ
NOUN SCONJ DET”. Figure 4a represents the 39 components
computed by the MFCC algorithm over the input audio at each
time step of 10ms. Figure 4b shows the output values of layer
1, Figure 4c shows the output values of layer 2 and Figure 4d
shows the output values of layer 3.

performance on the considered task, a hierarchical pipeline of
ESN moules is much more effective than a big single ESN.

C. Improving HTR Performance with the Hierarchical Task

In this section, we show the experimental results obtained
by HTR on the Anytime POS Task by varying the number
of layers. Table IV shows the test FERs achieved by HTR
considering progressively more layers in the architecture (i.e.,
1, 2 and 3 layers). The HTR architecture progressively im-

TABLE IV
TEST FERS OBTAINED ON THE ANYTIME POS TASK BY
PROGRESSIVELY ADDING LAYERS IN THE HTR ARCHITECTURE.

HTR
SP→POS
SP→PH→POS
SP→PH→WD→POS

FER
50.35(0.19)%
47.62(0.12)%
45.51(0.04)%

prove the performance when the number of layers increases
obtaining 50.35%, 47.62% and 45.51% test FER for 1, 2 and
3 layers respectively. Figure 3 shows the test FERs obtained
by HTR and HRC architecture with 1, 2 and 3 layers. First,

Fig. 4. Input and outputs for the full HTR architecture (3 layers). The
Figure a) shows the components of the MFCC computed from the input audio
relative to a pronounced sentence. Figures b), c) and d) show the output
values of the HTR architecture with 1, 2 and 3 layers respectively. The x-
axis represents the time and the y-axis represents the values. At several time
points, the label corresponding to the output with the maximum activation is
indicated.

In Figures 4b, c and d, each line represents the value of
an output neuron over the time, each neuron is associated to
a POS class and the output of the model at each time step
is the POS class associated to the neuron with the maximum
value. The estimated POS tags are shown in Figures 4 above
the output values. From Figure 4b we can see that in many
areas the estimation is not precise since some output units
have overlapped ranges. For instance after the estimation of
silence (label #h) in the ﬁrsts time steps the model suffers
from uncertainty with a consequent decrease of accuracy for
those predictions. Interestingly, from Figure 4c we can see
that considering one more layer in the HTR architecture the
estimation is signiﬁcantly improved since the predictions are
more clearly separated. This means that performing the phone
recognition before the POS estimation improves signiﬁcantly
the quality of the classiﬁer. Finally, in the HTR with 3 layers

Fig. 3. Test FER obtained by HTR and HRC when the number of layers
increases. The vertical intervals represent the standard deviation achieved by
the models.

we can note that the ability of HTR to correct errors among
the layers is better than the HRC case. Interestingly, while
HTR obtained a signiﬁcant improvement when the number of
layers increases, the performance tends to saturate quickly in
the case of HRC. This highlights the importance of the HTR
architecture which addresses sub-tasks with an increasing level
of abstraction.

D. Qualitative Comparison Between HTR and HRC

In this section, we show a qualitative comparison between
HTR and HRC of the Anytime POS estimation when the

050100150200250-40-2002040608005010015020025000.511.5h#AUXVERBPRONPARTVERBDETADJNOUNSCONJDETh#DETNOUN05010015020025000.511.5h#AUXh#NOUNh#NOUNVERBPRONNOUNVERBNOUNNOUNNOUNDETDETNOUNh#05010015020025000.511.5h#DETAUXVERBPRONPARTVERBDETADJNOUNSCONJDETh#b) SP > POSd) SP > PH > WD > POSc) SP > PH > POSa) SP (MFCC)Time stepsOutput Valuesthe (see Figure 4d) the quality of the classiﬁcation is further
improved.

Figures 5 show the qualitative analysis performed on the top
layers of the HRCs with 1, 2 and 3 layers. Although between

Fig. 5. Input and outputs for various HRC architectures (layers 1, 2 and
3). The Figure a) shows the components of the MFCC computed from the
input audio relative to a pronounced sentence. Figures b), c) and d) show the
output values of the HRC architecture with 1, 2 and 3 layers respectively. The
x-axis represents the time and the y-axis represents the values. At several time
points, the label corresponding to the output with the maximum activation is
indicated.

the ﬁrst and the second layers we have a small improvement
of predictions if we compare the values of the output layers of
HRC and HTR we can note that HTR provides a signiﬁcantly
better quality of classiﬁcation (see Figure 5d and Figure 4d).

E. Qualitative Analysis of HRT

In this section, we present the qualitative analysis performed
on the HTR architecture with 3 layers (SP→PH→WD→POS).
Figures 6b, c and d show the predictions of the layer 1, 2
and 3 relative to the phone, words and POS classiﬁcations
respectively. As we expected, since tasks are different and
progressively more abstract, we can see from Figures 6b and
6c that the layers values goes from an higher to a lower
frequency of prediction. This means that the readouts trained
on different kinds of tasks with different label frequencies
force progressively the dynamic of the layers from high to
low frequencies.

In Figures 6c and d, at the dashed vertical lines, we can see
an interesting example in which the model is able to estimate
the correct POS even if the word is OOV (i.e. label class for

Fig. 6. Input and outputs of the intermediate outputs of the full HTR
architecture (3 layers). The Figure a) shows the components of the MFCC
computed from the input audio relative to a pronounced sentence. Figures b),
c) and d) show the output values of the the layers 1, 2 and 3 of the HTR
architecture (i.e. ESN 1, ESN 2 and ESN 3 in Figure 6). The x-axis represents
the time and the y-axis represents the values. At several time points, the label
corresponding to the output with the maximum activation is indicated.

words not in TOP50 most frequent words). In this example,
the ground through labels are “don’t” for the WD task and
“AUX” (auxiliary verb) for the POS task. This highlights that
although the last layer is fed without the direct information
of the previous word the carried information is rich enough
to perform a correct classiﬁcation. It is also worth to mention
that also in the case of readouts progressively trained in this
qualitative evidence highlights the ability of a layer trained in
a different task

F. Architectural Variants of HRT

In this section, we present the results of other architec-
tural variants of HTR. First, we compare SP→PH→POS
with SP→WD→POS in order to evaluate a variant of HTR
without the phone recognition task. Table V shows the test
errors obtained by the two considered architectural vari-
ants. Interestingly, SP→WD→POS is outperformed by both
SP→PH→POS and SP→PH→WD→POS (see Table IV). This
highlights that it is important to address the task SP→PH for
layer 1 instead of addressing directly the task SP→WD.

Moreover, the results presented in Table IV suggest that
the 3rd layer (related to the task WD→POS) plays a relevant
role in the achievement of the global task. Indeed, the error
decreased from 47.62% to 45.51% FER. This highlights the

050100150200250-40-2002040608005010015020025000.511.5h#AUXAUXh#NOUNVERBPRONNOUNVERBNOUNADJADJNOUNSCONJNOUNSCONJDETh#NOUNNOUN05010015020025000.511.5h#NOUNAUXh#NOUNVERBPRONNOUNVERBNOUNADJNOUNSCONJNOUNSCONJDETNOUNh#b) SP > POSd) SP > POS > POS > POSc) SP > POS > POSa) SP (MFCC)NOUN05010015020025000.511.5h#AUXh#NOUNh#NOUNVERBPRONNOUNVERBNOUNNOUNNOUNDETDETNOUNh#Time stepsOutput Values05010015020025000.511.5h#DETVERBPRONPARTVERBDETADJNOUNSCONJDETh#AUX05010015020025000.511.5h#OOVaskOOVmeOOVcarryanoilyraglikethatOOVh#05010015020025000.511.5h#ownzaesh#niypclkehaxrriynswaoraeliyraepclraypclh#aespclh#050100150200250-40-20020406080b) SP > PHd) SP > PH > WD > POSc) SP > PH > WDa) SP (MFCC)Time stepsOutput ValuesTABLE V
TEST FERS ACHIEVED BY ARCHITECTURES SP→PH→POS AND
SP→WD→POS ON THE ANYTIME POS TASK.

TABLE VII
TEST FERS ACHIEVED BY WD(LB)→POS, PH(LB)→WD→POS AND
PH(LB)→POS ARCHITECTURES ON ANYTIME POS TASK.

Architectures
SP→PH→POS
SP→WD→POS

FER
47.62(0.12)%
48.52(0.32)%

Architectures
WD(lb)→POS
PH(lb)→WD→POS
PH(lb)→POS

FER
30.03(0.36)%
41.40(0.13)%
41.81(0.31)%

importance of the 3rd layer in the correction of errors made
by the previous layer. Then the obtained results highlight
that SP→PH→WD→POS is the best choice to improve the
performance on the Anytime POS task.

However, the use of only 50 words out of 6012 for the
WD→POS task could be a bottleneck for the richness of the
information used to solve the POS task. Therefore, a skip
connection between layer 1 and layer 3 could carry more
information and accordingly improve the results. The skip
connection is obtained by concatenating the input of ESN 3
with the output of ESN 1 (see Figure 2), we call this variant
HTR-skip. Table VI shows the test errors achieved by HTR
and HTR-skip. We can see from Table VI that HTR-skip and

TABLE VI
TEST FERS ACHIEVED BY HTR AND HTR-SKIP ON ANYTIME POS TASK.

Architectures
HTR
HTR-skip

FER
45.511(0.04)%
45.506(0.04)%

HTR obtained very similar results. The lack of performance
improvement and the qualitative analysis shown in Figure 6
suggest that the ESN 2 (see Figure 2) can carry enough rich
information even using only the estimation of the 50 words +
OOV label.

Overall, the results obtained by HRC in Table III (i.e. with-
out intermediate tasks) and the results obtained by architectural
variants in Table V (i.e. with only SP→PH or SP→WD
intermediate task) suggest that using several intermediate tasks
is crucial to obtain the best performance.

G. Ground Truth Architectures

Here, we present the results obtained by architectural vari-
ants which address the Anytime POS task starting from the
ground truth of phones or words instead of starting from the
speech signal. In this way, these architectures represent the
performance that the model can reach on the Anytime POS
task with the help of a perfect phone recognition system (i.e.
PH(lb)) or a perfect word recognition system (i.e. WD(lb)).
Table VII shows the test FERs obtained by WD(lb)→POS,
PH(lb)→WD→POS and PH(lb)→POS where WD(lb) and
PH(lb) are the ground truth of words and phones respectively.
As expected WD(lb)→POS obtained the best performance
with a FER of 30.03% followed by PH(lb)→WD→POS with
41.40% FER and PH(lb)→POS with 41.81% FER.

H. Comparing Results

Comparing results from TableVII and Table IV it seems
counter-intuitive that adding the WD task in-between the

PH→POS ﬂow improves performance mostly when starting
from the speech signal (from 47.62% to 45.51%) and not
when starting from the ground truth phones (from 41.81% to
41.81%). Therefore, it suggests that the WD task is actually
used to correct errors made at the phone-level (ESN 1) in
the full HTR architecture (i.e. SP→PH→WD→POS). This is
another aspect that conﬁrms the usefulness of our Hierarchical-
Task approach, since multiple tasks with an increasing level
of abstraction enable the correction of previous errors.

Moreover, we can say that the performance achieved by
WD(lb)→POS architecture (30.03% FER) shows that ob-
taining POS labels starting from phones (PH) signiﬁcantly
increases the difﬁculty of the task compared to starting from
words (WD). Therefore,
this suggests that using the WD
task in the full HTR architecture is crucial to have better
performances on POS tagging.

Finally, it is worth mentioning that the baseline performance
that we could expect to reach with the full HTR architecture
(41.40% FER with PH(lb)→WD→POS) starting from the
speech signal, is not so far away from the 45.51% obtained
starting from a perfect phone recognition system PH(lb).

VI. DISCUSSION

In this work, with the HTR architecture we introduced
a novel tool suitable for real-time sentence parsing [27] of
continuous speech. For this purpose, we introduced a novel
task for the Anytime POS tagging from continuous speech
extending the TIMIT corpus. The HTR is composed by a
hierarchy of ESNs in which each ESN is optimized on a
different task (i.e. phone, word, POS tag recognition). The
level of abstraction of the task increases when the layer’s level
increases.

The qualitative experiments performed on the output values
of the layers highlight that the learning of sub-tasks with
a progressively decreasing temporal frequency of labels for
higher layers force a progressively low temporal frequency
dynamic according to the depth of the architecture. This ability
can help the HTR to progressively develop a proper level
of abstraction of the input signal in order to improve the
performance of the whole task.

Moreover, we quantitatively compared HTR with a typical
hierarchical reservoir architecture that implements the estima-
tion of POS tags in each layer. Then, we also compare the HTR
with several architectural variants. The quantitative results
show that the whole hierarchy of sub-tasks implemented in
HTR is crucial
to signiﬁcantly improve the performance.
Finally, HTR obtain only about 4 points of FER less than the

architecture trained starting from the outputs of a perfect phone
recognition system (PH(lb)→WD→POS). We can conclude
that HTR is competitive with the state-of-the-art approaches
in the RC ﬁeld on the Anytime POS task.

Overall, the HTR model and the Anytime POS task, intro-
duced in this paper, are interesting tools for further studies
regarding the language comprehension in neuroscience ap-
proaches [28], [29] or for the implementation of a real-time
human-robot interaction (HRI) [5]–[7], [30].

In future work, it would be interesting to get inspiration
from neurobiological ﬁndings on brain hierarchy: in primate
brains there are feedforward and feedback connections be-
tween brain areas of different abstraction levels [12]. Indeed,
information does not only go from sensory (i.e. less abstract)
to more integrated areas (i.e. more abstract), it also ﬂows
from more abstract to less abstract areas. Thus, hierarchical
models could be designed to incorporate these bottom-up
processing (i.e. from sensory to more abstract representations)
and top-down processing (i.e. from abstract to more sensory
representations). In order to apply this idea to the current
HTR model, composed of feedforward reservoirs, we could
add backwards reservoirs (i.e. feedback reservoirs)1. These
backwards reservoirs would be trained to predict a less abstract
task (of the layer n − 1) given a more abstract task (of the
layer n). This would enable these backwards reservoirs to
predict and update low-level representations based on more
high-level representations. Most importantly, this could enable
to not only predict but also to postdict [31] low-level outputs:
this corresponds to predict the past given current information,
i.e. update previous beliefs or perceptions. The integration
of both prediction and postdiction in an architecture reminds
the ability of bi-LSTMs to use both past and future input
features [32]. Consequently, the output representations may
need to be updated in order to use a kind of a-temporal
representation of readouts: i.e. representing outputs for t − n,
t and t + n for any time step n, instead of just representing
the current output at time step t.

The proposed HTR architecture is a promising ﬁrst step
towards general hierarchical modeling of language compre-
hension and production starting from speech signal. Further
works in this line of research could focus on the addition
of more abstract layers to perform tasks such as sentence
chunking/segmentation, Name Entity Recognition, Sentiment
Analysis or Semantic-Role Labelling [33]. Moreover, because
the long-term goal of this architecture is to model brain
processes, thus is not limited to speech or natural language
processing, but sufﬁciently general to be applied to a variety
of tasks, such as gesture recognition or sensorimotor learning.

REFERENCES

[1] M. H. Christiansen et al. Creating language: Integrating evolution,

acquisition, and processing. MIT Press, 2016.

[2] I. Sutskever et al. Sequence to sequence learning with neural networks.

In NIPS, pp. 3104–3112, 2014.

1The word feedback could be misleading because already used in Reservoir
Computing terminology. Thus, we replace the word feedback by backwards
in the following discussion.

[3] D. Bahdanau et al. Neural machine translation by jointly learning to

align and translate. arXiv preprint arXiv:1409.0473, 2014.

[4] A. Vaswani et al. Attention is all you need. In NIPS, pp. 5998–6008,

2017.

[5] X. Hinaut et al. Exploring the acquisition and production of grammatical
constructions through human-robot interaction with echo state networks.
Frontiers in Neurorobotics, 8, 2014.

[6] J. Twiefel et al. Using Natural Language Feedback in a Neuro-inspired
Integrated Multimodal Robotic Architecture. In Proc. of RO-MAN, New
York City, USA, 2016.

[7] X. Hinaut and J. Twiefel. Teach your robot your language! trainable
neural parser for modelling human sentence processing: Examples for
15 languages. IEEE TCDS, 2019.

[8] J. Hatori et al.

Interactively picking real-world objects with uncon-

strained spoken language instructions. In IEEE ICRA, May 2018.
[9] F. Triefenbach et al. Acoustic modeling with hierarchical reser-
voirs. IEEE Transactions on Audio, Speech, and Language Processing,
21(11):2439–2450, November 2013.

[10] A. Graves et al. Speech recognition with deep recurrent neural networks.

In IEEE ICASSP, pp. 6645–6649, 2013.

[11] J. K. Chorowski et al. Attention-based models for speech recognition.

In NIPS, pp. 577–585, 2015.

[12] N. T. Markov and H. Kennedy. The importance of being hierarchical.

Current Opinion in Neurobiology, 23(2):187–194, April 2013.

[13] J. Schmidhuber. Learning complex, extended sequences using the
principle of history compression. Neural Computation, 4(2):234–242,
1992.

[14] S. E. Hihi and Y. Bengio. Hierarchical recurrent neural networks for

long-term dependencies. In NIPS, pp. 493–499, 1995.

[15] M. Hermans and B. Schrauwen. Training and analysing deep recurrent

neural networks. In NIPS, pp. 190–198, 2013.

[16] C. Gallicchio et al. Deep reservoir computing: a critical experimental

analysis. Neurocomputing, 268:87–99, 2017.

[17] C. Gallicchio et al. Design of deep echo state networks. Neural

Networks, 108:33 – 47, 2018.

[18] D. Verstraeten et al. An experimental uniﬁcation of reservoir computing

methods. Neural Networks, 20(3):391–403, 2007.

[19] M. Lukoˇseviˇcius and H. Jaeger. Reservoir computing approaches to
recurrent neural network training. Computer Science Review, 3(3):127–
149, 2009.

[20] F. Triefenbach et al.

Phoneme recognition with large hierarchical

reservoirs. In NIPS, pp. 2307–2315, 2010.

[21] J. Garofolo et al. Timit acoustic-phonetic continuous speech corpus.

Linguistic Data Consortium LDC93S1, 1993.

[22] H. Jaeger. The ”echo state” approach to analysing and training recurrent
neural networks. Technical Report 148, German National Research
Center for Information Technology GMD, Bonn, Germany, 2001.
[23] H. Jaeger et al. Optimization and applications of echo state networks
with leaky-integrator neurons. Neural Networks, 20(3):335–352, 2007.
[24] H. Jaeger and H. Haas. Harnessing nonlinearity: Predicting chaotic
Science,

systems and saving energy in wireless communication.
304(5667):78–80, 2004.

[25] C. Gallicchio. Chasing the echo state property. In ESANN, 2018.
[26] C. Gallicchio and A. Micheli. Echo state property of deep reservoir
computing networks. Cognitive Computation, 9(3):337–350, May 2017.
[27] J. Twiefel et al. Syntactic reanalysis in language models for speech

recognition. In IEEE ICDL-EpiRob, 2017.

[28] X. Hinaut and P. Dominey. Real-time parallel processing of grammatical
structure in the fronto-striatal system: a recurrent network simulation
study using reservoir computing. PLoS ONE, 8(2):e52946, 2013.
[29] X. Hinaut. Which input abstraction is better for a robot syntax
acquisition model? phonemes, words or grammatical constructions? In
IEEE ICDL-EpiRob, September 2018.

[30] X. Hinaut and M. Spranger. Learning to parse grounded language using

reservoir computing. In IEEE ICDL-EpiRob, August 2019.

[31] A. Hanuschkin et al. A hebbian learning rule gives rise to mirror neurons
and links them to control theoretic inverse models. Frontiers in Neural
Circuits, 7, 2013.

[32] Z. Huang et al. Bidirectional LSTM-CRF models for sequence tagging.

arXiv preprint arXiv:1508.01991, 2015.

[33] J. Twiefel et al. Semantic role labelling for robot instructions using

Echo State Networks. In ESANN, 2016.

