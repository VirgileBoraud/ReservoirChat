Autonomous Machine Learning Frédéric Alexandre

To cite this version:

Frédéric Alexandre. Autonomous Machine Learning. ERCIM News, 2016,
Special theme: Machine Learning, 107. ￿hal-01401888￿

HAL Id: hal-01401888

https://inria.hal.science/hal-01401888

Submitted on 23 Nov 2016

HAL is a multi-disciplinary open access archive for the deposit and
dissemination of sci- entific research documents, whether they are pub-
lished or not. The documents may come from teaching and research
institutions in France or abroad, or from public or private research
centers.

L’archive ouverte pluridisciplinaire HAL, est destinée au dépôt et à la
diffusion de documents scientifiques de niveau recherche, publiés ou
non, émanant des établissements d’enseignement et de recherche français
ou étrangers, des laboratoires publics ou privés.

Autonomous Machine Learning

F. Alexandre

Inspiration from human learning sets the focus on one essential but
poorly studied characteristic of learning: Autonomy.

One remarkable characteristic of human learning is that, whereas we are
in general not excellent in one specific domain, we are quite good in
most of them, and able to adapt when a new problem appears. We are
versatile and adaptable, which are critical properties for autonomous
learning: we can learn in a changing and uncertain world. With neither
explicit labels, nor data preprocessing or segmentation, we are able to
pay attention to important information and neglect noise. We define by
ourselves our goals and the means to reach them, self-evaluate our
performances and re-exploit previously learned knowledge and strategies
in some different context. In contrast, recent advances in Machine
Learning exhibit impressive results, with powerful algorithms surpassing
human performances in some very specific domains of expertise, but these
models still have very poor autonomy.

Our Mnemosyne Inria project-team is working in the Bordeaux Neurocampus
with medical and neuroscientist teams to develop systemic models in
computational neuroscience, focusing on these original characteristics
of human learning. Whereas our primary goal is to develop models of the
different kinds of memory in the brain and of their interactions, with
the objective to exploit them to study neurodegenerative diseases,
another important outcome of our work is to propose original models in
Machine Learning integrating some of these important characteristics.

We believe that important steps toward autonomous learning can be made
along these lines of research:

Developing an interacting system of memories:

Specific circuits in the brain are mobilized to learn explicit knowledge
and others to learn procedures. Besides modeling these circuits,
studying their interactions is crucial to understand how one system can
supervise another, resulting in a more autonomous learning. In the
domain of perceptual learning in the medial temporal lobe, we model
episodic memories storing important events in one trial, and forming
later, by consolidation in other circuits, new semantic categories. In
the domain of decision-making in the loops between the prefrontal cortex
and the basal ganglia, we model cerebral mechanisms by which
goal-directed behavior relying on explicit evaluation of expected
rewards can later become habits, automatically triggered with less
flexibility but increased effectiveness.

Coping with uncertainty:

We learn the rules that govern the world and consider it uncertain for
two main reasons: it can be predictable up to a certain level
(stochastic rules) or non-stationary (changing rules). Whereas standard
probabilistic models are rather good at tackling the first kind of
uncertainty, non- stationarity in a dynamic world raises more difficult
problems. We are studying how regions of the medial prefrontal cortex
are detecting and evaluating the kind and the level of uncertainty by
monitoring recent

history of performance at managing correctly incoming events. These
regions are also reported to activate the release of neuromodulators
like monoamines, known to play a central role in adaptation to
uncertainties [1]. In a nutshell, instead of developing large sets of
circuits to manage uncertainty as stable rules in various contexts, the
cerebral system has rather developed a general-purpose system adaptable
to uncertainty with hyperparameters sensitive to meta-learning by
neuromodulation, as we are currently trying to understand more precisely
[2].

Embodiment for emotional learning:

One important source of autonomy is due to our body itself that tells us
what is good or bad for us; what must be searched or avoided. Pavlovian
learning is modeled to detect and learn to predict biologically-
significant aversive and appetitive (emotional) stimuli which are key
targets for attentional processing and for the organization of behavior.
This learning can be done autonomously if the model of the cerebral
system is associated to a substrate corresponding to the body, including
sensors for pain and pleasure. A step further, we extend the study of
the Pavlovian rules to integrate the effects of Pavlovian responses onto
the body and the neuromodulatory system.

From motivation to self-evaluation:

Considering the brain and the body also introduces physiological needs,
fundamental to introduce internal goals in addition to the external
goals evoked above. This is the basis for renewed approaches regarding
reinforcement learning, defining criteria more complex than a simple
scalar representing an abstract reward. In humans, another important
source of information for learning autonomously is based on self-
evaluation of the performances. It is noticeable that both motivation
and self-evaluation processing are central in cognitive control [3] and
reported to be located in the anterior part of the prefrontal cortex, as
we endeavor to integrate in our models.

In addition to developing models to explore each of these mechanisms in
interaction with neuroscience and medicine, we also integrate them in a
common platform defining the adaptive characteristics of an autonomous
agent exploring an unknown virtual world together with the
characteristics of its artificial body. Beyond Machine Learning, this
numerical testbed is also a precious simulation tool for our medical and
neuroscientist colleagues.

[1] Yu, A.J., and Dayan, P. (2005). Uncertainty, Neuromodulation and
Attention. Neuron 46(4).

[2] Carrere, M., and Alexandre, F. (2016). Modeling the sensory roles of
noradrenaline in action selection. The Sixth Joint IEEE International
Conference Developmental Learning and Epigenetic Robotics.

[3] Koechlin, E., Ody, C., and Kouneiher, F. (2003). The Architecture of
Cognitive Control in the Human Prefrontal Cortex. Science,
302(5648):1181–1185.

Caption of the figure:

Example of a large scale model described in [2], studying the
interactions between two systems in the brain, respectively influenced
by noradrenaline (NE, released by Locus Coeruleus) and dopamine (DA,
released by VTA) and involving different regions of the loops between
the prefrontal cortex (ACC, OFC) and the basal ganglia (Ventral
Striatum, GPi). The NE system evaluates the level of non-stationarity of
sensory input and modifies accordingly the level of attention on sensory
cues, resulting in a shift between exploitation of previously learned
rules and exploration of new rules in the DA system performing action
selection.

Frederic ALEXANDRE, Inria Bordeaux Sud-Ouest, France +33/0 5 47 30 42 60
frederic.alexandre@inria.fr

https://team.inria.fr/mnemosyne/


