Généraliser les possibilités-nécessités pour
l’apprentissage profond
Théophane Vallaeys

To cite this version:

Théophane Vallaeys. Généraliser les possibilités-nécessités pour l’apprentissage profond. [Rapport de
recherche] RR-9422, Inria. 2021, pp.15. ￿hal-03338721v2￿

HAL Id: hal-03338721

https://inria.hal.science/hal-03338721v2

Submitted on 11 Oct 2021

HAL is a multi-disciplinary open access
archive for the deposit and dissemination of sci-
entific research documents, whether they are pub-
lished or not. The documents may come from
teaching and research institutions in France or
abroad, or from public or private research centers.

L’archive ouverte pluridisciplinaire HAL, est
destinée au dépôt et à la diffusion de documents
scientifiques de niveau recherche, publiés ou non,
émanant des établissements d’enseignement et de
recherche français ou étrangers, des laboratoires
publics ou privés.

Distributed under a Creative Commons Attribution 4.0 International License

Généraliser les
possibilités-nécessités
pour l’apprentissage
profond

Théophane Vallaeys

G
N
E
+
R
F
-
-
2
2
4
9
-
-

/

R
R
A
R
N

I

I

RESEARCH
REPORT
N° 9422
Septembre 2021

Project-Team Mnemosyne

N
R
S

I

9
9
3
6
-
9
4
2
0
N
S
S

I

Généraliser les possibilités-nécessités pour
l’apprentissage profond

Théophane Vallaeys

Équipe-Projet Mnemosyne

Rapport de recherche n° 9422 — Septembre 2021 — 14 pages

Résumé : Ce rapport porte sur un stage de 8 semaines eﬀectué avec l’équipe Inria Mnemosyne
travaillant sur l’action exploratoire AIDE (Artiﬁcial Intelligence Devoted to Education), et co-
encadré par Thierry Viéville et Chloé Mercier. Le cadre restait assez libre et peu déﬁni, mais invitait
à chercher à déﬁnir la notion de probabilité/nécessité étendue proposée, et tenter de l’appliquer à
des exemples d’apprentissages.

Mots-clés : apprentissage profond, réseaux de neurones, possibilités, nécessités

RESEARCH CENTRE
BORDEAUX – SUD-OUEST

200 avenue de la Vieille Tour
33405 Talence Cedex

Generalization of possibility-necessity for deep learning

Abstract: This report is about an 8 weeks internship with the Inria Mnemosyne team working
on the exploratory action AIDE (Artiﬁcial Intelligence Devoted to Education), and co-supervised
by Thierry Viéville and Chloé Mercier. The framework remained rather free, but invited to try
to deﬁne the extended notion of probability/necessity oﬀered in the subject, and to try to apply
it to examples of learning.

Key-words: deep learning, neural networks, possibility, necessity

Généraliser les possibilités-nécessités pour l’apprentissage profond

Table des matières

1 Introduction

1.1 Le sujet . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
1.2 Les possibilités/nécessités . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
1.3 Utilisations en IA . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
IA neuro-symbolique . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
1.4

2 Déﬁnir un cadre théorique

2.1 Une proposition de solution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
2.2 Propriétés élémentaires . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . . . . . .
2.3 Réseaux de neurones artiﬁciels
2.3.1 Neurones
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
2.3.2 Fonction de coût . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
2.3.3 Assurer les contraintes . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
2.3.4 Mesure de la précision . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

3 Applications expérimentales

3.1 Données synthétiques . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3.1.1 Données et entrainement . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3.1.2 Zone d’inconnu . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Interprétation des neurones . . . . . . . . . . . . . . . . . . . . . . . . . .
3.1.3
3.2 Application à MNIST . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3.2.1 Perceptron multicouche . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3.2.2 Réseau convolutionnel

4 Conclusion

Références

1

Introduction

1.1 Le sujet

3

3
3
3
4
4

4
6
7
9
9
10
10
11

11
12
12
12
13
14
14
15

15

16

En apprentissage profond, la sortie d’un réseau de neurones est généralement interprétée
comme une probabilité (c’est d’ailleurs le principe des couches softmax). Cependant, ce fonctionnement
ne permet pas de distinguer naturellement le fait de ne pas connaître un sujet, ou de savoir qu’une
information est aléatoire. De plus, ce fonctionnement ne ressemble pas beaucoup à ce que fait un
être humain et l’action AIDE veut explorer l’hypothèse que le raisonnement du cerveau ressemble
plus aux possibilités et nécessités.

Utiliser les possibilités et nécessités dans un réseau de neurones pourrait permettre de mieux
comprendre les raisonnements eﬀectués par le modèle artiﬁciel utilisé et représenter l’incertitude
et la connaissance partielle au delà d’un codage aléatoire.

1.2 Les possibilités/nécessités

Les possibilités et nécessités sont un cadre alternatif aux probabilités. Plutôt que de considérer
une fonction de somme pour l’union et de produit pour la diﬀérence, ce cadre utilise les fonctions
min et max. On ne considérera ici qu’un univers Ω discret, avec Π la possibilité (on garde P pour

RR n° 9422

4

Théophane Vallaeys

la probabilité). Alors on doit avoir ∀x ∈ Ω, Π(x) ∈ [0; 1] et maxx∈Ω Π(x) = 1. La nécessité est la
fonction duale, c’est à dire ν(A) = 1−Π(A). De plus, pour tout A, B non-nécessairement disjoints,
Π(A ∪ B) = max(Π(A), Π(B)) et ν(A ∩ B) = min(ν(A), ν(B)). Des détails supplémentaires et
des propriétés sont présentées dans [Benferhat14].

Alors que les probabilités peuvent représenter la logique classique, les possibilités et nécessités

peuvent représenter la logique modale, comme établi en [Denœux20].

1.3 Utilisations en IA

La notion de possibilité et nécessité a été appliquée à l’IA symbolique. Dans [Tettamanzi17],
cette notion est utilisée avec les base de connaissances RDF, qui est d’ailleurs un outil utilisé par
l’action AIDE. Ces bases de connaissances représentes des relations de tout type entre des objets,
et le contexte possibilité-nécessité permet de nuancer ces relations sur des catégories générales
(par exemple, tous les oiseaux ne volent pas, mais c’est souvent le cas).

Dans le cadre de l’apprentissage profond, une tentative d’utiliser les possibilités et nécessités
a été faite dans [Ishibuchi91]. Cette utilisation se résume à entraîner deux réseaux, l’un donnant
une possibilité et l’autre une nécessité, avec deux fonctions de coût adaptées et utiliser une
descente de gradient classique.

[Drago199] donne quelques bases du calcul avec des intervalles, puis une méthode pour séparer
l’espace en trois zones : la zone vrai, la zone fausse, et celle incertaine. Le réseau employé possède
un seul neurone en plus de la sortie, et la séparation est une suite de segments (en 2D, et un
ensemble d’hyperplans en général).

1.4

IA neuro-symbolique

L’intérêt des possibilités et nécessités serait de mieux représenter le raisonnement humain sur
des connaissances partielles, et de pouvoir expliciter quelques propriétés de ses mécanismes, car
c’est un but de l’action exploratoire AIDE que de pouvoir comprendre ce type de fonctionnements
et les rapprocher du comportement humain.

Il existe un grand nombre d’approches pour l’IA neuro-symbolique, avec diﬀérents niveaux,
présenté dans [Garcez20]. En utilisant le vocabulaire introduit dans ce papier, l’approche que j’ai
choisie est une représentation localiste. C’est à dire qu’une propriété est associée à un neurone
précis, alors qu’une représentation distribuée représente une combinaison par un vecteur de
valeurs sur tous les neurones d’une couche. Cependant je n’ai pas eu le temps d’intégrer une
vrai composante symbolique de manière expérimentale, et les réseaux présentés sont du Type 1
selon ce document, c’est à dire sans composante symbolique explicite.

L’une des approches pour l’apprentissage neuro-symbolique est l’utilisation de Logic Tensor
Networks, présentée dans [Seraﬁni16]. Les opérations du réseau utilisent des fonctions lui permettant
de représenter des opérations de logique à valeurs réelles dans sa structure particulière. [Donadello17]
montre que l’on peut l’appliquer à des problèmes d’interprétation sémantique d’image de manière
très eﬃcace. Bien que je n’ai pas utilisé cette structure, cela m’a servi à voir comment les fonctions
standard d’apprentissage profond pouvaient être modiﬁées pour développer une autre approche.

2 Déﬁnir un cadre théorique

Le sujet du stage s’interrogeait sur l’utilisation de couples (ν, Π) de nécessité-possibilité avec
pour seules contraintes que 0 (cid:54) ν (cid:54) π (cid:54) 1, sans contraindre de rester sur les axes avec Π(x) = 1
ou ν(x) = 0. Le but est d’avoir une interprétation sémantique possible plus large du résultat. Une
piste évoquée était d’utiliser les nombres complexes, que j’ai cependant écartée car les opérations

Inria

Généraliser les possibilités-nécessités pour l’apprentissage profond

5

usuelles sur ces derniers ne correspondent pas vraiment à ce que l’on cherche. Une représentation
sous forme d’un couple de R2 suﬃra.

Figure 1 – Représentation du sujet, par Thierry Viéville

Cependant, le cadre formel des possibilités et nécessités qui est détaillé dans [Denœux20]
ne satisfait pas les conditions qui nous intéressent : tout d’abord, on a toujours Π(x) = 1 ou
ν(x) = 0, avec Π la possibilité et ν la nécessité. On voudrait pouvoir utiliser les deux dimensions
du plan en même temps, pour représenter plus ﬁnement une connaissance partielle. De plus, une
telle contrainte n’est pas adaptée aux calculs faits par un RNA (réseau de neurones artiﬁciels)
sur deux variables, et cela reviendrait donc à n’avoir qu’une variable sur [−1; 1], ce qui n’est
guère intéressant en dehors de l’interprétation ﬁnale du résultat.

On voudrait également avoir un encadrement de la probabilité sous la forme ν(x) (cid:54) P (x) (cid:54)
Π(x). Cette dernière propriété n’est pas garantie, et elle est même très vite brisée : si notre réseau
à une très bonne connaissance pour des entrées x, y, avec ν(x) (cid:39) P (x) (cid:39) Π(x) et de même pour
y, et si P (x) (cid:39) P (y), alors P (x ∪ y) (cid:39) P (x) + P (y) > Π(x ∪ y) (cid:39) P (x).

Ainsi, on aurait de grandes diﬃcultés à avoir des fonctions permettant d’eﬀectuer des calculs
compatibles avec les probabilités, possibilités, nécessités, et leur extension sur le plan. Le plus
eﬃcace serait donc de déﬁnir quelque chose d’analogue aux possibilités / nécessités, mais en
partant des propriétés que l’on cherche à satisfaire, donc un encadrement de la probabilité.

[Denœux20] propose de déﬁnir des possibilités et nécessités en tant que fonctions de vraisemblance :

si on observe un état x et que l’on cherche des informations sur une propriété O, on utiliserait,
à un facteur multiplicatif près, Π(O) = maxo∈O P (x|o) et ν(O) = mino∈O P (x|o) qui encadrent
P (x|O). Cependant ce cadre est complexe à utiliser en deep learning, car les valeurs obtenues
dépendent beaucoup de la granularité de l’ensemble O. En eﬀet, si on choisit une propriété O
décrite par un seul élément (« c’est un chien »), alors Π(O) = P (x|O) = ν(O). Cela ne deviendrait
intéressant que si l’on découpe O en « sous-propriétés », ce qui est arbitraire. Par exemple, dans

RR n° 9422

6

Théophane Vallaeys

le cas de granularité maximum, le plus simple, où O = {o | o est une image de chien}, alors
ν(O) = 0 (en prenant o ∈ O, o (cid:54)= x), et soit Π(O) = 1 si x ∈ O, soit Π(O) = 0 sinon. Le but
du modèle serait alors de trouver une représentation intermédiaire, ou du moins d’estimer des
valeurs de Π et ν sur une telle représentation.

Figure 2 – Utilité d’apprendre des possibilités et nécessités, y compris en dehors de Π = 1 ou
ν = 0

La Figure ci-dessus montre que si un modèle est capable d’apprendre ces valeurs, il peut
distinguer une absence de connaissance (la zone vide) d’une connaissance parfaite d’un phénomène
). Cette représentation n’est pas
aléatoire (Π = 1
2
compatible avec les probabilités, ni les possibilités et nécessités classiques.

), ou partielle (avec Π = 3
4

et ν = 1
2

et ν = 1
4

2.1 Une proposition de solution

Le but de l’encadrement possibilité/nécessité est de prendre en compte à la fois l’incertitude

due à :

— des phénomènes aléatoires, du point de vue de l’observateur, du fait que l’agent n’ait
qu’une partie des données. Par exemple, lors d’un lancer de dé, la face sur laquelle il
va atterrir est déterministe si on possède toutes les variables physiques, mais peut être
considérée comme aléatoire pour un humain. Peut-être ne sait-on même pas si c’est un
d12 ou un d20. Un agent qui connaît toutes ces variables peut représenter cela par une
distribution de probabilités.

— l’incertitude due au manque de connaissances de l’agent. S’il n’a jamais appris ce qu’est
une girafe, ou qu’il n’a jamais vu une espèce de chat particulière, il peut ne pas être

Inria

 et pour avoir un point rougeInformation complète,impossibleInformation complète,certainInformation complète,pur aléatoireAucune informationInformation partielle, aléatoireGénéraliser les possibilités-nécessités pour l’apprentissage profond

7

certain de sa généralisation, même lorsqu’il en est capable. Cela va être représenté par
l’encadrement possibilité/nécessité de la probabilité.

On déﬁnit donc l’univers U , dont chaque élément décrit exactement ce qu’il se passe, l’issue
des tirages aléatoires éventuels et les données observables d’un état de l’univers. L’agent ne voit
cependant qu’une partie de la situation, via une fonction Γ : U → X, où X est l’ensemble
des observations possibles. On déﬁnit O un ensemble de propriétés élémentaires mutuellement
exclusives qui nous intéressent, et on peut déﬁnir f : U → O qui associe à une situation dont on
possède toutes les informations la propriété élémentaire vraie. On encodera donc une propriété
o comme un ensemble o ⊂ O de propriétés élémentaires. On va considérer dans la suite U , X et
O comme des variables aléatoires dans le cadre des fonctions de probabilité.

L’univers est associé à une «vraie» distribution de probabilité P0, inconnue de l’agent. Ce
dernier va supposer que l’univers est associé à une distribution de probabilité Pθ, paramétrée par
le paramètre θ ∈ Θ. On peut même restreindre ce cadre, car on ne s’intéressera à Pθ que sous la
forme Pθ(. . . |X = x). L’agent dispose de connaissances (qui peuvent évoluer selon le modèle de
l’agent) sous la forme d’un objet D, dont le type dépend de l’agent. Ce qui nous intéresse, c’est
D(Θ) qui est l’ensemble des paramètres θ ∈ Θ qui soient compatibles avec D. Par exemple, si D
contient un encodage numérique de « les chats ont presque toujours deux yeux », les distributions
Pθ ne correspondant pas à ce critère sont écartées. L’encodage pourrait par exemple conduire à
éliminer toutes les distributions Pθ où la proportion de chats ayant deux yeux serait inférieure à
un certain seuil (le fonctionnement dépend du modèle choisi).

Ainsi, l’agent dispose pour seules informations de x ∈ X (une observation) et D (des
connaissances). Il pourrait savoir que la situation observée est donc un des u ∈ Γ−1(x), bien
qu’il n’ait pas forcément la connaissance explicite de U . Il voudrait déterminer des informations
sur la valeur de vérité d’un certain o ⊂ O.

En cas de connaissance parfaite, la réponse serait la probabilité p0(o) = P0(o|x). Le point de
vue purement probabiliste (classiquement utilisé dans un réseau de neurones) serait de chercher
une estimation ˜θ telle que |P˜θ(o) − P0(o)| (cid:54) ε (ou au moins en terme d’espérance).

On va encadrer cette probabilité avec Π et ν en séparant la connaissance de l’agent de la

partie aléatoire :

ν(o) = min

θ∈D(Θ)

Pθ(o|x)

Π(o) = max
θ∈D(Θ)

Pθ(o|x)

(1)

(2)

Cela nous donne bien l’encadrement ν(o) (cid:54) p0(o) (cid:54) Π(o). Π et ν sont des fonctions de

croyances, car Π(∅) = 0, Π(O) = 1 et si A ⊂ B alors Π(A) (cid:54) Π(B), de même pour ν.

Dans ces formules, Pθ(. . . |x) est une répartition de probabilité sur Γ−1(x) ⊆ U . Dans un
cas comme le deep learning (où il y a des approximations), on peut assouplir la contrainte : on
veut que l’encadrement soit intéressant (donc proche de p0 si on a beaucoup d’informations), on
cherchera donc à ce que PU (ν(o) > P0(o|x)) < ε, et que PU (Π(o) < P0(o|x)) < ε.

2.2 Propriétés élémentaires

Il est à noter que les fonctions déﬁnies ci-dessus diﬀèrent du cadre classique des possibilités et
nécessités :

— Dans le cas d’un évènement purement aléatoire, mais où l’agent le sait, on peut par

exemple toujours avoir Π = ν = 1
2

.

— Ainsi, on n’a jamais Π = 1 ni ν = 0, et aucun évènement élémentaire entièrement possible
sur cet exemple. De manière générale, nous n’avons pas forcément max Π(o) = 1 ni

RR n° 9422

8

Théophane Vallaeys

min ν(o) = 0. C’est intéressant pour observer des systèmes aléatoires (ou pseudo-aléatoire
dû à la représentation limitée), car un agent devrait pouvoir déterminer les valeurs de ces
probabilités qui ne sont ni 0 ni 1.

— La propriété Π(A ∪ B) = max(Π(A), Π(B)) n’est pas vériﬁée ce qui diﬀère de l’approche
classique où elle était utilisé pour construire la distribution. Mais nous avons vu que c’était
nécessaire de ne pas l’avoir pour obtenir l’encadrement de P dans le cas général.
Cependant, on garde certaines propriétés, notamment le fait que ce soit des fonctions de croyance,
et :

ν(A) = min

(1 − Pθ(A))

θ∈D(Θ)

= 1 − max
θ∈D(Θ)

Pθ(A) = 1 − Π(A)

Donc Π et ν sont duales l’une de l’autre

ν(A ∪ B) = min

θ∈D(Θ)

Pθ(A ∪ B) = min

θ∈D(Θ)

Pθ(A) + Pθ(B) − Pθ(A ∩ B)

(cid:62) min
θ∈D(Θ)

max(Pθ(A), Pθ(B)) (car P (A ∩ B) (cid:54) min(P (A), P (B)))

(cid:62) max( min
θ∈D(Θ)

Pθ(A), min

θ∈D(Θ)

Pθ(A)) = max(ν(A), ν(B))

Π(A ∩ B) = 1 − ν(A ∩ B) (cid:54) 1 − max(ν(A), ν(B))

= min(1 − ν(A), 1 − ν(B)) = min(Π(A), Π(B))

Pour les autres bornes, on sait que Π(A ∪ B) (cid:62) max(Π(A), Π(B)), ν(A ∩ B) (cid:54) min(ν(A), ν(B))
(au lieu des égalités) et :

Π(A ∪ B) = max
θ∈D(Θ)

Pθ(A) + Pθ(B) − Pθ(A ∩ B) (cid:54) Π(A) + Π(B) − ν(A ∩ B)

=⇒ Π(A ∪ B) (cid:54) min(1, Π(A) + Π(B) − 1)
ν(A ∩ B) (cid:62) ν(A) + ν(B) − Π(A ∪ B)
=⇒ ν(A ∩ B) (cid:62) max(0, ν(A) + ν(B) − 1)

Comme le but est d’obtenir un encadrement correct de la probabilité, on pourrait utiliser
ces inégalités pour calculer de tels encadrements et donner des estimations supérieures de Π et
inférieures de ν. De plus, étant donné les signes dans les formules, on peut utiliser ces bornes
pour calculer d’autres bornes, en remplaçant Π et ν par leur estimation, et cela donnera d’autres
bornes correctes (mais on perd sans doute en précision à chaque fois).

De plus, si A et B sont des évènements indépendants (si pour tout x, θ, Pθ(A ∩ B|x) =

Pθ(A|x)Pθ(B|x)), alors :

ν(A)ν(B) (cid:54) ν(A ∩ B) (cid:54) Π(A ∩ B) (cid:54) Π(A)Π(B)
ν(A ∪ B) (cid:62) ν(A) + ν(B) − ν(A)ν(B)
Π(A ∪ B) (cid:54) Π(A) + Π(B) − Π(A)Π(B)

Inria

Généraliser les possibilités-nécessités pour l’apprentissage profond

9

2.3 Réseaux de neurones artiﬁciels

Dans un réseau de neurones artiﬁciels donnant en sortie des probabilités, l’entrée n’est pas
nécessairement constituée de probabilités. Par exemple, dans la classiﬁcation d’image, l’entrée est
assimilable à un «stimulus». La sortie des couches de convolution ou autres premières couches
peut être vue comme un stimulus également, où comme une probabilité d’avoir détecté une
propriété de l’image.

Ainsi, il faudra décider lors de la création du modèle d’une partie «détecteur», qui utilisera
les techniques classique des réseaux de neurones artiﬁciels mais donnera un résultat interprété
comme des probabilités en sortie, et d’une partie «raisonneur» qui utilisera les possibilités et
nécessités. La suite se concentrera sur ce «raisonneur».

En terme d’entraînement, il est possible d’entrainer le réseau de neurones directement avec
les possibilités et nécessités, mais aussi de le pré-entrainer avec uniquement des probabilités, puis
de le raﬃner ensuite (en commençant avec Π = p = ν).

2.3.1 Neurones

Un neurone classique prend la forme y = σ((cid:80)

i wixi + b) où σ est une fonction non-linéaire.

Ainsi en utilisant les déﬁnitions précédentes, on peut calculer des estimations de Π et ν avec

aΠ =

aν =

(cid:88)

i
(cid:88)

i

wΠΠ

i xΠ

i +

wνΠ

i xΠ

i +

(cid:88)

i
(cid:88)

i

wΠν

i xν

i + bΠ

wνν

i xν

i + bν

yΠ = σ(aΠ) yν = σ(aν)

Autrement dit, si on note yT = (yπ, yν), b ∈ R2, w =

ÅwΠΠ wνΠ
wΠν wνν

ã

, alors

(cid:88)

y = σ(

wixi + bi)

i

Si on a tous les xi, xΠ

et
bν (cid:54) b (cid:54) bΠ et σ : R → [0; 1] pour avoir des possibilités et nécessités valides. Cependant, ce n’est
pas la solution utilisée dans la suite.

(cid:62) 0, alors il suﬃt d’avoir wνΠ

(cid:54) wi (cid:54) wΠΠ

(cid:54) wi (cid:54) wΠν

, wνν
i

i , xν
i

i

i

i

On peut assurer que la sortie d’un neurone soit toujours dans [0; 1] en utilisant la fonction

sigmoïde, ou 1+tanh(x)

pour utiliser tanh.

2

Une autre solution serait d’utiliser une fonction «projecteur» qui prenne en paramètres aΠ
et aν, et retourne un point situé dans le triangle, sans rien imposer sur les wi ou la fonction de
non-linéarité. Par exemple, ˜σ(aΠ, aν) = (σ(aΠ), σ(aΠ)σ(aν)).

Pour la fonction softmax, on peut utiliser la déﬁnition suivante. Elle garde la propriété ν (cid:54)
, ce qui permet entre autres d’en déduire une distribution de

p0 (cid:54) Π, avec (cid:80)
probabilité correspondante.

(cid:54) 1 (cid:54) (cid:80)

i yν
i

i yΠ
i

yΠ
j =

yν
j =

RR n° 9422

i

j

eaΠ
i eaν
eaν
i eaΠ

j

i

(cid:80)

(cid:80)

10

Théophane Vallaeys

Mais cela pourrait ne pas bien fonctionner (bien que cette méthode ait été eﬃcace dans mes
expérimentations). En eﬀet, cette fonction permet d’avoir des valeurs de possibilité et nécessité
au dessus de 1, donc en dehors de l’échelle de valeurs. De plus, elle gère mal l’incertitude. Par
exemple, dans le cas extrême d’une seule sortie, on ne peut pas en avoir ν = 0 et Π = 1.

Une autre possibilité est d’utiliser une autre fonction qui ne soit pas construite autour de
l’encadrement des probabilités, mais qui fasse sens dans le cadre des possibilités et nécessités.
Comme les possibilités classiques remplacent la somme par le max, on divise par le max des
exponentielles des possibilités :

eaΠ
maxi eaΠ
eaν
maxi eaΠ
C’est cette dernière formule que j’ai utilisée dans mes expérimentations et elle fonctionnait

yΠ
j =

yν
j =

j

j

i

i

tout à fait.

2.3.2 Fonction de coût

On va considérer ˆyi ∈ [0; 1] les variables contenant la sortie attendue pour chaque neurone
les sorties eﬀectives, et c une fonction de coût basée sur la diﬀérence entre

de sortie, yπ
i
d = |y − ˆy|. En reprenant les fonctions classiques des réseaux de neurones :

et yν
i

— Pour la norme L2 (MSE) : c(d) = d2. On peut implémenter les normes L1, L3... de la

même façon.

— La fonction utilisée dans la suite : c(d) = log |1 − d|. Elle est inspirée de l’entropie croisée
et prends la même valeur pour ˆy = 0 et ˆy = 1. Pour d’autres valeurs, elle fonctionne
cependant correctement.
— Exponentielle : c(d) = ed
La fonction de coût est paramétrée par αΠ+, αΠ−, αν+, αν−. Le but est de pénaliser en priorité
i > ˆyi, car ces deux sorties représentent un intervalle dans lequel on doit
le fait que yΠ
trouver la sortie p en général (en considérant la probabilité comme étant la moyenne des ˆy sur
le même type d’entrée). On devra donc choisir αΠ+ < αΠ− et αν− < αν+.

i < ˆyi, et yν

l(z) =

1
|I|

(cid:88)

i∈I

αΠ+c(max(yΠ

i − ˆyi, 0)) + αΠ−c(max(ˆyi − yΠ

i , 0))

+αν+c(max(yν

i − ˆyi, 0)) + αν−c(max(ˆyi − yν

i , 0))

On peut simpliﬁer cette fonction avec un unique meta-paramètre α < 1 :

l(z) =

1
|I|

i∈I
+c(max(yν

(cid:88)

α c(max(yΠ

i − ˆyi, 0)) + c(max(ˆyi − yΠ

i , 0))

i − ˆyi, 0)) + α c(max(ˆyi − yν

i , 0))

2.3.3 Assurer les contraintes

En plus d’éventuels termes de régularisation, on peut ajouter des termes de contrainte ayant
un facteur de poids β suﬃsamment important pour que cela encode une vrai contrainte, mais

Inria

Généraliser les possibilités-nécessités pour l’apprentissage profond

11

pas trop grand pour que les cas dégénérés pouvant se présenter dans un ensemble de données
ne viennent pas perturber l’apprentissage. On suppose que l’on dispose d’une fonction de coût
c0 (qui peut changer selon la couche ou le coût) et d’un paramètre β. Lors de ce stage, j’ai
simplement choisit c0(x) = x2.

Pour assurer que les possibilités et nécessités respectent bien ν < Π, au lieu d’imposer des
contraintes sur les wi, j’ai utilisé une contrainte sur la sortie, en ajoutant à la fonction de coût
le terme suivant.

(cid:88)

β

couche o, i

c0(max(0, yΠ

o,i − yν

o,i))

De plus, sur les exemples connus, le réseau doit tenter d’apprendre un couple nécessité-
possibilité étroit, et large sur les exemples inconnus. Cela peut être simulé avec les termes suivants,
en prenant β+ et β− positifs mais faibles, et β+ assez grand pas rapport à β−, avec M une
marge dans [0; 1]. Cependant, cela n’a pas suﬃ sur les expérimentations que j’ai faites, et devrait
sûrement être amélioré. La première contrainte est tout de même gardée dans la suite, car elle
permet d’avoir un certain couplage entre ν et Π dans un même neurone.

(cid:88)

β+

couche o, i

c0(yΠ

o,i − yν

o,i)

(cid:88)

β−

neurone i

c0(max(σ(bν

i +

(cid:88)

i

|wνν

i,j | + |wνΠ

i,j |) − M, 0)) + c0(max(1 − σ(bΠ

i −

|wΠν

i,j | + |wΠΠ

i,j |) − M, 0))

(cid:88)

i

2.3.4 Mesure de la précision

Si la sortie attendue est une probabilité voire un intervalle possibilité-nécessité, il faudra
déﬁnir une distance δ telle que chaque variable de sortie doivent être à une distance d’au plus δ
de la vrai sortie pour être acceptée.

Cependant, il existe quatre points intéressants systématiquement. Si on s’intéresse à des cas
plus simples où chaque propriété de sortie peut être étiquetée «vrai», «faux», «aléatoire», ou
«inconnu », alors on peut utiliser ces points. «vrai» correspond au point (1, 1), «faux» à (0, 0),
i ) le
«aléatoire» à (1/2, 1/2) et «inconnu» à (0, 1). On peut associer à une paire de sortie (yν
point le plus proche, et accepter une sortie y si tous les points correspondent.

i , yΠ

Dans le cas où on ne se soucie pas du point «aléatoire», on peut procéder autrement et
arrondir yν
au plus proche, pour obtenir l’un des trois autres points. Cela donne une
i
manière eﬃcace en terme de calcul pour estimer le nombre de résultats corrects, et c’est ce que
j’utilise dans l’application à MNIST dans la suite.

et yΠ
i

3 Applications expérimentales

J’ai choisi d’implémenter ces modèles en utilisant Keras et TensorFlow. J’ai implémenté les
diﬀérentes types de couches utilisant possibilité et nécessité sous forme de nouvelles couches
Keras, en utilisant les opérations de TensorFlow, pour pouvoir les utiliser de façon modulaire
comme les couches standard. De même, j’ai implémenté l’équivalent des fonctions de coût et de
précision standard selon ce qui est expliqué dans la partie plus haut.

RR n° 9422

12

Théophane Vallaeys

3.1 Données synthétiques

Une première étape pour valider le modèle est de l’appliquer à des données synthétiques très

simples, générées par une petite fonction et pouvant facilement être représentées.

3.1.1 Données et entrainement

Les données d’entrée sont deux valeurs x, y ∈ [0; 1], que l’on peut interpréter comme deux
propriétés. Chaque point de sortie est associé à deux propriétés, bleu et rouge, qui sont complémentaires
l’une de l’autre : un point est soit bleu, soit rouge. Le carré de toutes les valeurs d’entrées est
découpé en quatre zones : la zone bleu, où les points sont bleus, la zone rouge, la zone verte où
la couleur est aléatoire ; et la zone jaune où il n’y a pas de données, donc la couleur ne peut pas
être connue. La seconde image ci-dessous montre un exemple de données d’entrée.

Un modèle très simple est utilisé, composé de trois couches de petite taille, et sans ﬁne-
tuning manuel, expliquant sans doute les zones d’imprécisions. Le résultat prédit correspond à la
troisième image. On observe que le modèle généralise naturellement en dehors des bornes. Même
en ajoutant des contraintes sous forme de coût supplémentaire comme décrit ci-dessus (ou avec
d’autres formules), cela ne permettait pas de régler ce problème.

(a) Les zones

(b) Exemple
données

d’ensemble

de

(c) Prédictions

3.1.2 Zone d’inconnu

Au vu de l’échec du coût supplémentaire pour apprendre au modèle à répondre qu’il ne sait
pas sur les zones inconnues, une autre solution plus manuelle est de lui présenter des données qu’il
ne doit pas savoir classer, et de les lui faire apprendre, ce qui revient à simplement donner une
3ème étiquette possible à des points. Les exemples d’entrée sont donc étiquetés «bleu», «rouge»,
ou «inconnu». Cela donne le résultat ci-dessous,

Inria

Généraliser les possibilités-nécessités pour l’apprentissage profond

13

(a) Données d’entrée

(b) Prédictions

3.1.3

Interprétation des neurones

L’utilisation des possibilités devrait pouvoir permettre de mieux interpréter les neurones et
leur sortie, et on peut commencer par visualiser la sortie de chaque neurone pour chacun des
points du plan. Ainsi sur la ﬁgurine suivante, pour chaque couche du réseau, il y a deux lignes de
vignettes. La première représente les nécessités, la seconde les possibilités, en fonction de l’entrée
(x, y). Le violet correspond à une sortie de 0 (pas d’activité), et le jaune à 1, tendis que le vert
représente 1
2

.

Figure 5 – Activité de la couche cachée 1 en fonction de l’entrée x et y

Figure 6 – Activité de la couche cachée 2 en fonction de l’entrée x et y

RR n° 9422

14

Théophane Vallaeys

Figure 7 – Activité de la couche de sortie en fonction de l’entrée x et y

Le réseau de neurone fonctionne relativement correctement, car il donne des valeurs correctes
sur la quasi-totalité des zones où il y a eu des échantillons, si ce n’est une particularité étrange à
cause de la marge entre vrai et faux au centre. Il atteint bien le but, c’est à dire d’être capable
sur un unique neurone de sortie de distinguer aléatoire, possible, certain et impossible.

On remarque qu’il y a un certain nombre de neurones peu intéressants, voire de neurones où
possibilité et nécessité sont toujours égaux, ou des neurones où seule une des deux sorties est
utile. Cependant certains tirent avantage du couplage et dessinent deux zones diﬀérentes que l’on
peut interpréter.

3.2 Application à MNIST

Le jeu de données MNIST semble aujourd’hui très élémentaire, mais au vu de la diﬃculté que
j’ai eu à faire fonctionner ce type de modèle, il permettait d’avoir un exemple un peu plus concret,
avec un passage entre des données représentant des «signaux» (blanc / noir / intermédiaire), à
un ensemble de nécessités et possibilités en sortie.

Pour représenter l’incertitude, j’ai découpé les données d’entrée en trois ensembles : connu
(chiﬀres 0 à 3), inconnu rencontré (chiﬀres 4 à 6), et inconnu jamais vu (chiﬀres 7 à 9). La
sortie consiste, pour chaque chiﬀre entre 0 et 3, en une possibilité et une nécessité que ça soit ce
chiﬀre-là. Les chiﬀres 4 à 6 sont donnés en entrée, mais une réponse de (0, 1) est attendue, tandis
que les chiﬀres de 7 à 9 sont retirés des données d’entraînement (mais pas de test). De plus, des
données aléatoires sont fournies en entrée, associées à la sortie (0, 1) (inconnu).

3.2.1 Perceptron multicouche

Le réseau le plus simple à mettre en place était un perceptron multi-couche. Le modèle
dispose de 3 couches entièrement connectées, utilise x (cid:55)→ 1+tanh(x)
comme fonction non-linéaire,
et la version modiﬁée du softmax basée sur le max pour la sortie. Les résultats obtenus sont les
suivants :

2

Inria

Généraliser les possibilités-nécessités pour l’apprentissage profond

15

Données d’entrainement

Chiﬀres 0-3
Chiﬀres 0-3 + aléatoire
Chiﬀres 0-7
sans contraintes
Chiﬀres 0-7
Chiﬀres 0-7 + aléatoire
sans contraintes
Chiﬀres 0-7 + aléatoire

Succès
entrainement

94.5%
97.7%

94.3%

92.6%

96.3%

95.9%

Succès
tests

39.6%
40.4%

92.9%

85.2%

83.9%

83.2%

Test chiﬀres
0 à 3

Test chiﬀres
4 à 6

Test chiﬀres
7 à 9

95.1%
96.7%

92.8%

91.6%

93.1%

92.7%

0%
0.4%

95.7%

94.3%

95.6%

95.4%

0%
0.3%

64.4%

67.7%

60%

58.4%

Il semble donc que les contraintes n’aient pas beaucoup d’impact sur la qualité des résultats
(mais elles permettent d’assurer la cohérence des sorties des neurones internes, ce qui est une
bonne raison de les utiliser). Les données aléatoires ne sont pas utiles pour améliorer les résultats,
mais les données supplémentaires (chiﬀres 4 à 6) permettent au réseau de généraliser le fait de
ne pas savoir classer certains chiﬀres, bien que peu eﬃcacement.

Si on change la manière de diviser les données, en entraînant sur tous les chiﬀres sauf 9 (mais
la sortie concerne toujours les chiﬀres 0 à 3), alors les chiﬀres 0 à 3 sont reconnus à 87.8%, les
chiﬀres 4 à 8 identiﬁés comme inconnus dans 95.3% des cas, et le chiﬀre 9 dans 97.8% des cas
sans avoir été vu. Ainsi, avec suﬃsamment de données non-labellisées, la distinction entre connu
et inconnu semble se généraliser assez bien.

3.2.2 Réseau convolutionnel

Les réseaux probabilistes convolutionnels fonctionnent très bien sur ce jeu de test, même en
étant très simples. J’ai cherché à implémenter l’équivalent avec les possibilités et nécessités, avec
la même structure de réseau, mais les résultats en utilisant des couches de convolution possiblistes
sont au mieux très mauvais, au pire signes d’une absence totale d’apprentissage.

Au vu de la durée du stage, je n’ai pas pu explorer plus en avant. En eﬀet ces résultats sont
sans doute provisoires et montrent qu’il faudrait retravailler plus en profondeur l’architecture du
réseau et la manière d’intégrer possibilités et nécessités avec une convolution pour ne pas bloquer
l’apprentissage.

4 Conclusion

Le sujet est intéressant mais semble complexe au vu des expérimentations préliminaires que

j’ai réalisées. Diﬀérentes autres approches pourraient être possibles :

— Utiliser une structure de réseau adaptée comme certains réseaux neuro-symboliques.
— Utiliser des fonctions beaucoup plus éloignées des réseaux classiques se basant sur min ou

max (avec des approximations prenant en compte les autres variables).

— Chercher à introduire de meilleurs manières d’encoder les contraintes, plus eﬃcaces.
— Trouver un moyen plus eﬃcace que d’utiliser des données réelles non labellisées pour

apprendre à ne pas généraliser excessivement.

— On pourrait entourer la vraisemblance au lieu de la probabilité, comme proposé dans

[Denœux20], avec Π(O) = maxo∈O P (x|o) et ν(O) = mino∈O P (x|o).

L’eﬃcacité de ce qui a été implémenté durant ce stage pourrait également être mieux observée
en testant sur des données incluant plus d’incertitude. Il m’a été proposé de tenter de mettre en
place une expérience à partir de données venant de l’action AIDE (une expérience avec des cubes
et des données sur leurs aﬀordances, etc...), mais réussir à rendre ce type de modèle fonctionnel

RR n° 9422

16

Théophane Vallaeys

sur ce type de problème nécessiterait encore un peu plus de travail. Pour étendre le dernier test
et voir si l’apprentissage visant à éviter de généraliser à des données inconnues fonctionne bien,
utiliser un ensemble de données ayant plus de classes (comme omniglot) pourrait être utile.

Références

[Benferhat14] S. Benferhat (CRIL), Th. Denoeux (Heudiasyc), D. Dubois (IRIT), H. Prade

(IRIT), Représentations de l’incertitude en intelligence artiﬁcielle, 2014

[Denœux20] Thierry Denœux, Didier Dubois, et Henri Prade, Representations of Uncertainty in

Artiﬁcial Intelligence : Probability and Possibility, 2020

[Tettamanzi17] Andrea Tettamanzi, Catherine Faron Zucker et Fabien Gandon, Possibilistic
testing of OWL axioms against RDF data. International Journal of Approximate Reasoning,
Elsevier, 2017, 10.1016/j.ijar.2017.08.012 . hal-01591001

[Ishibuchi91] Hisao Ishibuchi, Ryosuke Fujioka et Hideo Tanaka, Possibility and necessity pattern

classiﬁcation using neural networks, 1991

[Drago199] G.P. Drago1 et S. Ridella2, Possibility and Necessity Pattern Classiﬁcation using an

Interval Arithmetic Perceptron, 1999

[Garcez20] Artur d’Avila Garcezand Luis C. Lamb, Neurosymbolic AI : The 3rd Wave, 2020
[Seraﬁni16] Luciano Seraﬁni et Artur d’Avila Garcez, Logic Tensor Networks : Deep Learning

and Logical Reasoning from Data and Knowledge, 2016

[Donadello17] Ivan Donadello, Luciano Seraﬁni et Artur d’Avila Garcez, Logic Tensor Networks

for Semantic Image Interpretation, 2017

Inria

RESEARCH CENTRE
BORDEAUX – SUD-OUEST

200 avenue de la Vieille Tour
33405 Talence Cedex

Publisher
Inria
Domaine de Voluceau - Rocquencourt
BP 105 - 78153 Le Chesnay Cedex
inria.fr

ISSN 0249-6399

