DBA and K-means clustering : Explainability problems
for research on behaviors and strategies
Axel Palaude, Thierry Viéville

To cite this version:

Axel Palaude, Thierry Viéville. DBA and K-means clustering : Explainability problems for research on
behaviors and strategies. RR-9522, Inria & Labri, Université Bordeaux. 2023, pp.17. ￿hal-04254844￿

HAL Id: hal-04254844

https://inria.hal.science/hal-04254844

Submitted on 4 Dec 2023

HAL is a multi-disciplinary open access
archive for the deposit and dissemination of sci-
entific research documents, whether they are pub-
lished or not. The documents may come from
teaching and research institutions in France or
abroad, or from public or private research centers.

L’archive ouverte pluridisciplinaire HAL, est
destinée au dépôt et à la diffusion de documents
scientifiques de niveau recherche, publiés ou non,
émanant des établissements d’enseignement et de
recherche français ou étrangers, des laboratoires
publics ou privés.

Distributed under a Creative Commons Attribution 4.0 International License

DBA and K-means clustering : Explainability problems for research on behaviors and
strategies

2
Axel Palaude , Thierry Viéville
MNEMOSYNE

1

Research Report N° 9522— December 2023 —16 pages.

Abstract: Studying creative problem solving (CPS) activities can enrich our understanding of human
learning by facilitating the observation of behaviors related to realistic situations of complex open-ended
problem solving . Actions taken by an individual in such activities are situated in time, thus allowing the
creation of time sequences of observations. These observations are not purely numerical, and thus can
be represented by symbolic time sequences.
In particular, the formal analysis of such time sequences leads to a better understanding of the role of
temporality in the adoption of CPS strategies.
For this, we propose to apply clustering algorithms in order to group sequences in categories that could
be associated with emergent behavioral patterns, either at the whole activity level or at the level of
subsequences of actions. Clustering requires the deﬁnition of a distance between symbolic data
structures representing observations, used to determine the distance (more precisely dissimilarity), and
the capacity to interpret such clusters.
Our ongoing research uses Dynamic Time Warping (DTW) as an algorithm to compute dissimilarity
between sequences. This technical report addresses the issue of computing a K-means clustering
algorithm and centroids with DTW for symbolic sequences, using an approximation algorithm named
DTW Barycenter Averaging (DBA).
It appears that DBA for symbolic sequences is not relevant as it produces non-explainable sequences for
the pattern analysis, but this negative result is of interest and allows us to propose an alternative.
Clustering algorithms using medoids will be preferred in future research, and we explain why in this
report.

Key-words: creative problem-solving, learning analytics, dynamic time warping, clustering.

1 Axel Palaude, Inria Mnemosyne Team, AIdE – axel.palaude@inria.fr

2 Thierry Viéville, Inria Mnemosyne Team, UCA LINE Laboratory, thierry.vieville@inria.fr

DBA et le clustering des k-moyennes : Des problèmes d’explicabilité pour la recherche
sur les stratégies et comportements

4
Axel Palaude , Thierry Viéville
MNEMOSYNE

3

Rapport de Recherche N° 9522—December 2023—16 pages

Résumé : L’étude des activités de résolution créative de problèmes enrichit notre compréhension de
l’apprentissage humain en permettant d’observer les comportements humains dans des situations réelles de
résolution de problèmes ouverts et complexes. L’observation des actions eﬀectuées est située dans le temps,
ce qui permet la création de séquences temporelles d’observations, qui peuvent être représentées par des
séquences symboliques. L’analyse de ces séquences temporelles permet ainsi de mieux comprendre le rôle de
la temporalité dans l’adoption de stratégies pour la résolution créative de problèmes. Pour cela, nous
proposons d’utiliser des algorithmes de clustering aﬁn de regrouper des séquences similaires qui pourraient
ainsi être associés à des types de comportements, que ce soit des comportements généraux pour l’activité ou
des comportements relatifs à seulement une sous-séquence d’actions. Les algorithmes de clustering
nécessitent la déﬁnition d’une distance entre ces structures temporelles et symboliques. Nous utilisons le
Dynamic Time Warping (DTW) (ou déformation temporelle dynamique) comme méthode permettant de
calculer la dissimilarité entre les séquences. Cependant, dans l’optique d’utiliser des algorithmes tels que
l’algorithme des k-moyennes, nous avons besoin de mettre en place un algorithme permettant de calculer des
centroïdes. Pour cela, nous utilisons un algorithme nommé le DTW Barycenter Averaging (DBA).
Cependant, le DBA n’est ﬁnalement pas pertinent dans notre analyse de données, car la méthode donne lieu à
des centroïdes non interprétables, et pour d’autres raisons relatives à la structure hiérarchique de nos
données symboliques. Ainsi, nos prochains travaux se concentreront sur l’utilisation des médoïdes à la place
des centroïdes.

Mots clés : Résolution créative de problèmes, analyse de l’apprentissage, déformation temporelle dynamique,
clustering

3 Axel Palaude, équipe MNEMOSYNE (Inria), AIdE – axel.palaude@inria.fr

4 Thierry Viéville, équipe MNEMOSYNE (Inria, Laboratoire LINE UCA, thierry.vieville@inria.fr

From CreaCube to EscapeCube : trying to add internal sensors to collect data automatically

5

1. The CreaCube task modeling

1.1. The CreaCube task
1.2. The data corpus
2. Clustering symbolic data

2.1. Dynamic Time Warping on symbolic data
2.2. DTW Barycenter Averaging
2.3. Interpretation of DBA for centroid computing and boolean values

Conclusion
Bibliography

6
6
7
8
8
9
11
12
13

RR N° 9522

6

Axel Palaude, Thierry Viéville

1. The CreaCube task modeling

1.1. The CreaCube task

Problem solving such as the Tower of Hanoi (Fansher et al., 2022) have been largely studied and permitted the
formalization of general problem solving procedures using computational representations. In the case of the tower
of Hanoi problem, (Newell & Simon, 1972), the representation is equivalent to a finite-state automaton (Glushkov,
1961), that is a 5-tuple consisting of :

-
-
-

-

-

A set of states containing all possible states of the problem
A set of initial states containing all possible initial states of the problem, in this case only one initial state.
A set of output states containing all possible states that are considered as outputs, i.e. final states in
which the problem is solved.
An input alphabet consisting of all possible actions that it is possible to take (in this case, all actions
consist of moving a disk from one tower to another, so the alphabet contains 6 possible actions)
A state-transition function over the set of states and the input alphabet, that represents transitions
between states depending on the action taken.

The representation of

the automaton, as seen in Figure 1,

is an example of well-defined problem-solving.

Figure 1 : The 3-disk Hanoi towers problem space, with one initial state and one output (goal) state with moving
disks as a state-transition function, from (Knoblock, 1990)

We call this representation (states and transitions) the problem space, in which the subject is starting from an initial
state and moving from state to state to reach an output state.
However, well-defined problems are not a good representation of more general problems, in which information can
be unknown or obfuscated, and states and input alphabets can be virtually infinite, which is what we find in
everyday problems or open problems at work.
These ill-defined problems are complex to model and require different levels of abstraction from the subject to
solve it than a simple complete representation of it.

Inria

From CreaCube to EscapeCube : trying to add internal sensors to collect data automatically

7

In authentic learning settings, problem solving is more often developed through complex and domain-specific
problem-solving tasks (Molnár et al., 2013), including creative problem solving (CPS) tasks. CPS are ill-defined
problem solving tasks that cannot be defined through a set of predefined states and require the learner to engage
in an enactment of the conceptual or physical tools mediating the task. In ill-defined problems, there is no clear
path to the set of output states, or even no clear set of output states. In such CPS tasks, the learner must build a
representation of the problem, and then choose a behavior to adopt, which includes the choice of a (sub)goal and
the problem space exploration (discovering parts of the problem space or moving through it). Actions undertaken
by the learner in such tasks may be used as feedback to evaluate the result of the chosen behavior, evaluate the
intermediate situation and decide to adapt (or not) the behavior to advance the task. Figure 2 represents a general
representation of such problem space.

Figure 2 : A general representation of problem spaces. Paths represent sequences of actions taken by the learner
in order to reach the goal state from the initial state. Path constraints cannot be passed through, which is why the
learner needs to choose and adapt different behaviors in order to reach the goal state.

This study focuses on CPS tasks in which the subject needs to engage in a novel way of using a conceptual or
physical
is to characterize individuals’
behaviors by identifying patterns across our corpus. This is done by using clustering methods that could be
associated (or not) with general strategies for CPS. In particular, we are interested in an activity named Creacube.

tool which can satisfy the problem requirements. Our research goal

CreaCube is an ill-defined robotic game-based activity (Leroy et al., 2021; Romero et al.,2018). In this CPS task,
the participant is invited to manipulate four cubes of different colors. Each cube has different properties such as
wheels or sensors, but these technological affordances are unknown to the subject when starting the activity. The
goal of this CPS task is to build a vehicle composed of four pieces that can move autonomously from one point to
another, without any further initial information about the problem.

Figure 3 : A configuration of the CreaCube activity

Four different cubelets (red, white, blue and black) are presented on a table (with a black point and a red point on
it) to a player. The instructions, repeatable at will, consist in one sentence : « build a vehicle made up of four
pieces that moves by itself from the red point to the black point ». The setup of the activity is shown in Figure 3.
The black cube has a face with sensors, the blue cube has a switch on a face to activate a battery and the white

RR N° 9522

8

Axel Palaude, Thierry Viéville

cube has wheels on a face that need to be alimented and receive instructions from sensors to move at a certain
speed.

Figure 4 : CreaCube states associated to the general problem space representation

As for the problem space of the activity, we have an example (illustrated Figure 4) of the structure with one initial
state and multiple goal states (i.e. structures of four that respect the conditions) with different path constraints
corresponding to different types of problems (imbalance, unactivated battery etc.).

We can use the CreaCube activity in order to study some transversal competencies, also known as 21st-century
skills, including problem solving, collaboration, creativity and computational thinking (Romero, Lille et Patino,
2017). The data collection of CreaCube experiments consists of sets of observables, and a set of observables
represents the state of the activity at a given time. In this context, an observable represents a specific element of
the scene : the actual configuration of cubes or the player’s behavior. Observables require a decision on the way
direct analysis of the situation or indirect one (through video analysis) or other data such learning analytics
provided by the modular cubes can inform these observables. The set of observables used for this study is based
on the work of (Mercier, 2022), as seen in Figure 5.

Inria

From CreaCube to EscapeCube : trying to add internal sensors to collect data automatically

9

Figure 5 : Observables of the CreaCube activity, from (Mercier, 2022)

1.2. The data corpus

Based on a subset of the CreaCube corpus, selecting only children (7-12 y.o) who performed the task individually
(93 subjects), we have for each experiment a data set including a time sequence starting when the subject hears
the instructions for the first time and stopping when the subject succeeds or gives up. In each sequence, key
events that can be observed have been annotated, resulting in 83 different types of observables annotated across
all experiments. Detailed in Mercier (2022), they correspond to the discovery of affordances (the discovery of
properties of some cubes), the realization of the most common four-cubes shapes, the criteria those shapes fulfill
(or not) with regard to the guideline, and the final outcome of the activity. Those time sequences are thus symbolic
trajectories, and we want to cluster them. However, it is difficult to create clusters of symbolic trajectories, mainly
because it is difficult to define a measure of similarity between trajectories.

A trajectory of a subject is a list (sequence) of n-dimensonal boolean vectors, whose length is the length (in
seconds) of the activity. Precisely, those vectors have 83 different dimensions corresponding to each observable.
An observable can be activated or not at a given time, which is the reason why we are using boolean values.
In order to compare different trajectories, we need to compare similar elements from each. Those elements are the
83-dimensonal boolean vectors.

The first question to answer here is how to compare two vectors. We decided to use a simple edit distance :
Considering that one edition is the change of a boolean value into another (either True to False or False to True)
we can define the edit distance as the minimal number of editions necessary to transform one vector into another.
The edit distance is common and can be defined in a lot of different symbolic environments. For instance,
considering two words “call” and “salt”,we can define the edition as a letter change and in this case, the edit
distance between those two words is 2 (c becomes s and l becomes t).
We will now give an example with our data : we consider two points in time in different activities. In the first one,
the structure F002 is created, a tower of cube with only a problem of imbalance (the tower falls when the cubes
move), and in the second one, another structure F020 is created with no other problem. The edit distance between
those two points is 3 :

-
-

The F002 observable is edited from True to False
The Imbalance problem observable is edited from True to False

RR N° 9522

10

Axel Palaude, Thierry Viéville

-

The F020 observable is edited from False to True

Even with another distance, another problem arises : how to extend the distance between two points to a distance
between two trajectories ? We can think of a naive approach consisting of simply adding distances between points
at the same given time to compare two trajectories. For two trajectories, the distance will be the sum of the
distance between the vectors of each trajectory at t = 0 s and between the vectors of each trajectory at t = 1 s, etc.
However, this solution doesn’t take into account the fact that trajectories are of different lengths, because subjects
do not solve the problem at the same pace. It can be a matter of understanding or simply of speed of action.
Adding empty vectors at the end of shorter trajectories doesn’t solve the problem, as two subjects doing the exact
same actions but at different paces will have a big distance value in total, wether during the comparison with “real
vectors” who will be different at a given time or with “empty added vectors” who are different from non-empty
vectors of the longer trajectory.

We need to use a method that allows a comparison between trajectories that erase time differences caused by
e.g. pacing and to be adaptable depending on the chosen distance between vectors. This research report will
concentrate on a method called Dynamic Time Warping (DTW) to define a similarity function and a method called
DTW Barycenter Averaging (DBA) for prototype approximation of clusters.

2. Clustering symbolic data

2.1. Dynamic Time Warping on symbolic data

Dynamic Time Warping (DTW) is an algorithm used for measuring similarity between two temporal
sequences which may vary in speed (Müller, 2007). The DTW method consists on finding an optimal match
between two given time sequences by associating points from a time sequence to one or more points from
the other sequences, with some restrictions :

-
-

-

Every point from each sequence must be matched with at least one point from the other sequence
The first and last points of one sequence are respectively associated with at least the first and the
last points of the other sequence.
Considering that
j from the other
sequence, the next point i+1 from the first sequence can only be associated with point j or points
after j in the other time sequence, and vice versa.

from one sequence is associated with the point

the point

i

The optimal match between two given time sequences is then the mapping of associated points that satisfies
all of the previous restrictions and has the minimal cost of satisfying mappings, the minimal cost being the
sum of absolute differences between values of each paired points.
Figure 6 presents an optimal matching between two time sequences with either the euclidean distance and
the DTW optimal matching.

Figure 6 : Differences between euclidean distance and dynamic time warping (Tavenard, 2021)

Inria

From CreaCube to EscapeCube :
11

trying to add internal sensors to collect data automatically

The main benefit of using a dynamic matching algorithm like DTW is that it is able to take into account little
variations between two similar sequences, for instance a temporal shift between two identical sequences. In
particular, for Creacube, we consider that, as subjects are not identical, two subjects with the same behavior will
have slightly different sequences, as there will be differences in, for instance, the execution speed.

We will now detail the algorithm for the dynamic time warping algorithm. DTW is based on the Levenshtein
distance (Ney & Ortmanns, 1999). It is a dynamic algorithm that we compute using the following definition:

Given two sequences A and B :

We can compute the distance D :

So the distance between A and B will be :

This requires the definition of the distance d between two points.
For the CreaCube observables set, in order to compute the distance, we define a point by its position in time, and
by a set of boolean values : each boolean value corresponds to an observable, and is set to 1 if the observable is
observed (ie set to True) and set to 0 if the observable is not detected.
We define two distance functions :

-
-

Equivalence : the distance is 1 if the points are different (time excluded), 0 otherwise.
Hamming : the Hamming distance corresponds to the number of different values when comparing two
points. We note that this distance corresponds to the edit distance, as presented in the previous section.

We are using a K-Means algorithm (Ferreira et al., 2012) in order to find clusters. The K-Means algorithm consists
of the following steps :

1.

(Initialisation) Choose k sequences S1, S2… Sk from the corpus. These sequences, noted C1, C2, … Ck
are called centroïds.

2. For each sequence S from the corpus, compute the DTW algorithm between S and each centroïd. Each

sequence is then associated with the closest (i.e. the minimum DTW computed value) centroïd.

3. For each centroïd C, compute the mean of each sequence associated with it. The computed mean

becomes the new centroïd C.

4. Repeat 2 and 3 until all centroïds are stable (do not change during step 3) or until a determined number of

iterations.
(End) The k centroïds are centroïds of k sets of sequences that are the clusters.

5.

Step 3 requires a way to compute the mean of a set of sequences. For the CreaCube corpus, defining the mean of
a set of sequences requires a way to compute the mean of multiple trajectories in a multidimensional boolean
space. This research report focuses on one particular method called Dynamic Time Warping Barycenter Averaging
(Petitjean et al., 2011).

2.2. DTW Barycenter Averaging

DBA stands for DTW Barycenter Averaging. It is an averaging method which consists in iteratively refining an
average sequence in order to minimize the squared distance of the DTW value to average sequences.
Using the DTW algorithm to compare each sequence with the average, it is possible to associate a set of points
from sequences to each point of the average, and then computing the barycenter of all points from sequences
associated with each point from the average, thus creating a new average trajectory.

Let’s consider the barycenter function :

If we consider each point from the set as a n-dimensional vector, the addition sign corresponds to vector addition.
Given a set S, the sequence i of length m in the set is a succession of points :

RR N° 9522

12

Axel Palaude, Thierry Viéville

where each point is a vector in a n-dimensional space :

The average sequence A of length m’ is written :

where

For each point of A, we create a set of all points from sequences of S which are associated when applying DTW
between A and sequences from S. The created space is :

The DBA algorithm averages each point of A individually by replacing it by the barycenter of all its associated
points. In other words, at each iteration of the DBA algorithm, we do the following transformation for each point a
of A :

The algorithmic method then consists of the following steps :

1.

(Initialisation) : Create an initial average sequence A. This sequence can be random, preprocessed or
even a sequence from the corpus

2. For each sequence S from the corpus, compute the DTW algorithm between S and A. For each point a
from A, create a set s(a) containing all points associated with a from all sequences from the DTW
algorithm.

3. For each point a from the average sequence A, compute the barycenter of all points from the s(a) set,
coordinate by coordinate. The resulting barycenter becomes the new point a, thus modifying all points
from sequence A.

4. Repeat 2 and 3 until the average sequence A is stable (does not change during step 3) or until a

determined number of iterations.
(End) A is the average sequence.

5.

Figure 7 shows an execution of the DBA algorithm with 4 different iterations over two one-dimensional trajectories,
adapted from (Petitjean et al., 2011). Each point of the average sequence is associated with DTW to multiple
points from orange and blue sequences, and each associated point is then a point used in the update of the
average point with the barycenter function.

Inria

From CreaCube to EscapeCube :
13

trying to add internal sensors to collect data automatically

Figure 7 : An execution of the DBA algorithm over two-dimensional trajectories, from (Petitjean et al., 2011)

DBA is an iterative algorithm that allows to modify over time an average sequence, similar to the centroïds update
of the K-means clustering algorithm. We need to adapt DBA to make the result correspond to what we are
searching for, i.e. centroids.

2.3. Interpretation of DBA for centroid computing and boolean values

We will consider two different ways of considering DBA for centroïd computing : sequentially and concurrently
The first method is to consider using DBA as a way to compute the centroïd of a set of sequences : the
computation of the centroïd consists of applying DBA with a maximum number of iteration and by giving a random
sequence (or a sequence from the set) as the initial sequence to average.

The method, named sequential DBA clustering, will be the following :

1.

(Initialisation) Choose k sequences S1, S2… Sk from the corpus. These sequences, noted C1, C2, … Ck
are called centroïds.

2. For each sequence S from the corpus, compute the DTW algorithm between S and each centroïd. Each

sequence is then associated with the closest (i.e. the minimum DTW computed value) centroïd.

RR N° 9522

14

Axel Palaude, Thierry Viéville

3. For each centroïd C, compute the DBA algorithm with each sequence associated to C in step 2 with C as
the initial sequence to average, until the averaged sequence is stable (does not change during the
iteration step) or a maximum number of iterations is reached.

4. Repeat 2 and 3 until all centroïds are stable (do not change during step 3) or until a determined number of

iterations.
(End) The k centroïds are centroïds of k sets of sequences that are the clusters.

5.

The other method is to do each iteration of the K-means clustering algorithm and DBA concomitantly. For each
iteration of the K-means algorithm, an iteration of DBA is done, and the iteration of DBA changes the value of the
centroïd sequence.
This method, named concomitant DBA clustering, consists of the following :

1.

(Initialisation) Choose k sequences S1, S2… Sk from the corpus. These sequences, noted C1, C2, … Ck
are called centroïds.

2. For each sequence S from the corpus, compute the DTW algorithm between S and each centroïd. Each

sequence is then associated with the closest (i.e. the minimum DTW computed value) centroïd.

3. For each centroïd C, compute the barycenter of each point from C with its associated set of points from
sequences associated to C in step 2. The sequence consisting of the succession of each barycenter is
the new centroïd C.

4. Repeat 2 and 3 until all centroïds are stable (do not change during step 3) or until a determined number of

iterations.
(End) The k centroïds are centroïds of k sets of sequences that are the clusters.

5.

in the case of
Each method allows the computing of centroïds for
multidimensional vectors of booleans, and specifically for the study of the CreaCube task, multiple problems arise
from the DBA execution :

the K-means algorithm. However,

Centroïd interpretability. As every variable from our corpus is a boolean value, the barycenter of boolean values
is a value between 0 and 1. Those values are not interpretable unless, for instance, we consider a way to round
the values to 0 and 1 to force boolean values. However, this is not possible for our corpus :
A sequence will have less than 15 values put to 1 over time, and every boolean value is considered True only at
the moment the observable is detected. For instance, the discovery of an affordance is annotated as True only the
the affordance is discovered. This leads to mostly “empty” sequences that, when doing barycenter
moment
averaging, will lead to empty sequences. In any case, resulting centroïds are difficult to interpret.
Explainability and plausibility If we consider that we found a way to avoid the “emptiness” of averaged
sequences (by, let’s say, putting a threshold for rounding instead of a half rounding), we have another problem of
explainability. Resulting centroïds have no guarantee to be plausible, i.e. be a sequence that could potentially be
done by a subject. This is, among other things, due to the fact that our boolean values are not unrelated to each
other. For instance, it is impossible for two different final structures (i.e. two structures composed of four cubes, but
arranged differently) to be set to True at the same time.
Hierarchical boolean values Our observables dataset has related boolean values, that are for instance mutually
exclusive. In the case of the computing of centroïds, these kinds of properties are not necessarily maintained.

For these reasons, and in particular the problem of explainability of centroïds, we do not think that centroïds are a
good way to study behaviors among sequences. The use of DBA does not lead to satisfying prototypes that we
can use to try to find properties of clusters.
We will prefer other algorithms to create more explainable clusters and prototypes (representative of a cluster).

Conclusion

DTW Barycenter Averaging is a method used to create an average sequence from a set of multi-dimensional
sequences. However, the use of the barycenter function to compute the average makes it difficult to apply for
boolean values. This leads to the creation of average sequences that are difficult to explain (because they are for
instance not plausible) and to associate to behavior, which is the main point of our research. In addition, our
corpus of boolean values has an implied hierarchical structure, which implies that some dimensions are more
related to others (in particular booleans from the same category, see Figure 2). Using DBA requires at least the

Inria

From CreaCube to EscapeCube :
15

trying to add internal sensors to collect data automatically

definition of a distance that takes into account this hierarchical structure, which is not the case for distances we
defined until now.
The definition of centroïds is a main point of interest for our research, because these can be considered as “typical
sequences of actions” done by a subject. However, it appears that centroïds are not good candidates to represent
this kind of typical sequence. Instead of centroïds, we will consider medoïds, which are sequences from the corpus
: A medoïd of a group is the member of the group that is the closest to any other member of the group. We can
compute it by applying the K-medoïds clustering algorithm, which is similar to the K-means clustering, with the
advantage of producing real sequences from the corpus which are by definition plausible (because they exist
within the corpus). The K-medoïd algorithm is as follows :

1.

(Initialisation) Choose k sequences S1, S2… Sk from the corpus. These sequences, noted M1, M2, … Mk
are called medoïds.

2. For each sequence S from the corpus, compute the DTW algorithm between S and each medoïd. Each

sequence is then associated with the closest (i.e. the minimum DTW computed value) medoïd.

3. For each group, compute the mean square distance (with DTW) of each member with every other
member. The member which has the smallest mean square distance is the new medoïd of the group
4. Repeat 2 and 3 until all medoïds and groups are stable (do not change during steps 2 and 3) or until a

determined number of iterations.
(End) The k medoïds are medoïds of k sets of sequences that are the clusters.

5.

This method corrects most of the problems created by the K-means algorithm and DBA, and will be used for future
research as a way to find clusters and to find prototypes of such clusters used for comparison and interpretation.
future work will
remaining problems such as the hierarchical structure of our boolean values,
To correct
concentrate on the definition of numerical values evolving over time that could represent our boolean dataset.

6
Acknowledgement: This work is a collaboration between the ANR CreaMaker and the AEx AIDE
Thierry Viéville, Margarida Romero, Chloe Mercier and Frédéric Alexandre are gratefully acknowledged for
precious advice during the execution of this work and this report reviewing.

5

Bibliography

Fansher, M., Shah, P., & Hélie, S. (2022). The effect of mode of presentation on Tower of Hanoi problem solving.

Cognition, 224, 105041. https://doi.org/10.1016/j.cognition.2022.105041

Ferreira, N., Klosowski, J. T., Scheidegger, C., & Silva, C. (2012). Vector Field k-Means: Clustering Trajectories by

Fitting Multiple Vector Fields (arXiv:1208.5801). arXiv. https://doi.org/10.48550/arXiv.1208.5801

Glushkov, V. M. (1961). THE ABSTRACT THEORY OF AUTOMATA. Russian Mathematical Surveys, 16(5), 1.

https://doi.org/10.1070/RM1961v016n05ABEH004112

Knoblock, C. A. (1990). Abstracting the tower of hanoi. 4976, 1–11.

Mercier, C. (2022). An Ontology to Formalize a Creative Problem Solving Activity. IEEE Transactions on Cognitive

and Developmental Systems, 1–1. https://doi.org/10.1109/TCDS.2022.3210234

Molnár, G., Greiff, S., & Csapó, B. (2013). Inductive reasoning, domain specific and complex problem solving:

Relations and development. Thinking Skills and Creativity, 9, 35–45.

Müller, M. (Ed.). (2007). Dynamic Time Warping. In Information Retrieval for Music and Motion (pp. 69–84).

5 https://creamaker.wordpress.com
6 https://team.inria.fr/mnemosyne/en/aide/

RR N° 9522

16

Axel Palaude, Thierry Viéville

Springer. https://doi.org/10.1007/978-3-540-74048-3\_4

Newell, A., & Simon, H. A. (1972). Human problem solving. Prentice-Hall.

Ney, H., & Ortmanns, S. (1999). Dynamic programming search for continuous speech recognition. IEEE Signal

Processing Magazine, 16(5), 64–83. https://doi.org/10.1109/79.790984

Petitjean, F., Ketterlin, A., & Gançarski, P. (2011). A global averaging method for dynamic time warping, with

applications to clustering. Pattern Recognition, 44(3), 678–693. https://doi.org/10.1016/j.patcog.2010.09.013

Romero, M., Lille, B., & Patiño, A. (Eds.). (2017). Usages créatifs du numérique pour l’apprentissage au XXIe siècle

(1st ed.). Presses de l’Université du Québec. https://doi.org/10.2307/j.ctt1vw0rkx

Tavenard, R. (2021). An introduction to Dynamic TIme Warping. https://rtavenar.github.io/blog/dtw.html

Inria

