Past Word Context Enables Better MEG Encoding
Predictions than Current Word in Listening Stories
Subba Reddy Oota, Nathan Trouvain, Frédéric Alexandre, Xavier Hinaut

To cite this version:

Subba Reddy Oota, Nathan Trouvain, Frédéric Alexandre, Xavier Hinaut. Past Word Context Enables
Better MEG Encoding Predictions than Current Word in Listening Stories. NeuroFrance 2023, May
2023, Lyon, France. . ￿hal-04154794￿

HAL Id: hal-04154794

https://inria.hal.science/hal-04154794

Submitted on 7 Jul 2023

HAL is a multi-disciplinary open access
archive for the deposit and dissemination of sci-
entific research documents, whether they are pub-
lished or not. The documents may come from
teaching and research institutions in France or
abroad, or from public or private research centers.

L’archive ouverte pluridisciplinaire HAL, est
destinée au dépôt et à la diffusion de documents
scientifiques de niveau recherche, publiés ou non,
émanant des établissements d’enseignement et de
recherche français ou étrangers, des laboratoires
publics ou privés.

Distributed under a Creative Commons Attribution 4.0 International License

903

Contact:
\*subba-reddy.oota@inria.fr
†nathan.trouvain@inria.fr
‡xavier.hinaut@inria.fr

Abstract

> Brain encoding is the process of mapping s�muli to brain ac�vity. In this study, we encode 
brain ac�vity recorded through magnetoencephalography (MEG) to explore the nature of 
language processing in the brain. 

> MEG enables us to precisely examine the �ming of language processing during a naturalis-
�c task: 8 subjects listened to 4 independent stories (Gwilliams et al. 2022).

> We parsed or encoded words using several seman�c embeddings or features, syntac�c 
parsers, or language models, and predicted MEG ac�vity using these word representa�ons.

> We ﬁnd that only contextual representa�ons of words signiﬁcantly predict brain ac�vity at 
word onset. Moreover, the strong dependence of predic�vity on past word context suggests 
that the brain encodes words in transient representa�ons of their past context.

> Those ﬁndings are aligned with previous studies on MEG encoding showing past informa-
�on reten�on at phonemic scale (Gwilliams et al. 2022), and echo research on bird song 
produc�on showing a preference for past ac�ons encoding at ambiguous transi�on points 
in song in HVC (a song-related brain area in songbirds; Cohen et al. 2020).

Brain encoding using word representa�ons

Dataset: MASC-MEG (8 subjects listening to 4 stories)

«She moved her ﬁngers gracefully...»

text

speech

Language Model (BERT)
Word Embeddings (GloVe)
Syntac�c/seman�c features

Brain

Word representa�ons
(word as vectors)

X

Model predic�on

Y^

encoding model
f(X)=Y^

MEG recording

Predic�vity score (R²)

MEG recording 
at word onset 
(800ms window, 
208 sensors)

Y

Word representations

X

> Complexity Metrics (CM)
> Part-of-speech (POS)
> Dependency tags (DEP)
> GloVe (one 300-dimen-
sions vector per word, irres-
pec�ve of word context)
> BERT (one 768-dimensions 
vector from the intermediate 
layer (layer-7) to 
encoder 
obtain the embeddings.)

Sta�c: Word is represented 
out of context

Seman�c: 
Word is repre-
sented by its 
meaning

GloVe

CM

BERT

DEP
POS

Syntaxic: Word is 
represented by its 
role in the sentence

Contextual: Word is represented 
with its surrounding context

Past Word Context Enables Be�er MEG Encoding Predic�ons 
than Current Word in Listening Stories
S. Reddy Oota1,2,3\*, N. Trouvain1,2,3†, F. Alexandre1,2,3, X. Hinaut1,2,3‡
1Inria, Bordeaux, France 
2IMN, UMR 5293, Bordeaux, France
3LaBRI, UMR 5800, Talence, France

Context is all you need

Among all word representa�ons, only contextual representa-
�ons (BERT) are able to signiﬁcantly predict MEG ac�vity at 
word onset.
(One sample t-test, p < 0.05, FDR correc�on)

Predic�vity is func�on of context size and direc�on

Word onset

< For each word, BERT representa�ons are built from 
varying context sizes, e.g. from 1 to 5 words in the 
past or future, including current word.

Predic�vity is mostly signiﬁca�ve in 
temporal and inferior frontal lobes

5+

4

3

2

1

0

×10 4

×10 4

2
R
n
a
e
M

8

6

4

2

0

< Predic�vity is func�on of past 
context size. Peak predic�vity of MEG 
ac�vity is obtained 200 ms a�er word 
onset. Representa�ons built using 
long contexts correlate more to brain 
ac�vity than using short contexts.

Predic�vity is dependent on context 
direc�on: Past context is more corre-
lated to brain ac�vity than future 
context. >

20
5
4
3
2
1

2
R
n
a
e
M

8

6

4

2

0

Method
> Preprocessing: MEG ac�vity is ﬁltered (0.5Hz-30Hz) and epoched in 800ms windows 
around word onset (-0.2s before onset, +0.6s a�er word onset). First 200ms serve as ba-
seline for detrending.

>Encoding models are ﬁ�ed using linear regression with L2 regulariza�on (regulariza�on 
parameter found through 10-fold cross valida�on, for each story and each sensors and 
�mepoints).

> R² score signiﬁcance is assessed using a permuta�on test (5000 random permuta�ons 
within each story, FDR corrected using Benjamini-Hochberg method with α=0.05)

Conclusion
> Brain ac�vity seems to reﬂect contextual informa�on. MEG ac�vity is only signiﬁcantly 
predicted by BERT contextual embeddings, and predic�vity is func�on of past context size.

20 (past)
5 (past)
5 (future)
20 (future) 

0.2

0.4

0.6

0.8

Time (s)

0.2

0.4

0.6

0.8

Time (s)

> Words encoded with future context show very low predic�vity: If predic�ons are made 
by the brain, they can not be retrieved using BERT encodings.

MEG ac�vity is the product of current word informa�on and 
short-term context

> High predic�vity with lagged encodings suggests that past context plays an important 
role in encoding current word informa�on in the brain

> In the speaker's brain, there appears to be an "encoding center of mass" that is res-
ponsible for processing long-�me dependencies and encoding past ac�ons rather than 
future ac�ons. This is supported by studies on songbirds, where the brain area involved in 
managing these dependencies preferen�ally encodes past ac�ons, par�cularly during 
phrases with history-dependent transi�ons in song. Similarly, research on phoneme repre-
senta�ons suggests that past events or ac�ons are held in memory un�l they are used to 
disambiguate future events or ac�ons (Gwilliams et al. 2022)

References
L. Gwilliams, G. Flick, A. Marantz, L. Pylkkanen, D. Poeppel, and J.-R. King, “Meg-masc: a high-quality magneto-ence-
phalography dataset for evalua�ng natural speech processing,” arXiv preprint arXiv:2208.11488, 2022.

L. Gwilliams, J.-R. King, A. Marantz, and D. Poeppel, “Neural dynamics of phoneme sequences reveal posi�on-inva-
riant code for content and order,” Nature communications, vol. 13, no. 1, p. 6606, 2022.

Y. Cohen, J. Shen, D. Semu, D. P. Leman, W. A. Liber� III, L. N. Perkins, D. C. Liber�, D. N. Ko�on, and T. J. Gardner, 
“Hidden neural states underlie canary song syntax,” Nature, vol. 582, no. 7813, pp. 539–544, 2020.

 
 
