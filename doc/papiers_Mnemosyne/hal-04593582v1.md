Manifesto in Defence of Human-Centred Education in
the Age of Artificial Intelligence
Margarida Romero, Thomas Frosig, Amanda M L Taylor-Beswick, Jari Laru,

Bastienne Bernasco, Alex Urmeneta, Oksana Strutynska, Marc-André Girard

To cite this version:

Margarida Romero, Thomas Frosig, Amanda M L Taylor-Beswick, Jari Laru, Bastienne Bernasco, et
al.. Manifesto in Defence of Human-Centred Education in the Age of Artificial Intelligence. Creative
Applications of Artificial Intelligence in Education, Springer Nature Switzerland, pp.157 - 178, 2024,
Palgrave Studies in Creativity and Culture, ￿10.1007/978-3-031-55272-4\_12￿. ￿hal-04593582￿

HAL Id: hal-04593582

https://hal.science/hal-04593582

Submitted on 30 May 2024

HAL is a multi-disciplinary open access
archive for the deposit and dissemination of sci-
entific research documents, whether they are pub-
lished or not. The documents may come from
teaching and research institutions in France or
abroad, or from public or private research centers.

L’archive ouverte pluridisciplinaire HAL, est
destinée au dépôt et à la diffusion de documents
scientifiques de niveau recherche, publiés ou non,
émanant des établissements d’enseignement et de
recherche français ou étrangers, des laboratoires
publics ou privés.

12 

Manifesto in Defence of Human-Centred 
Education in the Age of Artificial 
Intelligence 

Margarida Romero, Thomas Frosig, 
Amanda M. L. Taylor-Beswick, Jari Laru, 
Bastienne Bernasco, Alex Urmeneta, Oksana Strutynska, 
and Marc-André Girard 

Abstract This manifesto advocates for the thoughtful integration of 
AI 
in education, emphasising a human-centred approach amid the 
rapid evolution of artiﬁcial intelligence (AI). The chapter explores the 
transformative potential of large language models (LLM) and gener-
ative AI (GenAI) 
in education, addressing both opportunities and 
concerns. While AI accelerates change in education, adapting to students’

M. Romero (B) · T. Frosig · A. Urmeneta 
Université Côte d’Azur, Nice, France 
e-mail: margarida.romero@univ-cotedazur.fr; margarida.romero@unice.fr 

T. Frosig 
e-mail: thomas.frosig@etu.univ-cotedazur.fr 

A. Urmeneta 
e-mail: alex.urmeneta@etu.univ-cotedazur.fr 

A. M. L. Taylor-Beswick 
University of Cumbria, Carlisle, UK 
e-mail: a.taylor-beswick@cumbria.ac.uk

© The Author(s) 2024 
A. Urmeneta and M. Romero (eds.), Creative Applications of Artiﬁcial Intelligence in 
Education, Palgrave Studies in Creativity and Culture, 
https://doi.org/10.1007/978-3-031-55272-4\_12 

157

158

M. Romero et al.

diverse 
learning needs, it also poses challenges to traditional assess-
ment paradigms. The manifesto stresses the importance of empowering 
teachers and students as decision-makers, highlighting the need for a 
balanced approach to AI integration. It emphasises human-centricity 
in AI use, promoting ethical considerations, responsible practices, and 
regulations. The right to choose and co-create is underscored, giving 
autonomy to educators and learners in selecting technologies aligned 
with their philosophies. Additionally, the manifesto 
introduces the 
concept of hybrid intelligence (HI), advocating collaboration between 
human and machine intelligence to enhance educational experiences. 
The manifesto encourages creative uses of AI in education, envisioning a 
harmonious partnership where AI and humans co-create transformative 
knowledge. 

Keywords Human-centred education · Hybrid intelligence · 
Generative AI · AI education · Large language models

J. Laru 
University of Oulu, Oulu, Finland 
e-mail: jari.laru@oulu.ﬁ 

B. Bernasco 
Saxion University of Applied Sciences, Enschede, The Netherlands 
e-mail: s.h.c.m.bernasco@saxion.nl 

O. Strutynska 
Dragomanov Ukrainian State University, Kyiv, Ukraine 
e-mail: o.v.strutynska@npu.edu.ua 

M.-A. Girard 
Université de Montréal, Montreal, QC, Canada 
e-mail: marc-andre.girard.2@umontreal.ca

12 Manifesto in Defence of Human-Centred Education …

159

Introduction 

When the term AI ﬁrst saw the light of day at the Dartmouth work-
shop in 1956, the proposal for the conference included the assertion 
that ‘every aspect of learning or any other feature of intelligence can be so 
precisely described that a machine can be made to simulate it’ (McCarthy 
et al., 2006, p. 12). In the past, the focus was on creating machines that 
could simulate learning and intelligence. However, the current discourse 
on AI in the public domain is shifting away from mere simulation 
towards acknowledging the signiﬁcant disruption of human processes 
and practices that AI has set in motion. Indeed, one could encapsu-
late this disruption by highlighting the stark contrast between the rapid 
evolution of AI and the comparatively slower pace at which most educa-
tional actors are acquainting themselves to these advancements. Unlike 
every transformative technology before it, AI developments continue to 
move at speed and scale, allowing little time for acceptability and the 
subsequent and necessary mechanisms of overview and governance. 

Traditional AI systems focused on narrow tasks, such as playing chess 
(Mainzer & Mainzer, 2020). In contrast, current foundation models 
possess a pre-trained, generalised knowledge base that enables them to 
perform a wide array of language-related tasks. This versatility positions 
foundation models as potential game-changers in education, in which 
learning is most often supported by linguistic interactions. Today’s AI 
foundational models, deﬁned as ‘the base models trained on large-scale 
data in a self-supervised semi-supervised manner that can be adapted for 
several other downstream tasks’ (Bommasani et al., 2021), are capable of 
simulating not only every neural aspect of learning but also a wide range 
of creative activities, solving complex problems, generating functional 
computer code, and quoting a majority of the authored world. These AI 
applications seek to produce a wide and general variety of outputs based 
on large linguistic models, which can be adapted to a range of educa-
tional interactions including information searches, creating exemplars, 
generating detailed explanations or summaries, language translations, 
creating quiz questions, and even simulating dialogue for interactive 
learning scenarios.

160

M. Romero et al.

In this manifesto, we consider the UNICEF deﬁnition of AI, which 
is future-proof, human-oriented, and data-dependent (Holmes et al., 
2022). AI refers to 
‘machine-based systems that can, given a set of 
human-deﬁned objectives, make predictions, recommendations, or deci-
sions that inﬂuence real or virtual environments’ (OECD, 2019, para. 
12). AI systems interact with us and act on our environment, either 
directly or indirectly. Often, they appear to operate autonomously, and 
can adapt their behaviour when provided additional context (UNICEF, 
2021). In this chapter, special focus is put on the educational and societal 
impacts of large language models (LLM) and generative AI (GenAI) over 
more traditional AI technologies, such as machine learning (ML). In the 
following paragraphs, we use the generic term artiﬁcial intelligence (AI) 
for these separate artiﬁcial intelligence technologies. 

The advanced capabilities of AI may be seductive as a potential tech-
nical solution for the educational system’s shortcomings during the global 
school closures caused by the COVID-19 pandemic as well as the current 
educational challenges around diversity in the learning process. Through 
adaptive learning environments (Dogan et al., 2023; Minn, 2022), AI 
can identify and respond to students’ unique learning challenges, pref-
erences, and pace, fostering a more inclusive and effective educational 
environment. Similar to AI, the use of mobile technologies in the class-
room has been discussed as both an opportunity, such as when it is 
used to support pedagogy or learning activities, as well as a distractor, in 
instances when it is applied without pedagogical strategies. As such, some 
schools have chosen to ban such devices or technologies in their codes of 
behaviour. In this context, the ongoing debates regarding the need to 
limit access to different types of technologies for K12 learners continue 
to highlight the concerns among educational stakeholders—notably 
parents, teachers, school principals, and policy makers—regarding its 
use. The integration of technology in school activities and curriculum 
remains a contentious issue in which technologists and technophobes 
provide different perspectives on a complex phenomenon where tech-
nology transformation creates both opportunities and challenges (Culver, 
2017; Romero et al., 2016). 

Likewise, AI accelerates the rate of change in different educational 
domains by developing models, enriched through machine learning, used

12 Manifesto in Defence of Human-Centred Education …

161

to develop predictions or create educational content. This process can 
disrupt the standard assessment paradigm (SAP), as deﬁned by Mislevy 
et al. (2012), by personalising the assessment process and allowing for 
more accurate and relevant measurements. Here AI excels at replicating 
educational elements, such as evaluation methods like multiple-choice 
questions, essays, and short-answer questions, while also supporting 
adaptive learning systems where learning analytics are used to support 
the learning process. However, it is important to note that AI cannot 
replicate every aspect of learning. For instance, when evaluating learning 
processes centred around a shared understanding or values fostering 
metacognition, as well as competency-based assessment of activities in 
which human empathy, morality, and subjectivity are required, AI tools 
are limited in their ability to develop real-sensitivity feedback, even if 
they can be designed to simulate a certain type of empathic relationship 
with the end-user (Montemayor et al., 2022). This underscores how AI 
is considered as an enhancement of teaching practices to augment the 
learning experience through a hybrid intelligence approach rather than 
a replacement of certain teaching tasks. Hence, while AI technologies 
provide enormous potential for the learner’s experience and education in 
general, there is also sufﬁcient cause for concerns (Dwivedi et al., 2023). 
Another challenge of AI technologies deals with human creation and 

originality. 

The integration of AI carries the potential for varying degrees of 
plagiarism and unethically facilitated collaborative creation of intellectual 
content. This ethical concern looms over both students and educators, 
encompassing not only the manner in which students use AI, but also 
the guidance provided by their teachers (Dwivedi et al., 2023). The 
intellectual property challenges in the use of generative AI have led to 
different research journals, newspapers, and Higher Education Institu-
tions setting up guidelines for regulating the ethical use of AI in the 
human production of new works. 

This manifesto advocates for a balanced and thoughtful integration 
of AI technology into the educational landscape. It does this by recog-
nising the current tensions between AI’s inherent potential and its ability 
to disrupt the current human-centred education paradigm. It also seeks 
to distance itself from the often polarising debate where AI is either

162

M. Romero et al.

a transformative solution with the ability to greatly beneﬁt education 
or an unpredictable technology, controlled by powerful companies with 
hidden motives. While both sides may yet hold some truth, by focusing 
solely on AI’s underlying technology, we risk losing sight of the very 
essence of education: the support of human development and well-being 
within a community. 

In the following sections, the learning scientists and education experts 
behind this manifesto present several recommendations to help miti-
gate the scale of AI’s disruption in educational settings. Our hope is 
that these recommendations provide context to educational stakeholders 
and developers seeking guidance on how to integrate AI technology, 
while retaining teacher and student agency and supporting, rather than 
displacing, future teaching and learning processes. Finally, we acknowl-
edge that these recommendations, presented here at the dawn of AI’s 
adoption, will need to evolve in order to keep pace with this rapidly 
changing technology. 

Empowering Students and Teachers 
as Decision-Makers 

Cuban (1986) recognises that one of the main challenges associated with 
integrating technology into education is the exclusion of teachers in the 
decision-making process. Involving teachers in the participatory design 
process and empowering them to adapt the technology to the needs 
of their students is indispensable for ensuring that developed learning 
solutions align with their needs and the needs of their learners (Frøsig, 
2023). Tedre et al. (2023) propose a similar approach with their project 
to engage Finnish students in a collaborative machine learning design 
process. Teachers are an essential component of the learning process in a 
human-centred educational system because they help students develop a 
common knowledge of their roles and duties based on a distinct purpose 
and core set of values. This relationship, based on collaboration and 
shared goals, is an essential component of education. 

However, the prevailing trend in educational technology to prioritise 
automated indicators, even though they can miss aspects of the learning

12 Manifesto in Defence of Human-Centred Education …

163

experience not easily represented by data, can sometimes lead to learning 
analytics being emphasised at the expense of pedagogic principles and 
ethics (Williamson, 2022). For example, factors such as socio-economic 
status, values, and motivations can be difﬁcult to quantify using data, 
but play a substantial role in a learner’s progress, nonetheless. Sahlberg 
and Hasak (2017) argue that mining for Big Data can divert educators, 
leaders, pundits, and policymakers from meeting the diverse and unique 
needs of their students. As such, they promote the use of ‘Small Data’ 
(Lindstrom, 2016) to underline ‘small clues that uncover huge trends’ 
(Sahlberg & Hasak, 2017, p. 7), typically centred on students’ progress, 
emotions, behaviours, and other important observable details. 

To enable meaningful integration, educational technologies should 
empower teachers to make informed choices, not only within their class-
rooms, but also at the national level. As Sahlberg and Hasak (2017) advo-
cate, this can be achieved by giving more autonomy to the educators, 
aiming for an emancipation from school bureaucracy. It is imperative 
to reverse the current trend of surrendering decision-making power to 
technologies and, instead, place educators at the forefront when shaping 
the educational journey of students (Tedre et al., 2023). Learning is a 
social process and, currently, only humans can process the full spectrum 
of observable and unobservable factors that impact student learning. 
Furthermore, sidelining teachers runs the risk of excluding a substan-
tial body of professional expertise and longitudinal knowledge regarding 
their learners. Additionally, teachers can act as a counterbalance to an 
over reliance on learning analytics where machine technology and its 
outputs are automatically assumed to be correct (Swiecki et al., 2022). 

Impact of Artificial Intelligence on Existing 
Educational Paradigms 

The widespread availability of technologies, such as generative AI, poses 
a signiﬁcant challenge to traditional pedagogical instruction-based prac-
tices and assessment methodologies. While the current educational 
systems in most of the member Organisation for Economic Co-operation

164

M. Romero et al.

and Development (OECD) countries focus on evaluating student perfor-
mance based on their ability to meet speciﬁc learning goals, there are 
initiatives afoot that seek to put student engagement and agency above 
the role of learning goals (Harouni, 2015). 

The current evolution of AI agents is moving them beyond text-based 
interactions towards multimodal collaboration where AI is seen as a 
partner rather than merely a tool. Here AI can assume the role of either 
a coach or a teammate, which can support self-regulation, collaboration, 
knowledge co-construction, and problem solving (Cress & Kimmerle, 
2023; Dwivedi et al., 2023; Lodge et al., 2023; Mollick & Mollick, 
2023; Sharples, 2023). 

Contemporary AI technologies can be considered as an extension 
of existing knowledge and skills, which extends and enhances in ways 
that go beyond what either a human or machine could do individually. 
More precisely, such technologies can be integrated into the thinking and 
learning processes students engage in. For example, AI image generators 
can potentially enhance and build on human capabilities for creativity 
(Lodge et al., 2023). 

several 

(2023) 

introduced 

Furthermore, Sharples 

ideas of how 
contemporary Generative AI tools could be used to scaffold students 
in collaborative and dialogical learning: (a) generator of possibilities; (b) 
opponent in argumentation; (c) an assistant in design; (d) an exploratory 
tool; (e) collaborator in creative writing. However, because the reliability 
and accuracy of information provided by generative AI is not guaranteed, 
metacognitive skills like self-reﬂection and critical thinking are needed 
when students work with generative AI. In practice, human learners 
need to self-monitor their learning goals and states, continuously eval-
uate AI responses, and adapt their own learning strategies or prompts to 
AI (Lodge et al., 2023). Evaluating responses is a complex skill in itself. It 
requires students to compare responses by AI to scientiﬁcally or expertly 
grounded responses, and to evaluate how relevant the AI responses are to 
the context of the problem. 

From a future perspective, designing AI that can fully participate as an 
agent in social learning activities and ﬁne-tune existing language models 
for educational purposes is not an adequate approach. According to 
Sharples (2023), current AI technologies lack, for example, ‘long-term

12 Manifesto in Defence of Human-Centred Education …

165

memory, the ability to reﬂect on its output and consolidate its knowl-
edge from each conversation. More fundamentally, it does not capture 
the affective and experiential aspects of what it takes to be a learner and 
teacher’ (p. 7). 

Likewise, it is also important to start considering how UX, in the 
framework of co-creative AI systems (CAIS), might encourage, or even 
discourage, new modes of human–AI co-creativity by virtue of its inter-
active design (Feldman, 2017). The idea of a text box being the ideal 
gateway to AI for the majority of users and use cases already seems 
dated. It will be interesting to see how users might perceive AI differently 
when engaged in a ‘spoken conversation’ versus words typed in a text box 
(Rezwana & Maher, 2021). Given its ability to impact the cognitive and 
emotional factors in human–AI interactions, there is a need to support 
further UX analysis and development for improving AI technologies in 
education. 

Artificial Intelligence in Human-Centred 
Education 

In advocacy of a human-centred approach to education, it is essential 
to establish frameworks that guide the ethical and responsible use of AI 
technologies. Creating these frameworks requires an ongoing dialogue 
between educators, learners, AI developers, technologists, legislators, and 
other stakeholders with the expressed purpose of creating alignment 
between the means (e.g. technology or pedagogy) and the objectives (e.g. 
the purpose of education) of its use. AI can be viewed as a tool for 
achieving speciﬁc goals, but those goals should be clearly deﬁned, shared 
among all stakeholders, and transparent in purpose. Within this context, 
the European Union’s (EU) recent AI Act takes the ﬁrst steps in creating 
a legally binding framework for the regulation of AI’s development and 
use in its member states. Importantly, one of the primary stated goals of 
the EU’s AI Act is that AI systems should be overseen by people, rather 
than being automated, recognising the role humans play in guiding its 
use and preventing harmful outcomes (Helberger & Diakopoulos, 2023; 
Kazim et al., 2023).

166

M. Romero et al.

Given its potential for disruption, teachers should have the autonomy 
to reject certain technologies that may not align with their pedagog-
ical philosophy or the unique needs of their students. Simultaneously, 
learners should be granted the right to explore and test emerging tech-
nologies under the guidance of educators. This dual approach respects 
the agency of both teachers and learners, fostering an environment where 
educational technologies are not imposed, but collaboratively chosen 
based on their merit and relevance. While teachers should be empow-
ered to reject certain technologies, learners should also have the right to 
beneﬁt from different technologies that might support their learning and 
co-creative processes. 

To support this aim, teachers will need access to ongoing profes-
sional development in the form of multi-disciplinary training groups 
and dynamic learning communities. Romero (2023) argues that this 
calls for a simultaneous focus on improving teachers’ digital competences 
as well as the time and space necessary to allow for their accultura-
tion to AI. Access to diverse types of acculturation activities is critical 
if teachers are to develop the conﬁdence and agency necessary to gauge 
the impact of rapidly evolving technologies. For instance, participation 
in dynamic learning communities can help teachers develop a diversity 
of expertises that beneﬁt not only their classrooms, but the school and 
wider community at large. Furthermore, participation in these learning 
communities can beneﬁt teachers by giving them access to peers whose 
speciﬁc digital competencies might scaffold their own inherent weak-
nesses. This also serves to beneﬁt learners who, without this framework 
of shared expertise, may not have had access to certain technologies 
such as educational robotics, artiﬁcial intelligence, maker education, or 
creative programming. Continuous professional development also plays 
a key role in ensuring that teachers are prepared for potential disruptions 
caused by AI in education. Given the speed at which AI technologies 
are advancing, ongoing professional training will be key to ensuring that 
teachers have access to the latest pedagogical methods and materials as 
well as continuous updates on the technology’s evolution. Additionally, 
co-design activities between researchers, learners, and educators should 
not only be encouraged, but proactively initiated and supported through 
curriculum, dedicated learning environments, and research partnerships.

12 Manifesto in Defence of Human-Centred Education …

167

An example of such an activity can be found in Finland with the Gener-
ation AI1 project, which aims to empower teachers and students by 
increasing their data agency and AI literacy through the use of co-created 
AI tools, materials, and pedagogies. 

Hybrid Intelligence 

Akata et al. (2020) introduce hybrid intelligence (HI) as a paradigm 
that combines human and machine intelligence to enhance human intel-
lect and capabilities, emphasising collaboration rather than replacement. 
In formulating a research agenda for HI, they identify four key chal-
lenges, including Collaborative HI, Adaptive HI, Responsible HI, and 
Explainable HI. These challenges underscore the need to address the 
intricate dynamics between humans and intelligent systems, laying the 
foundation for the evolution of AI technologies. The emphasis on collab-
oration between AI and humans within hybrid intelligence aligns with 
the idea of empowering individuals to actively engage with AI systems 
towards a deﬁned objective. Additionally, the pursuit of adaptive intel-
ligence supports an individuals’ capacity to learn and adapt to evolving 
technological landscapes, as facilitated by improved data and AI literacy. 
In contemplating the potential of hybrid intelligence to augment 
human capabilities through technology, it is essential to consider the 
foundational human resources that have been instrumental in the devel-
opment of AI. The agentic use of AI, as highlighted by the emphasis on 
data and AI literacy, serves to bridge the gap between AI’s technolog-
ical potential and the capacity to develop new activities and products. 
By nurturing the ability to comprehend and navigate the complexities of 
data and artiﬁcial intelligence, learners can become active participants in 
the development and utilisation of AI. This objective aligns seamlessly 
with the overarching goal of augmenting human capabilities, empha-
sising the empowerment of individuals to make informed decisions and

1 Generation AI project: https://www.generation-ai-stn.ﬁ. 

168

M. Romero et al.

contributions in a technology-driven landscape. These types of partici-
patory approaches can also support the development of the agentic uses 
of AI (Tedre et al., 2023). 

These participatory approaches become a pivotal aspect in addressing 
the challenges set forth by Akata et al. (2020) and implemented in the 
workshops by Tedre et al. (2020). It not only aligns with the goals of 
Collaborative and Adaptive HI, but also reinforces the importance of 
foundational human sources in shaping the trajectory of hybrid intelli-
gence. The development of data and AI literacy is not just an objective, 
but a catalyst for allowing learners to beneﬁt from AI with the possibility 
to develop different applications of hybrid intelligence in education. 

Lodge et al. (2023) refer to hybrid learning as an educational approach 
where generative AI systems work in conjunction with human learners in 
order to promote both cognitive and metacognitive aspects of learning. 
From a cognitive perspective, AI technologies can be used to scaffold 
instances of information processing, content generation, or problem 
solving. Similarly, AI from a metacognitive perspective can support 
learners with features 
like real-time feedback, adaptive questioning, 
and self-assessment prompts helping learners to monitor, evaluate, and 
adjust their learning strategies. This makes AI an active interlocutor or 
teammate (Lodge et al., 2023). 

Creative Uses of Artificial Intelligence 
in Education 

Beyond conventional uses of AI as a tool for generating text, image, or 
content, AI emerges as a dynamic force not only for co-creating knowl-
edge in participatory settings, but also for reshaping human practices. 
This transcendent use of AI for good (#AI4good) involves a paradigm 
shift, where AI tools engage in a shared, collaborative process with 
human agents, contributing to the conceptualization and development 
of critical knowledge (Septiani et al., 2023). At this pinnacle, AI is 
seamlessly integrated into the creation of transformative knowledge, 
fostering agency, and catalysing a profound evolution in human prac-
tices (Romero, 2023). It is here that humans and AI cohabitate, playing

12 Manifesto in Defence of Human-Centred Education …

169

to each other’s strengths, with each lending qualities that individually 
make them unique, but together true collaborators (Wu et al., 2021). 

Figure 12.1, showing the six levels of the #PPAI6 model, presents a 
way of differentiating between the different types of creative engage-
ment in human–AI activities (Romero, 2023). This model provides a 
continuum that starts with passive consumption and evolves into more 
active and participatory forms of engagement, emphasising the diverse 
ways in which individuals and groups can collaborate with AI in the 
learning process. 

. Level 1. Passive consumer: The learner consumes AI-generated content 

without understanding how it works.

. Level 2. Interactive consumer: The learner interacts with AI-generated 

content. The AI system adapts to the learners’ actions.

. Level 3. Individual content creation: The learner creates new content 

using AI tools.

. Level 4. Collaborative content creation: A team creates new content 

using AI tools.

. Level 5. Participatory knowledge co-creation: A team creates content 
thanks to AI tools and the collaboration of stakeholders in a complex 
problem.

. Level 6. Expansive learning supported by AI: In formative interven-
tions supported by AI, participants’ agency may expand or transform 
problematic situations. AI tools can be used to help identify contra-
dictions in complex problems and help generate concepts or artefacts 
to regulate conﬂicting stimuli and foster collective agency and action.

Fig. 12.1 

Six levels of creative engagement in human–AI in education

170

M. Romero et al.

AI tools can be used to assist in the modelling of activity systems 
as well as in the simulation of new actions, facilitating the expansive 
visualisation process.

In order to support the agentic use of AI, levels 5 and 6 of the model 
are designed to contribute to learners’ acculturation to AI and its funda-
mental principles. This strategic approach aims to empower learners, 
enabling their active engagement in participatory activities where hybrid 
intelligence ﬂourishes through the synergistic collaboration of human– 
AI systems. These higher levels also aim to raise student and teacher 
awareness of AI through the lens of agentic and creative engagement. 

In order to support agentic and creative engagement and establish 
new paradigms of human–AI co-creativity, more work will need to be 
done to address the challenges, latent or otherwise, to its acceptance. 
Foremost among these include displacement concerns, human biases 
towards AI created work, and the difﬁculty in applying value to AI 
co-creations given the subjective value assigned to creative works. Under-
standing creativity requires a nuanced consideration of speciﬁc cultural 
and human sensitivities, both in terms of their manifestation and eval-
uation. Consequently, as we contemplate human–AI co-creativity, it 
becomes imperative to explore the role of culture in shaping and inﬂu-
encing this collaborative process, understanding that it will need to 
navigate the same subjective, norm-aligned evaluation and value-assigned 
processes as other creativity projects. Likewise, Magni et al. (2023) 
highlight the phenomena of human gatekeeping where some forms of 
AI-produced work are assigned a lower value based on the perception of 
effort, or lack thereof. While there is research showing that anthropomor-
phic AI agents can moderate this producer-identify effect on the creative 
evaluation process (Glikson & Woolley, 2020; Israﬁlzade, 2023; Magni 
et al., 2023), further solutions will need to be found that counter the 
tendency for humans to ascribe value to effort or innate ability. Finally, 
there is a growing fear of displacement as humans wrestle with AI’s 
impact on future workforce and professional opportunities (Thomson & 
Thomas, 2023; Tiwari, 2023).

12 Manifesto in Defence of Human-Centred Education …

171

At its pinnacle, the transformative potential of AI can transcend its 
role from knowledge co-creation to actively transforming human prac-
tices (Romero, 2023). At the highest level of creative engagement with 
the AI model (#PPAI6), AI is integrated into the creation of critical 
knowledge, fostering agency, and reshaping human practices. The collab-
orative process between generative AI tools and human agents becomes 
a shared endeavour to develop agency and enact transformative changes. 
This aligns seamlessly with the goal of expansive learning where forma-
tive interventions contribute to expanding or transforming problematic 
situations. AI tools, in this context, play a vital role in identifying 
contradictions, generating concepts, regulating conﬂicting stimuli, and 
ultimately fostering collective agency and action. 

Inclusivity and Diversity in Artificial 
Intelligence 

The challenges in ethics and inclusivity arise due to the high complexity 
and diversity of cognitive technologies, including human–AI applica-
tions in education. The AI act developed at the European level has been 
a clear example of the level of complexity in creating consensus in AI 
principles that ensure citizens’ rights while simultaneously supporting 
innovation. Attempts to align individual issues with stakeholders are 
hindered by the many tensions between stakeholder objectives. Inter-
ventions in one part of the AI ecosystem (e.g. need for learners’ privacy) 
can have consequences in other parts (e.g. uses of facial recognition to 
identify the learners’ engagements). These tensions require a participa-
tory approach in the design of AI systems that could be developed for 
educational purposes (Holmes et al., 2021). 

Stahl (2021) proposes three main requirements for 

interventions 
meant to improve the ethical design and integration of AI. Firstly, inter-
ventions need to clearly delineate the boundaries of the ecosystem (e.g. 
the educational actors engaged) in relation to the actors, but also the 
geographical scope and the topics addressed. Secondly, interventions 
should focus on knowledge development, support, maintenance, and 
dissemination within the AI ecosystems. In education, this raises the

172

M. Romero et al.

need for the different educational actors to develop an understanding 
of AI fundamentals and the way that human–AI collaboration can 
support the teaching and learning processes. Lastly, interventions need 
to be adaptive and ﬂexible to emerging needs. In relation to inclusivity, 
there is a need to support pre-service and in-service teachers in their 
acculturation to the fundamentals of AI. This support will aid their 
decision-making process for the integration, or not, of AI technologies 
and allow them to consider the agentic and creative engagement learners 
can develop using these tools. 

Advancing Towards an Increased 
Human-Centred Education in the Age of AI 

The challenges and opportunities presented in this manifesto highlight 
the need to develop critical thinking as well as an acculturation to AI 
for each of the varied educational stakeholders. In particular, developing 
critical thinking skills has become essential given the escalating challenges 
posed by AI integration in the educational and non-educational uses of 
Generative AI. These include, but are not limited to, generating fake 
information, unethical AI-generated content, and impersonations such 
as deep fakes. The proliferation of misinformation, across digital formats, 
has the potential to manipulate public opinion, 
incite conﬂicts on 
various grounds (e.g., racial, religious), and exacerbate existing inequal-
ities and stereotypes such as gender disparities (Vartiainen et al., 2023). 
While students should be taught the skills necessary to recognise and 
dismiss fake information, there is also a need to regulate the type of AI 
content that could compromise students’ privacy and integrity. 

It is not just generative AI that impacts our students’ everyday lives. 
AI is ubiquitous and pervasive (social media and mobile phones are 
examples), and often coupled with massive-scale data collection. This 
has given rise to a plethora of complex challenges and ethical dilemmas 
including uneven power relationships, privacy rights violations, total 
surveillance, hybrid inﬂuencing, behaviour engineering, and algorithmic 
biases (Page et al., 2022). Kahila et al. (submitted) acknowledge the

12 Manifesto in Defence of Human-Centred Education …

173

computational processes changing the cultural practices and decision-
making by individuals, organisations, and institutions and suggest the 
development of data agency as a solution to these societal challenges. 

Educators face the crucial task of equipping citizens with the skills 
necessary to navigate a society permeated by AI systems and tools. In 
this context, fostering acculturation to AI from an early age, as part of 
an overarching digital literacy framework that includes critical thinking, 
emerges as a pivotal strategy. For this objective, the Digital Compe-
tence Framework for Citizens (DigComp 2.2) (Vuorikari et al., 2022) 
offers a comprehensive guide, encompassing elements tailored for inter-
acting with AI systems. To bolster citizens’ AI literacy, educators can 
leverage this framework as a foundation for planning and developing 
curricula and course materials. Furthermore, by integrating these compe-
tencies into educational practices, educators contribute to the cultivation 
of a digitally competent citizenry capable of discerning, evaluating, and 
navigating the intricate landscape of information in the age of AI. 

In collaboration with the DigComp 2.2 framework, educators will 
also need to develop age appropriate tools and materials to ensure that 
students at every level have access to fundamental AI concepts. These AI 
competency frameworks are required to navigate the evolving landscape 
of education in the age of AI and support a human-centred approach to 
education as a major pillar of our educational systems. This manifesto 
calls for a re-evaluation of the current contradictions, emphasising the 
need to empower teachers, ethically regulate the use of transformative 
technologies, and uphold the rights of both educators and learners. By 
doing so, we can forge a path towards an educational future where tech-
nology complements and enhances the human experience rather than 
overshadowing it. 

References 

Akata, Z., Balliet, D., De Rijke, M., Dignum, F., Dignum, V., Eiben, G., 
et al. (2020). A research agenda for hybrid intelligence: Augmenting human

174

M. Romero et al.

intellect with collaborative, adaptive, responsible, and explainable artiﬁcial 
intelligence. Computer, 53(8), 18–28. 

Bommasani, R., Hudson, D. A., Adeli, E., Altman, R., Arora, S., von Arx, 

S., et al. (2021). On the opportunities and risks of foundation models . arXiv 
preprint arXiv:2108.07258 

Cress, U., & Kimmerle, J. (2023). Co-constructing knowledge with genera-
tive AI tools: Reﬂections from a CSCL perspective. International Journal 
of Computer-Supported Collaborative Learning. https://doi.org/10.1007/s11 
412-023-09409-w 

Cuban, L. (1986). Teachers and machines: The classroom use of technology since 

1920. Teachers College Press. 

Culver, B. L. (2017). Technology in education: Technology integration into the 
school’s curriculum (doctoral dissertation). Trident University International, 
Cypress, CA. 

Dogan, M. E., Goru Dogan, T., & Bozkurt, A. (2023). The use of artiﬁ-
cial intelligence (AI) in online learning and distance education processes: 
A systematic review of empirical studies. Applied Sciences, 13(5), 3056. 
Dwivedi, Y. K., Kshetri, N., Hughes, L., Slade, E. L., Jeyaraj, A., Kar, A. K., 
et al. (2023). “So what if ChatGPT wrote it?” Multidisciplinary perspectives 
on opportunities, challenges and implications of generative conversational 
AI for research, practice and policy. International Journal of Information 
Management, 71, 102642. 

Feldman, S. S. (2017, July). Co-creation: Human and AI collaboration in 
creative expression. In Electronic Visualisation and the Arts (EVA 2017). BCS 
Learning & Development. 

Frøsig, T. B. (2023). Expanding the Technology Acceptance Model (TAM) 
to consider teachers needs and concerns in the design of Educational Tech-
nology (EdTAM). International Journal of Emerging Technologies in Learning, 
18(16), 130–140. 

Glikson, E., & Woolley, A. (2020, March 12). Human trust in artiﬁcial intel-
ligence: Review of empirical research. The Academy of Management Annals. 
https://doi.org/10.5465/annals.2018.0057. 

Harouni, H. (2015). Purpose and education: The case of mathematics (Doctoral 

dissertation). Harvard Graduate School of Education. 

Helberger, N., & Diakopoulos, N. (2023). ChatGPT and the AI act. Internet 

Policy Review, 12(1). https://doi.org/10.14763/2023.1.1682 

Holmes, W., Persson, J., Chounta, I. A., Wasson, B., & Dimitrova, V. (2022). 
Artiﬁcial intelligence and education: A critical view through the lens of human 
rights, democracy and the rule of law. Council of Europe.

12 Manifesto in Defence of Human-Centred Education …

175

Holmes, W., Porayska-Pomsta, K., Holstein, K., Sutherland, E., Baker, T., 
Shum, S. B., Santos, O. C., Rodrigo, M. T., Cukurova, M., Bittencourt, 
I. I., & Koedinger, K. R. (2021). Ethics of AI in education: Towards a 
community-wide framework. International Journal of Artiﬁcial Intelligence in 
Education, 32, 504–526. 

Israﬁlzade, K. (2023). Beyond automation: The impact of anthropomorphic gener-
ative AI on conversational marketing. 8th International European Conference 
on Interdisciplinary Scientiﬁc Research, Vol. 5, No. 2, pp. 757–766. 

Kahila, 

J., Vartiainen, H., Tedre, M., Arkko, E., Lin, A., Pope, N., 
for 

Jormanainen, I., & Valtonen, T. (submitted). Pedagogical framework 
cultivating children’s data agency and creative abilities in the age of AI. 

Kazim, E., Güçlütürk, O., Almeida, D., Kerrigan, C., Lomas, E., Koshiyama, 
A., et al. (2023). Proposed EU AI act—Presidency compromise text: Select 
overview and comment on the changes to the proposed regulation. AI and 
Ethics, 3(2), 381–387. 

Lindstrom, M. (2016). Small data: The tiny clues that reveal huge trends . Martin’s 

Press. 

Lodge, J., Yang, S., Furze, L., & Dawson, P. (2023). It’s not like a calculator, 
so what is the relationship between learners and generative artiﬁcial intel-
ligence? Learning: Research and Practice, 9 (2), 117–124. https://doi.org/10. 
1080/23735082.2023.2261106 

Magni, F., Park, J., & Chao, M. M. (2023). Humans as creativity gatekeepers: 
Are we biased against AI creativity? Journal of Business and Psychology, 1–14. 
Mainzer, K., & Mainzer, K. (2020). A short history of the AI. In Artiﬁcial 

intelligence—When do machines take over? (pp. 7–13). Springer. 

McCarthy, J., Minsky, M. L., Rochester, N., & Shannon, C. E. (2006). A 
proposal for the Dartmouth summer research project on artiﬁcial intelli-
gence, August 31, 1955. AI Magazine, 27 (4), 12. https://doi.org/10.1609/ 
aimag.v27i4.1904 

Minn, S. (2022). AI-assisted knowledge assessment techniques for adaptive 
learning environments. Computers and Education: Artiﬁcial Intelligence, 3, 
100050. 

Mislevy, R. J., Behrens, J. T., Dicerbo, K. E., & Levy, R. (2012). Design and 
discovery in educational assessment: Evidence-centered design, psychomet-
rics, and educational data mining. Journal of Educational Data Mining, 4 (1), 
11–48. https://doi.org/10.5281/zenodo.3554641 

Mollick, E. R., & Mollick, L. (2023). Assigning AI: Seven approaches for 

students, with prompts. SSRN . https://ssrn.com/abstract=4475995

176

M. Romero et al.

Montemayor, C., Halpern, J., & Fairweather, A. (2022). In principle obstacles 
for empathic AI: Why we can’t replace human empathy in healthcare. AI & 
Society, 37 (4), 1353–1359. 

OECD. (2019). Recommendation of the Council on Artiﬁcial Intelligence . OECD 
Legal Instruments. https://legalinstruments.oecd.org/en/instruments/oecd-
legal-0449 

Page, X., Berrios, S., Wilkinson, D., & Wisniewski, P. J. (2022). Social media 
and privacy. In B. P. Knijnenburg, X. Page, P. Wisniewski, H. R. Lipford, N. 
Proferes, & J. Romano (eds.), Modern socio-technical perspectives on privacy 
(pp. 113–147). Springer International Publishing. 
Rezwana, J., & Maher, M. L. (2021). COFI: A 

for modeling 

framework 

interaction in human-AI co-creative systems. ICCC, pp. 444–448. 

Romero, M. (2023). Lifelong learning challenges in the era of artiﬁcial intel-
ligence: A computational thinking perspective. 12th International Research 
Meeting in Business and Management. 

Romero, M., Laferriere, T., & Power, T. M. (2016). The move is on! From 
the passive multimedia learner to the engaged co-creator. ELearn, 2016 (3). 
https://doi.org/10.1145/2904374.2893358 

Sahlberg, P., & Hasak, J. (2017). Small data for big change. Education: Journal 

of the N.S.W. Public School Teachers Federation, 98(1), 7. 

Septiani, D. P., Kostakos, P., & Romero, M. (2023, July). Analysis of creative 
engagement in AI tools in education based on the# PPai6 framework. In 
International conference in methodologies and intelligent systems for technology 
enhanced learning (pp. 48–58). Springer. 

Sharples, M. (2023). Towards social generative AI for education: Theory, prac-
tices and ethics. Learning: Research and Practice, 9 (2), 159–167, https://doi. 
org/10.1080/23735082.2023.2261131 

Stahl, B. C. (2021). Artiﬁcial intelligence for a better future: An ecosystem perspec-
tive on the ethics of AI and emerging digital technologies (p. 124). Springer 
Nature. 

Swiecki, Z., Khosravi, H., Chen, G., Martinez-Maldonado, R., Lodge, J. M., 
Milligan, S., et al. (2022). Assessment in the age of artiﬁcial intelligence. 
Computers and Education: Artiﬁcial Intelligence, 3, 100075. 

Tedre, M., Mäkitalo, K., Vartiainen, H., Kahila, J., Laru, J., & Iwata, 
M. (2023, June). Generation AI: Participatory machine learning co-design 
projects with K-9 students in Finland . Proceedings of the 2023 Confer-
ence on Innovation and Technology in Computer Science Education, 2, 
pp. 657–657.

12 Manifesto in Defence of Human-Centred Education …

177

Tedre, M., Vartiainen, H., Kahila, J., Toivonen, T., Jormanainen, I., & 
Valtonen, T. (2020, October). Machine learning introduces new perspectives 
to data agency in K—12 computing education. In 2020 IEEE Frontiers in 
Education Conference (FIE) (pp. 1–8). IEEE. 

Thomson, T. J., & Thomas, R. (2023, December 12). Generative visual AI in 
newsrooms: Considerations related to production, presentation, and audi-
ence interpretation and impact. Journalism Research, 6 , 318–328. https:// 
doi.org/10.1453/2569-152X-3\_42023-13639-en 

Tiwari, R. (2023, January 19). The impact of AI and machine learning on job 
displacement and employment opportunities. International Journal of Engi-
neering Technologies and Management Research, 7 . https://doi.org/10.55041/ 
IJSREM17506 

UNICEF. (2021). Policy guidance on AI for children 2.0. https://www.uni 
cef.org/globalinsight/media/2356/ﬁle/UNICEF-Global-Insight-policy-gui 
dance-AI-children-2.0-2021.pdf 

Vartiainen, H., Kahila, J., Tedre, M., Sointu, E., & Valtonen, T. (2023). More 
than fabricated news reports: Children’s perspectives and experiences of fake 
news. Journal of Media Literacy Education, 15 (2), 17–30. https://doi.org/10. 
23860/JMLE-2023-15-2-2 

Vuorikari, R., Kluzer, S., & Punie, Y. (2022). DigComp 2.2: The digital compe-
tence framework for citizens—With new examples of knowledge, skills and 
attitudes (EUR 31006 EN). Publications Ofﬁce of the European Union. 
ISBN 978-92-76-48883-5. https://doi.org/10.2760/490274, JRC128415. 
Williamson, B. (2022). Big EdTech. Learning, Media and Technology, 47 (2), 

157–162. 

Wu, Z., Ji, D., Yu, K., Zeng, X., Wu, D., & Shidujaman, M. (2021). 
AI creativity and the human-AI co-creation model. In M. Kurosu (Ed.), 
Human-computer interaction. Theory, methods and tools. HCII 2021. Lecture 
Notes 
in Computer Science (Vol. 12762). Springer. https://doi.org/10. 
1007/978-3-030-78462-1\_13

178

M. Romero et al.

is 

licensed under 

Open Access This chapter 
the Creative 
Commons Attribution 4.0 International License (http://creativecommons.org/ 
licenses/by/4.0/), which permits use, sharing, adaptation, distribution and 
reproduction 
long as you give appropriate 
credit to the original author(s) and the source, provide a link to the Creative 
Commons license and indicate if changes were made. 

in any medium or format, as 

terms of 

the 

The images or other third party material in this chapter are included in the 
chapter’s Creative Commons license, unless indicated otherwise in a credit line 
to the material. If material is not included in the chapter’s Creative Commons 
license and your intended use is not permitted by statutory regulation or 
exceeds the permitted use, you will need to obtain permission directly from 
the copyright holder.

