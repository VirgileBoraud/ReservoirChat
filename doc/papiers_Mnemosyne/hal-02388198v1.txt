A neuro-computational model showing the effects of ventral striatum
lesion on the computation of reward prediction error in VTA Pramod S
Kaushik, Frédéric Alexandre

To cite this version:

Pramod S Kaushik, Frédéric Alexandre. A neuro-computational model
showing the effects of ventral striatum lesion on the computation of
reward prediction error in VTA. NeuroFrance, the international
conference of the french society of Neuroscience, May 2019, Marseille,
France. 2019. ￿hal-02388198￿

HAL Id: hal-02388198

https://inria.hal.science/hal-02388198

Submitted on 1 Dec 2019

HAL is a multi-disciplinary open access archive for the deposit and
dissemination of sci- entific research documents, whether they are pub-
lished or not. The documents may come from teaching and research
institutions in France or abroad, or from public or private research
centers.

L’archive ouverte pluridisciplinaire HAL, est destinée au dépôt et à la
diffusion de documents scientifiques de niveau recherche, publiés ou
non, émanant des établissements d’enseignement et de recherche français
ou étrangers, des laboratoires publics ou privés.

A neuro-computational model showing the eﬀects of ventral striatum
lesion on the computation of reward prediction error in VTA

Computational neuroscience

Dopamine

Reinformcent Learning

Pramod KAUSHIK1,2,3, Frédéric ALEXANDRE1,2,3 1INRIA Bordeaux Sud-Ouest,
200 Avenue de la Vieille Tour, 33405 Talence, France 2LaBRI, Université
de Bordeaux, Bordeaux INP, CNRS, UMR 5800, Talence, France 3IMN,
Université de Bordeaux, CNRS, UMR 5293, Bordeaux, France

Abstract

●Modeling Pavlovian learning which is a fundamental learning mechanism
in animals. ● Pairs a neutral conditioned stimulus (CS) with a rewarding
unconditioned stimulus

(US) and CS becomes rewarding stimulus after training

● Model focuses on the mechanism of RPE within pavlovian learning and
the eﬀects of Ventral Striatum (VS) lesions to illustrate a fundamental
dissociation of magnitude and timing replicating experimental studies.

-   Virtual lesions of VS to VTA GABA was made by disconnecting the link
    between them.

-   Magnitude of reward is still conserved when lesions are made

-   Timing information is lost indicating there are two dimensions to
    Pavlovian conditioning, namely timing and magnitude in a deviation
    from RL models

Model and Experimentation

Model Diagram illustrating structures involved in RPE Computation
Pointed arrows represent excitatory connections ,while rounded arrows
represent inhibitory projections. Dashed lines represent learnable
connections, while solid lines represent ﬁxed connections in the model.

Computational Principles The proposed model is composed of computational
units where each unit represents a population and computes the mean
activity of the population. V(t) represents the membrane potential of
the unit and the ﬁring rate is a positive scalar of V(t) given by U(t).

where τ is the time constant of the cell, B is the baseline ﬁring rate
and η(t) is the additive noise term chosen randomly at each time step
from an uniform distribution between −0.01 and 0.01.

VTA VS LH IT BLA CE OFC PPN

Model Terms

Ventral Tegmental Area Ventral Striatum Lateral Hypothalamus Inferior
temporal cortex Basolateral Amygdala Central Amygdala Orbitofrontal
Cortex Pedunculopontine nucleus

Features of the Model

-   Portrays partial conditioning where VTA dopamine has acquired some
    CS ﬁring and this expectation induces a partial expectation reducing
    US ﬁring

-   Not all early rewards have the same ﬁring and sooner early rewards
    ﬁre more than later early rewards in accordance with experiments
    (Fiorillo

2003) 

-   A new circuit with VTA GABA as a more biologically plausible

expectation signal compared to VS (Keiﬂin 2015)

-   VS Lesions do not aﬀect magnitude encoding of the stimulus and only

timing. (Takahashi 2017)

Predictions

-   CE and PPN FT encode magnitude of expectation
-   PPN through VTA GABA cancels dopamine
-   A new circuit with VTA GABA as a more biologically plausible

expectation signal compared to VS (Keiﬂin 2015)

-   Early Reward cancellation of expectation happens within PPN
-   Learning of Time before Learning of Magnitude

9 1 0 2

,

y a M 4 2 - 2 2 – e c n a r F

,

e l l i e s r a M

,

9 1 0 2 e c n a r F o r u e N

Conclusion

Conclusion and Acknowledgements

-   Represents a model-free reinforcement learning system and learns the
    CS-US association in classical

conditioning.

-   Posits the brain could be solving the dimensions involved in
    classical conditioning separately in such a

distributed manner.

-   Such distributed processing could enable the same dimensions to be
    used to process other natural phenomena..

REFERENCES

Fiorillo, Christopher D., Philippe N. Tobler, and Wolfram Schultz.
“Discrete coding of reward probability and uncertainty by dopamine
neurons.” Science 299.5614 (2003): 1898-1902.

Keiflin, Ronald, and Patricia H. Janak. “Dopamine prediction errors in
reward learning and addiction: from theory to neural circuitry.” Neuron
88.2 (2015): 247-263.

[Johnson et al., 2016] Johnson, M., Hofmann, K., Hutton, T., and
Bignell, D. (2016). The malmo platform for artificial intelligence
experimentation. In IJCAI, pages 4246–4247.

Takahashi, Yuji K., et al. “Temporal specificity of reward prediction
errors signaled by putative dopamine neurons in rat VTA depends on
ventral striatum.” Neuron 91.1 (2016): 182-193.

Acknowledgements

We thank Bapi Raju in IIIT Hyderabad for constant guidance and feedback
in this work.


