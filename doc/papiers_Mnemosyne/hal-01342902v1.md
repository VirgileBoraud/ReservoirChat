Modeling Neuromodulation as a Framework to Integrate
Uncertainty in General Cognitive Architectures
Frédéric Alexandre, Maxime Carrere

To cite this version:

Frédéric Alexandre, Maxime Carrere. Modeling Neuromodulation as a Framework to Integrate Un-
certainty in General Cognitive Architectures. The Ninth Conference on Artificial General Intelligence,
Jul 2016, New-York, United States. ￿10.1007/978-3-319-41649-6\_33￿. ￿hal-01342902￿

HAL Id: hal-01342902

https://inria.hal.science/hal-01342902

Submitted on 7 Jul 2016

HAL is a multi-disciplinary open access
archive for the deposit and dissemination of sci-
entific research documents, whether they are pub-
lished or not. The documents may come from
teaching and research institutions in France or
abroad, or from public or private research centers.

L’archive ouverte pluridisciplinaire HAL, est
destinée au dépôt et à la diffusion de documents
scientifiques de niveau recherche, publiés ou non,
émanant des établissements d’enseignement et de
recherche français ou étrangers, des laboratoires
publics ou privés.

Modeling Neuromodulation as a Framework to
Integrate Uncertainty in General Cognitive
Architectures

Fr´ed´eric Alexandre1,2,3 and Maxime Carrere2,1,3

1Inria Bordeaux Sud-Ouest, 200 Avenue de la Vieille Tour, 33405 Talence, France
2LaBRI, Universit´e de Bordeaux, Bordeaux INP, CNRS, UMR 5800, Talence, France
3Institut des Maladies Neurod´eg´en´eratives, Universit´e de Bordeaux, CNRS, UMR
5293, Bordeaux, France
frederic.alexandre@inria.fr

Abstract. One of the most critical properties of a versatile intelligent
agent is its capacity to adapt autonomously to any change in the envi-
ronment without overly complexifying its cognitive architecture. In this
paper, we propose that understanding the role of neuromodulation in
the brain is of central interest for this purpose. More precisely, we pro-
pose that an accurate estimation of the nature of uncertainty present
in the environment is performed by speciﬁc brain regions and broad-
cast throughout the cerebral network by neuromodulators, resulting in
appropriate changes in cerebral functioning and learning modes. Bet-
ter understanding the principles of these mechanisms in the brain might
tremendously inspire the ﬁeld of Artiﬁcial General Intelligence. The origi-
nal contribution of this paper is to relate the four major neuromodulators
to four fundamental dimensions of uncertainty.

Keywords: Neuromodulation, bio-inspiration, decision making

1

Introduction

Computational Neuroscience has contributed many models of cognitive func-
tions [32], emphasizing their implementation in cerebral circuits or underlying
neuronal mechanisms, notably related to learning. Nevertheless, from this huge
amount of local models of cognitive functions, deﬁning a general cognitive archi-
tecture, really autonomous and versatile is not just a matter of integration and
a lot of work remains to be done to propose an eﬀective framework of the brain,
seen as a global cognitive model at this systemic level.

One of the more puzzling capacities of human cognition is our ability to adapt
to any new circumstances without explicit labeling that the circumstances have
changed and require a speciﬁc adaptation. This is particularly critical in our
dynamic and stochastic world: Does an unusual event correspond to noise and
can be neglected, or announce an important change and must be analyzed with

2

Fr´ed´eric Alexandre and Maxime Carrere

care ? Whereas we are rather good at answering such questions, they turn out
to be diﬃcult to integrate in modeling studies.

This is revealed in the stability-plasticity problem, studied in the domains of
Artiﬁcial Neural Networks [19], Computational Neuroscience [23] and Lifelong
Machine Learning [30]. In short, this problem originates from the fact that we
would like at the same time to have a learning system able to adapt to any
change (plastic) and preserving its past experience and not deleting it, in case any
exception occurs (stable). A related dilemma is that of exploitation-exploration,
also encountered in many domains [6]. On the one hand we might have the will
to exploit our current knowledge of the present situation but on the other hand
we might also want to explore other recipes and possibly ﬁnd more eﬃcient
solutions.

This problem has been hardly studied in Cognitive Science. To our knowl-
edge, [14] is one of the rare experimental studies to analyze human cerebral
activations for such conﬂicts during decision making. Cohen and colleagues [11]
underline that in reinforcement learning, formal solutions of optimal policies
have been proposed only in simpliﬁed cases of this problem, particularly corre-
sponding to discovering noisy but stationary processes with ﬁxed probabilities
of reward, but not in the case of unstationarity whereas changing environments
are probably more realistic as far as human cognition is concerned.

The case of unstationary environments has been tackled in [17] formalizing
them as a set of stationary environments and a certain probability to switch
from an environment to the other. Accordingly, the very interesting MMBRL
model has been proposed [17], as a multi-modules model, each specialized on
an environment, learned by Q-learning, and predicting the current state. This
model is very original because at each moment, all the modules participate in
the decision and learn, but the number of environments must be ﬁxed in advance
and cannot evolve.

In the framework of decision making, the distinction between stationary and
unstationary environments can be presented as follows: when you try to asso-
ciate an action to a stimulus to get a reward, you might be willing to apply an
associative rule that you have learned before, proposing, for a given stimulus, the
best action to trigger to get a reward. Now, suppose that suddenly the rule does
not work any longer (you get no reward): Which conclusion should you draw
from this failure ? On the one hand, you might decide that the reason is that
the environment is stationary but the rule is probabilistic (not always valid). In
this case, the decison to make is only to revise its rate of validity and wait for
the next trial (hopefully more rewarding). On the other hand, you might decide
that the environment is unstationary and that the rule has suddenly changed.
In this case, you will have to elaborate a new rule or re-use an old one. It is
explained in [33] that these two interpretations are intricately linked. For exam-
ple, if a rule is highly stochastic, you will be less prone to consider a failure as
corresponding to unstationarity. Conversely a failure with a highly probable rule
will be immediately considered as requiring a new rule.

Modeling Neuromodulation

3

The paper by Yu and Dayan [33] had a big impact in the computational
neuroscience community because it was also proposing that two neuromodulators
in the brain, Acetylcholine (ACh) and Noradrenaline (or Norepinephrine NE)
were respectively signaling these two kinds of uncertainty. This view is partly
consistent with the wider view by Doya [16], proposing more generally a role for
neuromodulators in reinforcement learning.

In the present paper, based on biological knowledge extracted from the lit-
erature and on models and experimental simulations including from our group,
we propose to gather information about the main neuromodulators and insert
them in a more systematic framework, particularly relating their role to the
adaptation of the cerebral circuitry and the underlying cognitive functions, to
the kind of uncertainty and to the part of the behavioral episode concerned with
experienced uncertainty. Our goal is to show that neuromodulation in the brain
is a very powerful way to drive it in diﬀerent functioning and learning modes,
at a lower cost regarding the complexiﬁcation of the cognitive architecture. We
will also explain that this is made possible because the nature of the informa-
tion carried by neuromodulators is well adapted to such global modulations. We
will ﬁnally propose that this information is not so heterogenous as classically
reported but rather corresponds to adapting the cerebral network to diﬀerent
kinds of uncertainty.

2 The role of neuromodulation in neural processing

Information ﬂows that feed a neural network can have diﬀerent kinds of eﬀects
on its functioning and on its learning. Based on biological inspiration, three main
ﬂows can be considered. Friston has contrasted driver and modulator ﬂows [18],
corresponding respectively to sensory feed-forward aﬀerent ﬂows and to feed-
back ﬂows carrying expectations from higher regions of the network. Whereas
the driver ﬂows are directly integrated in the functioning rules of the neuronal
units (classically in the weighted sum performed therein) and have a major
(driving) impact on the resulting activation states, the modulator ﬂows, as their
name tells, have a more limited impact. They cannot generate an activation by
themselves but can modulate an existing activation, by acting on some internal
parameters like the gain of the activation rules. Relying on sparser and less
focused connectivity, the feed-back ﬂows can have consequently an attentional
eﬀect that can modify the level of activity in some regions. In addition, refering
to the classical hebbian framework, it is also clear that both kinds of ﬂows have
distinct roles in the learning rules.

In natural and artiﬁcial networks, neuromodulation can also have a distinct
eﬀect on neural networks but is more rarely considered in modeling approaches.
The main types of neuromodulators are monoamines (dopamine, serotonin, nora-
drenaline) and acetylcholine. The underlying mechanism [8, 15] is that, for each
kind of neuromodulators, speciﬁc neurons gathered in a nucleus project to most
regions of the brain. Accordingly, they can widely modify the functioning and
learning modes of extended networks by modifying intrinsic properties of neu-

4

Fr´ed´eric Alexandre and Maxime Carrere

rons and synaptic weights. This is done thanks to specialized receptors types on
diﬀerent parts of neurons. This kind of information broadcasting is interesting in
a distributed architecture like the brain, where the anatomy of interconnections
is rather stable and cannot be systematic but where some important informa-
tion has to be known in many regions to modulate their functioning and learning
modes [15]. Basically, neuromodulatory neurons can have two kinds of activity,
a phasic activity corresponding to a reaction synchronized to a speciﬁc event,
typically the reception of a reward, and a tonic activity corresponding to a
sustained release of the neuromodulator. Whereas phasic activity of neuromod-
ulatory neurons can have dramatic roles in brain functioning (cf. for example
the phasic dopamine, often described as representing the reward prediction error
[29]), their tonic activity is more consistent with the modulatory role that we
discuss here and will be only considered in the remaining of the paper.

In order to introduce the inﬂuence of neuromodulators on the normal func-
tioning of the cerebral structures, let us ﬁrst rapidly deﬁne what we call a ’nor-
mal’ (or nominal) functioning of the cognitive architecture. In short, an impor-
tant part of our deliberative cognition consists in analyzing current exteroception
and interoception to detect respectively important information in the external
world (sensory cues) and in the internal world (needs) and to apply correspond-
ing sensorimotor rules to satisfy currents goals [1]. Here, sensorimotor rules must
be understood as relations encoded in the prefrontal cortex associating percep-
tion to the result obtained when a decision is executed, which can correspond to
trigger a motor action in the external world or to trigger more internal decisions.
In the ideal case, the world is perfectly known and the corresponding important
sensory cues and rules have already been extracted by learning. But the world
is not ideal but uncertain, as it can be detected by reward prediction errors that
monitor uncertainty.

An important characteristic of the neuromodulatory systems is that they are
triggered by the central nucleus of the amygdala, a limbic structure known to
be active when an error of (negative or positive) reward prediction is detected.
As explained below, other evaluations are made in other cerebral regions to
diﬀerentiate the kind of uncertainty and inhibit non relevant neuromodulation.

3 Four kinds of neuromodulators

Acetylcholine (ACh) is released by basal forebrain nuclei like the nucleus basilis.
Its role has been related to expected uncertainty [33], corresponding to the
stochastic case evoked above, when the rule has not changed but is not al-
ways valid. The observed eﬀects of ACh in the sensory cortex are attentional
and correspond to increase the signal-to-noise ratio [27], resulting in promoting
feed-forward sensory information against feed-back expectations, when the envi-
ronment is judged highly stochastic. As modeled in [10], another observed eﬀect
of ACh in conditioning experiments [9] is to promote learning about the context
and not about (noisy) sensory cues.

Modeling Neuromodulation

5

Noradrenaline (or Norepinephrine NE) is released by the Locus Coeruleus
and has been associated to unexpected uncertainty [33] when the rules have
changed, like it is the case during reversal [2]. Accordingly, it is also associated
to an increase of exploration, to extract new contingencies and elaborate new
rules [3]. NE has been reported to have the same kinds of attentional eﬀects
as ACh to favor exploration of new sensory cues [33] The identiﬁcation of the
circumstances as corresponding to unexpected uncertainty has been modeled
in [24] by a signal depending on the reward rate and on measures of response
conﬂict estimated from two windows encompassing long term and short term
history of activity.

Concerning the other two neuromodulators considered here, Serotonin (or
5HT) released from the dorsal raphe nucleus and Dopamine (DA) released from
the Ventral Tegmental Area in the midbrain, the situation is more controver-
sial. Old models like [13] propose a dual role for these neuromodulators, with
tonic DA for average appetitive reward prediction and 5HT for average aver-
sive reward (punishment) prediction. More recent papers acknowledge a role for
5HT in aversive processing [12] but mainly for behavioral inhibition and pas-
sive avoidance. Accordingly, low levels of 5HT are also associated to impulsivity.
This is consistent with the view expressed in [16] relating 5HT to time discount-
ing, corresponding to the degree of preference between immediate over delayed
rewards, higher levels of 5HT corresponding to greater patience. This kind of
impulsivity can also be linked to the concept of risk, another major theory for
the role of 5HT [5], where a greater variance in rewards might be prefered to
more stable payoﬀs, even if disavantageous on the total reward received. Deﬁning
a utility function as the trade-oﬀ bewteen the expected reward and its variance
is proposed as a model for the level of tonic 5HT [5]. Concerning tonic DA,
recent papers generally agree for a role to set the trade-oﬀ between exploration
and exploitation [21], which has of course to be confronted to the hypothetized
role of NE mentioned above. The evoked model of tonic DA implements the
corresponding mechanisms in the output functions of the basal ganglia, a mo-
tor region responsible for action selection, with a probability distribution that
can be modulated by tonic DA from ﬂat (to favor exploration) to sharp (for
exploitation) [21] shapes.

4 Towards a common framework of interpretation

We propose that setting the focus on the concept of action is a good way to make
clear the ambiguities evoked above. This idea has also been proposed by Y. Niv
[25] to better explain the diﬀerences between the pavlovian and instrumental
conditioning paradigms. Instead of evoking mainly rewards, actions should be
considered as representing the main diﬀerence between both paradigms: The new
dimension brought by instrumental conditioning (and related decision making)
over pavlovian conditioning (and related reward value) is that the animal or hu-
man agent is responsible for deciding to trigger an action and more precisely for
its frequency, yielding the rapidity or the vigor of this action, but also a certain

6

Fr´ed´eric Alexandre and Maxime Carrere

cost corresponding to the energy necessary to trigger the action. Consequently
the vigor of the response (and the corresponding energetic price to pay for it) is
a good indicator of the motivation to have a reward and, similarly, the cost of a
delay in this procedure is more meaningful.

We propose to exploit the same duality between the rate of the action and
the reward as a way to disambiguate the respective roles of the neuromodulators
considered here and propose accordingly to go deeper in the speciﬁcation of dif-
ferent kinds of uncertainty. We have evoked several times above that uncertainty
manifests itself by the acknowledgement that the sensorimotor rule which has
been applied doesn’t bring the expected reward. The next question would be to
know what is the cause of this problem: Is it because the selected sensory cues
is not longer valid (unexpected sensory uncertainty) or just because it is only
noisy (expected sensory uncertainty) ? Or is it because the action to associate
to the (still correct) sensory cue has changed (unexpected motor uncertainty)
or just because it is only noisy and not always working (expected motor un-
certainty). We propose here that these cases respectively trigger the release of
Noradrenaline, Acetylcholine, Dopamine and Serotonin.

This view does not modify the acknowledged role of ACh on sensory pro-
cessing and is also consistent with information given above for tonic DA and
NE roles. DA would be for exploration/exploitation trade-oﬀ for action selection
whereas NE would be concerned with the same trade-oﬀ for selective attention
of the sensory cues. This is consistent with the fact that DA eﬀect is mainly
reported in the basal ganglia and the frontal cortex (known to be responsible
for the organization of action) and NE eﬀect in the posterior parietal cortex [4].
The role of NE to modify sensory processing in the thalamus and the cortex is
also acknowledged [28]. Similarly, DA has a clear role for wanting in the motor
pole and not for liking on the sensory side [7]. This separation of roles between
NE and DA has also been proposed in modeling studies [21].

Similarly, relating the role of 5HT to the estimation of risk and variance of
reward can rather be seen as a matter of noise or probabilistic distribution of
eﬀects, consistently with an interpretation of expected uncertainty related to
actions. Even older interpretations of DA and 5HT as respectively related to
reward and punishment can be re-examined here: It can be understood that
when the risk is high, this should promote behavioral inhibition and passive
avoidance, often related to aversive processing [12], whereas exploration due to
high level of tonic DA might be misinterpreted as behavioral activation to get a
reward.

5 Discussion

In this paper we have mainly discussed about the role of neuromodulators in
cognition. Structurally, they have been presented [15] as a way to broadcast in-
formation in a sparsely connected network like it is the case for the brain. Func-
tionally, it can be also argued that this kind of information passing is preferable
for certain types of information, orthogonal to the information processed locally

Modeling Neuromodulation

7

and rapidly changing. This is the case with uncertainty, that we have proposed
to be the key topic of neuromodulation. More precisely, we have proposed a dou-
ble set of criteria to qualify uncertainty. In addition to uncertainty announcing
a radical change in the underlying rules or simply reporting stochasticity in the
environment, as already proposed in [33], we suggest, as the major contribution
of the present paper, that uncertainty can also refer to the sensory cues or to the
actions. In this view, each of the resulting four kinds of uncertainty would require
fundamentally diﬀerent modiﬁcations in the cerebral network and consequently
diﬀerent neuromodulators.

Altogether, the contribution of the present view to the framework of Artiﬁcial
General Intelligence can be synthesized as follows: Deliberative decision-making
is often summarized as learning and exploiting sensorimotor rules, associating
the sensory context to the best actions to trigger to get rewards and reach goals.
Such a framework is very classical in machine learning, particularly correspond-
ing to reinforcement learning [31], and in cognitive science [1]. It is attractive
because of its simplicity and because several computational frameworks have
been developed to express and learn such rules, using symbols [1], neurons [31]
and bayesian formalism [33] and proposing accordingly eﬀective means to imple-
ment artiﬁcial intelligent agents. This simplicity can also be seen as a weakness,
reducing cognition to simple sensorimotor rules. One argument is that adapt-
ing to the unknown and changing world is more complex than learning simple
contingencies between situations and optimal decision to make, particularly be-
cause the world is uncertain, including dynamic and stochastic aspects. A really
autonomous agent, in the perspective of Artiﬁcial General Intelligence, should
be able to detect by itself such uncertainties and adapt to them.

The ﬁrst lesson that we propose to be drawn by inspiration from neuro-
modulation in the brain is that, in order to take uncertainties into account in a
cognitive architecture, there is no need to give up the framework of sensorimotor
rules and look for a completly diﬀerent or radically more complex framework.
Alternatively, it can be suﬃcient to build additional modules to detect the kind
of experienced uncertainty and to modulate or increment the set of sensorimotor
rules. This is interesting because existing systems based on sensorimotor rules
could be simply extended (and not fundamentally modiﬁed) and remain eﬀective
in an uncertain world, corresponding to an important improvement in autonomy
for the corresponding agent.

The second element that we introduce here, corresponding to the most orig-
inal contribution of this paper, is about the diﬀerent kinds of uncertainties that
can be experienced. In addition to the distinction between expected and unex-
pected uncertainties already proposed in [33], we propose here that the fact that
uncertainty applies either to sensory or to motor dimensions is of prime impor-
tance. In our view, the resulting four kinds of uncertainty should be signaled by
the four major neuromodulators in the brain, allowing for distinct modulation
of the cerebral system and, accordingly, of the existing set of sensorimotor rules.
Although we have given above some hints from existing models about the kind

8

Fr´ed´eric Alexandre and Maxime Carrere

of modulation performed by each neuromodulator in the cerebral system, a more
precise speciﬁcation of these eﬀects should be the topic of future work.

Another key topic hardly evoked here, is about the identiﬁcation of the kind
of uncertainty experienced by the agent and consequently of the kind of neuro-
modulator to release. We have evoked models performing this identiﬁcation from
history of response conﬂicts and reward errors [24]. The way these elements are
estimated and determination of their cerebral encoding is the topic of ongoing
research in the team. It can be also mentioned that metalearning occurs at this
level to help determine as fast and accurately as possible this critical information,
particularly depending on the context in which it occurs [26].

This tentative explanation for the role of neuromodulators in cognition needs
to be conﬁrmed by a deeper anchoring in neuroscience. Additional clues might
be particularly searched in the nucleus accumbens, known to be the gateway
between sensory limbic and motor sides of cognition [22] and more generally in
the basal ganglia concerning the respective roles of DA and 5HT in the balance
between inhibition and excitation of behavior [20]. Finally, an important issue
to consider in forthcoming works in about interneuromodulatory interactions: It
has been shown that many interactions exist between neuromodulators resulting
in more intricate roles than presented here [15].

Modeling Neuromodulation

9

References

1. Anderson, J.R., Bothell, D., Byrne, M.D., Douglass, S., Lebiere, C., Qin, Y.: An
integrated theory of the mind. Psychol Rev 111(4), 1036–1060 (Oct 2004), http:
//dx.doi.org/10.1037/0033-295x.111.4.1036

2. Aston-Jones, G., Rajkowski, J., Kubiak, P.: Conditioned responses of monkey lo-
cus coeruleus neurons anticipate acquisition of discriminative behavior in a vigi-
lance task. Neuroscience 80(3), 697–715 (Jul 1997), http://dx.doi.org/10.1016/
s0306-4522(97)00060-2

3. Aston-Jones, G., Cohen, J.D.: An integrative theory of Locus Coeruleus-
Norepinephrine function: Adaptive Gain and Optimal Performance. Annual
Review of Neuroscience 28(1), 403–450 (2005), http://dx.doi.org/10.1146/
annurev.neuro.28.061604.135709

4. Aston-Jones, G., Rajkowski, J., Cohen, J.: Role of locus coeruleus in attention and
behavioral ﬂexibility. Biological Psychiatry 46(9), 1309–1320 (Nov 1999), http:
//dx.doi.org/10.1016/s0006-3223(99)00140-7

5. Balasubramani, P.P., Chakravarthy, V.S., Ravindran, B., Moustafa, A.A.: An ex-
tended reinforcement learning model of basal ganglia to understand the contribu-
tions of serotonin and dopamine in risk-based decision making, reward prediction,
and punishment learning. Frontiers in computational neuroscience 8 (2014)

6. Berger-Tal, O., Nathan, J., Meron, E., Saltz, D.: The exploration-exploitation

dilemma: A multidisciplinary framework. PLoS ONE 9(4), 1–8 (04 2014)

7. Berridge, K.C., Robinson, T.E.: What is the role of dopamine in reward: hedonic
impact, reward learning, or incentive salience? Brain Research Reviews 28(3), 309–
369 (Dec 1998), http://dx.doi.org/10.1016/s0165-0173(98)00019-8

8. Bouret, S., Sara, S.J.: Network reset: a simpliﬁed overarching theory of locus
coeruleus noradrenaline function. Trends in Neurosciences 28(11), 574–582 (2005),
http://dx.doi.org/10.1016/j.tins.2005.09.002

9. Calandreau, L., Triﬁlieﬀ, P., Mons, N., Costes, L., Marien, M., Marighetto, A.,
Micheau, J., Jaﬀard, R., Desmedt, A.: Extracellular hippocampal acetylcholine
level controls amygdala function and promotes adaptive conditioned emotional
response. The Journal of neuroscience : the oﬃcial journal of the Society for Neu-
roscience 26(52), 13556–13566 (Dec 2006)

10. Carrere, M., Alexandre, F.: A pavlovian model of the amygdala and its inﬂuence
within the medial temporal lobe. Frontiers in Systems Neuroscience 9(41) (2015)
11. Cohen, J.D., McClure, S.M., Yu, A.J.: Should I stay or should I go? How the human
brain manages the trade-oﬀ between exploitation and exploration. Philosophical
transactions of the Royal Society of London. Series B, Biological sciences 362(1481),
933–942 (May 2007), http://dx.doi.org/10.1098/rstb.2007.2098

12. Cools, R., Nakamura, K., Daw, N.D.: Serotonin and dopamine: unifying aﬀective,
activational, and decision functions. Neuropsychopharmacology 36(1), 98–113 (Jan
2011), http://dx.doi.org/10.1038/npp.2010.121

13. Daw, N.D., Kakade, S., Dayan, P.: Opponent interactions between serotonin and
dopamine. Neural Networks 15(4-6), 603–616 (Jun 2002), http://dx.doi.org/10.
1016/s0893-6080(02)00052-7

14. Daw, N.D., O’Doherty, J.P., Dayan, P., Seymour, B., Dolan, R.J.: Cortical sub-
strates for exploratory decisions in humans. Nature 441(7095), 876–879 (Jun 2006),
http://dx.doi.org/10.1038/nature04766

15. Dayan, P.: Twenty-Five Lessons from Computational Neuromodulation. Neuron
76(1), 240–256 (Oct 2012), http://dx.doi.org/10.1016/j.neuron.2012.09.027

10

Fr´ed´eric Alexandre and Maxime Carrere

16. Doya, K.: Metalearning and neuromodulation. Neural Networks 15(4-6), 495–506

(Jun 2002), http://dx.doi.org/10.1016/s0893-6080(02)00044-8

17. Doya, K., Samejima, K., Katagiri, K.i., Kawato, M.: Multiple Model-Based Re-
inforcement Learning. Neural Comp. 14(6), 1347–1369 (2002), http://neco.
mitpress.org/cgi/content/abstract/14/6/1347

18. Friston, K.: Functional integration and inference in the brain. Progress in neu-
robiology 68(2), 113–143 (Oct 2002), http://view.ncbi.nlm.nih.gov/pubmed/
12450490

19. Grossberg, S.: Adaptive Resonance Theory: How a brain learns to consciously
attend, learn, and recognize a changing world. Neural Networks 37, 1–47 (Jan
2013), http://dx.doi.org/10.1016/j.neunet.2012.09.017

20. Haber, S., Fudge, J., McFarland, N.: Striatonigrostriatal pathways in primates
form an ascending spiral from the shell to the dorsolateral striatum. The Journal
of Neuroscience 20(6), 2369–2382 (2000)

21. Humphries, M.D., Khamassi, M., Gurney, K.: Dopaminergic control of the
exploration-exploitation trade-oﬀ via the basal ganglia. Frontiers in Neuroscience
6(9) (2012)

22. Mannella, F., Gurney, K., Baldassarre, G.: The nucleus accumbens as a nexus
between values and goals in goal-directed behavior: a review and a new hypothesis.
Frontiers in behavioral neuroscience 7 (2013)

23. McClelland, J.L., McNaughton, B.L., O’Reilly, R.C.: Why there are complementary
learning systems in the hippocampus and neocortex: insights from the successes
and failures of connectionist models of learning and memory. Psychological review
102(3), 419–457 (1995)

24. McClure, S., Gilzenrat, M., Cohen, J.: An exploration-exploitation model based on
norepinepherine and dopamine activity. In: Weiss, Y., Sch¨olkopf, B., Platt, J. (eds.)
Advances in Neural Information Processing Systems 18, pp. 867–874. MIT Press
(2006), http://www.csbmb.princeton.edu/\~{}smcclure/pdf/MGC\\_NIPS.pdf
25. Niv, Y.: Cost, Beneﬁt, Tonic, Phasic: What Do Response Rates Tell Us about
Dopamine and Motivation. Annals of the New York Academy of Sciences 1104(1),
357–376 (May 2007), http://dx.doi.org/10.1196/annals.1390.018

26. Pauli, W.M., Hazy, T.E., O’Reilly, R.C.: Expectancy, Ambiguity, and Behavioral
Flexibility: Separable and Complementary Roles of the Orbital Frontal Cortex and
Amygdala in Processing Reward Expectancies. Journal of Cognitive Neuroscience
24(2), 351–366 (2011), http://dx.doi.org/10.1162/jocn\\_a\\_00155

27. Pauli, W.M., O’Reilly, R.C.: Attentional control of associative learning–a possible
role of the central cholinergic system. Brain Research 1202, 43–53 (Apr 2008)
28. Sara, S.J., Bouret, S.: Orienting and Reorienting: The Locus Coeruleus Mediates
Cognition through Arousal. Neuron 76(1), 130–141 (Oct 2012), http://dx.doi.
org/10.1016/j.neuron.2012.09.011

29. Schultz, W.: Predictive reward signal of dopamine neurons. Journal of Neurophys-

iology 80(1), 1–27 (1998), http://jn.physiology.org/content/80/1/1

30. Silver, D., Yang, Q., Li, L.: Lifelong machine learning systems: Beyond learning

algorithms. In: AAAI Spring Symposium Series (2013)

31. Sutton, R.S., Barto, A.G.: Reinforcement Learning: An introduction. MIT Press

(1998)

32. Trappenberg, T.P.: Fundamentals of Computational Neuroscience (2. ed.). Oxford

University Press (2009)

33. Yu, A.J., Dayan, P.: Uncertainty, Neuromodulation, and Attention. Neuron 46(4)

(2005)

