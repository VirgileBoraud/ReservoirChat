Section focused on machine learning methods for
high-level cognitive capabilities in robotics
Tetsunari Inamura, Hiroki Yokoyama, Emre Ugur, Xavier Hinaut, Michael

Beetze, Tadahiro Taniguchi

To cite this version:

Tetsunari Inamura, Hiroki Yokoyama, Emre Ugur, Xavier Hinaut, Michael Beetze, et al.. Section
focused on machine learning methods for high-level cognitive capabilities in robotics. Advanced
Robotics, 2019, 33 (11), pp.537-538. ￿10.1080/01691864.2019.1625183￿. ￿hal-02432787￿

HAL Id: hal-02432787

https://inria.hal.science/hal-02432787

Submitted on 8 Jan 2020

HAL is a multi-disciplinary open access
archive for the deposit and dissemination of sci-
entific research documents, whether they are pub-
lished or not. The documents may come from
teaching and research institutions in France or
abroad, or from public or private research centers.

L’archive ouverte pluridisciplinaire HAL, est
destinée au dépôt et à la diffusion de documents
scientifiques de niveau recherche, publiés ou non,
émanant des établissements d’enseignement et de
recherche français ou étrangers, des laboratoires
publics ou privés.

1

6

11

16

21

26

31

36

41

46

51

ADVANCED ROBOTICS
https://doi.org/10.1080/01691864.2019.1625183

PREFACE

Q1
Q2

Section focused on machine learning methods for high-level cognitive
capabilities in robotics

Integrating high- and low-levelognitive capabilities is
essential for developing robotic systems that can adap-
tively act in our daily environment in active collabora-
tion with humans. Recent advances in machine learn-
ing techniques, including deep learning and hierarchical
Bayesian modeling, are providing us with new possibili-
ties to integrate high- and low-level cognitive capabilities
in robotics. It became clear that such learning meth-
ods are indispensable to create robots that can effectively
address uncertainties while acting smart in the real world.
We had organized workshops, named ‘Machine
Learning Methods for High-Level Cognitive Capabilities
in Robotics,’ in IROS 2016 and 2017. In the workshops,
we solicited excellent papers related to the demand for
accelerating the synergies of low- and high-level cogni-
tive capabilities. It would enable us to develop methods
that address real-world problems in a more robust man-
ner. Hence, we aim to share knowledge regarding state-
of-the-art machine learning methods that contribute
to modeling sensory-motor and cognitive capabilities
in robotics and to exchange views among cutting-edge
robotics researchers with a special emphasis on adaptive
high-level cognition.

Through the workshops, researchers from cogni-
tive robotics, speech processing, artificial intelligence,
machine learning, computer vision, natural
language
processing, and so on were gathered to discuss the cur-
rent challenges in machine learning methods for high-
level cognitive capabilities in robotics. Typical keywords
discussed in the workshop were as follows: Multimodal
communication, learning motor skills and segmentation
of time-series information, concept formation, proba-
bilistic models, language acquisition, human–robot com-
munication and collaboration, deep learning, the theory
of mind and model of others, skill transfer, Bayesian
modeling, application in communicable service robots,
and so on. These keywords should be organized using
Figure 1, which was used in the workshop discussion in
2017.

Our daily environment is full of uncertainties, with
complex objects and challenging tasks. A robot is not only
required to deal with things appropriately in a physical

manner, but also perform logical and linguistic tasks in
the real world. Consider a scenario where a human user
tells a robot, ‘please move it into the blue box.’ In addition
to solving a manipulation task, the robot must move the
target object to a particular blue box and estimate what ‘it’
represents. In addition to solving the manipulation task,
the robot should estimate the meaning of ‘into,’ repre-
senting the relationship between ‘it’ and ‘the blue box’
in a real-world environment. When a robot attempts to
communicate and collaborate with human users in a real-
world environment, bridging high- and low-level cogni-
tive capabilities is critical. Low-level cognitive capabilities
include physical control, behavioral motion generation,
and sensory perception (node (i) in Figure 1). In contrast,
high-level cognitive capabilities include logical inference,
planning, and language (node (ii) in Figure 1).

Conventionally,

symbol-based and/or

rule-based
approaches have been employed to model high-level
cognitive capabilities in robotics. However, it has been
reported that such conventional methods could not cre-
ate a robot that could address inevitable uncertainties
in the physical environment and natural human–robot
communications. In other words, the difficulty of direct
transformation between nodes (i) and (ii) was the major
cause of the low performance of natural human–robot
communications. However, recent advances in machine
learning techniques have provided a bridge between node
(i) and the top node, and between node (ii) and the
top node, as shown in Figure 1. It has become increas-
ingly clear that machine learning methods are indis-
pensable for creating robots that address uncertainties.
In addition to machine learning techniques, big data
in human–robot interactions through a virtual reality
environment can be applied to accelerate the learning
process to connect the high- and low-level cognitive
capabilities.

We organized a new type of submission strategy at the
second workshop in 2017. Authors could choose from
two submission categories:

(A) Extended abstract (maximum 2 pages in length)
(B) Full paper (maximum 6 pages in length)

© 2019 Informa UK Limited, trading as Taylor & Francis Group and The Robotics Society of Japan

56

61

66

71

76

81

86

91

96

101

106

2

PREFACE

t
n
i
r
p
n

i

W
/
B

,
e
n

i
l

n
o
r
u
o
o
C

l

Figure 1. Bridge between low-level cognitive capabilities,
i.e.
node (i), and high-level cognitive capability, i.e. node (ii). Direct
transformation between nodes (i) and (ii) is diﬃcult using con-
ventional methods; however, recent machine learning techniques
provide high-level cognitive models, depicted as the top node
that solves the gap between (i) and (ii).

All the papers submitted to the workshop are reviewed
for consideration as both (A) and (B). The difference
between (A) and (B) is that the reviewer process for the
special issue in Advanced Robotics begins at the submis-
sion for the workshop. The review process for the journal
is independent of the review process for this workshop;
however, the authors can receive the review result from
the editors of Advanced Robotics within approximately
90 days (on average). This implies that the authors might
be able to state in the workshop that the paper will be pub-
lished in the journal later. Hence, the paper for category
(B) should not be published in the workshop proceed-
ings. We believe that this new strategy would result in a
good opportunity for and encourage young researchers to
join an international discussion community to improve
their ideas through discussions at the workshop and
review processes. Unfortunately, only one paper will be
accepted through category (B); however, we have received
many papers using this submission and review strategy.
We plan to adopt this strategy in future workshops.

The first paper, entitled ‘Navigation Behavior based
on Self-organized Spatial Representation in Hierarchical
Recurrent Neural Network’ by Wataru Noguchi et al. is
accepted using the above submission category (B). This
paper proposes a cognitive map representation based
on hierarchical recurrent neural networks. The model
acquires the relationship between a sequence of images
and navigation skill through navigation experiences. This

111

116

121

126

131

136

141

146

151

156

161

relationship is illustrated as a part of Figure 1, i.e. the bidi-
rectional arrow between node (i) (motion skill and image
sequence) and the top node (cognitive map representa-
tion).

The second paper is entitled ‘Bidirectional Estima-
tion Between Context and Motion in Motion Sequence
in Which Context Changes’ by Takashi Ogura et al.
This paper proposes an architecture for the bidirectional
recognition of motion patterns and background context.
Motion recognition affects context estimation, and con-
text estimation affects motion recognition. This relation-
ship is depicted as a part of Figure 1, i.e. between the top
node for context and node (i) for motion patterns.

Our research community organized a workshop
named ‘Language and Robotics’ in IROS in 2018. The
name of the workshop was changed; however, the posi-
tioning of the research interest was almost the same as
that of the workshops in 2017. The understanding of
the natural language by social service robots in daily life
environment requires high-level cognitive information
and numerous raw sensor information related to human
activity, which is depicted as node (i) in Figure 1. We
believe that the section focusing on this issue should
be the starting point for the development of cognitive
intelligent robot systems, including the use of language
ability.

166

171

176

181

186

191

Disclosure statement

No potential conflict of interest was reported by the authors. Q4

Tetsunari Inamura
National Institute of Informatics, Tokyo, Japan
inamura@nii.ac.jp

Hiroki Yokoyama
University of Tamagawa, Machida, Japan

Emre Ugur
Bogazici University, Istanbul, Turkey

196

201

Xavier Hinaut
INRIA, France

Q3

206

Michael Beetze
University of Bremen, Bremen, Germany

Tadahiro Taniguchi
Ritsumeikan University, Kyoto, Japan

211

216

