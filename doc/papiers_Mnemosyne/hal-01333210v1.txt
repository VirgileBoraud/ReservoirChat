Dynamics of reward based decision making a computational study Bhargav
Teja Nallapu, Nicolas P. Rougier

To cite this version:

Bhargav Teja Nallapu, Nicolas P. Rougier. Dynamics of reward based
decision making a computational study. ICANN 2016 , Sep 2016, Barcelona,
France. ￿hal-01333210￿

HAL Id: hal-01333210

https://inria.hal.science/hal-01333210

Submitted on 17 Jun 2016

HAL is a multi-disciplinary open access archive for the deposit and
dissemination of sci- entific research documents, whether they are pub-
lished or not. The documents may come from teaching and research
institutions in France or abroad, or from public or private research
centers.

L’archive ouverte pluridisciplinaire HAL, est destinée au dépôt et à la
diffusion de documents scientifiques de niveau recherche, publiés ou
non, émanant des établissements d’enseignement et de recherche français
ou étrangers, des laboratoires publics ou privés.

Dynamics of reward based decision making a computational study

Bhargav Teja Nallapu1,2 and Nicolas P. Rougier2,3,4

1 International Institute of Information Technology (I.I.I.T), Hyderabad
2 INRIA, Bordeaux Sud-Ouest, Talence, France 3 IMN, CNRS, University of
Bordeaux, UMR 5293, IMN, Bordeaux, France 4 University of Bordeaux, CNRS
UMR 5800, Labri, IPB, Talence, France

Abstract. We consider a biologically plausible model of the basal gan-
glia that is able to learn a probabilistic two armed bandit task using
reinforcement learning. This model is able to choose the best option and
to reach optimal performances after only a few trials. However, we show
in this study that the inﬂuence of exogenous factors such as stimuli
salience and/or timing seems to prevail over optimal decision making,
hence questioning the very deﬁnition of action-selection. What are the
ecological conditions for optimal action selection ?

Keywords: Decision making, neural dynamics, basal ganglia, optimal
behavior

1

Introduction

Basal ganglia are known to be involved in decision making and action
selection based on reinforcement learning and a number of models have
been designed to give account on such action selection [10, 2, 3]. We
have been studying a speciﬁc computational model of the basal ganglia
that has been introduced in [4] and replicated in [13]. This model has
been used to explain, to some extent, decision making in primates on a
two armed bandit task. One of the questions we attempt to address in
this study is to what extent the physical properties of the stimulus
such as the visual salience or other characteristics aﬀect the decision
and lead to a suboptimal choice. For example (and quite obviously), a
stimulus is very likely to be selected, if it is presented before the
other stimuli and this selection will be made irrespectively of the
potential reward associated with this stimulus. Moreover, there may be
other factors such as stimulus salience or population size that may also
disrupt the optimal performance. This led us to do a systematic study of
the inﬂuence of such exogenous factors to understand what are the
ecological conditions for optimal decision making.

2 Methods

2.1 Task

The task that has been used to demonstrate action selection in the model
is a probabilistic learning task that is described in [8]. Four target
shapes are

associated with diﬀerent reward probabilities (see ﬁgure 1). A trial is
a time period in which any two of the four possible shapes are presented
at two random positions (out of the four possible positions - up, right,
down and left). The model is allowed to settle for the ﬁrst 500ms of the
trial and then two random cues are presented. By the end of trial
period, a choice is made and the reward is given according to the reward
probability associated with the chosen shape. A trial is

Trial start

Cue presentation

Go signal

Decision

Reward

Trial stop

0.5s - 1.5s

1.0s - 1.5s

1.0s - 1.5s

Reward probabilities

P = 1.00

P = 0.33

P = 0.66

P = 0.00

Time

Fig. 1. The two armed bandit task as described in [8, 4].

considered to be successful if a decision is made by the model,
irrespective of the reward received. In a single independent trial, the
cognitive decision (shape of the cue) and motor decision (position of
the cue) are independent of each other. At any decision-making level of
the model, each of the four cue shapes and each of the four motor
movement directions is represented by one unit (neuron) each. Thus in a
given trial, when two cue shapes are presented at two diﬀerent
positions, two cognitive, two motor and two associative (in cortex and
striatum, see ﬁgure 2) neurons are activated. The task is run for a
session, a number of trials, while at the end of each trial, the model
learns the reward associated to its selection. (see Learning).

2.2 Model

In [5], authors demonstrated an action selection mechanism in the
cortico-basal ganglia loops based on a competition between the positive
feedback, direct pathway through the striatum and the negative feedback,
hyperdirect pathway through the subthalamic nucleus. In [4], authors
investigated further how multi- ple level action selection could be
performed by the basal ganglia, and the model has been extended in a
manner consistent with known anatomy and electro- physiology of the
basal ganglia in the monkey (see ﬁgure 2). This model allows a
bidirectional information ﬂow between loops such that during early
trials, a direction can be selected randomly, irrespective of the cue
positions. However, after repeated trials, the model is able to
consistently make the cognitive deci- sion before the motor decision in
each trial (see ﬁgure 3) and most frequently the motor decision, biased
by the cognitive decision, towards the position of the more rewarding
cue shape.

Learning . Learning has been derived from a simple actor-critic
algorithm [12] that shapes the gain between the cognitive cortex and the
cognitive striatum.

EXCITATORY

INHIBITORY

EXTERNAL

E C R U O S

T E G R A T

STN motor

STN cognitive

External current

External current

External current

Cortex motor

Cortex associative

Cortex cognitive

Striatum motor

Striatum associative

Striatum cognitive

GPi motor

GPi cognitive

Thalamus motor

Thalamus cognitive

STN motor

STN cognitive

Cortex motor

Cortex associative

Cortex cognitive

Striatum motor

Striatum associative

Striatum cognitive

GPi motor

GPi cognitive

Thalamus motor

Thalamus cognitive

Direct pathway

STN motor

STN cognitive

Cortex motor

Cortex associative

Cortex cognitive

Striatum motor

Striatum associative

Striatum cognitive

GPi motor

GPi cognitive

Thalamus motor

Thalamus cognitive

Hyperdirect pathway

Fig. 2. Architecture of the basal ganglia model which is organised
around three parallel loops: cognitive, associative and motor. Only the
direct and hyperdirect pathways have been modelled.

According to the amount of reward received at the end of each trial (0
or 1), the model learns to estimate the value of chosen stimulus and
then the cognitive pathway is biased in favor of the stimulus with the
highest value.

Neuronal dynamics . This model uses the same, simple neuronal rate model
as in [5] and [4] to focus on the network dynamics. Within each
structure, each neuron (in each channel of any loop) is modeled as a
single rate coded neuron with the equation:

dm dt = −m + Is + IExt − T decay time constant of the synaptic input τ ,
negative values of activation, m and threshold of the neuron T are set
to respective constant values as per the model in [4]. IExt is an
external input representing the sensory visual salience of the cue,
which is unchanged throughout the process of learning.

(1) 

τ

Fig. 3. Time course of a decision in the motor cortex (blue curves) and
cognitive cortex (red curve) before learning. At trial start (t=500ms),
there is a ﬁrst bifurcation between stimuli that are actually presented
and those who are not. The second bifurcation around t=750ms is the
actual decision of the model.

3 Results

In all the following cases, we consider 4 stimuli A, B, C, D
respectively associated with reward probability of 1.0, 0.66, 0.33 and
0.0. Learning is performed over 120 trials until the model reaches a
performance of 0.90, meaning it chooses the best stimulus 90% of the
time. We then stopped learning in the model and simulated a scenario
where one stimulus is presented ﬁrst and the other follows after a
certain delay. Another scenario involved presenting one stimulus with
more salience than the other. In both the scenarios, the intent was to
emphasize the advantage (earlier presentation or higher salience) to the
lesser rewarding stimulus and see if that leads the model to a
suboptimal decision. We presented the model with various scenarios
involving diﬀerent delays and saliences. (see ﬁgure 4).

Fig. 4. Two stimuli A & B can diﬀer in salience (∆V ) and/or in timing
(∆t). ∆V is expressed as the relative ratio between the less salient and
the most salient stimuli (∆V = (VA − VB)/VB. ∆t is expressed as the
delay separating the two stimuli onsets (∆t = tA − tB).

0.00.5(Trial start)1.01.52.02.5(Trial stop)3.0Time
(seconds)0102030405060Activity (Hz)Cognitive CortexMotor Cortex∆tOnset
AOnset BOﬀsetA & BStimulus AStimulus B∆VSaliencyTime3.1

Inﬂuence of delay

We ﬁrst tested the inﬂuence of a small delay (between 0ms and 60ms)
between the presentation of the two stimuli. The worst stimulus, that is
the one associ- ated with the lesser probability of reward, is presented
ﬁrst and after the delay, the second (better rewarding) stimulus is
presented. We have been testing sys- tematically all combinations of
stimuli (A/B, A/C, A/D, B/C, B/D, C/D) and averaged the mean performance
over 25 trials (see ﬁgure 5). As expected, the performance decreased
with the increase in delay and the crossing (i.e. perfor- mance is
random) happens around 35ms for all combinations but the last one (C/D)
that happens very early, around 20ms. This speciﬁc case can be explained
by the poor estimation of the value of C and D during learning because
those stimuli are almost never chosen (most of the time, they are
presented with a better stimuli).

Fig. 5. Performance of the model as a function of the delay between the
worst and the best stimuli. All combinations have been tested and mean
performance has been averaged over 25 trials.

3.2

Inﬂuence of salience

We tested the inﬂuence of salience by presenting simultaneously the two
stimuli but the worst stimulus, i.e, the one associated with a lesser
probability of reward,

01020304050600.00.51.0PerformanceStimuli A / DStimuli B / DStimuli C /
D01020304050600.00.51.0PerformanceStimuli A / CStimuli B /
C0102030405060Delay(ms) in presentation of higher rewarding
cue0.00.51.0PerformanceStimuli A / BChange in performance with delay in
presentationhas been made virtually stronger than the other. The model,
having learned the rewarding probabilities, is expected to select the
higher rewarding stimulus irre- spective of the salience. However, the
increased salience of the lesser rewarding stimulus aﬀects the model and
leads it to take a bad decision (see ﬁgure 6). As the salience of the
lesser rewarding stimulus increases, a consistent decrease in the
performance of model is observed. Interestingly, the threshold
percentage of salience diﬀerence after which the performance of the
model decreases, is a characteristic of the diﬀerence in the reward
probabilities of both the stimuli presented. Quite visibly (ﬁgure 6), it
takes higher salience diﬀerence for a lesser rewarding stimulus to be
chosen against the best rewarding one (in this case, A) whereas a lesser
increase in salience seems to be suﬃcient to compromise the decisions
involving lesser rewarding stimuli, like B.

In various neuropsychological studies on humans, like in [7] and [9], it
has been emphasized that the visual saliency of stimuli inﬂuences the
choices over the learned preferences and visual working memory.
Interestingly, in [7] where at an exposure time of 1500ms, which is
quite similar to that of the model discussed here, the inﬂuence of
visual saliency was particularly evident when there were no strong
preferences among the options. This observation is supported by the
early performance decline of the model discussed here, when presented
with two closely rewarding stimuli (Stimuli C/D in ﬁgure 6).

Fig. 6. Decrease in performance of the model when the lesser rewarding
stimulus is presented with stronger salience than the higher rewarding
stimulus.

051015202530350.00.51.0PerformanceStimuli A / DStimuli B / DStimuli C /
D051015202530350.00.51.0PerformanceStimuli A / CStimuli B /
C05101520253035 Relative difference in salience (%)
0.00.51.0PerformanceStimuli A / BChange in performance with relative
salience3.3 Joint inﬂuence of delay and salience

We further tested the model and studied the joint inﬂuence of delay and
salience by make the worst stimulus to be presented earlier and with a
stronger salience. As shown in ﬁgure 7, this dramatically degrades the
performance and the domain of optimal performance is even more
restricted compared to original results.

Fig. 7. Joint inﬂuence of delay and salience on the performance of the
model. The two eﬀects appears to linearly sum up and the domain of
optimal performance is even more restricted.

4 Conclusion

These early results tend to question the very notion of optimal action
selection as deﬁned in a number of theoretical works. The action may be
considered optimal provided the two options are presented simultaneously
and with an equivalent representation. In the reinforcement learning
paradigm, such consideration does not hold much relevance. However, from
a more behavioral and embodied per- spective, we think this is an
important dimension to consider because an animal is scarcely confronted
by a set of perfectly equivalent options (but their asso- ciated value).
One may come ﬁrst or one may just appear more ”obvious” (i.e. more
salient). In such a case, the inner dynamics of the model may lead to a
suboptimal choice as it is the case using the model from [4]. Although
we did not perform the study presented here on primates yet, the results
from the model as- sert the need for a closer look at the way we
perceive decision making paradigms.

0510152025303540Salience (%)0510152025303540Delay
(ms)0.1500.3000.4500.6000.7500.900Stimuli A / D0510152025303540Salience
(%)0510152025303540Delay (ms)0.1500.3000.4500.6000.7500.900Stimuli A /
C0510152025303540Salience (%)0510152025303540Delay
(ms)0.1500.3000.4500.6000.7500.900Stimuli A / B0510152025303540Salience
(%)0510152025303540Delay (ms)0.1500.3000.4500.6000.7500.900Stimuli C /
D0510152025303540Salience (%)0510152025303540Delay
(ms)0.1500.3000.4500.6000.7500.900Stimuli C / B0510152025303540Salience
(%)0510152025303540Delay (ms)0.1500.3000.4500.6000.750Stimuli C / DThe
question is to know to what extent some dedicated brain mechanisms are
able to cope with these problems. For example, concerning the time
delay, a stop signal, as it has been reported in [11], may represent a
potential mechanism to be able to solve the problem for small delays (<
200ms).

For the salience diﬀerence however, and to the best of our knowledge,
there is no such dedicated mechanism. In [6], a stimulus-reward
association study on macaque monkeys, spike recordings showed signiﬁcant
reward dependence in their responses to the visual cues. In [1], rewards
were shown to teach visual selective attention maximizing the positive
outcomes. However both the studies do not identify the underlying
mechanisms that caused the observations on the eﬀect of salience. This
study hence suggests that measuring experimentally per- formance using
diﬀerent salience levels could bring useful insights into decision
making.

References

1.  Chelazzi, L., Perlato, A., Santandrea, E., Della Libera, C.: Rewards
    teach visual

selective attention. Vision Research 85, 58–72 (2013)

2.  Gurney, K., Prescott, T.J., Redgrave, P.: A computational model of
    action selection in the basal ganglia. I. A new functional anatomy.
    Biological cybernetics 84(6), 401–410 (2001)

3.  Gurney, K., Prescott, T.J., Redgrave, P.: A computational model of
    action selection in the basal ganglia. II. Analysis and simulation
    of behaviour. Biological cybernetics 84(6), 411–423 (2001)

4.  Guthrie, M., Leblois, A., Garenne, A., Boraud, T.: Interaction
    between cognitive and motor cortico-basal ganglia loops during
    decision making: a computational study. Journal of neurophysiology
    109(12) (2013)

5.  Leblois, A., Boraud, T., Meissner, W., Bergman, H., Hansel, D.:
    Competition be- tween feedback loops underlies normal and
    pathological dynamics in the basal ganglia. Journal of Neurosciences
    26, 3567–3583 (2006)

6.  Mogami, T., Tanaka, K.: Reward association aﬀects neuronal responses
    to visual stimuli in macaque te and perirhinal cortices. The Journal
    of neuroscience 26(25), 6761–6770 (2006)

7.  Mormann, M.M., Navalpakkam, V., Koch, C., Rangel, A.: Relative
    visual saliency diﬀerences induce sizable bias in consumer choice.
    Journal of Consumer Psychology 22(1) (2012)

8.  Pasquereau, B., Nadjar, A., Arkadir, D., Bezard, E., Goillandeau,
    M., Bioulac, B., Gross, C.E., Boraud, T.: Shaping of Motor Responses
    by Incentive Values through the Basal Ganglia. Journal of
    Neuroscience 27(5) (2007)

9.  Pooresmaeili, A., Bach, D.R., Dolan, R.J.: The eﬀect of visual
    salience on memory-

based choices. Journal of neurophysiology 111(3), 481–487 (2014)

10. Redgrave, P., Prescott, T.J., Gurney, K.: The basal ganglia: a
    vertebrate solution

to the selection problem? Neuroscience 89(4), 1009–1023 (1999)

11. Schmidt, R., Leventhal, D.K., Mallet, N., Chen, F., Berke, J.D.:
    Canceling actions involves a race between basal ganglia pathways.
    Nature Neuroscience (2013)
12. Sutton, R., Barto, A.: Reinforcement Learning: An Introduction. MIT
    Press (1998)
13. Topalidou, M., Rougier, N.: [re] interaction between cognitive and
    motor cortico- basal ganglia loops during decision making: a
    computational study. ReScience 1(1)

(2015) 


