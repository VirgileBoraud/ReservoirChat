Interagir sans interprÃ©ter Apport dâ€™une IA pour
autonomiser un objet robotique
Yann Boniface, Nicolas P. Rougier

To cite this version:

Yann Boniface, Nicolas P. Rougier. Interagir sans interprÃ©ter Apport dâ€™une IA pour autonomiser un
objet robotique. WACAI 2020 - Workshop sur les Affects, Compagnons artificiels et Interactions, Jun
2020, Saint Pierre dâ€™OlÃ©ron, France. ï¿¿hal-02933478ï¿¿

HAL Id: hal-02933478

https://inria.hal.science/hal-02933478

Submitted on 8 Sep 2020

HAL is a multi-disciplinary open access
archive for the deposit and dissemination of sci-
entific research documents, whether they are pub-
lished or not. The documents may come from
teaching and research institutions in France or
abroad, or from public or private research centers.

Lâ€™archive ouverte pluridisciplinaire HAL, est
destinÃ©e au dÃ©pÃ´t et Ã  la diffusion de documents
scientifiques de niveau recherche, publiÃ©s ou non,
Ã©manant des Ã©tablissements dâ€™enseignement et de
recherche franÃ§ais ou Ã©trangers, des laboratoires
publics ou privÃ©s.

Interagir sans interprÃ©ter
Apport dâ€™une IA pour autonomiser un objet robotique

Yann Boniface
Yann.Boniface@loria.fr
UniversitÃ© de Lorraine, CNRS, LORIA, UMR 7503
Vandoeuvre-lÃ¨s-Nancy, F-54506, France

RÃ‰SUMÃ‰

Nous proposons de prÃ©senter dans cet article lâ€™utilisation dâ€™une
carte auto-organisatrice dans le processus de dÃ©cision de lâ€™action
dâ€™un objet robotisÃ© muni dâ€™un capteur, ici une camÃ©ra, interagis-
sant avec un ou plusieurs humains. Cette carte utilise le capteur
pour sâ€™adapter Ã  ses interlocuteur, ici les traits de leur visage, et
ainsi ajuster ses mouvements au comportement des humains, sans
toutefois les interprÃ©ter.

KEYWORDS

Interaction, Robot, Cartes auto-organisatrices, DSOM
ACM Reference Format:
Yann Boniface and Nicolas Rougier. 2020. Interagir sans interprÃ©ter Apport
dâ€™une IA pour autonomiser un objet robotique. In Proceedings of Confe-
rence (WACAI). ACM, New York, NY, USA, 5 pages. https://doi.org/10.1145/
nnnnnnn.nnnnnnn

1 INTRODUCTION

Le groupe Psyphine [7], groupe pluridisciplinaire nÃ© en 2011,
rassemble des chercheurs issus de lâ€™universitÃ© de Lorraine en in-
telligence artificielle, philosophie, psychologie, neurosciences, so-
ciolinguistique et anthropologie. Il sâ€™interroge sur les interactions
homme/robot et plus particuliÃ¨rement sur lâ€™attribution ou non dâ€™in-
tentions, dâ€™intelligence voire de conscience Ã  un objet robotisÃ© non
humanoÃ¯de. Pour mener ses expÃ©riences, il dispose dâ€™une lampe
(figure 1) robotisÃ©e et munie dâ€™une camÃ©ra, au dessus de son am-
poule, qui est utilisÃ©e en salle dâ€™expÃ©rience comme dans des lieux
publics (mÃ©diathÃ¨que, marchÃ© alimentaire, etc.). Ces expÃ©riences
mettent en relation cet objet avec un ou plusieurs humains pour
Ã©tudier leurs rÃ©actions et tenter de les interprÃ©ter [2]. Lâ€™une des
difficultÃ©s de nos expÃ©riences passÃ©es rÃ©side dans les biais dus aux
manipulateurs, qui contrÃ´lent tout ou partie du comportement de
la lampe. Nous avons donc dÃ©veloppÃ© un algorithme permettant
Ã  cette lampe dâ€™acquÃ©rir une forme dâ€™autonomie, câ€™est-Ã -dire de
bouger sans contrÃ´le ni intervention de notre part, tout en adaptant
son comportement Ã  celui de ses interlocuteurs. Câ€™est ce compor-
tement, qui conjugue suivi de visage et mouvements dÃ©clenchÃ©s
par les attitudes des sujets, que nous proposons de prÃ©senter. Ces

Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than ACM
must be honored. Abstracting with credit is permitted. To copy otherwise, or republish,
to post on servers or to redistribute to lists, requires prior specific permission and/or a
fee. Request permissions from permissions@acm.org.
WACAI, Juin 2020, Ãle dâ€™OlÃ©ron, France
Â© 2020 Association for Computing Machinery.
ACM ISBN 978-x-xxxx-xxxx-x/YY/MM. . .$15.00
https://doi.org/10.1145/nnnnnnn.nnnnnnn

Nicolas Rougier
Nicolas.Rougier@inria.fr
Inria Bordeaux Sud-Ouest
Talence, F-33405, France

attitudes sont apprises au cours de la passation et donc spÃ©cifiques
Ã  chaque expÃ©rience.

Figure 1: La lampe robotisÃ©e du groupe Psyphine. Elle dis-
pose de 5 moteurs (M1 Ã  M5) et dâ€™une camÃ©ra dans son abat-
jour.

2 VERS DES EXPÃ‰RIENCES AUTONOMES ET

QUALITATIVES

Pour Ã©tudier ces Ã©ventuelles attributions dâ€™intentions Ã  un objet
robotisÃ©, le groupe Psyphine a effectuÃ© diffÃ©rentes expÃ©riences au
cours des annÃ©es que nous dÃ©crivons succinctement dans cette
section, pour une description plus prÃ©cise voir [2].

Figure 2: Un exemple de dispositif dâ€™expÃ©rience en labora-
toire. Le sujet est placÃ© devant la lampe et est filmÃ© par une
camÃ©ra.

WACAI, Juin 2020, Ãle dâ€™OlÃ©ron, France

Yann Boniface and Nicolas Rougier

2.1 ExpÃ©riences dirigÃ©es et analyses

quantitatives

Passation. Pour nos premiÃ¨res expÃ©riences, nous avons crÃ©Ã© des
comportements pour notre lampe qui sont des sÃ©ries de commandes
motrices prÃ©dÃ©terminÃ©es et dÃ©crivant un mouvement complet de
lâ€™objet afin de tenter dâ€™exprimer une Ã©motion (surprise, joie, ennui,
peur, etc.). Nous placions, en laboratoire, un sujet devant la lampe
(voir figure 2) et un manipulateur, cachÃ© au sujet et qui voyait la
passation Ã  travers une camÃ©ra, dÃ©clenchait des comportements en
fonction des attitudes du sujet. Une passation alternative permettant
une comparaison des interactions proposait une sÃ©rie dÃ©terministe
de comportements sâ€™exÃ©cutant donc sans tenir compte des rÃ©actions
du sujet.

Ã‰valuation quantitative. Nous faisions ensuite remplir un ques-
tionnaire au sujet pour comparer les rÃ©sultats entre les expÃ©riences
avec sÃ©quence dÃ©terministe et celles avec un opÃ©rateur.

Bilan. Ces expÃ©riences se sont avÃ©rÃ©es non satisfaisantes pour

plusieurs raisons :

â€” Les comportements construits nâ€™Ã©taient pas interprÃ©tÃ©s de la
mÃªme faÃ§on par les diffÃ©rents sujets, et jamais, ou trÃ¨s rare-
ment, comme ils avaient Ã©tÃ© imaginÃ©s lors de leurs concep-
tions. Une expÃ©rience dÃ©diÃ©e Ã  cette question, Qualcom (voir
[3]) le confirme.

â€” Les expÃ©riences rÃ©alisÃ©es en laboratoire influent fortement
sur lâ€™attitude des sujets en raison du caractÃ¨re trop solennel
des lieux, de lâ€™aspect intimidant du dispositif (camÃ©ras, pro-
jecteurs, Ã©crans, etc.) et de la connaissance mÃªme quâ€™il sâ€™agit
dâ€™une expÃ©rience contrÃ´lÃ©e, mesurÃ©e et enregistrÃ©e.

â€” Les expÃ©riences sont fortement biaisÃ©es par le manipulateur,
son interprÃ©tation de lâ€™attitude du sujets, son interprÃ©tation
des sÃ©quences de mouvements et certains dÃ©rapages de jeux
avec le sujet (quâ€™il faudrait un jour Ã©tudier, mais ce nâ€™est pas
notre propos ici). Le tout variant en fonction des manipula-
teurs.

â€” Les questionnaires quantitatifs se sont avÃ©rÃ©s peu informatifs,
en raison principalement de lâ€™interprÃ©tation des question-
naires et de son vocabulaire par les sujets, des interprÃ©tations
des barÃ¨mes qualitatifs et de lâ€™orientation des rÃ©ponses in-
duites par la formulation des questionnaires.

2.2 ExpÃ©riences semi-dirigÃ©es et analyses

qualitatives

Pour corriger ces limitations, nous nous sommes orientÃ©s vers

une nouvelle sÃ©rie dâ€™expÃ©riences, appelÃ©e Decide.

Passation. Les passations se font, comme on peut le voir dans la
figure 3, dans des lieux publics (marchÃ© alimentaire, mÃ©diathÃ¨que,
etc.). Les sujets sont placÃ©s par deux (sâ€™ajoutent des participants
spontanÃ©s prÃ©sents sur le lieu et curieux de lâ€™expÃ©rience en cours)
devant lâ€™objet et doivent se mettre dâ€™accord sur une question qui
leur est posÃ©e au sujet de la lampe (sur son autonomie, son rÃ´le fonc-
tionnel par exemple). Lâ€™expÃ©rience sâ€™arrÃªte quand ils sâ€™accordent.
Le comportement de la lampe est contrÃ´lÃ© par un opÃ©rateur qui
dispose de diffÃ©rentes fonctionnalitÃ©s (voir figure 4). Pour permettre
une forme dâ€™autonomie de la lampe, et sâ€™inspirant du projet Pinokio

Figure 3: Les expÃ©riences en milieu ouvert (marchÃ© alimen-
taire) consistaient Ã  demander Ã  deux personnes de discuter
en prÃ©sence de la lampe afin de dÃ©terminer si celle-ci est au-
tonome ou non, sachant que cette derniÃ¨re est contrÃ´lÃ©e Ã 
distance par un opÃ©rateur cachÃ©.

Figure 4: Lâ€™interface de contrÃ´le de lâ€™expÃ©rience telle que
vue par lâ€™opÃ©rateur, Ã  gauche lâ€™interface de contrÃ´le de la
lampe. Il est possible de la manipuler en mode manuel (au
joystick), dâ€™utiliser la fonctionnalitÃ© de suivi de visage ou de
dÃ©clencher, par les boutons de couleur, ce que nous appelons
un comportement (joie, peur, ennui, etc.), câ€™est-Ã -dire une sÃ©-
rie de mouvements prÃ©-construits. A noter que la seule en-
trÃ©e vidÃ©o est celle de la camÃ©ra de la lampe et il nâ€™y a donc
pas de vue globale pour lâ€™opÃ©rateur.

[1] nous lâ€™avons dotÃ©e dâ€™un comportement de suivi de visages. Il
sâ€™agit de dÃ©tecter et dâ€™isoler un visage dans le champs visuel de
sa camÃ©ra (situÃ©e dans lâ€™abat-jour) et dâ€™utiliser ses moteurs afin
de centrer ce visage dans lâ€™image. Ce comportement est toutefois
insuffisant, notre objet ne bouge pas en lâ€™absence de visage et le
perd frÃ©quemment en cours dâ€™expÃ©rience. Pour retrouver les sujets
et relancer le suivi, lâ€™opÃ©rateur, qui ne voit lâ€™expÃ©rience que par la
camÃ©ra de lâ€™objet, dispose des comportement dÃ©finis prÃ©cÃ©demment
et dâ€™un contrÃ´le au joystick.

Ã‰valuation qualitative. Lâ€™Ã©valuation de nos passations se fait en

deux Ã©tapes.

â€” Les passations sont filmÃ©es et sont ensuite analysÃ©es par nos
soins. Nous cherchons Ã  comprendre les perceptions et inter-
rogations des participants par lâ€™analyse de leur dialogue.

Interagir sans interprÃ©ter

WACAI, Juin 2020, Ãle dâ€™OlÃ©ron, France

â€” Les sujets sont interrogÃ©s par lâ€™un dâ€™entre nous pour dÃ©crire
leur sensations et interprÃ©tations. Ces interviews sont enre-
gistrÃ©es et ensuite analysÃ©es par nos soins.

de la donnÃ©e. Ces classes sont apprises Ã  lâ€™aide des donnÃ©es, per-
mettant ainsi une classification propre Ã  chaque jeu de donnÃ©es, ou
Ã  chaque expÃ©rience produisant des donnÃ©es.

Bilan. Ces sÃ©ries dâ€™expÃ©riences se sont avÃ©rÃ©es plus satisfaisantes,
notamment grÃ¢ce aux lieux ouverts, le dialogue entre les partici-
pants et les interviews mais comportent encore des biais, les princi-
paux Ã©tant :

â€” Pour lâ€™analyse des expÃ©riences, les sujets sont encore trop
influencÃ©s par la personne effectuant lâ€™entretien. Nous nous
sommes tournÃ©s ensuite vers des mÃ©thodes dâ€™autoconfron-
tation, mÃ©thode qui fait lâ€™objet dâ€™une seconde soumission Ã 
Wacai.

â€” Le comportement de suivi de visage, trop simple, est rapide-

ment identifiÃ© par les sujets.

â€” Les comportements de â€™recentragesâ€™, au joystick ou Ã  lâ€™aide
des comportements construits, qui permettent de relancer le
suivi de visage, restent trop dÃ©pendant de lâ€™opÃ©rateur, avec
tous les biais Ã©noncÃ©s plus haut.

2.3 Limitations

Au delÃ  du suivi de visage, qui autonomise en partie notre lampe
au cours des passations, nous restons donc trÃ¨s dÃ©pendants de
lâ€™opÃ©rateur et des biais induits : interprÃ©tations des comportements
construits de la lampe, interprÃ©tation des attitudes des sujets, sou-
hait de crÃ©er sa propre interaction avec les sujets, de rÃ©pondre Ã 
certaines de leur -supposÃ©es- demandes dâ€™interaction, etc. Nous
souhaitons donc enrichir notre suivi de visage en Ã©vitant Ã  la fois
des mouvements stÃ©rÃ©otypÃ©s ou systÃ©matiques et des interventions
humaines (commandes manuelles) trop sujettes Ã  biais. Nous sou-
haitons toutefois que les mouvements de la lampe soient spÃ©cifiques
aux sujets et cohÃ©rents par rapport Ã  leurs attitudes, par exemple
une attitude identique du sujet devra dÃ©clencher une mÃªme rÃ©action,
un mÃªme mouvement, de la lampe.

3 LES SOM, CLASSIFIEURS NEURONAUX

Pour obtenir cette adaptation dÃ©pendante du sujet, nous utilisons
lâ€™algorithme DSOM [8], variation des classiques classifieurs cartes
auto-organisatrices (SOM) [6], permettant dâ€™apprendre des donnÃ©es
dynamiques, câ€™est-Ã -dire changeantes au cours du temps. Ici ce
sont les sujets, et leurs attitudes, qui changent au cours du temps
(au cours dâ€™une expÃ©rience ou dâ€™une expÃ©rience Ã  une autre) et le
comportement de la lampe doit sâ€™y adapter. Plus exactement, ce
sont les traits des visages, les coordonnÃ©es des points des yeux,
bouches, etc. dans le visage des sujets qui sont les donnÃ©es prises
en compte pour notre classification.

3.1 Carte auto-organisatrice

Lâ€™algorithme des cartes auto-organisatrices est un algorithme de
classification des donnÃ©es permettant de les reprÃ©senter avec une
cohÃ©rence topologique : deux classes proches dans lâ€™espace de re-
prÃ©sentation de la carte reprÃ©senteront des donnÃ©es proches. Cette
classification permet de reprÃ©senter les donnÃ©es dans un espace
fini (la taille de la carte), chacune des donnÃ©es (un vecteur) Ã©tant
reprÃ©sentÃ©e par une classe, celle qui a le vecteur le plus proche (au
sens dâ€™une mesure numÃ©rique, la distance euclidienne par exemple)

3.2 Carte auto-organisatrice dynamique

Nous avons modifiÃ© lâ€™algorithme original de SOM afin de rendre
sa rÃ¨gle dâ€™apprentissage et son voisinage indÃ©pendants du temps. Il
en rÃ©sulte un couplage Ã©troit entre lâ€™environnement et le modÃ¨le
qui assure Ã  la fois stabilitÃ© et plasticitÃ©. Plus prÃ©cisÃ©ment, La carte
DSOM est une carte neurale dotÃ©e dâ€™une structure (un hypercube
ou un rÃ©seau hexagonal) oÃ¹ chaque neurone ğ‘– se voit attribuer une
position fixe pq avec ğ‘ la dimension de la carte (gÃ©nÃ©ralement 1
ou 2). Le processus dâ€™apprentissage est un processus itÃ©ratif dans
lequel les vecteurs ğ‘  âˆˆ Î© sont prÃ©sentÃ©s sÃ©quentiellement sur la
carte par rapport Ã  la fonction de densitÃ© de probabilitÃ© ğ‘“ . Pour
chaque vecteur ğ‘£ prÃ©sentÃ©, un gagnant ğ‘  âˆˆ ğ‘ est dÃ©terminÃ© selon
lâ€™Ã©quation. Tous les codes wi du codebook ğ‘Š sont alors dÃ©calÃ©s
vers ğ‘£ selon lâ€™Ã©quation :

Î”wğ‘– = ğœ€ âˆ¥v âˆ’ wğ‘– âˆ¥Î© â„ğœ‚ (ğ‘–, ğ‘ , v)(v âˆ’ wğ‘– )
(1)
avec ğœ€ le pas dâ€™apprentissage (constant), et â„ğœ‚ (ğ‘–, ğ‘ , v)(v âˆ’ wğ‘– ) la
fonction de voisinage de la forme :

â„ğœ‚ (ğ‘–, ğ‘ , v)(v âˆ’ wğ‘– ) = exp âˆ’

1
ğœ‚2

âˆ¥pğ‘– âˆ’ pğ‘  âˆ¥2
âˆ¥v âˆ’ wğ‘  âˆ¥2
Î©

(2)

avec ğœ‚ le paramÃ¨tre dâ€™Ã©lasticitÃ©. A noter que lorsque v = wğ‘  , on a
â„ğœ‚ (ğ‘–, ğ‘ , v) = 0.

Lâ€™algorithme DSOM est donc essentiellement une variante de
lâ€™algorithme SOM dont la dÃ©pendance temporelle a Ã©tÃ© supprimÃ©e.
La fonction dâ€™apprentissage rÃ©gulier et la fonction de voisinage
ont Ã©tÃ© respectivement remplacÃ©es par les Ã©quations (1) et (2) qui
reflÃ¨tent deux idÃ©es principales :

â€” Si un neurone est suffisamment proche des donnÃ©es, il nâ€™est
pas nÃ©cessaire que les autres apprennent quoi que ce soit : le
gagnant peut reprÃ©senter les donnÃ©es.

â€” Sâ€™il nâ€™y a pas de neurone suffisamment proche des donnÃ©es,
tout neurone apprend les donnÃ©es en fonction de sa propre
distance par rapport aux donnÃ©es.

Cela entraÃ®ne plusieurs consÃ©quences sur la notion de voisinage
qui est dÃ©sormais dynamique et conduit Ã  une auto-organisation
qualitativement diffÃ©rente qui peut Ãªtre contrÃ´lÃ©e Ã  lâ€™aide dâ€™un
paramÃ¨tre dâ€™Ã©lasticitÃ© libre ğœ‚.

4 CLASSIFIER POUR INTERAGIR

Nous dÃ©crivons dans cette section lâ€™utilisation de notre classifieur
dans le cadre de nos expÃ©rience avec la lampe du groupe Psyphine.

4.1 Extraire dâ€™une image les traits du visage

Comme nous pouvons le voir sur la figure 5, Ã  partir de lâ€™image
reÃ§ue de la camÃ©ra, nous isolons un visage (le carrÃ© rouge) Ã  lâ€™aide
de la librairie opencv ([4]). Nous extrayons ensuite de chaque image
un vecteur de points (les points bleus dans le carrÃ© gris en haut
Ã  gauche de la figure) reprÃ©sentant certains traits 1 de ce visage Ã 

1. Ici sourcils et lÃ¨vres, mais tous les points visibles dans le carrÃ© rouge sont

disponibles.

WACAI, Juin 2020, Ãle dâ€™OlÃ©ron, France

Yann Boniface and Nicolas Rougier

sur dâ€™autres, et mÃªme Ã  des changements de personnes, lâ€™Ã©lasti-
citÃ© de DSOM permet lâ€™apprentissage en temps rÃ©el de nouveaux
prototypes.

Figure 5: La localisation des visages et la capture des traits
principaux Ã  partir de lâ€™image de la camÃ©ra de la lampe est
effectuÃ© en temps rÃ©el via la librairie Open-CV. Seules les
informations relatives aux sourcils et Ã  la bouche sont ici
utilisÃ©es par la carte auto-organisatrice.

lâ€™aide de lâ€™algorithme de [5]. Câ€™est ce vecteur de points qui constitue
la donnÃ©e numÃ©rique apprise par notre classifieur.

4.2 Classifier les attitudes des sujets

La figure 6 montre les vecteurs qui sont appris en temps rÃ©el
par notre le classifieur DSOM. Pour dÃ©crire rapidement lâ€™apprentis-
sage dâ€™une carte, il faut noter quâ€™une classe est considÃ©rÃ©e comme
gagnante, pour un visage, quand les points extraits sont les plus
proches des points appris par cette classe. Cette classe se modifie
alors en fonction de cette nouvelle donnÃ©e pour sâ€™en approcher,
et entraÃ®ne ses voisins (dans la topologie de la carte) pour quâ€™ils
sâ€™en approchent aussi, mais de moins en moins en fonction de la
distance dans la carte.

Chaque image capturÃ©e par la camÃ©ra est traitÃ©e par lâ€™algorithme
dâ€™extraction de traits et apporte ainsi un nouvel exemple pour
lâ€™apprentissage de la carte, câ€™est-Ã -dire pour la spÃ©cialisation de
la classe gagnante et de ses voisines. Chaque classe reprÃ©sente
ainsi une posture caractÃ©ristique, une attitude, (reprÃ©sentÃ©e par
les points) de visage, et nous disposons ainsi en temps rÃ©el dâ€™une
information sur les postures de visage les plus frÃ©quentes du ou des
sujets placÃ©s dans le champs de la camÃ©ra.

Cette classification est unique et totalement dÃ©pendante des traits
et des postures du sujet au cours de lâ€™expÃ©rience, une personne trÃ¨s
expressive aura une distance entre les classes la reprÃ©sentant plus
importante quâ€™une autre moins expressive, nÃ©anmoins, le nombre
de classes cartographiant ses expressions sera le mÃªme. Cette clas-
sification se fait ainsi de maniÃ¨re totalement autonome et sans
aucune interprÃ©tation dâ€™Ã©ventuelles Ã©motions portÃ©es par ces pos-
tures. Notre question est dâ€™isoler des postures de visage, pas dâ€™en
comprendre la signification.

Pour finir, DSOM permettant lâ€™apprentissage de donnÃ©es dyna-
miques, cette classification sâ€™adaptera Ã  plusieurs sujets, câ€™est-Ã -dire
que certaines classes se spÃ©cialiseront sur lâ€™un des sujets, les autres

Figure 6: Une carte DSOM avec 64 (8Ã—8) neurones. Chaque
neurone est reprÃ©sentÃ© par son prototype (points bleus) dans
lâ€™espace des images. Lâ€™auto-organisation permet de sâ€™assurer
que deux neurones proches (au sens de la topologie de la
carte) possÃ¨dent des prototypes proches (au sens de la dis-
tance entre prototypes). Dans lâ€™exemple montrÃ© ci-dessus,
les neurones dans les coins supÃ©rieur gauche et infÃ©rieur
droit sont opposÃ©s, mais il existe un chemin continu dans
la carte permettant de passer de lâ€™un Ã  lâ€™autre). Le paramÃ¨tre
dâ€™Ã©lasticitÃ© permet de contrÃ´ler la similitude entre les proto-
types de deux neurones voisins.

4.3 Associer des comportements aux classes

Figure 7: Distribution des comportements sur les classes.
Nous pouvons voir au dessus la rÃ©partition des classes ga-
gnantes, câ€™est-Ã -dire le nombre dâ€™images pour lesquelles
chaque classe fut la plus proche.

Interagir sans interprÃ©ter

WACAI, Juin 2020, Ãle dâ€™OlÃ©ron, France

Au cours de la mise en place de nos diffÃ©rentes expÃ©riences,
nous nous sommes construit un catalogue assez variÃ© de comporte-
ments de la lampe, câ€™est-Ã -dire de mouvements prÃ©programmÃ©s [3],
certains ayant Ã©tÃ© conÃ§us pour -tenter dâ€™- exprimer une Ã©motion
(peur, etc.) dâ€™autres non (vers la droite, vers le haut, etc.). Comme le
montre la figure 7, en utilisant toujours notre classificateur DSOM,
nous distribuons nos comportements sur une carte de mÃªme taille
que celle des traits. Ce sont les vecteurs de commandes motrices
qui sont cette fois appris, de la mÃªme maniÃ¨re que prÃ©cÃ©demment
les points extraits des images de la camÃ©ra. Les deux cartes Ã©tant
de la mÃªme taille, nous pouvons lier un comportement de la lampe
Ã  chaque expression des sujets apprise. Ainsi la classe gagnante
(en rouge sur la figure 6) sera associÃ©e au comportement PEUR.
Cette distribution des comportements de la lampe se fait au dÃ©but
de lâ€™expÃ©rience et reste donc, dans lâ€™Ã©tat actuel de lâ€™algorithme, la
mÃªme tout au long de lâ€™expÃ©rience. Elle peut aussi Ãªtre gardÃ©e dâ€™une
passation Ã  une autre.

5 UNE EXPÃ‰RIENCE AUTONOME

Avec ces cartographies, nous disposons maintenant dâ€™un algo-
rithme permettant de dÃ©clencher un mouvement de notre objet ro-
botisÃ© en fonction des attitudes du ou des sujets ayant Ã©tÃ© prÃ©sents
dans le champs de sa camÃ©ra. Il reste Ã  construire une expÃ©rience
Ã  lâ€™aide des fonctions dont dispose notre lampe, une expÃ©rience
qui, en plus dâ€™Ãªtre autonome, est spÃ©cifique aux sujets prÃ©sents et Ã 
leurs attitudes au cours de lâ€™expÃ©rience. Lâ€™expÃ©rience sâ€™articule donc
principalement sur le suivi de visage, puis, quand ce suivi Ã©choue,
sur lâ€™apprentissage dÃ©crit ci-dessus. Le suivi de visage peut Ã©chouer
pour de nombreuses raisons, la lampe ne peut physiquement plus
suivre le mouvement (les articulations sont aux limites de leurs
possibilitÃ©s), le sujet suivi a Ã©tÃ© perdu (dÃ©placement trop rapide
par exemple), le visage est masquÃ©, etc. Lâ€™expÃ©rience proposÃ©e est
dÃ©crite par lâ€™algorithme suivant :

Apprendre la carte des comportements (DSOM)
RÃ‰PÃ‰TER

Capturer une image depuis la camÃ©ra de la lampe
SI un visage peut Ãªtre extrait de l'image

. Apprendre ce nouveau visage dans la carte des expressions

Ã  l'aide de DSOM

. IncrÃ©menter le nombre de victoires de la classe gagnante
. TI = 0;
. DÃ©placer la lampe pour centrer le visage dans

l'image de la camÃ©ra

SINON

SI Le temps d'impatience (TI) est dÃ©passÃ©

.DÃ©clencher le comportement associÃ© Ã  la classe
des expressions qui a le plus gagnÃ©.
.TI=0
.Mise Ã  zÃ©ro des victoires de la carte des expressions

A noter que les paramÃ¨tres de cet algorithme sont :
â€” La taille des cartes auto-organisatrices.
â€” Le nombre de comportements de la lampe.

Il nâ€™est pas souhaitable dâ€™avoir plus de comportements que de classes,
il est mÃªme conseillÃ© dâ€™en avoir beaucoup moins, pour distribuer un
mÃªme comportement sur plusieurs classes.

â€” Les temps dâ€™impatience.

Temps au terme duquel une action autre que le suivi de visage sera
dÃ©clenchÃ©e. Il est gÃ©nÃ©ralement de 1500 milli-secondes.

â€” Les traits pris en compte.

Nous disposons de diffÃ©rentes catÃ©gories de traits (nez, sourcils, lÃ¨vres,
yeux, chacun pouvant Ãªtre dÃ©composÃ© : droite/gauche, haut/bas). Il
nâ€™est pas toujours utile de considÃ©rer tous les points dans lâ€™apprentis-
sage, dâ€™autant que certains traits (lÃ¨vres par exemple, par leur nombre
de points, Ã©crasent les autres). Dans lâ€™expÃ©rience qui illustre cet article
nous nâ€™utilisons que les sourcils et les lÃ¨vres.

6 DISCUSSION

Le modÃ¨le prÃ©sentÃ© dans cet article permet de rendre le comportement
de la lampe autonome et interactif. Autonome en ce quâ€™il ne requiert plus
lâ€™intervention dâ€™un opÃ©rateur et interactif en ce quâ€™il rÃ©agit aux informa-
tions captÃ©es par sa camÃ©ra (les visages en particulier) sans pour autant
chercher Ã  interprÃ©ter ces informations. Câ€™est lÃ  une propriÃ©tÃ© importante
puisquâ€™elle garantit lâ€™absence de biais de la part de lâ€™opÃ©rateur et autorisera
Ã  terme des interactions plus neutres, du moins du cÃ´tÃ© de la lampe. Câ€™est
dans ce contexte que nous travaillons actuellement sur une version plus
robuste permettant de laisser notre objet dans un lieu ouvert et de le laisser
interagir au grÃ¨s du passage alÃ©atoire des personnes et des visages entrant
dans le champ de sa camÃ©ra. Cela requiert cependant de rÃ©gler quelques
paramÃ¨tres comme le temps dâ€™impatience (pas de visage dÃ©tectÃ©) au-delÃ 
duquel la lampe dÃ©clenche des comportements moteurs qui sont alors sus-
ceptibles dâ€™attirer des personnes Ã  elle. Cependant, toute la difficultÃ© de
ces expÃ©riences rÃ©side dans la nature du milieu, Ã  la fois ouvert et non
contrÃ´lÃ©. Comme nous lâ€™avons expliquÃ© auparavant, la nature solennelle
des expÃ©riences en laboratoire semble perturber lâ€™interaction entre les parti-
cipants et la lampe, ce quâ€™il ne semble pas Ãªtre le cas lorsque les sujets sont
libres dâ€™interagir (ou non) avec la lampe. Nous devrons donc Ã  terme dÃ©-
finir une mÃ©thode de mesure objective afin de rendre compte de lâ€™expÃ©rience.

Note aux relecteurs : Cet article prÃ©sente une solution pour construire
des expÃ©riences avec un objet totalement autonome au cours de la passation.
Nous hÃ©sitons Ã  proposer cette expÃ©rience comme dÃ©monstration pour cause
de fragilitÃ© de la lampe. Mais sâ€™il vous semble plus pertinent de la mettre
dans cette rubrique... Par ailleurs, cet article a Ã©tÃ© rÃ©digÃ© quelque peu dans
lâ€™urgence, ses auteurs Ã©tant fort impliquÃ©s dans le mouvement dâ€™opposition
aux contre rÃ©formes en cours pour les universitÃ©s et les retraites, il pourra
donc Ãªtre largement remaniÃ© pour une version dÃ©finitive le cas Ã©chÃ©ant.

RÃ‰FÃ‰RENCES
[1] Ben-Dror Adam and Zhou Shanshan. 2012. Projet Pinokio. http://www.ben-

dror.com/pinokio.

[2] Virginie AndrÃ© and Yann Boniface. 2018. Quelques considÃ©rations interactionnelles
autour dâ€™une expÃ©rience robotique. In WACAI 2018 - Workshop sur les â€Affects,
Compagnons Artificiels et Interactionsâ€. Ile de Porquerolles, France. https://hal.
archives-ouvertes.fr/hal-01862725

[3] Joffrey Becker, Virginie Andre, and Alain Dutech. 2019. QUALCOM : une ex-
pÃ©rience sur la qualification des comportements dâ€™une lampe robotique. Tech-
niques & culture : Revue semestrielle dâ€™anthropologie des techniques (2019). https:
//hal.archives-ouvertes.fr/hal-02075467

[4] Itseez. 2015. Open Source Computer Vision Library. https://github.com/itseez/

opencv.

[5] Vahid Kazemi and Josephine Sullivan. 2014. One Millisecond Face Alignment
with an Ensemble of Regression Trees. In Proceedings of the 2014 IEEE Conference
on Computer Vision and Pattern Recognition (CVPR â€™14). IEEE Computer Society,
Washington, DC, USA, 1867â€“1874. https://doi.org/10.1109/CVPR.2014.241
[6] T. Kohonen, M. R. Schroeder, and T. S. Huang (Eds.). 2001. Self-Organizing Maps

(3rd ed.). Springer-Verlag, Berlin, Heidelberg.

[7] Psyphine. 2011. https://psyphine.hypotheses.org. MSH, UniversitÃ© de Lorraine.
[8] Nicolas P. Rougier and Yann Boniface. 2011. Dynamic Self-Organising Map.
Neurocomputing 74, 11 (2011), 1840â€“1847. https://doi.org/10.1016/j.neucom.2010.
06.034

