Creativity explained by Computational Cognitive Neuroscience Frédéric
Alexandre

To cite this version:

Frédéric Alexandre. Creativity explained by Computational Cognitive
Neuroscience. ICCC’20 - In- ternational Conference on Computational
Creativity, Sep 2020, Coimbra, Portugal. ￿hal-02891491￿

HAL Id: hal-02891491

https://inria.hal.science/hal-02891491

Submitted on 6 Jul 2020

HAL is a multi-disciplinary open access archive for the deposit and
dissemination of sci- entific research documents, whether they are pub-
lished or not. The documents may come from teaching and research
institutions in France or abroad, or from public or private research
centers.

L’archive ouverte pluridisciplinaire HAL, est destinée au dépôt et à la
diffusion de documents scientifiques de niveau recherche, publiés ou
non, émanant des établissements d’enseignement et de recherche français
ou étrangers, des laboratoires publics ou privés.

Creativity explained by Computational Cognitive Neuroscience

Frederic Alexandre Inria Bordeaux Sud-Ouest; Labri UMR 5800; IMN UMR
5293 146 rue Leo Saignat; 33076 Bordeaux, France
Frederic.Alexandre@inria.fr

Abstract

Recently, models in Computational Cognitive Neuro- science (CCN) have
gained a renewed interest because they could help analyze current
limitations in Artiﬁcial Intelligence (AI) and propose operational ways
to ad- dress them. These limitations are related to difﬁcul- ties in
giving a semantic grounding to manipulated con- cepts, in coping with
high dimensionality and in man- aging uncertainty. In this paper, we
describe the main principles and mechanisms of these models and explain
that they can be directly transferred to Computational Creativity (CC),
to propose operational mechanisms but also a better understanding of
what creativity is.

Introduction Artiﬁcial Intelligence (AI) has developed approaches based
on knowledge manipulation and others based on data pro- cessing. The
latter ones have made tremendous progresses recently, mostly due to
technological improvements. Nev- ertheless, the development of AI
remains constrained by a series of limitations, which are present from
the birth of this domain and still unsolved. This is also the case for
CC, seen as a subﬁeld of AI (Colton and Wiggins 2012).

The three limitations of Artiﬁcial Intelligence

These limitations are mostly methodological, which means that they do
not prevent the design of projects of AI or CC but they render difﬁcult
their development up to a realistic size and they miss a realistic
description of certain charac- teristics, particularly when targeting
their autonomy.

Giving a semantic grounding Probably, one of the most fundamental
limitations of AI is the difﬁculty to make sense and exploit the meaning
of the objects they are manipulat- ing. This limitation is also
important in CC where a novel point of view can come from such a
semantic analysis. This is often related to the incapacity to ground
these objects in the real world (Harnard 1990) and to propose solutions
re- lated to the intrinsic meaning of the objects in the task. This
problem is generally addressed by developping ontologies of the task,
but these ontologies are often built explicitly from knowledge, whereas
in humans, intrinsic meanings are gen- erally acquired implicitly and
difﬁcult to express explicitly.

Coping with high dimensionality Recently, the increase of computational
resources allowed AI to explore tasks in high dimensional spaces but
this progress remains negligi- ble as compared to the virtually inﬁnite
size of state spaces in realistic tasks. Similarly, (Colton and Wiggins
2012) un- derline the growing tendency in CC to exploit web and other
large resources. A strategy is to use heuristics and to explore a
limited part of the state space. A side effect of long lasting
exploration in high dimensional state spaces is that learning requires
many examples and long training times, which is not realistic, as
compared to the ability of animals and espe- cially of humans to learn
quickly with few examples.

Managing uncertainty Tasks in the real world can be stochastic, marring
observations with noise; they can be volatile, implying that a relation
learned one day can sud- denly be no longer valid. A related important
problem, when an intelligent system receives an error signal, is to
decide if this is due to stochasticity (in the case, the best strategy
is to insist) or to volatility (requiring to look for a new response).
This is related to the balance between explo- ration and exploitation,
questioned in many models in AI. Exploration can be purely random, but
this is not consistent with observation of a certain degree of
ﬂexibility in chang- ing environments, where the appropriate behavior is
imme- diately reinstated each time the same context is revisited.
Choosing between exploration and exploitation and going beyond random
processes are also important issues in CC. All these problems are
generally tackled in various prob- abilistic frameworks (like bayesian
techniques). Some of them propose solid and mathematically grounded
methods but they are computationally prohibitive, thus adding to the
problem of high dimensionality deﬁned in the previous item.

The CCN approach CCN models are primarily developed as a way to opera-
tionalize proposed cognitive concepts, together with their brain
implementation. They can sometimes give a biolog- ical basis to
classical models in AI as it is the case in Re- inforcement Learning.
They can also help study how the brain solves some problems that remain
difﬁcult with clas- sical mathematical approaches. This is speciﬁcally
the case with the three limitations mentioned above, as we describe now
in more details.

Giving a semantic grounding It is generally considered that access to
the semantic meaning of objects is due to the fact that we have a body
that we can perceive externally (sense of exteroception, including
proprioception) and inter- nally (sense of interoception (Craig 2009)).
Considering the consequences of taking these sensations into account
onto cognition is studied in what is called embodied AI (Pfeifer,
Bongard, and Grand 2007).

Internal representation of the body is built in the insular cortex. On
the one hand, rich signals of pain and pleasure al- low to elaborate
reinforcement signals much more complex than the unique scalar generally
used in reinforcement learn- ing. Learning to anticipate these signals
(pavlovian condi- tioning, see a model in (Carrere and Alexandre 2015))
elic- its what is called emotions and plays a pivotal role in deci- sion
making by allowing to compare different signals under a common currency,
as summarized by the principle of the somatic markers (Damasio, Everitt,
and Bishop 1996).

On the other hand, other important internal signals form motivations and
can be related to physiological needs (ex- trinsic motivations) as well
as needs for certain kinds of in- formation (intrinsic motivations).
Such signals are partic- ularly important to generate internal goals and
to prevent from obeying only stimuli in the environment. This is an
important dimension for goal-directed behaviors, see com- putational
frameworks in (Pezzulo and Castelfranchi 2009).

Coping with high dimensionality One important contri- bution has arisen
from CCN about the way humans can learn in high dimensionality with the
Complementary Learning System (CLS) framework (McClelland, McNaughton,
and O’Reilly 1995). In this framework, it is proposed that hu- mans can,
at the same time, learn slowly concepts in seman- tic memory, in the
cortex, and store quickly episodes in the hippocampus. Later on, by a
phenomenon called consolida- tion, the hippocampus will send episodes
back to the cortex to train it off-line and ensure good properties to
the learn- ing process, for example to avoid mix-up, also called catas-
trophic forgetting. This kind of principles has been used in Machine
Learning to propose ways of training large archi- tectures (for example
deep networks) with “not so big data”, cf a model in (Drumond,
Vi´eville, and Alexandre 2019).

Recently, progresses in neuroscience about the hippocam- pus and in the
corresponding models led to more precise explanation about information
encoding in the hippocam- pus, and particularly about place cells and
grid cells (model in (Stachenfeld, Botvinick, and Gershman 2017)) and
their proposed contribution in the goal-oriented exploration of
high-dimensional spaces. It has particularly been proposed that replays
of episodes for consolidation are not random but obey subtle strategies
(implemented in (Mattar and Daw 2018)) and that they can be organized in
time to partic- ipate to the elaboration of knowledge-based strategies
in the frontal cortex (cf computational framework in (Daw 2018)). It has
also been experimentally shown (Derdik- man and Moser 2010) that the
hippocampus not only replays stored episodes but is also able to create
new episodes com- bining pieces of old episodes, thus promoting an
imaginative training with virtual episodes.

These concepts and models are today transfered to the do- main of AI to
elaborate what is called Episodic Reinforce- ment Learning (Gershman and
Daw 2017) and participate to the design of more realistic and faster
learning in high dimensional data spaces.

Managing uncertainty Deﬁning the stochastic or volatile nature of the
environment has been related to the role of neu- romodulation and
exploited in models (Alexandre and Car- rere 2016), adapting a general
framework of behavior selec- tion to the estimated kind and level of
uncertainty.

As for the ﬂexible adaptation of behavior to a volatile en- vironment,
the role of the prefrontal cortex has been men- tioned for a long time
in neuroscience, observing that pa- tients with a frontal lesion
demonstrate perseveration and are unable to adapt to changes (Nauta
1971). Accordingly, it has been proposed that the prefrontal cortex is
the place where nondominant behaviors are deﬁned (Wise 2008) or, to tell
it differently, the place where top-down modulations are sent to other
regions of the brain to insert internally gen- erated priorities and to
help resist to immediate responses driven by stimuli (Mesulam 2008),
thus deﬁning two impor- tant mechanisms in the prefrontal cortex: the
inhibition of dominant and occasionally non-adapted behaviors and the
triggering and maintenance by working memory of atten- tional focus
towards characteristics supposedly important to generate the presently
appropriate behavior.

Corresponding models describe the prefrontal cortex as a region where
tasks in speciﬁc contexts are represented, thus deﬁning the notion of
Task Sets (Domenech and Koechlin 2015), learning in certain contexts to
inhibit the default be- havior and to suggest new behaviors by an
attentional pro- cess (cf model in (O’Reilly et al. 2002)) biasing the
cur- rent perception. In order to select the pertinent nondominant
behavior, some interesting mathematical frameworks have been proposed
(Collins and Koechlin 2012) to tame the com- binatorial exploration and
generate a limited number of hy- potheses. Other interesting and
bio-inspired computational mechanisms have been proposed to control and
monitor the execution of such behaviors, particularly in the case of
hier- archical planning (Pezzulo and Castelfranchi 2009).

These models and concepts are also presently transferred to AI in
so-called Meta Reinforcement Learning (Wang et al. 2018), considering
that, to adapt to the changing world, a meta learner must quickly learn
to select a specialized (and slowly learning) learner, depending on the
context.

Another important limitation in AI: Creativity

It is often mentioned though disputable (Boden 2009) that creativity
remains one of the rare cognitive phenomena that AI cannot replicate
(with other phenomena like sense of hu- mor, not to say consciouness).
Remarkably, studying so- lutions proposed by CCN to remedy limitations
in AI (and consequently in CC), we argue (and will establish below) that
they massively rely on cognitive characteristics related to creativity.
We consequently propose that CCN could be pivotal to fuel CC with fresh
ideas and particularly add a global view often missing in AI.

Deﬁning creativity Whether dealing with creativity in speciﬁc domains
(like musical improvisation or scientiﬁc creativity) or from a gen- eral
point of view (Beaty et al. 2016), authors often men- tion that
creativity has two main steps: creating a novel idea and verifying that
this idea is useful or appropriate to the task (Dietrich 2004); else the
idea is adapted or rejected and another novel idea is elaborated. These
two steps are re- spectively termed divergent and convergent thinking in
hu- man creativity research (Jung et al. 2013). Corresponding mechanisms
in CC are called “generate and evaluate”. The ﬁrst step can be
associated to insight (Kounios and Beeman 2014) and originate from an
emotional or a more cognitive process (Dietrich 2004). As for the second
step, it is gener- ally proposed that the assessment of the value of
what has been proposed is carried out by brain circuits associated to
executive functions. The brain circuits responsible for these two steps
have been studied in different ways as it will be discussed in more
details below.

The two steps of creativity Concerning the divergent thinking step, it
is reported that self generated thoughts can be spontaneous or goal
directed (to meet speciﬁc task demands) (Dietrich 2004). This can
correspond to the reinterpretation of a situation to produce a
nondominant interpretation (Kounios and Beeman 2014) or to using
generative models to try to explicitly build a novel solution, which has
been qualiﬁed as a more restricted but more efﬁcient solution (Dietrich
2004). (Boden 2009) proposes that novel ideas can be produced by
combination, exploration or by transformation. (Dietrich 2004) proposes
four types of creativity: In the ﬁrst step, novelty can come from
emotional or cognitive structures and the processing can be deliberate
or spontaneous.

Among neuronal mechanisms evoked above, it can be re- marked that the
hippocampus is a good candidate to gener- ate spontaneous novel ideas
and that the mechanisms in the prefrontal cortex, responsible for
selecting a new Task Set, might participate to the explicit elaboration
of new thoughts. Let us also underline that the model proposed in
(Collins and Koechlin 2012) explicitly mentions that if no existing Task
Set is appropriate to the task, a new Task Set might be cre- ated by the
combination between two existing Task Sets or by the random generation
of a new one.

The convergent thinking step is often related to cogni- tive control,
the role of which is also to ensure appropri- ateness in the execution
of a behavior. Appropriateness can be syntactic (checking that
procedural constraints are respected, which is easy to do with a
generative model) or semantic (checking that manipulated objects have
con- sistent values, which is probably less easy (Dietrich 2004; Boden
2009)). In all cases, it is proposed that these veriﬁca- tions are made
by the PFC, with the corresponding informa- tion set in working memory
for their conscious evaluation.

The two steps of creativity in brain circuitry The functional
description of brain circuits is often made through networks of brain
regions (Mesulam 2008), high- lighting some regions as critical hubs for
the spreading and

processing of information. The attentional, semantic, de- fault,
cognitive control and salience networks are the major ones and play a
central role in creativity (Jung et al. 2013). The default network
(activated by default, for sponta- neous thinking, including parietal
cortex, medial prefrontal cortex and hippocampal regions) is much
involved in cre- ativity and is known for its links to episodic memory
in the hippocampus, spontaneous retrieval, replay activity and sim-
ulations based on personal past experiences (Dietrich 2004). To evaluate
the semantic and syntactic appropriateness of candidate ideas, a
reference is made toward an emotional system for biological signiﬁcance
of events (involving the semantic network, associated to the insula and
other limbic regions) and an information processing system to perform
detailed feature analysis involving attentional control net- works
(Beaty et al. 2016). As a synthesis, pertinence, adap- tation or
rejection of candidate ideas is made by the cogni- tive control network,
involving the lateral prefrontal cortex and the anterior cingulate
cortex, performing top-down mod- ulation of self generated information
for efﬁcacy evaluation, selection and adaptation to the task (Beaty et
al. 2016).

Dynamics of inhibition and excitation in hubs and net- works are
observed with the analysis of EEG activity in behavioral and
psychological tasks (Kounios and Beeman 2014). It must be remarked that
corresponding tests of cre- ativity are in fact relying on measures of
ﬂuency, ﬂexibility, originality and elaboration, all measures also
related to prob- lem solving. This is also a strong argument to propose
that the same brain circuits and cognitive mechanisms are used for
higher brain functions and for creativity (Dietrich 2004).

Discussion CCN models presented in this paper insist on the need to
build, inspired from neuroscience, different kinds of repre- sentations
in different regions of the brain (Alexandre, Car- rere, and Kassab
2014) and to organize the selection of be- havior through the
interactions between different kinds of memories (Alexandre 2000).

Understanding these mechanisms and corresponding brain circuitry is
particularly important to address current limitations in AI. As a
central claim for this paper, we pro- pose that these mechanisms and
cognitive processes are also central to understand creativity as it is
carried out in the brain. Perhaps this is not so surprising if we
consider that among the mechanisms the brain has developed to circum-
vent the tedious and systematic analysis of some situtations, creativity
might be a choice mechanism to efﬁciently ex- plore novel approaches.

The present paper mentions operational models that could be directly
exploited to implement CC. It also proposes paths of research to
implement speciﬁc mechanisms. Spon- taneous processing could be related
to the hippocampus and its role in the default network, whereas
deliberate process- ing would be more frontal and related to the
combination of Task Sets. The more difﬁcult aspect of combinational cre-
ativity could be linked to the limitation of semantic ground- ing, thus
pleading for a closer look to the semantic network. Using CCN models to
implement CC could be also an eas- ier way to choose the type of
creativity to generate or even

to study fundamental differences between human and non- human
creativity (Colton and Wiggins 2012).

The very nature of creativity itself can be questioned from the elements
reported here. Creativity is often associated to the generation of
completly novel ideas. What is reported here about convergent but also
divergent thinking is that most of the time, old memories are used to
create new ideas. Here also, it is the old that makes the new. What is
also reported here (in line with (Boden 2009) claiming that cre- ativity
is not magic) is that CC, indeed considered as a sci- entiﬁc
questioning, suffers mainly from fragmentation in AI research (Colton,
de Mantaras, and Stock 2009) and could highly beneﬁt from the global
framework proposed by cog- nitive neuroscience.

References Alexandre, F., and Carrere, M. 2016. Modeling Neuromod-
ulation as a Framework to Integrate Uncertainty in General Cognitive
Architectures. In The Ninth Conference on Artiﬁ- cial General
Intelligence. Alexandre, F.; Carrere, M.; and Kassab, R. 2014. Fea-
ture, Conﬁguration, History : a bio-inspired framework for information
representation in neural networks. In Interna- tional Conference on
Neural Computation Theory and Ap- plications. Alexandre, F. 2000.
Biological Inspiration for Multiple Memories Implementation and
Cooperation. In In V. Kvas- nicka P. Sincak, J. Vascak and R. Mesiar,
editors, Interna- tional Conference on Computational Intelligence.
Beaty, R. E.; Benedek, M.; Silvia, P. J.; and Schacter, D. L. 2016.
Creative Cognition and Brain Network Dynamics. Trends in Cognitive
Sciences 20(2):87–95. Boden, M. A. 2009. Computer Models of Creativity.
AI Magazine 30(3):23–23. Number: 3. Carrere, M., and Alexandre, F. 2015.
A pavlovian model of the amygdala and its inﬂuence within the medial
temporal lobe. Frontiers in Systems Neuroscience 9(41). Collins, A., and
Koechlin, E. 2012. Reasoning, Learning, and Creativity: Frontal Lobe
Function and Human Decision- Making. PLOS Biology 10(3):e1001293+.
Colton, S., and Wiggins, G. A. 2012. Computational Cre- ativity: The
Final Frontier? In ECAI’12. Colton, S.; de Mantaras, R. L.; and Stock,
O. 2009. Compu- tational Creativity: Coming of Age. AI Magazine
30(3):4pp. Craig, A. 2009. How do you feel – now? the anterior insula
and human awareness. Nat. Rev. Neurosci. 10:59–70. Damasio, A. R.;
Everitt, B. J.; and Bishop, D. 1996. The Somatic Marker Hypothesis and
the Possible Func- tions of the Prefrontal Cortex. Philosophical
Transactions of the Royal Society of London. Series B: Biological
Sciences 351(1346):1413–1420. Daw, N. D. 2018. Are we of two minds?
Nature Neuro- science 21(11):1497–1499. Derdikman, D., and Moser, M.-B.
2010. A Dual Role for Hippocampal Replay. Neuron 65(5):582–584.
Publisher: Elsevier.

Dietrich, A. 2004. The cognitive neuroscience of creativity. Psychonomic
Bulletin & Review 11(6):1011–1026. Domenech, P., and Koechlin, E. 2015.
Executive control and decision-making in the prefrontal cortex. Current
Opinion in Behavioral Sciences 1:101–106. Drumond, T. F.; Vi´eville, T.;
and Alexandre, F. 2019. Bio- inspired Analysis of Deep Learning on
Not-So-Big Data Using Data-Prototypes. Frontiers in Computational Neuro-
science 12. Gershman, S. J., and Daw, N. D. 2017. Reinforcement Learning
and Episodic Memory in Humans and Animals: An Integrative Framework.
Annual Review of Psychology 68(1):101–128. Harnard, S. 1990. The symbol
grounding problem. Physica D: Nonlinear Phenomena 42:335–346. Jung, R.
E.; Mead, B. S.; Carrasco, J.; and Flores, R. A. 2013. The structure of
creative cognition in the human brain. Frontiers in Human Neuroscience
7. Kounios, J., and Beeman, M. 2014. The cognitive neuro- science of
insight. Annual Review of Psychology 65:71–93. Mattar, M. G., and Daw,
N. D. 2018. Prioritized memory access explains planning and hippocampal
replay. Nature Neuroscience 21(11):1609–1617. McClelland, J. L.;
McNaughton, B. L.; and O’Reilly, R. C. 1995. Why there are complementary
learning systems in the hippocampus and neocortex: insights from the
successes and failures of connectionist models of learning and mem- ory.
Psychological review 102(3):419–457. Mesulam, M. 2008. Representation,
inference, and tran- scendent encoding in neurocognitive networks of the
human brain. Annals of Neurology 64(5):367–78. Nauta, W. J. 1971. The
problem of the frontal lobe: A rein- terpretation. Journal of
Psychiatric Research 8(3-4):167– 187. O’Reilly, R. C.; Noelle, D. C.;
Braver, T. S.; and Cohen, J. D. 2002. Prefrontal cortex and dynamic
categorization representational organization and neuromodulatory tasks:
control. Cereb Cortex 12(3):246–257. Pezzulo, G., and Castelfranchi, C.
2009. Thinking as the control of imagination: a conceptual framework for
goal- directed systems. Psychological Research 73(4):559–577. Pfeifer,
R.; Bongard, J.; and Grand, S. 2007. How the body shapes the way we
think: a new view of intelligence. Brad- ford Books. MIT Press.
Stachenfeld, K. L.; Botvinick, M. M.; and Gershman, S. J. 2017. The
hippocampus as a predictive map. Nature Neuro- science 20(11):1643–1653.
Wang, J. X.; Kurth-Nelson, Z.; Kumaran, D.; Tirumala, D.; Soyer, H.;
Leibo, J. Z.; Hassabis, D.; and Botvinick, M. 2018. Prefrontal cortex as
a meta-reinforcement learning system. Nature Neuroscience 21(6):860–868.
Number: 6 Publisher: Nature Publishing Group. Wise, S. P. Forward
Frontal Fields: Phy- logeny and Fundamental Function. Trends in
neurosciences 31(12):599–608.

2008. 


