How does the brain process syntactic structure while
listening?
Subba Reddy Oota, Mounika Marreddy, Manish Gupta, Raju Surampudi Bapi

To cite this version:

Subba Reddy Oota, Mounika Marreddy, Manish Gupta, Raju Surampudi Bapi. How does the brain
process syntactic structure while listening?. ACL 2023 - The 61st Annual Meeting of the Association
for Computational Linguistics, Association for Computational Linguistics, Jul 2023, Toronto, Canada.
￿hal-04131510￿

HAL Id: hal-04131510

https://hal.science/hal-04131510

Submitted on 16 Jun 2023

HAL is a multi-disciplinary open access
archive for the deposit and dissemination of sci-
entific research documents, whether they are pub-
lished or not. The documents may come from
teaching and research institutions in France or
abroad, or from public or private research centers.

L’archive ouverte pluridisciplinaire HAL, est
destinée au dépôt et à la diffusion de documents
scientifiques de niveau recherche, publiés ou non,
émanant des établissements d’enseignement et de
recherche français ou étrangers, des laboratoires
publics ou privés.

How does the brain process syntactic structure while listening?

Subba Reddy Oota1, Mounika Marreddy2, Manish Gupta2,3 and Bapi Raju Surampudi2
1INRIA, Bordeaux, France; 2IIIT Hyderabad, India; 3Microsoft, India
subba-reddy.oota@inria.fr, mounika.marreddy@research.iiit.ac.in

gmanish@microsoft.com, raju.bapi@iiit.ac.in

Abstract

Syntactic parsing is the task of assigning a
syntactic structure to a sentence. There are
two popular syntactic parsing methods: con-
stituency and dependency parsing. Recent
works have used syntactic embeddings based
on constituency trees, incremental top-down
parsing, and other word syntactic features for
brain activity prediction given the text stimuli
to study how the syntax structure is represented
in the brain’s language network. However, the
effectiveness of dependency parse trees or the
relative predictive power of the various syn-
tax parsers across brain areas, especially for
the listening task, is yet unexplored. In this
study, we investigate the predictive power of
the brain encoding models in three settings: (i)
individual performance of the constituency and
dependency syntactic parsing based embedding
methods, (ii) efficacy of these syntactic parsing
based embedding methods when controlling for
basic syntactic signals, (iii) relative effective-
ness of each of the syntactic embedding meth-
ods when controlling for the other. Further,
we explore the relative importance of syntactic
information (from these syntactic embedding
methods) versus semantic information using
BERT embeddings. We find that constituency
parsers help explain activations in the temporal
lobe and middle-frontal gyrus, while depen-
dency parsers better encode syntactic structure
in the angular gyrus and posterior cingulate cor-
tex. Although semantic signals from BERT are
more effective compared to any of the syntactic
features or embedding methods, syntactic em-
bedding methods explain additional variance
for a few brain regions. We make our code
publicly available1.

1

Introduction

A key assumption in psycholinguistics is that sen-
tence processing involves two operations: (i) the
construction of a syntactic structure that represents

1https://tinyurl.com/BrainSyntax

the relation between its components and (ii) the
retrieval of the meaning of single linguistic units
from semantic memory. When presented with a
sentence in a task, humans can understand word
meaning effectively while reading and listening.
Listeners and readers appear to extract a similar se-
mantic meaning from narrative stories (Rubin et al.,
2000; Diakidoy et al., 2005), hence suggesting that
the brain represents semantic information in an
amodal form, i.e., independent of input modality.
Further, earlier language-fMRI encoding studies
have observed that sentence semantics alone cannot
explain all the variance in brain activity; syntactic
information can also be used to explain some of
the variance (Binder et al., 2016; Fedorenko and
Thompson-Schill, 2014).

Prior to different aspects of semantic interpreta-
tion, the brain performs syntactic structure analysis
inherently (Hirst, 1984). The syntactic informa-
tion helps to identify the structural constituents that
have to be interpreted as nominal, ordinal, or noun
phrases, e.g., we identify “Brazil”, “four”, “world
cups”, and “2002” in a sentence: “Brazil won four
world cups till 2002” before interpreting the seman-
tics. Hence, investigating how the brain encodes
syntactic word features is crucial for understanding
language comprehension in the brain.
Two paradigms of syntactic parsing: Con-
stituency and dependency are two different syn-
tactic formalisms using different structural prim-
itives (dependency relations and phrases). There
has been some discussion in the field of theoret-
ical linguistics with regard to whether they cap-
ture the same information or to what degree the
structures they sanction are equivalent (Hays, 1964;
Jung, 1995). Discussing the linguistic information
the two parsers capture, Rambow (2010) states
from a theoretical linguistic point of view that
they describe distinct syntactic entities; thus, they
are not strictly equivalent. Dependencies capture
direct relations between words, identical to the-

Figure 1: Four steps of our proposed approach: (1) fMRI acquisition, (2) Syntactic parsing, (3) Regression model
training, and (4) Predictive power analysis of the three embeddings methods.

matic functions such as subject, object, modifier,
etc. Constituent syntactic structure, on the other
hand, is not so much about functional relations be-
tween words but about the recursive grouping of
sentence constituents (words and phrases), such
that at each level, each grouping acts as a syntac-
tic unit (Schneider, 1998). Moreover, according
to Jung (1995), only dependencies can express
the syntactic word-to-word relations of a sentence,
whereas constituency expresses the linear order of
a sentence. On the other hand, an incremental top-
down constituency parser processes input words
from left to right, producing the possible parses
in a top-down manner as future words are read.
Therefore, Jung (1995) sees the two grammars
as complementary but not equivalent. Following
these last observations, we consider dependency
and constituent structures as distinct and the type
of information they capture as nonequivalent. The
question we address in this study is whether dif-
ferent brain regions are associated with building
different kinds of syntactic structures. We com-
pare the predictive power of syntactic structural
measures derived from these parsers with regard to
modeling the brain activity in language processing
areas recorded during naturalistic story listening.
Stimulus types for studying syntactic processing:
Earlier psycholinguistic studies explored syntactic
processing while subjects were involved in activi-
ties that required less versus more syntactic compre-
hension effort (Friederici, 2011) using carefully de-
signed sentence/phrase stimuli. In the past decade,
the study of syntactic processing has been extended
to naturalistic settings that use narratives, such as
reading (Reddy and Wehbe, 2021) or listening to
stories (Bhattasali et al., 2018; Zhang et al., 2022)
generally in a task-free setting. Due to the com-

plexity of extracting syntactic word embeddings
from sentence parsers, investigation of the predic-
tive power of sentence parsers for brain encoding,
especially for the neuroimaging data from natural-
istic listening paradigms, is still under-explored.
Brain Regions of Interest (ROIs) for syntactic
processing: Several classical studies report the
involvement of a language network of mostly left-
lateralised cortical regions, including the left in-
ferior frontal gyrus (IFG) with sub-regions (BA
44 and BA 45), the left posterior superior tempo-
ral gyrus (pSTG), and the left anterior temporal
pole (ATP) (Caramazza and Zurif, 1976; Friederici
et al., 2006; Friederici, 2011; Pallier et al., 2011;
Zaccarella and Friederici, 2015). However, sev-
eral other studies did not report activity in left
IFG and left pSTG (Humphries et al., 2006; Ro-
galsky and Hickok, 2009; Bemis and Pylkkänen,
2011), despite using paradigms similar to the stud-
ies mentioned above. A series of recent studies
have used functional magnetic resonance imaging
(fMRI) brain activity to find that those brain re-
gions spanning both the left and right hemispheres
are involved in language processing (Fedorenko
and Thompson-Schill, 2014; Caucheteux et al.,
2021a; Reddy and Wehbe, 2021; Zhang et al.,
2022; Oota et al., 2022b,a; Toneva et al., 2022;
Aw and Toneva, 2023; Oota et al., 2022c; Merlin
and Toneva, 2022). Further, these works conclude
that syntax is distributed throughout the language
system (Blank et al., 2016; Fedorenko et al., 2012,
2020; Caucheteux et al., 2021a; Wang et al., 2020;
Reddy and Wehbe, 2021; Zhang et al., 2022; Oota
et al.). However, whether different brain regions
are sensitive to distinct sentence-parsing strategies
remains unclear. Moreover, in a listening task, it is
unclear how syntactic features are represented in

Step 2: Extract parser representations of the storyfMRIStep 1: Acquire brain activity of people listening to natural storyI began my illustrious …Step 3: For each brain region, learn a regression model that predicts brain activity using the representations of the corresponding words Step 4: Control syntactic information from each representation and evaluate (i)individual predictive power of these three syntactic word embedding methods, (ii)predictive power of the three syntactic word embedding methods when controlling for basic syntactic signals, (iii)predictive power of each of the three syntactic word embedding methods when controlling for the other two.y=f(x)(a) Constituency parse tree(b) Dependency parse treeSNPDTNPPPVPNNDTNNVBDINThecatsatonthemat(c) Incremental top-down parse treeROOTVP..SNPDTNNThecatVBDPPsatINNPonDTNNthematFigure1:Fourstepsofourproposedapproach:(1)fMRIacquisition,(2)Syntacticparsing,(3)Regressionmodeltraining,and(4)Predictivepoweranalysisofthethreeembeddingsmethods.guisticinformationthethreeparserscapture,Ram-084bow(2010)statesfromatheoreticallinguisticpoint085ofviewthattheydescribedistinctsyntacticentities,086andthusarenotstrictlyequivalent.Dependencies087capturedirectrelationsbetweenwords,identical088tothematicfunctionssuchassubject,object,mod-089ifier,etc.Constituentsyntacticstructure,onthe090otherhand,isnotsomuchaboutfunctionalrela-091tionsbetweenwords,butabouttherecursivegroup-092ingofsentenceconstituents(wordsandphrases),093suchthatateachlevel,eachgroupingactsasasyn-094tacticunit(Schneider,1998).Moreover,accord-095ingtoJung(1995)onlydependenciescanexpress096thesyntacticword-to-wordrelationsofasentence,097whereasconstituencyexpressesthelinearorderofa098sentence.Ontheotherhand,incrementaltop-down099parserprocessesinputwordsfromlefttoright,pro-100ducingthepossibleparsesinatop-downmanner101asfuturewordsareread.Therefore,Jung(1995)102seesthetwogrammarsascomplementarybutnot103equivalent.Followingtheselastobservations,we104considerdependencyandconstituentstructuresas105distinctandthetypeofinformationthattheycap-106tureasnonequivalent.Thequestionweaddress107inthisstudyiswhetherdifferentbrainregionsare108associatedwithbuildingdifferentkindsofsyntac-109ticstructure.Wecomparethepredictivepowerof110syntacticstructuralmeasuresderivedfromthese111parserswithregardtomodelingthebrainactiv-112ityinlanguageprocessingareasrecordedduring113naturalisticstorylistening.114Stimulustypesforstudyingsyntacticprocessing:115Earlierpsycholinguisticstudiesexploredsyntactic116processingwhilesubjectswereinvolvedinactivi-117tiesthatrequiredlessversusmoresyntacticcompre-118hensioneffort(Friederici,2011)usingcarefullyde-119signedsentence/phrasestimuli.Inthepastdecade,120thestudyofsyntacticprocessinghasbeenextended121tonaturalisticsettingsthatusenarratives,suchas122reading(ReddyandWehbe,2021)orlisteningto123stories(Bhattasalietal.,2018;Zhangetal.,2022)124generallyinatask-freesetting.Duetothecom-125plexityofextractingsyntacticwordembeddings126fromsentenceparsers,investigationofthepredic-127tivepowerofsentenceparsersforbrainencoding,128especiallyfortheneuroimagingdatafromnatural-129isticlisteningparadigmsisstillunder-explored.130BrainRegionsofInterest(ROIs)forsyntactic131processing:Severalclassicalstudiesreportthe132involvementofalanguagenetworkofmostlyleft-133lateralisedcorticalregionsincludingtheleftin-134feriorfrontalgyrus(IFG)withsubregions(BA13544andBA45),theleftposteriorsuperiortempo-136ralgyrus(pSTG),andtheleftanteriortemporal137pole(ATP)(CaramazzaandZurif,1976;Friederici138etal.,2006;Friederici,2011;Pallieretal.,2011;139ZaccarellaandFriederici,2015).However,sev-140eralotherstudiesdonotreportactivityinleftIFG141andleftpSTG(Humphriesetal.,2006;Rogalsky142andHickok,2009;BemisandPylkkänen,2011),143despiteusingparadigmssimilartotheabovemen-144tionedstudies.Aseriesofrecentstudieshaveused145functionalmagneticresonanceimaging(fMRI)146brainactivitytofindthatthosebrainregionsspan-147ningboththeleftandrighthemispheresarein-148volvedinlanguageprocessing(Fedorenkoand149Thompson-Schill,2014;Caucheteuxetal.,2021a;150ReddyandWehbe,2021;Zhangetal.,2022;Oota1512the brain and whether the neural correlates of differ-
ent syntactic parsing signals overlap or dissociate
from one another.

Word stimulus representations for brain en-
coding: Several studies have used basic syntac-
tic features such as part-of-speech, dependency
relations, complexity metrics (Caucheteux et al.,
2021a; Reddy and Wehbe, 2021), and semantic
word embeddings (Oota et al., 2018; Jain and Huth,
2018; Hollenstein et al., 2019) to represent words
for brain encoding with text stimulus. In this paper,
to understand how the brain processes linguistic
structure in sentences, we leverage three different
text representations using syntax parsers, as shown
in Fig. 1. We aim to understand the relative impor-
tance of these syntax parser embeddings and also
their additional importance when compared with
basic syntactic features or semantic embeddings
like BERT.

Limitations of previous work: (i) Existing work
has focused on either constituency parsing mainly
including incremental top-down parsing (Reddy
and Wehbe, 2021). No previous work has ex-
plored syntactic structure present in dependency
trees. Reddy and Wehbe (2021) have only used
one-hot vector for dependency tags as part of their
complexity metrics. But we leverage dependency
information more systematically by learning the
dependency representations using graph convolu-
tional networks. (ii) Existing work has mostly fo-
cused on reading tasks only, and that too on small
number of subjects (e.g., 7 subjects in (Reddy and
Wehbe, 2021)). There is evidence that several cor-
tical regions are activated during listening (Hand-
jaras et al., 2016). But which brain areas and sub-
regions of the language network are involved in
syntactic processing is yet unexplored. (iii) Lastly,
existing work does not perform pairwise predic-
tive power comparison for different syntactic parse
methods.

Overall, our main contributions are as follows.
(1) We explore (a) basic syntactic features such
as complexity metrics, part-of-speech (POS) tags,
and dependency role (DT) tags, (b) embeddings
obtained from three parse tree representations, and
(c) semantic BERT embeddings for brain encod-
ing. (2) Constituency and dependency tree-based
embeddings are effective across different language
regions for brain activity prediction, even after con-
trolling for basic syntactic signals. (3) We find that
prediction of the activation in regions such as the

bilateral temporal areas (ATL, PTL) and middle-
frontal gyrus (MFG) is significantly related to con-
stituency parse representations. At the same time,
brain activity in other language regions, such as the
angular gyrus (AG) and posterior cingulate cortex
(PCC) is significantly associated with dependency
parse embeddings. (4) Lastly, in the inferior frontal
gyrus (IFG), we identify that dependency parse em-
beddings encode syntactic information better in the
sub-regions such as 44, 45, IFJa, and IFSp of the
left hemisphere, whereas constituency parse tree
and incremental top-down parse tree based embed-
dings are better aligned in the right hemisphere.

2 Feature Representations

We used four different features computed per word
to simultaneously test different syntactic and se-
mantic representations.
(1) Constituency Tree-based Embeddings: Sim-
ilar to Reddy and Wehbe (2021), we build three
types of constituency tree-based graph embeddings
(ConTreGE): (i) ConTreGE Complete vectors (CC),
(ii) ConTreGE Incomplete vectors (CI) and (iii) In-
cremental Top-Down Parser Embeddings (INC). A
CC vector is generated for every word using the
largest subtree completed by that word. A sub-
tree is considered complete when all of its leaves
are terminals. The largest subtree completed by a
given word refers to the subtree with the largest
height. A CI vector is generated for every word
using the incomplete subtree that contains all of
the Phrase Structure Grammar productions needed
to derive the words seen till then, starting from the
root of the sentence’s tree. Some examples for CC
and CI are added in the Appendix (Figs. 6 and 7).
Like (Reddy and Wehbe, 2021), we use Berkeley
Neural Parser2 for constituency parsing (i.e., for
both CI and CC).

In ConTreGE Complete tree (CC), the largest
subtree completed by a given word refers to the
subtree with the largest height that also satisfies the
following conditions - the given word must be one
of its leaves and all of its leaves must only contain
words that have been seen till then.

In ConTreGE Incomplete tree (CI), the embed-
dings are constructed using incomplete subtrees
that are constructed by retaining all the phrase
structure grammar productions that are required
to derive the words seen till then, starting from the

2https://spacy.io/universe/project/

self-attentive-parser

root of the sentence’s tree. If incomplete subtrees
are more representative of the brain’s processes, it
would mean that the brain correctly predicts certain
phrase structures even before the entire phrase or
sentence is read.

The incremental top-down parser is a statisti-
cal syntactic parser that processes input strings
from left to right, producing partial derivations in
a top-down manner, using beam search as detailed
in (Roark, 2001). Specifically, we use the imple-
mentation as described here3. The INC embed-
dings are obtained using exactly the same methods
as described in Section 3 of (Reddy and Wehbe,
2021). The brain could be computing several pos-
sible top-down partial parses that can derive the
words seen so far and modifying the list of pos-
sible parses as future words are read. The INC
feature space is constructed to encode the differ-
ent possible parse trees that can derive the words
seen so far. When considering parse tree based
representations, the embeddings may contain infor-
mation about what is yet to be seen by the subject.
However, this is not a problem since it mimics the
human capability of guessing what is to come next.
With this embedding space, we attempt to measure
the ability of the brain to predict future constituents
correctly.
(2) Dependency Tree-based Embeddings (DEP):
Graph Convolutional Networks (GCNs) have been
widely used to encode syntactic information from
dependency parse trees (Vashishth et al., 2019).
Rather than using pretrained syntactic GCN word
embeddings generated from Wikipedia (Vashishth
et al., 2019), we create DEP embeddings using
GCNs on the “Narrative stories” dataset as fol-
lows. To generate syntactic word embeddings us-
ing GCN, we first extract the dependency parse
tree Gs=(Vs, ϵs) for every sentence in our dataset
s = (w1, w2,. . . , wn), using the Stanford CoreNLP
parser (Manning et al., 2014). Here, Vs = {w1,
w2,. . . , wn} and ϵs denotes the labeled directed
dependency edges of the form (wi, wj , lij ), where
lij is the dependency relation of wi to wj. GCN
computations iteratively utilize the context defined
by a word’s neighbors in the graph to compute
embedding for every word wi. Further, we also
perform edge-wise gating to give importance to
relevant edges and suppress noisy ones. We fol-
low the architecture defined in (Vashishth et al.,

3https://github.com/roarkbr/

incremental-top-down-parser

2019) for training a GCN on our dataset leading
to syntactically-rich DEP embeddings. Overall,
GCN utilizes syntactic context to learn rich DEP
embeddings.

(3) Basic Syntactic Features: Similar to (Wang
et al., 2020; Reddy and Wehbe, 2021; Zhang et al.,
2022), we use various multi-dimensional syntac-
tic features such as Punctuation (PU), Complexity
Metrics (CM), and Part-of-speech and dependency
tags (PD), described briefly below.

Punctuation (PU) The role of punctuation is to
resolve syntactic and semantic ambiguity in the lex-
ical grammar and encode relational discourse links
between text units in sentences (Briscoe, 1996).
Punctuation-based features are encoded using a
one-hot vector where the type of punctuation is
presented along with a word (e.g. . or ,).

Complexity Metrics (CM) We use three features
in the complexity metrics: Node Count (NC), Word
Length (WL), and Word Frequency (WF). The
node count for each word is the number of subtrees
that are completed by incorporating each word into
its sentence. Word length is the number of charac-
ters present in the word. Word frequency reports
log base-10 of the number of occurrences per bil-
lion of a given word in a large text corpus.

Part-of-speech and Dependency tags (PD) We
use the Spacy English dependency parser (Hon-
nibal and Montani, 2017) to extract the Part-of-
speech (POS) and dependency tags. Unlike DEP
embeddings (which use GCNs), in PD, we gener-
ate a one-hot vector for each word and dependency
tag. The final vector is called PD, a concatenation
of both the POS tag and dependency vector. Note
that DEP and PD features use different methods for
dependency analysis – PD features are just one-hot
encoded representations while DEP features are
learned syntactic embeddings using GCNs.

(4) BERT Features Given an input sentence, the
pretrained BERT (Devlin et al., 2019) outputs token
representations at each layer. Since BERT embeds
a rich hierarchy of linguistic signals: surface in-
formation at the bottom, syntactic information in
the middle, semantic information at the top (Jawa-
har et al., 2019); hence, we use the #tokens ×
768D vector from the last hidden layer to obtain
the semantic embeddings. For uniformity of fea-
ture dimensions, we used PCA to bring down the
dimensions to 250.

3 Dataset Curation

Brain Imaging Dataset The “Narratives” collec-
tion aggregates a variety of fMRI datasets collected
while human subjects listened to real spoken sto-
ries (Nastase et al., 2021). We analyze data from
82 subjects listening to the story titled ‘PieMan’
with 282 TRs (repetition time – fMRI recorded ev-
ery 1.5 sec.). We chose this story since it contains
maximum number of subjects in the “Narratives”
collection. The dataset is in English and contains
957 words across 67 sentences. The story duration
is 07m:02s. We use the multi-modal parcellation of
the human cerebral cortex (Glasser Atlas: consists
of 180 ROIs in each hemisphere) to display the
brain maps (Glasser et al., 2016) since the Narra-
tives dataset contains annotations tied to this atlas.
The data covers eight language brain ROIs with
the following subdivisions: (i) angular gyrus (AG:
PFm, PGs, PGi, TPOJ2, and TPOJ3); (ii) anterior
temporal lobe (ATL: STSda, STSva, STGa, TE1a,
TE2a, TGv, and TGd); (iii) posterior temporal lobe
(PTL: A5, STSdp, STSvp, PSL, STV, TPOJ1); (iv)
inferior frontal gyrus (IFG: 44, 45, IFJa, IFSp);
(v) middle frontal gyrus (MFG: 55b); (vi) inferior
frontal gyrus orbital (IFGOrb: a47r, p47r, a9-46v),
(vii) posterior cingulate cortex (PCC: 31pv, 31pd,
PCV, 7m, 23, RSC); and (viii) dorsal medial pre-
frontal cortex (dmPFC: 9m, 10d, d32) (Baker et al.,
2018; Milton et al., 2021; Desai et al., 2023). The
dataset has been made available freely without re-
strictions by Nastase et al. (2021).
Downsampling Since the rate of fMRI data ac-
quisition (TR = 1.5sec) was lower than the rate at
which the text stimulus was presented to the sub-
jects, several words fall under the same TR in a sin-
gle acquisition. Hence, we match the stimulus ac-
quisition rate to fMRI data recording by downsam-
pling the stimulus features using a 3-lobed Lanczos
filter (LeBel et al., 2021). After downsampling,
we obtain chunk-embedding corresponding to each
TR.
TR Alignment To account for the slowness of the
hemodynamic response, we model the hemody-
namic response function using finite response filter
(FIR) per voxel and for each subject separately with
8 temporal delays corresponding to 12 seconds.

4 Methodology

Encoding Model To explore how and where syn-
tactic and semantic specific features are represented
in the brain when listening to stories, we extract dif-

ferent features describing each stimulus sentence
and use them in an encoding model to predict brain
responses. If a feature is a good predictor of a spe-
cific brain region, information about that feature is
likely encoded in that region.

F + λ∥W ∥2

∥Yi − XiW ∥2

The main goal of each fMRI encoder model is
to predict brain responses associated with each
brain voxel when given stimuli. We train a model
per subject separately. Following the literature
on brain encoding (Wehbe et al., 2014; Toneva
et al., 2020; Caucheteux et al., 2021b; Reddy and
Wehbe, 2021; Toneva et al., 2021; Zhang et al.,
2022; Oota et al., 2022b, 2023), we choose to use
a ridge regression model instead of more com-
plicated models. We plan to explore more such
models as part of future work. The ridge re-
gression objective function for the ith example is
f (Xi) = min
F . Here, W
W
are the learnable weight parameters, ∥.∥F denotes
the Frobenius norm, and λ > 0 is a tunable hyper-
parameter representing the regularization weight.
λ was tuned on a small disjoint validation set ob-
tained from the training set.
Cross-Validation We follow 4-fold (K=4) cross-
validation. All the data samples from K-1 folds
were used for training, and the model was tested
on samples of the left-out fold.
Evaluation Metric We evaluate our models using
the popular brain encoding evaluation metric, R2.
Let TR be the number of time repetitions. Let
Y = {Yi}T R
i=1 denote the actual
and predicted value vectors for a single voxel. Thus,
Y ∈ RT R and also ˆY ∈ RT R. We use R2(Y, ˆY )
metric to measure the coefficient of determination
for every voxel. We average R2 score over all
voxels in a region to get region-level aggregated
metric. Finally, they are further averaged across all
subjects to obtain final region-level metrics, which
are reported with mean and standard deviation.
Statistical Significance We run a permutation test
to check if R2 scores are significantly higher than
chance. We permute blocks of contiguous fMRI
TRs, instead of individual TRs, to account for the
slowness of the underlying hemodynamic response.
We choose a standard value of 10 TRs. The pre-
dictions are permuted within fold 5000 times, and
the resulting R2 scores are used as an empirical
distribution of chance performance, from which
the p-value of the unpermuted performance is es-
timated. We also run a bootstrap test, to test if a
model has a higher R2 score than another. In each

i=1 and ˆY = { ˆYi}T R

iteration, we sample with replacement the predic-
tions of both models for a block of TRs, compute
the difference of their R2, and use the resulting dis-
tribution to estimate the p-value of the unpermuted
difference. Finally, the Benjamni-Hochberg False
Discovery Rate (FDR) correction (Benjamini and
Hochberg, 1995) is used for all tests (appropriate
because fMRI data is considered to have positive
dependence (Genovese, 2000)). The correction is
performed by grouping all the voxel-level p-values
(i.e., across all subjects and feature groups) and
choosing one threshold for all of our results. The
correction is done this way as we test multiple pre-
diction models across multiple voxels and subjects.

5 Experiments and Results

We discuss detailed hyper-parameter settings in
Appendix A.
Which word representations are semantic ver-
sus syntactic? We first empirically show that
syntactic embeddings do not encode a signifi-
cant amount of semantic information. In partic-
ular, we train the RidgeCV regression model in
a 10-fold cross-validation setting to predict the
semantic GloVe (Pennington et al., 2014) fea-
tures (300 dimensions) using syntactic embed-
dings for all the representations, similar to earlier
works (Caucheteux et al., 2021a; Reddy and We-
hbe, 2021; Zhang et al., 2022).

Average R2 scores are as follows: BERT (0.560),
CC (0.052), CI (0.020), DEP (0.170), INC (0.040),
PD (0.183), CM (0.027), and PU (0.005). These R2
scores indicate that (a) overall, BERT has high se-
mantic information compared to other embeddings,
and (b) constituency parsers have low semantic
information compared to DEP. Overall, all the syn-
tactic embeddings consist of very low semantic
information. Hence, it is reasonable to infer that
any additional variance predicted by the syntactic
parsing methods compared to the semantic feature
space (BERT) is mainly due to their syntactic in-
formation.
Performance of individual embedding methods:
In order to assess the performance of the fMRI en-
coder models learned using the individual syntactic
and semantic representations, we computed the R2
scores between the predicted and true responses
across various ROIs of the language network. Fig. 2
reports the % of ROI voxels with significant R2
scores (based on a hypothesis test where the R2
score for each voxel is greater than 0) across differ-

ent representations for different language regions
in the left and right hemispheres. We make the
following observations from Fig. 2: (1) Among
basic syntactic features, PD features perform best
across most of the language regions, whereas CM
yields the second-best result. (2) Among the syn-
tactic embedding methods, CC encodes syntactic
information better in the language regions such
as temporal lobes (ATL and PTL) and MFG. (3)
Among the syntactic embedding methods, DEP
embeddings predict brain activity better in the lan-
guage regions (PCC and IFG of left hemisphere,
and AG, IFGorb, and PCC of right hemisphere).
(4) Semantic embeddings using BERT are the best
across all regions in the right hemisphere, but the
effectiveness of BERT is rather mixed in the left
hemisphere.

Further, we report the avg R2 scores across all
different language ROIs in the Appendix (Fig. 8).
We further demonstrate the performance of em-
bedding methods for various sub-regions of each
language ROI in the Appendix Figs. 9 to 15. We
observe the following from these figures: (1) In
the ATL region (Fig. 10), CC better encodes in
the superior temporal sulcus with dorsal attention
(STSda). For STS in ventral attention (STSva), CC
encodes better in the left hemisphere while DEP is
better in the right. (2) In the PTL region (Fig. 11),
CC is best for STSdp sub-region. (3) In the IFG
region (Fig. 12), DEP is better aligned with 44
region whereas CC is better aligned with IFJa re-
gion. These results are in line with observations
made in (Pallier et al., 2011). Overall, a higher per-
centage of voxels with all the frontal and temporal
regions, demonstrates that language comprehen-
sion may be associated more with both frontal and
temporal regions (Cohen et al., 2021).

We also report brain maps with avg R2 for all
the representations in Fig. 3. From Figs. 2 and 3,
we can infer that the different word representa-
tions, including all syntactic and semantic meth-
ods, are highly distributed across ROIs of language
network. In particular, PTL and MFG have high
overlap for both syntactic (CC, CI, DEP, INC), and
semantic (BERT) features. Also, ROIs such as
PTL, IFGOrb and PCC have higher overlap with
PD. Most of these observations agree with previous
findings on the brain networks of language process-
ing (Friederici, 2011; Fedorenko and Thompson-
Schill, 2014; Caucheteux et al., 2021a; Reddy
and Wehbe, 2021; Zhang et al., 2022), support-

Figure 2: Performance of Individual Embedding Methods: ROI-wise analysis of the prediction performance of
various feature sets. We show the % of ROI voxels with a significant increase in prediction performance. Each bar
shows avg %; error bars show standard error across 82 subjects. Left hemisphere (Top); Right hemisphere (Bottom).

Figure 3: R2 score per voxel for the whole brain. (a) PU (b) CM (c) PD (d) CC (e) CI (f) INC (g) DEP (h) BERT.

Figure 4: Additional Predictive Power of various Representations: For each model, we show the % of ROI
voxels with a significant increase in prediction performance. Each bar shows avg %; error bars show standard error
across 82 subjects. ‘-’ indicates a hypothesis test for the difference in R2 scores between the two feature groups
being larger than 0. Left hemisphere (Top); Right hemisphere (Bottom). Note that PU values here are slightly
different from Fig. 2 since here the FDR correction was done across all the groups.

ing that both syntax and semantics are distributed
across language ROIs. Lastly, similar to an earlier
study (Blank et al., 2016), basic syntactic features
are much less associated with voxels in AG region.

Additional predictive power of various repre-
sentations Many feature spaces have overlapping
information, e.g., PD (part-of-speech and depen-

dency) tags include punctuation, BERT vectors
have been shown to encode syntax (Jawahar et al.,
2019; Luoma and Pyysalo, 2020), and DEP em-
beddings built from GCNs encode some POS tags
information. Are various representations capturing
very similar signals, i.e., redundant or capturing
new information, which is additionally useful to

AGATLPTLIFGMFGIFGOrbPCCdMPFC0102030405060708090{PU}{CM}{PD}{CC}{CI}{INC}{DEP}{BERT}% of Significant VoxelsLEFT HEMISPHEREAGATLPTLIFGMFGIFGOrbPCCdMPFC01020304050607080% of Significant VoxelsRIGHT HEMISPHEREAGATLPTLIFGMFGIFGOrbPCCdMPFC051015202530{PU}{CM,PU}-{PU}{PD,CM,PU}-{CM,PU}{CC,PD,CM,PU}-{PD,CM,PU}{CI,PD,CM,PU}-{PD,CM,PU}{INC,PD,CM,PU}-{PD,CM,PU}{DEP,PD,CM,PU}-{PD,CM,PU}{BERT,CC,PD,CM,PU}-{CC,PD,CM,PU}{BERT,CI,PD,CM,PU}-{CI,PD,CM,PU}{BERT,INC,PD,CM,PU}-{INC,PD,CM,PU}{BERT,DEP,PD,CM,PU}-{DEP,PD,CM,PU}% of Significant VoxelsLEFT HEMISPHEREAGATLPTLIFGMFGIFGOrbPCCdMPFC0510152025% of Significant VoxelsRIGHT HEMISPHEREpredict brain activations? To answer this question,
we first organize the feature groups in the increas-
ing order of syntactic information. We build hierar-
chical feature groups in increasing order of syntac-
tic information and test for significant differences
in prediction performance between two consecutive
groups. We start with the simple feature – punctua-
tion (PU) and then add more complex features in
this order: the complexity metrics (CM), POS and
dependency tags (PD), {CC, CI, INC, DEP}, and
lastly, BERT. Fig. 4 reports the % of ROI voxels
with significant R2 scores (hypothesis test where
the difference in R2 scores between the two feature
groups is larger than 0) across feature groups for
different ROIs in the left and right hemispheres,
respectively.

We make the following observations from Fig. 4.
(i) Unlike (Reddy and Wehbe, 2021), we find that
punctuation features yield a lower predictive per-
formance across language regions for listening in
both the left and right hemispheres. This is intuitive
since punctuation marks are not “visible” when lis-
tening. (ii) Amongst CC, CI, INC, and DEP, after
controlling for basic syntactic features {PD, CM,
PU}, CC displays a large % of significant voxels
across multiple language sub-regions, largest in
ATL, PTL, and MFG in left and in IFGOrb, PCC
and dmPFC in the right hemispheres. This means
there are voxels in these language sub-regions that
capture hierarchical English grammar syntax be-
yond simple syntax signals captured by PD, CM,
and PU. (iii) DEP parser explains addition variance
after controlling for basic syntactic features for the
AG region which is mainly a knowledge store of
thematic relations between entities. Also, DEP
yields a large % of significant voxels for the IFG re-
gion in the left hemisphere whereas PCC region in
the right hemisphere. Although INC does not show
any additional variance in the left hemisphere, it
performs well for IFG and MFG in the right hemi-
sphere. (iv) On top of these representations, BERT
adds to the variance the most in the context of CC,
CI, INC, and DEP features in both hemispheres.

Pairwise predictive power comparison for syn-
tactic parse methods and BERT To compare rel-
ative extra syntactic information in various parse-
based representations, we compute the difference
in R2 between every pair of representations from
{CC, CI, DEP}. For this analysis, we ignore INC
since it performed worst, as shown in Fig. 2. Thus,
we plot % of significant ROI voxels for {CC, DEP}-

{CC} and other such feature-pairwise combinations
in Fig. 5 for both hemispheres. We make the follow-
ing observations from Fig. 5. (i) CC and CI show
greater variance in brain predictivity (ATL and PTL
for both hemispheres, MFG, IFGOrb and dmPFC
of left hemisphere) even after controlling for either
DEP. Also, CC and DEP show greater variance af-
ter controlling for CI. However, DEP or CI have
negligible % of ROI voxels after controlling for
CC, specifically for temporal lobe (ATL and PTL)
and frontal regions (IFG and MFG). Thus, we can
conclude that constituency trees, specifically CC,
encode similar syntactic information as DEP in
temporal lobe (ATL and PTL) and frontal regions
(IFG and MFG). Also, DEP based on dependency
trees does not have additional syntactic information
compared to constituency trees, except for AG, IF-
GOrb, PCC and dmPFC regions. (ii) While BERT
provides improvement over CC, CI and DEP in
most brain areas (especially in MFG and dMPFC),
surprisingly in AG and IFG, BERT does not pro-
vide much additive value.

6 Discussion

In this section, we correlate our empirical findings
about syntactic parsing methods with previously
proposed neuroscience theories.

From Fig. 4, we observe that activity in the left
temporal lobe (ATL and PTL) seems to be pre-
dicted well using either CC or basic syntactic (PD)
representations. These results are supported by the-
ory of Matchin and Hickok (2020), who concluded
that parts of the PTL are involved in hierarchical
lexical-syntactic structure building, while the ATL
is a knowledge store of entities. While activity in
the left IFGOrb, left PCC, and left AG seems to
be better modeled by basic syntactic feature (PD)
representations, that in MFG seems to be related
to CC representations. DEP embeddings seem to
perform better for activity in the left AG, left ATL
and left IFG. This supports the theory of Matchin
and Hickok (2020), which reports that ATL is a
knowledge store of entities and AG is a store of
thematic relations between entities.

A sub-ROI in the left AG, namely parietal area
G inferior (PGi) has significantly more number
of voxels sensitive to dependency features when
we control for all other syntactic features. On the
other hand sub-ROIs in the right temporo-parieto-
occipital junction (TPOJ) are more sensitive to in-
cremental top-down syntactic features (Appendix

Figure 5: Pairwise Predictive Power Comparison for Syntactic Parse Methods and BERT: For each model,
we show the percentage of ROI voxels in which we see a significant increase in prediction performance. Each bar
represents the average percentage across 82 subjects, and the error bars show the standard error across subjects. ‘-’
indicates a hypothesis test for the difference in R2 scores between the two feature groups being larger than 0. Left
hemisphere (Top) and Right hemisphere (Bottom).

Fig. 16). While it is known that AG is sensitive
to stimuli that are connected through a narrative
rather than unconnected words (Baker et al., 2018),
the current findings suggest that distinct sub-ROIs
within AG are related to different syntactic features.

Further sub-regions in the prefrontal cortex such
as Brodmann area (BA) 44 and the inferior frontal
junction area (IFJa) also seem to be related to
representations of dependency parser (Appendix
Fig. 19). The results in the prefrontal cortex seem
to concur with the observations of Grodzinsky and
Friederici (2006) and Kaan and Swaab (2002) who
have shown that Broca’s area (Brodmann areas 44
and 45) has higher brain activation while process-
ing complex sentences. Since narrative listening
also involves processing highly complex sentences,
consistent activation found in Left Brodmann ar-
eas 44 and 45 may relate to parsing of sentences
or to see if they had distinct meanings. The right
hemisphere activation in the language network (AG,
ATL, PTL, IFG, MFG, IFGOrb, PCC, and dMPFC)
on the whole seems to be associated with basic syn-
tactic features such as word length, word frequency,
word count as embodied in CM representations. In
linguistic studies, INC has been shown to be effec-
tive in checking if sentences with different syntax,
have the same or different meaning. This in line
with our observation that representations from INC
parser seem to be more related to language regions
(inferior frontal gyrus, IFG) in the right hemisphere
as shown in Fig. 19.

Overall, Grodzinsky and Friederici (2006) con-
cluded that syntax processing is not limited to spe-
cific regions (left IFG or Broca’s area). Along with

IFG, other regions such as PTL, ATL, MFG, and IF-
GOrb are also involved in different stages of syntax
processing (Oota et al., 2022c). Our results (Fig. 2)
also seem to support distributed representation of
syntax across the language network. Moreover, our
results clearly show the kind of syntax encoded by
these individual ROIs.

7 Conclusion
We studied the relative importance of multiple con-
stituency and dependency syntax parsing methods
for fMRI prediction for the listening task. We find
that (1) both CC and DEP are effective; CC is more
important than CI, (2) CC is better in temporal
cortex and MFG, while DEP is better in AG and
PCC, (3) while BERT embeddings seem to be the
most effective, syntactic embedding methods also
explain additional variance for a few ROIs. In line
with previous works, we find that syntax and se-
mantic processing is spread across multiple brain
areas.

8 Limitations

Although these experiments were performed on
only one dataset, it is indeed large with data from
82 participants. That said, it will be nice to perform
experiments with more listening datasets.

We experiment with a linear encoder – Ridge
regression. We plan to experiment with more com-
plex encoders as part of future work.

This work was done on data related to English
stories only. Several other languages belong to the
same language family as English (Malik-Moraleda
et al., 2022). While we can expect the insights

AGATLPTLIFGMFGIFGOrbPCCdMPFC05101520253035{CC,CI}-{CC}{CC,CI}-{CI}{CC,DEP}-{CC}{CC,DEP}-{DEP}{CI,DEP}-{CI}{CI,DEP}-{DEP}{BERT,CC}-{BERT}{BERT,CI}-{BERT}{BERT,DEP}-{BERT}% of Significant VoxelsLEFT HEMISPHEREAGATLPTLIFGMFGIFGOrbPCCdMPFC051015202530% of Significant VoxelsRIGHT HEMISPHEREand learnings to hold across languages in the same
language family as English, empirical validation
needs to be done. For languages in other language
families, syntactic structure may be very different
from English. Hence, more work needs to be done
to check which of these insights hold for datasets
in other language families.

This work was conducted on a dataset where
the participants were involved in the listening task.
However, the stimuli was represented in the text
form. We believe that an audio form of the stimuli
can lead to improved insights. Thus, more work
needs to be done to design representations (like
prosodic features) for auditory stimuli.

9 Ethical Statement

We did not create any new fMRI data as part
of
this work. We used Narratives-Pieman
dataset which is publicly available without
any restrictions.
Narratives dataset can be
dowloaded from https://datasets.datalad.
org/?dir=/labs/hasson/narratives.
Please
read their terms of use4 for more details.

We do not foresee any harmful uses of this tech-

nology.

References

Khai Loong Aw and Mariya Toneva. 2023. Training
language models to summarize narratives improves
brain alignment. In The Eleventh International Con-
ference on Learning Representations.

Cordell M Baker, Joshua D Burks, Robert G Briggs,
Andrew K Conner, Chad A Glenn, Kathleen N Tay-
lor, Goksel Sali, Tressie M McCoy, James D Bat-
tiste, Daniel L O’Donoghue, et al. 2018. A con-
nectomic atlas of the human cerebrum—chapter 7:
the lateral parietal lobe. Operative Neurosurgery,
15(suppl\_1):S295–S349.

Douglas K Bemis and Liina Pylkkänen. 2011. Simple
composition: A magnetoencephalography investiga-
tion into the comprehension of minimal linguistic
phrases. Journal of Neuroscience, 31(8):2801–2814.

Yoav Benjamini and Yosef Hochberg. 1995. Control-
ling the false discovery rate: a practical and pow-
erful approach to multiple testing. Journal of the
Royal statistical society: series B (Methodological),
57(1):289–300.

Shohini Bhattasali, John Hale, Christophe Pallier,
Jonathan Brennan, Wen-Ming Luh, and R Nathan

4https://datasets.datalad.org/labs/hasson/

narratives/stimuli/README

Spreng. 2018. Differentiating phrase structure pars-
ing and memory retrieval in the brain. Proceedings of
the Society for Computation in Linguistics, 1(1):74–
80.

Jeffrey R Binder, Lisa L Conant, Colin J Humphries,
Leonardo Fernandino, Stephen B Simons, Mario
Aguilar, and Rutvik H Desai. 2016. Toward a brain-
based componential semantic representation. Cogni-
tive neuropsychology, 33(3-4):130–174.

Idan Blank, Zuzanna Balewski, Kyle Mahowald, and
Evelina Fedorenko. 2016. Syntactic processing is
distributed across the language system. Neuroimage,
127:307–323.

Ted Briscoe. 1996. The syntax and semantics of punctu-
ation and its use in interpretation. In Proceedings of
the Association for Computational Linguistics Work-
shop on Punctuation, pages 1–7. Citeseer.

Alfonso Caramazza and Edgar B Zurif. 1976. Dissoci-
ation of algorithmic and heuristic processes in lan-
guage comprehension: Evidence from aphasia. Brain
and language, 3(4):572–582.

Charlotte Caucheteux, Alexandre Gramfort, and Jean-
Remi King. 2021a. Disentangling syntax and seman-
tics in the brain with deep networks. In International
Conference on Machine Learning, pages 1336–1348.
PMLR.

Charlotte Caucheteux, Alexandre Gramfort, and Jean-
Remi King. 2021b. Model-based analysis of brain
activity reveals the hierarchy of language in 305 sub-
jects. In Findings of the Association for Computa-
tional Linguistics: EMNLP 2021, pages 3635–3644.

Laurent Cohen, Philippine Salondy, Christophe Pallier,
and Stanislas Dehaene. 2021. How does inattention
affect written and spoken language processing? cor-
tex, 138:212–227.

Rutvik H Desai, Usha Tadimeti, and Nicholas Riccardi.
2023. Proper and common names in the semantic
system. Brain Structure and Function, 228(1):239–
254.

Jacob Devlin, Ming-Wei Chang, Kenton Lee, and
Kristina Toutanova. 2019. Bert: Pre-training of deep
bidirectional transformers for language understand-
ing. In Proceedings of the 2019 Conference of the
North American Chapter of the Association for Com-
putational Linguistics: Human Language Technolo-
gies, Volume 1 (Long and Short Papers), pages 4171–
4186.

Irene-Anna N Diakidoy, Polyxeni Stylianou, Christina
Karefillidou, and Panayiota Papageorgiou. 2005. The
relationship between listening and reading compre-
hension of different types of text at increasing grade
levels. Reading psychology, 26(1):55–80.

Evelina Fedorenko, Idan Asher Blank, Matthew Siegel-
man, and Zachary Mineroff. 2020. Lack of selectivity
for syntax relative to word meanings throughout the
language network. Cognition, 203:104348.

Evelina Fedorenko, Alfonso Nieto-Castanon, and Nancy
Kanwisher. 2012. Lexical and syntactic representa-
tions in the brain: an fmri investigation with multi-
voxel pattern analyses. Neuropsychologia, 50(4):499–
513.

Shailee Jain and Alexander G Huth. 2018. Incorporating
context into language encoding models for fmri. In
Proceedings of the 32nd International Conference
on Neural Information Processing Systems, pages
6629–6638.

Evelina Fedorenko and Sharon L Thompson-Schill.
2014. Reworking the language network. Trends
in cognitive sciences, 18(3):120–126.

Angela D Friederici. 2011. The brain basis of language
processing: from structure to function. Physiological
reviews, 91(4):1357–1392.

Angela D Friederici, Christian J Fiebach, Matthias
Schlesewsky, Ina D Bornkessel, and D Yves Von Cra-
mon. 2006. Processing linguistic complexity and
grammaticality in the left frontal cortex. Cerebral
Cortex, 16(12):1709–1717.

Christopher R Genovese. 2000. A bayesian time-course
model for functional magnetic resonance imaging
data. Journal of the American Statistical Association,
95(451):691–703.

Matthew F Glasser, Timothy S Coalson, Emma C
Robinson, Carl D Hacker, John Harwell, Essa Ya-
coub, Kamil Ugurbil, Jesper Andersson, Christian F
Beckmann, Mark Jenkinson, et al. 2016. A multi-
modal parcellation of human cerebral cortex. Nature,
536(7615):171–178.

Yosef Grodzinsky and Angela D Friederici. 2006. Neu-
roimaging of syntax and syntactic processing. Cur-
rent opinion in neurobiology, 16(2):240–246.

Giacomo Handjaras, Emiliano Ricciardi, Andrea Leo,
Alessandro Lenci, Luca Cecchetti, Mirco Cosottini,
Giovanna Marotta, and Pietro Pietrini. 2016. How
concepts are encoded in the human brain: a modality
independent, category-based cortical organization of
semantic knowledge. Neuroimage, 135:232–242.

David G Hays. 1964. Dependency theory: A formalism
and some observations. Language, 40(4):511–525.

Graeme Hirst. 1984. A semantic process for syntactic

disambiguation. In AAAI, pages 148–152.

Nora Hollenstein, A de la Torre, Nicolas Langer, and
Ce Zhang. 2019. Cognival: A framework for cogni-
tive word embedding evaluation. In Proceedings of
The SIGNLL Conference on Computational Natural
Language Learning 2019.

Matthew Honnibal and Ines Montani. 2017. spaCy 2:
Natural language understanding with Bloom embed-
dings, convolutional neural networks and incremental
parsing. To appear.

Colin Humphries, Jeffrey R Binder, David A Medler,
and Einat Liebenthal. 2006. Syntactic and semantic
modulation of neural activity during auditory sen-
tence comprehension. Journal of cognitive neuro-
science, 18(4):665–679.

Ganesh Jawahar, Benoît Sagot, and Djamé Seddah.
2019. What does bert learn about the structure of
language? In ACL 2019-57th Annual Meeting of the
Association for Computational Linguistics.

Wha-Young Jung. 1995. Syntaktische Relationen im
Rahmen der Dependenzgrammatik, volume 9. Buske
Verlag.

Edith Kaan and Tamara Y Swaab. 2002. The brain
circuitry of syntactic comprehension. Trends in cog-
nitive sciences, 6(8):350–356.

Amanda LeBel, Shailee Jain, and Alexander G Huth.
2021. Voxelwise encoding models show that cerebel-
lar language representations are highly conceptual.
Journal of Neuroscience, 41(50):10341–10355.

Jouni Luoma and Sampo Pyysalo. 2020. Exploring
cross-sentence contexts for named entity recognition
with bert. In Proceedings of the 28th International
Conference on Computational Linguistics, pages 904–
914.

Saima Malik-Moraleda, Dima Ayyash, Jeanne Gallée,
Josef Affourtit, Malte Hoffmann, Zachary Mineroff,
Olessia Jouravlev, and Evelina Fedorenko. 2022. An
investigation across 45 languages and 12 language
families reveals a universal language network. Na-
ture Neuroscience, 25(8):1014–1019.

Christopher D Manning, Mihai Surdeanu, John Bauer,
Jenny Rose Finkel, Steven Bethard, and David Mc-
Closky. 2014. The stanford corenlp natural language
processing toolkit. In Proceedings of 52nd annual
meeting of the association for computational linguis-
tics: system demonstrations, pages 55–60.

William Matchin and Gregory Hickok. 2020. The
cortical organization of syntax. Cerebral Cortex,
30(3):1481–1498.

Gabriele Merlin and Mariya Toneva. 2022.

Lan-
guage models and brain alignment: beyond word-
arXiv preprint
level semantics and prediction.
arXiv:2212.00596.

Camille K Milton, Vukshitha Dhanaraj, Isabella M
Young, Hugh M Taylor, Peter J Nicholas, Robert G
Briggs, Michael Y Bai, Rannulu D Fonseka, Jorge
Hormovas, Yueh-Hsin Lin, et al. 2021. Parcellation-
based anatomic model of the semantic network.
Brain and behavior, 11(4):e02065.

Samuel A Nastase, Yun-Fei Liu, Hanna Hillman, Asieh
Zadbood, Liat Hasenfratz, Neggin Keshavarzian, Jan-
ice Chen, Christopher J Honey, Yaara Yeshurun, Mor
Regev, et al. 2021. The “narratives” fmri dataset for
evaluating models of naturalistic language compre-
hension. Scientific data, 8(1):1–22.

Subba Reddy Oota, Frederic Alexandre, and Xavier
Hinaut. 2022a. Long-term plausibility of language
models and neural dynamics during narrative listen-
ing. In Proceedings of the Annual Meeting of the
Cognitive Science Society, volume 44.

Subba Reddy Oota, Jashn Arora, Veeral Agarwal,
Mounika Marreddy, Manish Gupta, and Bapi Suram-
pudi. Neural language taskonomy: Which nlp tasks
are the most predictive of fmri brain activity? In
Proceedings of the 2022 Conference of the North
American Chapter of the Association for Computa-
tional Linguistics: Human Language Technologies,
pages 3220–3237.

Subba Reddy Oota, Jashn Arora, Vijay Rowtula, Man-
ish Gupta, and Raju S Bapi. 2022b. Visio-linguistic
In Proceedings of the 29th Inter-
brain encoding.
national Conference on Computational Linguistics,
pages 116–133.

Subba Reddy Oota, Manish Gupta, and Mariya Toneva.
Joint processing of linguistic properties
arXiv preprint

2022c.
in brains and language models.
arXiv:2212.08094.

Subba Reddy Oota, Naresh Manwani, and Raju S Bapi.
2018. fMRI Semantic Category Decoding Using Lin-
guistic Encoding of Word Embeddings. In Interna-
tional Conference on Neural Information Processing,
pages 3–15. Springer.

Subba Reddy Oota, Khushbu Pahwa, Mounika
Marreddy, Manish Gupta, and Bapi S Raju. 2023.
Neural architecture of speech. In ICASSP 2023-2023
IEEE International Conference on Acoustics, Speech
and Signal Processing (ICASSP), pages 1–5. IEEE.

Christophe Pallier, Anne-Dominique Devauchelle, and
Stanislas Dehaene. 2011. Cortical representation of
the constituent structure of sentences. Proceedings
of the National Academy of Sciences, 108(6):2522–
2527.

Jeffrey Pennington, Richard Socher, and Christopher D
Manning. 2014. Glove: Global vectors for word rep-
resentation. In Proceedings of the 2014 conference
on empirical methods in natural language processing
(EMNLP), pages 1532–1543.

Owen Rambow. 2010. The simple truth about depen-
dency and phrase structure representations: An opin-
ion piece. In Human language technologies: The
2010 annual conference of the North American Chap-
ter of the Association for Computational Linguistics,
pages 337–340.

Aniketh Janardhan Reddy and Leila Wehbe. 2021. Can
fmri reveal the representation of syntactic structure
in the brain? Advances in Neural Information Pro-
cessing Systems, 34.

Brian Roark. 2001. Probabilistic top-down parsing
and language modeling. Computational linguistics,
27(2):249–276.

Corianne Rogalsky and Gregory Hickok. 2009. Se-
lective attention to semantic and syntactic features
modulates sentence processing networks in anterior
temporal cortex. Cerebral Cortex, 19(4):786–796.

Donald L Rubin, Teresa Hafer, and Kevin Arata.
2000. Reading and listening to oral-based versus
literate-based discourse. Communication Education,
49(2):121–133.

Gerold Schneider. 1998. A linguistic comparison of
constituency, dependency and link grammar. Ph.D.
thesis, Master’s thesis, University of Zürich.

Mariya Toneva, Tom M Mitchell, and Leila Wehbe.
2022. Combining computational controls with natu-
ral text reveals aspects of meaning composition. Na-
ture Computational Science, 2(11):745–757.

Mariya Toneva, Otilia Stretcu, Barnabás Póczos, Leila
Wehbe, and Tom M Mitchell. 2020. Modeling task
effects on meaning representation in the brain via
zero-shot meg prediction. Advances in Neural Infor-
mation Processing Systems, 33:5284–5295.

Mariya Toneva, Jennifer Williams, Anand Bollu,
Christoph Dann, and Leila Wehbe. 2021. Same
cause; different effects in the brain. In First Con-
ference on Causal Learning and Reasoning.

Shikhar Vashishth, Manik Bhandari, Prateek Yadav,
Piyush Rai, Chiranjib Bhattacharyya, and Partha P
Talukdar. 2019. Incorporating syntactic and semantic
information in word embeddings using graph convo-
lutional networks. In ACL (1).

Shaonan Wang, Jiajun Zhang, Nan Lin, and Chengqing
Zong. 2020. Probing brain activation patterns by
dissociating semantics and syntax in sentences. In
Proceedings of the AAAI Conference on Artificial
Intelligence, volume 34, pages 9201–9208.

Leila Wehbe, Brian Murphy, Partha Talukdar, Alona
Fyshe, Aaditya Ramdas, and Tom Mitchell. 2014.
Simultaneously uncovering the patterns of brain re-
gions involved in different story reading subpro-
cesses. PloS one, 9(11):e112575.

Emiliano Zaccarella and Angela D Friederici. 2015.
Merge in the human brain: A sub-region based func-
tional investigation in the left pars opercularis. Fron-
tiers in psychology, 6:1818.

Xiaohan Zhang, Shaonan Wang, Nan Lin, Jiajun Zhang,
and Chengqing Zong. 2022. Probing word syntactic
representations in the brain by a feature elimination
method. In AAAI.

A Hyper-parameter Settings

All experiments were conducted on a machine with
1 NVIDIA GEFORCE-GTX GPU with 16GB GPU
RAM. We used banded ridge-regression with fol-
lowing parameters: MSE loss function, and L2-
decay (λ) varied from 10−1 to 10−3; best λ was

chosen by tuning on validation data; number of
cross-validation runs was 4.

B Constituency Complete Trees

We now present the largest subtrees completed by
a few of the words in the sentence: “I began my
illustrious career as a hard-boiled reporter in the
Bronx where I toiled for the Ram, uh, Fordham
University’s student newspaper”.

(a) I

(b) began

Figure 6: Complete trees for the words: I, began, and Bronx, for the sentence “I began my illustrious career as a
hard-boiled reporter in the Bronx where I toiled for the Ram, uh, Fordham University’s student newspaper.”

(c) Bronx

Figure 7: Incomplete trees for the word: I, for the sentence “I began my illustrious career as a hard-boiled reporter
in the Bronx where I toiled for the Ram, uh, Fordham University’s student newspaper.”

Figure 8: Performance of Individual Embedding Methods: Region of Interest (ROI) analysis of the prediction
performance of various feature sets. For each model, we show R2 score. Each bar represents the average score and
error bars show standard error across 82 subjects. Left hemisphere (Top) and Right hemisphere (Bottom)

Figure 9: Performance of Individual Embedding Methods for AG region: Region of Interest (ROI) analysis of
the prediction performance of various feature sets for various sub-regions. For each model, we show the % of ROI
voxels with a significant increase in prediction performance. Each bar represents the average score and error bars
show standard error across 82 subjects. Left hemisphere (Top) and Right hemisphere (Bottom)

AGATLPTLIFGMFGIFGOrbPCCdMPFC00.020.040.060.080.1{PU}{CM}{PD}{CC}{CI}{INC}{DEP}{BERT}Avg R 2 ScoreAGATLPTLIFGMFGIFGOrbPCCdMPFC00.020.040.060.080.1{PU}{CM}{PD}{CC}{CI}{INC}{DEP}{BERT}Avg R 2 ScorePFmPGsPGiTPOJ2TPOJ3010203040{PU}{CM}{PD}{CC}{CI}{INC}{DEP}{BERT}% of Significant VoxelsPFmPGsPGiTPOJ2TPOJ30102030405060% of Significant VoxelsFigure 10: Performance of Individual Embedding Methods for ATL region: Region of Interest (ROI) analysis of
the prediction performance of various feature sets for various sub-regions. For each model, we show the % of ROI
voxels with a significant increase in prediction performance. Each bar represents the average score and error bars
show standard error across 82 subjects. Left hemisphere (Top) and Right hemisphere (Bottom)

Figure 11: Performance of Individual Embedding Methods for PTL region: Region of Interest (ROI) analysis of
the prediction performance of various feature sets for various sub-regions of PTL region. For each model, we show
the % of ROI voxels with a significant increase in prediction performance. Each bar represents the average score
and error bars show standard error across 82 subjects. Left hemisphere (Top) and Right hemisphere (Bottom)

STGaTGdTE1aTE2aTGvSTSdaSTSva0102030405060708090100{PU}{CM}{PD}{CC}{CI}{INC}{DEP}{BERT}% of Significant VoxelsSTGaTGdTE1aTE2aTGvSTSdaSTSva01020304050607080% of Significant VoxelsSTSdpA5TPOJ1PSLSTVSTSvp0102030405060708090100{PU}{CM}{PD}{CC}{CI}{INC}{DEP}{BERT}% of Significant VoxelsSTSdpA5TPOJ1PSLSTVSTSvp0102030405060708090100% of Significant VoxelsFigure 12: Performance of Individual Embedding Methods for IFG region: Region of Interest (ROI) analysis of
the prediction performance of various feature sets for various sub-regions of IFG region. For each model, we show
the % of ROI voxels with a significant increase in prediction performance. Each bar represents the average score
and error bars show standard error across 82 subjects. Left hemisphere (Top) and Right hemisphere (Bottom).

Figure 13: Performance of Individual Embedding Methods for IFGOrb region: Region of Interest (ROI)
analysis of the prediction performance of various feature sets for various sub-regions of IFGOrb region. For each
model, we show the % of ROI voxels with a significant increase in prediction performance. Each bar represents the
average score and error bars show standard error across 82 subjects. Left hemisphere (Top) and Right hemisphere
(Bottom).

4445IFJaIFSp01020304050607080{PU}{CM}{PD}{CC}{CI}{INC}{DEP}{BERT}% of Significant Voxels4445IFJaIFSp0102030405060708090% of Significant Voxelsa47rp47ra9-46v010203040506070{PU}{CM}{PD}{CC}{CI}{INC}{DEP}{BERT}% of Significant Voxelsa47rp47ra9-46v010203040% of Significant VoxelsFigure 14: Performance of Individual Embedding Methods for PCC region: Region of Interest (ROI) analysis
of the prediction performance of various feature sets for various sub-regions of PCC region. For each model, we
show the % of ROI voxels with a significant increase in prediction performance. Each bar represents the average
score and error bars show standard error across 82 subjects. Left hemisphere (Top) and Right hemisphere (Bottom).

Figure 15: Performance of Individual Embedding Methods for dmPFC region: Region of Interest (ROI) analysis
of the prediction performance of various feature sets for various sub-regions of dmPFC region. For each model, we
show the % of ROI voxels with a significant increase in prediction performance. Each bar represents the average
score and error bars show standard error across 82 subjects. Left hemisphere (Top) and Right hemisphere (Bottom).

31PCV7m23RSC01020304050{PU}{CM}{PD}{CC}{CI}{INC}{DEP}{BERT}% of Significant Voxels31PCV7m23RSC0102030405060% of Significant Voxels9m10dd3201020304050{PU}{CM}{PD}{CC}{CI}{INC}{DEP}{BERT}% of Significant Voxels9m10dd320102030% of Significant VoxelsFigure 16: Additional Predictive Power of various Representations for various sub-regions of Angular Gyrus
(AG) region. For each model, we show the percentage of ROI voxels in which we see a significant increase in
prediction performance. Each bar represents the average percentage across 82 subjects, and the error bars show the
standard error across subjects. ‘-’ indicates a hypothesis test for the difference in R2 scores between the two feature
groups being larger than 0. Left hemisphere (Top) and Right hemisphere (Bottom).

Figure 17: Additional Predictive Power of various Representations for various sub-regions of Anterior
Temporal Lobe (ATL) region. For each model, we show the percentage of ROI voxels in which we see a significant
increase in prediction performance. Each bar represents the average percentage across 82 subjects, and the error
bars show the standard error across subjects. ‘-’ indicates a hypothesis test for the difference in R2 scores between
the two feature groups being larger than 0. Left hemisphere (Top) and Right hemisphere (Bottom).

PFmPGsPGiTPOJ2TPOJ305101520253035404550{PU}{CM,PU}-{PU}{PD,CM,PU}-{CM,PU}{CC,PD,CM,PU}-{PD,CM,PU}{CI,PD,CM,PU}-{PD,CM,PU}{INC,PD,CM,PU}-{PD,CM,PU}{DEP,PD,CM,PU}-{PD,CM,PU}{BERT,CC,PD,CM,PU}-{CC,PD,CM,PU}{BERT,CI,PD,CM,PU}-{CI,PD,CM,PU}{BERT,INC,PD,CM,PU}-{INC,PD,CM,PU}{BERT,DEP,PD,CM,PU}-{DEP,PD,CM,PU}% of Significant VoxelsPFmPGsPGiTPOJ2TPOJ305101520253035% of Significant VoxelsSTGaTGdTE1aTE2aTGvSTSdaSTSva051015202530{PU}{CM,PU}-{PU}{PD,CM,PU}-{CM,PU}{CC,PD,CM,PU}-{PD,CM,PU}{CI,PD,CM,PU}-{PD,CM,PU}{INC,PD,CM,PU}-{PD,CM,PU}{DEP,PD,CM,PU}-{PD,CM,PU}{BERT,CC,PD,CM,PU}-{CC,PD,CM,PU}{BERT,CI,PD,CM,PU}-{CI,PD,CM,PU}{BERT,INC,PD,CM,PU}-{INC,PD,CM,PU}{BERT,DEP,PD,CM,PU}-{DEP,PD,CM,PU}% of Significant VoxelsSTGaTGdTE1aTE2aTGvSTSdaSTSva05101520% of Significant VoxelsFigure 18: Additional Predictive Power of various Representations for various sub-regions of Posterior
Temporal Lobe (PTL) region. For each model, we show the percentage of ROI voxels in which we see a significant
increase in prediction performance. Each bar represents the average percentage across 82 subjects, and the error
bars show the standard error across subjects. ‘-’ indicates a hypothesis test for the difference in R2 scores between
the two feature groups being larger than 0. Left hemisphere (Top) and Right hemisphere (Bottom).

Figure 19: Additional Predictive Power of various Representations for various sub-regions of Inferior Frontal
Gyrus (IFG) region. For each model, we show the percentage of ROI voxels in which we see a significant increase
in prediction performance. Each bar represents the average percentage across 82 subjects, and the error bars show
the standard error across subjects. ‘-’ indicates a hypothesis test for the difference in R2 scores between the two
feature groups being larger than 0. Left hemisphere (Top) and Right hemisphere (Bottom).

STSdpA5TPOJ1PSLSTVA4STSvp051015202530354045505560{PU}{CM,PU}-{PU}{PD,CM,PU}-{CM,PU}{CC,PD,CM,PU}-{PD,CM,PU}{CI,PD,CM,PU}-{PD,CM,PU}{INC,PD,CM,PU}-{PD,CM,PU}{DEP,PD,CM,PU}-{PD,CM,PU}{BERT,CC,PD,CM,PU}-{CC,PD,CM,PU}{BERT,CI,PD,CM,PU}-{CI,PD,CM,PU}{BERT,INC,PD,CM,PU}-{INC,PD,CM,PU}{BERT,DEP,PD,CM,PU}-{DEP,PD,CM,PU}% of Significant VoxelsSTSdpA5TPOJ1PSLSTVA4STSvp051015202530354045505560% of Significant Voxels4445IFJaIFSp051015{PU}{CM,PU}-{PU}{PD,CM,PU}-{CM,PU}{CC,PD,CM,PU}-{PD,CM,PU}{CI,PD,CM,PU}-{PD,CM,PU}{INC,PD,CM,PU}-{PD,CM,PU}{DEP,PD,CM,PU}-{PD,CM,PU}{BERT,CC,PD,CM,PU}-{CC,PD,CM,PU}{BERT,CI,PD,CM,PU}-{CI,PD,CM,PU}{BERT,INC,PD,CM,PU}-{INC,PD,CM,PU}{BERT,DEP,PD,CM,PU}-{DEP,PD,CM,PU}% of Significant Voxels4445IFJaIFSp051015% of Significant VoxelsFigure 20: Additional Predictive Power of various Representations for various sub-regions of Inferior Frontal
Gyrus Orbital (IFGOrb) region. For each model, we show the percentage of ROI voxels in which we see a
significant increase in prediction performance. Each bar represents the average percentage across 82 subjects, and
the error bars show the standard error across subjects. ‘-’ indicates a hypothesis test for the difference in R2 scores
between the two feature groups being larger than 0. Left hemisphere (Top) and Right hemisphere (Bottom).

Figure 21: Additional Predictive Power of various Representations for various sub-regions of Posterior
Cingulate Cortex (PCC) region. For each model, we show the percentage of ROI voxels in which we see a
significant increase in prediction performance. Each bar represents the average percentage across 82 subjects, and
the error bars show the standard error across subjects. ‘-’ indicates a hypothesis test for the difference in R2 scores
between the two feature groups being larger than 0. Left hemisphere (Top) and Right hemisphere (Bottom).

a47rp47ra9-46v0510{PU}{CM,PU}-{PU}{PD,CM,PU}-{CM,PU}{CC,PD,CM,PU}-{PD,CM,PU}{CI,PD,CM,PU}-{PD,CM,PU}{INC,PD,CM,PU}-{PD,CM,PU}{DEP,PD,CM,PU}-{PD,CM,PU}{BERT,CC,PD,CM,PU}-{CC,PD,CM,PU}{BERT,CI,PD,CM,PU}-{CI,PD,CM,PU}{BERT,INC,PD,CM,PU}-{INC,PD,CM,PU}{BERT,DEP,PD,CM,PU}-{DEP,PD,CM,PU}% of Significant Voxelsa47rp47ra9-46v05101520% of Significant Voxels31PCV7m23RSC05101520253035404550{PU}{CM,PU}-{PU}{PD,CM,PU}-{CM,PU}{CC,PD,CM,PU}-{PD,CM,PU}{CI,PD,CM,PU}-{PD,CM,PU}{INC,PD,CM,PU}-{PD,CM,PU}{DEP,PD,CM,PU}-{PD,CM,PU}{BERT,CC,PD,CM,PU}-{CC,PD,CM,PU}{BERT,CI,PD,CM,PU}-{CI,PD,CM,PU}{BERT,INC,PD,CM,PU}-{INC,PD,CM,PU}{BERT,DEP,PD,CM,PU}-{DEP,PD,CM,PU}% of Significant Voxels31PCV7m23RSC0510152025303540455055% of Significant VoxelsFigure 22: Additional Predictive Power of various Representations for various sub-regions of Dorsal Medial
Prefrontal Cortex (dmPFC) region. For each model, we show the percentage of ROI voxels in which we see a
significant increase in prediction performance. Each bar represents the average percentage across 82 subjects, and
the error bars show the standard error across subjects. ‘-’ indicates a hypothesis test for the difference in R2 scores
between the two feature groups being larger than 0. Left hemisphere (Top) and Right hemisphere (Bottom).

9m10dd3205101520{PU}{CM,PU}-{PU}{PD,CM,PU}-{CM,PU}{CC,PD,CM,PU}-{PD,CM,PU}{CI,PD,CM,PU}-{PD,CM,PU}{INC,PD,CM,PU}-{PD,CM,PU}{DEP,PD,CM,PU}-{PD,CM,PU}{BERT,CC,PD,CM,PU}-{CC,PD,CM,PU}{BERT,CI,PD,CM,PU}-{CI,PD,CM,PU}{BERT,INC,PD,CM,PU}-{INC,PD,CM,PU}{BERT,DEP,PD,CM,PU}-{DEP,PD,CM,PU}% of Significant Voxels9m10dd32051015% of Significant Voxels