From biological to numerical experiments in systemic
neuroscience: a simulation platform
Nicolas Denoyelle, Maxime Carrere, Florian Pouget, Thierry Viéville, Frédéric

Alexandre

To cite this version:

Nicolas Denoyelle, Maxime Carrere, Florian Pouget, Thierry Viéville, Frédéric Alexandre. From bio-
logical to numerical experiments in systemic neuroscience: a simulation platform. A.R. Londral, P.
Encarnação. Advances in Neurotechnology, Electronics and Informatics, 12, Springer, 2015, Biosys-
tems & Biorobotics. ￿hal-01227968￿

HAL Id: hal-01227968

https://inria.hal.science/hal-01227968

Submitted on 12 Nov 2015

HAL is a multi-disciplinary open access
archive for the deposit and dissemination of sci-
entific research documents, whether they are pub-
lished or not. The documents may come from
teaching and research institutions in France or
abroad, or from public or private research centers.

L’archive ouverte pluridisciplinaire HAL, est
destinée au dépôt et à la diffusion de documents
scientifiques de niveau recherche, publiés ou non,
émanant des établissements d’enseignement et de
recherche français ou étrangers, des laboratoires
publics ou privés.

Distributed under a Creative Commons Attribution 4.0 International License

From biological to numerical experiments in
systemic neuroscience: a simulation platform

Nicolas Denoyelle12, Maxime Carrere123, Florian Pouget12, Thierry Vi´eville1 and
Fr´ed´eric Alexandre123

Key words: Simulation, Computational Neuroscience, Virtual Reality.

Abstract Studying and modeling the brain as a whole is a real challenge. For such
systemic models (in contrast to models of one brain area or aspect), there is a real
need for new tools designed to perform complex numerical experiments, beyond
usual tools distributed in the computer science and neuroscience communities. Here,
we describe an effective solution, freely available on line and already in use, to val-
idate such models of the brain functions. We explain why this is the best choice,
as a complement to robotic setup, and what are the general requirements for such
a benchmarking platform. In this experimental setup, the brainy-bot implementing
the model to study is embedded in a simpliﬁed but realistic controlled environment.
From visual, tactile and olfactory input, to body, arm and eye motor command, in ad-
dition to vital interoceptive cues, complex survival behaviors can be experimented.
We also discuss here algorithmic high-level cognitive modules, making the job of
building biologically plausible bots easier. The key point is to possibly alternate the
use of symbolic representation and of complementary and usual neural coding. As
a consequence, algorithmic principles have to be considered at higher abstract level,
beyond a given data representation, which is an interesting challenge.

1 Introduction

Computational neuroscience is often presented as a way to better understand the
complex relations between structures and functions in the brain. Particularly, these
relations are complex because they are not symmetrical: one stucture participates to
several functions and functions are distributed among many structures. This is an
important limitation against developping a model of a structure in isolation, which
is often the case in computational neuroscience. This is not sufﬁcient to emulate
one behavioral function, but participates only to studying some of its properties,
with the risk of neglecting the key inﬂuence of another structure on this function.

1 Inria Bordeaux Sud-Ouest, 200 Avenue de la Vieille Tour, 33405 Talence, France 2LaBRI, Uni-
versit´e de Bordeaux, Institut Polytechnique de Bordeaux, CNRS, UMR 5800, Talence, France
3Institut des Maladies Neurod´eg´en´eratives, Universit´e de Bordeaux, CNRS, UMR 5293, Bordeaux,
France e-mail: Frederic.Alexandre@inria.fr

1

2

Authors Suppressed Due to Excessive Length

Consequently, for modeling studies interested in integrative and behavioral neuro-
science and in the emulation of behavioral functions, this analysis is a plea for de-
signing brain models including many brain structures. In addition, in the framework
of studying behavioral functions, the brain must also be considered as a complex
system in interaction with the body and the environment. Two important conse-
quences can be drawn. The ﬁrst consequence is related to the model itself. Addi-
tional modules must be considered, to allow for the sensation and processing of
signals from the environment (exteroception) and also from the body (interocep-
tion). Designing such a network of brain structures and modules at the interface
with the outer and inner world includes not only understanding how each subsystem
(visual, motor, emotional, etc.) works but also how these subsystems interact as a
whole, to yield emerging behaviors, i.e. effects that result from interactions between
subsystems. The second consequence is related to the use of this complex system.
Studying and validating functional models of brain structures at a macroscopic be-
havioral scale cannot be performed with restrained artiﬁcial static paradigms but
requires experiments in complex environments, with realistic sensory-motor tasks
to be performed, including high-level interactive behaviors (e.g. survival strategy
in the presence of prey/predators) and long-term protocols (since both statistical
studies and biologically-plausible learning mechanisms require long epochs). Such
paradigms are to be related to biological experiments conducted on animals. These
statements are not only characterizing brain models working in interaction with their
environment, they also give strong requirements on the tools that must be designed
to simulate these models and to experiment them.

Designing such tools is also an excellent way to address at the same time the
two main objectives of such brain models at the macroscopic scale. One one hand,
they are intended to serve neuroscientists as a new platform of experimentation, on
which they can apply their classical protocols of observation and analysis of animals
at the behavioral as well as electrophysiological levels. It is consequently important
that neuroscientists can observe the inner activity of the models, as they use to do
for example with electrodes (but we can imagine that this observation in digital
models might be more easy than in the real brain). It is also important that they can
deﬁne classical behavioral protocols like they do in animals (eg. fear conditioning)
in order to observe the resulting behavior and the corresponding brain activation.
Deﬁning such protocols implies that the structure of the external world (e.g., maze,
food magazine) as well as its intrinsic rules (eg. tone followed by an electric shock)
should be easy to design.

On the other hand, these tools are also intended to serve computer scientists
as a way to design artiﬁcial autonomous systems, driven by brain models. In this
case, it is important for the supposed properties of the models (e.g., capacity to
learn, robustness to noise or changing rules) to be assessed by rigorous evaluation
procedures, as it is deﬁned for example in the domain of machine learning. In this
case also an easy access must be proposed both to the inner circuitry of the models
and to the speciﬁcation of the external world.

With in mind this double goal of offering convenient tools to both scientiﬁc com-
munities, we report in this paper the speciﬁcations that we have elaborated and

Title Suppressed Due to Excessive Length

3

present the corresponding software platform that we call VirtualEnaction. We also
introduce the case study of a behavioral function presently under study in our team,
pavlovian conditioning, as an illustration of the use of VirtualEnaction. Before that,
some more words must be said to justify the need for such a platform.

2 Problem position

Concerning the nature of such a simulator, real robotic systems are often used and
answer particularly well to the second requirement about a realistic environment.
However, building viable robotic systems and making them evolve in realistic en-
vironments (e.g. natural sites) for long periods of time (e.g. several days) is just
too expensive in term of cost and manpower in many circumstances and particu-
larly during early phases of development. Furthermore, the goal of such simulation
is not only to make a demo, but also, and more importantly, to study and quantify
the behavior of functional models of the brain. As a consequence we not only need
a complex, long-term, realistic experimental setup, but we also need a controllable
and measurable setup where stimuli can be tuned and responses can be measured. In
fact, real environment complexity and parameters are intrinsically difﬁcult when not
impossible to control. This is the reason why we propose to use a digital simulator
implementing realistic survival and other biological scenarios.

A step further, available macroscopic models of brain functions are not designed
for ”performance” but to properly implement phenomenological concepts that have
been investigated in some cognitive or behavioral framework. They would therefore
have ”no chance” in a real world. Note that recent computer science mechanisms
designed without any constraint regarding biological plausibility but only towards
ﬁnal performances are nowadays probably more efﬁcient but that are not relevant
regarding the brain behavior explanation.

As a consequence we also need a setup which can provide a “simpliﬁed environ-
ment”, for systemic models of the brain at the state of the art not to fail immediately.
We must also take into account the fact that (i) such models are rather slow to sim-
ulate (unless huge computer power is available), and that (ii) they are not supposed
to focus on precise issues regarding low-level sensory input or motor output but on
integrated cognitive functions and the resulting behaviors.

This, in addition to technical constraints, yields three key characteristics:

1. No real-time but a look-and-move paradigm : The main restriction we propose
is to have the simulator running at a “slower” time (i.e. using several seconds to
simulate one real-time second) and also to consider discrete time sampling. This
seems obvious as far as digital simulation is concerned, but in terms of underlying
framework, this has several consequences (e.g., giving up the possibility for a
human observer to interact with the simulation, restraining to clock-based (and
not event-based) dynamical models, etc.) [Taouali et al., 2011].

2. No real robotic control but only motor command : Since in the nervous system
motor control seems to be a hierarchical system with high-level motor com-

4

Authors Suppressed Due to Excessive Length

Fig. 1 Two examples of digital experimental environments for systemic neuroscience. Left: A
minimal environment corresponding to a standard maze reinforcement learning task (source: one
of our virtual enaction built). Right: A complex environment in which survival capabilities are to
be checked (source: landscape encountered when playing with the standard game).

mands, while their closed loop execution is delegated to the peripheral motor
system [Uithol et al., 2012], we may accept to only simulate gesture and dis-
placement at a rather symbolic level such as “stand-up” or “turn 90◦ rightward”.
This indeed cancels the possibility to study sharp phenomena of motor interac-
tions with the environment but allows us to concentrate on high-level control
such as action selection mechanism and motor planning.

3. Complex but not necessarily natural visual environment: The third main restric-
tion we propose to accept is to consider a complex visual environment (with
visual textures, several objects in motion, etc.) but not to invest in the simulation
of a realistic natural scene simulation. The reason of this choice is that natu-
ral image vision is an issue already well studied [Hyv¨arinen, 2009]. The general
conclusion is that biological visual systems are tuned to natural image statistics,
decomposed by the early visual front-end in such a way that higher-level visual
input only relates on cues orthogonal (in a wide sense) to natural image statistics.
In other words, the job regarding this aspect is done by early-vision layers and
we may consider more stylistic visual cues at a higher-level. Depending on the
study, we may also wish to work on either a pixelic or a symbolic representation
of the visual scene. See [Teftef et al., 2013] for details of how the early-visual
system implements such dual representation.

3 System description

We consider that a “brainy-bot”, i.e. the implementation of a global model of the
brain functionalities, interacts with its environment with the simple goal of surviv-
ing. Our objective is to simulate the sensory-motor interactions of this bot with
respect to its environment. Examples of such surroundings are shown in Fig. 1.

Survival is precisely deﬁned as maintaining vital variable values in correct
ranges, as formalized in, e.g., [Friston, 2012]. In our context, health, food, water,
energy, and oxygen are the vital state variables. The bot has access to these values.
These variables decrease or increase with time since the bot body is supposed to

Title Suppressed Due to Excessive Length

5

consume the related resource depending on its activity, or change in the presence
of an external event (e.g. energy during a predator attack), and restore resources.
Restoring resources is obtained either by ingesting items or taking rest (i.e., when
making the choice of stopping an action, with the beneﬁt of vital resource increase
and the drawback of not acting on the environement, this might be a short-term pol-
icy choice if vital variables are low and is a middle-term policy choice otherwise).
The environment structure is very simple and made of “blocks”. Each object in
this environment (including the ﬂoor, relief, ..) is a collection of blocks. Each block
is deﬁned by its 3D position, orientation and size, roughness, hardness, temperature,
and color. Some blocks correspond to eatable or drinkable resources. Other entities
correspond to objects that interact with the bot (e.g. predators that attack the bot or
lava to avoid). At this level, survival corresponds to avoid or kill the predators and
ﬁnd resources to eat or drink.

The bot anatomy is functionally made of a body, an arm and an head/eye. It
carries a bag with objects found in its environment. The body can move at a given
speed and in a given direction, and also rotate at each step to a given angle. It can
also jump up to a given relative height, or knee down to take a rest. The head/eye
can gaze in a given yaw/pitch direction. The arm can perform predeﬁned symbolic
gestures : take an object in hand out of its bag, put the object in hand into its bag,
either drop or throw the object in hand, ingest the block in hand (food or water),
grasp the object in front of him. The arm can also attack (quantiﬁed by a force value
and with or without an object in hand) the object in front of him. This is the complete
description of the bot motor command output in the present context.

The bot sensory input corresponds to cues related to the blocks which are around
it. The touch cues allow the bot to estimate the roughness, hardness and temperature
of the object in hand. The olfactory cues allow to estimate the smell type and inten-
sity of objects close to it (computed by integrating average values over the blocks
characteristics). At the bot level, pixelic vision provides an image of the visual ﬁeld
view (i.e., calculating the blocks texture and color projection on the virtual retina).
Finally, the proprioceptive cues correspond to gaze direction estimation.

In order to quantify the bot behavior, the interface provides an additional ac-
cess to the bot absolute position and orientation in space. Symbolic vision is also
available, as a list of blocks visible in its visual ﬁeld, with an access to the block
characteristics.

Fig. 2 Left: The software interface is trivial: each implementation of a brainy-bot provides an ini-
tialization routine initBot() and a stop function stopCondition(), while at each time-step
the brainDo() method is called. Right: All status, input and output functionalities are available
via a simple API. For instance, hand or vital input, body and head displacement, gestures of re-
source injection and attack against predator are shown.

6

Authors Suppressed Due to Excessive Length

An adaptation of the minecraft open game software yields the proper answer
to this wish-list and the so called virtualenaction is an open-source free-
license implementation of these speciﬁcations. Each user buys a end-user low-cost
mojang license (< 20$) for minecraft, while virtualenaction is free of
use under a CeCILL-C license. Fully-documented scripts facilitate the installation
of the software bundle under Linux OS. The bot is implemented in either C/C++, or
possibly in Python (via an existing swig wrapper) or other computer languages.
It uses a simple API, as described in Fig. 2. Furthermore, in order to both observe
in slow-down real-time the bot behavior and interact with the digital experiment, a
graphic user interface is available as described in Fig. 4. The simple architecture of
the platform is schematized in Fig. 3.

Fig. 3 The platform architecture. At the user level, only the notion of (i) game server where the
environment and its mobile objects interactions are computed, (ii) game client where the game-
play is rendered and (iii) brainy-bot where the brain model simulation is issued have to be taken
into account.

4 Brainy-bot generic functionality

Even when restraining to functional modeling, it is not possible to simulate all sub-
systems of the brain at the same level of details. We thus must represent parts of
the system with efﬁcient models, but without biologically plausible models. A few
sets of generic functionalities are to be proposed to this end. Let us discuss three of
them.

-1- Associative memory Any system has not only to take into account the present
input and output in order to generate a proper behavior, but also to store and recall
past information. Information is however never exactly the same and similar pieces
of information (i.e., being almost equal up to a given threshold) have to be consid-
ered as a unique item. Such a memory must not only store and retrieve information,
but also deﬁne a notion of indistinguishable information.

Title Suppressed Due to Excessive Length

7

In our context this has a special meaning: the input/output information corre-
sponds to a hierarchical logical-structure1, mixing quantitative and qualitative in-
formation2, and using3 structures like set or sequence, in addition to t-uples as con-
tainers. More precisely:

@action: {

life: { stop: @bool },
body: { translation: { speed: @percent, direction: @degree }, orientation: , rest: @bool },
head: { vertical: @percent, horizontal: @percent },
attack: { strongness: @percent },
jump: { height: @percent },
gesture: { touch: @bool, ingest: @bool, throw: @bool, climb: @bool },
hand: { put: { slot: @index }, get: { slot: @index }, count: @count }

},
@sensation: {

location: { position: @position, orientation: { yaw: @degree, pitch: @degree} },
vital: { health: @percent, food: @percent, water: @percent, oxygen: @percent, energy: @percent},
vision: { blocks: [ @block\* ], entities: [ @block\* ] },
touch: { blocks: [ @block\* ], entities: [ @block\* ] },
hand: { roughness: @percent, hardness: @percent, item: @item },
olfaction: { intensity: @percent, toxicity: @percent, friendliness: @percent, edibleness: @percent },
inventory: [ @item\* ]

},
@block: {
id: @index,
position: @position, roughness: @percent, hardness: @percent, temperature: @percent, color: @color
},
@item: {
id: @index, count: @count, slot: @index
},
@position: {
x: @real, y: @real, z: @real

Notion of divergence. As a consequence, it is not obvious to deﬁne a “distance”
between to such state values (i.e. the whole input/output data structure). But this is
required to decide if they are distinguishable or not. Our claim is that the correct
notion is the notion of premetric4 or divergence4, for two state values s1 and s2:

d(s1, s2) ≥ 0 and d(s1, s2) = 0 ⇔ s1 = s2

as being the weakest concept that allows to state that two values are distinguishable
if and only if d(s1, s2) ≥ ε > 0, for some threshold ε. It appears that all premetrics
we need are always symmetric (i.e., it is a semimetric4). In our context, the diver-
gence corresponds to a Euclidean distance for a position, angular distance for
an orientation, while the divergence between two t-uples is simply deﬁned as
the weighted sum between each t-uple values divergence, for a given set of weights,
while the divergence with respect to a undeﬁned value must be deﬁned for this def-
inition to be coherent. At this stage, divergence computation is linear with respect
to the state structure size. The introduction of dissimilarity computation of t-uples
is the cause of being in the context of a semimetric and not a complete metric with
the triangle inequality veriﬁed.

1 Such a structure is of common use in computer science: It corresponds to, e.g., a XML logical-
structure, or the Json syntax underlying data model.
2 The following scalar values are used: bool for an either true or false Boolean value, percent
for a proportion value between 0 and 1, degree for an angle in degree, index stands for a non-
negative integer index, count stands for a non-negative integer count value, color stands for a
RGB color value, real stands for a unbounded decimal value.
3 Sets are unordered lists without repetition, Sequences are sequential lists, and t-uples map strings,
or names, to their corresponding value.
4 Deﬁnition available on https://en.wikipedia.org

8

Authors Suppressed Due to Excessive Length

A step further, we need pairing4 divergence between two unsorted sequences
(i.e., it corresponds to the classical “stable marriage problem”4). This tool is re-
quired to deﬁne how two sets of blocks (e.g., for symbolic vision input) match, in
order, e.g., to recognize a visual object. This pairing is not a distance in the general
case.

We also need to deﬁne an edit distance (a generalization of the Levenshtein4
distance, called the Victor-Purpura4 metric) to deﬁne how two temporal sequences
match.

Both pairing and edit divergence can be implemented as algorithms quadratic

with respect to the set or sequence size.

Let us also mention that informing the bot about its absolute position and orienta-
tion or about symbolic information of the scene, as it is the case, is a way to shortcut
its localization and sensory modules and provide integrated cognitive information,
without considering the related computational issues.

With this set of tools, the mechanism of associative memory of state values is
entirely speciﬁed, and it must be pointed out that since the space of states has no
special structure the algorithms allowing to retrieve a value in the memory (namely
the closest value whose divergence with respect to the input value is minimal), or
insert a new value (if not already in the memory in an indistinguishable form), or
delete it, can not have less than a complexity of O(memory-size), since hash-coding
is not compatible with retrieving a similar value.

-2- State Categorization A generic key cognitive feature is the capability to “extract”
symbolic information from a bundle of quantitative or qualitative values. During a
supervised learning phase prototypes of state values with the corresponding known
category are registered. Then, for an incoming state the most plausible category
is calculated. Such mechanism includes sensory events detection (e.g., detect the
presence of predator from sensory cues), object labeling (e.g., an element as a re-
source to ingest): Such examples are qualitative values. A biologically plausible
support vector machine4 mechanism is available to this end, with versatile uses
[Vi´eville and Crahay, 2004]. This also includes quantitative values (e.g., associate
a reward to a given sensation or action), and support vector machines also include
the capability to categorize using a ﬂoating point value.

In our case, the issue is the following: If a simple nearest neighbor mechanism
(i.e., the category of an incoming state value is set (or interpolated) using the cate-
gory of the nearest neighbor (or neighbors)) is used, then the notion of divergence
introduced before is sufﬁcient. However, such a mechanism is known as being the
worst in term of generalization (i.e., inferring correctly the category for incoming
state value not corresponding to the prototypes) and robustness (i.e., providing reli-
able results even if some spurious prototypes).

Notion of gradient. In order to introduce a better mechanism of categorization
that will optimize a criterion, we need to deﬁne the notion of gradient, i.e., small
variation of a given state value. One impediment is the fact that some variables are
discrete variables. In the present case, index and count are not to be optimized,
thus remain ﬁxed. Boolean variables bool however correspond to effective choices

Title Suppressed Due to Excessive Length

9

or meaningful information, and must be taken into account. As a consequence, we
would have to deal with the combinatory complexity of discrete values optimization,
known as NP-hard. To overcome this caveat, we simply propose to embed each
b = bool value in bounded v = [0, 1] value, with the obvious correspondence:

v = if b then 1 else 0;

v = b > 0.5

With these speciﬁcation choices, given a state s we can deﬁne a small variation ∂ s as
small variations of all quantitative scalar values (namely real, color, degree,
percent and bool represented by a [0, 1] value). Given a state criterion, i.e., a real
value function of the state, we can optimize this criterion with respect to quantitative
values. This construction implicitly maps a state to a N-dimensional real space of
the different quantitative variables. This is not exactly an Euclidean space since
real value like color or angle lies in some non-Euclidean metric spaces, but usual
differential methods can be used.

Following the method in [Vi´eville and Crahay, 2004] that simply requires opti-
mization with respect to the prototypes state value (and contrary to the original SVM
algorithm that proceed in a dual space, which we can not deﬁne here since we do not
have a concrete metric) we thus can improve the raw nearest neighbor mechanism,
by eliminating or merging useless prototypes, and modifying prototypes values to
maximize the margin between classes. It must be understood that this method will
not (i) perform qualitative optimization (e.g., will not ﬁnd that we must add or delete
a block to represent an object) and (ii) is sub-optimal since we reuse a well-founded
method in a context where not all assumptions are veriﬁed.

- -3- Gesture interpolation: At a functional level a “behavior” (i.e., a complex ges-
ture) can be speciﬁed as ﬁnding a path from an initial state (e.g., being hungry while
food is known to be present elsewhere) to a ﬁnal state (e.g., having the food in-
gested) taking constraints into account (e.g., avoiding or moving aside obstacles
on the way). Generic speciﬁcation of such problem and universal algorithms to
solve them exist, in relation with harmonic control which is a biologically plausible
framework (i.e., with fully distributed computation based on diffusion mechanism)
[Vi´eville and Vadot, 2006]. This also corresponds to the fact that, in the motor cor-
tex, a motor command is represented by its ﬁnal state or “end point”, while the
trajectory generation to attain this ﬁnal state is generated elsewhere.

In order to deﬁne such a mechanism we simply need the notion of state diver-
gence and state gradient introduced previously. Obstacle to avoid is simply deﬁned
by constraints (e.g. real value function of the state that must remain, say, positive).
The goal is attained when the divergence to the ﬁnal state is below the indistin-
guishability threshold. The algorithm proposed in [Vi´eville and Vadot, 2006] builds
harmonic potential, here in the real space on which the state quantitative variables
are mapped. It requires the operation of projection (of a state onto a constraint) to
deﬁne a repulsive point, and such algorithm reduces to an optimization problem,
implementable thanks to our different design choices.

10

Authors Suppressed Due to Excessive Length

Though we present the simplest aspect of this class of methods, harmonic control
is easily linked to optimal control [Connolly and Grupen, 1993], in link with rein-
forcement learning considering a non-ﬁnite realistic state-space [Todorov, 2004].

As a conclusion, this section has analyzed to which extent some powerful generic
machine learning techniques can be reused in this context and adapted to the sym-
bolic hierarchical data structure deﬁning the bot input and output. The two main
ideas are to use a weaker notion of distance and accept adaptation mechanism of
the state restrained to quantitative values. Further developing the link with machine-
learning algorithms applied on such data structure in order to deﬁne high level al-
gorithmic ersatz of cognitive functions is a perspective of this work.

5 Neuroscience application

Fig. 4 The software’s graphic user interface. In order to observe and control the experiment, a
view of the bot vision, status, input and output is available via interactive panels. It is also possible
to “cheat” by controlling these variables values, in order to debug an experiment and understand in
details what happens in such a complex system interaction.

Let us now discuss how this setup constitutes a step towards integrative neuro-

science digital experimentation.

First of all, let us compare this project with complementary connected projects.
The AnimatLab is a software platform allowing to simulate embodiment (bio-
mechanical simulation of a body) allowing to investigate the relation between brain
and body [Cofer et al., 2010]. Furthermore, it proposes a neural network architec-
ture for the implementation of cognitive functions. On the contrary, the present
framework has a rather limited description of the embodiment, but a much larger
set of possible interactions with the environment. A step further, not only artiﬁcial
neural network models are usable in VirtualEnaction, whereas the interface with

Title Suppressed Due to Excessive Length

11

any existing neuroscience simulation tool (e.g., python based neural simulators, see
[Brette et al., 2007, Davison et al., 2008]) is straightforward. This feature is essen-
tial, since we must simulate the system at different modeling scales, as developed
now. The Morse is a generic simulator for academic robotics, with realistic 3D simu-
lation of small to large environments, allowing complete integration with any simu-
lation tools. It outperforms concurrent systems like Webot. The interest of VirtualE-
naction with respect to Morse is twofold: Since we target integrative cognitive tasks
of survival which is exactly what happens with the Minecraft environment, using
this specialized product is far simpler and somehow more demonstrative. In terms
of performances, as being less sophisticated (using a simpliﬁed 3D rendering, while
Morse has all 3D capabilities) and being agnostic in terms of programming lan-
guages (i.e., allowing fast C/C++ implementation of user modules, whereas Morse
is limited to Python scripts) the VirtualEnaction platform is a priori expected to be
more efﬁcient in terms of CPU usage. However, with a larger humanpower all what
has been developed within VirtualEnaction could have been developed in Morse.

The main application regarding neuroscience is to test cognitive computational
models in realistic conditions. Very simply, a behavioral experiment is performed
on an animal model or on humans, usually with a training phase, the measurement
phase and the data analysis. In order to formalize the obtained result a computational
model is proposed that explains the data, and may also have prediction regarding
other falsiﬁable future experiments. The present software and methodological tool
allow us to propose to enhance this very general paradigm in the following direc-
tions:

• Test the model prediction for several others experimental conditions or model
parameter ranges : The idea is to reproduce the experimental setup in this virtual
environment (e.g., a delayed reward task, an exploration paradigm) and connect
the computational model to this paradigm. As for usual computational modeling,
the chosen biological measurements (e.g. neural activity, task success perfor-
mance) are simulated when running the model. Such model is indeed expected
to reproduce qualitatively the ground truth, for a given set of parameters val-
ues. A step further, it is very important to numerically verify what happens when
modifying any quantitative or qualitative parameter value. If the numerical sen-
sibility is so strong that the results cannot be reproduced for some tiny parameter
variation, the model is meaningless because biological values make sense as a
numerical range, not a single number. If the numerical sensibility is so weak that
any parameter value produces the expected result, this parameter is meaningless
and a simpler model very likely explains the same data set. The key-point here
is that such predictive veriﬁcation is not only going to be possible, given a ﬁxed
data set, but for any data set obtained during virtual environment simulations.
In other words, the computational model variants are going to be always tested
in-situ. With no practical bounds on the experimental variants (e.g., number of
trials, sensory input precision, task complexity).

• Design new experimental paradigms to confront the computational model to fal-
siﬁable conditions : Building an experiment considering an animal model, train-
ing the animals for weeks, restarting from the beginning if it appears that there

12

Authors Suppressed Due to Excessive Length

is an unexpected trap (e.g., the task is too simple or unfeasible, or does not al-
low to discriminate between two concurrent models) may be a huge work. Start-
ing to design the experiment in a virtual environment completely changes the
method: the hypothesized computational model is ﬁrst tested in silico (i.e., nei-
ther in vivo, nor in vitro, but in a software environment) and only confronted to
the biological reality in a second stage. The workplan is inverted with respect
to usual neuroscience studies, but in computational engineering (e.g., designing
new airplanes) this is exactly the way it goes until a few decades. It is however
not new in neuroscience, at the scale of mesoscopic brain map study (see e.g.,
[Chemla et al., 2007] or [Brette et al., 2007]). The key point here is that such ap-
proach is now possible at the behavioral level, considering sensory-motor interac-
tions with a simple or complex environment. Such process also obviously yields
a parsimonious use of animal models. A step further, it lays down the challenge
of performing realistic experiment with a computational model of the brain be-
havior and not only considering toy situations where the plausibility of the model
can not be checked.

6 Case study: pavlovian conditioning

The degree of equivalence between simulation outcome and neuroscience experi-
mental results is a key issue. This is the reason why we have chosen a software
platform where usual behavioral neuroscience experiments can be reproduced “as
a whole”. Such classical experiments include pavlovian and operant conditioning,
spatial navigation with tasks involving the focus of attention and multi-sensory in-
tegration and other high level cognitive functions involving working memory and
planning. The main brain structures involved in such tasks are the thalamus and
posterior cortex for sensory processing, the basal ganglia system for selection of ac-
tion and decision, the hippocampus for episodic memory and the prefrontal cortex
for the temporal organization of behavior. Depending on the task, other more spe-
cialized structures like the amygdala, cerebellum, superior colliculus, hypothalamus
and others may also be considered. These tasks are often related to fundamental sur-
vival programs (nurishment, reproduction, integrity of the body) and are organized
towards goals, deﬁned from the environment (acquiring appetitive goals or avoiding
noxious ones) or from the body (satisfying internal needs), which endows them with
a strong behavioral ecological anchoring.

As an illustration, we introduce pavlovian conditioning, presently studied in our
team, including the integration of related computational models in VirtualEnaction.
Pavlovian conditioning is a fundamental learning capability, allowing to identify
aversive and appetitive events in the environment and also exploited in many com-
plex tasks. This learning relies on the ability of animals to automatically detect
biologically signiﬁcant stimuli (also called US, unconditional stimuli) and to trigger
corresponding reﬂexes. Pavlovian learning occurs when a neutral stimulus (condi-
tioned stimulus, CS) reliably predicts the occurrence of the US. After acquisition,

Title Suppressed Due to Excessive Length

13

the CS presented alone will also trigger a response and allows the animal to antic-
ipate the nature of the US to come. For example, in the case of fear conditioning
[Herry et al., 2008], the US can be an electric shock automatically triggering freez-
ing. Subsequently to the pairing of the US with a CS like the auditory perception of
a tone, the CS alone will evoke freezing. It will also allow the animal to anticipate
the nature of the US and prepare more adapted behavior like an escape, depending
on the nature of the task and the environment.

Fear conditioning has been extensively studied because in its basic forms, it in-
volves a rather simple and well know cerebral circuit, associated to accessible stim-
uli in the environment. The amygdala is the key structure for the acquisition and
expression of fear conditioning [LeDoux, 2007]. Its lateral nucleus receives extero
and interoceptive information from the thalamus and the sensory cortex and is re-
ported to perform the acquisition of CS-US associations and to activate its central
nucleus, a motor structure responsible for the expression of pavlovian responses.

This simple associative learning has also been studied because beyond its simple
expression, it demonstrates non trivial characteristics. For example, the CS can be
more complex than a simple tone, because it includes a temporal structure (delays)
or speciﬁc spatial characteristics like the context of learning (the room in which con-
ditioning occurs) or the composition of several stimuli (compound stimuli). In this
case, the sensory cortex is not able to supply the information in an adapted conﬁg-
uration and the hippocampus has been shown to be necessary for the acquisition of
this CS-US association, through its projections to the basal nucleus of the amygdala
[Eichenbaum et al., 2012]. The involvement of the hippocampus is not really sur-
prising here, since this structure is known for its role in episodic learning, another
kind of associative learning of arbitrary relations between features including spatial
and temporal contexts [Rolls, 2010].

Learning CS-US association can also become more complex when the associa-
tion is not deterministic but can vary in time. This can be due to stochasticity (the
association is probabilistic) and also to changes in the rules of our dynamic and
changing world, as it is observed in the case of extinction [Herry et al., 2008]. Ex-
periments in neuroscience have shown that when a predicted US no longer occurs,
this does not correspond to the removal of the learned CS-US association but to
its temporary inhibition by the medial prefrontal cortex, learning history of perfor-
mance in behavior. Particularly, this means that, in the case of renewal (the old rule
becomes valid again), reacquisition of the CS-US association is immediate because
it was not forgotten but only inhibited.

Pavlovian conditioning is also studied for its impact, at a systemic level, on other
kinds of learning in the brain. Without going too deep in details, it can be mentioned
that sucesses and errors of US prediction have also a deep impact on episodic learn-
ing in the hippocamus and on perceptive category learning in the sensory cortex and
also in operant conditioning. It must be also underlined that stimuli learned by the
pavlovian procedure are often re-used as goals in operant conditioning.

This short overview of pavlovian conditioning was only meant to indicate that
behavioral sequences related to this kind of learning can be studied at different lev-
els of complexity, which is the case in neuroscience, depending on the context of

14

Authors Suppressed Due to Excessive Length

the experiment. Accordingly, our VirtualEnaction platform must adapt to these con-
texts. In its simplest form, the environment includes simple sensory CS and US and
the body must express stereotyped avoidance or attraction movements. In this case,
our brainy-bot integrates a model of the amygdala as we can ﬁnd in the literature
or as we developed in the team. In more complex cases, we might for example take
into account the spatial context in which the CS is perceived, which requires to in-
tegrate a functionality like episodic memory. In this case, we can integrate a generic
functionality of symbolic information manipulation as described in section 4 or a
more advanced neuronal model of the hippocampus, depending on the aspects that
are to be more deeply studied in relation to biological experiments. The principle
would be the same for integrating a model of the medial prefrontal cortex or a sim-
ple statistical analysis of the recent history of received and predicted US, in case of
an experiment related to an extinction procedure.

In addition to the design of the system adapted to the task under study, another
critical step is about the design of the scenarios to be tested. Here, scenario stands
for the description of the environment (stimuli and their perceptual dimensions, con-
texts like a cage or a maze), of the laws ruling this environment (which stimulus is a
US and triggers an unconditional response; which stimulus is a CS and how reliably
it predicts the US; and other physical laws of the environment like objects that can
be moved) and of the precise timing of sequence of events (deﬁning protocols im-
plementing acquisition, extinction and renewal procedures). In its most basic form,
such a design is generally thought to ﬁt biological experiments and will be used for
the purpose of comparison with behavioral performances as well as with patterns of
neuronal population activation and learning. In a more advanced form, this system
could be also exploited on the side of computer science, either in terms of perfor-
mance of learning, to be evaluated in a machine learning perspective, or in terms of
autonomous agent, to be evaluated with regard to the range of available behaviors
and to the pertinence of their selection. Implementing not only pavlovian condition-
ing but also operant conditioning is a strong prerequisite for this latter perspective,
as the authors are presently considering.

7 Discussion

In this paper, we have presented the platform VirtualEnaction, for implementing
brain models and their bodily and external environment. Beyond the description
of the functionalities of the platform, we have also explained why it was corre-
sponding to a need in the behavioral and computational neuroscience community.
We have illustrated these elements with a case study related to an important class
of learning, from a behavioral point of view. Indeed, let us mention that this plat-
form has already been used for preliminary digital experiments about Pavlovian
conditioning [Gorojosky and Alexandre, 2013] involving the functional modeling
of the amygdala and hippocampus, decision making mechanisms in link with rein-
forcing signals yielded by aversive or appetitive stimuli and internal computation

Title Suppressed Due to Excessive Length

15

[Beati et al., 2013], plus a student work of the AGREL connectionist categorization
model here confronted to a realistic environment [Carrere and Alexandre, 2013].

Building one “brainy-bot” is a rather huge task and requires several high-level
cognitive functionalities. However, though systemic neuroscience requires to study
the system as a whole, it does not imply that each functionality has to be studied
at the same level of details. Several blocks may be considered as black-boxes inter-
acting with the part of the system to be extensively studied. This is the reason why
the present platform is not limited to a survival environment, but comes also with
middleware (presently in development) related to the basic cognitive functionality
involved in such paradigms [Denoyelle et al., 2014]. Some modules will thus be
implemented according to a rough description, e.g., via an algorithmic ersatz. The
nervous sub-system under study on the reverse, is going to be implemented at a very
ﬁne scale (neural network mesoscopic models or even spiking neural networks).

The key features of this digital experimentation platform include the capabil-
ity to perform experiments involving both long-term continuous time paradigms or
short-term decision tasks with a few time-steps. It also allows us to consider either
symbolic motor command or sensory input (e.g., ingest or not food, detect the pres-
ence of a stimulus) or quantitative gestures and complex trajectory generation (e.g.,
ﬁnd resources in an unknown environment). A key point is to be able to mimic and
repeat at will experiments performed in neuroscience laboratory on animals. Here,
the obtained computational models are not only going to “ﬁt the data” but to be ex-
plored far beyond, yielding the possibility to study long-term adaptation, statistical
robustness, etc. Not only one instance of a bot can be checked, but several parallel
experiments can be run in order to explore different parameter ranges, or compare
alternative models.

Beyond these basic features, the input and output can be easily manipulated in
order to enlarge the experimental setup. Up to now, the main aspect is “input or
output degradation”, i.e. adding noise. Originally, bot perception and action are per-
formed without any added noise or random mistake. Depending on the experiment
to be conducted, it is obvious (i.e. inserting a few lines of code between the plat-
form and the bot), either to reduce variables precision range (e.g., add noise to the
pixelic image) or to randomly draw the fact that a gesture may succeed or fail (e.g.,
introduce spurious command).

A step further, as already implemented as plugins, since all environment elements
are available (not to the bot, but to the experiment software), it would be possible
to design other cues, or more generally other interactions with the environment.
However, in collaboration with neuroscience experimentalists, we have carefully
selected what seems useful to explore biological systemic models, and avoided to
provide a too general tool that does anything.

It would also be instructive to better understand to which extent such bio-inspired
architectures actually required to control a biological system could enhance artiﬁcial
control rules commonly applied in robotics or game engines. This is a challenging
issue, beyond the present study, but an interesting perspective of the present work.

Acknowledgments Huge thanks to Nicolas Rougier for precious advice.

16

References

Authors Suppressed Due to Excessive Length

Beati et al., 2013. Beati, T., Carrere, M., and Alexandre, F. (2013). Which reinforcing signals in
autonomous systems? In Third International Symposium on Biology of Decision Making, Paris,
France.

Brette et al., 2007. Brette, R., Rudolph, M., Carnevale, T., Hines, M., Beeman, D., Bower, J. M.,
Diesmann, M., Morrison, A., Goodman, P. H., Harris, F. C., Zirpe, M., Natschl¨ager, T., Pecevski,
D., Ermentrout, B., Djurfeldt, M., Lansner, A., Rochel, O., Vieville, T., Muller, E., Davison, A. P.,
El Boustani, S., and Destexhe, A. (2007). Simulation of networks of spiking neurons: a review
of tools and strategies. Journal of computational neuroscience, 23(3):349–398.

Carrere and Alexandre, 2013. Carrere, M. and Alexandre, F. (2013). ´Emergence de cat´egories par
interaction entre syst`emes d’apprentissage. In Preux, P. and Tommasi, M., editors, Conf´erence
Francophone sur l’Apprentissage Automatique (CAP), Lille, France.

Chemla et al., 2007. Chemla, S., Chavane, F., Vieville, T., and Kornprobst, P. (2007). Biophysical

cortical column model for optical signal analysis. BMC Neuroscience, 8(Suppl 2):P140.

Cofer et al., 2010. Cofer, D., Cymbalyuk, G., Reid, J., Zhu, Y., Heitler, W. J., and Edwards, D. H.
(2010). AnimatLab: a 3D graphics environment for neuromechanical simulations. Journal of
neuroscience methods, 187(2):280–288.

Connolly and Grupen, 1993. Connolly, C. I. and Grupen, R. A. (1993). The applications of har-

monic functions to robotic. Journal of Robotic Systems, 10(7):931–946.

Davison et al., 2008. Davison, A. P., Br¨uderle, D., Eppler, J., Kremkow, J., Muller, E., Pecevski,
D., Perrinet, L., and Yger, P. (2008). PyNN: A Common Interface for Neuronal Network Simu-
lators. Frontiers in neuroinformatics, 2.

Denoyelle et al., 2014. Denoyelle, N., Pouget, F., Vi´eville, T., and Alexandre, F. (2014). Vir-
tualEnaction: A Platform for Systemic Neuroscience Simulation. In International Congress on
Neurotechnology, Electronics and Informatics, Rome, Italy.

Eichenbaum et al., 2012. Eichenbaum, H., Sauvage, M., Fortin, N., Komorowski, R., and Lipton,
P. (2012). Towards a functional organization of episodic memory in the medial temporal lobe.
Neurosci Biobehav Rev., 36(7):1597–1608.

Friston, 2012. Friston, K. (2012). A Free Energy Principle for Biological Systems. Entropy,

14(11):2100–2121.

Gorojosky and Alexandre, 2013. Gorojosky, R. and Alexandre, F. (2013). Models of Hippocam-

pus for pavlovian learning. Rapport de recherche RR-8377, INRIA.

Herry et al., 2008. Herry, C., Ciocchi, S., Senn, V., Demmou, L., Muller, C., and Luthi, A. (2008).

Switching on and off fear by distinct neuronal circuits. Nature, 454(7204):600–606.

Hyv¨arinen, 2009. Hyv¨arinen, A. (2009). Natural image statistics a probabilistic approach to early

computational vision. Hardcover.

LeDoux, 2007. LeDoux, J. (2007). The amygdala. Current Biology, 17(20):R868–R874.
Rolls, 2010. Rolls, E. T. (2010). A computational theory of episodic memory formation in the

hippocampus. Behav Brain Res, 215(2):180–96.

Taouali et al., 2011. Taouali, W., Vi´eville, T., Rougier, N. P., and Alexandre, F. (2011). No clock

to rule them all. Journal of physiology, Paris, 105(1-3):83–90.

Teftef et al., 2013. Teftef, E., Escobar, M.-J., Astudillo, A., Carvajal, C., Cessac, B., Palacios,
A., Vi´eville, T., and Alexandre, F. (2013). Modeling non-standard retinal in/out function using
computer vision variational methods. Rapport de recherche RR-8217, INRIA.

Todorov, 2004. Todorov, E. (2004). Optimality principles in sensorimotor control. Nature Neuro-

science, 7(9).

Uithol et al., 2012. Uithol, S., van Rooij, I., Bekkering, H., and Haselager, P. (2012). Hierarchies

in action and motor control. Journal of cognitive neuroscience, 24(5):1077–1086.

Vi´eville and Crahay, 2004. Vi´eville, T. and Crahay, S. (2004). Using an Hebbian learning rule for

multi-class SVM classiﬁers. Journal of Computational Neuroscience.

Vi´eville and Vadot, 2006. Vi´eville, T. and Vadot, C. (2006). An improved biologically plausible

trajectory generator. Technical Report 4539-2, INRIA.

