Intelligence artificielle et singularité Nicolas P. Rougier

To cite this version:

Nicolas P. Rougier. Intelligence artificielle et singularité.
Hypermondes #01 Robots, , 2021, 978-2- 36183-749-5. ￿hal-03452067￿

HAL Id: hal-03452067

https://inria.hal.science/hal-03452067

Submitted on 26 Nov 2021

HAL is a multi-disciplinary open access archive for the deposit and
dissemination of sci- entific research documents, whether they are pub-
lished or not. The documents may come from teaching and research
institutions in France or abroad, or from public or private research
centers.

L’archive ouverte pluridisciplinaire HAL, est destinée au dépôt et à la
diffusion de documents scientifiques de niveau recherche, publiés ou
non, émanant des établissements d’enseignement et de recherche français
ou étrangers, des laboratoires publics ou privés.

Intelligence ar,ﬁcielle et singularité Nicolas P. Rougier Cet ar2cle
est une version étendue de textes ini2alement parus sur les sites
Inters2ces et The Conversa2on.

Les origines. L’intelligence ar2ﬁcielle, ou IA, est oﬃciellement née en
1956 lors d’une conférence à Dartmouth (USA). Même si les recherches ont
de fait commencé dès l’après-guerre (par exemple le « Test de Turing »
en 1950), ceUe conférence est historique en ce qu’elle a rassemblé en un
même lieu presque toutes les ﬁgures embléma2ques de l’IA, notamment John
McCarthy, mathéma2cien, Herbert Simon, théoricien des organisa2ons,
Allen Newell, mathéma2cien, Claude Shannon, père de la théorie de
l’informa2on et Marvin Minsky, mathéma2cien. Ces pionniers rêvaient
alors de construire des machines pouvant égaler voire surpasser
l’intelligence humaine, sur la base des nouveaux moyens de l’informa2que
naissante. C’était un projet d’une ambi2on folle, puisque, à ceUe
époque, tout restait à faire. Or, malgré les immenses diﬃcultés qui se
trouvaient devant eux, ces chercheurs, aidés d’autres scien2ﬁques, vont
rapidement obtenir des résultats qui ﬁrent date dans l’histoire de
l’informa2que.

Ainsi, dès 1955, Newell et Simon conçoivent un programme (Logic theorist
ou logicien théoriste en français) qui permet de démontrer
automa2quement 38 des 52 théorèmes du traité Principia Mathema2ca
d’Alfred North Whitehead et Bertrand Russell (1913). C’est un résultat
majeur et extrêmement impressionnant pour l’époque, puisque pour la
première fois, une machine est capable de raisonnement. On considère
légi2mement ce programme comme la toute première intelligence ar2ﬁcielle
de l’histoire. Quelques années plus tard, Newell et Simon généralisent
ceUe approche et concevoir le GPS — General Problem Solver (solveur
universel) — qui permet de résoudre n’importe quel type de problème,
pour peu que l’on puisse le spéciﬁer formellement à la machine. À ceUe
même époque, d’autres chercheurs défrichent les domaines de la traduc2on
automa2que, de la robo2que, de la théorie des jeux, de la vision, etc.
Jusqu’au milieu des années 1970, l’intelligence ar2ﬁcielle est
extrêmement proliﬁque et engendre un nombre considérable de résultats.
Mais elle va bientôt être vic2me de ses folles promesses originelles. En
eﬀet, si des avancées extraordinaires ont

été réalisées, les chercheurs sont encore très loin d’avoir résolu le
problème général de l’intelligence. Ils se rendent compte qu’ils ont été
un peu trop op2mistes, à l’exemple de Marvin Minsky qui aﬃrmait en 1970
que « Dans trois à huit ans nous aurons une machine avec l’intelligence
générale d’un être humain ordinaire » (cita2on rapportée par Brad
Darrach dans le magazine Life en 1970,). On parle de ce coup d’arrêt
comme du premier hiver de l’IA. Mais avec l’arrivée des systèmes experts
et la résolu2on du problème de l’appren2ssage dans les réseaux de
neurones ar2ﬁciels, l’IA connaît un second souﬄe jusqu’à la ﬁn des
années 1990 où, de nouveau, tout s’arrête ou presque pour à peu près les
mêmes raisons. Le lecteur intéressé pourra se référer au très joli texte
de Dominique Cardon, Jean-Philippe Cointet et Antoine Mazières « La
revanche des neurones » pour un historique un plus complet.

Deep Blue vs. Kasparov. Il aura fallu aUendre 1997, pour enﬁn lire ces
quelques lignes dans le journal « L’Humanité » du 13 mai 1997 :

Kasparov mis en échec par Deep Blue. […] le super-ordinateur d’IBM a
vaincu le champion du monde […] en gagnant dimanche soir la sixième et
dernière par2e de leur choc. […] Le grand maître électronique s’impose
3-1/2 à 2-1/2 face au meilleur des humains et devient surtout le premier
ordinateur à l’emporter sur un champion du monde dans une rencontre
classique.

Avec presque trente ans de retard, la prophé2e de Newell et Simon s’est
réalisée (« d’ici dix ans un ordinateur sera le champion du monde des
échecs »), l’automate joueur d’échec d’Ambrose Bierce (Le maître de
Moxon, 1899) était devenu réel. Les objec2fs de l’intelligence
ar2ﬁcielle auraient-ils été ﬁnalement aUeints ? Serions-nous capables de
concevoir des machines intelligentes et omnipotentes ?

La réponse est non. S’il est eﬀec2vement possible aujourd’hui de baUre
n’importe quel humain aux échecs, au Go ou au Poker, il reste
impossible, par exemple, de faire jouer un robot au football contre un
quelconque adversaire humain, quand bien même les scien2ﬁques y
travaillent en organisant des compé22ons des matches de football entre
robots (la Robocup) dont le but à terme est de faire jouer les robots
contre des humains. Le football ne peut pourtant prétendre rivaliser en
ﬁnesse et en intelligence avec le jeu des échecs. Mais comment peut-on
baUre le champion du monde des échecs et se trouver en même temps
incapable de jouer au football ? CeUe situa2on paradoxale s’explique par
la diversité d’interpréta2on de la no2on d’intelligence. En eﬀet,
l’intelligence que l’on veut prêter à Deep Blue est ici fondée sur le
calcul, l’analyse et le raisonnement (courant symbolique de l’IA).
Depuis le Discours de la méthode de Descartes, le courant de pensée des
ra2onalistes, mené par Descartes, Spinoza et Leibniz, a voulu croire à
ceUe intelligence, une intelligence fondée sur l’esprit et la raison,
équivalente à l’intelligence humaine. À l’opposé, le courant de pensée
des empiristes (courant connexioniste de l’IA), parmi lesquels Bacon,
Locke, Berkeley et Hume, prôna la prise en compte de l’expérience
sensible du monde et rejeta l’idée de la connaissance réduite à l’esprit
et à la raison.

la naissance de

Ainsi, dès l’IA, deux courants de pensée vont coexister plus ou moins
paciﬁquement. Un premier courant, symbolique, considère la machine comme
un système de manipula2on de symboles qui peut être u2lisé pour
manipuler des représenta2ons formelles du monde. Il est fondé sur la
logique, se faisant ainsi l’héri2er des ra2onalistes. Sa philosophie
peut se résumer à la volonté de construire un esprit (« making a mind
»). Mené par Allen Newell et Herbert Simon, ce courant symbolique s2pule
que l’intelligence repose sur la no2on de symbole. Le deuxième courant,
connexionniste, considère en revanche la machine comme un support de la
modélisa2on du cerveau, oﬀrant les capacités nécessaires pour simuler
les interac2ons entre les neurones. Il s’appuie sur le domaine des
sta2s2ques et sa philosophie peut se résumer à la volonté de modéliser
le cerveau (« modelling the brain »). Ce courant connexionniste, mené
entre autres par Frank RosenblaU, propose une vision numérique du
traitement de l’informa2on et s’oppose en cela à l’hypothèse symboliste.

La victoire de Deep Blue sur Kasparov représente le paroxysme de
l’approche symbolique. En eﬀet, le jeu d’échecs est un très beau
problème de nature symbolique, où il faut en substance déplacer des
pièces sur des cases pour aUeindre un but précis (échec et mat). La plus
grande diﬃculté est l’explosion combinatoire, lorsque le programme
souhaite prédire des séquences de coups. Cependant,

grâce à des algorithmes très ingénieux, à la force brute, à la rapidité
de calcul et une bibliothèque d’ouvertures bien fournie, Deep Blue a pu
prédire plus de coups à l’avance que ce qu’il est humainement possible
de faire. Deep Blue est-il intelligent au sens commun du terme ? A
priori non, c’est simplement un logiciel qui joue aux échecs et ne fait
que cela.

Certains n’ont pas été réellement surpris par ce résultat. Ainsi Rodney
Brooks écrivait dès 1990 un ar2cle au 2tre un peu curieux, « Les
éléphants ne jouent pas aux échecs ». Ce qu’il voulait expliquer alors,
c’était que les éléphants ont une certaine intelligence — ils doivent se
nourrir, trouver des points d’eau, se reproduire, fuir les prédateurs,
etc. — mais n’ont a priori pas besoin de manipuler des symboles
abstraits pour le faire. C’est de fait une cri2que assez sévère du
courant symbolique de l’IA, que l’on désigne aussi par le terme GOFAI («
Good Old Fashion Ar2ﬁcial Intelligence », la bonne vieille intelligence
ar2ﬁcielle). Or, nous savons aujourd’hui que ce courant de l’IA ne
pourra pas résoudre le problème de l’intelligence générale à cause du
problème de l’ancrage du symbole notamment. En eﬀet, comment meUre en
rela2on les symboles avec les objets qu’ils désignent ? Comment faire le
lien entre un verre, le mot, et un verre, l’objet physique que je vois
posé sur la table ? Autant cela est évident pour nous humains, autant
cela reste un déﬁ pour une machine qui n’a jamais soif et qui n’a pas de
corps pour manipuler l’objet. C’est pourquoi ceUe théorie de la cogni2on
incarnée a émergé dès les années 1990, en meUant en avant le rôle du
corps dans la cogni2on et son intelligence propre.

Un cerveau + un corps. Si vous possédez un animal domes2que, par exemple
un chien ou un chat, regardez-le aUen2vement et vous aurez alors un bon
aperçu de tout ce qu’on ne sait pas faire en intelligence ar2ﬁcielle… «
Mais mon chat ne fait rien de la journée à part dormir, manger et se
laver », pourriez-vous me répondre. Et pourtant votre chat sait marcher,
courir, sauter (et retomber sur ses paUes), entendre, voir, gueUer,
apprendre, se cacher, être heureux, être triste, avoir peur, rêver,
chasser, se nourrir, se baUre, s’enfuir, se reproduire, éduquer ses
chatons, et la liste est encore très longue. Chacune de ces ac2ons met
en œuvre des processus qui ne sont pas directement de l’intelligence au
sens le plus commun mais relève de la cogni2on et de l’intelligence
animale. Tous les animaux ont une cogni2on qui leur est propre, de
l’araignée qui 2sse sa toile jusqu’aux chiens guides qui viennent en
aide aux personnes. Pour certains, ils peuvent même communiquer avec
nous. Pas par la parole, bien entendu, mais en u2lisant le langage du
corps ainsi que la vocalisa2on (par exemple des miaulements ou des
aboiements). En ce qui concerne votre chat, lorsqu’il vient négligemment
se froUer contre vous ou bien qu’il reste assis devant sa gamelle ou
devant une porte, le message est assez clair. Il ou elle veut une
caresse, a faim ou veut sor2r, puis rentrer, puis sor2r, puis rentrer…
Il a appris à interagir avec vous pour arriver à ses ﬁns. Parmi toutes
ces ap2tudes cogni2ves, il n’y en a aujourd’hui qu’une toute pe2te
poignée que l’on commence un peu à savoir reproduire ar2ﬁciellement. Par
exemple la marche bipède. Ça n’a l’air rien de rien et c’est pourtant
quelque chose d’extrêmement compliqué à réaliser pour la robo2que et il
aura fallu de nombreuses décennies de recherche avant de savoir
construire et programmer un robot qui marche convenablement sur deux
jambes. C’est-à-dire sans tomber à cause d’un pe2t caillou sous son pied
ou lorsqu’une personne l’a simplement eﬄeuré d’un peu trop près. Mais
ceUe complexité existe aussi chez l’homme puisque si vous vous rappelez
bien, il nous faut en moyenne une année pour apprendre à marcher. C’est
dire la complexité du problème.

Qu’en est-il de la reconnaissance des objets ? S’il est vrai que l’on a
vu apparaître ces dernières années des algorithmes capables de nommer le
contenu de pra2quement n’importe quelle image, on ne parle pas pour
autant d’intelligence ou de cogni2on. Pour le comprendre, il faut
regarder comment ces algorithmes fonc2onnent. L’appren2ssage supervisé,
qui reste aujourd’hui la méthode la plus populaire, consiste à présenter
au programme des images ainsi qu’un mot décrivant le contenu de l’image.
Le nombre total d’images est généralement bien supérieur au nombre de
mots u2lisés car pour un même mot, on va associer un très grand nombre
d’images représentant l’objet dans diﬀérentes situa2ons, sous diﬀérents
angles de vues, sous diﬀérentes lumières, etc. Par exemple, pour
reconnaître les chats, on peut présenter jusqu’à un million d’images. En
faisant cela, le programme va se cons2tuer une représenta2on visuelle
interne de ce qu’est cet objet, en calculant une sorte de moyenne de
l’ensemble des images. Mais ceUe représenta2on n’est in ﬁne qu’une
simple descrip2on qui n’est pas ancrée dans la réalité du monde.

En a<endant Terminator. Aujourd’hui, en 2020, l’Intelligence Ar2ﬁcielle
connaît un second souﬄe, notamment avec l’avènement du big data et une
puissance de calcul inégalée jusqu’alors. Ainsi, la redécouverte récente
de l’appren2ssage profond (deep learning), qui date des années 1980, a
permis de nouvelles avancées en traitement de données et reconnaissance
d’images. Cet algorithme d’appren2ssage est un réseau de neurones
ar2ﬁciel qui permet d’apprendre à par2r d’exemples. De fait, la
diﬀérence fondamentale entre les années 1980 et les années 2010 se situe
au niveau de la puissance de calcul mise en jeu et de la masse de
données qui a aUeint des propor2ons gigantesques. Imaginez un peu que
plus d’un milliard de personnes postent leur photo sur Facebook alors
qu’il y a trente ans, les chercheurs se démenaient pour cons2tuer des
échan2llons de quelques dizaines de portraits. De nos jours, ils peuvent
donc avoir accès à des centaines de millions de visages. C’est ainsi que
Facebook possède un algorithme de reconnaissance faciale qui égale
sta2s2quement les performances humaines. Est-il besoin de préciser qu’on
ne parle pas ici d’intelligence, mais bien d’algorithmes et
d’appren2ssage machine sur des gros volumes de données ?

Diverses interven2ons dans les médias soulignent les avancées
extraordinaires en intelligence ar2ﬁcielle et ses dangers poten2els.
S’il existe certainement des dangers liés à ce domaine comme à tout
progrès scien2ﬁque, les vrais risques de l’IA sont peut-être masqués par
la crainte que des machines prennent le pouvoir. Faut-il s’eﬀrayer de
l’avènement futur d’une super IA issue de la singularité ? Si ceUe idée
est assez populaire en liUérature et au cinéma (« Terminator », « 2001 A
Space Odyssey », « Ex-Machina »), elle l’est beaucoup moins dans le
domaine scien2ﬁque. Ce concept de singularité a été de fait introduit
par Vernon Vinge (professeur de mathéma2ques et auteur de science-ﬁc2on)
lors du symposium « Vision 21: Interdisciplinary Science and Engineering
in the Era of Cyberspace » organisé par la NASA en 1993 :

Within thirty years, we will have the technological means to create
superhuman intelligence. Shortly a^er, the human era will be ended.

Dans trente ans, nous aurons les moyens de créer une intelligence
sur-humaine. Peu de temps après, l’ère de l’humanité prendra ﬁn.

Si l’on s’en 2ent à ceUe prédic2on, nous pouvons en déduire que nous
allons bientôt disparaître puisqu’une super IA doit d’ores et déjà
exister dans quelques labos secrets. Or, force est de constater que nous
sommes encore très loin de ces conclusions drama2ques car il n’y a pas
aujourd’hui de machine « super-intelligente ». Pourtant, ce concept de
singularité peut séduire car il repose sur une idée somme toute assez
simple : si l’on construisait des ordinateurs de plus en plus «
intelligents », alors ceux-ci deviendraient plus intelligents que leurs
concepteurs et pourraient à leur tour concevoir de nouveaux ordinateurs
plus intelligents qu’eux-mêmes. Le moment précis où l’Homme construirait
cet ordinateur plus intelligent que lui-même est précisément ce que
Vernor Vinge désigne par singularité : puisque les ordinateurs sont
beaucoup plus rapides que nous, l’accroissement de l’intelligence se
ferait alors de façon exponen2elle. Avec les nouveaux résultats
époustouﬂants de ces dernières années, ce concept a été remis au goût du
jour, bien qu’il soit bancal (lire à ce sujet le livre de Jean-Gabriel
Ganascia «Le Mythe de la singularité »). Pour interpréter les prédic2ons
de Vernor Vinge sur la singularité, il conviendrait de lui faire
préciser sa pensée, aﬁn de savoir ce qu’il considère être une
intelligence surpra-humaine. Par exemple, ceUe intelligence devrait-elle
parler ? avoir des buts propres ? avoir un corps ? avoir des opinions ?
des amis ? des émo2ons ? des rêves ? etc. Et d’ailleurs, comment
pourrions-nous reconnaître la singularité, c’est-à-dire, comment
pourrions-nous savoir que la machine que nous venons de créer est
intelligente ?

Au ﬁnal, l’intelligence ar2ﬁcielle est un champ de recherche extrêmement
fécond, qui a enfanté à son tour de très nombreux champs de recherche,
que ce soit en reconnaissance de la parole, en algorithmes pour la
géné2que, en fouille de données, en vision par ordinateur, en réseaux de
neurones ar2ﬁciels, en appren2ssage machine, etc. L’IA « canal
historique » a permis de concevoir de très nombreux algorithmes que l’on
retrouve aujourd’hui dans un très grand nombre d’applica2ons grand
public. Et si aujourd’hui on ne les appelle plus IA, ils en sont
pourtant les héri2ers directs. C’est

d’ailleurs là une des malédic2ons de l’IA, car dès qu’un algorithme
fonc2onne, on a tendance à lui re2rer sa ﬁlia2on. En eﬀet, si une
machine sait le faire, c’est qu’il ne s’agit plus d’intelligence !


