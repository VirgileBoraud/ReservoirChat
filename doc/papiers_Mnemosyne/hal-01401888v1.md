Autonomous Machine Learning
Frédéric Alexandre

To cite this version:

Frédéric Alexandre. Autonomous Machine Learning. ERCIM News, 2016, Special theme: Machine
Learning, 107. ￿hal-01401888￿

HAL Id: hal-01401888

https://inria.hal.science/hal-01401888

Submitted on 23 Nov 2016

HAL is a multi-disciplinary open access
archive for the deposit and dissemination of sci-
entific research documents, whether they are pub-
lished or not. The documents may come from
teaching and research institutions in France or
abroad, or from public or private research centers.

L’archive ouverte pluridisciplinaire HAL, est
destinée au dépôt et à la diffusion de documents
scientifiques de niveau recherche, publiés ou non,
émanant des établissements d’enseignement et de
recherche français ou étrangers, des laboratoires
publics ou privés.

Autonomous Machine Learning 

F. Alexandre 

Inspiration from human learning sets the focus on one essential but 
poorly studied characteristic of learning: Autonomy. 

One remarkable characteristic of human learning is that, whereas we are 
in general not excellent in one specific domain, we are quite good in 
most of them, and able to adapt when a new problem appears. We are 
versatile and adaptable, which are critical properties for autonomous 
learning: we can learn in a changing and uncertain world. With neither 
explicit labels, nor data preprocessing or segmentation, we are able to 
pay attention to important information and neglect noise. We define by 
ourselves our goals and the means to reach them, self-evaluate our 
performances and re-exploit previously learned knowledge and strategies 
in some different context. In contrast, recent advances in Machine 
Learning exhibit impressive results, with powerful algorithms surpassing 
human performances in some very specific domains of expertise, but these 
models still have very poor autonomy. 

Our Mnemosyne Inria project-team is working in the Bordeaux Neurocampus 
with medical and neuroscientist teams to develop systemic models in 
computational neuroscience, focusing on these original characteristics of 
human learning. Whereas our primary goal is to develop models of the 
different kinds of memory in the brain and of their interactions, with 
the objective to exploit them to study neurodegenerative diseases, 
another important outcome of our work is to propose original models in 
Machine Learning integrating some of these important characteristics. 

We believe that important steps toward autonomous learning can be made 
along these lines of research: 

Developing an interacting system of memories: 

Specific circuits in the brain are mobilized to learn explicit knowledge 
and others to learn procedures. Besides modeling these circuits, studying 
their interactions is crucial to understand how one system can supervise 
another, resulting in a more autonomous learning. In the domain of 
perceptual learning in the medial temporal lobe, we model episodic 
memories storing important events in one trial, and forming later, by 
consolidation in other circuits, new semantic categories. In the domain 
of decision-making in the loops between the prefrontal cortex and the 
basal ganglia, we model cerebral mechanisms by which goal-directed 
behavior relying on explicit evaluation of expected rewards can later 
become habits, automatically triggered with less flexibility but 
increased effectiveness. 

Coping with uncertainty: 

We learn the rules that govern the world and consider it uncertain for 
two main reasons: it can be predictable up to a certain level (stochastic 
rules) or non-stationary (changing rules). Whereas standard probabilistic 
models are rather good at tackling the first kind of uncertainty, non-
stationarity in a dynamic world raises more difficult problems. We are 
studying how regions of the medial prefrontal cortex are detecting and 
evaluating the kind and the level of uncertainty by monitoring recent 

 
 
 
 
 
 
 
 
 
 
history of performance at managing correctly incoming events. These 
regions are also reported to activate the release of neuromodulators like 
monoamines, known to play a central role in adaptation to uncertainties 
[1]. In a nutshell, instead of developing large sets of circuits to 
manage uncertainty as stable rules in various contexts, the cerebral 
system has rather developed a general-purpose system adaptable to 
uncertainty with hyperparameters sensitive to meta-learning by 
neuromodulation, as we are currently trying to understand more precisely 
[2]. 

Embodiment for emotional learning: 

One important source of autonomy is due to our body itself that tells us 
what is good or bad for us; what must be searched or avoided. Pavlovian 
learning is modeled to detect and learn to predict biologically-
significant aversive and appetitive (emotional) stimuli which are key 
targets for attentional processing and for the organization of behavior. 
This learning can be done autonomously if the model of the cerebral 
system is associated to a substrate corresponding to the body, including 
sensors for pain and pleasure. A step further, we extend the study of the 
Pavlovian rules to integrate the effects of Pavlovian responses onto the 
body and the neuromodulatory system. 

From motivation to self-evaluation: 

Considering the brain and the body also introduces physiological needs, 
fundamental to introduce internal goals in addition to the external goals 
evoked above. This is the basis for renewed approaches regarding 
reinforcement learning, defining criteria more complex than a simple 
scalar representing an abstract reward. In humans, another important 
source of information for learning autonomously is based on self-
evaluation of the performances. It is noticeable that both motivation and 
self-evaluation processing are central in cognitive control [3] and 
reported to be located in the anterior part of the prefrontal cortex, as 
we endeavor to integrate in our models. 

In addition to developing models to explore each of these mechanisms in 
interaction with neuroscience and medicine, we also integrate them in a 
common platform defining the adaptive characteristics of an autonomous 
agent exploring an unknown virtual world together with the 
characteristics of its artificial body. Beyond Machine Learning, this 
numerical testbed is also a precious simulation tool for our medical and 
neuroscientist colleagues. 

[1] Yu, A.J., and Dayan, P. (2005). Uncertainty, Neuromodulation and 
Attention. Neuron 46(4). 

[2] Carrere, M., and Alexandre, F. (2016). Modeling the sensory roles of 
noradrenaline in action selection. The Sixth Joint IEEE International 
Conference Developmental Learning and Epigenetic Robotics. 

[3] Koechlin, E., Ody, C., and Kouneiher, F. (2003). The Architecture of 
Cognitive Control in the Human Prefrontal Cortex. Science, 
302(5648):1181–1185. 

Caption of the figure: 

 
 
 
 
 
 
 
 
 
 
Example of a large scale model described in [2], studying the 
interactions between two systems in the brain, respectively influenced by 
noradrenaline (NE, released by Locus Coeruleus) and dopamine (DA, 
released by VTA) and involving different regions of the loops between the 
prefrontal cortex (ACC, OFC) and the basal ganglia (Ventral Striatum, 
GPi). The NE system evaluates the level of non-stationarity of sensory 
input and modifies accordingly the level of attention on sensory cues, 
resulting in a shift between exploitation of previously learned rules and 
exploration of new rules in the DA system performing action selection. 

Frederic ALEXANDRE, Inria Bordeaux Sud-Ouest, France 
+33/0 5 47 30 42 60 
frederic.alexandre@inria.fr 

https://team.inria.fr/mnemosyne/ 

 
 
 
