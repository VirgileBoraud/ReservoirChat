Qu’est ce que l’IA et qu’est ce que ce n’est pas ? Aurelie Lagarrigue,
Thierry Viéville

To cite this version:

Aurelie Lagarrigue, Thierry Viéville. Qu’est ce que l’IA et qu’est ce
que ce n’est pas ?. 2021. 03494002￿

￿hal-

HAL Id: hal-03494002

https://inria.hal.science/hal-03494002

Submitted on 18 Dec 2021

HAL is a multi-disciplinary open access archive for the deposit and
dissemination of sci- entific research documents, whether they are pub-
lished or not. The documents may come from teaching and research
institutions in France or abroad, or from public or private research
centers.

L’archive ouverte pluridisciplinaire HAL, est destinée au dépôt et à la
diffusion de documents scientifiques de niveau recherche, publiés ou
non, émanant des établissements d’enseignement et de recherche français
ou étrangers, des laboratoires publics ou privés.

Distributed under a Creative Commons Attribution 4.0 International
License

Qu’est ce que l’IA et qu’est ce que ce n’est pas ? Article d’Aurélie
Lagarrigue et Thierry Viéville

Publié dans L’intelligence artificielle au service de la lecture LECTURE
JEUNE 180 | DECEMBRE 2021
http://www.lecturejeunesse.org/livre/lintelligence-artificielle-au-service-de-la-lecturen180-
decembre-2021/

Chapô : « L’intelligence artificielle correspond à ce que l’on peut
faire faire à une machine et qui eût été intelligent si cela avait été
fait par un humain ». En posant cette définition, Marvin Minsky, un des
fondateurs de l’intelligence artificielle, positionne le débat
exactement au bon endroit : comment nommer un certain nombre de tâches
cognitives, c’est-à-dire liées aux grandes fonctions de l’esprit,
lorsqu’elles peuvent être déléguées à une machine ?

Aurélie Lagarrigue, ingénieure pédagogique à l’INRIA Learning Lab
Docteure en neurosciences cognitives, Aurélie Lagarrigue s’intéresse aux
processus d’apprentissage. Elle a codéveloppé le MOOC Class’Code/INRIA
IAI et a participé à son animation.

Thierry Viéville, chercheur en neurosciences Spécialisé en neurosciences
computationnelles appliquées à la compréhension de l’apprentissage
humain dans l’éducation, Thierry Viéville participe à des actions de
médiation en sciences du numérique, en lien notamment avec
l’intelligence artificielle. Il participe au MOOC Class’Code.

La formation citoyenne Class’Code IAI, https://classcode.fr/iai,
réutilisable, permet à toutes et tous de mieux appréhender l’IA

Aux origines de l’intelligence artificielle

raisonnements

Dès le début du XXe siècle, les chercheurs réfléchissent à la manière de
pouvoir logiques avec deux automatiser des calculs symboliques et des
préoccupations : le faire de la manière la plus rigoureuse et efficace
possible. Ils découvrent cependant pendant les années 1930 que quel que
soit le mécanisme, certaines questions resteraient indécidables. Reconnu
comme discipline scientifique à partir de 1956, l’IA va alors se
développer jusqu’en 1974 sans prendre en compte ces limites, poussant
les investisseurs, découragés par le manque de résultat, à se
désintéresser de ce secteur jusque dans les années 1980, où sont
développés des systèmes experts visant à reproduire des capacités
cognitives, sans parvenir néanmoins à répondre aux espoirs placés dans
cette nouvelle technologie.

Il faut attendre le milieu des années 1990 pour qu’une nouvelle manière
d’appréhender l’intelligence artificielle en bouleverse les
performances. On essaye en effet de reproduire ces fonctions cognitives
de manière approximative par des calculs numériques massifs, dont les
paramètres sont ajustés sur des ensembles de données gigantesques. Les
performances atteignent enfin les attentes placées dans l’IA, que ce
soit dans la reconnaissance d’images, l’analyse d’imagerie médicale, le
traitement en langage naturel ou même les jeux de société : on pense
ainsi à la victoire, très symbolique, remportée en 1997 par le programme
Deep Blue d’IBM contre le champion d’échecs Garry Kasparov, même si la
méthode n’est pas intelligente en soi.

Ces prouesses technologiques, loin d’être infaillibles, n’en
bouleversent pas moins notre société. Dans les domaines de la justice,
l’IA peut par exemple s’appuyer sur les données de la jurisprudence pour
rendre une sentence plus fiable que celle d’un juge qui se fierait à sa
seule mémoire, tandis que la conduite d’un train ou d’un geste
chirurgical délicat peut être confié à un robot plutôt qu’à un humain.
Les champs d’application de l’IA, toujours plus nombreux, nous obligent
alors à adopter une attitude technocritique éclairée par une vision
citoyenne de la science. En effet, l’extension du domaine de l’IA
implique des changements en profondeur : or, il convient de débattre de
ces choix de société afin qu’ils puissent être démocratiquement
tranchés.

Alan Turing est l’un des fondateurs de la science informatique, qui
comprend dès 1936, quels types de traitements de l’information peuvent
être effectués par une machine, et quelles en sont les limites. Il
imagina, avant les débuts de l’IA, que le fonctionnement d’une telle
machine pouvait être confondu avec la cognition humaine. ©wikicommon

L’IA, c’est aussi un jargon à comprendre

Tout au long du développement de l’IA et de sa complexification, il a
fallu trouver des termes techniques pour désigner ses modes de
fonctionnement spécifiques.

Par exemple, on parle d’apprentissage machine pour signifier l’opération
consistant à présenter des exemples à l’IA afin de laisser l’algorithme
ajuster lui-même ses paramètres pour minimiser l’erreur entre sa
prédiction et le résultat attendu. Cela fonctionne un peu comme pour “Le
juste prix” ou “Qui est-ce” : une proposition est lancée et en fonction
des erreurs, les valeurs sont ajustées pour aboutir au résultat
recherché.

On désigne également par le terme d’apprentissage “profond” (ou deep
learning) le fait d’empiler plusieurs couches de calculs pour travailler
de manière plus efficace avec toutes sortes de données.

Enfin, on utilise le terme “big-data” (littéralement grosses données)
pour désigner des masses énormes de données rendues plus facilement
accessibles avec internet. Celles- ci ont cependant une grande valeur et
peuvent concerner notamment des informations sensibles, ce qui n’est pas
sans problèmes éthiques. Il est par ailleurs important de prendre du
recul par rapport aux données car si celles-ci sont biaisées, par
exemple parce qu’on aurait dit que tous les chats étaient gris,
l’apprentissage le sera également et les résultats seront inutilisables
(en l’occurrence par rapport aux chats d’autres couleurs).

Il est alors très étonnant de voir comment l’intelligence est réduite à
un simple calcul : c’est un changement radical de la vision que nous
avons de l’esprit humain.

Comment fonctionne l’IA ?

Jusque-là, ces lignes que vous avez lu n’ont pas été tapées au clavier
mais… dictées par ordinateur ? Ce dernier comprend-il ce qui lui est dit
? Nullement. Alors comment fait-il ? ! Comprend-il ce que je dis ?
Nullement. Alors comment fait-il ? La parole humaine est constituée
d’environ une cinquantaine de phonèmes. Les phonèmes sont des sons
élémentaires (entre une voyelle et une syllabe) quise combinent pour
former

des mots. Nous utilisons entre 1 000 et 3 000 mots différents par jour,
et en connaissons de l’ordre de 1 0000 en tout, selon notre usage de
lecture. Pour un calcul statistique, ce n’est guère élèvé : le son de la
voix est donc simplement découpé en une séquence de petits éléments qui
sont plus ou moins associés à des phonèmes, pour ensuite être associés à
des mots. Le calcul statistique cherche, parmi tous les bouts de
séquences de mots, celles qui semblent correspondre au son ainsi découpé
et qui sont les plus probables. Il ne reste plus qu’à sortir le résultat
sous forme d’une chaîne de lettres ou de caractères pour obtenir l’oral.
une

phrase

à

Bien entendu, le mécanisme ne “comprend rien à rien”. Ces mots ne font
pas du tout sens par la machine, puisqu’il ne s’agit que d’une mise en
correspondance entre des sons et des symboles. Ce procédé n’est donc
exploitable que parce que la voix humaine est moins complexe qu’elle n’y
paraît, et surtout car il a été possible de se baser sur une quantité
énorme de données (des milliers et des milliers de paroles mises en
correspondance avec des milliers et des milliers de bouts de séquences
de mots) pour procéder à une restitution fiable du propos dicté. Ces
calculs sont à la fois numériques, puisque chaque son est représenté par
une valeur numérique manipulée par calcul, et symboliques, chaque
phonème ou mot étant un symbole manipulé par un calcul algorithmique.

Suivant un autre exemple concernant la reconnaissance d’images, l’IA va
procéder à des calculs élémentaires comme si c’était un réseau de
“neurones” artificiels” pour distinguer le ciel de la mer. La couleur
moyenne ne serait ici pas un critère très discriminant car le ciel est
bleu clair et la mer d’un bleu plus profond. Par contre, la position
verticale dans l’image est caractéristique, avec le ciel au-dessus et la
mer au-dessous. C’est pourquoi l’IA combine deux entrées, l’une plus que
l’autre.

Un réseau de neurones n’est qu’une accumulation de calculs faits par des
unités organisées entre une couche d’entrée, des couches intermédiaires
et des sorties, connectées entre elles.

Là où notre cerveau procède par analogie, un algorithme “raisonne” plus
efficacement en énumérant un très grand nombre de cas ou en
échantillonnant au hasard pour explorer les possibilités. L’IA ne
calcule par ailleurs pas comme un humain. Elle ne multiplie pas comme
nous suivant un système décimal, mais en recourant au langage binaire
qui correspond à des câblages électroniques dont la sortie correspond au
résultat attendu. Ainsi, les algorithmes qui différencient, par exemple,
un chat d’un chien dans une image, ne s’appuient pas sur des
caractéristiques physiologiques, mais effectuent des comparaisons
statistiques avec des images de références, à la suite de
transformations numériques qui sont la plupart du temps peu
interprétables.

Il en résulte qu’aucun de ces algorithmes ne peut fonctionner sans
erreur compte tenu de son mode même de fonctionnement, et ce quelle que
soit l’ampleur de l’apprentissage. L’IA sera toujours confrontée à des
cas faisant exception et à des configurations inattendues qui le
mettront en échec.

Plus la requête est spécifique à résoudre, plus l’algorithme pourra être
efficace car il pourra ajuster son calcul en fonction d’une tâche très
précise. A contrario, un résolveur de problèmes qui serait généraliste
ne pourrait pas, en théorie, être performant. Super efficaces mais sans
aucune intelligence, uniquement dédiés à des tâches spécifiques, et
toujours faillibles : voilà ce qui caractérise les mécanismes dits
d’intelligence artificielle, loin des images fantasmées par notre
imaginaire (v. art. et itw Jérémie Dres).

Figure reprise du travail de Lake et al 2017
(https://arxiv.org/abs/1604.00289) qui étudie dans quelle mesure
l’apprentissage machine peut se comparer à l’apprentissage humain : ici
on voit des interprétations tout à fait “plausibles” mais complètement
absurdes, car il manque au mécanisme à la fois une compréhension
générale du fonctionnement du monde et des informations de contexte.


