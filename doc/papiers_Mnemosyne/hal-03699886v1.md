Investigating Long-Term Context of Language Models
on Brain Activity during Narrative Listening in fMRI
Subba Reddy Oota, Frédéric Alexandre, Xavier Hinaut

To cite this version:

Subba Reddy Oota, Frédéric Alexandre, Xavier Hinaut. Investigating Long-Term Context of Language
Models on Brain Activity during Narrative Listening in fMRI. FENS Forum 2022, Jul 2022, Paris,
France. ￿hal-03699886￿

HAL Id: hal-03699886

https://inria.hal.science/hal-03699886

Submitted on 20 Jun 2022

HAL is a multi-disciplinary open access
archive for the deposit and dissemination of sci-
entific research documents, whether they are pub-
lished or not. The documents may come from
teaching and research institutions in France or
abroad, or from public or private research centers.

L’archive ouverte pluridisciplinaire HAL, est
destinée au dépôt et à la diffusion de documents
scientifiques de niveau recherche, publiés ou non,
émanant des établissements d’enseignement et de
recherche français ou étrangers, des laboratoires
publics ou privés.

Investigating Long-Term Context of Language Models on
Brain Activity during Narrative Listening in fMRI

Subba Reddy Oota1,2,3,4

Frédéric Alexandre1,2,3,4, Xavier Hinaut1,2,3,4

1INRIA Bordeaux Sud-Ouest, France

2LaBRI, UMR 5800

3IMN, UMR 5293

4Universite de Bordeaux, France

• Introduction

1 Sequence-based and pretrained language models have been found
to be successful for text-driven prediction of brain activations.
2 However, these models still lack long-term memory plausibility

(i.e. how they deal with long-term dependencies and contextual
information)

Can current language models deal
with long-term dependencies?

Figure 1:Sequence length is fixed to 512 words in Transformers.

• Questions

1 What kind of language models can represent long-term

dependencies?

2 Could these language models also predict better brain activity

while subjects are engaged in longer stories ?

• Main Contributions

1 We propose the problem of finding which type of language

models are the most predictive of fMRI brain activity for listening
tasks.

• Models Considered

1 GloVe, Long Short-Term Memory Networks (LSTM)
2 ELMo, Longformer

• Evaluation Metrics

1 2V2 Accuracy
2 Pearson Correlation (R)

Brain Encoding

Brain Maps (Pearson Correlation)

Narrative Listening (Pieman dataset from Nastase et al. 2021)

Encoding Performance of Language Models

Figure 2:Whole Brain

• Cognitive Insights

1 In LSTM, the cell state representations (long term memory
vector) yield better encoding performance than hidden state
representations.

2 We used different layers of ELMo and Longformer, where higher
layers display better correlation for ELMo while intermediate
layers show superior performance for Longformer.

Conclusion

• Language models with longer context (e.g.

Longformer) better predict brain activity while
subjects listening to stories.

• Future Directions: (i) Use more plausible language
models than Transformers. (ii) Make hierarchical
language models.

References

[1] Martin Schrimpf et al. 2021.

The neural architecture of language: Integrative modeling
converges on predictive processing.

[2] Ashish Vaswani et al. 2017.
Attention is all you need.

[3] Samuel A Nastase et al. 2021.

The “narratives” fmri dataset for evaluating models of
naturalistic language comprehension.

Acknowledgements

• We thank Gaël Jobard and Clara Moreau for their

very helpful comments on the poster.

StimulusParagraphsSchrimpf et al. 2021, Vaswani et al. 2017Transformerlanguage models(BERT, XML, GPT,…)Hochreiter et al. 1997Long MemoryShortMemoryStimulusRidge RegressionPresentInputOutputXYWPearson Correlation (R) = Corr(Y, W(X))StimulusPresentEAC\_LEAC\_RAAC\_LAAC\_RPMC\_LPMC\_RTPOJ\_LTPOJ\_RDFL\_LDFL\_R00.10.2Rand NoiseGloVeRandLSTM (hidden state)RandLSTM (cell state)LSTM (hidden state)LSTM (cell state)ELMoLongformerAverage of SubjectsPearson CorrelationEAC\_LEAC\_RAAC\_LAAC\_RPMC\_LPMC\_RTPOJ\_LTPOJ\_RDFL\_LDFL\_R0.50.7Average of Subjects2V2 AccuracyLongformerELMoLHRH