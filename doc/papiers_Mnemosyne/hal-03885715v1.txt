The Opportunistic PFC: Downstream Modulation of a Hippocampus-inspired
Network is Optimal for Contextual Memory Recall Hugo Chateau-Laurent,
Frédéric Alexandre

To cite this version:

Hugo Chateau-Laurent, Frédéric Alexandre. The Opportunistic PFC:
Downstream Modulation of a Hippocampus-inspired Network is Optimal for
Contextual Memory Recall. 36th Conference on Neural Information
Processing System, Dec 2022, New Orleans, United States. ￿hal-03885715￿

HAL Id: hal-03885715

https://hal.science/hal-03885715

Submitted on 6 Dec 2022

HAL is a multi-disciplinary open access archive for the deposit and
dissemination of sci- entific research documents, whether they are pub-
lished or not. The documents may come from teaching and research
institutions in France or abroad, or from public or private research
centers.

L’archive ouverte pluridisciplinaire HAL, est destinée au dépôt et à la
diffusion de documents scientifiques de niveau recherche, publiés ou
non, émanant des établissements d’enseignement et de recherche français
ou étrangers, des laboratoires publics ou privés.

The Opportunistic PFC: Downstream Modulation of a Hippocampus-inspired
Network is Optimal for Contextual Memory Recall

Hugo Chateau-Laurent1,2,3

Frédéric Alexandre1,2,3

1Inria centre at the university of Bordeaux, France 2Institute of
Neurodegenerative Diseases, Bordeaux, France 3LaBRI, Université de
Bordeaux, France {hugo.chateau-laurent,frederic.alexandre}@inria.fr

Abstract

Episodic memory serves as a store of individual experiences and allows
for flexible adaptation to environment volatility and goal changes. The
selection of episodic memories to recall is often considered to be
driven by external sensory cues. Ex- perimental studies suggest that
this process is also influenced by internal cues, and that projections
from the medial prefrontal cortex to the hippocampus play a role in this
contextual modulation. In order to make sense of the biological
configuration of prefrontal-to-hippocampus connectivity, we investigate
the effec- tiveness of modulating various layers of a
hippocampus-inspired neural network in a contextual memory task. Our
results reveal that providing context information to the most downstream
regions (i.e. last layers) of the model leads to better performance. In
addition, the best average performance is obtained when contex- tual
connections target the regions corresponding to the biological subfields
that receive information from the prefrontal cortex, which provides a
normative account of the biological connectivity. We relate this work to
the need for augmenting reinforcement learning with flexible episodic
memory. We make the code available at
https://github.com/HugoChateauLaurent/opportunistic-PFC.

1

Introduction

Episodic memory is our ability to store and recall memories along with
their spatiotemporal context of acquisition. Information about what,
when and where events happened in the past can be retrieved and used to
make decisions in the present. This cognitive function contrasts with
the formation of semantic memories which are decontextualized and cached
for efficient use [6]. While heavy inspiration has been drawn from
semantic memory to develop deep learning algorithms, artificial agents
most often lack episodic memory, and more generally explicit memory,
despite their forecasted potential to improve sample efficiency and
flexibility [7, 15, 19]. In order to guide behavior efficiently,
recalled memories should be relevant to the current situation. More
precisely, the memory selection process should be influenced by both
contextual and sensory information. In contrast to the information that
is directly accessible to the agent through its perception of the
environment, contextual information encompasses any internal
representation that is not directly perceptible, but is susceptible to
help the agent predict future rewards and states. This includes
information about the temporal unfolding of events, spatial integration,
but also the goals pursued by the agent. Numerous studies have shown the
influence of temporal (e.g. [13, 31, 17]), spatial (e.g. [11, 21, 22]),
semantic (also investigated in [11]), and goal [1] factors on episodic
memory.

36th Conference on Neural Information Processing Systems (NeurIPS 2022).

The most influential theory of stimulus-driven memory recall states
that the hippocampus is able to perform pattern completion on partial
and noisy cues by implementing attractor dynamics through recurrent
connections in area CA3 [27] (but see [8] for an alternative account in
which CA1 performs pattern completion and CA3 learns sequences). With
this process, memories to be recalled are those that share similarities
with current sensory observations, or in other words, those with the
closest attractor. Interestingly, stimulus-driven episodic recall has
been implemented in a Neural Episodic Control architecture [24] and
shown to improve sample efficiency of classical deep reinforcement
learning algorithms. In this study, a Differentiable Neural Dictionary
was used to store episodes while the network was playing Atari games,
and similarity with the situation faced by the agent was used as a
criterion for selecting episodes to recall.

While stimulus-driven retrieval has been studied both empirically and
theoretically, much less is known about the contextual modulation of
episodic recall. We believe that a better comprehension of the
mechanisms involved is necessary to develop a complete theory of
episodic memory, but also to develop machine learning algorithms that
can comprehend a wider variety of spatiotemporal contexts and direct
their behavior towards internal goals. More precisely, synergy between
episodic memory and contextual control could yield significant
improvements over algorithms that use context alone (e.g. [29, 5, 14,
25, 4]) in terms of sample and parameter efficiency. It is worth noting
that Neural Episodic Control [24] was later extended to include a
LSTM-based working memory which arguably represents some sort of
contextual information and influences episodic recall [12]. Other
related works include model-based episodic learning [18], episodic meta
learning [20, 26], separate retrieval mechanisms [16], and so on. Yet,
this line of machine learning research is largely disconnected from the
biology.

Experiments suggest that the prefrontal cortex (PFC) and
prefrontal-hippocampal interactions play an important role in this
function [2, 10, 17, 21, 22]. In comparison with sensory cortices, PFC
is connected to the hippocampus through many pathways (see [10] for a
review). Just as sensory information, information represented in PFC
reaches the hippocampus through superficial layers of the entorhinal
cortex (EC). PFC also directly projects to deeper layers of the EC. In
addition, PFC is connected to the dentate gyrus and CA1 through the
supramammillary and reuniens nuclei respectively. Strikingly, there
seems to be no pathway connecting PFC and CA3 [3].

In a modeling study similar to ours [23], contextual information was fed
to the dentate gyrus to modulate recall, but other
prefrontal-to-hippocampus pathways were not considered. Here, we address
the question of why PFC targets the hippocampus the way it does, by
investigating the effectiveness of potential PFC-hippocampus
configurations in a neural network performing a contextual memory task.
First, we evaluate the added benefit of providing context at
intermediate layers of the network over providing it to the input layer
along sensory observations. Second, we test the hypothesis that more
downstream modulations (targeting CA1 and the output portion of EC) are
more efficient.

2 Methods

2.1 Task

Like the model of [23], our model performed the rodent task described in
[21, 22]. Eight object- discrimination problems presented in two
different contexts were used to evaluate context-guided memory recall.
In a given task ti(i = 1, …, 8) and context c, the network learned to
choose a rewarded object Ri,c over a non-rewarded object ¯Ri,c. In the
alternative context c′, it learned to choose between the same objects as
in context c, except that the non-rewarded object in context c was
rewarded in c′, and conversely (i.e. ¯Rc i ). As in [23], objects were
represented in the network as 6 × 4 matrices with 6 active entries of
value 1 placed at random locations, and other entries with value 0
(fig. 1, table 1).

i and Rc

i = Rc′

i = ¯Rc′

2.2 Model

The hippocampus model is a 6-layered fully-connected neural network
which follows the anatomy of the biological medial temporal lobe.
Information flow corresponds to the trisynaptic pathway: Input −→ ECin
−→ DG −→ CA3 −→ CA1 −→ ECout −→ Output. The number of neurons in each
region is set as the number of neurons in the analog rat region, as
retrieved from [9], scaled down by a factor N (see table 2). The network
input consists of three pattern slots: two for the objects to choose
between

2

Table 2: Network summary.

Table 1: Input summary. The “Objects” input size corresponds to the
product of the number, width and height of input patterns.

Input

Size

Context Objects

2 3 × 6 × 4

Layer

ECin DG CA3 CA1 ECout Output

Function

Output size 1.1 × 105N ReLU 12 × 105N ReLU 2.5 × 105N ReLU 3.9 × 105N
ReLU 3.3 × 105N ReLU 3 × 6 × 4

sigmoid

and one for the rewarded object (table 1). The assignment of Rc i to the
first or second slot is random. ReLU was used as the activation function
of hidden layers and sigmoid was used in the output layer to map latent
activity back to the pattern space (table 2). An additional input was
used to modulate different layers of the hippocampal network
contextually. It represents the two possible contexts as a 2D one-hot
vector. Note that the output layer was never modulated, since it does
not model a medial temporal lobe region. CA3 was recurrently connected
to store memories. We used the following hebbian rule to update its
recurrent weights:

i and ¯Rc

Mt = λMt−1 + ηCA3tCA3T t

(1) 

where CA3t is the result of the DG-to-CA3 connection (i.e. before
recurrent processing). λ and η respectively denote the rates of
forgetting and remembering. During both training and test phases, a
single iteration of an attractor network similar to that of [4] and [30]
was used for memory retrieval. It yielded a new vector, CA3r

t , to be passed to the next layer CA1: CA3r

t = ReLU(κCA3t + Mt−1CA3t)

(2) 

where κ is a decay term.

2.3 Training and hyperparameterization

All task-context combinations were presented once during each epoch, in
random order. Similarly to the recently proposed autoencoder model of
the hippocampus [28], the network learned to output its input, namely
the two input object patterns and the rewarded one. Thus, the loss
function to be minimized was the mean squared error between the input
and the output. Learning was online, as training examples were presented
one by one. The rewarded pattern was provided as input to the network
during training, but was masked during test (i.e. values of the third
input slot were set to 0). In the test phases, a trial was considered
correct when the pattern stored in the third slot of the output was
closer to the rewarded pattern than the non-rewarded one, as assessed by
the mean squared error. Unless otherwise mentioned, networks were
trained during 100 epochs, and hyperparameters were selected randomly to
ensure robustness of the results. These include N , the learning rate,
κ, λ and η. The same hyperparameterization was shared along
configurations of modulated layers to allow for the use of paired
difference statistical tests.

3 Results

Performance was evaluated according to which layers were modulated by
contextual information (fig. 2, left panel). The depth of the layer
receiving contextual input (ranging from ECin : 1 to ECout : 5)
positively correlated with performance (Spearman’s r(1250) = .34, p <
.001). Wilcoxon Signed-ranks tests indicated that performance was
significantly lower when context was provided to ECin (Median = 66.88%)
than when provided to DG (Median = 78.16%, z = −4.28, p < .001), CA3
(Median = 82.88%, z = −5.98, p < .001), CA1 (Median = 84.97%, z = −8.67,
p < .001) or ECout (Median = 85.66%, z = −9.54, p < .001). Modulating
either CA1 (Median = 84.97%) or ECout (Median = 85.66%) gave the best
results, and did not differ significantly (p = .29). We then tested
whether the effects of modulating individual layers would add up when
multiple layers received contextual information. We found that
modulating both CA1 and ECout was more efficient (Median = 89.97%) than
modulating CA1 (Median = 84.97%, z = −3.44, p < .001) or ECout (Median =
85.66%, z = −2.39, p < .01) individually (fig. 2, right). We
investigated the relationship between

3

Figure 2: Recall performance when different layers are contextually
modu- lated.

Figure 1: Example series of eight tasks. Here, the network was trained
during 1000 epochs and parameterized with N = .001, a learning rate of
10−4.5, and κ = η = λ = .5. The output shown was taken from the test
phase.

Figure 3: Recall performance when a different number of layers is
contextu- ally modulated.

Figure 4: Recall performance of all possible modulatory configurations,
ordered by their median.

4

Pattern 1Pattern 2Rewarded in cNetwork output in cRewarded in c’Network
output in c’ECinDGCA3CA1ECout5060708090100Performance (% correct)CA1 &
ECout0.00.20.40.60.81.0Modulated layers0.00.20.40.60.81.012345Number of
modulated layers5060708090100Performance (%
correct)5060708090100Performance (% correct)Combinations of modulated
layersECoutCA1CA3DGECinthe number of modulated layers and performance
by generating all possible combinations of targeted layers. As shown in
figure 3, the relationship was weakly positive (Spearman’s r(7750) =
.08, p < .001), and seemed to stagnate when more than 2 layers received
contextual information. In fact, Mann-Whitney U tests revealed that
while modulating two layers was significantly more efficient (Median =
85.13%) than modulating one (Median = 79.88%, U = 1, 365, 367, p <
.001), modulating five (Median = 87.28%) did not yield significantly
better results than modulating two (Median = 85.13%, U = 292, 927, p =
.05).

Over all configurations, the best performance was obtained when CA1 and
ECout were simultaneously modulated (fig. 4), and the worst
configuration was to modulate ECin alone. Surprisingly, the second best
configuration was to modulate ECin in addition to CA1 and ECout. We also
noted that ECin was more present than CA3 and DG in top configurations,
and that CA3 was the least present.

4 Discussion

Our results provide support for a role of prefrontal projections to CA1
and deep layers of the EC in top-down control of memory retrieval. A
general trend was that modulating the last layers was more efficient
than modulating upstream layers, suggesting that PFC is opportunist and
biases processing at the end of the information flow. The fact that PFC
generally targets high-level sensory regions of the brain suggests that
these results might extend to non-mnemonic cognitive control.
Projections to superficial layers of the EC were found to be the most
inefficient yet not significantly detrimental when accompanied by
downstream modulation. On the contrary, projections to CA3 which seem to
be absent in biology, or even to DG, were not found to be very efficient
whether being alone or with other prefrontal projections. Results also
indicate that feeding multiple layers with the same contextual
information is not redundant for the network and can instead improve
performance. Yet, the relationship between the number of modulated
layers and performance does not seem to be straightforward, as adding
more modulations did not necessarily improve performance and rather
increased variance (fig. 3).

These preliminary results along with the study of [23] open up a new
line of research dedicated to the understanding of controlled episodic
memory using computational tools, with a focus on the hippocampus and
PFC. For example, the model could be extended with a biologically
motivated monosynaptic pathway (i.e. a shortcut connection from ECin to
CA1). Other tasks could also be considered to further disentangle the
selective role of each prefrontal-hippocampal pathway. For example, the
need for cognitive control could be increased by generating patterns
with more spatial overlap. Sequence memory tasks could also be
investigated. Interestingly, it has been reported that inactivating
either the entorhinal or thalamic afferences from PFC led to
qualitatively different sequence memory impairments [17]. We believe
that this research avenue will yield significant improvements of
episodic reinforcement learning algorithms, as simple stimulus-driven
recall will be augmented with contextual cues, goal-directedness, and
possibly sequence modeling.

Acknowledgements

The authors would like to thank Fandilla-Marie Furlan, Xavier Hinaut and
David Trocellier for their generous feedback. Experiments presented in
this paper were carried out using the PlaFRIM experi- mental testbed,
supported by Inria, CNRS (LABRI and IMB), Université de Bordeaux,
Bordeaux INP and Conseil Régional d’Aquitaine (see
https://www.plafrim.fr).

References

[1] M. C. Anderson and C. Green. Suppressing unwanted memories by
executive control. Nature,

410(6826):366–369, 2001.

[2] M. C. Anderson, J. G. Bunce, and H. Barbas. Prefrontal–hippocampal
pathways underlying

inhibitory control over memory. Neurobiology of learning and memory,
134:145–161, 2016.

[3] L. Andrianova, S. Yanakieva, G. Margetts-Smith, S. Kohli, E. S.
Brady, J. P. Aggleton, and M. T. Craig. No evidence from complementary
data sources of a direct projection from the mouse anterior cingulate
cortex to the hippocampal formation. bioRxiv, 2022.

5

[4] J. Ba, G. E. Hinton, V. Mnih, J. Z. Leibo, and C. Ionescu. Using
fast weights to attend to the

recent past. Advances in neural information processing systems, 29,
2016.

[5] S. Babu, P. Savarese, and M. Maire. Online meta-learning via
learning with layer-distributed

memory. Advances in Neural Information Processing Systems,
34:14795–14808, 2021.

[6] M. Botvinick, S. Ritter, J. X. Wang, Z. Kurth-Nelson, C. Blundell,
and D. Hassabis. Reinforce-

ment learning, fast and slow. Trends in cognitive sciences,
23(5):408–422, 2019.

[7] H. Chateau-Laurent and F. Alexandre. Augmenting machine learning
with flexible episodic

memory. In 13th International Joint Conference on Computational
Intelligence, 2021.

[8] S. Cheng. The crisp theory of hippocampal function in episodic
memory. Frontiers in neural

circuits, 7:88, 2013.

[9] V. Cutsuridis, B. P. Graham, S. Cobb, and I. Vida. Hippocampal
microcircuits: a computational

modeler’s resource book. Springer, 2019.

[10] H. Eichenbaum. Prefrontal–hippocampal interactions in episodic
memory. Nature Reviews

Neuroscience, 18(9):547–558, 2017.

[11] A. Ennaceur, N. Neave, and J. P. Aggleton. Spontaneous object
recognition and object location memory in rats: the effects of lesions
in the cingulate cortices, the medial prefrontal cortex, the cingulum
bundle and the fornix. Experimental brain research, 113(3):509–519,
1997.

[12] M. Fortunato, M. Tan, R. Faulkner, S. Hansen, A. Puigdomènech
Badia, G. Buttimore, C. Deck, J. Z. Leibo, and C. Blundell.
Generalization of reinforcement learners with working and episodic
memory. Advances in neural information processing systems, 32, 2019.

[13] L. M. Frank, E. N. Brown, and M. Wilson. Trajectory encoding in the
hippocampus and

entorhinal cortex. Neuron, 27(1):169–178, 2000.

[14] H. Fu, H. Tang, J. Hao, C. Chen, X. Feng, D. Li, and W. Liu.
Towards effective context for meta-reinforcement learning: an approach
based on contrastive learning. In Proceedings of the AAAI Conference on
Artificial Intelligence, volume 35, pages 7457–7465, 2021.

[15] S. J. Gershman and N. D. Daw. Reinforcement learning and episodic
memory in humans and

animals: an integrative framework. Annual review of psychology, 68:101,
2017.

[16] A. Goyal, A. Friesen, A. Banino, T. Weber, N. R. Ke, A. P. Badia,
A. Guez, M. Mirza, P. C. Humphreys, K. Konyushova, et
al. Retrieval-augmented reinforcement learning. In International
Conference on Machine Learning, pages 7740–7765. PMLR, 2022.

[17] M. Jayachandran, S. B. Linley, M. Schlecht, S. V. Mahler, R. P.
Vertes, and T. A. Allen. Prefrontal pathways provide top-down control of
memory for sequences of events. Cell reports, 28(3):640–654, 2019.

[18] H. Le, T. Karimpanal George, M. Abdolshah, T. Tran, and S.
Venkatesh. Model-based episodic memory induces dynamic hybrid controls.
Advances in Neural Information Processing Systems, 34:30313–30325, 2021.

[19] M. Lengyel and P. Dayan. Hippocampal contributions to control: the
third way. Advances in

neural information processing systems, 20, 2007.

[20] L. C. Melo. Transformers are meta-reinforcement learners. In
International Conference on

Machine Learning, pages 15340–15359. PMLR, 2022.

[21] R. Navawongse and H. Eichenbaum. Distinct pathways for rule-based
retrieval and spatial mapping of memory representations in hippocampal
neurons. Journal of Neuroscience, 33(3): 1002–1013, 2013.

[22] G. J. Peters, C. N. David, M. D. Marcus, and D. M. Smith. The
medial prefrontal cortex is critical for memory retrieval and resolving
interference. Learning & memory, 20(4):201–209, 2013.

[23] P. K. Pilly, M. D. Howard, and R. Bhattacharyya. Modeling
contextual modulation of memory

associations in the hippocampus. Frontiers in Human Neuroscience,
12:442, 2018.

[24] A. Pritzel, B. Uria, S. Srinivasan, A. P. Badia, O. Vinyals, D.
Hassabis, D. Wierstra, and C. Blundell. Neural episodic control. In
International Conference on Machine Learning, pages 2827–2836. PMLR,
2017.

6

[25] H. Ren, A. Garg, and A. Anandkumar. Contextbased
meta-reinforcement learning with struc-

tured latent space. In Skills Workshop NeurIPS, 2019.

[26] S. Ritter, J. Wang, Z. Kurth-Nelson, S. Jayakumar, C. Blundell, R.
Pascanu, and M. Botvinick. Been there, done that: Meta-learning with
episodic recall. In International conference on machine learning, pages
4354–4363. PMLR, 2018.

[27] E. T. Rolls. A theory of hippocampal function in memory.
Hippocampus, 6(6):601–620, 1996. [28] D. Santos-Pata, A. F. Amil, I. G.
Raikov, C. Rennó-Costa, A. Mura, I. Soltesz, and P. F. Verschure.
Entorhinal mismatch: A model of self-supervised learning in the
hippocampus. Iscience, 24(4):102364, 2021.

[29] S. Sodhani, A. Zhang, and J. Pineau. Multi-task reinforcement
learning with context-based representations. In International Conference
on Machine Learning, pages 9767–9779. PMLR, 2021.

[30] J. C. Whittington, T. H. Muller, S. Mark, G. Chen, C. Barry, N.
Burgess, and T. E. Behrens. The tolman-eichenbaum machine: unifying
space and relational memory through generalization in the hippocampal
formation. Cell, 183(5):1249–1263, 2020.

[31] E. R. Wood, P. A. Dudchenko, R. J. Robitsek, and H. Eichenbaum.
Hippocampal neurons encode information about different types of memory
episodes occurring in the same location. Neuron, 27(3):623–633, 2000.

7


