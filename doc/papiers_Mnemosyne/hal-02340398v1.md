Challenge to test reproducibility of old computer code
Nicolas P. Rougier, Konrad Hinsen

To cite this version:

Nicolas P. Rougier, Konrad Hinsen. Challenge to test reproducibility of old computer code. Nature,
2019, 574 (7780), pp.634. ￿10.1038/d41586-019-03296-8￿. ￿hal-02340398￿

HAL Id: hal-02340398

https://inria.hal.science/hal-02340398

Submitted on 6 Nov 2019

HAL is a multi-disciplinary open access
archive for the deposit and dissemination of sci-
entific research documents, whether they are pub-
lished or not. The documents may come from
teaching and research institutions in France or
abroad, or from public or private research centers.

L’archive ouverte pluridisciplinaire HAL, est
destinée au dépôt et à la diffusion de documents
scientifiques de niveau recherche, publiés ou non,
émanant des établissements d’enseignement et de
recherche français ou étrangers, des laboratoires
publics ou privés.

Correspondence about: Workflow systems turn raw data into scientific knowledge, Jeffrey M. Perkel, 
Nature 573, 149-150 (2019). Link: https://www.nature.com/articles/d41586-019-02619-z 

Putting reproducibility to the test 
Konrad Hinsen (Centre for Molecular Biophysics, CNRS, Orléans, France), konrad.hinsen@cnrs.fr 
Nicolas Rougier (Inria Bordeaux South West Research Centre, Talence, France), nicolas.rougier@inria.fr 
Contact: nicolas.rougier@inria.fr 

“Workflows tools can make your computational methods portable, maintainable, reproducible and 
shareable” as explained in Nature 573, 149-150 (2019) [1]. But for how long? Will such workflow be 
still reproducible in a decade? Considering the fast pace of transformations in operating systems and 
programming languages, it is difficult to foresee future causes of non-reproducibility. This is perfectly 
illustrated with Python 2 (a very popular programming language in Science) whose official end of life 
(EOL) has been set to 1st January 2020 in favor of Python 3. Even though this EOL was announced 
almost a decade ago, this will undoubtedly break things in a foreseeable future. 

This naturally questions the long-term validity of computational results if you’re unable to run the 
original code a decade later. This is the reason why we are organizing the ten years reproducibility 
challenge (https://rescience.github.io/ten-years/) until April 2020 to put reproducibility to the test. 
We invite researchers to try to run the code they’ve created for a scientific publication that was 
published more than ten years ago (before 2010). Sounds easy? We have good reasons to think this 
might be more difficult than it appears. And maybe the first problem researchers will have to solve is 
to find their own source code [2]. This challenge should be also an opportunity to identify long-term 
causes of non-reproducibility. 

References 
[1] Jeffrey M. Perkel , Workflow systems turn raw data into scientific knowledge,Nature 573, 149-150 (2019) 
[2] Elizabeth Gibney and Richard Van Noorden , Scientists losing data at a rapid rate, Nature News (2013). 
doi:10.1038/nature.2013.14416 

 
 
 
 
 
 
