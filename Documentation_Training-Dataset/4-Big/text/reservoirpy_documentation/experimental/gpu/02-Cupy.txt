    import time

    import json

    from pathlib import Path

    from collections import defaultdict



    import matplotlib.pyplot as plt

    import numpy as np

    from scipy import linalg

    from scipy import sparse

    from tqdm import tqdm, trange



    from reservoirpy.compat import ESN

    from reservoirpy import mat_gen

    from reservoirpy.datasets import mackey_glass, to_forecasting



    import cupy as cp

    import cupyx as cpx

    from cupyx.time import repeat

    def nrmse(ytrue, ypred):

        rmse = np.sqrt(np.sum((ytrue - ypred)**2)) / ytrue.shape[0]

        return rmse / (ytrue.max() - ytrue.min())

    T = 20001

    T_tot = T + 501



    X = []

    taus = list(range(12, 37, 3))

    for tau in taus:

        X.append(mackey_glass(T_tot, tau=tau))



    X = np.concatenate(X, axis=1)

    X = 2 * (X - X.min(axis=0)) / (X.max(axis=0) - X.min(axis=0)) - 1

    X, Xtest = X[:-501], X[-501:]

    X, y = to_forecasting(X, forecast=1)

    Xtest, ytest = to_forecasting(Xtest, forecast=1)

    fig, axes = plt.subplots(len(taus), 1)

    for i, tau in enumerate(taus):

        _ = axes[i].plot(X[:500, i])

        axes[i].set_ylabel(tau)

    N = 1000

    W32 = mat_gen.generate_internal_weights(N, sr=1.25, seed=12345).astype(np.float32)

    Win32 = mat_gen.generate_input_weights(N, len(taus), input_bias=True, seed=12345).astype(np.float32)

    esn32 = ESN(lr=0.3, input_bias=True, W=W32, Win=Win32, typefloat=np.float32)

    def esn_kernel(W, Win, s, u, lr):

        xp = cp.get_array_module(s)

        x = s @ W + u @ Win.T

        x = (1 - lr) * s + lr * xp.tanh(x)

        return x

    def esn_states_gpu(W, Win, inputs, lr, progress=True):

        states = np.zeros(shape=(len(inputs), W.shape[0]))

        s = cp.zeros(shape=(1, W.shape[0]))

        U = np.hstack([np.ones(shape=(inputs.shape[0], 1)), inputs])

        for i, u in enumerate(tqdm(U, disable=not progress)):

            u = cp.array(u).reshape(1, -1)

            s = esn_kernel(W, Win, s, u, lr)

            states[i, :] = s.get()



        return states

    def esn_states_cpu(W, Win, inputs, lr, progress=True):

        states = np.zeros(shape=(len(inputs), W.shape[0]))

        s = np.zeros(shape=(1, W.shape[0]))

        U = np.array(inputs)

        U = np.hstack([np.ones(shape=(U.shape[0], 1)), U])

        for i, u in enumerate(tqdm(U, disable=not progress)):

            s = esn_kernel(W, Win, s, u, lr)

            states[i, :] = s



        return states

    states_gpu = esn_states_gpu(cp.array(W32.toarray()), cp.array(Win32), X, 0.3)

    states_cpu = esn_states_cpu(W32.toarray(), Win32, X, 0.3)

    perf = repeat(esn_states_gpu,

                  (cp.array(W32.toarray()), cp.array(Win32), X, 0.3),

                  n_repeat=20)



    print(perf)

    Ns = [100, 300, 500, 800, 1000, 2000, 5000, 10000]

    sparse_cpu_times = defaultdict(list)

    for n in Ns:

        if n not in sparse_cpu_times:

            W32 = mat_gen.generate_internal_weights(n, sr=1.25, seed=12345).astype(np.float32)

            Win32 = mat_gen.generate_input_weights(n, len(taus), input_bias=True, seed=12345).astype(np.float32)

            for i in trange(20):

                start = time.time()

                esn_states_cpu(W32, sparse.csr_matrix(Win32), X, 0.3, progress=False)

                sparse_cpu_times[n].append(time.time() - start)



    dense_cpu_times = defaultdict(list)

    for n in []: # too long, already computed

        if n not in dense_cpu_times:

            W32 = mat_gen.generate_internal_weights(n, sr=1.25, seed=12345).astype(np.float32)

            Win32 = mat_gen.generate_input_weights(n, len(taus), input_bias=True, seed=12345).astype(np.float32)

            for i in trange(20):

                start = time.time()

                esn_states_cpu(W32.toarray(), Win32, X, 0.3, progress=False)

                dense_cpu_times[n].append(time.time() - start)



    dense_gpu_times = defaultdict(list)

    for n in Ns:

        if n not in dense_gpu_times:

            W32 = mat_gen.generate_internal_weights(n, sr=1.25, seed=12345).astype(np.float32)

            Win32 = mat_gen.generate_input_weights(n, len(taus), input_bias=True, seed=12345).astype(np.float32)

            for i in trange(20):

                start = time.time()

                esn_states_gpu(cp.array(W32.toarray()), cp.array(Win32), X, 0.3, progress=False)

                dense_gpu_times[n].append(time.time() - start)



    sparse_gpu_times = defaultdict(list)

    for n in Ns:

        if n not in sparse_gpu_times:

            W32 = mat_gen.generate_internal_weights(n, sr=1.25, seed=12345).astype(np.float32)

            Win32 = mat_gen.generate_input_weights(n, len(taus), input_bias=True, seed=12345).astype(np.float32)

            for i in trange(20):

                start = time.time()

                esn_states_gpu(cpx.scipy.sparse.csr_matrix(W32),

                               cpx.scipy.sparse.csr_matrix(sparse.csr_matrix(Win32)), X, 0.3, progress=False)

                sparse_gpu_times[n].append(time.time() - start)

    report_nobatch = Path("../resultats/cupy-nobatch")

    if not report_nobatch.exists():

        report_nobatch.mkdir(parents=True)



    with (report_nobatch / "cpu_sparse.json").open("w+") as fp:

        json.dump(sparse_cpu_times, fp)



    with (report_nobatch / "cpu_dense.json").open("w+") as fp:

        json.dump(dense_cpu_times, fp)



    with (report_nobatch / "gpu_sparse.json").open("w+") as fp:

        json.dump(sparse_gpu_times, fp)



    with (report_nobatch / "gpu_dense.json").open("w+") as fp:

        json.dump(dense_gpu_times, fp)

    report_nobatch = Path("../resultats/cupy-nobatch")

    with (report_nobatch / "cpu_sparse.json").open("r") as fp:

        sparse_cpu_times = json.load(fp)



    with (report_nobatch / "cpu_dense.json").open("r") as fp:

        dense_cpu_times = json.load(fp)



    with (report_nobatch / "gpu_sparse.json").open("r") as fp:

        sparse_gpu_times = json.load(fp)



    with (report_nobatch / "gpu_dense.json").open("r") as fp:

        dense_gpu_times = json.load(fp)

    fig, ax = plt.subplots(1, 1)



    mean_cs = np.array([np.mean(v) for v in sparse_cpu_times.values()])

    std_cs = np.array([np.std(v) for v in sparse_cpu_times.values()])



    mean_cd = np.array([np.mean(v) for v in dense_cpu_times.values()])

    std_cd = np.array([np.std(v) for v in dense_cpu_times.values()])



    mean_gs = np.array([np.mean(v) for v in sparse_gpu_times.values()])

    std_gs = np.array([np.std(v) for v in sparse_gpu_times.values()])



    mean_gd = np.array([np.mean(v) for v in dense_gpu_times.values()])

    std_gd = np.array([np.std(v) for v in dense_gpu_times.values()])



    ax.plot(Ns, mean_cs, label="CPU sparse")

    ax.fill_between(Ns, mean_cs + std_cs, mean_cs - std_cs, alpha=0.2)



    #ax.plot(Ns, mean_cd, label="CPU dense")

    #ax.fill_between(Ns, mean_cd + std_cd, mean_cd - std_cd, alpha=0.2)



    ax.plot(Ns, mean_gs, label="GPU sparse")

    ax.fill_between(Ns, mean_gs + std_gs, mean_gs - std_gs, alpha=0.2)



    ax.plot(Ns, mean_gd, label="GPU dense")

    ax.fill_between(Ns, mean_gd + std_gd, mean_gd - std_gd, alpha=0.2)





    ax.set_xlabel("N")

    ax.set_ylabel("Time (s)")

    _ = ax.legend()

    def esn_batched_gpu(W, Win, inputs, lr, batch_size=100):

        states = np.zeros(shape=(len(inputs), W.shape[0]))

        s = cp.zeros(shape=(1, W.shape[0]))

        U = np.hstack([np.ones(shape=(inputs.shape[0], 1)), inputs])



        max_length = len(inputs)

        num_batches = int(np.ceil(U.shape[0] / batch_size))

        for i in range(num_batches):

            end = (i+1)*batch_size if (i+1)*batch_size < max_length else max_length

            u_batch = cp.array(U[i*batch_size:end])

            s_batch = cp.empty((u_batch.shape[0], s.shape[1]))

            for j in range(u_batch.shape[0]):

                x = s @ W + cp.dot(u_batch[j, :], Win.T)

                s = (1 - lr) * s + lr * cp.tanh(x)

                s_batch[j, :] = s.reshape(-1)

            states[i*batch_size:end] = s_batch.get()



        return states

    states = esn_batched_gpu(cp.array(W32.toarray()), cp.array(Win32), X, 0.3, batch_size=100)

    times = []

    for i in trange(20):

        start = time.time()

        esn_batched_gpu(cp.array(W32.toarray()), cp.array(Win32), X, 0.3, batch_size=100)

        times.append(time.time() - start)



    print(f"Batched (100) GPU time: {np.mean(times)} Â± {np.std(times)} "

          f"(min: {np.min(times)}, max: {np.max(times)})")

    batches = list(range(100, 1001, 100))

    batches.insert(0, 1)



    batch_gpu_times = defaultdict(lambda: defaultdict(list))

    for n in Ns:

        W32 = mat_gen.generate_internal_weights(n, sr=1.25, seed=12345).astype(np.float32)

        Win32 = mat_gen.generate_input_weights(n, len(taus), input_bias=True, seed=12345).astype(np.float32)

        for batch_size in batches:

            for i in trange(20):

                start = time.time()

                esn_batched_gpu(cp.array(W32.toarray()), cp.array(Win32), X, 0.3, batch_size=batch_size)

                batch_gpu_times[n][batch_size].append(time.time() - start)

    report_batch = Path("../resultats/cupy-batch")

    if not report_batch.exists():

        report_batch.mkdir(parents=True)



    with (report_batch / "gpu_batched.json").open("w+") as fp:

        json.dump(batch_gpu_times, fp)

    report_batch = Path("../resultats/cupy-batch")

    with (report_batch / "gpu_batched.json").open("r") as fp:

        batch_gpu_times = json.load(fp)

    import matplotlib as mpl

    Ns = [100, 300, 500, 800, 1000, 1500, 2000]



    bgt = defaultdict(lambda: defaultdict((list)))

    for n, res in batch_gpu_times.items():

        for b, values in res.items():

            bgt[b][n] = values



    evenly_spaced_interval = np.linspace(0.5, 1, len(batches))

    colors = [mpl.cm.Blues(x) for x in evenly_spaced_interval]



    for i, (batch, res) in enumerate(bgt.items()):



        means = np.array([np.mean(v) for v in res.values()])

        stds = np.array([np.std(v) for v in res.values()])

        upper = means + stds

        lower = means - stds

        color = colors[i]

        plt.plot(Ns, means, color=color, label=batch)

        plt.fill_between(Ns, upper, lower, color=color, alpha=0.2)



    plt.legend()

    def esn_batched_gpu_with_training(W, Win, inputs, teachers, lr, batch_size=500):

        s = cp.zeros(shape=(1, W.shape[0]), dtype=np.float32)

        N = W.shape[0]

        XXT = cp.zeros(shape=(N+1, N+1), dtype=np.float32)

        YXT = cp.zeros(shape=(teachers.shape[1], N+1), dtype=np.float32)

        R = np.eye(N+1, dtype=np.float32) * 10

        U = np.hstack([np.ones(shape=(inputs.shape[0], 1)), inputs])



        max_length = len(inputs)

        num_batches = int(np.ceil(U.shape[0] / batch_size))



        for i in range(num_batches):

            end = (i+1)*batch_size if (i+1)*batch_size < max_length else max_length



            u_batch = cp.array(U[i*batch_size:end]).astype(np.float32)

            t_batch = cp.array(teachers[i*batch_size:end]).astype(np.float32)

            s_batch = cp.empty((u_batch.shape[0], s.shape[1])).astype(np.float32)



            for j in range(u_batch.shape[0]):

                x = s @ W + u_batch[j, :] @ Win.T

                s = (1 - lr) * s + lr * cp.tanh(x)

                s_batch[j, :] = s.reshape(-1)



            s_batch = cp.hstack([cp.ones((s_batch.shape[0], 1)), s_batch])



            XXT += s_batch.T @ s_batch

            YXT += t_batch.T @ s_batch



        Wout = linalg.solve(XXT.get() + R, YXT.T.get(), assume_a="sym")



        return Wout.T

    def esn_batched_cpu_with_training(W, Win, inputs, teachers, lr, batch_size=500):

        N = W.shape[0]

        s = np.zeros(shape=(1, N), dtype=np.float32)

        XXT = np.zeros(shape=(N+1, N+1), dtype=np.float32)

        YXT = np.zeros(shape=(teachers.shape[1], N+1), dtype=np.float32)

        R = np.eye(N+1, dtype=np.float32) * 10

        U = np.hstack([np.ones(shape=(inputs.shape[0], 1)), inputs])



        max_length = len(inputs)

        num_batches = int(np.ceil(U.shape[0] / batch_size))



        for i in range(num_batches):

            end = (i+1)*batch_size if (i+1)*batch_size < max_length else max_length



            u_batch = np.array(U[i*batch_size:end]).astype(np.float32)

            t_batch = np.array(teachers[i*batch_size:end]).astype(np.float32)

            s_batch = np.empty((u_batch.shape[0], s.shape[1])).astype(np.float32)



            for j in range(u_batch.shape[0]):

                x = s @ W + u_batch[j, :] @ Win.T

                s = (1 - lr) * s + lr * np.tanh(x)

                s_batch[j, :] = s.reshape(-1)



            s_batch = np.hstack([np.ones((s_batch.shape[0], 1)), s_batch])



            XXT += s_batch.T @ s_batch

            YXT += t_batch.T @ s_batch



        Wout = linalg.solve(XXT + R, YXT.T, assume_a="sym")



        return Wout.T

    T = 20001

    T_tot = T + 501



    X = mackey_glass(T_tot)



    X = 2 * (X - X.min(axis=0)) / (X.max(axis=0) - X.min(axis=0)) - 1

    X, Xtest = X[:-501], X[-501:]

    X, y = to_forecasting(X, forecast=1)

    Xtest, ytest = to_forecasting(Xtest, forecast=1)

    N = 1000

    W32 = mat_gen.generate_internal_weights(N, sr=1.25, seed=12345).astype(np.float32)

    Win32 = mat_gen.generate_input_weights(N, 1, input_bias=True, seed=12345).astype(np.float32)

    Wout_gpu = esn_batched_gpu_with_training(cp.array(W32.toarray()), cp.array(Win32), X, y, 0.3, batch_size=500)

    Wout_cpu = esn_batched_cpu_with_training(W32, Win32, X, y, 0.3, batch_size=500)

    fig, (ax1, ax2) = plt.subplots(1, 2)

    ax1.hist(Wout_cpu.T, bins=50, label="CPU")

    ax2.hist(Wout_gpu.T, bins=50, label="GPU")

    _ = ax1.legend()

    _ = ax2.legend()

    esn32 = ESN(lr=0.3, input_bias=True, W=W32, Win=Win32, typefloat=np.float32)

    esn32.Wout = Wout_gpu

    outputs_g, _ = esn32.run([Xtest.astype(np.float32)])



    esn32.Wout = Wout_cpu

    outputs_c, _ = esn32.run([Xtest.astype(np.float32)])

    plt.plot(ytest[:500], label="M-G", color="gray", marker="^", markevery=0.1)

    plt.plot(outputs_g[0][:500], label="GPU batched")

    plt.plot(outputs_c[0][:500], label="CPU batched")

    _ = plt.legend()

    sparse_cpu_times = defaultdict(list)

    dense_cpu_times = defaultdict(list)

    dense_gpu_times = defaultdict(list)

    sparse_gpu_times = defaultdict(list)

    Ns = [100, 300, 500, 800, 1000, 2000, 5000, 10000]





    for n in Ns:

        if n not in sparse_cpu_times:

            W32 = mat_gen.generate_internal_weights(n, sr=1.25, seed=12345).astype(np.float32)

            Win32 = mat_gen.generate_input_weights(n, 1, input_bias=True, seed=12345).astype(np.float32)

            for i in trange(20):

                start = time.time()

                esn_batched_cpu_with_training(W32, sparse.csr_matrix(Win32), X, y, 0.3)

                sparse_cpu_times[n].append(time.time() - start)



    for n in []: #too long

        if n not in dense_cpu_times:

            W32 = mat_gen.generate_internal_weights(n, sr=1.25, seed=12345).astype(np.float32)

            Win32 = mat_gen.generate_input_weights(n, 1, input_bias=True, seed=12345).astype(np.float32)

            for i in trange(20):

                start = time.time()

                esn_batched_cpu_with_training(W32.toarray(), Win32, X, y, 0.3, progress=False)

                dense_cpu_times[n].append(time.time() - start)





    for n in Ns:

        if n not in dense_gpu_times:

            W32 = mat_gen.generate_internal_weights(n, sr=1.25, seed=12345).astype(np.float32)

            Win32 = mat_gen.generate_input_weights(n, 1, input_bias=True, seed=12345).astype(np.float32)

            for i in trange(20):

                start = time.time()

                esn_batched_gpu_with_training(cp.array(W32.toarray()), cp.array(Win32), X, y, 0.3)

                dense_gpu_times[n].append(time.time() - start)





    for n in Ns:

        if n not in sparse_gpu_times:

            W32 = mat_gen.generate_internal_weights(n, sr=1.25, seed=12345).astype(np.float32)

            Win32 = mat_gen.generate_input_weights(n, 1, input_bias=True, seed=12345).astype(np.float32)

            for i in trange(20):

                start = time.time()

                esn_batched_gpu_with_training(cpx.scipy.sparse.csr_matrix(W32),

                               cpx.scipy.sparse.csr_matrix(sparse.csr_matrix(Win32)), X, y, 0.3)

                sparse_gpu_times[n].append(time.time() - start)

    report_trainbatch = Path("../resultats/cupy-numpy-train-batch")

    if not report_trainbatch.exists():

        report_trainbatch.mkdir(parents=True)



    with (report_trainbatch / "cpu_sparse.json").open("w+") as fp:

        json.dump(sparse_cpu_times, fp)



    with (report_trainbatch / "cpu_dense.json").open("w+") as fp:

        json.dump(dense_cpu_times, fp)



    with (report_trainbatch / "gpu_sparse.json").open("w+") as fp:

        json.dump(sparse_gpu_times, fp)



    with (report_trainbatch / "gpu_dense.json").open("w+") as fp:

        json.dump(dense_gpu_times, fp)

    fig, ax = plt.subplots(1, 1)



    mean_cs = np.array([np.mean(v) for v in sparse_cpu_times.values()])

    std_cs = np.array([np.std(v) for v in sparse_cpu_times.values()])



    mean_cd = np.array([np.mean(v) for v in dense_cpu_times.values()])

    std_cd = np.array([np.std(v) for v in dense_cpu_times.values()])



    mean_gs = np.array([np.mean(v) for v in sparse_gpu_times.values()])

    std_gs = np.array([np.std(v) for v in sparse_gpu_times.values()])



    mean_gd = np.array([np.mean(v) for v in dense_gpu_times.values()])

    std_gd = np.array([np.std(v) for v in dense_gpu_times.values()])



    ax.plot(Ns, mean_cs, label="CPU sparse")

    ax.fill_between(Ns, mean_cs + std_cs, mean_cs - std_cs, alpha=0.2)



    #ax.plot(Ns, mean_cd, label="CPU dense")

    #ax.fill_between(Ns, mean_cd + std_cd, mean_cd - std_cd, alpha=0.2)



    ax.plot(Ns, mean_gs, label="GPU sparse")

    ax.fill_between(Ns, mean_gs + std_gs, mean_gs - std_gs, alpha=0.2)



    ax.plot(Ns, mean_gd, label="GPU dense")

    ax.fill_between(Ns, mean_gd + std_gd, mean_gd - std_gd, alpha=0.2)



    ax.set_xlabel("N")

    ax.set_ylabel("Time (s)")

    _ = ax.legend()
