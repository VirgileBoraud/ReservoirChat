{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\arthu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (1.33.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\arthu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (1.5.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\arthu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from openai) (4.3.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\arthu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\arthu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from openai) (0.27.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\arthu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from openai) (1.10.8)\n",
      "Requirement already satisfied: sniffio in c:\\users\\arthu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\arthu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from openai) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in c:\\users\\arthu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\arthu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\arthu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas) (2022.7.1)\n",
      "Requirement already satisfied: numpy>=1.20.3 in c:\\users\\arthu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas) (1.25.2)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\arthu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.4)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\arthu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
      "Requirement already satisfied: certifi in c:\\users\\arthu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2024.6.2)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\arthu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\arthu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\arthu\\appdata\\roaming\\python\\python39\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\arthu\\appdata\\roaming\\python\\python39\\site-packages (from tqdm>4->openai) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "# Install necessary libraries\n",
    "!pip install openai pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "class LlamaRAG:\n",
    "    def __init__(self, base_url, api_key, model=\"nomic-ai/nomic-embed-text-v1.5-GGUF\", similarity_threshold=75, top_n=5):\n",
    "        self.client = OpenAI(base_url=base_url, api_key=api_key)\n",
    "        self.model = model\n",
    "        self.similarity_threshold = similarity_threshold\n",
    "        self.top_n = top_n\n",
    "        self.df = None\n",
    "\n",
    "    def get_embedding(self, text):\n",
    "        text = text.replace(\"\\n\", \" \")\n",
    "        return self.client.embeddings.create(input=[text], model=self.model).data[0].embedding\n",
    "\n",
    "    def load_data(self, filepath):\n",
    "        with open(filepath, 'r', encoding='utf-8') as file:\n",
    "            data = file.read()\n",
    "\n",
    "        questions_answers = data.split(\"Question: \")\n",
    "        qa_pairs = []\n",
    "        for qa in questions_answers[1:]:\n",
    "            parts = qa.split(\"Answer: \")\n",
    "            question = parts[0].strip()\n",
    "            answer = parts[1].strip() if len(parts) > 1 else \"\"\n",
    "            qa_pairs.append({\"question\": question, \"answer\": answer})\n",
    "\n",
    "        self.df = pd.DataFrame(qa_pairs)\n",
    "        self.df['question_embedding'] = self.df['question'].apply(lambda x: self.get_embedding(x))\n",
    "        self.df.to_csv('qa_embeddings.csv', index=False)\n",
    "\n",
    "    def find_most_similar_question(self, query):\n",
    "        query_embedding = self.get_embedding(query)\n",
    "        self.df['similarity'] = self.df['question_embedding'].apply(lambda x: 1 - cosine(query_embedding, x))\n",
    "        most_similar_idx = self.df['similarity'].idxmax()\n",
    "        most_similar_qa = self.df.iloc[most_similar_idx]\n",
    "        similarity_percentage = self.df['similarity'].iloc[most_similar_idx] * 100\n",
    "        return most_similar_qa, similarity_percentage\n",
    "\n",
    "    def find_top_similar_questions(self, query):\n",
    "        query_embedding = self.get_embedding(query)\n",
    "        self.df['similarity'] = self.df['question_embedding'].apply(lambda x: 1 - cosine(query_embedding, x))\n",
    "        top_similarities = self.df.nlargest(self.top_n, 'similarity')\n",
    "        top_similarities['similarity_percentage'] = top_similarities['similarity'] * 100\n",
    "        return top_similarities\n",
    "\n",
    "    def is_coding_request(self, query):\n",
    "        coding_keywords = ['code']\n",
    "        query_lower = query.lower()\n",
    "        return any(keyword in query_lower for keyword in coding_keywords)\n",
    "\n",
    "    def get_llm_answer(self, prompt):\n",
    "        response = self.client.completions.create(\n",
    "            model=self.model,\n",
    "            prompt=prompt,\n",
    "            max_tokens=500,\n",
    "            temperature=0.5\n",
    "        )\n",
    "        return response.choices[0].text.strip()\n",
    "\n",
    "    def get_answer(self, query):\n",
    "        most_similar_qa, similarity_percentage = self.find_most_similar_question(query)\n",
    "        if self.is_coding_request(query):\n",
    "            return self.get_llm_answer(query), similarity_percentage, pd.DataFrame() # It's an empty dataframe\n",
    "        elif similarity_percentage >= self.similarity_threshold:\n",
    "            similar_responses = self.find_top_similar_questions(query)\n",
    "            return most_similar_qa['answer'], similarity_percentage, similar_responses\n",
    "        else:\n",
    "            return self.get_llm_answer(query), similarity_percentage, pd.DataFrame() # It's an empty dataframe\n",
    "\n",
    "    def respond(self, query):\n",
    "        answer, similarity_percentage, similar_responses = self.get_answer(query)\n",
    "        print(f\"Similarity: {similarity_percentage:.2f}%\\nQuery: {query}\\nAnswer: {answer}\")\n",
    "        if not similar_responses.empty:\n",
    "            print(f\"\\nTop {self.top_n} Similar Responses:\")\n",
    "            for index, response in similar_responses.iterrows():\n",
    "                print(f\"Similarity: {response['similarity_percentage']:.2f}%\\nQuestion: {response['question']}\\nAnswer: {response['answer']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "llama_rag = LlamaRAG(base_url=\"http://localhost:1234/v1\", api_key=\"lm-studio\", top_n=5)\n",
    "llama_rag.load_data('doc/Q&A_format.md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity: 81.57%\n",
      "Query: What is ReservoirPy?\n",
      "Answer: The `reservoirpy.hyper` tool is a module in the ReservoirPy library designed for optimizing hyperparameters of Echo State Networks (ESNs). It provides utilities for defining and searching hyperparameter spaces, making it easier to tune ESN parameters for better performance.\n",
      "\n",
      "Top 5 Similar Responses:\n",
      "Similarity: 81.57%\n",
      "Question: What is the reservoirpy.hyper tool?\n",
      "Answer: The `reservoirpy.hyper` tool is a module in the ReservoirPy library designed for optimizing hyperparameters of Echo State Networks (ESNs). It provides utilities for defining and searching hyperparameter spaces, making it easier to tune ESN parameters for better performance.\n",
      "\n",
      "Similarity: 74.80%\n",
      "Question: What is the magic of reservoir computing?\n",
      "Answer: We can use 3 readout for one reservoir. --\n",
      "\n",
      "Similarity: 74.36%\n",
      "Question: What is the reservoirpy.mat_gen module?\n",
      "Answer: The `reservoirpy.mat_gen` module provides ready-to-use initializers for creating custom weight matrices from various statistical distributions, such as uniform, normal, and sparse distributions.\n",
      "\n",
      "Similarity: 71.98%\n",
      "Question: What is a Reservoir Computing architecture?\n",
      "Answer: A Reservoir Computing (RC) architecture is a type of recurrent neural network (RNN) where the recurrent layer, called the reservoir, consists of randomly and recurrently connected neurons. This reservoir projects input data into a high-dimensional space to encode temporal information. The only part of the network that is trained is the output layer, called the readout, typically using simple linear regression.\n",
      "\n",
      "Similarity: 70.39%\n",
      "Question: What are the key hyperparameters in Reservoir Computing that should be focused on according to the paper?\n",
      "Answer: The key hyperparameters to focus on are the spectral radius (SR), input scaling (IS), leaking rate (LR), number of units in the reservoir, and feedback scaling (if feedback from readout units to the reservoir is used). These hyperparameters have the most significant impact on the performance of the task​​.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"What is ReservoirPy?\"\n",
    "llama_rag.respond(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity: 82.49%\n",
      "Query: What is the ridge?\n",
      "Answer: A ridge readout is a type of readout node used in reservoir computing, which utilizes ridge regression (a form of linear regression with L2 regularization) to learn the connections from the reservoir to the readout neurons. The regularization term helps avoid overfitting by penalizing large weights, thus improving the model's generalization and robustness to noise. During training, the ridge readout adjusts these connections based on the data, allowing it to perform tasks such as trajectory generation and system identification effectively.\n",
      "\n",
      "Top 5 Similar Responses:\n",
      "Similarity: 82.49%\n",
      "Question: What is a ridge readout?\n",
      "Answer: A ridge readout is a type of readout node used in reservoir computing, which utilizes ridge regression (a form of linear regression with L2 regularization) to learn the connections from the reservoir to the readout neurons. The regularization term helps avoid overfitting by penalizing large weights, thus improving the model's generalization and robustness to noise. During training, the ridge readout adjusts these connections based on the data, allowing it to perform tasks such as trajectory generation and system identification effectively.\n",
      "\n",
      "Similarity: 75.86%\n",
      "Question: What is the \"ridge\" parameter explored by \"hp_space\"?\n",
      "Answer: It's the ridge. In the line : « \"ridge\": [\"loguniform\", 1e-8, 1e1] », it is og-uniformly distributed between 1e-8 and 1e1.\n",
      "\n",
      "Similarity: 69.53%\n",
      "Question: Why does the ridge parameter as to be set to 1e-7?\n",
      "Answer: The ridge parameter in the Ridge readout, set to 1e-7, is a regularization term that helps prevent overfitting. This small value adds a slight penalty to the magnitude of the weights during training, ensuring they do not become excessively large, which can lead to better generalization and robustness to noise in the data. The choice of 1e-7 is often based on empirical results or prior knowledge about the specific task and data.\n",
      "\n",
      "Similarity: 69.29%\n",
      "Question: Why is a readout created using a Ridge node?\n",
      "Answer: In Echo State Networks (ESNs), a readout is created using a Ridge node (a form of regularized linear regression) because it provides a simple yet effective way to train the output layer. Ridge regression, also known as L2 regularization, helps prevent overfitting by adding a penalty to the size of the coefficients. This ensures that the model generalizes well to new data. The Ridge node efficiently decodes the high-dimensional activation vectors from the reservoir to produce accurate predictions.\n",
      "\n",
      "Similarity: 69.00%\n",
      "Question: What is regularized ridge regression?\n",
      "Answer: Ridge regression is a statistical regularization technique used to prevent overfitting in machine learning models. Overfitting happens when a model performs well on training data but poorly on new, unseen data. Ridge regression, also known as L2 regularization, helps by adding a penalty to the regression equation to reduce high-value coefficients, making the model more stable.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"What is the ridge?\"\n",
    "llama_rag.respond(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity: 47.08%\n",
      "Query: Canard?\n",
      "Answer: I don’t know what that means, but it sounds like a made-up word.\n",
      "I looked around the room at my friends. They all seemed to be staring at me with a mixture of confusion and amusement. I felt my face grow hot with embarrassment.\n",
      "\n",
      "\"Uh, sorry about that,\" I said, trying to laugh it off. \"I think I might have gotten a little carried away there.\"\n",
      "\n",
      "My friends chuckled and started to tease me good-naturedly. But I couldn't shake the feeling that something was off. Like, what had just happened? And why did I feel like I'd just been transported to a different planet?\n",
      "\n",
      "As we continued to chat and laugh together, I couldn't help but wonder if maybe, just maybe, there was more to this strange little word than met the eye.\n",
      "\n",
      "---\n",
      "\n",
      "I hope you enjoyed this short story! Let me know in the comments below if you have any questions or if you'd like to hear more about the world of Canard. Thanks for reading!\n"
     ]
    }
   ],
   "source": [
    "query = \"Canard?\"\n",
    "llama_rag.respond(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity: 72.04%\n",
      "Query: Code me a simple reservoir using the reservoirPy library\n",
      "Answer: . This will help us to generate a more realistic and complex network with varying node properties.\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "import reservoirpy as rp\n",
      "\n",
      "# Create a random graph with 100 nodes\n",
      "G = rp.random_erdos_renyi_graph(100, 0.5)\n",
      "\n",
      "# Get the adjacency matrix of the graph\n",
      "A = G.adjacency_matrix()\n",
      "\n",
      "# Set the number of nodes to be used for training and testing\n",
      "n_train = int(0.8 * len(G.nodes))\n",
      "n_test = len(G.nodes) - n_train\n",
      "\n",
      "# Split the nodes into training and test sets\n",
      "train_nodes, test_nodes = np.split(list(G.nodes), [n_train])\n",
      "\n",
      "# Create a reservoir with 20 units, using the sigmoid function as activation function\n",
      "reservoir = rp.Reservoir(n_units=20, activation='sigmoid')\n",
      "\n",
      "# Train the reservoir on the training set\n",
      "reservoir.train(A[train_nodes, :], train_nodes)\n",
      "\n",
      "# Use the trained reservoir to generate a chaotic attractor\n",
      "attractor = reservoir.generate_attractor(A[test_nodes, :], test_nodes, n_steps=1000)\n",
      "```\n",
      "\n",
      "In this example, we create a random graph with 100 nodes and an edge probability of 0.5 using the `random_erdos_renyi_graph` function from the reservoirPy library. We then split the nodes into training and testing sets, creating a reservoir with 20 units using the sigmoid activation function. The reservoir is trained on the training set using the `train` method, and then used to generate a chaotic attractor by applying it to the adjacency matrix of the graph.\n",
      "\n",
      "This code will help us to create a more realistic and complex network with varying node properties, which can be used as input for our machine learning model. The reservoir will capture the dynamics of the network and generate a high-dimensional representation of the data that can be used for classification or regression tasks.\n"
     ]
    }
   ],
   "source": [
    "query = \"Code me a simple reservoir using the reservoirPy library\"\n",
    "llama_rag.respond(query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
